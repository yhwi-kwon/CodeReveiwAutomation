{"patch": "@@ -442,7 +442,17 @@ configRetry:\n \t\tlog.Infof(\"Starting the Typha connection\")\n \t\terr := typhaConnection.Start(context.Background())\n \t\tif err != nil {\n-\t\t\tlog.WithError(err).Fatal(\"Failed to connect to Typha\")\n+\t\t\tretry := 0\n+\t\t\tfor err != nil && retry < 10 {\n+\t\t\t\t// Set Ready and Live to false\n+\t\t\t\thealthAggregator.Report(healthName, &health.HealthReport{Live: false, Ready: false})\n+\t\t\t\terr = typhaConnection.Start(context.Background())\n+\t\t\t\tlog.WithError(err).Warn(\"Retrying to start Typha\")\n+\t\t\t\tretry++\n+\t\t\t}\n+\t\t\tif err != nil && retry > 10 {\n+\t\t\t\tlog.WithError(err).Fatal(\"Failed to connect to Typha\")\n+\t\t\t}\n \t\t}\n \t\tgo func() {\n \t\t\ttyphaConnection.Finished.Wait()", "y": 1, "oldf": "// Copyright (c) 2017-2019 Tigera, Inc. All rights reserved.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage daemon\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"math/rand\"\n\t\"net/http\"\n\t\"os\"\n\t\"os/exec\"\n\t\"os/signal\"\n\t\"runtime\"\n\t\"runtime/debug\"\n\t\"syscall\"\n\t\"time\"\n\n\t\"github.com/prometheus/client_golang/prometheus\"\n\t\"github.com/prometheus/client_golang/prometheus/promhttp\"\n\tlog \"github.com/sirupsen/logrus\"\n\t\"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/client-go/kubernetes\"\n\t\"k8s.io/client-go/rest\"\n\n\t\"github.com/projectcalico/felix/buildinfo\"\n\t\"github.com/projectcalico/felix/calc\"\n\t\"github.com/projectcalico/felix/config\"\n\t_ \"github.com/projectcalico/felix/config\"\n\tdp \"github.com/projectcalico/felix/dataplane\"\n\t\"github.com/projectcalico/felix/logutils\"\n\t\"github.com/projectcalico/felix/policysync\"\n\t\"github.com/projectcalico/felix/proto\"\n\t\"github.com/projectcalico/felix/statusrep\"\n\t\"github.com/projectcalico/felix/usagerep\"\n\tapiv3 \"github.com/projectcalico/libcalico-go/lib/apis/v3\"\n\t\"github.com/projectcalico/libcalico-go/lib/backend\"\n\tbapi \"github.com/projectcalico/libcalico-go/lib/backend/api\"\n\t\"github.com/projectcalico/libcalico-go/lib/backend/model\"\n\t\"github.com/projectcalico/libcalico-go/lib/backend/syncersv1/felixsyncer\"\n\t\"github.com/projectcalico/libcalico-go/lib/backend/syncersv1/updateprocessors\"\n\t\"github.com/projectcalico/libcalico-go/lib/backend/watchersyncer\"\n\tcerrors \"github.com/projectcalico/libcalico-go/lib/errors\"\n\t\"github.com/projectcalico/libcalico-go/lib/health\"\n\tlclogutils \"github.com/projectcalico/libcalico-go/lib/logutils\"\n\t\"github.com/projectcalico/libcalico-go/lib/set\"\n\t\"github.com/projectcalico/pod2daemon/binder\"\n\t\"github.com/projectcalico/typha/pkg/syncclient\"\n)\n\nconst usage = `Felix, the Calico per-host daemon.\n\nUsage:\n  calico-felix [options]\n\nOptions:\n  -c --config-file=<filename>  Config file to load [default: /etc/calico/felix.cfg].\n  --version                    Print the version and exit.\n`\n\nconst (\n\t// Our default value for GOGC if it is not set.  This is the percentage that heap usage must\n\t// grow by to trigger a garbage collection.  Go's default is 100, meaning that 50% of the\n\t// heap can be lost to garbage.  We reduce it to this value to trade increased CPU usage for\n\t// lower occupancy.\n\tdefaultGCPercent = 20\n\n\t// String sent on the failure report channel to indicate we're shutting down for config\n\t// change.\n\treasonConfigChanged = \"config changed\"\n\t// Process return code used to report a config change.  This is the same as the code used\n\t// by SIGHUP, which means that the wrapper script also restarts Felix on a SIGHUP.\n\tconfigChangedRC = 129\n)\n\n// Run is the entry point to run a Felix instance.\n//\n// Its main role is to sequence Felix's startup by:\n//\n// Initialising early logging config (log format and early debug settings).\n//\n// Parsing command line parameters.\n//\n// Loading datastore configuration from the environment or config file.\n//\n// Loading more configuration from the datastore (this is retried until success).\n//\n// Starting the configured internal (golang) or external dataplane driver.\n//\n// Starting the background processing goroutines, which load and keep in sync with the\n// state from the datastore, the \"calculation graph\".\n//\n// Starting the usage reporting and prometheus metrics endpoint threads (if configured).\n//\n// Then, it defers to monitorAndManageShutdown(), which blocks until one of the components\n// fails, then attempts a graceful shutdown.  At that point, all the processing is in\n// background goroutines.\n//\n// To avoid having to maintain rarely-used code paths, Felix handles updates to its\n// main config parameters by exiting and allowing itself to be restarted by the init\n// daemon.\nfunc Run(configFile string) {\n\t// Go's RNG is not seeded by default.  Do that now.\n\trand.Seed(time.Now().UTC().UnixNano())\n\n\t// Special-case handling for environment variable-configured logging:\n\t// Initialise early so we can trace out config parsing.\n\tlogutils.ConfigureEarlyLogging()\n\n\tctx := context.Background()\n\n\tif os.Getenv(\"GOGC\") == \"\" {\n\t\t// Tune the GC to trade off a little extra CPU usage for significantly lower\n\t\t// occupancy at high scale.  This is worthwhile because Felix runs per-host so\n\t\t// any occupancy improvement is multiplied by the number of hosts.\n\t\tlog.Debugf(\"No GOGC value set, defaulting to %d%%.\", defaultGCPercent)\n\t\tdebug.SetGCPercent(defaultGCPercent)\n\t}\n\n\tbuildInfoLogCxt := log.WithFields(log.Fields{\n\t\t\"version\":    buildinfo.GitVersion,\n\t\t\"buildDate\":  buildinfo.BuildDate,\n\t\t\"gitCommit\":  buildinfo.GitRevision,\n\t\t\"GOMAXPROCS\": runtime.GOMAXPROCS(0),\n\t})\n\tbuildInfoLogCxt.Info(\"Felix starting up\")\n\n\t// Health monitoring, for liveness and readiness endpoints.  The following loop can take a\n\t// while before the datastore reports itself as ready - for example when there is data that\n\t// needs to be migrated from a previous version - and we still want to Felix to report\n\t// itself as live (but not ready) while we are waiting for that.  So we create the\n\t// aggregator upfront and will start serving health status over HTTP as soon as we see _any_\n\t// config that indicates that.\n\thealthAggregator := health.NewHealthAggregator()\n\n\tconst healthName = \"felix-startup\"\n\n\t// Register this function as a reporter of liveness and readiness, with no timeout.\n\thealthAggregator.RegisterReporter(healthName, &health.HealthReport{Live: true, Ready: true}, 0)\n\n\t// Load the configuration from all the different sources including the\n\t// datastore and merge. Keep retrying on failure.  We'll sit in this\n\t// loop until the datastore is ready.\n\tlog.Info(\"Loading configuration...\")\n\tvar backendClient bapi.Client\n\tvar configParams *config.Config\n\tvar typhaAddr string\n\tvar numClientsCreated int\nconfigRetry:\n\tfor {\n\t\tif numClientsCreated > 60 {\n\t\t\t// If we're in a restart loop, periodically exit (so we can be restarted) since\n\t\t\t// - it may solve the problem if there's something wrong with our process\n\t\t\t// - it prevents us from leaking connections to the datastore.\n\t\t\texitWithCustomRC(configChangedRC, \"Restarting to avoid leaking datastore connections\")\n\t\t}\n\n\t\t// Make an initial report that says we're live but not yet ready.\n\t\thealthAggregator.Report(healthName, &health.HealthReport{Live: true, Ready: false})\n\n\t\t// Load locally-defined config, including the datastore connection\n\t\t// parameters. First the environment variables.\n\t\tconfigParams = config.New()\n\t\tenvConfig := config.LoadConfigFromEnvironment(os.Environ())\n\t\t// Then, the config file.\n\t\tlog.Infof(\"Loading config file: %v\", configFile)\n\t\tfileConfig, err := config.LoadConfigFile(configFile)\n\t\tif err != nil {\n\t\t\tlog.WithError(err).WithField(\"configFile\", configFile).Error(\n\t\t\t\t\"Failed to load configuration file\")\n\t\t\ttime.Sleep(1 * time.Second)\n\t\t\tcontinue configRetry\n\t\t}\n\t\t// Parse and merge the local config.\n\t\tconfigParams.UpdateFrom(envConfig, config.EnvironmentVariable)\n\t\tif configParams.Err != nil {\n\t\t\tlog.WithError(configParams.Err).WithField(\"configFile\", configFile).Error(\n\t\t\t\t\"Failed to parse configuration environment variable\")\n\t\t\ttime.Sleep(1 * time.Second)\n\t\t\tcontinue configRetry\n\t\t}\n\t\tconfigParams.UpdateFrom(fileConfig, config.ConfigFile)\n\t\tif configParams.Err != nil {\n\t\t\tlog.WithError(configParams.Err).WithField(\"configFile\", configFile).Error(\n\t\t\t\t\"Failed to parse configuration file\")\n\t\t\ttime.Sleep(1 * time.Second)\n\t\t\tcontinue configRetry\n\t\t}\n\n\t\t// Each time round this loop, check that we're serving health reports if we should\n\t\t// be, or cancel any existing server if we should not be serving any more.\n\t\thealthAggregator.ServeHTTP(configParams.HealthEnabled, configParams.HealthHost, configParams.HealthPort)\n\n\t\t// We should now have enough config to connect to the datastore\n\t\t// so we can load the remainder of the config.\n\t\tdatastoreConfig := configParams.DatastoreConfig()\n\t\t// Can't dump the whole config because it may have sensitive information...\n\t\tlog.WithField(\"datastore\", datastoreConfig.Spec.DatastoreType).Info(\"Connecting to datastore\")\n\t\tbackendClient, err = backend.NewClient(datastoreConfig)\n\t\tif err != nil {\n\t\t\tlog.WithError(err).Error(\"Failed to create datastore client\")\n\t\t\ttime.Sleep(1 * time.Second)\n\t\t\tcontinue configRetry\n\t\t}\n\t\tlog.Info(\"Created datastore client\")\n\t\tnumClientsCreated++\n\t\tfor {\n\t\t\tglobalConfig, hostConfig, err := loadConfigFromDatastore(\n\t\t\t\tctx, backendClient, configParams.FelixHostname)\n\t\t\tif err == ErrNotReady {\n\t\t\t\tlog.Warn(\"Waiting for datastore to be initialized (or migrated)\")\n\t\t\t\ttime.Sleep(1 * time.Second)\n\t\t\t\thealthAggregator.Report(healthName, &health.HealthReport{Live: true, Ready: true})\n\t\t\t\tcontinue\n\t\t\t} else if err != nil {\n\t\t\t\tlog.WithError(err).Error(\"Failed to get config from datastore\")\n\t\t\t\ttime.Sleep(1 * time.Second)\n\t\t\t\tcontinue configRetry\n\t\t\t}\n\t\t\tconfigParams.UpdateFrom(globalConfig, config.DatastoreGlobal)\n\t\t\tconfigParams.UpdateFrom(hostConfig, config.DatastorePerHost)\n\t\t\tbreak\n\t\t}\n\t\tconfigParams.Validate()\n\t\tif configParams.Err != nil {\n\t\t\tlog.WithError(configParams.Err).Error(\n\t\t\t\t\"Failed to parse/validate configuration from datastore.\")\n\t\t\ttime.Sleep(1 * time.Second)\n\t\t\tcontinue configRetry\n\t\t}\n\n\t\t// We now have some config flags that affect how we configure the syncer.\n\t\t// After loading the config from the datastore, reconnect, possibly with new\n\t\t// config.  We don't need to re-load the configuration _again_ because the\n\t\t// calculation graph will spot if the config has changed since we were initialised.\n\t\tdatastoreConfig = configParams.DatastoreConfig()\n\t\tbackendClient, err = backend.NewClient(datastoreConfig)\n\t\tif err != nil {\n\t\t\tlog.WithError(err).Error(\"Failed to (re)connect to datastore\")\n\t\t\ttime.Sleep(1 * time.Second)\n\t\t\tcontinue configRetry\n\t\t}\n\t\tnumClientsCreated++\n\n\t\t// If we're configured to discover Typha, do that now so we can retry if we fail.\n\t\ttyphaAddr, err = discoverTyphaAddr(configParams)\n\t\tif err != nil {\n\t\t\tlog.WithError(err).Error(\"Typha discovery enabled but discovery failed.\")\n\t\t\ttime.Sleep(1 * time.Second)\n\t\t\tcontinue configRetry\n\t\t}\n\n\t\tbreak configRetry\n\t}\n\n\tif numClientsCreated > 2 {\n\t\t// We don't have a way to close datastore connection so, if we reconnected after\n\t\t// a failure to load config, restart felix to avoid leaking connections.\n\t\texitWithCustomRC(configChangedRC, \"Restarting to avoid leaking datastore connections\")\n\t}\n\n\t// We're now both live and ready.\n\thealthAggregator.Report(healthName, &health.HealthReport{Live: true, Ready: true})\n\n\t// Enable or disable the health HTTP server according to coalesced config.\n\thealthAggregator.ServeHTTP(configParams.HealthEnabled, configParams.HealthHost, configParams.HealthPort)\n\n\t// If we get here, we've loaded the configuration successfully.\n\t// Update log levels before we do anything else.\n\tlogutils.ConfigureLogging(configParams)\n\t// Since we may have enabled more logging, log with the build context\n\t// again.\n\tbuildInfoLogCxt.WithField(\"config\", configParams).Info(\n\t\t\"Successfully loaded configuration.\")\n\n\t// Start up the dataplane driver.  This may be the internal go-based driver or an external\n\t// one.\n\tvar dpDriver dp.DataplaneDriver\n\tvar dpDriverCmd *exec.Cmd\n\n\tfailureReportChan := make(chan string)\n\tconfigChangedRestartCallback := func() { failureReportChan <- reasonConfigChanged }\n\n\tdpDriver, dpDriverCmd = dp.StartDataplaneDriver(configParams, healthAggregator, configChangedRestartCallback)\n\n\t// Initialise the glue logic that connects the calculation graph to/from the dataplane driver.\n\tlog.Info(\"Connect to the dataplane driver.\")\n\n\tvar connToUsageRepUpdChan chan map[string]string\n\tif configParams.UsageReportingEnabled {\n\t\t// Make a channel for the connector to use to send updates to the usage reporter.\n\t\t// (Otherwise, we pass in a nil channel, which disables such updates.)\n\t\tconnToUsageRepUpdChan = make(chan map[string]string, 1)\n\t}\n\tdpConnector := newConnector(configParams, connToUsageRepUpdChan, backendClient, dpDriver, failureReportChan)\n\n\t// If enabled, create a server for the policy sync API.  This allows clients to connect to\n\t// Felix over a socket and receive policy updates.\n\tvar policySyncServer *policysync.Server\n\tvar policySyncProcessor *policysync.Processor\n\tvar policySyncAPIBinder binder.Binder\n\tcalcGraphClientChannels := []chan<- interface{}{dpConnector.ToDataplane}\n\tif configParams.PolicySyncPathPrefix != \"\" {\n\t\tlog.WithField(\"policySyncPathPrefix\", configParams.PolicySyncPathPrefix).Info(\n\t\t\t\"Policy sync API enabled.  Creating the policy sync server.\")\n\t\ttoPolicySync := make(chan interface{})\n\t\tpolicySyncUIDAllocator := policysync.NewUIDAllocator()\n\t\tpolicySyncProcessor = policysync.NewProcessor(toPolicySync)\n\t\tpolicySyncServer = policysync.NewServer(\n\t\t\tpolicySyncProcessor.JoinUpdates,\n\t\t\tpolicySyncUIDAllocator.NextUID,\n\t\t)\n\t\tpolicySyncAPIBinder = binder.NewBinder(configParams.PolicySyncPathPrefix)\n\t\tpolicySyncServer.RegisterGrpc(policySyncAPIBinder.Server())\n\t\tcalcGraphClientChannels = append(calcGraphClientChannels, toPolicySync)\n\t}\n\n\t// Now create the calculation graph, which receives updates from the\n\t// datastore and outputs dataplane updates for the dataplane driver.\n\t//\n\t// The Syncer has its own thread and we use an extra thread for the\n\t// Validator, just to pipeline that part of the calculation then the\n\t// main calculation graph runs in a single thread for simplicity.\n\t// The output of the calculation graph arrives at the dataplane\n\t// connection via channel.\n\t//\n\t// Syncer -chan-> Validator -chan-> Calc graph -chan->   dataplane\n\t//        KVPair            KVPair             protobufs\n\n\t// Get a Syncer from the datastore, or a connection to our remote sync daemon, Typha,\n\t// which will feed the calculation graph with updates, bringing Felix into sync.\n\tvar syncer Startable\n\tvar typhaConnection *syncclient.SyncerClient\n\tsyncerToValidator := calc.NewSyncerCallbacksDecoupler()\n\tif typhaAddr != \"\" {\n\t\t// Use a remote Syncer, via the Typha server.\n\t\tlog.WithField(\"addr\", typhaAddr).Info(\"Connecting to Typha.\")\n\t\ttyphaConnection = syncclient.New(\n\t\t\ttyphaAddr,\n\t\t\tbuildinfo.GitVersion,\n\t\t\tconfigParams.FelixHostname,\n\t\t\tfmt.Sprintf(\"Revision: %s; Build date: %s\",\n\t\t\t\tbuildinfo.GitRevision, buildinfo.BuildDate),\n\t\t\tsyncerToValidator,\n\t\t\t&syncclient.Options{\n\t\t\t\tReadTimeout:  configParams.TyphaReadTimeout,\n\t\t\t\tWriteTimeout: configParams.TyphaWriteTimeout,\n\t\t\t\tKeyFile:      configParams.TyphaKeyFile,\n\t\t\t\tCertFile:     configParams.TyphaCertFile,\n\t\t\t\tCAFile:       configParams.TyphaCAFile,\n\t\t\t\tServerCN:     configParams.TyphaCN,\n\t\t\t\tServerURISAN: configParams.TyphaURISAN,\n\t\t\t},\n\t\t)\n\t} else {\n\t\t// Use the syncer locally.\n\t\tsyncer = felixsyncer.New(backendClient, syncerToValidator)\n\t}\n\tlog.WithField(\"syncer\", syncer).Info(\"Created Syncer\")\n\n\t// Create the ipsets/active policy calculation graph, which will\n\t// do the dynamic calculation of ipset memberships and active policies\n\t// etc.\n\tasyncCalcGraph := calc.NewAsyncCalcGraph(\n\t\tconfigParams,\n\t\tcalcGraphClientChannels,\n\t\thealthAggregator,\n\t)\n\n\tif configParams.UsageReportingEnabled {\n\t\t// Usage reporting enabled, add stats collector to graph.  When it detects an update\n\t\t// to the stats, it makes a callback, which we use to send an update on a channel.\n\t\t// We use a buffered channel here to avoid blocking the calculation graph.\n\t\tstatsChanIn := make(chan calc.StatsUpdate, 1)\n\t\tstatsCollector := calc.NewStatsCollector(func(stats calc.StatsUpdate) error {\n\t\t\tstatsChanIn <- stats\n\t\t\treturn nil\n\t\t})\n\t\tstatsCollector.RegisterWith(asyncCalcGraph.CalcGraph)\n\n\t\t// Rather than sending the updates directly to the usage reporting thread, we\n\t\t// decouple with an extra goroutine.  This prevents blocking the calculation graph\n\t\t// goroutine if the usage reporting goroutine is blocked on IO, for example.\n\t\t// Using a buffered channel wouldn't work here because the usage reporting\n\t\t// goroutine can block for a long time on IO so we could build up a long queue.\n\t\tstatsChanOut := make(chan calc.StatsUpdate)\n\t\tgo func() {\n\t\t\tvar statsChanOutOrNil chan calc.StatsUpdate\n\t\t\tvar stats calc.StatsUpdate\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase stats = <-statsChanIn:\n\t\t\t\t\t// Got a stats update, activate the output channel.\n\t\t\t\t\tlog.WithField(\"stats\", stats).Debug(\"Buffer: stats update received\")\n\t\t\t\t\tstatsChanOutOrNil = statsChanOut\n\t\t\t\tcase statsChanOutOrNil <- stats:\n\t\t\t\t\t// Passed on the update, deactivate the output channel until\n\t\t\t\t\t// the next update.\n\t\t\t\t\tlog.WithField(\"stats\", stats).Debug(\"Buffer: stats update sent\")\n\t\t\t\t\tstatsChanOutOrNil = nil\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\n\t\tusageRep := usagerep.New(\n\t\t\tconfigParams.UsageReportingInitialDelaySecs,\n\t\t\tconfigParams.UsageReportingIntervalSecs,\n\t\t\tstatsChanOut,\n\t\t\tconnToUsageRepUpdChan,\n\t\t)\n\t\tgo usageRep.PeriodicallyReportUsage(context.Background())\n\t} else {\n\t\t// Usage reporting disabled, but we still want a stats collector for the\n\t\t// felix_cluster_* metrics.  Register a no-op function as the callback.\n\t\tstatsCollector := calc.NewStatsCollector(func(stats calc.StatsUpdate) error {\n\t\t\treturn nil\n\t\t})\n\t\tstatsCollector.RegisterWith(asyncCalcGraph.CalcGraph)\n\t}\n\n\t// Create the validator, which sits between the syncer and the\n\t// calculation graph.\n\tvalidator := calc.NewValidationFilter(asyncCalcGraph)\n\n\t// Start the background processing threads.\n\tif syncer != nil {\n\t\tlog.Infof(\"Starting the datastore Syncer\")\n\t\tsyncer.Start()\n\t} else {\n\t\tlog.Infof(\"Starting the Typha connection\")\n\t\terr := typhaConnection.Start(context.Background())\n\t\tif err != nil {\n\t\t\tlog.WithError(err).Fatal(\"Failed to connect to Typha\")\n\t\t}\n\t\tgo func() {\n\t\t\ttyphaConnection.Finished.Wait()\n\t\t\tfailureReportChan <- \"Connection to Typha failed\"\n\t\t}()\n\t}\n\tgo syncerToValidator.SendTo(validator)\n\tasyncCalcGraph.Start()\n\tlog.Infof(\"Started the processing graph\")\n\tvar stopSignalChans []chan<- bool\n\tif configParams.EndpointReportingEnabled {\n\t\tdelay := configParams.EndpointReportingDelaySecs\n\t\tlog.WithField(\"delay\", delay).Info(\n\t\t\t\"Endpoint status reporting enabled, starting status reporter\")\n\t\tdpConnector.statusReporter = statusrep.NewEndpointStatusReporter(\n\t\t\tconfigParams.FelixHostname,\n\t\t\tconfigParams.OpenstackRegion,\n\t\t\tdpConnector.StatusUpdatesFromDataplane,\n\t\t\tdpConnector.InSync,\n\t\t\tdpConnector.datastore,\n\t\t\tdelay,\n\t\t\tdelay*180,\n\t\t)\n\t\tdpConnector.statusReporter.Start()\n\t}\n\n\t// Start communicating with the dataplane driver.\n\tdpConnector.Start()\n\n\tif policySyncProcessor != nil {\n\t\tlog.WithField(\"policySyncPathPrefix\", configParams.PolicySyncPathPrefix).Info(\n\t\t\t\"Policy sync API enabled.  Starting the policy sync server.\")\n\t\tpolicySyncProcessor.Start()\n\t\tsc := make(chan bool)\n\t\tstopSignalChans = append(stopSignalChans, sc)\n\t\tgo policySyncAPIBinder.SearchAndBind(sc)\n\t}\n\n\t// Send the opening message to the dataplane driver, giving it its\n\t// config.\n\tdpConnector.ToDataplane <- &proto.ConfigUpdate{\n\t\tConfig: configParams.RawValues(),\n\t}\n\n\tif configParams.PrometheusMetricsEnabled {\n\t\tlog.Info(\"Prometheus metrics enabled.  Starting server.\")\n\t\tgaugeHost := prometheus.NewGauge(prometheus.GaugeOpts{\n\t\t\tName:        \"felix_host\",\n\t\t\tHelp:        \"Configured Felix hostname (as a label), typically used in grouping/aggregating stats; the label defaults to the hostname of the host but can be overridden by configuration. The value of the gauge is always set to 1.\",\n\t\t\tConstLabels: prometheus.Labels{\"host\": configParams.FelixHostname},\n\t\t})\n\t\tgaugeHost.Set(1)\n\t\tprometheus.MustRegister(gaugeHost)\n\t\tgo servePrometheusMetrics(configParams)\n\t}\n\n\t// Register signal handlers to dump memory/CPU profiles.\n\tlogutils.RegisterProfilingSignalHandlers(configParams)\n\n\t// Now monitor the worker process and our worker threads and shut\n\t// down the process gracefully if they fail.\n\tmonitorAndManageShutdown(failureReportChan, dpDriverCmd, stopSignalChans)\n}\n\nfunc servePrometheusMetrics(configParams *config.Config) {\n\tfor {\n\t\tlog.WithField(\"port\", configParams.PrometheusMetricsPort).Info(\"Starting prometheus metrics endpoint\")\n\t\tif configParams.PrometheusGoMetricsEnabled && configParams.PrometheusProcessMetricsEnabled {\n\t\t\tlog.Info(\"Including Golang & Process metrics\")\n\t\t} else {\n\t\t\tif !configParams.PrometheusGoMetricsEnabled {\n\t\t\t\tlog.Info(\"Discarding Golang metrics\")\n\t\t\t\tprometheus.Unregister(prometheus.NewGoCollector())\n\t\t\t}\n\t\t\tif !configParams.PrometheusProcessMetricsEnabled {\n\t\t\t\tlog.Info(\"Discarding process metrics\")\n\t\t\t\tprometheus.Unregister(prometheus.NewProcessCollector(prometheus.ProcessCollectorOpts{}))\n\t\t\t}\n\t\t}\n\t\thttp.Handle(\"/metrics\", promhttp.Handler())\n\t\terr := http.ListenAndServe(fmt.Sprintf(\":%v\", configParams.PrometheusMetricsPort), nil)\n\t\tlog.WithError(err).Error(\n\t\t\t\"Prometheus metrics endpoint failed, trying to restart it...\")\n\t\ttime.Sleep(1 * time.Second)\n\t}\n}\n\nfunc monitorAndManageShutdown(failureReportChan <-chan string, driverCmd *exec.Cmd, stopSignalChans []chan<- bool) {\n\t// Ask the runtime to tell us if we get a term/int signal.\n\tsignalChan := make(chan os.Signal, 1)\n\tsignal.Notify(signalChan, syscall.SIGTERM)\n\tsignal.Notify(signalChan, syscall.SIGINT)\n\tsignal.Notify(signalChan, syscall.SIGHUP)\n\n\t// Start a background thread to tell us when the dataplane driver stops.\n\t// If the driver stops unexpectedly, we'll terminate this process.\n\t// If this process needs to stop, we'll kill the driver and then wait\n\t// for the message from the background thread.\n\tdriverStoppedC := make(chan bool)\n\tgo func() {\n\t\tif driverCmd == nil {\n\t\t\tlog.Info(\"No driver process to monitor\")\n\t\t\treturn\n\t\t}\n\t\terr := driverCmd.Wait()\n\t\tlog.WithError(err).Warn(\"Driver process stopped\")\n\t\tdriverStoppedC <- true\n\t}()\n\n\t// Wait for one of the channels to give us a reason to shut down.\n\tdriverAlreadyStopped := driverCmd == nil\n\treceivedFatalSignal := false\n\tvar reason string\n\tselect {\n\tcase <-driverStoppedC:\n\t\treason = \"Driver stopped\"\n\t\tdriverAlreadyStopped = true\n\tcase sig := <-signalChan:\n\t\tif sig == syscall.SIGHUP {\n\t\t\tlog.Warning(\"Received a SIGHUP, treating as a request to reload config\")\n\t\t\treason = reasonConfigChanged\n\t\t} else {\n\t\t\treason = fmt.Sprintf(\"Received OS signal %v\", sig)\n\t\t\treceivedFatalSignal = true\n\t\t}\n\tcase reason = <-failureReportChan:\n\t}\n\tlogCxt := log.WithField(\"reason\", reason)\n\tlogCxt.Warn(\"Felix is shutting down\")\n\n\t// Notify other components to stop.\n\tfor _, c := range stopSignalChans {\n\t\tselect {\n\t\tcase c <- true:\n\t\tdefault:\n\t\t}\n\t}\n\n\tif !driverAlreadyStopped {\n\t\t// Driver may still be running, just in case the driver is\n\t\t// unresponsive, start a thread to kill this process if we\n\t\t// don't manage to kill the driver.\n\t\tlogCxt.Info(\"Driver still running, trying to shut it down...\")\n\t\tgiveUpOnSigTerm := make(chan bool)\n\t\tgo func() {\n\t\t\ttime.Sleep(4 * time.Second)\n\t\t\tgiveUpOnSigTerm <- true\n\t\t\ttime.Sleep(1 * time.Second)\n\t\t\tlog.Fatal(\"Failed to wait for driver to exit, giving up.\")\n\t\t}()\n\t\t// Signal to the driver to exit.\n\t\tdriverCmd.Process.Signal(syscall.SIGTERM)\n\t\tselect {\n\t\tcase <-driverStoppedC:\n\t\t\tlogCxt.Info(\"Driver shut down after SIGTERM\")\n\t\tcase <-giveUpOnSigTerm:\n\t\t\tlogCxt.Error(\"Driver did not respond to SIGTERM, sending SIGKILL\")\n\t\t\tdriverCmd.Process.Kill()\n\t\t\t<-driverStoppedC\n\t\t\tlogCxt.Info(\"Driver shut down after SIGKILL\")\n\t\t}\n\t}\n\n\tif !receivedFatalSignal {\n\t\t// We're exiting due to a failure or a config change, wait\n\t\t// a couple of seconds to ensure that we don't go into a tight\n\t\t// restart loop (which would make the init daemon in calico/node give\n\t\t// up trying to restart us).\n\t\tlogCxt.Info(\"Sleeping to avoid tight restart loop.\")\n\t\tgo func() {\n\t\t\ttime.Sleep(2 * time.Second)\n\n\t\t\tif reason == reasonConfigChanged {\n\t\t\t\texitWithCustomRC(configChangedRC, \"Exiting for config change\")\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tlogCxt.Fatal(\"Exiting.\")\n\t\t}()\n\n\t\tfor {\n\t\t\tsig := <-signalChan\n\t\t\tif sig == syscall.SIGHUP {\n\t\t\t\tlogCxt.Warning(\"Ignoring SIGHUP because we're already shutting down\")\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tlogCxt.WithField(\"signal\", sig).Fatal(\n\t\t\t\t\"Signal received while shutting down, exiting immediately\")\n\t\t}\n\t}\n\n\tlogCxt.Fatal(\"Exiting immediately\")\n}\n\nfunc exitWithCustomRC(rc int, message string) {\n\t// Since log writing is done a background thread, we set the force-flush flag on this log to ensure that\n\t// all the in-flight logs get written before we exit.\n\tlog.WithFields(log.Fields{\n\t\t\"rc\":                       rc,\n\t\tlclogutils.FieldForceFlush: true,\n\t}).Info(message)\n\tos.Exit(rc)\n}\n\nvar (\n\tErrNotReady = errors.New(\"datastore is not ready or has not been initialised\")\n)\n\nfunc loadConfigFromDatastore(\n\tctx context.Context, client bapi.Client, hostname string,\n) (globalConfig, hostConfig map[string]string, err error) {\n\n\t// The configuration is split over 3 different resource types and 4 different resource\n\t// instances in the v3 data model:\n\t// -  ClusterInformation (global): name \"default\"\n\t// -  FelixConfiguration (global): name \"default\"\n\t// -  FelixConfiguration (per-host): name \"node.<hostname>\"\n\t// -  Node (per-host): name: <hostname>\n\t// Get the global values and host specific values separately.  We re-use the updateprocessor\n\t// logic to convert the single v3 resource to a set of v1 key/values.\n\thostConfig = make(map[string]string)\n\tglobalConfig = make(map[string]string)\n\tvar ready bool\n\terr = getAndMergeConfig(\n\t\tctx, client, globalConfig,\n\t\tapiv3.KindClusterInformation, \"default\",\n\t\tupdateprocessors.NewClusterInfoUpdateProcessor(),\n\t\t&ready,\n\t)\n\tif err != nil {\n\t\treturn\n\t}\n\tif !ready {\n\t\t// The ClusterInformation struct should contain the ready flag, if it is not set, abort.\n\t\terr = ErrNotReady\n\t\treturn\n\t}\n\terr = getAndMergeConfig(\n\t\tctx, client, globalConfig,\n\t\tapiv3.KindFelixConfiguration, \"default\",\n\t\tupdateprocessors.NewFelixConfigUpdateProcessor(),\n\t\t&ready,\n\t)\n\tif err != nil {\n\t\treturn\n\t}\n\terr = getAndMergeConfig(\n\t\tctx, client, hostConfig,\n\t\tapiv3.KindFelixConfiguration, \"node.\"+hostname,\n\t\tupdateprocessors.NewFelixConfigUpdateProcessor(),\n\t\t&ready,\n\t)\n\tif err != nil {\n\t\treturn\n\t}\n\terr = getAndMergeConfig(\n\t\tctx, client, hostConfig,\n\t\tapiv3.KindNode, hostname,\n\t\tupdateprocessors.NewFelixNodeUpdateProcessor(),\n\t\t&ready,\n\t)\n\tif err != nil {\n\t\treturn\n\t}\n\n\treturn\n}\n\n// getAndMergeConfig gets the v3 resource configuration extracts the separate config values\n// (where each configuration value is stored in a field of the v3 resource Spec) and merges into\n// the supplied map, as required by our v1-style configuration loader.\nfunc getAndMergeConfig(\n\tctx context.Context, client bapi.Client, config map[string]string,\n\tkind string, name string,\n\tconfigConverter watchersyncer.SyncerUpdateProcessor,\n\tready *bool,\n) error {\n\tlogCxt := log.WithFields(log.Fields{\"kind\": kind, \"name\": name})\n\n\tcfg, err := client.Get(ctx, model.ResourceKey{\n\t\tKind:      kind,\n\t\tName:      name,\n\t\tNamespace: \"\",\n\t}, \"\")\n\tif err != nil {\n\t\tswitch err.(type) {\n\t\tcase cerrors.ErrorResourceDoesNotExist:\n\t\t\tlogCxt.Info(\"No config of this type\")\n\t\t\treturn nil\n\t\tdefault:\n\t\t\tlogCxt.WithError(err).Info(\"Failed to load config from datastore\")\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// Re-use the update processor logic implemented for the Syncer.  We give it a v3 config\n\t// object in a KVPair and it uses the annotations defined on it to split it into v1-style\n\t// KV pairs.  Log any errors - but don't fail completely to avoid cyclic restarts.\n\tv1kvs, err := configConverter.Process(cfg)\n\tif err != nil {\n\t\tlogCxt.WithError(err).Error(\"Failed to convert configuration\")\n\t}\n\n\t// Loop through the converted values and update our config map with values from either the\n\t// Global or Host configs.\n\tfor _, v1KV := range v1kvs {\n\t\tif _, ok := v1KV.Key.(model.ReadyFlagKey); ok {\n\t\t\tlogCxt.WithField(\"ready\", v1KV.Value).Info(\"Loaded ready flag\")\n\t\t\tif v1KV.Value == true {\n\t\t\t\t*ready = true\n\t\t\t}\n\t\t} else if v1KV.Value != nil {\n\t\t\tswitch k := v1KV.Key.(type) {\n\t\t\tcase model.GlobalConfigKey:\n\t\t\t\tconfig[k.Name] = v1KV.Value.(string)\n\t\t\tcase model.HostConfigKey:\n\t\t\t\tconfig[k.Name] = v1KV.Value.(string)\n\t\t\tdefault:\n\t\t\t\tlogCxt.WithField(\"KV\", v1KV).Debug(\"Skipping config - not required for initial loading\")\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}\n\ntype DataplaneConnector struct {\n\tconfig                     *config.Config\n\tconfigUpdChan              chan<- map[string]string\n\tToDataplane                chan interface{}\n\tStatusUpdatesFromDataplane chan interface{}\n\tInSync                     chan bool\n\tfailureReportChan          chan<- string\n\tdataplane                  dp.DataplaneDriver\n\tdatastore                  bapi.Client\n\tstatusReporter             *statusrep.EndpointStatusReporter\n\n\tdatastoreInSync bool\n\n\tfirstStatusReportSent bool\n}\n\ntype Startable interface {\n\tStart()\n}\n\nfunc newConnector(configParams *config.Config,\n\tconfigUpdChan chan<- map[string]string,\n\tdatastore bapi.Client,\n\tdataplane dp.DataplaneDriver,\n\tfailureReportChan chan<- string,\n) *DataplaneConnector {\n\tfelixConn := &DataplaneConnector{\n\t\tconfig:                     configParams,\n\t\tconfigUpdChan:              configUpdChan,\n\t\tdatastore:                  datastore,\n\t\tToDataplane:                make(chan interface{}),\n\t\tStatusUpdatesFromDataplane: make(chan interface{}),\n\t\tInSync:                     make(chan bool, 1),\n\t\tfailureReportChan:          failureReportChan,\n\t\tdataplane:                  dataplane,\n\t}\n\treturn felixConn\n}\n\nfunc (fc *DataplaneConnector) readMessagesFromDataplane() {\n\tdefer func() {\n\t\tfc.shutDownProcess(\"Failed to read messages from dataplane\")\n\t}()\n\tlog.Info(\"Reading from dataplane driver pipe...\")\n\tctx := context.Background()\n\tfor {\n\t\tpayload, err := fc.dataplane.RecvMessage()\n\t\tif err != nil {\n\t\t\tlog.WithError(err).Error(\"Failed to read from front-end socket\")\n\t\t\tfc.shutDownProcess(\"Failed to read from front-end socket\")\n\t\t}\n\t\tlog.WithField(\"payload\", payload).Debug(\"New message from dataplane\")\n\t\tswitch msg := payload.(type) {\n\t\tcase *proto.ProcessStatusUpdate:\n\t\t\tfc.handleProcessStatusUpdate(ctx, msg)\n\t\tcase *proto.WorkloadEndpointStatusUpdate:\n\t\t\tif fc.statusReporter != nil {\n\t\t\t\tfc.StatusUpdatesFromDataplane <- msg\n\t\t\t}\n\t\tcase *proto.WorkloadEndpointStatusRemove:\n\t\t\tif fc.statusReporter != nil {\n\t\t\t\tfc.StatusUpdatesFromDataplane <- msg\n\t\t\t}\n\t\tcase *proto.HostEndpointStatusUpdate:\n\t\t\tif fc.statusReporter != nil {\n\t\t\t\tfc.StatusUpdatesFromDataplane <- msg\n\t\t\t}\n\t\tcase *proto.HostEndpointStatusRemove:\n\t\t\tif fc.statusReporter != nil {\n\t\t\t\tfc.StatusUpdatesFromDataplane <- msg\n\t\t\t}\n\t\tdefault:\n\t\t\tlog.WithField(\"msg\", msg).Warning(\"Unknown message from dataplane\")\n\t\t}\n\t\tlog.Debug(\"Finished handling message from front-end\")\n\t}\n}\n\nfunc (fc *DataplaneConnector) handleProcessStatusUpdate(ctx context.Context, msg *proto.ProcessStatusUpdate) {\n\tlog.Debugf(\"Status update from dataplane driver: %v\", *msg)\n\tstatusReport := model.StatusReport{\n\t\tTimestamp:     msg.IsoTimestamp,\n\t\tUptimeSeconds: msg.Uptime,\n\t\tFirstUpdate:   !fc.firstStatusReportSent,\n\t}\n\tkv := model.KVPair{\n\t\tKey:   model.ActiveStatusReportKey{Hostname: fc.config.FelixHostname, RegionString: model.RegionString(fc.config.OpenstackRegion)},\n\t\tValue: &statusReport,\n\t\tTTL:   fc.config.ReportingTTLSecs,\n\t}\n\tapplyCtx, cancel := context.WithTimeout(ctx, 2*time.Second)\n\t_, err := fc.datastore.Apply(applyCtx, &kv)\n\tcancel()\n\tif err != nil {\n\t\tif _, ok := err.(cerrors.ErrorOperationNotSupported); ok {\n\t\t\tlog.Debug(\"Datastore doesn't support status reports.\")\n\t\t\treturn // and it won't support the last status key either.\n\t\t} else {\n\t\t\tlog.Warningf(\"Failed to write status to datastore: %v\", err)\n\t\t}\n\t} else {\n\t\tfc.firstStatusReportSent = true\n\t}\n\tkv = model.KVPair{\n\t\tKey:   model.LastStatusReportKey{Hostname: fc.config.FelixHostname, RegionString: model.RegionString(fc.config.OpenstackRegion)},\n\t\tValue: &statusReport,\n\t}\n\tapplyCtx, cancel = context.WithTimeout(ctx, 2*time.Second)\n\t_, err = fc.datastore.Apply(applyCtx, &kv)\n\tcancel()\n\tif err != nil {\n\t\tlog.Warningf(\"Failed to write status to datastore: %v\", err)\n\t}\n}\n\nvar handledConfigChanges = set.From(\"CalicoVersion\", \"ClusterGUID\", \"ClusterType\")\n\nfunc (fc *DataplaneConnector) sendMessagesToDataplaneDriver() {\n\tdefer func() {\n\t\tfc.shutDownProcess(\"Failed to send messages to dataplane\")\n\t}()\n\n\tvar config map[string]string\n\tfor {\n\t\tmsg := <-fc.ToDataplane\n\t\tswitch msg := msg.(type) {\n\t\tcase *proto.InSync:\n\t\t\tlog.Info(\"Datastore now in sync.\")\n\t\t\tif !fc.datastoreInSync {\n\t\t\t\tlog.Info(\"Datastore in sync for first time, sending message to status reporter.\")\n\t\t\t\tfc.datastoreInSync = true\n\t\t\t\tfc.InSync <- true\n\t\t\t}\n\t\tcase *proto.ConfigUpdate:\n\t\t\tif config != nil {\n\t\t\t\tlog.WithFields(log.Fields{\n\t\t\t\t\t\"old\": config,\n\t\t\t\t\t\"new\": msg.Config,\n\t\t\t\t}).Info(\"Config updated, checking whether we need to restart\")\n\t\t\t\trestartNeeded := false\n\t\t\t\tfor kNew, vNew := range msg.Config {\n\t\t\t\t\tlogCxt := log.WithFields(log.Fields{\"key\": kNew, \"new\": vNew})\n\t\t\t\t\tif vOld, prs := config[kNew]; !prs {\n\t\t\t\t\t\tlogCxt = logCxt.WithField(\"updateType\", \"add\")\n\t\t\t\t\t} else if vNew != vOld {\n\t\t\t\t\t\tlogCxt = logCxt.WithFields(log.Fields{\"old\": vOld, \"updateType\": \"update\"})\n\t\t\t\t\t} else {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif handledConfigChanges.Contains(kNew) {\n\t\t\t\t\t\tlogCxt.Info(\"Config change can be handled without restart\")\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tlogCxt.Warning(\"Config change requires restart\")\n\t\t\t\t\trestartNeeded = true\n\t\t\t\t}\n\t\t\t\tfor kOld, vOld := range config {\n\t\t\t\t\tlogCxt := log.WithFields(log.Fields{\"key\": kOld, \"old\": vOld, \"updateType\": \"delete\"})\n\t\t\t\t\tif _, prs := msg.Config[kOld]; prs {\n\t\t\t\t\t\t// Key was present in the message so we've handled above.\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif handledConfigChanges.Contains(kOld) {\n\t\t\t\t\t\tlogCxt.Info(\"Config change can be handled without restart\")\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tlogCxt.Warning(\"Config change requires restart\")\n\t\t\t\t\trestartNeeded = true\n\t\t\t\t}\n\n\t\t\t\tif restartNeeded {\n\t\t\t\t\tfc.shutDownProcess(\"config changed\")\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Take a copy of the config to compare against next time.\n\t\t\tconfig = make(map[string]string)\n\t\t\tfor k, v := range msg.Config {\n\t\t\t\tconfig[k] = v\n\t\t\t}\n\n\t\t\tif fc.configUpdChan != nil {\n\t\t\t\t// Send the config over to the usage reporter.\n\t\t\t\tfc.configUpdChan <- config\n\t\t\t}\n\t\tcase *calc.DatastoreNotReady:\n\t\t\tlog.Warn(\"Datastore became unready, need to restart.\")\n\t\t\tfc.shutDownProcess(\"datastore became unready\")\n\t\t}\n\t\tif err := fc.dataplane.SendMessage(msg); err != nil {\n\t\t\tfc.shutDownProcess(\"Failed to write to dataplane driver\")\n\t\t}\n\t}\n}\n\nfunc (fc *DataplaneConnector) shutDownProcess(reason string) {\n\t// Send a failure report to the managed shutdown thread then give it\n\t// a few seconds to do the shutdown.\n\tfc.failureReportChan <- reason\n\ttime.Sleep(5 * time.Second)\n\t// The graceful shutdown failed, terminate the process.\n\tlog.Panic(\"Managed shutdown failed. Panicking.\")\n}\n\nfunc (fc *DataplaneConnector) Start() {\n\t// Start a background thread to write to the dataplane driver.\n\tgo fc.sendMessagesToDataplaneDriver()\n\n\t// Start background thread to read messages from dataplane driver.\n\tgo fc.readMessagesFromDataplane()\n}\n\nvar ErrServiceNotReady = errors.New(\"Kubernetes service missing IP or port.\")\n\nfunc discoverTyphaAddr(configParams *config.Config) (string, error) {\n\tif configParams.TyphaAddr != \"\" {\n\t\t// Explicit address; trumps other sources of config.\n\t\treturn configParams.TyphaAddr, nil\n\t}\n\n\tif configParams.TyphaK8sServiceName == \"\" {\n\t\t// No explicit address, and no service name, not using Typha.\n\t\treturn \"\", nil\n\t}\n\n\t// If we get here, we need to look up the Typha service using the k8s API.\n\t// TODO Typha: support Typha lookup without using rest.InClusterConfig().\n\tk8sconf, err := rest.InClusterConfig()\n\tif err != nil {\n\t\tlog.WithError(err).Error(\"Unable to create Kubernetes config.\")\n\t\treturn \"\", err\n\t}\n\tclientset, err := kubernetes.NewForConfig(k8sconf)\n\tif err != nil {\n\t\tlog.WithError(err).Error(\"Unable to create Kubernetes client set.\")\n\t\treturn \"\", err\n\t}\n\tsvcClient := clientset.CoreV1().Services(configParams.TyphaK8sNamespace)\n\tsvc, err := svcClient.Get(configParams.TyphaK8sServiceName, v1.GetOptions{})\n\tif err != nil {\n\t\tlog.WithError(err).Error(\"Unable to get Typha service from Kubernetes.\")\n\t\treturn \"\", err\n\t}\n\thost := svc.Spec.ClusterIP\n\tlog.WithField(\"clusterIP\", host).Info(\"Found Typha ClusterIP.\")\n\tif host == \"\" {\n\t\tlog.WithError(err).Error(\"Typha service had no ClusterIP.\")\n\t\treturn \"\", ErrServiceNotReady\n\t}\n\tfor _, p := range svc.Spec.Ports {\n\t\tif p.Name == \"calico-typha\" {\n\t\t\tlog.WithField(\"port\", p).Info(\"Found Typha service port.\")\n\t\t\ttyphaAddr := fmt.Sprintf(\"%s:%v\", host, p.Port)\n\t\t\treturn typhaAddr, nil\n\t\t}\n\t}\n\tlog.Error(\"Didn't find Typha service port.\")\n\treturn \"\", ErrServiceNotReady\n}\n", "idx": 1, "id": 16830, "msg": "Please log once here at Error level \"Failed to connect to Typha, will retry...\"", "proj": "projectcalico-felix", "lang": "c"}
{"patch": "@@ -23,8 +23,8 @@ import (\n )\n \n const (\n-\tTPRGroup   = \"monitoring.coreos.com\"\n-\tTPRVersion = \"v1alpha1\"\n+\tGroup   = \"monitoring.coreos.com\"\n+\tVersion = \"v1alpha1\"\n )\n \n type MonitoringV1alpha1Interface interface {", "y": 1, "oldf": "// Copyright 2016 The prometheus-operator Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage v1alpha1\n\nimport (\n\t\"k8s.io/apimachinery/pkg/runtime/schema\"\n\t\"k8s.io/apimachinery/pkg/runtime/serializer\"\n\t\"k8s.io/client-go/dynamic\"\n\t\"k8s.io/client-go/pkg/api\"\n\t\"k8s.io/client-go/rest\"\n)\n\nconst (\n\tTPRGroup   = \"monitoring.coreos.com\"\n\tTPRVersion = \"v1alpha1\"\n)\n\ntype MonitoringV1alpha1Interface interface {\n\tRESTClient() rest.Interface\n\tPrometheusesGetter\n\tAlertmanagersGetter\n\tServiceMonitorsGetter\n}\n\ntype MonitoringV1alpha1Client struct {\n\trestClient    rest.Interface\n\tdynamicClient *dynamic.Client\n}\n\nfunc (c *MonitoringV1alpha1Client) Prometheuses(namespace string) PrometheusInterface {\n\treturn newPrometheuses(c.restClient, c.dynamicClient, namespace)\n}\n\nfunc (c *MonitoringV1alpha1Client) Alertmanagers(namespace string) AlertmanagerInterface {\n\treturn newAlertmanagers(c.restClient, c.dynamicClient, namespace)\n}\n\nfunc (c *MonitoringV1alpha1Client) ServiceMonitors(namespace string) ServiceMonitorInterface {\n\treturn newServiceMonitors(c.restClient, c.dynamicClient, namespace)\n}\n\nfunc (c *MonitoringV1alpha1Client) RESTClient() rest.Interface {\n\treturn c.restClient\n}\n\nfunc NewForConfig(c *rest.Config) (*MonitoringV1alpha1Client, error) {\n\tconfig := *c\n\tsetConfigDefaults(&config)\n\tclient, err := rest.RESTClientFor(&config)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tdynamicClient, err := dynamic.NewClient(&config)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &MonitoringV1alpha1Client{client, dynamicClient}, nil\n}\n\nfunc setConfigDefaults(config *rest.Config) {\n\tconfig.GroupVersion = &schema.GroupVersion{\n\t\tGroup:   TPRGroup,\n\t\tVersion: TPRVersion,\n\t}\n\tconfig.APIPath = \"/apis\"\n\tconfig.NegotiatedSerializer = serializer.DirectCodecFactory{CodecFactory: api.Codecs}\n\treturn\n}\n", "idx": 1, "id": 8541, "msg": "We should bump this before releasing and remove all legacy fields that are safe to do so. Since we cannot have multiple versions anyway there's little value in walking around with the \"alpha\" stamp.", "proj": "prometheus-operator-prometheus-operator", "lang": "go"}
{"patch": "@@ -30,7 +30,10 @@ var tableGrid = tableUtils.toGrid(node);\n \n // Look for all the bad headers\n var out = headers.reduce(function (res, header) {\n-\tif (header.id && reffedHeaders.indexOf(header.id) !== -1) {\n+\tif (\n+\t\theader.getAttribute('id') &&\n+\t\treffedHeaders.includes(header.getAttribute('id'))\n+\t) {\n \t\treturn (!res ? res : true);\n \t}\n ", "y": 1, "oldf": "var tableUtils = axe.commons.table;\nvar cells = tableUtils.getAllCells(node);\nvar checkResult = this;\n\n// Get a list of all headers reffed to in this rule\nvar reffedHeaders = [];\ncells.forEach(function (cell) {\n\tvar headers = cell.getAttribute('headers');\n\tif (headers) {\n\t\treffedHeaders = reffedHeaders.concat(headers.split(/\\s+/));\n\t}\n\n\tvar ariaLabel = cell.getAttribute('aria-labelledby');\n\tif (ariaLabel) {\n\t\treffedHeaders = reffedHeaders.concat(ariaLabel.split(/\\s+/));\n\t}\n});\n\n// Get all the headers\nvar headers = cells.filter(function (cell) {\n\tif (axe.commons.text.sanitize(cell.textContent) === '') {\n\t\treturn false;\n\t}\n\treturn (cell.nodeName.toUpperCase() === 'TH' ||\n\t\t['rowheader', 'columnheader'].indexOf(cell.getAttribute('role')) !== -1);\n});\n\n\nvar tableGrid = tableUtils.toGrid(node);\n\n// Look for all the bad headers\nvar out = headers.reduce(function (res, header) {\n\tif (header.id && reffedHeaders.indexOf(header.id) !== -1) {\n\t\treturn (!res ? res : true);\n\t}\n\n\tvar hasCell = false;\n\tvar pos = tableUtils.getCellPosition(header, tableGrid);\n\n\t// Look for any data cells or row headers that this might refer to\n\tif (tableUtils.isColumnHeader(header)) {\n\t\thasCell = tableUtils.traverse('down', pos, tableGrid)\n\t\t.reduce((out, cell) => {\n\t\t\treturn (out || (\n\t\t\t\taxe.commons.dom.hasContent(cell) &&\n\t\t\t\t!tableUtils.isColumnHeader(cell))\n\t\t\t);\n\t\t}, false);\n\t}\n\n\t// Look for any data cells or column headers that this might refer to\n\tif (!hasCell && tableUtils.isRowHeader(header)) {\n\t\thasCell = tableUtils.traverse('right', pos, tableGrid)\n\t\t.reduce((out, cell) => {\n\t\t\treturn out || (\n\t\t\t\taxe.commons.dom.hasContent(cell) &&\n\t\t\t\t!tableUtils.isRowHeader(cell)\n\t\t\t);\n\t\t}, false);\n\t}\n\n\t// report the node as having failed\n\tif (!hasCell) {\n\t\tcheckResult.relatedNodes(header);\n\t}\n\n\treturn res && hasCell;\n}, true);\n\nreturn out ? true : undefined;\n", "idx": 1, "id": 11198, "msg": "Does this code fit on one line under 80 characters? It would be more consistent with our existing style.", "proj": "dequelabs-axe-core", "lang": "js"}
{"patch": "@@ -24,5 +24,16 @@ var (\n \t\t  \"openebs.io/version\": \"{{.}}\"\n \t   }\n \t}\n+ }`\n+\t// VersionDetailsPatch is generic template for version details patch\n+\tVersionDetailsPatch = `{\n+\t\"metadata\": {\n+\t   \"labels\": {\n+\t\t  \"openebs.io/version\": \"{{.}}\"\n+\t   }\n+\t},\n+\t\"versionDetails\": {\n+\t\t\"desired\": \"{{.}}\"\n+\t}\n  }`\n )", "y": 1, "oldf": "/*\nCopyright 2019 The OpenEBS Authors\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage templates\n\nvar (\n\t// OpenebsVersionPatch is generic template for openebs version patch\n\tOpenebsVersionPatch = `{\n\t\"metadata\": {\n\t   \"labels\": {\n\t\t  \"openebs.io/version\": \"{{.}}\"\n\t   }\n\t}\n }`\n)\n", "idx": 1, "id": 17402, "msg": "is this supposed to be `Desired`?", "proj": "openebs-maya", "lang": "go"}
{"patch": "@@ -651,10 +651,17 @@ type localOpenFile struct {\n \to    *Object           // object that is open\n \tin   io.ReadCloser     // handle we are wrapping\n \thash *hash.MultiHasher // currently accumulating hashes\n+\tfd   *os.File          // file object reference\n }\n \n // Read bytes from the object - see io.Reader\n func (file *localOpenFile) Read(p []byte) (n int, err error) {\n+\t// Check if file has the same size and modTime\n+\tfi, err := file.fd.Stat()\n+\tif file.o.size != fi.Size() || file.o.modTime != fi.ModTime() {\n+\t\treturn 0, errors.New(\"can't copy - source file is being updated\")\n+\t}\n+\n \tn, err = file.in.Read(p)\n \tif n > 0 {\n \t\t// Hash routines never return an error", "y": 1, "oldf": "// Package local provides a filesystem interface\npackage local\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"os\"\n\t\"path\"\n\t\"path/filepath\"\n\t\"regexp\"\n\t\"runtime\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\t\"unicode/utf8\"\n\n\t\"github.com/ncw/rclone/fs\"\n\t\"github.com/ncw/rclone/fs/config\"\n\t\"github.com/ncw/rclone/fs/config/flags\"\n\t\"github.com/ncw/rclone/fs/hash\"\n\t\"github.com/ncw/rclone/lib/readers\"\n\t\"github.com/pkg/errors\"\n\t\"google.golang.org/appengine/log\"\n)\n\nvar (\n\tfollowSymlinks = flags.BoolP(\"copy-links\", \"L\", false, \"Follow symlinks and copy the pointed to item.\")\n\tskipSymlinks   = flags.BoolP(\"skip-links\", \"\", false, \"Don't warn about skipped symlinks.\")\n\tnoUTFNorm      = flags.BoolP(\"local-no-unicode-normalization\", \"\", false, \"Don't apply unicode normalization to paths and filenames\")\n)\n\n// Constants\nconst devUnset = 0xdeadbeefcafebabe // a device id meaning it is unset\n\n// Register with Fs\nfunc init() {\n\tfsi := &fs.RegInfo{\n\t\tName:        \"local\",\n\t\tDescription: \"Local Disk\",\n\t\tNewFs:       NewFs,\n\t\tOptions: []fs.Option{{\n\t\t\tName:     \"nounc\",\n\t\t\tHelp:     \"Disable UNC (long path names) conversion on Windows\",\n\t\t\tOptional: true,\n\t\t\tExamples: []fs.OptionExample{{\n\t\t\t\tValue: \"true\",\n\t\t\t\tHelp:  \"Disables long file names\",\n\t\t\t}},\n\t\t}},\n\t}\n\tfs.Register(fsi)\n}\n\n// Fs represents a local filesystem rooted at root\ntype Fs struct {\n\tname        string              // the name of the remote\n\troot        string              // The root directory (OS path)\n\tfeatures    *fs.Features        // optional features\n\tdev         uint64              // device number of root node\n\tprecisionOk sync.Once           // Whether we need to read the precision\n\tprecision   time.Duration       // precision of local filesystem\n\twmu         sync.Mutex          // used for locking access to 'warned'.\n\twarned      map[string]struct{} // whether we have warned about this string\n\tnounc       bool                // Skip UNC conversion on Windows\n\t// do os.Lstat or os.Stat\n\tlstat    func(name string) (os.FileInfo, error)\n\tdirNames *mapper // directory name mapping\n}\n\n// Object represents a local filesystem object\ntype Object struct {\n\tfs      *Fs    // The Fs this object is part of\n\tremote  string // The remote path - properly UTF-8 encoded - for rclone\n\tpath    string // The local path - may not be properly UTF-8 encoded - for OS\n\tsize    int64  // file metadata - always present\n\tmode    os.FileMode\n\tmodTime time.Time\n\thashes  map[hash.Type]string // Hashes\n}\n\n// ------------------------------------------------------------\n\n// NewFs constructs an Fs from the path\nfunc NewFs(name, root string) (fs.Fs, error) {\n\tvar err error\n\n\tif *noUTFNorm {\n\t\tlog.Errorf(nil, \"The --local-no-unicode-normalization flag is deprecated and will be removed\")\n\t}\n\n\tnounc := config.FileGet(name, \"nounc\")\n\tf := &Fs{\n\t\tname:     name,\n\t\twarned:   make(map[string]struct{}),\n\t\tnounc:    nounc == \"true\",\n\t\tdev:      devUnset,\n\t\tlstat:    os.Lstat,\n\t\tdirNames: newMapper(),\n\t}\n\tf.root = f.cleanPath(root)\n\tf.features = (&fs.Features{\n\t\tCaseInsensitive:         f.caseInsensitive(),\n\t\tCanHaveEmptyDirectories: true,\n\t}).Fill(f)\n\tif *followSymlinks {\n\t\tf.lstat = os.Stat\n\t}\n\n\t// Check to see if this points to a file\n\tfi, err := f.lstat(f.root)\n\tif err == nil {\n\t\tf.dev = readDevice(fi)\n\t}\n\tif err == nil && fi.Mode().IsRegular() {\n\t\t// It is a file, so use the parent as the root\n\t\tf.root, _ = getDirFile(f.root)\n\t\t// return an error with an fs which points to the parent\n\t\treturn f, fs.ErrorIsFile\n\t}\n\treturn f, nil\n}\n\n// Name of the remote (as passed into NewFs)\nfunc (f *Fs) Name() string {\n\treturn f.name\n}\n\n// Root of the remote (as passed into NewFs)\nfunc (f *Fs) Root() string {\n\treturn f.root\n}\n\n// String converts this Fs to a string\nfunc (f *Fs) String() string {\n\treturn fmt.Sprintf(\"Local file system at %s\", f.root)\n}\n\n// Features returns the optional features of this Fs\nfunc (f *Fs) Features() *fs.Features {\n\treturn f.features\n}\n\n// caseInsenstive returns whether the remote is case insensitive or not\nfunc (f *Fs) caseInsensitive() bool {\n\t// FIXME not entirely accurate since you can have case\n\t// sensitive Fses on darwin and case insenstive Fses on linux.\n\t// Should probably check but that would involve creating a\n\t// file in the remote to be most accurate which probably isn't\n\t// desirable.\n\treturn runtime.GOOS == \"windows\" || runtime.GOOS == \"darwin\"\n}\n\n// newObject makes a half completed Object\n//\n// if dstPath is empty then it is made from remote\nfunc (f *Fs) newObject(remote, dstPath string) *Object {\n\tif dstPath == \"\" {\n\t\tdstPath = f.cleanPath(filepath.Join(f.root, remote))\n\t}\n\tremote = f.cleanRemote(remote)\n\treturn &Object{\n\t\tfs:     f,\n\t\tremote: remote,\n\t\tpath:   dstPath,\n\t}\n}\n\n// Return an Object from a path\n//\n// May return nil if an error occurred\nfunc (f *Fs) newObjectWithInfo(remote, dstPath string, info os.FileInfo) (fs.Object, error) {\n\to := f.newObject(remote, dstPath)\n\tif info != nil {\n\t\to.setMetadata(info)\n\t} else {\n\t\terr := o.lstat()\n\t\tif err != nil {\n\t\t\tif os.IsNotExist(err) {\n\t\t\t\treturn nil, fs.ErrorObjectNotFound\n\t\t\t}\n\t\t\tif os.IsPermission(err) {\n\t\t\t\treturn nil, fs.ErrorPermissionDenied\n\t\t\t}\n\t\t\treturn nil, err\n\t\t}\n\t}\n\tif o.mode.IsDir() {\n\t\treturn nil, errors.Wrapf(fs.ErrorNotAFile, \"%q\", remote)\n\t}\n\treturn o, nil\n}\n\n// NewObject finds the Object at remote.  If it can't be found\n// it returns the error ErrorObjectNotFound.\nfunc (f *Fs) NewObject(remote string) (fs.Object, error) {\n\treturn f.newObjectWithInfo(remote, \"\", nil)\n}\n\n// List the objects and directories in dir into entries.  The\n// entries can be returned in any order but should be for a\n// complete directory.\n//\n// dir should be \"\" to list the root, and should not have\n// trailing slashes.\n//\n// This should return ErrDirNotFound if the directory isn't\n// found.\nfunc (f *Fs) List(dir string) (entries fs.DirEntries, err error) {\n\tdir = f.dirNames.Load(dir)\n\tfsDirPath := f.cleanPath(filepath.Join(f.root, dir))\n\tremote := f.cleanRemote(dir)\n\t_, err = os.Stat(fsDirPath)\n\tif err != nil {\n\t\treturn nil, fs.ErrorDirNotFound\n\t}\n\n\tfd, err := os.Open(fsDirPath)\n\tif err != nil {\n\t\treturn nil, errors.Wrapf(err, \"failed to open directory %q\", dir)\n\t}\n\tdefer func() {\n\t\tcerr := fd.Close()\n\t\tif cerr != nil && err == nil {\n\t\t\terr = errors.Wrapf(cerr, \"failed to close directory %q:\", dir)\n\t\t}\n\t}()\n\n\tfor {\n\t\tfis, err := fd.Readdir(1024)\n\t\tif err == io.EOF && len(fis) == 0 {\n\t\t\tbreak\n\t\t}\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrapf(err, \"failed to read directory %q\", dir)\n\t\t}\n\n\t\tfor _, fi := range fis {\n\t\t\tname := fi.Name()\n\t\t\tmode := fi.Mode()\n\t\t\tnewRemote := path.Join(remote, name)\n\t\t\tnewPath := filepath.Join(fsDirPath, name)\n\t\t\t// Follow symlinks if required\n\t\t\tif *followSymlinks && (mode&os.ModeSymlink) != 0 {\n\t\t\t\tfi, err = os.Stat(newPath)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\tmode = fi.Mode()\n\t\t\t}\n\t\t\tif fi.IsDir() {\n\t\t\t\t// Ignore directories which are symlinks.  These are junction points under windows which\n\t\t\t\t// are kind of a souped up symlink. Unix doesn't have directories which are symlinks.\n\t\t\t\tif (mode&os.ModeSymlink) == 0 && f.dev == readDevice(fi) {\n\t\t\t\t\td := fs.NewDir(f.dirNames.Save(newRemote, f.cleanRemote(newRemote)), fi.ModTime())\n\t\t\t\t\tentries = append(entries, d)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tfso, err := f.newObjectWithInfo(newRemote, newPath, fi)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\tif fso.Storable() {\n\t\t\t\t\tentries = append(entries, fso)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn entries, nil\n}\n\n// cleanRemote makes string a valid UTF-8 string for remote strings.\n//\n// Any invalid UTF-8 characters will be replaced with utf8.RuneError\n// It also normalises the UTF-8 and converts the slashes if necessary.\nfunc (f *Fs) cleanRemote(name string) string {\n\tif !utf8.ValidString(name) {\n\t\tf.wmu.Lock()\n\t\tif _, ok := f.warned[name]; !ok {\n\t\t\tfs.Logf(f, \"Replacing invalid UTF-8 characters in %q\", name)\n\t\t\tf.warned[name] = struct{}{}\n\t\t}\n\t\tf.wmu.Unlock()\n\t\tname = string([]rune(name))\n\t}\n\tname = filepath.ToSlash(name)\n\treturn name\n}\n\n// mapper maps raw to cleaned directory names\ntype mapper struct {\n\tmu sync.RWMutex      // mutex to protect the below\n\tm  map[string]string // map of un-normalised directory names\n}\n\nfunc newMapper() *mapper {\n\treturn &mapper{\n\t\tm: make(map[string]string),\n\t}\n}\n\n// Lookup a directory name to make a local name (reverses\n// cleanDirName)\n//\n// FIXME this is temporary before we make a proper Directory object\nfunc (m *mapper) Load(in string) string {\n\tm.mu.RLock()\n\tout, ok := m.m[in]\n\tm.mu.RUnlock()\n\tif ok {\n\t\treturn out\n\t}\n\treturn in\n}\n\n// Cleans a directory name recording if it needed to be altered\n//\n// FIXME this is temporary before we make a proper Directory object\nfunc (m *mapper) Save(in, out string) string {\n\tif in != out {\n\t\tm.mu.Lock()\n\t\tm.m[out] = in\n\t\tm.mu.Unlock()\n\t}\n\treturn out\n}\n\n// Put the Object to the local filesystem\nfunc (f *Fs) Put(in io.Reader, src fs.ObjectInfo, options ...fs.OpenOption) (fs.Object, error) {\n\tremote := src.Remote()\n\t// Temporary Object under construction - info filled in by Update()\n\to := f.newObject(remote, \"\")\n\terr := o.Update(in, src, options...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn o, nil\n}\n\n// PutStream uploads to the remote path with the modTime given of indeterminate size\nfunc (f *Fs) PutStream(in io.Reader, src fs.ObjectInfo, options ...fs.OpenOption) (fs.Object, error) {\n\treturn f.Put(in, src, options...)\n}\n\n// Mkdir creates the directory if it doesn't exist\nfunc (f *Fs) Mkdir(dir string) error {\n\t// FIXME: https://github.com/syncthing/syncthing/blob/master/lib/osutil/mkdirall_windows.go\n\troot := f.cleanPath(filepath.Join(f.root, dir))\n\terr := os.MkdirAll(root, 0777)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif dir == \"\" {\n\t\tfi, err := f.lstat(root)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tf.dev = readDevice(fi)\n\t}\n\treturn nil\n}\n\n// Rmdir removes the directory\n//\n// If it isn't empty it will return an error\nfunc (f *Fs) Rmdir(dir string) error {\n\troot := f.cleanPath(filepath.Join(f.root, dir))\n\treturn os.Remove(root)\n}\n\n// Precision of the file system\nfunc (f *Fs) Precision() (precision time.Duration) {\n\tf.precisionOk.Do(func() {\n\t\tf.precision = f.readPrecision()\n\t})\n\treturn f.precision\n}\n\n// Read the precision\nfunc (f *Fs) readPrecision() (precision time.Duration) {\n\t// Default precision of 1s\n\tprecision = time.Second\n\n\t// Create temporary file and test it\n\tfd, err := ioutil.TempFile(\"\", \"rclone\")\n\tif err != nil {\n\t\t// If failed return 1s\n\t\t// fmt.Println(\"Failed to create temp file\", err)\n\t\treturn time.Second\n\t}\n\tpath := fd.Name()\n\t// fmt.Println(\"Created temp file\", path)\n\terr = fd.Close()\n\tif err != nil {\n\t\treturn time.Second\n\t}\n\n\t// Delete it on return\n\tdefer func() {\n\t\t// fmt.Println(\"Remove temp file\")\n\t\t_ = os.Remove(path) // ignore error\n\t}()\n\n\t// Find the minimum duration we can detect\n\tfor duration := time.Duration(1); duration < time.Second; duration *= 10 {\n\t\t// Current time with delta\n\t\tt := time.Unix(time.Now().Unix(), int64(duration))\n\t\terr := os.Chtimes(path, t, t)\n\t\tif err != nil {\n\t\t\t// fmt.Println(\"Failed to Chtimes\", err)\n\t\t\tbreak\n\t\t}\n\n\t\t// Read the actual time back\n\t\tfi, err := os.Stat(path)\n\t\tif err != nil {\n\t\t\t// fmt.Println(\"Failed to Stat\", err)\n\t\t\tbreak\n\t\t}\n\n\t\t// If it matches - have found the precision\n\t\t// fmt.Println(\"compare\", fi.ModTime(), t)\n\t\tif fi.ModTime() == t {\n\t\t\t// fmt.Println(\"Precision detected as\", duration)\n\t\t\treturn duration\n\t\t}\n\t}\n\treturn\n}\n\n// Purge deletes all the files and directories\n//\n// Optional interface: Only implement this if you have a way of\n// deleting all the files quicker than just running Remove() on the\n// result of List()\nfunc (f *Fs) Purge() error {\n\tfi, err := f.lstat(f.root)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif !fi.Mode().IsDir() {\n\t\treturn errors.Errorf(\"can't purge non directory: %q\", f.root)\n\t}\n\treturn os.RemoveAll(f.root)\n}\n\n// Move src to this remote using server side move operations.\n//\n// This is stored with the remote path given\n//\n// It returns the destination Object and a possible error\n//\n// Will only be called if src.Fs().Name() == f.Name()\n//\n// If it isn't possible then return fs.ErrorCantMove\nfunc (f *Fs) Move(src fs.Object, remote string) (fs.Object, error) {\n\tsrcObj, ok := src.(*Object)\n\tif !ok {\n\t\tfs.Debugf(src, \"Can't move - not same remote type\")\n\t\treturn nil, fs.ErrorCantMove\n\t}\n\n\t// Temporary Object under construction\n\tdstObj := f.newObject(remote, \"\")\n\n\t// Check it is a file if it exists\n\terr := dstObj.lstat()\n\tif os.IsNotExist(err) {\n\t\t// OK\n\t} else if err != nil {\n\t\treturn nil, err\n\t} else if !dstObj.mode.IsRegular() {\n\t\t// It isn't a file\n\t\treturn nil, errors.New(\"can't move file onto non-file\")\n\t}\n\n\t// Create destination\n\terr = dstObj.mkdirAll()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Do the move\n\terr = os.Rename(srcObj.path, dstObj.path)\n\tif os.IsNotExist(err) {\n\t\t// race condition, source was deleted in the meantime\n\t\treturn nil, err\n\t} else if os.IsPermission(err) {\n\t\t// not enough rights to write to dst\n\t\treturn nil, err\n\t} else if err != nil {\n\t\t// not quite clear, but probably trying to move a file across file system\n\t\t// boundaries. Copying might still work.\n\t\tfs.Errorf(src, \"Can't move: %v: trying copy\", err)\n\t\treturn nil, fs.ErrorCantMove\n\t}\n\n\t// Update the info\n\terr = dstObj.lstat()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn dstObj, nil\n}\n\n// DirMove moves src, srcRemote to this remote at dstRemote\n// using server side move operations.\n//\n// Will only be called if src.Fs().Name() == f.Name()\n//\n// If it isn't possible then return fs.ErrorCantDirMove\n//\n// If destination exists then return fs.ErrorDirExists\nfunc (f *Fs) DirMove(src fs.Fs, srcRemote, dstRemote string) error {\n\tsrcFs, ok := src.(*Fs)\n\tif !ok {\n\t\tfs.Debugf(srcFs, \"Can't move directory - not same remote type\")\n\t\treturn fs.ErrorCantDirMove\n\t}\n\tsrcPath := f.cleanPath(filepath.Join(srcFs.root, srcRemote))\n\tdstPath := f.cleanPath(filepath.Join(f.root, dstRemote))\n\n\t// Check if destination exists\n\t_, err := os.Lstat(dstPath)\n\tif !os.IsNotExist(err) {\n\t\treturn fs.ErrorDirExists\n\t}\n\n\t// Create parent of destination\n\tdstParentPath, _ := getDirFile(dstPath)\n\terr = os.MkdirAll(dstParentPath, 0777)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Do the move\n\treturn os.Rename(srcPath, dstPath)\n}\n\n// Hashes returns the supported hash sets.\nfunc (f *Fs) Hashes() hash.Set {\n\treturn hash.Supported\n}\n\n// ------------------------------------------------------------\n\n// Fs returns the parent Fs\nfunc (o *Object) Fs() fs.Info {\n\treturn o.fs\n}\n\n// Return a string version\nfunc (o *Object) String() string {\n\tif o == nil {\n\t\treturn \"<nil>\"\n\t}\n\treturn o.remote\n}\n\n// Remote returns the remote path\nfunc (o *Object) Remote() string {\n\treturn o.remote\n}\n\n// Hash returns the requested hash of a file as a lowercase hex string\nfunc (o *Object) Hash(r hash.Type) (string, error) {\n\t// Check that the underlying file hasn't changed\n\toldtime := o.modTime\n\toldsize := o.size\n\terr := o.lstat()\n\tif err != nil {\n\t\treturn \"\", errors.Wrap(err, \"hash: failed to stat\")\n\t}\n\n\tif !o.modTime.Equal(oldtime) || oldsize != o.size {\n\t\to.hashes = nil\n\t}\n\n\tif o.hashes == nil {\n\t\to.hashes = make(map[hash.Type]string)\n\t\tin, err := os.Open(o.path)\n\t\tif err != nil {\n\t\t\treturn \"\", errors.Wrap(err, \"hash: failed to open\")\n\t\t}\n\t\to.hashes, err = hash.Stream(in)\n\t\tcloseErr := in.Close()\n\t\tif err != nil {\n\t\t\treturn \"\", errors.Wrap(err, \"hash: failed to read\")\n\t\t}\n\t\tif closeErr != nil {\n\t\t\treturn \"\", errors.Wrap(closeErr, \"hash: failed to close\")\n\t\t}\n\t}\n\treturn o.hashes[r], nil\n}\n\n// Size returns the size of an object in bytes\nfunc (o *Object) Size() int64 {\n\treturn o.size\n}\n\n// ModTime returns the modification time of the object\nfunc (o *Object) ModTime() time.Time {\n\treturn o.modTime\n}\n\n// SetModTime sets the modification time of the local fs object\nfunc (o *Object) SetModTime(modTime time.Time) error {\n\terr := os.Chtimes(o.path, modTime, modTime)\n\tif err != nil {\n\t\treturn err\n\t}\n\t// Re-read metadata\n\treturn o.lstat()\n}\n\n// Storable returns a boolean showing if this object is storable\nfunc (o *Object) Storable() bool {\n\t// Check for control characters in the remote name and show non storable\n\tfor _, c := range o.Remote() {\n\t\tif c >= 0x00 && c < 0x20 || c == 0x7F {\n\t\t\tfs.Logf(o.fs, \"Can't store file with control characters: %q\", o.Remote())\n\t\t\treturn false\n\t\t}\n\t}\n\tmode := o.mode\n\t// On windows a file with os.ModeSymlink represents a file with reparse points\n\tif runtime.GOOS == \"windows\" && (mode&os.ModeSymlink) != 0 {\n\t\tfs.Debugf(o, \"Clearing symlink bit to allow a file with reparse points to be copied\")\n\t\tmode &^= os.ModeSymlink\n\t}\n\tif mode&os.ModeSymlink != 0 {\n\t\tif !*skipSymlinks {\n\t\t\tfs.Logf(o, \"Can't follow symlink without -L/--copy-links\")\n\t\t}\n\t\treturn false\n\t} else if mode&(os.ModeNamedPipe|os.ModeSocket|os.ModeDevice) != 0 {\n\t\tfs.Logf(o, \"Can't transfer non file/directory\")\n\t\treturn false\n\t} else if mode&os.ModeDir != 0 {\n\t\t// fs.Debugf(o, \"Skipping directory\")\n\t\treturn false\n\t}\n\treturn true\n}\n\n// localOpenFile wraps an io.ReadCloser and updates the md5sum of the\n// object that is read\ntype localOpenFile struct {\n\to    *Object           // object that is open\n\tin   io.ReadCloser     // handle we are wrapping\n\thash *hash.MultiHasher // currently accumulating hashes\n}\n\n// Read bytes from the object - see io.Reader\nfunc (file *localOpenFile) Read(p []byte) (n int, err error) {\n\tn, err = file.in.Read(p)\n\tif n > 0 {\n\t\t// Hash routines never return an error\n\t\t_, _ = file.hash.Write(p[:n])\n\t}\n\treturn\n}\n\n// Close the object and update the hashes\nfunc (file *localOpenFile) Close() (err error) {\n\terr = file.in.Close()\n\tif err == nil {\n\t\tif file.hash.Size() == file.o.Size() {\n\t\t\tfile.o.hashes = file.hash.Sums()\n\t\t}\n\t}\n\treturn err\n}\n\n// Open an object for read\nfunc (o *Object) Open(options ...fs.OpenOption) (in io.ReadCloser, err error) {\n\tvar offset, limit int64 = 0, -1\n\thashes := hash.Supported\n\tfor _, option := range options {\n\t\tswitch x := option.(type) {\n\t\tcase *fs.SeekOption:\n\t\t\toffset = x.Offset\n\t\tcase *fs.RangeOption:\n\t\t\toffset, limit = x.Decode(o.size)\n\t\tcase *fs.HashesOption:\n\t\t\thashes = x.Hashes\n\t\tdefault:\n\t\t\tif option.Mandatory() {\n\t\t\t\tfs.Logf(o, \"Unsupported mandatory option: %v\", option)\n\t\t\t}\n\t\t}\n\t}\n\n\tfd, err := os.Open(o.path)\n\tif err != nil {\n\t\treturn\n\t}\n\twrappedFd := readers.NewLimitedReadCloser(fd, limit)\n\tif offset != 0 {\n\t\t// seek the object\n\t\t_, err = fd.Seek(offset, 0)\n\t\t// don't attempt to make checksums\n\t\treturn wrappedFd, err\n\t}\n\thash, err := hash.NewMultiHasherTypes(hashes)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\t// Update the md5sum as we go along\n\tin = &localOpenFile{\n\t\to:    o,\n\t\tin:   wrappedFd,\n\t\thash: hash,\n\t}\n\treturn in, nil\n}\n\n// mkdirAll makes all the directories needed to store the object\nfunc (o *Object) mkdirAll() error {\n\tdir, _ := getDirFile(o.path)\n\treturn os.MkdirAll(dir, 0777)\n}\n\n// Update the object from in with modTime and size\nfunc (o *Object) Update(in io.Reader, src fs.ObjectInfo, options ...fs.OpenOption) error {\n\thashes := hash.Supported\n\tfor _, option := range options {\n\t\tswitch x := option.(type) {\n\t\tcase *fs.HashesOption:\n\t\t\thashes = x.Hashes\n\t\t}\n\t}\n\n\terr := o.mkdirAll()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tout, err := os.OpenFile(o.path, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0666)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Calculate the hash of the object we are reading as we go along\n\thash, err := hash.NewMultiHasherTypes(hashes)\n\tif err != nil {\n\t\treturn err\n\t}\n\tin = io.TeeReader(in, hash)\n\n\t_, err = io.Copy(out, in)\n\tcloseErr := out.Close()\n\tif err == nil {\n\t\terr = closeErr\n\t}\n\tif err != nil {\n\t\tfs.Logf(o, \"Removing partially written file on error: %v\", err)\n\t\tif removeErr := os.Remove(o.path); removeErr != nil {\n\t\t\tfs.Errorf(o, \"Failed to remove partially written file: %v\", removeErr)\n\t\t}\n\t\treturn err\n\t}\n\n\t// All successful so update the hashes\n\to.hashes = hash.Sums()\n\n\t// Set the mtime\n\terr = o.SetModTime(src.ModTime())\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// ReRead info now that we have finished\n\treturn o.lstat()\n}\n\n// setMetadata sets the file info from the os.FileInfo passed in\nfunc (o *Object) setMetadata(info os.FileInfo) {\n\t// Don't overwrite the info if we don't need to\n\t// this avoids upsetting the race detector\n\tif o.size != info.Size() {\n\t\to.size = info.Size()\n\t}\n\tif !o.modTime.Equal(info.ModTime()) {\n\t\to.modTime = info.ModTime()\n\t}\n\tif o.mode != info.Mode() {\n\t\to.mode = info.Mode()\n\t}\n}\n\n// Stat a Object into info\nfunc (o *Object) lstat() error {\n\tinfo, err := o.fs.lstat(o.path)\n\tif err == nil {\n\t\to.setMetadata(info)\n\t}\n\treturn err\n}\n\n// Remove an object\nfunc (o *Object) Remove() error {\n\treturn os.Remove(o.path)\n}\n\n// Return the directory and file from an OS path. Assumes\n// os.PathSeparator is used.\nfunc getDirFile(s string) (string, string) {\n\ti := strings.LastIndex(s, string(os.PathSeparator))\n\tdir, file := s[:i], s[i+1:]\n\tif dir == \"\" {\n\t\tdir = string(os.PathSeparator)\n\t}\n\treturn dir, file\n}\n\n// cleanPathFragment cleans an OS path fragment which is part of a\n// bigger path and not necessarily absolute\nfunc cleanPathFragment(s string) string {\n\tif s == \"\" {\n\t\treturn s\n\t}\n\ts = filepath.Clean(s)\n\tif runtime.GOOS == \"windows\" {\n\t\ts = strings.Replace(s, `/`, `\\`, -1)\n\t}\n\treturn s\n}\n\n// cleanPath cleans and makes absolute the path passed in and returns\n// an OS path.\n//\n// The input might be in OS form or rclone form or a mixture, but the\n// output is in OS form.\n//\n// On windows it makes the path UNC also and replaces any characters\n// Windows can't deal with with their replacements.\nfunc (f *Fs) cleanPath(s string) string {\n\ts = cleanPathFragment(s)\n\tif runtime.GOOS == \"windows\" {\n\t\tif !filepath.IsAbs(s) && !strings.HasPrefix(s, \"\\\\\") {\n\t\t\ts2, err := filepath.Abs(s)\n\t\t\tif err == nil {\n\t\t\t\ts = s2\n\t\t\t}\n\t\t}\n\t\tif !f.nounc {\n\t\t\t// Convert to UNC\n\t\t\ts = uncPath(s)\n\t\t}\n\t\ts = cleanWindowsName(f, s)\n\t} else {\n\t\tif !filepath.IsAbs(s) {\n\t\t\ts2, err := filepath.Abs(s)\n\t\t\tif err == nil {\n\t\t\t\ts = s2\n\t\t\t}\n\t\t}\n\t}\n\treturn s\n}\n\n// Pattern to match a windows absolute path: \"c:\\\" and similar\nvar isAbsWinDrive = regexp.MustCompile(`^[a-zA-Z]\\:\\\\`)\n\n// uncPath converts an absolute Windows path\n// to a UNC long path.\nfunc uncPath(s string) string {\n\t// UNC can NOT use \"/\", so convert all to \"\\\"\n\ts = strings.Replace(s, `/`, `\\`, -1)\n\n\t// If prefix is \"\\\\\", we already have a UNC path or server.\n\tif strings.HasPrefix(s, `\\\\`) {\n\t\t// If already long path, just keep it\n\t\tif strings.HasPrefix(s, `\\\\?\\`) {\n\t\t\treturn s\n\t\t}\n\n\t\t// Trim \"\\\\\" from path and add UNC prefix.\n\t\treturn `\\\\?\\UNC\\` + strings.TrimPrefix(s, `\\\\`)\n\t}\n\tif isAbsWinDrive.MatchString(s) {\n\t\treturn `\\\\?\\` + s\n\t}\n\treturn s\n}\n\n// cleanWindowsName will clean invalid Windows characters replacing them with _\nfunc cleanWindowsName(f *Fs, name string) string {\n\toriginal := name\n\tvar name2 string\n\tif strings.HasPrefix(name, `\\\\?\\`) {\n\t\tname2 = `\\\\?\\`\n\t\tname = strings.TrimPrefix(name, `\\\\?\\`)\n\t}\n\tif strings.HasPrefix(name, `//?/`) {\n\t\tname2 = `//?/`\n\t\tname = strings.TrimPrefix(name, `//?/`)\n\t}\n\t// Colon is allowed as part of a drive name X:\\\n\tcolonAt := strings.Index(name, \":\")\n\tif colonAt > 0 && colonAt < 3 && len(name) > colonAt+1 {\n\t\t// Copy to name2, which is unfiltered\n\t\tname2 += name[0 : colonAt+1]\n\t\tname = name[colonAt+1:]\n\t}\n\n\tname2 += strings.Map(func(r rune) rune {\n\t\tswitch r {\n\t\tcase '<', '>', '\"', '|', '?', '*', ':':\n\t\t\treturn '_'\n\t\t}\n\t\treturn r\n\t}, name)\n\n\tif name2 != original && f != nil {\n\t\tf.wmu.Lock()\n\t\tif _, ok := f.warned[name]; !ok {\n\t\t\tfs.Logf(f, \"Replacing invalid characters in %q to %q\", name, name2)\n\t\t\tf.warned[name] = struct{}{}\n\t\t}\n\t\tf.wmu.Unlock()\n\t}\n\treturn name2\n}\n\n// Check the interfaces are satisfied\nvar (\n\t_ fs.Fs          = &Fs{}\n\t_ fs.Purger      = &Fs{}\n\t_ fs.PutStreamer = &Fs{}\n\t_ fs.Mover       = &Fs{}\n\t_ fs.DirMover    = &Fs{}\n\t_ fs.Object      = &Object{}\n)\n", "idx": 1, "id": 6791, "msg": "`fi` is what the result of Stat is called elsewhere in this file not `finfo`", "proj": "rclone-rclone", "lang": "go"}
{"patch": "@@ -202,7 +202,9 @@ namespace Microsoft.DotNet.Build.Tasks.Packaging\n                                {\n                                    Id = d.ItemSpec,\n                                    Version = d.GetVersion(),\n-                                   TargetFramework = d.GetTargetFramework()\n+                                   TargetFramework = d.GetTargetFramework(),\n+                                   Include = d.GetValueList(\"Include\"),\n+                                   Exclude = d.GetValueList(\"Exclude\")\n                                };\n \n             return (from dependency in dependencies", "y": 1, "oldf": "// Licensed to the .NET Foundation under one or more agreements.\n// The .NET Foundation licenses this file to you under the MIT license.\n// See the LICENSE file in the project root for more information.\n\nusing Microsoft.Build.Framework;\nusing Microsoft.Build.Utilities;\nusing NuGet;\nusing NuGet.Frameworks;\nusing NuGet.Packaging.Core;\nusing NuGet.Versioning;\nusing System;\nusing System.Collections.Generic;\nusing System.IO;\nusing System.Linq;\nusing System.Runtime.Versioning;\nusing System.Text;\n\nnamespace Microsoft.DotNet.Build.Tasks.Packaging\n{\n    public class GenerateNuSpec : Task\n    {\n        private const string NuSpecXmlNamespace = @\"http://schemas.microsoft.com/packaging/2010/07/nuspec.xsd\";\n\n        public string InputFileName { get; set; }\n\n        [Required]\n        public string OutputFileName { get; set; }\n\n        public string MinClientVersion { get; set; }\n\n        [Required]\n        public string Id { get; set; }\n\n        [Required]\n        public string Version { get; set; }\n\n        [Required]\n        public string Title { get; set; }\n\n        [Required]\n        public string Authors { get; set; }\n\n        [Required]\n        public string Owners { get; set; }\n\n        [Required]\n        public string Description { get; set; }\n\n        public string ReleaseNotes { get; set; }\n\n        public string Summary { get; set; }\n\n        public string Language { get; set; }\n\n        public string ProjectUrl { get; set; }\n\n        public string IconUrl { get; set; }\n\n        public string LicenseUrl { get; set; }\n\n        public string Copyright { get; set; }\n\n        public bool RequireLicenseAcceptance { get; set; }\n\n        public bool DevelopmentDependency { get; set; }\n\n        public string Tags { get; set; }\n\n        public ITaskItem[] Dependencies { get; set; }\n\n        public ITaskItem[] References { get; set; }\n\n        public ITaskItem[] FrameworkReferences { get; set; }\n\n        public ITaskItem[] Files { get; set; }\n\n        public override bool Execute()\n        {\n            try\n            {\n                WriteNuSpecFile();\n            }\n            catch (Exception ex)\n            {\n                Log.LogError(ex.ToString());\n                Log.LogErrorFromException(ex);\n            }\n\n            return !Log.HasLoggedErrors;\n        }\n\n        private void WriteNuSpecFile()\n        {\n            var manifest = CreateManifest();\n\n            if (!IsDifferent(manifest))\n            {\n                Log.LogMessage(\"Skipping generation of .nuspec because contents are identical.\");\n                return;\n            }\n\n            var directory = Path.GetDirectoryName(OutputFileName);\n            if (!Directory.Exists(directory))\n            {\n                Directory.CreateDirectory(directory);\n            }\n\n            using (var file = File.Create(OutputFileName))\n            {\n                manifest.Save(file, false);\n            }\n        }\n\n        private bool IsDifferent(Manifest newManifest)\n        {\n            if (!File.Exists(OutputFileName))\n                return true;\n\n            var oldSource = File.ReadAllText(OutputFileName);\n            var newSource = \"\";\n            using (var stream = new MemoryStream())\n            {\n                newManifest.Save(stream);\n                stream.Seek(0, SeekOrigin.Begin);\n                newSource = Encoding.UTF8.GetString(stream.ToArray());\n            }\n\n            return oldSource != newSource;\n        }\n\n        private Manifest CreateManifest()\n        {\n            Manifest manifest;\n            ManifestMetadata manifestMetadata;\n            if (!string.IsNullOrEmpty(InputFileName))\n            {\n                using (var stream = File.OpenRead(InputFileName))\n                {\n                    manifest = Manifest.ReadFrom(stream);\n                }\n                if (manifest.Metadata == null)\n                {\n                    manifest = new Manifest(new ManifestMetadata(), manifest.Files);\n                }\n            }\n            else\n            {\n                manifest = new Manifest(new ManifestMetadata());\n            }\n\n\n            manifestMetadata = manifest.Metadata;\n\n            manifestMetadata.UpdateMember(x => x.Authors, Authors?.Split(';'));\n            manifestMetadata.UpdateMember(x => x.Copyright, Copyright);\n            manifestMetadata.UpdateMember(x => x.DependencySets, GetDependencySets());\n            manifestMetadata.UpdateMember(x => x.Description, Description);\n            manifestMetadata.DevelopmentDependency |= DevelopmentDependency;\n            manifestMetadata.UpdateMember(x => x.FrameworkAssemblies, GetFrameworkAssemblies());\n            manifestMetadata.UpdateMember(x => x.IconUrl, IconUrl != null ? new Uri(IconUrl) : null);\n            manifestMetadata.UpdateMember(x => x.Id, Id);\n            manifestMetadata.UpdateMember(x => x.Language, Language);\n            manifestMetadata.UpdateMember(x => x.LicenseUrl, new Uri(LicenseUrl));\n            manifestMetadata.UpdateMember(x => x.MinClientVersionString, MinClientVersion);\n            manifestMetadata.UpdateMember(x => x.Owners, Owners?.Split(';'));\n            manifestMetadata.UpdateMember(x => x.ProjectUrl, ProjectUrl != null ? new Uri(ProjectUrl) : null);\n            manifestMetadata.AddRangeToMember(x => x.PackageAssemblyReferences, GetReferenceSets());\n            manifestMetadata.UpdateMember(x => x.ReleaseNotes, ReleaseNotes);\n            manifestMetadata.RequireLicenseAcceptance |= RequireLicenseAcceptance;\n            manifestMetadata.UpdateMember(x => x.Summary, Summary);\n            manifestMetadata.UpdateMember(x => x.Tags, Tags);\n            manifestMetadata.UpdateMember(x => x.Title, Title);\n            manifestMetadata.UpdateMember(x => x.Version, Version != null ? new NuGetVersion(Version) : null);\n\n            manifest.AddRangeToMember(x => x.Files, GetManifestFiles());\n\n            return manifest;\n        }\n\n        private List<ManifestFile> GetManifestFiles()\n        {\n            return (from f in Files.NullAsEmpty()\n                    select new ManifestFile(\n                        f.GetMetadata(Metadata.FileSource),\n                        f.GetMetadata(Metadata.FileTarget),\n                        f.GetMetadata(Metadata.FileExclude)\n                        )).OrderBy(f => f.Target, StringComparer.OrdinalIgnoreCase).ToList();\n        }\n\n        private List<FrameworkAssemblyReference> GetFrameworkAssemblies()\n        {\n            return (from fr in FrameworkReferences.NullAsEmpty()\n                    orderby fr.ItemSpec, StringComparer.Ordinal\n                    select new FrameworkAssemblyReference(fr.ItemSpec, new[] { fr.GetTargetFramework() })\n                    ).ToList();\n        }\n\n        private List<PackageDependencySet> GetDependencySets()\n        {\n            var dependencies = from d in Dependencies.NullAsEmpty()\n                               select new Dependency\n                               {\n                                   Id = d.ItemSpec,\n                                   Version = d.GetVersion(),\n                                   TargetFramework = d.GetTargetFramework()\n                               };\n\n            return (from dependency in dependencies\n                    group dependency by dependency.TargetFramework into dependenciesByFramework\n                    select new PackageDependencySet(\n                        dependenciesByFramework.Key,\n                        from dependency in dependenciesByFramework\n                                        where dependency.Id != \"_._\"\n                                        orderby dependency.Id, StringComparer.Ordinal\n                                        group dependency by dependency.Id into dependenciesById\n                                        select new PackageDependency(\n                                            dependenciesById.Key,\n                                            VersionRange.Parse(\n                                                dependenciesById.Select(x => x.Version)\n                                                .Aggregate(AggregateVersions)\n                                                .ToStringSafe())\n                    ))).OrderBy(s => s?.TargetFramework?.GetShortFolderName(), StringComparer.Ordinal)\n                    .ToList();\n        }\n\n        private ICollection<PackageReferenceSet> GetReferenceSets()\n        {\n            var references = from r in References.NullAsEmpty()\n                             select new\n                             {\n                                 File = r.ItemSpec,\n                                 TargetFramework = r.GetTargetFramework(),\n                             };\n\n            return (from reference in references\n                    group reference by reference.TargetFramework into referencesByFramework\n                    select new PackageReferenceSet(\n                        referencesByFramework.Key,\n                        from reference in referencesByFramework\n                                       orderby reference.File, StringComparer.Ordinal\n                                       select reference.File\n                                       )\n                    ).ToList();\n        }\n\n        private static VersionRange AggregateVersions(VersionRange aggregate, VersionRange next)\n        {\n            var versionRange = new VersionRange();\n            SetMinVersion(ref versionRange, aggregate);\n            SetMinVersion(ref versionRange, next);\n            SetMaxVersion(ref versionRange, aggregate);\n            SetMaxVersion(ref versionRange, next);\n\n            if (versionRange.MinVersion == null && versionRange.MaxVersion == null)\n            {\n                versionRange = null;\n            }\n\n            return versionRange;\n        }\n\n        private static void SetMinVersion(ref VersionRange target, VersionRange source)\n        {\n            if (source == null || source.MinVersion == null)\n            {\n                return;\n            }\n\n            bool update = false;\n            NuGetVersion minVersion = target.MinVersion;\n            bool includeMinVersion = target.IsMinInclusive;\n\n            if (target.MinVersion == null)\n            {\n                update = true;\n                minVersion = source.MinVersion;\n                includeMinVersion = source.IsMinInclusive;\n            }\n\n            if (target.MinVersion < source.MinVersion)\n            {\n                update = true;\n                minVersion = source.MinVersion;\n                includeMinVersion = source.IsMinInclusive;\n            }\n\n            if (target.MinVersion == source.MinVersion)\n            {\n                update = true;\n                includeMinVersion = target.IsMinInclusive && source.IsMinInclusive;\n            }\n\n            if (update)\n            {\n                target = new VersionRange(minVersion, includeMinVersion, target.MaxVersion, target.IsMaxInclusive, target.IncludePrerelease, target.Float, target.OriginalString);\n            }\n        }\n\n        private static void SetMaxVersion(ref VersionRange target, VersionRange source)\n        {\n            if (source == null || source.MaxVersion == null)\n            {\n                return;\n            }\n\n            bool update = false;\n            NuGetVersion maxVersion = target.MaxVersion;\n            bool includeMaxVersion = target.IsMaxInclusive;\n\n            if (target.MaxVersion == null)\n            {\n                update = true;\n                maxVersion = source.MaxVersion;\n                includeMaxVersion = source.IsMaxInclusive;\n            }\n\n            if (target.MaxVersion > source.MaxVersion)\n            {\n                update = true;\n                maxVersion = source.MaxVersion;\n                includeMaxVersion = source.IsMaxInclusive;\n            }\n\n            if (target.MaxVersion == source.MaxVersion)\n            {\n                update = true;\n                includeMaxVersion = target.IsMaxInclusive && source.IsMaxInclusive;\n            }\n\n            if (update)\n            {\n                target = new VersionRange(target.MinVersion, target.IsMinInclusive, maxVersion, includeMaxVersion, target.IncludePrerelease, target.Float, target.OriginalString);\n            }\n        }\n\n        private class Dependency\n        {\n            public string Id { get; set; }\n\n            public NuGetFramework TargetFramework { get; set; }\n\n            public VersionRange Version { get; set; }\n        }\n    }\n}\n", "idx": 1, "id": 7716, "msg": "Do we actually use Include anywhere yet or is this just for completion?", "proj": "dotnet-buildtools", "lang": ".cs"}
{"patch": "@@ -4880,7 +4880,7 @@ os_normalized_sysnum(int num_raw, instr_t *gateway, dcontext_t *dcontext)\n         }\n     }\n #    ifdef X64\n-    if (num_raw >> 24 == 0x2)\n+    if (num_raw & SYSCALL_NUM_MARKER_BSD)\n         return (int)(num_raw & 0xffffff); /* Drop BSD bit */\n     else\n         num = (int)num_raw; /* Keep Mach and Machdep bits */", "y": 1, "oldf": "/* *******************************************************************************\n * Copyright (c) 2010-2021 Google, Inc.  All rights reserved.\n * Copyright (c) 2011 Massachusetts Institute of Technology  All rights reserved.\n * Copyright (c) 2000-2010 VMware, Inc.  All rights reserved.\n * *******************************************************************************/\n\n/*\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n * * Redistributions of source code must retain the above copyright notice,\n *   this list of conditions and the following disclaimer.\n *\n * * Redistributions in binary form must reproduce the above copyright notice,\n *   this list of conditions and the following disclaimer in the documentation\n *   and/or other materials provided with the distribution.\n *\n * * Neither the name of VMware, Inc. nor the names of its contributors may be\n *   used to endorse or promote products derived from this software without\n *   specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED. IN NO EVENT SHALL VMWARE, INC. OR CONTRIBUTORS BE LIABLE\n * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\n * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH\n * DAMAGE.\n */\n\n/* Copyright (c) 2003-2007 Determina Corp. */\n/* Copyright (c) 2001-2003 Massachusetts Institute of Technology */\n/* Copyright (c) 2000-2001 Hewlett-Packard Company */\n\n/*\n * os.c - Linux specific routines\n */\n\n/* Easiest to match kernel stat struct by using 64-bit.\n * This limits us to 2.4+ kernel but that's ok.\n * I don't really want to get into requiring kernel headers to build\n * general release packages, though that would be fine for targeted builds.\n * There are 3 different stat syscalls (SYS_oldstat, SYS_stat, and SYS_stat64)\n * and using _LARGEFILE64_SOURCE with SYS_stat64 is the best match.\n */\n#define _LARGEFILE64_SOURCE\n/* for mmap-related #defines */\n#include <sys/types.h>\n#include <sys/mman.h>\n/* in case MAP_32BIT is missing */\n#ifndef MAP_32BIT\n#    define MAP_32BIT 0x40\n#endif\n#ifndef MAP_ANONYMOUS\n#    define MAP_ANONYMOUS MAP_ANON /* MAP_ANON on Mac */\n#endif\n/* for open */\n#include <sys/stat.h>\n#include <fcntl.h>\n#include \"../globals.h\"\n#include \"../hashtable.h\"\n#include \"../native_exec.h\"\n#include <unistd.h> /* for write and usleep and _exit */\n#include <limits.h>\n\n#ifdef MACOS\n#    include <sys/sysctl.h> /* for sysctl */\n#    ifndef SYS___sysctl\n/* The name was changed on Yosemite */\n#        define SYS___sysctl SYS_sysctl\n#    endif\n#    include <mach/mach_traps.h> /* for swtch_pri */\n#    include \"include/syscall_mach.h\"\n#endif\n\n#ifdef LINUX\n#    include <sys/vfs.h> /* for statfs */\n#elif defined(MACOS)\n#    include <sys/mount.h> /* for statfs */\n#    include <mach/mach.h>\n#    include <mach/task.h>\n#    include <mach/semaphore.h>\n#    include <mach/sync_policy.h>\n#endif\n\n#include <dirent.h>\n\n/* for getrlimit */\n#include <sys/time.h>\n#include <sys/resource.h>\n#ifndef X64\nstruct compat_rlimit {\n    uint rlim_cur;\n    uint rlim_max;\n};\n#endif\n#ifdef MACOS\ntypedef struct rlimit rlimit64_t;\n#else\ntypedef struct rlimit64 rlimit64_t;\n#endif\n\n#ifdef LINUX\n/* For clone and its flags, the manpage says to include sched.h with _GNU_SOURCE\n * defined.  _GNU_SOURCE brings in unwanted extensions and causes name\n * conflicts.  Instead, we include unix/sched.h which comes from the Linux\n * kernel headers.\n */\n#    include <linux/sched.h>\n#endif\n\n#include \"module.h\" /* elf */\n#include \"tls.h\"\n\n#if defined(X86) && defined(DEBUG)\n#    include \"os_asm_defines.asm\" /* for TLS_SELF_OFFSET_ASM */\n#endif\n\n#ifndef F_DUPFD_CLOEXEC /* in linux 2.6.24+ */\n#    define F_DUPFD_CLOEXEC 1030\n#endif\n\n/* This is not always sufficient to identify a syscall return value.\n * For example, MacOS has some 32-bit syscalls that return 64-bit\n * values in xdx:xax.\n */\n#define MCXT_SYSCALL_RES(mc) ((mc)->IF_X86_ELSE(xax, r0))\n#if defined(DR_HOST_AARCH64)\n#    define READ_TP_TO_R3_DISP_IN_R2    \\\n        \"mrs \" ASM_R3 \", tpidr_el0\\n\\t\" \\\n        \"ldr \" ASM_R3 \", [\" ASM_R3 \", \" ASM_R2 \"] \\n\\t\"\n#elif defined(DR_HOST_ARM)\n#    define READ_TP_TO_R3_DISP_IN_R2                                           \\\n        \"mrc p15, 0, \" ASM_R3                                                  \\\n        \", c13, c0, \" STRINGIFY(USR_TLS_REG_OPCODE) \" \\n\\t\"                    \\\n                                                    \"ldr \" ASM_R3 \", [\" ASM_R3 \\\n                                                    \", \" ASM_R2 \"] \\n\\t\"\n#endif /* ARM */\n\n/* Prototype for all functions in .init_array. */\ntypedef int (*init_fn_t)(int argc, char **argv, char **envp);\n\n/* For STATIC_LIBRARY we do not cache environ so the app can change it. */\n#ifndef STATIC_LIBRARY\n/* i#46: Private __environ pointer.  Points at the environment variable array\n * on the stack, which is different from what libc __environ may point at.  We\n * use the environment for following children and setting options, so its OK\n * that we don't see what libc says.\n */\nchar **our_environ;\n#endif\n\n#include <errno.h>\n/* avoid problems with use of errno as var name in rest of file */\n#if !defined(STANDALONE_UNIT_TEST) && !defined(MACOS)\n#    undef errno\n#endif\n/* we define __set_errno below */\n\n/* must be prior to <link.h> => <elf.h> => INT*_{MIN,MAX} */\n#include \"instr.h\" /* for get_app_segment_base() */\n\n#include \"decode_fast.h\" /* decode_cti: maybe os_handle_mov_seg should be ifdef X86? */\n\n#include <dlfcn.h>\n#include <stdlib.h>\n#include <stdio.h>\n#include <signal.h>\n#include <syslog.h> /* vsyslog */\n#include \"../vmareas.h\"\n#ifdef RCT_IND_BRANCH\n#    include \"../rct.h\"\n#endif\n#ifdef LINUX\n#    include \"include/syscall.h\" /* our own local copy */\n#    include \"include/clone3.h\"\n#    include \"include/close_range.h\"\n#else\n#    include <sys/syscall.h>\n#endif\n#include \"../module_shared.h\"\n#include \"os_private.h\"\n#include \"../synch.h\"\n#include \"memquery.h\"\n#include \"ksynch.h\"\n#include \"dr_tools.h\" /* dr_syscall_result_info_t */\n\n#ifndef HAVE_MEMINFO_QUERY\n#    include \"memcache.h\"\n#endif\n\n#include \"instrument.h\"\n\n#ifdef LINUX\n#    include \"rseq_linux.h\"\n#endif\n\n#ifdef MACOS\n#    define SYSNUM_EXIT_PROCESS SYS_exit\n#    define SYSNUM_EXIT_THREAD SYS_bsdthread_terminate\n#else\n#    define SYSNUM_EXIT_PROCESS SYS_exit_group\n#    define SYSNUM_EXIT_THREAD SYS_exit\n#endif\n\n#ifdef ANDROID\n/* Custom prctl flags specific to Android (xref i#1861) */\n#    define PR_SET_VMA 0x53564d41\n#    define PR_SET_VMA_ANON_NAME 0\n#endif\n\n/* Guards data written by os_set_app_thread_area(). */\nDECLARE_CXTSWPROT_VAR(static mutex_t set_thread_area_lock,\n                      INIT_LOCK_FREE(set_thread_area_lock));\n\nstatic bool first_thread_tls_initialized;\nstatic bool last_thread_tls_exited;\n\ntls_type_t tls_global_type;\n\n#ifndef HAVE_TLS\n/* We use a table lookup to find a thread's dcontext */\n/* Our only current no-TLS target, VMKernel (VMX86_SERVER), doesn't have apps with\n * tons of threads anyway\n */\n#    define MAX_THREADS 512\ntypedef struct _tls_slot_t {\n    thread_id_t tid;\n    dcontext_t *dcontext;\n} tls_slot_t;\n/* Stored in heap for self-prot */\nstatic tls_slot_t *tls_table;\n/* not static so deadlock_avoidance_unlock() can look for it */\nDECLARE_CXTSWPROT_VAR(mutex_t tls_lock, INIT_LOCK_FREE(tls_lock));\n#endif\n\n/* Should we place this in a client header?  Currently mentioned in\n * dr_raw_tls_calloc() docs.\n */\nstatic bool client_tls_allocated[MAX_NUM_CLIENT_TLS];\nDECLARE_CXTSWPROT_VAR(static mutex_t client_tls_lock, INIT_LOCK_FREE(client_tls_lock));\n\n#include <stddef.h> /* for offsetof */\n\n#include <sys/utsname.h> /* for struct utsname */\n\n/* forward decl */\nstatic void\nhandle_execve_post(dcontext_t *dcontext);\nstatic bool\nos_switch_lib_tls(dcontext_t *dcontext, bool to_app);\nstatic bool\nos_switch_seg_to_context(dcontext_t *dcontext, reg_id_t seg, bool to_app);\n#ifdef X86\nstatic bool\nos_set_dr_tls_base(dcontext_t *dcontext, os_local_state_t *tls, byte *base);\n#endif\n#ifdef LINUX\nstatic bool\nhandle_app_mremap(dcontext_t *dcontext, byte *base, size_t size, byte *old_base,\n                  size_t old_size, uint old_prot, uint old_type);\nstatic void\nhandle_app_brk(dcontext_t *dcontext, byte *lowest_brk /*if known*/, byte *old_brk,\n               byte *new_brk);\n#endif\n\n/* full path to our own library, used for execve */\nstatic char dynamorio_library_path[MAXIMUM_PATH]; /* just dir */\nstatic char dynamorio_library_filepath[MAXIMUM_PATH];\n/* Issue 20: path to other architecture */\nstatic char dynamorio_alt_arch_path[MAXIMUM_PATH];\nstatic char dynamorio_alt_arch_filepath[MAXIMUM_PATH]; /* just dir */\n/* Makefile passes us LIBDIR_X{86,64} defines */\n#define DR_LIBDIR_X86 STRINGIFY(LIBDIR_X86)\n#define DR_LIBDIR_X64 STRINGIFY(LIBDIR_X64)\n\n/* pc values delimiting dynamo dll image */\nstatic app_pc dynamo_dll_start = NULL;\nstatic app_pc dynamo_dll_end = NULL; /* open-ended */\n\n/* pc values delimiting the app, equal to the \"dll\" bounds for static DR */\nstatic app_pc executable_start = NULL;\nstatic app_pc executable_end = NULL;\n\n/* Used by get_application_name(). */\nstatic char executable_path[MAXIMUM_PATH];\nstatic char *executable_basename;\n\n/* Pointers to arguments. Refers to the main stack set up by the kernel.\n * These are only written once during process init and we can live with\n * the non-guaranteed-delay until they are visible to other cores.\n */\nstatic int *app_argc = NULL;\nstatic char **app_argv = NULL;\n\n/* does the kernel provide tids that must be used to distinguish threads in a group? */\nstatic bool kernel_thread_groups;\n\nstatic bool kernel_64bit;\n\npid_t pid_cached;\n\nstatic bool fault_handling_initialized;\n\n#ifdef PROFILE_RDTSC\nuint kilo_hertz; /* cpu clock speed */\n#endif\n\n/* Xref PR 258731, dup of STDOUT/STDERR in case app wants to close them. */\nDR_API file_t our_stdout = STDOUT_FILENO;\nDR_API file_t our_stderr = STDERR_FILENO;\nDR_API file_t our_stdin = STDIN_FILENO;\n\n/* we steal fds from the app */\nstatic rlimit64_t app_rlimit_nofile; /* cur rlimit set by app */\nstatic int min_dr_fd;\n\n/* we store all DR files so we can prevent the app from changing them,\n * and so we can close them in a child of fork.\n * the table key is the fd and the payload is the set of DR_FILE_* flags.\n */\nstatic generic_table_t *fd_table;\n#define INIT_HTABLE_SIZE_FD 6 /* should remain small */\n#ifdef DEBUG\nstatic int num_fd_add_pre_heap;\n#endif\n\n#ifdef LINUX\n/* i#1004: brk emulation */\nstatic byte *app_brk_map;\nstatic byte *app_brk_cur;\nstatic byte *app_brk_end;\n#endif\n\n#ifdef MACOS\nstatic int macos_version;\n#endif\n\nstatic bool\nis_readable_without_exception_internal(const byte *pc, size_t size, bool query_os);\n\nstatic bool\nmmap_check_for_module_overlap(app_pc base, size_t size, bool readable, uint64 inode,\n                              bool at_map);\n\n#ifdef LINUX\nstatic char *\nread_proc_self_exe(bool ignore_cache);\n#endif\n\n/* Libc independent directory iterator, similar to readdir.  If we ever need\n * this on Windows we should generalize it and export it to clients.\n */\ntypedef struct _dir_iterator_t {\n    file_t fd;\n    int off;\n    int end;\n    const char *name;           /* Name of the current entry. */\n    char buf[4 * MAXIMUM_PATH]; /* Expect stack alloc, so not too big. */\n} dir_iterator_t;\n\nstatic void\nos_dir_iterator_start(dir_iterator_t *iter, file_t fd);\nstatic bool\nos_dir_iterator_next(dir_iterator_t *iter);\n/* XXX: If we generalize to Windows, will we need os_dir_iterator_stop()? */\n\n/* vsyscall page.  hardcoded at 0xffffe000 in earlier kernels, but\n * randomly placed since fedora2.\n * marked rx then: FIXME: should disallow this guy when that's the case!\n * random vsyscall page is identified in maps files as \"[vdso]\"\n * (kernel-provided fake shared library or Virt Dyn Shared Object).\n */\n/* i#1583: vdso is now 2 pages, yet we assume vsyscall is on 1st page. */\n/* i#2945: vdso is now 3 pages and vsyscall is not on the 1st page. */\napp_pc vsyscall_page_start = NULL;\n/* pc of the end of the syscall instr itself */\napp_pc vsyscall_syscall_end_pc = NULL;\n/* pc where kernel returns control after sysenter vsyscall */\napp_pc vsyscall_sysenter_return_pc = NULL;\n/* pc where our hook-displaced code was copied */\napp_pc vsyscall_sysenter_displaced_pc = NULL;\n#define VSYSCALL_PAGE_START_HARDCODED ((app_pc)(ptr_uint_t)0xffffe000)\n#ifdef X64\n/* i#430, in Red Hat Enterprise Server 5.6, vsyscall region is marked\n * not executable\n * ffffffffff600000-ffffffffffe00000 ---p 00000000 00:00 0  [vsyscall]\n */\n#    define VSYSCALL_REGION_MAPS_NAME \"[vsyscall]\"\n#endif\n/* i#1908: vdso and vsyscall are now split */\napp_pc vdso_page_start = NULL;\nsize_t vdso_size = 0;\n\n#if !defined(STANDALONE_UNIT_TEST) && !defined(STATIC_LIBRARY)\n/* The pthreads library keeps errno in its pthread_descr data structure,\n * which it looks up by dispatching on the stack pointer.  This doesn't work\n * when within dynamo.  Thus, we define our own __errno_location() for use both\n * by us and the app, to prevent pthreads looking at the stack pointer when\n * out of the code cache.\n */\n\n/* FIXME: maybe we should create 1st dcontext earlier so we don't need init_errno?\n * any problems with init_errno being set and then dcontext->errno being read?\n * FIXME: if a thread issues a dr_app_stop, then we don't want to use\n * this errno slot?  But it may later do a start...probably ok to keep using\n * the slot.  But, when threads die, they'll all use the same init_errno!\n */\nstatic int init_errno; /* errno until 1st dcontext created */\n\nint *\n__errno_location(void)\n{\n    /* Each dynamo thread should have a separate errno */\n    dcontext_t *dcontext = get_thread_private_dcontext();\n    if (dcontext == NULL)\n        return &init_errno;\n    else {\n        /* WARNING: init_errno is in data segment so can be RO! */\n        return &(dcontext->upcontext_ptr->dr_errno);\n    }\n}\n#endif /* !STANDALONE_UNIT_TEST && !STATIC_LIBRARY */\n\n#ifdef HAVE_TLS\n/* i#598\n * (gdb) x/20i (*(errno_loc_t)0xf721e413)\n * 0xf721e413 <__errno_location>:       push   %ebp\n * 0xf721e414 <__errno_location+1>:     mov    %esp,%ebp\n * 0xf721e416 <__errno_location+3>:     call   <__x86.get_pc_thunk.cx>\n * 0xf721e41b <__errno_location+8>:     add    $0x166bd9,%ecx\n * 0xf721e421 <__errno_location+14>:    mov    -0x1c(%ecx),%eax\n * 0xf721e427 <__errno_location+20>:    add    %gs:0x0,%eax\n * 0xf721e42e <__errno_location+27>:    pop    %ebp\n * 0xf721e42f <__errno_location+28>:    ret\n *\n * __errno_location calcuates the errno location by adding\n * TLS's base with errno's offset in TLS.\n * However, because the TLS has been switched in os_tls_init,\n * the calculated address is wrong.\n * We first get the errno offset in TLS at init time and\n * calculate correct address by adding the app's tls base.\n */\n/* __errno_location on ARM:\n * 0xb6f0b290 <__errno_location>:    ldr r3, [pc, #12]\n * 0xb6f0b292 <__errno_location+2>:  mrc 15, 0, r0, cr13, cr0, {3}\n * 0xb6f0b296 <__errno_location+6>:  add r3, pc\n * 0xb6f0b298 <__errno_location+8>:  ldr r3, [r3, #0]\n * 0xb6f0b29a <__errno_location+10>: adds r0, r0, r3\n * 0xb6f0b29c <__errno_location+12>: bx lr\n * It uses the predefined offset to get errno location in TLS,\n * and we should be able to reuse the code here.\n */\nstatic int libc_errno_tls_offs;\nstatic int *\nour_libc_errno_loc(void)\n{\n    void *app_tls = os_get_app_tls_base(NULL, TLS_REG_LIB);\n    if (app_tls == NULL)\n        return NULL;\n    return (int *)(app_tls + libc_errno_tls_offs);\n}\n#endif\n\n/* i#238/PR 499179: libc errno preservation\n *\n * Errno location is per-thread so we store the\n * function globally and call it each time.  Note that pthreads seems\n * to be the one who provides per-thread errno: using raw syscalls to\n * create threads, we end up with a global errno:\n *\n *   > for i in linux.thread.*0/log.*; do grep 'libc errno' $i | head -1; done\n *   libc errno loc: 0x00007f153de26698\n *   libc errno loc: 0x00007f153de26698\n *   > for i in pthreads.pthreads.*0/log.*; do grep 'libc errno' $i | head -1; done\n *   libc errno loc: 0x00007fc24d1ce698\n *   libc errno loc: 0x00007fc24d1cd8b8\n *   libc errno loc: 0x00007fc24c7cc8b8\n */\ntypedef int *(*errno_loc_t)(void);\n\n#ifdef LINUX\n/* Stores whether clone3 is unsupported on the system we're running on. */\nstatic bool is_clone3_enosys = false;\n#endif\n\nstatic errno_loc_t\nget_libc_errno_location(bool do_init)\n{\n    static errno_loc_t libc_errno_loc;\n\n    if (do_init) {\n        module_iterator_t *mi = module_iterator_start();\n        while (module_iterator_hasnext(mi)) {\n            module_area_t *area = module_iterator_next(mi);\n            const char *modname = GET_MODULE_NAME(&area->names);\n            /* We ensure matches start to avoid matching \"libgolibc.so\".\n             * GET_MODULE_NAME never includes the path: i#138 will add path.\n             */\n            if (modname != NULL && strstr(modname, \"libc.so\") == modname) {\n                bool found = true;\n                /* called during init when .data is writable */\n                libc_errno_loc =\n                    (errno_loc_t)d_r_get_proc_address(area->start, \"__errno_location\");\n                ASSERT(libc_errno_loc != NULL);\n                LOG(GLOBAL, LOG_THREADS, 2, \"libc errno loc func: \" PFX \"\\n\",\n                    libc_errno_loc);\n                /* Currently, the DR is loaded by system loader and hooked up\n                 * to app's libc.  So right now, we still need this routine.\n                 * we can remove this after libc independency and/or\n                 * early injection\n                 */\n                if (INTERNAL_OPTION(private_loader)) {\n                    acquire_recursive_lock(&privload_lock);\n                    if (privload_lookup_by_base(area->start) != NULL)\n                        found = false;\n                    release_recursive_lock(&privload_lock);\n                }\n                if (found)\n                    break;\n            }\n        }\n        module_iterator_stop(mi);\n#ifdef HAVE_TLS\n        /* i#598: init the libc errno's offset.  If we didn't find libc above,\n         * then we don't need to do this.\n         */\n        if (INTERNAL_OPTION(private_loader) && libc_errno_loc != NULL) {\n            void *priv_lib_tls_base = os_get_priv_tls_base(NULL, TLS_REG_LIB);\n            ASSERT(priv_lib_tls_base != NULL);\n            libc_errno_tls_offs = (void *)libc_errno_loc() - priv_lib_tls_base;\n            libc_errno_loc = &our_libc_errno_loc;\n        }\n#endif\n    }\n    return libc_errno_loc;\n}\n\n/* i#238/PR 499179: our __errno_location isn't affecting libc so until\n * we have libc independence or our own private isolated libc we need\n * to preserve the app's libc's errno\n */\nint\nget_libc_errno(void)\n{\n#if defined(STANDALONE_UNIT_TEST) && (defined(MACOS) || defined(ANDROID))\n    return errno;\n#else\n#    ifdef STANDALONE_UNIT_TEST\n    errno_loc_t func = __errno_location;\n#    else\n    errno_loc_t func = get_libc_errno_location(false);\n#    endif\n    if (func == NULL) {\n        /* libc hasn't been loaded yet or we're doing early injection. */\n        return 0;\n    } else {\n        int *loc = (*func)();\n        ASSERT(loc != NULL);\n        LOG(THREAD_GET, LOG_THREADS, 5, \"libc errno loc: \" PFX \"\\n\", loc);\n        if (loc != NULL)\n            return *loc;\n    }\n    return 0;\n#endif\n}\n\n/* N.B.: pthreads has two other locations it keeps on a per-thread basis:\n * h_errno and res_state.  See glibc-2.2.4/linuxthreads/errno.c.\n * If dynamo ever modifies those we'll need to do to them what we now do to\n * errno.\n */\n\n/* The environment vars exhibit totally messed up behavior when someone\n * does an execve of /bin/sh -- not sure what's going on, but using our\n * own implementation of unsetenv fixes all our problems.  If we use\n * libc's, unsetenv either does nothing or ends up having getenv return\n * NULL for other vars that are obviously set (by iterating through environ).\n * FIXME: find out the real story here.\n */\nint\nour_unsetenv(const char *name)\n{\n    /* FIXME: really we should have some kind of synchronization */\n    size_t name_len;\n    char **env = our_environ;\n    if (name == NULL || *name == '\\0' || strchr(name, '=') != NULL) {\n        return -1;\n    }\n    ASSERT(our_environ != NULL);\n    if (our_environ == NULL)\n        return -1;\n    name_len = strlen(name);\n    while (*env != NULL) {\n        if (strncmp(*env, name, name_len) == 0 && (*env)[name_len] == '=') {\n            /* We have a match.  Shift the subsequent entries.  Keep going to\n             * handle later matches.\n             */\n            char **e;\n            for (e = env; *e != NULL; e++)\n                *e = *(e + 1);\n        } else {\n            env++;\n        }\n    }\n    return 0;\n}\n\n/* Clobbers the name rather than shifting, to preserve auxv (xref i#909). */\nbool\ndisable_env(const char *name)\n{\n    size_t name_len;\n    char **env = our_environ;\n    if (name == NULL || *name == '\\0' || strchr(name, '=') != NULL) {\n        return false;\n    }\n    ASSERT(our_environ != NULL);\n    if (our_environ == NULL)\n        return false;\n    name_len = strlen(name);\n    while (*env != NULL) {\n        if (strncmp(*env, name, name_len) == 0 && (*env)[name_len] == '=') {\n            /* We have a match.  If we shift subsequent entries we'll mess\n             * up access to auxv, which is after the env block, so we instead\n             * disable the env var by changing its name.\n             * We keep going to handle later matches.\n             */\n            snprintf(*env, name_len, \"__disabled__\");\n        }\n        env++;\n    }\n    return true;\n}\n\n/* i#46: Private getenv.\n */\nchar *\nour_getenv(const char *name)\n{\n    char **env = our_environ;\n    size_t i;\n    size_t name_len;\n    if (name == NULL || name[0] == '\\0' || strchr(name, '=') != NULL) {\n        return NULL;\n    }\n    ASSERT_MESSAGE(CHKLVL_ASSERTS,\n                   \"our_environ is missing.  _init() or \"\n                   \"dynamorio_set_envp() were not called\",\n                   our_environ != NULL);\n    if (our_environ == NULL)\n        return NULL;\n    name_len = strlen(name);\n    for (i = 0; env[i] != NULL; i++) {\n        if (strncmp(env[i], name, name_len) == 0 && env[i][name_len] == '=') {\n            return env[i] + name_len + 1;\n        }\n    }\n    return NULL;\n}\n\nbool\nis_our_environ_followed_by_auxv(void)\n{\n#ifdef STATIC_LIBRARY\n    /* Since we initialize late, our_environ is likely no longer pointed at\n     * the stack (i#2122).\n     */\n    return false;\n#else\n    return true;\n#endif\n}\n\n/* Work around drpreload's _init going first.  We can get envp in our own _init\n * routine down below, but drpreload.so comes first and calls\n * dynamorio_app_init before our own _init routine gets called.  Apps using the\n * app API are unaffected because our _init routine will have run by then.  For\n * STATIC_LIBRARY, we used to set our_environ in our_init(), but to support\n * the app setting DYNAMORIO_OPTIONS after our_init() runs, we now just use environ.\n */\nDYNAMORIO_EXPORT\nvoid\ndynamorio_set_envp(char **envp)\n{\n    our_environ = envp;\n}\n\n/* shared library init */\nstatic int\nour_init(int argc, char **argv, char **envp)\n{\n    /* If we do not want to use drpreload.so, we can take over here: but when using\n     * drpreload, this is called *after* we have already taken over.\n     */\n    extern void dynamorio_app_take_over(void);\n    bool takeover = false;\n#ifdef INIT_TAKE_OVER\n    takeover = true;\n#endif\n#ifdef VMX86_SERVER\n    /* PR 391765: take over here instead of using preload */\n    takeover = os_in_vmkernel_classic();\n#endif\n#ifndef STATIC_LIBRARY\n    if (our_environ != NULL) {\n        /* Set by dynamorio_set_envp above.  These should agree. */\n        ASSERT(our_environ == envp);\n    } else {\n        our_environ = envp;\n    }\n#endif\n    /* if using preload, no -early_inject */\n#ifdef STATIC_LIBRARY\n    if (!takeover) {\n        const char *takeover_env = getenv(\"DYNAMORIO_TAKEOVER_IN_INIT\");\n        if (takeover_env != NULL && strcmp(takeover_env, \"1\") == 0) {\n            takeover = true;\n        }\n    }\n#endif\n    if (takeover) {\n        if (dynamorio_app_init() == 0 /* success */) {\n            dynamorio_app_take_over();\n        }\n    }\n    return 0;\n}\n\n#if defined(STATIC_LIBRARY) || defined(STANDALONE_UNIT_TEST)\n/* If we're getting linked into a binary that already has an _init definition\n * like the app's exe or unit_tests, we add a pointer to our_init() to the\n * .init_array section.  We can't use the constructor attribute because not all\n * toolchains pass the args and environment to the constructor.\n */\nstatic init_fn_t\n#    ifdef MACOS\n    __attribute__((section(\"__DATA,__mod_init_func\"), aligned(sizeof(void *)), used))\n#    else\n    __attribute__((section(\".init_array\"), aligned(sizeof(void *)), used))\n#    endif\n    init_array[] = { our_init };\n#else\n/* If we're a normal shared object, then we override _init.\n */\nint\n_init(int argc, char **argv, char **envp)\n{\n#    ifdef ANDROID\n    /* i#1862: the Android loader passes *nothing* to lib init routines.  We\n     * rely on DR being listed before libc so we can read the TLS slot the\n     * kernel set up.\n     */\n    if (!get_kernel_args(&argc, &argv, &envp)) {\n        /* XXX: scan the stack and look for known auxv patterns or sthg. */\n        argc = 0;\n        argv = NULL;\n        envp = NULL;\n    }\n    ASSERT_MESSAGE(CHKLVL_ASSERTS, \"failed to find envp\", envp != NULL);\n#    endif\n    return our_init(argc, argv, envp);\n}\n#endif\n\nbool\nkernel_is_64bit(void)\n{\n    return kernel_64bit;\n}\n\n#ifdef MACOS\n/* XXX: if we get enough of these, move to os_macos.c or sthg */\nstatic bool\nsysctl_query(int level0, int level1, void *buf, size_t bufsz)\n{\n    int res;\n    int name[2];\n    size_t len = bufsz;\n    name[0] = level0;\n    name[1] = level1;\n    res = dynamorio_syscall(SYS___sysctl, 6, &name, 2, buf, &len, NULL, 0);\n    return (res >= 0);\n}\n\nint\nos_get_version(void)\n{\n    return macos_version;\n}\n#endif\n\nstatic void\nget_uname(void)\n{\n    /* assumption: only called at init, so we don't need any synch\n     * or .data unprot\n     */\n    static struct utsname uinfo; /* can be large, avoid stack overflow */\n#ifdef MACOS\n    if (!sysctl_query(CTL_KERN, KERN_OSTYPE, &uinfo.sysname, sizeof(uinfo.sysname)) ||\n        !sysctl_query(CTL_KERN, KERN_HOSTNAME, &uinfo.nodename, sizeof(uinfo.nodename)) ||\n        !sysctl_query(CTL_KERN, KERN_OSRELEASE, &uinfo.release, sizeof(uinfo.release)) ||\n        !sysctl_query(CTL_KERN, KERN_VERSION, &uinfo.version, sizeof(uinfo.version)) ||\n        !sysctl_query(CTL_HW, HW_MACHINE, &uinfo.machine, sizeof(uinfo.machine))) {\n        ASSERT(false && \"sysctl queries failed\");\n        return;\n    }\n#else\n    DEBUG_DECLARE(int res =)\n    dynamorio_syscall(SYS_uname, 1, (ptr_uint_t)&uinfo);\n    ASSERT(res >= 0);\n#endif\n    LOG(GLOBAL, LOG_TOP, 1, \"uname:\\n\\tsysname: %s\\n\", uinfo.sysname);\n    LOG(GLOBAL, LOG_TOP, 1, \"\\tnodename: %s\\n\", uinfo.nodename);\n    LOG(GLOBAL, LOG_TOP, 1, \"\\trelease: %s\\n\", uinfo.release);\n    LOG(GLOBAL, LOG_TOP, 1, \"\\tversion: %s\\n\", uinfo.version);\n    LOG(GLOBAL, LOG_TOP, 1, \"\\tmachine: %s\\n\", uinfo.machine);\n    if (strncmp(uinfo.machine, \"x86_64\", sizeof(\"x86_64\")) == 0)\n        kernel_64bit = true;\n#ifdef MACOS\n    /* XXX: I would skip these checks for standalone so we don't have to set env\n     * vars for frontends to see the options but I'm still afraid of some syscall\n     * crash with no output: I'd rather have two messages than silent crashing.\n     */\n    if (DYNAMO_OPTION(max_supported_os_version) != 0) { /* 0 disables */\n        /* We only support OSX 10.7.5+.  That means kernels 11.x+. */\n#    define MIN_DARWIN_VERSION_SUPPORTED 11\n        int kernel_major;\n        if (sscanf(uinfo.release, \"%d\", &kernel_major) != 1 ||\n            kernel_major > DYNAMO_OPTION(max_supported_os_version) ||\n            kernel_major < MIN_DARWIN_VERSION_SUPPORTED) {\n            /* We make this non-fatal as it's likely DR will work */\n            SYSLOG(SYSLOG_WARNING, UNSUPPORTED_OS_VERSION, 3, get_application_name(),\n                   get_application_pid(), uinfo.release);\n        }\n        macos_version = kernel_major;\n    }\n#endif\n}\n\n#if defined(LINUX)\n/* For some syscalls, detects whether they are unsupported by the system\n * we're running on. Particularly, we are interested in detecting missing\n * support early-on for syscalls that require complex pre-syscall handling\n * by DR. We use this information to fail early for those syscalls.\n *\n * XXX: Move other logic for detecting unsupported syscalls from their\n * respective locations to here at init time, like that for\n * SYS_memfd_create in os_create_memory_file.\n *\n */\nstatic void\ndetect_unsupported_syscalls()\n{\n    /* We know that when clone3 is available, it fails with EINVAL with\n     * these args.\n     */\n    int clone3_errno =\n        dynamorio_syscall(SYS_clone3, 2, NULL /*clone_args*/, 0 /*clone_args_size*/);\n    ASSERT(clone3_errno == -ENOSYS || clone3_errno == -EINVAL);\n    is_clone3_enosys = clone3_errno == -ENOSYS;\n}\n#endif\n\n/* os-specific initializations */\nvoid\nd_r_os_init(void)\n{\n    ksynch_init();\n\n    get_uname();\n\n    /* Populate global data caches. */\n    get_application_name();\n    get_application_base();\n\n    /* determine whether gettid is provided and needed for threads,\n     * or whether getpid suffices.  even 2.4 kernels have gettid\n     * (maps to getpid), don't have an old enough target to test this.\n     */\n#ifdef MACOS\n    kernel_thread_groups = (dynamorio_syscall(SYS_thread_selfid, 0) >= 0);\n#else\n    kernel_thread_groups = (dynamorio_syscall(SYS_gettid, 0) >= 0);\n#endif\n    LOG(GLOBAL, LOG_TOP | LOG_STATS, 1, \"thread id is from %s\\n\",\n        kernel_thread_groups ? \"gettid\" : \"getpid\");\n#ifdef MACOS\n    /* SYS_thread_selfid was added in 10.6.  We have no simple way to get the\n     * thread id on 10.5, so we don't support it.\n     */\n    if (!kernel_thread_groups) {\n        SYSLOG(SYSLOG_WARNING, UNSUPPORTED_OS_VERSION, 3, get_application_name(),\n               get_application_pid(), \"Mac OSX 10.5 or earlier\");\n    }\n#else\n    ASSERT_CURIOSITY(kernel_thread_groups);\n#endif\n\n    pid_cached = get_process_id();\n\n#ifdef VMX86_SERVER\n    vmk_init();\n#endif\n\n    d_r_signal_init();\n    /* We now set up an early fault handler for d_r_safe_read() (i#350) */\n    fault_handling_initialized = true;\n\n    memquery_init();\n\n#ifdef PROFILE_RDTSC\n    if (dynamo_options.profile_times) {\n        ASSERT_NOT_TESTED();\n        kilo_hertz = get_timer_frequency();\n        LOG(GLOBAL, LOG_TOP | LOG_STATS, 1, \"CPU MHz is %d\\n\", kilo_hertz / 1000);\n    }\n#endif /* PROFILE_RDTSC */\n    /* Needs to be after heap_init */\n    IF_NO_MEMQUERY(memcache_init());\n\n    /* we didn't have heap in os_file_init() so create and add global logfile now */\n    fd_table = generic_hash_create(\n        GLOBAL_DCONTEXT, INIT_HTABLE_SIZE_FD, 80 /* load factor: not perf-critical */,\n        HASHTABLE_SHARED | HASHTABLE_PERSISTENT, NULL _IF_DEBUG(\"fd table\"));\n#ifdef DEBUG\n    if (GLOBAL != INVALID_FILE)\n        fd_table_add(GLOBAL, OS_OPEN_CLOSE_ON_FORK);\n#endif\n\n    /* Ensure initialization */\n    get_dynamorio_dll_start();\n\n#ifdef LINUX\n    if (DYNAMO_OPTION(emulate_brk))\n        init_emulated_brk(NULL);\n#endif\n\n#ifdef ANDROID\n    /* This must be set up earlier than privload_tls_init, and must be set up\n     * for non-client-interface as well, as this initializes DR_TLS_BASE_OFFSET\n     * (i#1931).\n     */\n    init_android_version();\n#endif\n#ifdef LINUX\n    if (!standalone_library)\n        d_r_rseq_init();\n#endif\n#ifdef MACOS64\n    tls_process_init();\n#endif\n#if defined(LINUX)\n    detect_unsupported_syscalls();\n#endif\n}\n\n/* called before any logfiles are opened */\nvoid\nos_file_init(void)\n{\n    /* We steal fds from the app for better transparency.  We lower the max file\n     * descriptor limit as viewed by the app, and block SYS_dup{2,3} and\n     * SYS_fcntl(F_DUPFD*) from creating a file explicitly in our space.  We do\n     * not try to stop incremental file opening from extending into our space:\n     * if the app really is running out of fds, we'll give it some of ours:\n     * after all we probably don't need all -steal_fds, and if we really need fds\n     * we typically open them at startup.  We also don't bother watching all\n     * syscalls that take in fds from affecting our fds.\n     */\n    if (DYNAMO_OPTION(steal_fds) > 0) {\n        struct rlimit rlimit_nofile;\n        /* SYS_getrlimit uses an old 32-bit-field struct so we want SYS_ugetrlimit */\n        if (dynamorio_syscall(\n                IF_MACOS_ELSE(SYS_getrlimit, IF_X64_ELSE(SYS_getrlimit, SYS_ugetrlimit)),\n                2, RLIMIT_NOFILE, &rlimit_nofile) != 0) {\n            /* linux default is 1024 */\n            SYSLOG_INTERNAL_WARNING(\"getrlimit RLIMIT_NOFILE failed\"); /* can't LOG yet */\n            rlimit_nofile.rlim_cur = 1024;\n            rlimit_nofile.rlim_max = 1024;\n        }\n        /* pretend the limit is lower and reserve the top spots for us.\n         * for simplicity and to give as much room as possible to app,\n         * raise soft limit to equal hard limit.\n         * if an app really depends on a low soft limit, they can run\n         * with -steal_fds 0.\n         */\n        if (rlimit_nofile.rlim_max > DYNAMO_OPTION(steal_fds)) {\n            int res;\n            min_dr_fd = rlimit_nofile.rlim_max - DYNAMO_OPTION(steal_fds);\n            app_rlimit_nofile.rlim_max = min_dr_fd;\n            app_rlimit_nofile.rlim_cur = app_rlimit_nofile.rlim_max;\n\n            rlimit_nofile.rlim_cur = rlimit_nofile.rlim_max;\n            res = dynamorio_syscall(SYS_setrlimit, 2, RLIMIT_NOFILE, &rlimit_nofile);\n            if (res != 0) {\n                SYSLOG_INTERNAL_WARNING(\"unable to raise RLIMIT_NOFILE soft limit: %d\",\n                                        res);\n            }\n        } else /* not fatal: we'll just end up using fds in app space */\n            SYSLOG_INTERNAL_WARNING(\"unable to reserve fds\");\n    }\n\n    /* we don't have heap set up yet so we init fd_table in os_init */\n}\n\n/* we need to re-cache after a fork */\nstatic char *\nget_application_pid_helper(bool ignore_cache)\n{\n    static char pidstr[16];\n\n    if (!pidstr[0] || ignore_cache) {\n        int pid = get_process_id();\n        snprintf(pidstr, sizeof(pidstr) - 1, \"%d\", pid);\n    }\n    return pidstr;\n}\n\n/* get application pid, (cached), used for event logging */\nchar *\nget_application_pid()\n{\n    return get_application_pid_helper(false);\n}\n\n/* The OSX kernel used to place the bare executable path above envp.\n * On recent XNU versions, the kernel now prefixes the executable path\n * with the string executable_path= so it can be parsed getenv style.\n */\n#ifdef MACOS\n#    define EXECUTABLE_KEY \"executable_path=\"\n#endif\n/* i#189: we need to re-cache after a fork */\nstatic char *\nget_application_name_helper(bool ignore_cache, bool full_path)\n{\n    if (!executable_path[0] || ignore_cache) {\n#ifdef VMX86_SERVER\n        if (os_in_vmkernel_userworld()) {\n            vmk_getnamefrompid(pid, executable_path, sizeof(executable_path));\n        } else\n#endif\n            if (DYNAMO_OPTION(early_inject)) {\n            ASSERT(executable_path[0] != '\\0' &&\n                   \"i#907: Can't read /proc/self/exe for early injection\");\n        } else {\n#ifdef LINUX\n            /* Populate cache from /proc/self/exe link. */\n            strncpy(executable_path, read_proc_self_exe(ignore_cache),\n                    BUFFER_SIZE_ELEMENTS(executable_path));\n#else\n            /* OSX kernel puts full app exec path above envp */\n            char *c, **env = our_environ;\n            do {\n                env++;\n            } while (*env != NULL);\n            env++; /* Skip the NULL separating the envp array from exec_path */\n            c = *env;\n            if (strncmp(EXECUTABLE_KEY, c, strlen(EXECUTABLE_KEY)) == 0) {\n                c += strlen(EXECUTABLE_KEY);\n            }\n            /* If our frontends always absolute-ize paths prior to exec,\n             * this should usually be absolute -- but we go ahead and\n             * handle relative just in case (and to handle child processes).\n             * We add the cur dir, but note that the resulting path can\n             * still contain . or .. so it's not normalized (but it is a\n             * correct absolute path).  Xref i#1402, i#1406, i#1407.\n             */\n            if (*c != '/') {\n                int len;\n                if (!os_get_current_dir(executable_path,\n                                        BUFFER_SIZE_ELEMENTS(executable_path)))\n                    len = 0;\n                else\n                    len = strlen(executable_path);\n                snprintf(executable_path + len,\n                         BUFFER_SIZE_ELEMENTS(executable_path) - len, \"%s%s\",\n                         len > 0 ? \"/\" : \"\", c);\n            } else\n                strncpy(executable_path, c, BUFFER_SIZE_ELEMENTS(executable_path));\n#endif\n            NULL_TERMINATE_BUFFER(executable_path);\n            /* FIXME: Fall back on /proc/self/cmdline and maybe argv[0] from\n             * _init().\n             */\n            ASSERT(strlen(executable_path) > 0 && \"readlink /proc/self/exe failed\");\n        }\n    }\n\n    /* Get basename. */\n    if (executable_basename == NULL || ignore_cache) {\n        executable_basename = strrchr(executable_path, '/');\n        executable_basename =\n            (executable_basename == NULL ? executable_path : executable_basename + 1);\n    }\n    return (full_path ? executable_path : executable_basename);\n}\n\n/* get application name, (cached), used for event logging */\nchar *\nget_application_name(void)\n{\n    return get_application_name_helper(false, true /* full path */);\n}\n\n/* i#907: Called during early injection before data section protection to avoid\n * issues with /proc/self/exe.\n */\nvoid\nset_executable_path(const char *exe_path)\n{\n    strncpy(executable_path, exe_path, BUFFER_SIZE_ELEMENTS(executable_path));\n    NULL_TERMINATE_BUFFER(executable_path);\n    /* Re-compute the basename in case the full path changed. */\n    get_application_name_helper(true /* re-compute */, false /* basename */);\n}\n\n/* Note: this is exported so that libdrpreload.so (preload.c) can use it to\n * get process names to do selective process following (PR 212034).  The\n * alternative is to duplicate or compile in this code into libdrpreload.so,\n * which is messy.  Besides, libdynamorio.so is already loaded into the process\n * and avaiable, so cleaner to just use functions from it.\n */\nDYNAMORIO_EXPORT const char *\nget_application_short_name(void)\n{\n    return get_application_name_helper(false, false /* short name */);\n}\n\n/* Sets pointers to the application's command-line arguments. These pointers are then used\n * by get_app_args().\n */\nvoid\nset_app_args(IN int *app_argc_in, IN char **app_argv_in)\n{\n    app_argc = app_argc_in;\n    app_argv = app_argv_in;\n}\n\n/* Returns the number of application's command-line arguments. */\nint\nnum_app_args()\n{\n    if (!DYNAMO_OPTION(early_inject)) {\n        set_client_error_code(NULL, DR_ERROR_NOT_IMPLEMENTED);\n        return -1;\n    }\n\n    return *app_argc;\n}\n\n/* Returns the application's command-line arguments. */\nint\nget_app_args(OUT dr_app_arg_t *args_array, int args_count)\n{\n    if (args_array == NULL || args_count < 0) {\n        set_client_error_code(NULL, DR_ERROR_INVALID_PARAMETER);\n        return -1;\n    }\n\n    if (!DYNAMO_OPTION(early_inject)) {\n        set_client_error_code(NULL, DR_ERROR_NOT_IMPLEMENTED);\n        return -1;\n    }\n\n    int num_args = num_app_args();\n    int min = (args_count < num_args) ? args_count : num_args;\n    for (int i = 0; i < min; i++) {\n        args_array[i].start = (void *)app_argv[i];\n        args_array[i].size = strlen(app_argv[i]) + 1 /* consider NULL byte */;\n        args_array[i].encoding = DR_APP_ARG_CSTR_COMPAT;\n    }\n    return min;\n}\n\n/* Processor information provided by kernel */\n#define PROC_CPUINFO \"/proc/cpuinfo\"\n#define CPUMHZ_LINE_LENGTH 64\n#define CPUMHZ_LINE_FORMAT \"cpu MHz\\t\\t: %lu.%03lu\\n\"\n/* printed in /usr/src/linux-2.4/arch/i386/kernel/setup.c calibrated in time.c */\n/* seq_printf(m, \"cpu MHz\\t\\t: %lu.%03lu\\n\", cpu_khz / 1000, (cpu_khz % 1000)) */\n/* e.g. cpu MHz           : 1594.851 */\nstatic timestamp_t\nget_timer_frequency_cpuinfo(void)\n{\n    file_t cpuinfo;\n    ssize_t nread;\n    char *buf;\n    char *mhz_line;\n    ulong cpu_mhz = 1000;\n    ulong cpu_khz = 0;\n\n    cpuinfo = os_open(PROC_CPUINFO, OS_OPEN_READ);\n\n    /* This can happen in a chroot or if /proc is disabled. */\n    if (cpuinfo == INVALID_FILE)\n        return 1000 * 1000; /* 1 GHz */\n\n    /* cpu MHz is typically in the first 4096 bytes.  If not, or we get a short\n     * or interrupted read, our timer frequency estimate will be off, but it's\n     * not the end of the world.\n     * FIXME: Factor a buffered file reader out of our maps iterator if we want\n     * to do this the right way.\n     */\n    buf = global_heap_alloc(PAGE_SIZE HEAPACCT(ACCT_OTHER));\n    nread = os_read(cpuinfo, buf, PAGE_SIZE - 1);\n    if (nread > 0) {\n        buf[nread] = '\\0';\n        mhz_line = strstr(buf, \"cpu MHz\\t\\t:\");\n        if (mhz_line != NULL &&\n            sscanf(mhz_line, CPUMHZ_LINE_FORMAT, &cpu_mhz, &cpu_khz) == 2) {\n            LOG(GLOBAL, LOG_ALL, 2, \"Processor speed exactly %lu.%03luMHz\\n\", cpu_mhz,\n                cpu_khz);\n        }\n    }\n    global_heap_free(buf, PAGE_SIZE HEAPACCT(ACCT_OTHER));\n    os_close(cpuinfo);\n\n    return cpu_mhz * 1000 + cpu_khz;\n}\n\ntimestamp_t\nget_timer_frequency()\n{\n#ifdef VMX86_SERVER\n    if (os_in_vmkernel_userworld()) {\n        return vmk_get_timer_frequency();\n    }\n#endif\n    return get_timer_frequency_cpuinfo();\n}\n\n/* DR has standardized on UTC time which counts from since Jan 1, 1601.\n * That's the Windows standard.  But Linux uses the Epoch of Jan 1, 1970.\n */\n#define UTC_TO_EPOCH_SECONDS 11644473600\n\n/* seconds since 1601 */\nuint\nquery_time_seconds(void)\n{\n    struct timeval current_time;\n    uint64 val = dynamorio_syscall(SYS_gettimeofday, 2, &current_time, NULL);\n#ifdef MACOS\n    /* MacOS before Sierra returns usecs:secs and does not set the timeval struct. */\n    if (macos_version < MACOS_VERSION_SIERRA) {\n        if ((int)val < 0)\n            return 0;\n        return (uint)val + UTC_TO_EPOCH_SECONDS;\n    }\n#endif\n    if ((int)val >= 0) {\n        return current_time.tv_sec + UTC_TO_EPOCH_SECONDS;\n    } else {\n        ASSERT_NOT_REACHED();\n        return 0;\n    }\n}\n\n/* milliseconds since 1601 */\nuint64\nquery_time_millis()\n{\n    struct timeval current_time;\n    uint64 val = dynamorio_syscall(SYS_gettimeofday, 2, &current_time, NULL);\n#ifdef MACOS\n    /* MacOS before Sierra returns usecs:secs and does not set the timeval struct. */\n    if (macos_version < MACOS_VERSION_SIERRA) {\n        if ((int)val > 0) {\n            current_time.tv_sec = (uint)val;\n            current_time.tv_usec = (uint)(val >> 32);\n        }\n    }\n#endif\n    if ((int)val >= 0) {\n        uint64 res =\n            (((uint64)current_time.tv_sec) * 1000) + (current_time.tv_usec / 1000);\n        res += UTC_TO_EPOCH_SECONDS * 1000;\n        return res;\n    } else {\n        ASSERT_NOT_REACHED();\n        return 0;\n    }\n}\n\n/* microseconds since 1601 */\nuint64\nquery_time_micros()\n{\n    struct timeval current_time;\n    uint64 val = dynamorio_syscall(SYS_gettimeofday, 2, &current_time, NULL);\n#ifdef MACOS\n    /* MacOS before Sierra returns usecs:secs and does not set the timeval struct. */\n    if (macos_version < MACOS_VERSION_SIERRA) {\n        if ((int)val > 0) {\n            current_time.tv_sec = (uint)val;\n            current_time.tv_usec = (uint)(val >> 32);\n        }\n    }\n#endif\n    if ((int)val >= 0) {\n        uint64 res = (((uint64)current_time.tv_sec) * 1000000) + current_time.tv_usec;\n        res += UTC_TO_EPOCH_SECONDS * 1000000;\n        return res;\n    } else {\n        ASSERT_NOT_REACHED();\n        return 0;\n    }\n}\n\n#ifdef RETURN_AFTER_CALL\n/* Finds the bottom of the call stack, presumably at program startup. */\n/* This routine is a copycat of internal_dump_callstack and makes\n   assumptions about program state, i.e. that frame pointers are valid\n   and should be used only in well known points for release build.\n*/\nstatic app_pc\nfind_stack_bottom()\n{\n    app_pc retaddr = 0;\n    int depth = 0;\n    reg_t *fp;\n    /* from dump_dr_callstack() */\n    asm(\"mov  %%\" ASM_XBP \", %0\" : \"=m\"(fp));\n\n    LOG(THREAD_GET, LOG_ALL, 3, \"Find stack bottom:\\n\");\n    while (fp != NULL && is_readable_without_exception((byte *)fp, sizeof(reg_t) * 2)) {\n        retaddr = (app_pc) * (fp + 1); /* presumably also readable */\n        LOG(THREAD_GET, LOG_ALL, 3,\n            \"\\tframe ptr \" PFX \" => parent \" PFX \", ret = \" PFX \"\\n\", fp, *fp, retaddr);\n        depth++;\n        /* yes I've seen weird recursive cases before */\n        if (fp == (reg_t *)*fp || depth > 100)\n            break;\n        fp = (reg_t *)*fp;\n    }\n    return retaddr;\n}\n#endif /* RETURN_AFTER_CALL */\n\n/* os-specific atexit cleanup */\nvoid\nos_slow_exit(void)\n{\n#ifdef MACOS64\n    tls_process_exit();\n#endif\n#ifdef LINUX\n    if (!standalone_library)\n        d_r_rseq_exit();\n#endif\n    d_r_signal_exit();\n    memquery_exit();\n    ksynch_exit();\n\n    generic_hash_destroy(GLOBAL_DCONTEXT, fd_table);\n    fd_table = NULL;\n\n    if (doing_detach) {\n        vsyscall_page_start = NULL;\n        IF_DEBUG(num_fd_add_pre_heap = 0;)\n    }\n\n    DELETE_LOCK(set_thread_area_lock);\n    DELETE_LOCK(client_tls_lock);\n    IF_NO_MEMQUERY(memcache_exit());\n}\n\n/* Helper function that calls cleanup_and_terminate after blocking most signals\n *(i#2921).\n */\nvoid\nblock_cleanup_and_terminate(dcontext_t *dcontext, int sysnum, ptr_uint_t sys_arg1,\n                            ptr_uint_t sys_arg2, bool exitproc,\n                            /* these 2 args are only used for Mac thread exit */\n                            ptr_uint_t sys_arg3, ptr_uint_t sys_arg4)\n{\n    /* This thread is on its way to exit. We are blocking all signals since any\n     * signal that reaches us now can be delayed until after the exit is complete.\n     * We may still receive a suspend signal for synchronization that we may need\n     * to reply to (i#2921).\n     */\n    if (sysnum == SYS_kill)\n        block_all_noncrash_signals_except(NULL, 2, dcontext->sys_param0, SUSPEND_SIGNAL);\n    else\n        block_all_noncrash_signals_except(NULL, 1, SUSPEND_SIGNAL);\n    cleanup_and_terminate(dcontext, sysnum, sys_arg1, sys_arg2, exitproc, sys_arg3,\n                          sys_arg4);\n}\n\n/* os-specific atexit cleanup */\nvoid\nos_fast_exit(void)\n{\n    /* nothing */\n}\n\nvoid\nos_terminate_with_code(dcontext_t *dcontext, terminate_flags_t flags, int exit_code)\n{\n    /* i#1319: we support a signal via 2nd byte */\n    bool use_signal = exit_code > 0x00ff;\n    /* XXX: TERMINATE_THREAD not supported */\n    ASSERT_NOT_IMPLEMENTED(TEST(TERMINATE_PROCESS, flags));\n    if (use_signal) {\n        int sig = (exit_code & 0xff00) >> 8;\n        os_terminate_via_signal(dcontext, flags, sig);\n        ASSERT_NOT_REACHED();\n    }\n    if (TEST(TERMINATE_CLEANUP, flags)) {\n        /* we enter from several different places, so rewind until top-level kstat */\n        KSTOP_REWIND_UNTIL(thread_measured);\n        block_cleanup_and_terminate(dcontext, SYSNUM_EXIT_PROCESS, exit_code, 0,\n                                    true /*whole process*/, 0, 0);\n    } else {\n        /* clean up may be impossible - just terminate */\n        d_r_config_exit(); /* delete .1config file */\n        exit_process_syscall(exit_code);\n    }\n}\n\nvoid\nos_terminate(dcontext_t *dcontext, terminate_flags_t flags)\n{\n    os_terminate_with_code(dcontext, flags, -1);\n}\n\nint\nos_timeout(int time_in_milliseconds)\n{\n    ASSERT_NOT_IMPLEMENTED(false);\n    return 0;\n}\n\n/************************************************************************\n * SEGMENT STEALING\n *\n * Not easy to make truly transparent -- but the alternative of dispatch\n * by thread id on global memory has performance implications.\n * Pull the non-STEAL_SEGMENT code out of the cvs attic for a base if\n * transparency becomes more of a problem.\n */\n\n#define TLS_LOCAL_STATE_OFFSET (offsetof(os_local_state_t, state))\n\n/* offset from top of page */\n#define TLS_OS_LOCAL_STATE 0x00\n\n#define TLS_SELF_OFFSET (TLS_OS_LOCAL_STATE + offsetof(os_local_state_t, self))\n#define TLS_THREAD_ID_OFFSET (TLS_OS_LOCAL_STATE + offsetof(os_local_state_t, tid))\n#define TLS_DCONTEXT_OFFSET (TLS_OS_LOCAL_STATE + TLS_DCONTEXT_SLOT)\n#ifdef X86\n#    define TLS_MAGIC_OFFSET (TLS_OS_LOCAL_STATE + offsetof(os_local_state_t, magic))\n#endif\n\n/* they should be used with os_tls_offset, so do not need add TLS_OS_LOCAL_STATE here\n */\n#define TLS_APP_LIB_TLS_BASE_OFFSET (offsetof(os_local_state_t, app_lib_tls_base))\n#define TLS_APP_ALT_TLS_BASE_OFFSET (offsetof(os_local_state_t, app_alt_tls_base))\n#define TLS_APP_LIB_TLS_REG_OFFSET (offsetof(os_local_state_t, app_lib_tls_reg))\n#define TLS_APP_ALT_TLS_REG_OFFSET (offsetof(os_local_state_t, app_alt_tls_reg))\n\n/* N.B.: imm and offs are ushorts!\n * We use %c[0-9] to get gcc to emit an integer constant without a leading $ for\n * the segment offset.  See the documentation here:\n * http://gcc.gnu.org/onlinedocs/gccint/Output-Template.html#Output-Template\n * Also, var needs to match the pointer size, or else we'll get stack corruption.\n * XXX: This is marked volatile prevent gcc from speculating this code before\n * checks for is_thread_tls_initialized(), but if we could find a more\n * precise constraint, then the compiler would be able to optimize better.  See\n * glibc comments on THREAD_SELF.\n */\n#ifdef DR_HOST_NOT_TARGET\n#    define WRITE_TLS_SLOT_IMM(imm, var) var = 0, ASSERT_NOT_REACHED()\n#    define READ_TLS_SLOT_IMM(imm, var) var = 0, ASSERT_NOT_REACHED()\n#    define WRITE_TLS_INT_SLOT_IMM(imm, var) var = 0, ASSERT_NOT_REACHED()\n#    define READ_TLS_INT_SLOT_IMM(imm, var) var = 0, ASSERT_NOT_REACHED()\n#    define WRITE_TLS_SLOT(offs, var) offs = var ? 0 : 1, ASSERT_NOT_REACHED()\n#    define READ_TLS_SLOT(offs, var) var = (void *)(ptr_uint_t)offs, ASSERT_NOT_REACHED()\n#elif defined(MACOS64)\n/* For now we have both a directly-addressable os_local_state_t and a pointer to\n * it in slot 6.  If we settle on always doing the full os_local_state_t in slots,\n * we would probably get rid of the indirection here and directly access slot fields.\n */\n#    define WRITE_TLS_SLOT_IMM(imm, var)                                             \\\n        IF_NOT_HAVE_TLS(ASSERT_NOT_REACHED());                                       \\\n        ASSERT(sizeof(var) == sizeof(void *));                                       \\\n        __asm__ __volatile__(                                                        \\\n            \"mov %%gs:%1, %%\" ASM_XAX \" \\n\\t\"                                        \\\n            \"movq %0, %c2(%%\" ASM_XAX \") \\n\\t\"                                       \\\n            :                                                                        \\\n            : \"r\"(var), \"m\"(*(void **)(DR_TLS_BASE_SLOT * sizeof(void *))), \"i\"(imm) \\\n            : \"memory\", ASM_XAX);\n\n#    define READ_TLS_SLOT_IMM(imm, var)                                            \\\n        IF_NOT_HAVE_TLS(ASSERT_NOT_REACHED());                                     \\\n        ASSERT(sizeof(var) == sizeof(void *));                                     \\\n        __asm__ __volatile__(\"mov %%gs:%1, %%\" ASM_XAX \" \\n\\t\"                     \\\n                             \"movq %c2(%%\" ASM_XAX \"), %0 \\n\\t\"                    \\\n                             : \"=r\"(var)                                           \\\n                             : \"m\"(*(void **)(DR_TLS_BASE_SLOT * sizeof(void *))), \\\n                               \"i\"(imm)                                            \\\n                             : ASM_XAX);\n\n#    define WRITE_TLS_SLOT(offs, var)                                              \\\n        IF_NOT_HAVE_TLS(ASSERT_NOT_REACHED());                                     \\\n        __asm__ __volatile__(\"mov %%gs:%0, %%\" ASM_XAX \" \\n\\t\"                     \\\n                             \"movzwq %1, %%\" ASM_XDX \" \\n\\t\"                       \\\n                             \"movq %2, (%%\" ASM_XAX \", %%\" ASM_XDX \") \\n\\t\"        \\\n                             :                                                     \\\n                             : \"m\"(*(void **)(DR_TLS_BASE_SLOT * sizeof(void *))), \\\n                               \"m\"(offs), \"r\"(var)                                 \\\n                             : \"memory\", ASM_XAX, ASM_XDX);\n\n#    define READ_TLS_SLOT(offs, var)                                               \\\n        IF_NOT_HAVE_TLS(ASSERT_NOT_REACHED());                                     \\\n        ASSERT(sizeof(var) == sizeof(void *));                                     \\\n        __asm__ __volatile__(\"mov %%gs:%1, %%\" ASM_XAX \" \\n\\t\"                     \\\n                             \"movzwq %2, %%\" ASM_XDX \" \\n\\t\"                       \\\n                             \"movq (%%\" ASM_XAX \", %%\" ASM_XDX \"), %0 \\n\\t\"        \\\n                             : \"=r\"(var)                                           \\\n                             : \"m\"(*(void **)(DR_TLS_BASE_SLOT * sizeof(void *))), \\\n                               \"m\"(offs)                                           \\\n                             : \"memory\", ASM_XAX, ASM_XDX);\n\n#elif defined(X86)\n#    define WRITE_TLS_SLOT_IMM(imm, var)       \\\n        IF_NOT_HAVE_TLS(ASSERT_NOT_REACHED()); \\\n        ASSERT(sizeof(var) == sizeof(void *)); \\\n        asm volatile(\"mov %0, %\" ASM_SEG \":%c1\" : : \"r\"(var), \"i\"(imm));\n\n#    define READ_TLS_SLOT_IMM(imm, var)        \\\n        IF_NOT_HAVE_TLS(ASSERT_NOT_REACHED()); \\\n        ASSERT(sizeof(var) == sizeof(void *)); \\\n        asm volatile(\"mov %\" ASM_SEG \":%c1, %0\" : \"=r\"(var) : \"i\"(imm));\n\n#    define WRITE_TLS_INT_SLOT_IMM(imm, var)   \\\n        IF_NOT_HAVE_TLS(ASSERT_NOT_REACHED()); \\\n        ASSERT(sizeof(var) == sizeof(int));    \\\n        asm volatile(\"movl %0, %\" ASM_SEG \":%c1\" : : \"r\"(var), \"i\"(imm));\n\n#    define READ_TLS_INT_SLOT_IMM(imm, var)    \\\n        IF_NOT_HAVE_TLS(ASSERT_NOT_REACHED()); \\\n        ASSERT(sizeof(var) == sizeof(int));    \\\n        asm volatile(\"movl %\" ASM_SEG \":%c1, %0\" : \"=r\"(var) : \"i\"(imm));\n\n/* FIXME: need dedicated-storage var for _TLS_SLOT macros, can't use expr */\n#    define WRITE_TLS_SLOT(offs, var)                                                   \\\n        IF_NOT_HAVE_TLS(ASSERT_NOT_REACHED());                                          \\\n        ASSERT(sizeof(var) == sizeof(void *));                                          \\\n        ASSERT(sizeof(offs) == 2);                                                      \\\n        asm(\"mov %0, %%\" ASM_XAX : : \"m\"((var)) : ASM_XAX);                             \\\n        asm(\"movzw\" IF_X64_ELSE(\"q\", \"l\") \" %0, %%\" ASM_XDX : : \"m\"((offs)) : ASM_XDX); \\\n        asm(\"mov %%\" ASM_XAX \", %\" ASM_SEG \":(%%\" ASM_XDX \")\" : : : ASM_XAX, ASM_XDX);\n\n#    define READ_TLS_SLOT(offs, var)                                                    \\\n        ASSERT(sizeof(var) == sizeof(void *));                                          \\\n        ASSERT(sizeof(offs) == 2);                                                      \\\n        asm(\"movzw\" IF_X64_ELSE(\"q\", \"l\") \" %0, %%\" ASM_XAX : : \"m\"((offs)) : ASM_XAX); \\\n        asm(\"mov %\" ASM_SEG \":(%%\" ASM_XAX \"), %%\" ASM_XAX : : : ASM_XAX);              \\\n        asm(\"mov %%\" ASM_XAX \", %0\" : \"=m\"((var)) : : ASM_XAX);\n#elif defined(AARCHXX)\n/* Android needs indirection through a global.  The Android toolchain has\n * trouble with relocations if we use a global directly in asm, so we convert to\n * a local variable in these macros.  We pay the cost of the extra instructions\n * for Linux ARM to share the code.\n */\n#    define WRITE_TLS_SLOT_IMM(imm, var)                                            \\\n        do {                                                                        \\\n            uint _base_offs = DR_TLS_BASE_OFFSET;                                   \\\n            __asm__ __volatile__(\"mov \" ASM_R2 \", %0 \\n\\t\" READ_TP_TO_R3_DISP_IN_R2 \\\n                                 \"str %1, [\" ASM_R3 \", %2] \\n\\t\"                    \\\n                                 :                                                  \\\n                                 : \"r\"(_base_offs), \"r\"(var), \"i\"(imm)              \\\n                                 : \"memory\", ASM_R2, ASM_R3);                       \\\n        } while (0)\n#    define READ_TLS_SLOT_IMM(imm, var)                                             \\\n        do {                                                                        \\\n            uint _base_offs = DR_TLS_BASE_OFFSET;                                   \\\n            __asm__ __volatile__(\"mov \" ASM_R2 \", %1 \\n\\t\" READ_TP_TO_R3_DISP_IN_R2 \\\n                                 \"ldr %0, [\" ASM_R3 \", %2] \\n\\t\"                    \\\n                                 : \"=r\"(var)                                        \\\n                                 : \"r\"(_base_offs), \"i\"(imm)                        \\\n                                 : ASM_R2, ASM_R3);                                 \\\n        } while (0)\n#    define WRITE_TLS_INT_SLOT_IMM WRITE_TLS_SLOT_IMM /* b/c 32-bit */\n#    define READ_TLS_INT_SLOT_IMM READ_TLS_SLOT_IMM   /* b/c 32-bit */\n#    define WRITE_TLS_SLOT(offs, var)                                               \\\n        do {                                                                        \\\n            uint _base_offs = DR_TLS_BASE_OFFSET;                                   \\\n            __asm__ __volatile__(\"mov \" ASM_R2 \", %0 \\n\\t\" READ_TP_TO_R3_DISP_IN_R2 \\\n                                 \"add \" ASM_R3 \", \" ASM_R3 \", %2 \\n\\t\"              \\\n                                 \"str %1, [\" ASM_R3 \"]   \\n\\t\"                      \\\n                                 :                                                  \\\n                                 : \"r\"(_base_offs), \"r\"(var), \"r\"(offs)             \\\n                                 : \"memory\", ASM_R2, ASM_R3);                       \\\n        } while (0)\n#    define READ_TLS_SLOT(offs, var)                                                \\\n        do {                                                                        \\\n            uint _base_offs = DR_TLS_BASE_OFFSET;                                   \\\n            __asm__ __volatile__(\"mov \" ASM_R2 \", %1 \\n\\t\" READ_TP_TO_R3_DISP_IN_R2 \\\n                                 \"add \" ASM_R3 \", \" ASM_R3 \", %2 \\n\\t\"              \\\n                                 \"ldr %0, [\" ASM_R3 \"]   \\n\\t\"                      \\\n                                 : \"=r\"(var)                                        \\\n                                 : \"r\"(_base_offs), \"r\"(offs)                       \\\n                                 : ASM_R2, ASM_R3);                                 \\\n        } while (0)\n#endif /* X86/ARM */\n\n#ifdef X86\n/* We use this at thread init and exit to make it easy to identify\n * whether TLS is initialized (i#2089).\n * We assume alignment does not matter.\n */\nstatic os_local_state_t uninit_tls; /* has .magic == 0 */\n#endif\n\nstatic bool\nis_thread_tls_initialized(void)\n{\n#ifdef MACOS64\n    /* For now we have both a directly-addressable os_local_state_t and a pointer to\n     * it in slot 6.  If we settle on always doing the full os_local_state_t in slots,\n     * we would probably get rid of the indirection here and directly read the magic\n     * field from its slot.\n     */\n    byte **tls_swap_slot;\n    tls_swap_slot = (byte **)get_app_tls_swap_slot_addr();\n    if (tls_swap_slot == NULL || *tls_swap_slot == NULL ||\n        *tls_swap_slot == TLS_SLOT_VAL_EXITED)\n        return false;\n    return true;\n#elif defined(X86)\n    if (INTERNAL_OPTION(safe_read_tls_init)) {\n        /* Avoid faults during early init or during exit when we have no handler.\n         * It's not worth extending the handler as the faults are a perf hit anyway.\n         * For standalone_library, first_thread_tls_initialized will always be false,\n         * so we'll return false here and use our check in get_thread_private_dcontext().\n         */\n        if (!first_thread_tls_initialized || last_thread_tls_exited)\n            return false;\n        /* i#3535: Avoid races between removing DR's SIGSEGV signal handler and\n         * detached threads being passed native signals.  The detaching thread is\n         * the one doing all the real cleanup, so we simply avoid any safe reads\n         * or TLS for detaching threads.  This var is not cleared until re-init,\n         * so we have no race with the end of detach.\n         */\n        if (detacher_tid != INVALID_THREAD_ID && detacher_tid != get_sys_thread_id())\n            return false;\n        /* To handle WSL (i#1986) where fs and gs start out equal to ss (0x2b),\n         * and when the MSR is used having a zero selector, and other complexities,\n         * we just do a blind safe read as the simplest solution once we're past\n         * initial init and have a fault handler.\n         *\n         * i#2089: to avoid the perf cost of syscalls to verify the tid, and to\n         * distinguish a fork child from a separate-group thread, we no longer read\n         * the tid field and check that the TLS belongs to this particular thread:\n         * instead we rely on clearing the .magic field for child threads and at\n         * thread exit (to avoid a fault) and we simply check the field here.\n         * A native app thread is very unlikely to match this.\n         */\n        return safe_read_tls_magic() == TLS_MAGIC_VALID;\n    } else {\n        /* XXX i#2089: we're keeping this legacy code around until\n         * we're confident that the safe read code above is safer, more\n         * performant, and more robust.\n         */\n        os_local_state_t *os_tls = NULL;\n        ptr_uint_t cur_seg = read_thread_register(SEG_TLS);\n        /* Handle WSL (i#1986) where fs and gs start out equal to ss (0x2b) */\n        if (cur_seg != 0 && cur_seg != read_thread_register(SEG_SS)) {\n            /* XXX: make this a safe read: but w/o dcontext we need special asm support */\n            READ_TLS_SLOT_IMM(TLS_SELF_OFFSET, os_tls);\n        }\n#    ifdef X64\n        if (os_tls == NULL && tls_dr_using_msr()) {\n            /* When the MSR is used, the selector in the register remains 0.\n             * We can't clear the MSR early in a new thread and then look for\n             * a zero base here b/c if kernel decides to use GDT that zeroing\n             * will set the selector, unless we want to assume we know when\n             * the kernel uses the GDT.\n             * Instead we make a syscall to get the tid.  This should be ok\n             * perf-wise b/c the common case is the non-zero above.\n             */\n            byte *base = tls_get_fs_gs_segment_base(SEG_TLS);\n            ASSERT(tls_global_type == TLS_TYPE_ARCH_PRCTL);\n            if (base != (byte *)POINTER_MAX && base != NULL) {\n                os_tls = (os_local_state_t *)base;\n            }\n        }\n#    endif\n        if (os_tls != NULL) {\n            return (os_tls->tid == get_sys_thread_id() ||\n                    /* The child of a fork will initially come here */\n                    os_tls->state.spill_space.dcontext->owning_process ==\n                        get_parent_id());\n        } else\n            return false;\n    }\n#elif defined(AARCHXX)\n    byte **dr_tls_base_addr;\n    if (tls_global_type == TLS_TYPE_NONE)\n        return false;\n    dr_tls_base_addr = (byte **)get_dr_tls_base_addr();\n    if (dr_tls_base_addr == NULL || *dr_tls_base_addr == NULL ||\n        /* We use the TLS slot's value to identify a now-exited thread (i#1578) */\n        *dr_tls_base_addr == TLS_SLOT_VAL_EXITED)\n        return false;\n    /* We would like to ASSERT is_dynamo_address(*tls_swap_slot) but that leads\n     * to infinite recursion for an address not in the vm_reserve area, as\n     * dynamo_vm_areas_start_reading() ending up calling\n     * deadlock_avoidance_unlock() which calls get_thread_private_dcontext()\n     * which comes here.\n     */\n    return true;\n#endif\n}\n\nbool\nis_DR_segment_reader_entry(app_pc pc)\n{\n    /* This routine is used to avoid problems with dr_prepopulate_cache() building\n     * bbs for DR code that reads DR segments when DR is a static library.\n     * It's a little ugly but it's not clear there's a better solution.\n     * See the discussion in i#2463 c#2.\n     */\n#ifdef X86\n    if (INTERNAL_OPTION(safe_read_tls_init)) {\n        return pc == (app_pc)safe_read_tls_magic || pc == (app_pc)safe_read_tls_self;\n    }\n#endif\n    /* XXX i#2463: for ARM and for -no_safe_read_tls_init it may be\n     * more complicated as the PC may not be a function entry but the\n     * start of a bb after a branch in our C code that uses inline asm\n     * to read the TLS.\n     */\n    return false;\n}\n\n#if defined(X86) || defined(DEBUG)\nstatic bool\nis_thread_tls_allocated(void)\n{\n#    if defined(X86) && !defined(MACOS64)\n    if (INTERNAL_OPTION(safe_read_tls_init)) {\n        /* We use this routine to allow currently-native threads, for which\n         * is_thread_tls_initialized() (and thus is_thread_initialized()) will\n         * return false.\n         * Caution: this will also return true on a fresh clone child.\n         */\n        uint magic;\n        if (!first_thread_tls_initialized || last_thread_tls_exited)\n            return false;\n        magic = safe_read_tls_magic();\n        return magic == TLS_MAGIC_VALID || magic == TLS_MAGIC_INVALID;\n    }\n#    endif\n    return is_thread_tls_initialized();\n}\n#endif\n\n/* converts a local_state_t offset to a segment offset */\nushort\nos_tls_offset(ushort tls_offs)\n{\n    /* no ushort truncation issues b/c TLS_LOCAL_STATE_OFFSET is 0 */\n    IF_NOT_HAVE_TLS(ASSERT_NOT_REACHED());\n    ASSERT(TLS_LOCAL_STATE_OFFSET == 0);\n    return (TLS_LOCAL_STATE_OFFSET + tls_offs IF_MACOS64(+tls_get_dr_offs()));\n}\n\n/* converts a segment offset to a local_state_t offset */\nushort\nos_local_state_offset(ushort seg_offs)\n{\n    /* no ushort truncation issues b/c TLS_LOCAL_STATE_OFFSET is 0 */\n    IF_NOT_HAVE_TLS(ASSERT_NOT_REACHED());\n    ASSERT(TLS_LOCAL_STATE_OFFSET == 0);\n    return (seg_offs - TLS_LOCAL_STATE_OFFSET IF_MACOS64(-tls_get_dr_offs()));\n}\n\n/* XXX: Will return NULL if called before os_thread_init(), which sets\n * ostd->dr_fs/gs_base.\n */\nvoid *\nos_get_priv_tls_base(dcontext_t *dcontext, reg_id_t reg)\n{\n    os_thread_data_t *ostd;\n\n    IF_NOT_HAVE_TLS(ASSERT_NOT_REACHED());\n    ASSERT(reg == TLS_REG_ALT || reg == TLS_REG_LIB);\n\n    if (dcontext == NULL)\n        dcontext = get_thread_private_dcontext();\n    if (dcontext == NULL)\n        return NULL;\n    ostd = (os_thread_data_t *)dcontext->os_field;\n    if (reg == TLS_REG_LIB)\n        return ostd->priv_lib_tls_base;\n    else if (reg == TLS_REG_ALT)\n        return ostd->priv_alt_tls_base;\n    ASSERT_NOT_REACHED();\n    return NULL;\n}\n\nos_local_state_t *\nget_os_tls(void)\n{\n    os_local_state_t *os_tls;\n    ASSERT(is_thread_tls_initialized());\n    READ_TLS_SLOT_IMM(TLS_SELF_OFFSET, os_tls);\n    return os_tls;\n}\n\n/* Obtain TLS from dcontext directly, which succeeds in pre-thread-init\n * situations where get_os_tls() fails.\n */\nstatic os_local_state_t *\nget_os_tls_from_dc(dcontext_t *dcontext)\n{\n    byte *local_state;\n    ASSERT(dcontext != NULL);\n    local_state = (byte *)dcontext->local_state;\n    if (local_state == NULL)\n        return NULL;\n    return (os_local_state_t *)(local_state - offsetof(os_local_state_t, state));\n}\n\n#ifdef AARCHXX\nbool\nos_set_app_tls_base(dcontext_t *dcontext, reg_id_t reg, void *base)\n{\n    os_local_state_t *os_tls;\n    IF_NOT_HAVE_TLS(ASSERT_NOT_REACHED());\n    ASSERT(reg == TLS_REG_LIB || reg == TLS_REG_ALT);\n    if (dcontext == NULL)\n        dcontext = get_thread_private_dcontext();\n    /* we will be called only if TLS is initialized */\n    ASSERT(dcontext != NULL);\n    os_tls = get_os_tls_from_dc(dcontext);\n    if (reg == TLS_REG_LIB) {\n        os_tls->app_lib_tls_base = base;\n        LOG(THREAD, LOG_THREADS, 1, \"TLS app lib base  =\" PFX \"\\n\", base);\n        return true;\n    } else if (reg == TLS_REG_ALT) {\n        os_tls->app_alt_tls_base = base;\n        LOG(THREAD, LOG_THREADS, 1, \"TLS app alt base  =\" PFX \"\\n\", base);\n        return true;\n    }\n    ASSERT_NOT_REACHED();\n    return false;\n}\n#endif\n\nvoid *\nos_get_app_tls_base(dcontext_t *dcontext, reg_id_t reg)\n{\n    os_local_state_t *os_tls;\n    IF_NOT_HAVE_TLS(ASSERT_NOT_REACHED());\n    ASSERT(reg == TLS_REG_LIB || reg == TLS_REG_ALT);\n    if (dcontext == NULL)\n        dcontext = get_thread_private_dcontext();\n    if (dcontext == NULL) {\n        /* No dcontext means we haven't initialized TLS, so we haven't replaced\n         * the app's segments.  get_segment_base is expensive, but this should\n         * be rare.  Re-examine if it pops up in a profile.\n         */\n        return get_segment_base(reg);\n    }\n    os_tls = get_os_tls_from_dc(dcontext);\n    if (reg == TLS_REG_LIB)\n        return os_tls->app_lib_tls_base;\n    else if (reg == TLS_REG_ALT)\n        return os_tls->app_alt_tls_base;\n    ASSERT_NOT_REACHED();\n    return NULL;\n}\n\nushort\nos_get_app_tls_base_offset(reg_id_t reg)\n{\n    IF_NOT_HAVE_TLS(ASSERT_NOT_REACHED());\n    ASSERT(TLS_LOCAL_STATE_OFFSET == 0);\n    if (reg == TLS_REG_LIB)\n        return TLS_APP_LIB_TLS_BASE_OFFSET;\n    else if (reg == TLS_REG_ALT)\n        return TLS_APP_ALT_TLS_BASE_OFFSET;\n    ASSERT_NOT_REACHED();\n    return 0;\n}\n\n#ifdef X86\nushort\nos_get_app_tls_reg_offset(reg_id_t reg)\n{\n    IF_NOT_HAVE_TLS(ASSERT_NOT_REACHED());\n    ASSERT(TLS_LOCAL_STATE_OFFSET == 0);\n    if (reg == TLS_REG_LIB)\n        return TLS_APP_LIB_TLS_REG_OFFSET;\n    else if (reg == TLS_REG_ALT)\n        return TLS_APP_ALT_TLS_REG_OFFSET;\n    ASSERT_NOT_REACHED();\n    return 0;\n}\n#endif\n\nvoid *\nd_r_get_tls(ushort tls_offs)\n{\n    void *val;\n    READ_TLS_SLOT(tls_offs, val);\n    return val;\n}\n\nvoid\nd_r_set_tls(ushort tls_offs, void *value)\n{\n    WRITE_TLS_SLOT(tls_offs, value);\n}\n\n/* Returns POINTER_MAX on failure.\n * Assumes that cs, ss, ds, and es are flat.\n * Should we export this to clients?  For now they can get\n * this information via opnd_compute_address().\n */\nbyte *\nget_segment_base(uint seg)\n{\n#ifdef MACOS64\n    ptr_uint_t *pthread_self = (ptr_uint_t *)read_thread_register(seg);\n    return (byte *)&pthread_self[SEG_TLS_BASE_OFFSET];\n#elif defined(X86)\n    if (seg == SEG_CS || seg == SEG_SS || seg == SEG_DS || seg == SEG_ES)\n        return NULL;\n#    ifdef HAVE_TLS\n    return tls_get_fs_gs_segment_base(seg);\n#    else\n    return (byte *)POINTER_MAX;\n#    endif /* HAVE_TLS */\n#elif defined(AARCHXX)\n    /* XXX i#1551: should we rename/refactor to avoid \"segment\"? */\n    return (byte *)read_thread_register(seg);\n#endif\n}\n\n/* i#572: handle opnd_compute_address to return the application\n * segment base value.\n */\nbyte *\nget_app_segment_base(uint seg)\n{\n#ifdef X86\n    if (seg == SEG_CS || seg == SEG_SS || seg == SEG_DS || seg == SEG_ES)\n        return NULL;\n#endif /* X86 */\n    if (INTERNAL_OPTION(private_loader) && first_thread_tls_initialized &&\n        !last_thread_tls_exited) {\n        return d_r_get_tls(os_get_app_tls_base_offset(seg));\n    }\n    return get_segment_base(seg);\n}\n\nlocal_state_extended_t *\nget_local_state_extended()\n{\n    os_local_state_t *os_tls;\n    ASSERT(is_thread_tls_initialized());\n    READ_TLS_SLOT_IMM(TLS_SELF_OFFSET, os_tls);\n    return &(os_tls->state);\n}\n\nlocal_state_t *\nget_local_state()\n{\n#ifdef HAVE_TLS\n    return (local_state_t *)get_local_state_extended();\n#else\n    return NULL;\n#endif\n}\n\n#ifdef DEBUG\nvoid\nos_enter_dynamorio(void)\n{\n#    ifdef ARM\n    /* i#1578: check that app's tls value doesn't match our sentinel */\n    ASSERT(*(byte **)get_dr_tls_base_addr() != TLS_SLOT_VAL_EXITED);\n#    endif\n}\n#endif\n\n/* i#107: handle segment register usage conflicts between app and dr:\n * os_handle_mov_seg updates the app's tls selector maintained by DR.\n * It is called before entering code cache in dispatch_enter_fcache.\n */\nvoid\nos_handle_mov_seg(dcontext_t *dcontext, byte *pc)\n{\n#ifdef X86\n    instr_t instr;\n    opnd_t opnd;\n    reg_id_t seg;\n    ushort sel = 0;\n    our_modify_ldt_t *desc;\n    int desc_idx;\n    os_local_state_t *os_tls;\n    os_thread_data_t *ostd;\n\n    instr_init(dcontext, &instr);\n    decode_cti(dcontext, pc, &instr);\n    /* the first instr must be mov seg */\n    ASSERT(instr_get_opcode(&instr) == OP_mov_seg);\n    opnd = instr_get_dst(&instr, 0);\n    ASSERT(opnd_is_reg(opnd));\n    seg = opnd_get_reg(opnd);\n    ASSERT(reg_is_segment(seg));\n\n    ostd = (os_thread_data_t *)dcontext->os_field;\n    desc = (our_modify_ldt_t *)ostd->app_thread_areas;\n    os_tls = get_os_tls();\n\n    /* get the selector value */\n    opnd = instr_get_src(&instr, 0);\n    if (opnd_is_reg(opnd)) {\n        sel = (ushort)reg_get_value_priv(opnd_get_reg(opnd), get_mcontext(dcontext));\n    } else {\n        void *ptr;\n        ptr = (ushort *)opnd_compute_address_priv(opnd, get_mcontext(dcontext));\n        ASSERT(ptr != NULL);\n        if (!d_r_safe_read(ptr, sizeof(sel), &sel)) {\n            /* FIXME: if invalid address, should deliver a signal to user. */\n            ASSERT_NOT_IMPLEMENTED(false);\n        }\n    }\n    /* calculate the entry_number */\n    desc_idx = SELECTOR_INDEX(sel) - tls_min_index();\n    if (seg == TLS_REG_LIB) {\n        os_tls->app_lib_tls_reg = sel;\n        os_tls->app_lib_tls_base = (void *)(ptr_uint_t)desc[desc_idx].base_addr;\n    } else {\n        os_tls->app_alt_tls_reg = sel;\n        os_tls->app_alt_tls_base = (void *)(ptr_uint_t)desc[desc_idx].base_addr;\n    }\n    instr_free(dcontext, &instr);\n    LOG(THREAD_GET, LOG_THREADS, 2,\n        \"thread \" TIDFMT \" segment change %s to selector 0x%x => \"\n        \"app lib tls base: \" PFX \", alt tls base: \" PFX \"\\n\",\n        d_r_get_thread_id(), reg_names[seg], sel, os_tls->app_lib_tls_base,\n        os_tls->app_alt_tls_base);\n#elif defined(ARM)\n    /* FIXME i#1551: NYI on ARM */\n    ASSERT_NOT_REACHED();\n#endif /* X86/ARM */\n}\n\n/* Initialization for TLS mangling (-mangle_app_seg on x86).\n * Must be called before DR setup its own segment.\n */\nstatic void\nos_tls_app_seg_init(os_local_state_t *os_tls, void *segment)\n{\n    app_pc app_lib_tls_base, app_alt_tls_base;\n#if defined(X86) && !defined(MACOS64)\n    int i, index;\n    our_modify_ldt_t *desc;\n\n    os_tls->app_lib_tls_reg = read_thread_register(TLS_REG_LIB);\n    os_tls->app_alt_tls_reg = read_thread_register(TLS_REG_ALT);\n#endif\n    app_lib_tls_base = get_segment_base(TLS_REG_LIB);\n    app_alt_tls_base = get_segment_base(TLS_REG_ALT);\n\n    /* If we're a non-initial thread, tls will be set to the parent's value,\n     * or to &uninit_tls (i#2089), both of which will be is_dynamo_address().\n     */\n    os_tls->app_lib_tls_base =\n        is_dynamo_address(app_lib_tls_base) ? NULL : app_lib_tls_base;\n    os_tls->app_alt_tls_base =\n        is_dynamo_address(app_alt_tls_base) ? NULL : app_alt_tls_base;\n\n#if defined(X86) && !defined(MACOS64)\n    /* get all TLS thread area value */\n    /* XXX: is get_thread_area supported in 64-bit kernel?\n     * It has syscall number 211.\n     * It works for a 32-bit application running in a 64-bit kernel.\n     * It returns error value -38 for a 64-bit app in a 64-bit kernel.\n     */\n    desc = &os_tls->os_seg_info.app_thread_areas[0];\n    tls_initialize_indices(os_tls);\n    index = tls_min_index();\n    for (i = 0; i < GDT_NUM_TLS_SLOTS; i++) {\n        tls_get_descriptor(i + index, &desc[i]);\n    }\n#endif /* X86 */\n    os_tls->os_seg_info.dr_tls_base = segment;\n    os_tls->os_seg_info.priv_alt_tls_base = IF_X86_ELSE(segment, NULL);\n\n    /* now allocate the tls segment for client libraries */\n    if (INTERNAL_OPTION(private_loader)) {\n        os_tls->os_seg_info.priv_lib_tls_base = IF_UNIT_TEST_ELSE(\n            os_tls->app_lib_tls_base, privload_tls_init(os_tls->app_lib_tls_base));\n    }\n#if defined(X86) && !defined(MACOSX64)\n    LOG(THREAD_GET, LOG_THREADS, 1,\n        \"thread \" TIDFMT \" app lib tls reg: 0x%x, alt tls reg: 0x%x\\n\",\n        d_r_get_thread_id(), os_tls->app_lib_tls_reg, os_tls->app_alt_tls_reg);\n#endif\n    LOG(THREAD_GET, LOG_THREADS, 1,\n        \"thread \" TIDFMT \" app lib tls base: \" PFX \", alt tls base: \" PFX \"\\n\",\n        d_r_get_thread_id(), os_tls->app_lib_tls_base, os_tls->app_alt_tls_base);\n    LOG(THREAD_GET, LOG_THREADS, 1,\n        \"thread \" TIDFMT \" priv lib tls base: \" PFX \", alt tls base: \" PFX \", \"\n        \"DR's tls base: \" PFX \"\\n\",\n        d_r_get_thread_id(), os_tls->os_seg_info.priv_lib_tls_base,\n        os_tls->os_seg_info.priv_alt_tls_base, os_tls->os_seg_info.dr_tls_base);\n}\n\nvoid\nos_tls_init(void)\n{\n#ifdef X86\n    ASSERT(TLS_MAGIC_OFFSET_ASM == TLS_MAGIC_OFFSET);\n    ASSERT(TLS_SELF_OFFSET_ASM == TLS_SELF_OFFSET);\n#endif\n#ifdef HAVE_TLS\n    /* We create a 1-page segment with an LDT entry for each thread and load its\n     * selector into fs/gs.\n     * FIXME PR 205276: this whole scheme currently does not check if app is using\n     * segments need to watch modify_ldt syscall\n     */\n#    ifdef MACOS64\n    /* Today we're allocating enough contiguous TLS slots to hold os_local_state_t.\n     * We also store a pointer to it in TLS slot 6.\n     */\n    byte *segment = tls_get_dr_addr();\n#    else\n    byte *segment = heap_mmap(PAGE_SIZE, MEMPROT_READ | MEMPROT_WRITE,\n                              VMM_SPECIAL_MMAP | VMM_PER_THREAD);\n#    endif\n    os_local_state_t *os_tls = (os_local_state_t *)segment;\n\n    LOG(GLOBAL, LOG_THREADS, 1, \"os_tls_init for thread \" TIDFMT \"\\n\",\n        d_r_get_thread_id());\n    ASSERT(!is_thread_tls_initialized());\n\n    /* MUST zero out dcontext slot so uninit access gets NULL */\n    memset(segment, 0, PAGE_SIZE);\n    /* store key data in the tls itself */\n    os_tls->self = os_tls;\n    os_tls->tid = get_sys_thread_id();\n    os_tls->tls_type = TLS_TYPE_NONE;\n#    ifdef X86\n    os_tls->magic = TLS_MAGIC_VALID;\n#    endif\n    /* We save DR's TLS segment base here so that os_get_dr_tls_base() will work\n     * even when -no_mangle_app_seg is set.  If -mangle_app_seg is set, this\n     * will be overwritten in os_tls_app_seg_init().\n     */\n    os_tls->os_seg_info.dr_tls_base = segment;\n    ASSERT(proc_is_cache_aligned(os_tls->self + TLS_LOCAL_STATE_OFFSET));\n    /* Verify that local_state_extended_t should indeed be used. */\n    ASSERT(DYNAMO_OPTION(ibl_table_in_tls));\n\n    /* initialize DR TLS seg base before replacing app's TLS in tls_thread_init */\n    if (MACHINE_TLS_IS_DR_TLS)\n        os_tls_app_seg_init(os_tls, segment);\n\n    tls_thread_init(os_tls, segment);\n    ASSERT(os_tls->tls_type != TLS_TYPE_NONE);\n    /* store type in global var for convenience: should be same for all threads */\n    tls_global_type = os_tls->tls_type;\n\n    /* FIXME: this should be a SYSLOG fatal error?  Should fall back on !HAVE_TLS?\n     * Should have create_ldt_entry() return failure instead of asserting, then.\n     */\n#else\n    tls_table = (tls_slot_t *)global_heap_alloc(MAX_THREADS *\n                                                sizeof(tls_slot_t) HEAPACCT(ACCT_OTHER));\n    memset(tls_table, 0, MAX_THREADS * sizeof(tls_slot_t));\n#endif\n    if (!first_thread_tls_initialized) {\n        first_thread_tls_initialized = true;\n        if (last_thread_tls_exited) /* re-attach */\n            last_thread_tls_exited = false;\n    }\n    ASSERT(is_thread_tls_initialized());\n}\n\nstatic bool\nshould_zero_tls_at_thread_exit()\n{\n#ifdef X86\n    /* i#2089: For a thread w/o CLONE_SIGHAND we cannot handle a fault, so we want to\n     * leave &uninit_tls (which was put in place in os_thread_exit()) as long as\n     * possible.  For non-detach, that means until the exit.\n     */\n    return !INTERNAL_OPTION(safe_read_tls_init) || doing_detach;\n#else\n    return true;\n#endif\n}\n\n/* TLS exit for the current thread who must own local_state. */\nvoid\nos_tls_thread_exit(local_state_t *local_state)\n{\n#ifdef HAVE_TLS\n    /* We assume (assert below) that local_state_t's start == local_state_extended_t */\n    os_local_state_t *os_tls =\n        (os_local_state_t *)(((byte *)local_state) - offsetof(os_local_state_t, state));\n    tls_type_t tls_type = os_tls->tls_type;\n    int index = os_tls->ldt_index;\n    ASSERT(offsetof(local_state_t, spill_space) ==\n           offsetof(local_state_extended_t, spill_space));\n\n    if (should_zero_tls_at_thread_exit()) {\n        tls_thread_free(tls_type, index);\n\n#    if defined(X86) && defined(X64) && !defined(MACOS)\n        if (tls_type == TLS_TYPE_ARCH_PRCTL) {\n            /* syscall re-sets gs register so re-clear it */\n            if (read_thread_register(SEG_TLS) != 0) {\n                static const ptr_uint_t zero = 0;\n                WRITE_DR_SEG(zero); /* macro needs lvalue! */\n            }\n        }\n#    endif\n    }\n\n    /* We already set TLS to &uninit_tls in os_thread_exit() */\n\n    /* Do not set last_thread_tls_exited if a client_thread is exiting.\n     * If set, get_thread_private_dcontext() returns NULL, which may cause\n     * other thread fault on using dcontext.\n     */\n    if (dynamo_exited_all_other_threads && !last_thread_tls_exited) {\n        last_thread_tls_exited = true;\n        first_thread_tls_initialized = false; /* for possible re-attach */\n    }\n#endif\n}\n\n/* Frees local_state.  If the calling thread is exiting (i.e.,\n * !other_thread) then also frees kernel resources for the calling\n * thread; if other_thread then that may not be possible.\n */\nvoid\nos_tls_exit(local_state_t *local_state, bool other_thread)\n{\n#ifdef HAVE_TLS\n#    if defined(X86) && !defined(MACOS64)\n    static const ptr_uint_t zero = 0;\n#    endif /* X86 */\n    /* We can't read from fs: as we can be called from other threads */\n#    if defined(X86) && !defined(MACOS64)\n    /* If the MSR is in use, writing to the reg faults.  We rely on it being 0\n     * to indicate that.\n     */\n    if (!other_thread && read_thread_register(SEG_TLS) != 0 &&\n        should_zero_tls_at_thread_exit()) {\n        WRITE_DR_SEG(zero); /* macro needs lvalue! */\n    }\n#    endif /* X86 */\n\n    /* For another thread we can't really make these syscalls so we have to\n     * leave it un-cleaned-up.  That's fine if the other thread is exiting:\n     * but for detach (i#95) we get the other thread to run this code.\n     */\n    if (!other_thread)\n        os_tls_thread_exit(local_state);\n\n#    ifndef MACOS64\n    /* We can't free prior to tls_thread_free() in case that routine refs os_tls */\n    /* ASSUMPTION: local_state_t is laid out at same start as local_state_extended_t */\n    os_local_state_t *os_tls =\n        (os_local_state_t *)(((byte *)local_state) - offsetof(os_local_state_t, state));\n    heap_munmap(os_tls->self, PAGE_SIZE, VMM_SPECIAL_MMAP | VMM_PER_THREAD);\n#    endif\n#else\n    global_heap_free(tls_table, MAX_THREADS * sizeof(tls_slot_t) HEAPACCT(ACCT_OTHER));\n    DELETE_LOCK(tls_lock);\n#endif\n}\n\nstatic int\nos_tls_get_gdt_index(dcontext_t *dcontext)\n{\n    os_local_state_t *os_tls = (os_local_state_t *)(((byte *)dcontext->local_state) -\n                                                    offsetof(os_local_state_t, state));\n    if (os_tls->tls_type == TLS_TYPE_GDT)\n        return os_tls->ldt_index;\n    else\n        return -1;\n}\n\nvoid\nos_tls_pre_init(int gdt_index)\n{\n#if defined(X86) && !defined(MACOS64)\n    /* Only set to above 0 for tls_type == TLS_TYPE_GDT */\n    if (gdt_index > 0) {\n        /* PR 458917: clear gdt slot to avoid leak across exec */\n        DEBUG_DECLARE(bool ok;)\n        static const ptr_uint_t zero = 0;\n        /* Be sure to clear the selector before anything that might\n         * call get_thread_private_dcontext()\n         */\n        WRITE_DR_SEG(zero); /* macro needs lvalue! */\n        DEBUG_DECLARE(ok =)\n        tls_clear_descriptor(gdt_index);\n        ASSERT(ok);\n    }\n#elif defined(ARM)\n    /* FIXME i#1551: NYI on ARM */\n    ASSERT_NOT_IMPLEMENTED(false);\n#endif /* X86/ARM */\n}\n\n/* Allocates num_slots tls slots aligned with alignment align */\nbool\nos_tls_calloc(OUT uint *offset, uint num_slots, uint alignment)\n{\n    bool res = false;\n    uint i, count = 0;\n    int start = -1;\n    uint offs = offsetof(os_local_state_t, client_tls);\n    if (num_slots == 0 || num_slots > MAX_NUM_CLIENT_TLS)\n        return false;\n    d_r_mutex_lock(&client_tls_lock);\n    for (i = 0; i < MAX_NUM_CLIENT_TLS; i++) {\n        if (!client_tls_allocated[i] &&\n            /* ALIGNED doesn't work for 0 */\n            (alignment == 0 || ALIGNED(offs + i * sizeof(void *), alignment))) {\n            if (start == -1)\n                start = i;\n            count++;\n            if (count >= num_slots)\n                break;\n        } else {\n            start = -1;\n            count = 0;\n        }\n    }\n    if (count >= num_slots) {\n        for (i = 0; i < num_slots; i++)\n            client_tls_allocated[i + start] = true;\n        *offset = offs + start * sizeof(void *);\n        res = true;\n    }\n    d_r_mutex_unlock(&client_tls_lock);\n    return res;\n}\n\nbool\nos_tls_cfree(uint offset, uint num_slots)\n{\n    uint i;\n    uint offs = (offset - offsetof(os_local_state_t, client_tls)) / sizeof(void *);\n    bool ok = true;\n    d_r_mutex_lock(&client_tls_lock);\n    for (i = 0; i < num_slots; i++) {\n        if (!client_tls_allocated[i + offs])\n            ok = false;\n        client_tls_allocated[i + offs] = false;\n    }\n    d_r_mutex_unlock(&client_tls_lock);\n    return ok;\n}\n\n/* os_data is a clone_record_t for signal_thread_inherit */\nvoid\nos_thread_init(dcontext_t *dcontext, void *os_data)\n{\n    os_local_state_t *os_tls = get_os_tls();\n    os_thread_data_t *ostd = (os_thread_data_t *)heap_alloc(\n        dcontext, sizeof(os_thread_data_t) HEAPACCT(ACCT_OTHER));\n    dcontext->os_field = (void *)ostd;\n    /* make sure stack fields, etc. are 0 now so they can be initialized on demand\n     * (don't have app esp register handy here to init now)\n     */\n    memset(ostd, 0, sizeof(*ostd));\n\n    ksynch_init_var(&ostd->suspended);\n    ksynch_init_var(&ostd->wakeup);\n    ksynch_init_var(&ostd->resumed);\n    ksynch_init_var(&ostd->terminated);\n    ksynch_init_var(&ostd->detached);\n\n#ifdef RETURN_AFTER_CALL\n    /* We only need the stack bottom for the initial thread, and due to thread\n     * init now preceding vm_areas_init(), we initialize in find_executable_vm_areas()\n     */\n    ostd->stack_bottom_pc = NULL;\n#endif\n\n    ASSIGN_INIT_LOCK_FREE(ostd->suspend_lock, suspend_lock);\n\n    signal_thread_init(dcontext, os_data);\n\n    /* i#107, initialize thread area information,\n     * the value was first get in os_tls_init and stored in os_tls\n     */\n    ostd->priv_lib_tls_base = os_tls->os_seg_info.priv_lib_tls_base;\n    ostd->priv_alt_tls_base = os_tls->os_seg_info.priv_alt_tls_base;\n    ostd->dr_tls_base = os_tls->os_seg_info.dr_tls_base;\n\n    LOG(THREAD, LOG_THREADS, 1, \"TLS app lib base  =\" PFX \"\\n\", os_tls->app_lib_tls_base);\n    LOG(THREAD, LOG_THREADS, 1, \"TLS app alt base  =\" PFX \"\\n\", os_tls->app_alt_tls_base);\n    LOG(THREAD, LOG_THREADS, 1, \"TLS priv lib base =\" PFX \"\\n\", ostd->priv_lib_tls_base);\n    LOG(THREAD, LOG_THREADS, 1, \"TLS priv alt base =\" PFX \"\\n\", ostd->priv_alt_tls_base);\n    LOG(THREAD, LOG_THREADS, 1, \"TLS DynamoRIO base=\" PFX \"\\n\", ostd->dr_tls_base);\n\n#ifdef X86\n    if (INTERNAL_OPTION(mangle_app_seg)) {\n        ostd->app_thread_areas = heap_alloc(\n            dcontext, sizeof(our_modify_ldt_t) * GDT_NUM_TLS_SLOTS HEAPACCT(ACCT_OTHER));\n        memcpy(ostd->app_thread_areas, os_tls->os_seg_info.app_thread_areas,\n               sizeof(our_modify_ldt_t) * GDT_NUM_TLS_SLOTS);\n    }\n#endif\n\n    LOG(THREAD, LOG_THREADS, 1, \"post-TLS-setup, cur %s base is \" PFX \"\\n\",\n        IF_X86_ELSE(\"gs\", \"tpidruro\"),\n        get_segment_base(IF_X86_ELSE(SEG_GS, DR_REG_TPIDRURO)));\n    LOG(THREAD, LOG_THREADS, 1, \"post-TLS-setup, cur %s base is \" PFX \"\\n\",\n        IF_X86_ELSE(\"fs\", \"tpidrurw\"),\n        get_segment_base(IF_X86_ELSE(SEG_FS, DR_REG_TPIDRURW)));\n\n#ifdef MACOS\n    /* XXX: do we need to free/close dcontext->thread_port?  I don't think so. */\n    dcontext->thread_port = dynamorio_mach_syscall(MACH_thread_self_trap, 0);\n    LOG(THREAD, LOG_ALL, 1, \"Mach thread port: %d\\n\", dcontext->thread_port);\n#endif\n}\n\n/* os_data is a clone_record_t for signal_thread_inherit */\nvoid\nos_thread_init_finalize(dcontext_t *dcontext, void *os_data)\n{\n    /* We do not want to record pending signals until at least synch_thread_init()\n     * is finished so we delay until here: but we need this inside the\n     * thread_initexit_lock (i#2779).\n     */\n    signal_thread_inherit(dcontext, os_data);\n}\n\nvoid\nos_thread_exit(dcontext_t *dcontext, bool other_thread)\n{\n    os_thread_data_t *ostd = (os_thread_data_t *)dcontext->os_field;\n\n    /* i#237/PR 498284: if we had a vfork child call execve we need to clean up\n     * the env vars.\n     */\n    if (dcontext->thread_record->execve)\n        handle_execve_post(dcontext);\n\n    DELETE_LOCK(ostd->suspend_lock);\n\n    signal_thread_exit(dcontext, other_thread);\n\n    ksynch_free_var(&ostd->suspended);\n    ksynch_free_var(&ostd->wakeup);\n    ksynch_free_var(&ostd->resumed);\n    ksynch_free_var(&ostd->terminated);\n    ksynch_free_var(&ostd->detached);\n\n#ifdef X86\n    if (ostd->clone_tls != NULL) {\n        if (!other_thread) {\n            /* Avoid faults in is_thread_tls_initialized() */\n            /* FIXME i#2088: we need to restore the app's aux seg, if any, instead. */\n            os_set_dr_tls_base(dcontext, NULL, (byte *)&uninit_tls);\n        }\n        /* We have to free in release build too b/c \"local unprotected\" is global. */\n        HEAP_TYPE_FREE(dcontext, ostd->clone_tls, os_local_state_t, ACCT_THREAD_MGT,\n                       UNPROTECTED);\n    }\n#endif\n\n    if (INTERNAL_OPTION(private_loader))\n        privload_tls_exit(IF_UNIT_TEST_ELSE(NULL, ostd->priv_lib_tls_base));\n    /* for non-debug we do fast exit path and don't free local heap */\n    DODEBUG({\n        if (MACHINE_TLS_IS_DR_TLS) {\n#ifdef X86\n            heap_free(dcontext, ostd->app_thread_areas,\n                      sizeof(our_modify_ldt_t) * GDT_NUM_TLS_SLOTS HEAPACCT(ACCT_OTHER));\n#endif\n        }\n        heap_free(dcontext, ostd, sizeof(os_thread_data_t) HEAPACCT(ACCT_OTHER));\n    });\n}\n\n/* Happens in the parent prior to fork. */\nstatic void\nos_fork_pre(dcontext_t *dcontext)\n{\n    os_thread_data_t *ostd = (os_thread_data_t *)dcontext->os_field;\n\n    /* Otherwise a thread might wait for us. */\n    ASSERT_OWN_NO_LOCKS();\n    ASSERT(ostd->fork_threads == NULL && ostd->fork_num_threads == 0);\n\n    /* i#239: Synch with all other threads to ensure that they are holding no\n     * locks across the fork.\n     * FIXME i#26: Suspend signals received before initializing siginfo are\n     * squelched, so we won't be able to suspend threads that are initializing.\n     */\n    LOG(GLOBAL, 2, LOG_SYSCALLS | LOG_THREADS,\n        \"fork: synching with other threads to prevent deadlock in child\\n\");\n    if (!synch_with_all_threads(THREAD_SYNCH_SUSPENDED_VALID_MCONTEXT_OR_NO_XFER,\n                                &ostd->fork_threads, &ostd->fork_num_threads,\n                                THREAD_SYNCH_VALID_MCONTEXT,\n                                /* If we fail to suspend a thread, there is a\n                                 * risk of deadlock in the child, so it's worth\n                                 * retrying on failure.\n                                 */\n                                THREAD_SYNCH_SUSPEND_FAILURE_RETRY)) {\n        /* If we failed to synch with all threads, we live with the possiblity\n         * of deadlock and continue as normal.\n         */\n        LOG(GLOBAL, 1, LOG_SYSCALLS | LOG_THREADS,\n            \"fork: synch failed, possible deadlock in child\\n\");\n        ASSERT_CURIOSITY(false);\n    }\n\n    vmm_heap_fork_pre(dcontext);\n\n    /* We go back to the code cache to execute the syscall, so we can't hold\n     * locks.  If the synch succeeded, no one else is running, so it should be\n     * safe to release these locks.  However, if there are any rogue threads,\n     * then releasing these locks will allow them to synch and create threads.\n     * Such threads could be running due to synch failure or presence of\n     * non-suspendable client threads.  We keep our data in ostd to prevent some\n     * conflicts, but there are some unhandled corner cases.\n     */\n    d_r_mutex_unlock(&thread_initexit_lock);\n    d_r_mutex_unlock(&all_threads_synch_lock);\n}\n\n/* Happens after the fork in both the parent and child. */\nstatic void\nos_fork_post(dcontext_t *dcontext, bool parent)\n{\n    os_thread_data_t *ostd = (os_thread_data_t *)dcontext->os_field;\n    /* Re-acquire the locks we released before the fork. */\n    d_r_mutex_lock(&all_threads_synch_lock);\n    d_r_mutex_lock(&thread_initexit_lock);\n    /* Resume the other threads that we suspended. */\n    if (parent) {\n        LOG(GLOBAL, 2, LOG_SYSCALLS | LOG_THREADS,\n            \"fork: resuming other threads after fork\\n\");\n    }\n    end_synch_with_all_threads(ostd->fork_threads, ostd->fork_num_threads,\n                               parent /*resume in parent, not in child*/);\n    ostd->fork_threads = NULL; /* Freed by end_synch_with_all_threads. */\n    ostd->fork_num_threads = 0;\n    vmm_heap_fork_post(dcontext, parent);\n}\n\n/* this one is called before child's new logfiles are set up */\nvoid\nos_fork_init(dcontext_t *dcontext)\n{\n    int iter;\n    /* We use a larger data size than file_t to avoid clobbering our stack (i#991) */\n    ptr_uint_t fd;\n    ptr_uint_t flags;\n\n    /* Static assert would save debug build overhead: could use array bound trick */\n    ASSERT(sizeof(file_t) <= sizeof(ptr_uint_t));\n\n    /* i#239: If there were unsuspended threads across the fork, we could have\n     * forked while another thread held locks.  We reset the locks and try to\n     * cope with any intermediate state left behind from the parent.  If we\n     * encounter more deadlocks after fork, we can add more lock and data resets\n     * on a case by case basis.\n     */\n    d_r_mutex_fork_reset(&all_threads_synch_lock);\n    d_r_mutex_fork_reset(&thread_initexit_lock);\n\n    os_fork_post(dcontext, false /*!parent*/);\n\n    /* re-populate cached data that contains pid */\n    pid_cached = get_process_id();\n    get_application_pid_helper(true);\n    get_application_name_helper(true, true /* not important */);\n\n    /* close all copies of parent files */\n    TABLE_RWLOCK(fd_table, write, lock);\n    iter = 0;\n    do {\n        iter = generic_hash_iterate_next(GLOBAL_DCONTEXT, fd_table, iter, &fd,\n                                         (void **)&flags);\n        if (iter < 0)\n            break;\n        if (TEST(OS_OPEN_CLOSE_ON_FORK, flags)) {\n            close_syscall((file_t)fd);\n            iter = generic_hash_iterate_remove(GLOBAL_DCONTEXT, fd_table, iter, fd);\n        }\n    } while (true);\n    TABLE_RWLOCK(fd_table, write, unlock);\n}\n\nstatic void\nos_swap_dr_tls(dcontext_t *dcontext, bool to_app)\n{\n#ifdef X86\n    /* If the option is off, we really should swap it (xref i#107/i#2088 comments\n     * in os_swap_context()) but there are few consequences of not doing it, and we\n     * have no code set up separate from the i#2089 scheme here.\n     */\n    if (!INTERNAL_OPTION(safe_read_tls_init))\n        return;\n    if (to_app) {\n        /* i#2089: we want the child to inherit a TLS with invalid .magic, but we\n         * need our own syscall execution and post-syscall code to have valid scratch\n         * and dcontext values.  We can't clear our own magic b/c we don't know when\n         * the child will be scheduled, so we use a copy of our TLS.  We carefully\n         * never have a valid magic there in case a prior child is still unscheduled.\n         *\n         * We assume the child will not modify this TLS copy in any way.\n         * CLONE_SETTLS touc * hes the other segment (we'll have to watch for\n         * addition of CLONE_SETTLS_AUX). The parent will use the scratch space\n         * returning from the syscall to d_r_dispatch, but we restore via os_clone_post()\n         * immediately before anybody calls get_thread_private_dcontext() or\n         * anything.\n         */\n        /* FIXME i#2088: to preserve the app's aux seg, if any, we should pass it\n         * and the seg reg value via the clone record (like we do for ARM today).\n         */\n        os_thread_data_t *ostd = (os_thread_data_t *)dcontext->os_field;\n        os_local_state_t *cur_tls = get_os_tls_from_dc(dcontext);\n        if (ostd->clone_tls == NULL) {\n            ostd->clone_tls = (os_local_state_t *)HEAP_TYPE_ALLOC(\n                dcontext, os_local_state_t, ACCT_THREAD_MGT, UNPROTECTED);\n            LOG(THREAD, LOG_THREADS, 2, \"TLS copy is \" PFX \"\\n\", ostd->clone_tls);\n        }\n        /* Leave no window where a prior uninit child could read valid magic by\n         * invalidating prior to copying.\n         */\n        cur_tls->magic = TLS_MAGIC_INVALID;\n        memcpy(ostd->clone_tls, cur_tls, sizeof(*ostd->clone_tls));\n        cur_tls->magic = TLS_MAGIC_VALID;\n        ostd->clone_tls->self = ostd->clone_tls;\n        os_set_dr_tls_base(dcontext, NULL, (byte *)ostd->clone_tls);\n    } else {\n        /* i#2089: restore the parent's DR TLS */\n        os_local_state_t *real_tls = get_os_tls_from_dc(dcontext);\n        /* For dr_app_start we can end up here with nothing to do, so we check. */\n        if (get_segment_base(SEG_TLS) != (byte *)real_tls) {\n            DEBUG_DECLARE(os_thread_data_t *ostd =\n                              (os_thread_data_t *)dcontext->os_field);\n            ASSERT(get_segment_base(SEG_TLS) == (byte *)ostd->clone_tls);\n            /* We assume there's no need to copy the scratch slots back */\n            os_set_dr_tls_base(dcontext, real_tls, (byte *)real_tls);\n        }\n    }\n#elif defined(AARCHXX)\n    /* For aarchxx we don't have a separate thread register for DR, and we\n     * always leave the DR pointer in the slot inside the app's or privlib's TLS.\n     * That means we have nothing to do here.\n     * For SYS_clone, we are ok with the parent's TLS being inherited until\n     * new_thread_setup() calls set_thread_register_from_clone_record().\n     */\n#endif\n}\n\nstatic void\nos_new_thread_pre(void)\n{\n    /* We use a barrier on new threads to ensure we make progress when\n     * attaching to an app that is continually making threads.\n     * XXX i#1305: if we fully suspend all threads during attach we can\n     * get rid of this barrier.\n     */\n    wait_for_event(dr_attach_finished, 0);\n    ATOMIC_INC(int, uninit_thread_count);\n}\n\n/* This is called from pre_system_call() and before cloning a client thread in\n * dr_create_client_thread. Hence os_clone_pre is used for app threads as well\n * as client threads. Do not add anything that we do not want to happen while\n * in DR mode.\n */\nstatic void\nos_clone_pre(dcontext_t *dcontext)\n{\n    /* We switch the lib tls segment back to app's segment.\n     * Please refer to comment on os_switch_lib_tls.\n     */\n    if (INTERNAL_OPTION(private_loader)) {\n        os_switch_lib_tls(dcontext, true /*to app*/);\n    }\n    os_swap_dr_tls(dcontext, true /*to app*/);\n}\n\n/* This is called from d_r_dispatch prior to post_system_call() and after\n * cloning a client thread in dr_create_client_thread. Hence os_clone_post is\n * used for app threads as well as client threads. Do not add anything that\n * we do not want to happen while in DR mode.\n */\nvoid\nos_clone_post(dcontext_t *dcontext)\n{\n    os_swap_dr_tls(dcontext, false /*to DR*/);\n}\n\nbyte *\nos_get_dr_tls_base(dcontext_t *dcontext)\n{\n    os_thread_data_t *ostd = (os_thread_data_t *)dcontext->os_field;\n    return ostd->dr_tls_base;\n}\n\n/* We only bother swapping the library segment if we're using the private\n * loader.\n */\nbool\nos_should_swap_state(void)\n{\n#ifdef X86\n    /* -private_loader currently implies -mangle_app_seg, but let's be safe. */\n    return (INTERNAL_OPTION(mangle_app_seg) && INTERNAL_OPTION(private_loader));\n#elif defined(AARCHXX)\n    return INTERNAL_OPTION(private_loader);\n#endif\n}\n\nbool\nos_using_app_state(dcontext_t *dcontext)\n{\n#ifdef X86\n    /* FIXME: This could be optimized to avoid the syscall by keeping state in\n     * the dcontext.\n     */\n    if (INTERNAL_OPTION(mangle_app_seg)) {\n        return (get_segment_base(TLS_REG_LIB) ==\n                os_get_app_tls_base(dcontext, TLS_REG_LIB));\n    }\n#endif\n    /* We're always in the app state if we're not mangling. */\n    return true;\n}\n\n/* Similar to PEB swapping on Windows, this call will switch between DR's\n * private lib segment base and the app's segment base.\n * i#107/i#2088: If the app wants to use SEG_TLS, we should also switch that back at\n * this boundary, but there are many places where we simply assume it is always\n * installed.\n */\nvoid\nos_swap_context(dcontext_t *dcontext, bool to_app, dr_state_flags_t flags)\n{\n    if (os_should_swap_state())\n        os_switch_seg_to_context(dcontext, LIB_SEG_TLS, to_app);\n    if (TEST(DR_STATE_DR_TLS, flags))\n        os_swap_dr_tls(dcontext, to_app);\n}\n\nvoid\nos_thread_under_dynamo(dcontext_t *dcontext)\n{\n    os_swap_context(dcontext, false /*to dr*/, DR_STATE_GO_NATIVE);\n    signal_swap_mask(dcontext, false /*to dr*/);\n    start_itimer(dcontext);\n}\n\nvoid\nos_thread_not_under_dynamo(dcontext_t *dcontext)\n{\n    stop_itimer(dcontext);\n    signal_swap_mask(dcontext, true /*to app*/);\n    os_swap_context(dcontext, true /*to app*/, DR_STATE_GO_NATIVE);\n}\n\nvoid\nos_process_under_dynamorio_initiate(dcontext_t *dcontext)\n{\n    LOG(GLOBAL, LOG_THREADS, 1, \"process now under DR\\n\");\n    /* We only support regular process-wide signal handlers for delayed takeover. */\n    /* i#2161: we ignore alarm signals during the attach process to avoid races. */\n    signal_reinstate_handlers(dcontext, true /*ignore alarm*/);\n    /* XXX: there's a tradeoff here: we have a race when we remove the hook\n     * because dr_app_stop() has no barrier and a thread sent native might\n     * resume from vsyscall after we remove the hook.  However, if we leave the\n     * hook, then the next takeover signal might hit a native thread that's\n     * inside DR just to go back native after having hit the hook.  For now we\n     * remove the hook and rely on translate_from_synchall_to_dispatch() moving\n     * threads from vsyscall to our gencode and not relying on the hook being\n     * present to finish up their go-native code.\n     */\n    hook_vsyscall(dcontext, false);\n}\n\nvoid\nos_process_under_dynamorio_complete(dcontext_t *dcontext)\n{\n    /* i#2161: only now do we un-ignore alarm signals. */\n    signal_reinstate_alarm_handlers(dcontext);\n    IF_NO_MEMQUERY({\n        /* Update the memory cache (i#2037) now that we've taken over all the\n         * threads, if there may have been a gap between setup and start.\n         */\n        if (dr_api_entry)\n            memcache_update_all_from_os();\n    });\n}\n\nvoid\nos_process_not_under_dynamorio(dcontext_t *dcontext)\n{\n    /* We only support regular process-wide signal handlers for mixed-mode control. */\n    signal_remove_handlers(dcontext);\n    unhook_vsyscall();\n    LOG(GLOBAL, LOG_THREADS, 1, \"process no longer under DR\\n\");\n}\n\nbool\ndetach_do_not_translate(thread_record_t *tr)\n{\n    return false;\n}\n\nvoid\ndetach_finalize_translation(thread_record_t *tr, priv_mcontext_t *mc)\n{\n    /* Nothing to do. */\n}\n\nvoid\ndetach_finalize_cleanup(void)\n{\n    /* Nothing to do. */\n}\n\nstatic pid_t\nget_process_group_id()\n{\n    return dynamorio_syscall(SYS_getpgid, 0);\n}\n\nprocess_id_t\nget_parent_id(void)\n{\n    return dynamorio_syscall(SYS_getppid, 0);\n}\n\nthread_id_t\nget_sys_thread_id(void)\n{\n#ifdef MACOS\n    if (kernel_thread_groups)\n        return dynamorio_syscall(SYS_thread_selfid, 0);\n#else\n    if (kernel_thread_groups)\n        return dynamorio_syscall(SYS_gettid, 0);\n#endif\n    return dynamorio_syscall(SYS_getpid, 0);\n}\n\nthread_id_t\nd_r_get_thread_id(void)\n{\n    /* i#228/PR 494330: making a syscall here is a perf bottleneck since we call\n     * this routine in read and recursive locks so use the TLS value instead\n     */\n    thread_id_t id = get_tls_thread_id();\n    if (id != INVALID_THREAD_ID)\n        return id;\n    else\n        return get_sys_thread_id();\n}\n\nthread_id_t\nget_tls_thread_id(void)\n{\n    ptr_int_t tid; /* can't use thread_id_t since it's 32-bits */\n    if (!is_thread_tls_initialized())\n        return INVALID_THREAD_ID;\n    READ_TLS_SLOT_IMM(TLS_THREAD_ID_OFFSET, tid);\n    /* it reads 8-bytes into the memory, which includes app_gs and app_fs.\n     * 0x000000007127357b <get_tls_thread_id+37>:      mov    %gs:(%rax),%rax\n     * 0x000000007127357f <get_tls_thread_id+41>:      mov    %rax,-0x8(%rbp)\n     * so we remove the TRUNCATE check and trucate it on return.\n     */\n    return (thread_id_t)tid;\n}\n\n/* returns the thread-private dcontext pointer for the calling thread */\ndcontext_t *\nget_thread_private_dcontext(void)\n{\n#ifdef HAVE_TLS\n    dcontext_t *dcontext;\n    /* We have to check this b/c this is called from __errno_location prior\n     * to os_tls_init, as well as after os_tls_exit, and early in a new\n     * thread's initialization (see comments below on that).\n     */\n    if (!is_thread_tls_initialized())\n        return standalone_library ? GLOBAL_DCONTEXT : NULL;\n    /* We used to check tid and return NULL to distinguish parent from child, but\n     * that was affecting performance (xref PR 207366: but I'm leaving the assert in\n     * for now so debug build will still incur it).  So we fixed the cases that\n     * needed that:\n     *\n     * - dynamo_thread_init() calling is_thread_initialized() for a new thread\n     *   created via clone or the start/stop interface: so we have\n     *   is_thread_initialized() pay the d_r_get_thread_id() cost.\n     * - new_thread_setup()'s ENTER_DR_HOOK kstats, or a crash and the signal\n     *   handler asking about dcontext: we have new_thread_dynamo_start()\n     *   clear the segment register for us early on.\n     * - child of fork (ASSERT_OWN_NO_LOCKS, etc. on re-entering DR):\n     *   here we just suppress the assert: we'll use this same dcontext.\n     *   xref PR 209518 where w/o this fix we used to need an extra KSTOP.\n     *\n     * An alternative would be to have the parent thread clear the segment\n     * register, or even set up the child's TLS ahead of time ourselves\n     * (and special-case so that we know if at clone syscall the app state is not\n     * quite correct: but we're already stealing a register there: PR 286194).\n     * We could also have the kernel set up TLS for us (PR 285898).\n     *\n     * For hotp_only or non-full-control (native_exec, e.g.) (PR 212012), this\n     * routine is not the only issue: we have to catch all new threads since\n     * hotp_only gateways assume tls is set up.\n     * Xref PR 192231.\n     */\n    /* PR 307698: this assert causes large slowdowns (also xref PR 207366) */\n    DOCHECK(CHKLVL_DEFAULT + 1, {\n        ASSERT(get_tls_thread_id() == get_sys_thread_id() ||\n               /* ok for fork as mentioned above */\n               pid_cached != get_process_id());\n    });\n    READ_TLS_SLOT_IMM(TLS_DCONTEXT_OFFSET, dcontext);\n    return dcontext;\n#else\n    /* Assumption: no lock needed on a read => no race conditions between\n     * reading and writing same tid!  Since both get and set are only for\n     * the current thread, they cannot both execute simultaneously for the\n     * same tid, right?\n     */\n    thread_id_t tid = d_r_get_thread_id();\n    int i;\n    if (tls_table != NULL) {\n        for (i = 0; i < MAX_THREADS; i++) {\n            if (tls_table[i].tid == tid) {\n                return tls_table[i].dcontext;\n            }\n        }\n    }\n    return NULL;\n#endif\n}\n\n/* sets the thread-private dcontext pointer for the calling thread */\nvoid\nset_thread_private_dcontext(dcontext_t *dcontext)\n{\n#ifdef HAVE_TLS\n    ASSERT(is_thread_tls_allocated());\n    WRITE_TLS_SLOT_IMM(TLS_DCONTEXT_OFFSET, dcontext);\n#else\n    thread_id_t tid = d_r_get_thread_id();\n    int i;\n    bool found = false;\n    ASSERT(tls_table != NULL);\n    d_r_mutex_lock(&tls_lock);\n    for (i = 0; i < MAX_THREADS; i++) {\n        if (tls_table[i].tid == tid) {\n            if (dcontext == NULL) {\n                /* if setting to NULL, clear the entire slot for reuse */\n                tls_table[i].tid = 0;\n            }\n            tls_table[i].dcontext = dcontext;\n            found = true;\n            break;\n        }\n    }\n    if (!found) {\n        if (dcontext == NULL) {\n            /* don't do anything...but why would this happen? */\n        } else {\n            /* look for an empty slot */\n            for (i = 0; i < MAX_THREADS; i++) {\n                if (tls_table[i].tid == 0) {\n                    tls_table[i].tid = tid;\n                    tls_table[i].dcontext = dcontext;\n                    found = true;\n                    break;\n                }\n            }\n        }\n    }\n    d_r_mutex_unlock(&tls_lock);\n    ASSERT(found);\n#endif\n}\n\n/* replaces old with new\n * use for forking: child should replace parent's id with its own\n */\nstatic void\nreplace_thread_id(thread_id_t old, thread_id_t new)\n{\n#ifdef HAVE_TLS\n    thread_id_t new_tid = new;\n    ASSERT(is_thread_tls_initialized());\n    DOCHECK(1, {\n        thread_id_t old_tid;\n        IF_LINUX_ELSE(READ_TLS_INT_SLOT_IMM(TLS_THREAD_ID_OFFSET, old_tid),\n                      READ_TLS_SLOT_IMM(TLS_THREAD_ID_OFFSET, old_tid));\n        ASSERT(old_tid == old);\n    });\n    IF_LINUX_ELSE(WRITE_TLS_INT_SLOT_IMM(TLS_THREAD_ID_OFFSET, new_tid),\n                  WRITE_TLS_SLOT_IMM(TLS_THREAD_ID_OFFSET, new_tid));\n#else\n    int i;\n    d_r_mutex_lock(&tls_lock);\n    for (i = 0; i < MAX_THREADS; i++) {\n        if (tls_table[i].tid == old) {\n            tls_table[i].tid = new;\n            break;\n        }\n    }\n    d_r_mutex_unlock(&tls_lock);\n#endif\n}\n\n/* translate native flags to platform independent protection bits */\nstatic inline uint\nosprot_to_memprot(uint prot)\n{\n    uint mem_prot = 0;\n    if (TEST(PROT_EXEC, prot))\n        mem_prot |= MEMPROT_EXEC;\n    if (TEST(PROT_READ, prot))\n        mem_prot |= MEMPROT_READ;\n    if (TEST(PROT_WRITE, prot))\n        mem_prot |= MEMPROT_WRITE;\n    return mem_prot;\n}\n\n/* returns osprot flags preserving all native protection flags except\n * for RWX, which are replaced according to memprot */\nuint\nosprot_replace_memprot(uint old_osprot, uint memprot)\n{\n    /* Note only protection flags PROT_ are relevant to mprotect()\n     * and they are separate from any other MAP_ flags passed to mmap()\n     */\n    uint new_osprot = memprot_to_osprot(memprot);\n    return new_osprot;\n}\n\n/* libc independence */\nstatic inline long\nmprotect_syscall(byte *p, size_t size, uint prot)\n{\n    return dynamorio_syscall(SYS_mprotect, 3, p, size, prot);\n}\n\n/* free memory allocated from os_raw_mem_alloc */\nbool\nos_raw_mem_free(void *p, size_t size, uint flags, heap_error_code_t *error_code)\n{\n    long rc;\n    ASSERT(error_code != NULL);\n    ASSERT(size > 0 && ALIGNED(size, PAGE_SIZE));\n\n    rc = munmap_syscall(p, size);\n    if (rc != 0) {\n        *error_code = -rc;\n    } else {\n        *error_code = HEAP_ERROR_SUCCESS;\n    }\n    return (rc == 0);\n}\n\n/* try to alloc memory at preferred from os directly,\n * caller is required to handle thread synchronization and to update\n */\nvoid *\nos_raw_mem_alloc(void *preferred, size_t size, uint prot, uint flags,\n                 heap_error_code_t *error_code)\n{\n    byte *p;\n    uint os_prot = memprot_to_osprot(prot);\n    uint os_flags =\n        MAP_PRIVATE | MAP_ANONYMOUS | (TEST(RAW_ALLOC_32BIT, flags) ? MAP_32BIT : 0);\n\n    ASSERT(error_code != NULL);\n    /* should only be used on aligned pieces */\n    ASSERT(size > 0 && ALIGNED(size, PAGE_SIZE));\n\n    p = mmap_syscall(preferred, size, os_prot, os_flags, -1, 0);\n    if (!mmap_syscall_succeeded(p)) {\n        *error_code = -(heap_error_code_t)(ptr_int_t)p;\n        LOG(GLOBAL, LOG_HEAP, 3, \"os_raw_mem_alloc %d bytes failed\" PFX \"\\n\", size, p);\n        return NULL;\n    }\n    if (preferred != NULL && p != preferred) {\n        *error_code = HEAP_ERROR_NOT_AT_PREFERRED;\n        os_raw_mem_free(p, size, flags, error_code);\n        LOG(GLOBAL, LOG_HEAP, 3, \"os_raw_mem_alloc %d bytes failed\" PFX \"\\n\", size, p);\n        return NULL;\n    }\n    LOG(GLOBAL, LOG_HEAP, 2, \"os_raw_mem_alloc: \" SZFMT \" bytes @ \" PFX \"\\n\", size, p);\n    return p;\n}\n\n#ifdef LINUX\nvoid\ninit_emulated_brk(app_pc exe_end)\n{\n    ASSERT(DYNAMO_OPTION(emulate_brk));\n    if (app_brk_map != NULL) {\n        return;\n    }\n    /* i#1004: emulate brk via a separate mmap.  The real brk starts out empty, but\n     * we need at least a page to have an mmap placeholder.  We also want to reserve\n     * enough memory to avoid a client lib or other mmap truncating the brk at a\n     * too-small size, which can crash the app (i#3982).\n     */\n#    define BRK_INITIAL_SIZE 4 * 1024 * 1024\n    app_brk_map = mmap_syscall(exe_end, BRK_INITIAL_SIZE, PROT_READ | PROT_WRITE,\n                               MAP_ANONYMOUS | MAP_PRIVATE, -1, 0);\n    ASSERT(mmap_syscall_succeeded(app_brk_map));\n    app_brk_cur = app_brk_map;\n    app_brk_end = app_brk_map + BRK_INITIAL_SIZE;\n    LOG(GLOBAL, LOG_HEAP, 1, \"%s: initial brk is \" PFX \"-\" PFX \"\\n\", __FUNCTION__,\n        app_brk_cur, app_brk_end);\n}\n\nstatic byte *\nemulate_app_brk(dcontext_t *dcontext, byte *new_val)\n{\n    byte *old_brk = app_brk_cur;\n    ASSERT(DYNAMO_OPTION(emulate_brk));\n    LOG(THREAD, LOG_HEAP, 2, \"%s: cur=\" PFX \", requested=\" PFX \"\\n\", __FUNCTION__,\n        app_brk_cur, new_val);\n    new_val = (byte *)ALIGN_FORWARD(new_val, PAGE_SIZE);\n    if (new_val == NULL || new_val == app_brk_cur ||\n        /* Not allowed to shrink below original base */\n        new_val < app_brk_map) {\n        /* Just return cur val */\n    } else if (new_val < app_brk_cur) {\n        /* Shrink */\n        if (munmap_syscall(new_val, app_brk_cur - new_val) == 0) {\n            app_brk_cur = new_val;\n            app_brk_end = new_val;\n        }\n    } else if (new_val < app_brk_end) {\n        /* We've already allocated the space */\n        app_brk_cur = new_val;\n    } else {\n        /* Expand */\n        byte *remap = (byte *)dynamorio_syscall(SYS_mremap, 4, app_brk_map,\n                                                app_brk_end - app_brk_map,\n                                                new_val - app_brk_map, 0 /*do not move*/);\n        if (mmap_syscall_succeeded(remap)) {\n            ASSERT(remap == app_brk_map);\n            app_brk_cur = new_val;\n            app_brk_end = new_val;\n        } else {\n            LOG(THREAD, LOG_HEAP, 1, \"%s: mremap to \" PFX \" failed\\n\", __FUNCTION__,\n                new_val);\n        }\n    }\n    if (app_brk_cur != old_brk)\n        handle_app_brk(dcontext, app_brk_map, old_brk, app_brk_cur);\n    return app_brk_cur;\n}\n#endif /* LINUX */\n\n#ifdef LINUX\nDR_API\n/* XXX: could add dr_raw_mem_realloc() instead of dr_raw_mremap() -- though there\n * is no realloc for Windows: supposed to reserve yourself and then commit in\n * pieces.\n */\nvoid *\ndr_raw_mremap(void *old_address, size_t old_size, size_t new_size, int flags,\n              void *new_address)\n{\n    byte *res;\n    dr_mem_info_t info;\n    dcontext_t *dcontext = get_thread_private_dcontext();\n    /* i#173: we need prot + type from prior to mremap */\n    DEBUG_DECLARE(bool ok =)\n    query_memory_ex(old_address, &info);\n    /* XXX: this could be a large region w/ multiple protection regions\n     * inside.  For now we assume our handling of it doesn't care.\n     */\n    ASSERT(ok);\n    if (is_pretend_or_executable_writable(old_address))\n        info.prot |= DR_MEMPROT_WRITE;\n    /* we just unconditionally send the 5th param */\n    res = (byte *)dynamorio_syscall(SYS_mremap, 5, old_address, old_size, new_size, flags,\n                                    new_address);\n    handle_app_mremap(dcontext, res, new_size, old_address, old_size, info.prot,\n                      info.size);\n    return res;\n}\n\nDR_API\nvoid *\ndr_raw_brk(void *new_address)\n{\n    dcontext_t *dcontext = get_thread_private_dcontext();\n    if (DYNAMO_OPTION(emulate_brk)) {\n        /* i#1004: emulate brk via a separate mmap */\n        return (void *)emulate_app_brk(dcontext, (byte *)new_address);\n    } else {\n        /* We pay the cost of 2 syscalls.  This should be infrequent enough that\n         * it doesn't mater.\n         */\n        if (new_address == NULL) {\n            /* Just a query */\n            return (void *)dynamorio_syscall(SYS_brk, 1, new_address);\n        } else {\n            byte *old_brk = (byte *)dynamorio_syscall(SYS_brk, 1, 0);\n            byte *res = (byte *)dynamorio_syscall(SYS_brk, 1, new_address);\n            handle_app_brk(dcontext, NULL, old_brk, res);\n            return res;\n        }\n    }\n}\n#endif /* LINUX */\n\n/* caller is required to handle thread synchronization and to update dynamo vm areas */\nvoid\nos_heap_free(void *p, size_t size, heap_error_code_t *error_code)\n{\n    long rc;\n    ASSERT(error_code != NULL);\n    if (!dynamo_exited)\n        LOG(GLOBAL, LOG_HEAP, 4, \"os_heap_free: %d bytes @ \" PFX \"\\n\", size, p);\n    rc = munmap_syscall(p, size);\n    if (rc != 0) {\n        *error_code = -rc;\n    } else {\n        *error_code = HEAP_ERROR_SUCCESS;\n    }\n    ASSERT(rc == 0);\n}\n\n/* reserve virtual address space without committing swap space for it,\n   and of course no physical pages since it will never be touched */\n/* to be transparent, we do not use sbrk, and are\n * instead using mmap, and asserting that all os_heap requests are for\n * reasonably large pieces of memory */\nvoid *\nos_heap_reserve(void *preferred, size_t size, heap_error_code_t *error_code,\n                bool executable)\n{\n    void *p;\n    uint prot = PROT_NONE;\n#ifdef VMX86_SERVER\n    /* PR 365331: we need to be in the mmap_text region for code cache and\n     * gencode (PROT_EXEC).\n     */\n    ASSERT(!os_in_vmkernel_userworld() || !executable || preferred == NULL ||\n           ((byte *)preferred >= os_vmk_mmap_text_start() &&\n            ((byte *)preferred) + size <= os_vmk_mmap_text_end()));\n    /* Note that a preferred address overrides PROT_EXEC and a mmap_data\n     * address will be honored, even though any execution there will fault.\n     */\n    /* FIXME: note that PROT_EXEC => read access, so our guard pages and other\n     * non-committed memory, while not writable, is readable.\n     * Plus, we can't later clear all prot bits for userworld mmap due to PR 107872\n     * (PR 365748 covers fixing this for us).\n     * But in most uses we should get our preferred vmheap and shouldn't run\n     * out of vmheap, so this should be a corner-case issue.\n     */\n    if (executable)\n        prot = PROT_EXEC;\n#endif\n    /* should only be used on aligned pieces */\n    ASSERT(size > 0 && ALIGNED(size, PAGE_SIZE));\n    ASSERT(error_code != NULL);\n\n    /* FIXME: note that this memory is in fact still committed - see man mmap */\n    /* FIXME: case 2347 on Linux or -vm_reserve should be set to false */\n    /* FIXME: Need to actually get a mmap-ing with |MAP_NORESERVE */\n    p = mmap_syscall(\n        preferred, size, prot,\n        MAP_PRIVATE |\n            MAP_ANONYMOUS IF_X64(| (DYNAMO_OPTION(heap_in_lower_4GB) ? MAP_32BIT : 0)),\n        -1, 0);\n    if (!mmap_syscall_succeeded(p)) {\n        *error_code = -(heap_error_code_t)(ptr_int_t)p;\n        LOG(GLOBAL, LOG_HEAP, 4, \"os_heap_reserve %d bytes failed \" PFX \"\\n\", size, p);\n        return NULL;\n    } else if (preferred != NULL && p != preferred) {\n        /* We didn't get the preferred address.  To harmonize with windows behavior and\n         * give greater control we fail the reservation. */\n        heap_error_code_t dummy;\n        *error_code = HEAP_ERROR_NOT_AT_PREFERRED;\n        os_heap_free(p, size, &dummy);\n        ASSERT(dummy == HEAP_ERROR_SUCCESS);\n        LOG(GLOBAL, LOG_HEAP, 4,\n            \"os_heap_reserve %d bytes at \" PFX \" not preferred \" PFX \"\\n\", size,\n            preferred, p);\n        return NULL;\n    } else {\n        *error_code = HEAP_ERROR_SUCCESS;\n    }\n    LOG(GLOBAL, LOG_HEAP, 2, \"os_heap_reserve: %d bytes @ \" PFX \"\\n\", size, p);\n#ifdef VMX86_SERVER\n    /* PR 365331: ensure our memory is all in the mmap_text region */\n    ASSERT(!os_in_vmkernel_userworld() || !executable ||\n           ((byte *)p >= os_vmk_mmap_text_start() &&\n            ((byte *)p) + size <= os_vmk_mmap_text_end()));\n#endif\n#if defined(ANDROID) && defined(DEBUG)\n    /* We don't label in release to be more transparent */\n    dynamorio_syscall(SYS_prctl, 5, PR_SET_VMA, PR_SET_VMA_ANON_NAME, p, size,\n                      \"DynamoRIO-internal\");\n#endif\n    return p;\n}\n\nstatic bool\nfind_free_memory_in_region(byte *start, byte *end, size_t size, byte **found_start OUT,\n                           byte **found_end OUT)\n{\n    memquery_iter_t iter;\n    /* XXX: despite /proc/sys/vm/mmap_min_addr == PAGE_SIZE, mmap won't\n     * give me that address if I use it as a hint.\n     */\n    app_pc last_end = (app_pc)(PAGE_SIZE * 16);\n    bool found = false;\n    memquery_iterator_start(&iter, NULL, false /*won't alloc*/);\n    while (memquery_iterator_next(&iter)) {\n        if (iter.vm_start >= start &&\n            MIN(iter.vm_start, end) - MAX(last_end, start) >= size) {\n            if (found_start != NULL)\n                *found_start = MAX(last_end, start);\n            if (found_end != NULL)\n                *found_end = MIN(iter.vm_start, end);\n            found = true;\n            break;\n        }\n        if (iter.vm_end >= end)\n            break;\n        last_end = iter.vm_end;\n    }\n    memquery_iterator_stop(&iter);\n    return found;\n}\n\nvoid *\nos_heap_reserve_in_region(void *start, void *end, size_t size,\n                          heap_error_code_t *error_code, bool executable)\n{\n    byte *p = NULL;\n    byte *try_start = NULL, *try_end = NULL;\n    uint iters = 0;\n\n    ASSERT(ALIGNED(start, PAGE_SIZE) && ALIGNED(end, PAGE_SIZE));\n    ASSERT(ALIGNED(size, PAGE_SIZE));\n\n    LOG(GLOBAL, LOG_HEAP, 3,\n        \"os_heap_reserve_in_region: \" SZFMT \" bytes in \" PFX \"-\" PFX \"\\n\", size, start,\n        end);\n\n    /* if no restriction on location use regular os_heap_reserve() */\n    if (start == (void *)PTR_UINT_0 && end == (void *)POINTER_MAX)\n        return os_heap_reserve(NULL, size, error_code, executable);\n\n        /* loop to handle races */\n#define RESERVE_IN_REGION_MAX_ITERS 128\n    while (find_free_memory_in_region(start, end, size, &try_start, &try_end)) {\n        /* If there's space we'd prefer the end, to avoid the common case of\n         * a large binary + heap at attach where we're likely to reserve\n         * right at the start of the brk: we'd prefer to leave more brk space.\n         */\n        p = os_heap_reserve(try_end - size, size, error_code, executable);\n        if (p != NULL) {\n            ASSERT(*error_code == HEAP_ERROR_SUCCESS);\n            ASSERT(p >= (byte *)start && p + size <= (byte *)end);\n            break;\n        }\n        if (++iters > RESERVE_IN_REGION_MAX_ITERS) {\n            ASSERT_NOT_REACHED();\n            break;\n        }\n    }\n    if (p == NULL)\n        *error_code = HEAP_ERROR_CANT_RESERVE_IN_REGION;\n    else\n        *error_code = HEAP_ERROR_SUCCESS;\n\n    LOG(GLOBAL, LOG_HEAP, 2,\n        \"os_heap_reserve_in_region: reserved \" SZFMT \" bytes @ \" PFX \" in \" PFX \"-\" PFX\n        \"\\n\",\n        size, p, start, end);\n    return p;\n}\n\n/* commit previously reserved with os_heap_reserve pages */\n/* returns false when out of memory */\n/* A replacement of os_heap_alloc can be constructed by using os_heap_reserve\n   and os_heap_commit on a subset of the reserved pages. */\n/* caller is required to handle thread synchronization */\nbool\nos_heap_commit(void *p, size_t size, uint prot, heap_error_code_t *error_code)\n{\n    uint os_prot = memprot_to_osprot(prot);\n    long res;\n    /* should only be used on aligned pieces */\n    ASSERT(size > 0 && ALIGNED(size, PAGE_SIZE));\n    ASSERT(p);\n    ASSERT(error_code != NULL);\n\n    /* FIXME: note that the memory would not be not truly committed if we have */\n    /* not actually marked a mmap-ing without MAP_NORESERVE */\n    res = mprotect_syscall(p, size, os_prot);\n    if (res != 0) {\n        *error_code = -res;\n        return false;\n    } else {\n        *error_code = HEAP_ERROR_SUCCESS;\n    }\n\n    LOG(GLOBAL, LOG_HEAP, 2, \"os_heap_commit: %d bytes @ \" PFX \"\\n\", size, p);\n    return true;\n}\n\n/* caller is required to handle thread synchronization and to update dynamo vm areas */\nvoid\nos_heap_decommit(void *p, size_t size, heap_error_code_t *error_code)\n{\n    int rc;\n    ASSERT(error_code != NULL);\n\n    if (!dynamo_exited)\n        LOG(GLOBAL, LOG_HEAP, 4, \"os_heap_decommit: %d bytes @ \" PFX \"\\n\", size, p);\n\n    *error_code = HEAP_ERROR_SUCCESS;\n    /* FIXME: for now do nothing since os_heap_reserve has in fact committed the memory */\n    rc = 0;\n    /* TODO:\n           p = mmap_syscall(p, size, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0);\n       we should either do a mremap()\n       or we can do a munmap() followed 'quickly' by a mmap() -\n       also see above the comment that os_heap_reserve() in fact is not so lightweight\n    */\n    ASSERT(rc == 0);\n}\n\nbool\nos_heap_systemwide_overcommit(heap_error_code_t last_error_code)\n{\n    /* FIXME: conservative answer yes */\n    return true;\n}\n\nbool\nos_heap_get_commit_limit(size_t *commit_used, size_t *commit_limit)\n{\n    /* FIXME - NYI */\n    return false;\n}\n\n/* yield the current thread */\nvoid\nos_thread_yield()\n{\n#ifdef MACOS\n    /* XXX i#1291: use raw syscall instead */\n    swtch_pri(0);\n#else\n    dynamorio_syscall(SYS_sched_yield, 0);\n#endif\n}\n\nbool\nthread_signal(process_id_t pid, thread_id_t tid, int signum)\n{\n#ifdef MACOS\n    /* FIXME i#58: this takes in a thread port.  Need to map thread id to port.\n     * Need to figure out whether we support raw Mach threads w/o pthread on top.\n     */\n    ASSERT_NOT_IMPLEMENTED(false);\n    return false;\n#else\n    /* FIXME: for non-NPTL use SYS_kill */\n    /* Note that the pid is equivalent to the thread group id.\n     * However, we can have threads sharing address space but not pid\n     * (if created via CLONE_VM but not CLONE_THREAD), so make sure to\n     * use the pid of the target thread, not our pid.\n     */\n    return (dynamorio_syscall(SYS_tgkill, 3, pid, tid, signum) == 0);\n#endif\n}\n\nstatic bool\nknown_thread_signal(thread_record_t *tr, int signum)\n{\n#ifdef MACOS\n    ptr_int_t res;\n    if (tr->dcontext == NULL)\n        return FALSE;\n    res = dynamorio_syscall(SYS___pthread_kill, 2, tr->dcontext->thread_port, signum);\n    LOG(THREAD_GET, LOG_ALL, 3, \"%s: signal %d to port %d => %ld\\n\", __FUNCTION__, signum,\n        tr->dcontext->thread_port, res);\n    return res == 0;\n#else\n    return thread_signal(tr->pid, tr->id, signum);\n#endif\n}\n\nvoid\nos_thread_sleep(uint64 milliseconds)\n{\n#ifdef MACOS\n    semaphore_t sem = MACH_PORT_NULL;\n    int res;\n#else\n    struct timespec remain;\n    int count = 0;\n#endif\n    struct timespec req;\n    req.tv_sec = (milliseconds / 1000);\n    /* docs say can go up to 1000000000, but doesn't work on FC9 */\n    req.tv_nsec = (milliseconds % 1000) * 1000000;\n#ifdef MACOS\n    if (sem == MACH_PORT_NULL) {\n        DEBUG_DECLARE(kern_return_t res =)\n        semaphore_create(mach_task_self(), &sem, SYNC_POLICY_FIFO, 0);\n        ASSERT(res == KERN_SUCCESS);\n    }\n    res =\n        dynamorio_syscall(SYSNUM_NO_CANCEL(SYS___semwait_signal), 6, sem, MACH_PORT_NULL,\n                          1, 1, (int64_t)req.tv_sec, (int32_t)req.tv_nsec);\n    if (res == -EINTR) {\n        /* FIXME i#58: figure out how much time elapsed and re-wait */\n    }\n#else\n    /* FIXME: if we need accurate sleeps in presence of itimers we should\n     * be using SYS_clock_nanosleep w/ an absolute time instead of relative\n     */\n    while (dynamorio_syscall(SYS_nanosleep, 2, &req, &remain) == -EINTR) {\n        /* interrupted by signal or something: finish the interval */\n        ASSERT_CURIOSITY_ONCE(remain.tv_sec <= req.tv_sec &&\n                              (remain.tv_sec < req.tv_sec ||\n                               /* there seems to be some rounding, and sometimes\n                                * remain nsec > req nsec (I've seen 40K diff)\n                                */\n                               req.tv_nsec - remain.tv_nsec < 100000 ||\n                               req.tv_nsec - remain.tv_nsec > -100000));\n        /* not unusual for client threads to use itimers and have their run\n         * routine sleep forever\n         */\n        if (count++ > 3 && !IS_CLIENT_THREAD(get_thread_private_dcontext())) {\n            ASSERT_NOT_REACHED();\n            break; /* paranoid */\n        }\n        req = remain;\n    }\n#endif\n}\n\nbool\nos_thread_suspend(thread_record_t *tr)\n{\n    os_thread_data_t *ostd = (os_thread_data_t *)tr->dcontext->os_field;\n    ASSERT(ostd != NULL);\n    /* See synch comments in os_thread_resume: the mutex held there\n     * prevents prematurely sending a re-suspend signal.\n     */\n    d_r_mutex_lock(&ostd->suspend_lock);\n    ostd->suspend_count++;\n    ASSERT(ostd->suspend_count > 0);\n    /* If already suspended, do not send another signal.  However, we do\n     * need to ensure the target is suspended in case of a race, so we can't\n     * just return.\n     */\n    if (ostd->suspend_count == 1) {\n        /* PR 212090: we use a custom signal handler to suspend.  We wait\n         * here until the target reaches the suspend point, and leave it\n         * up to the caller to check whether it is a safe suspend point,\n         * to match Windows behavior.\n         */\n        ASSERT(ksynch_get_value(&ostd->suspended) == 0);\n        if (!known_thread_signal(tr, SUSPEND_SIGNAL)) {\n            ostd->suspend_count--;\n            d_r_mutex_unlock(&ostd->suspend_lock);\n            return false;\n        }\n    }\n    /* we can unlock before the wait loop b/c we're using a separate \"resumed\"\n     * int and os_thread_resume holds the lock across its wait.  this way a resume\n     * can proceed as soon as the suspended thread is suspended, before the\n     * suspending thread gets scheduled again.\n     */\n    d_r_mutex_unlock(&ostd->suspend_lock);\n    while (ksynch_get_value(&ostd->suspended) == 0) {\n        /* For Linux, waits only if the suspended flag is not set as 1. Return value\n         * doesn't matter because the flag will be re-checked.\n         */\n        /* We time out and assert in debug build to provide better diagnostics than a\n         * silent hang.  We can't safely return false b/c the synch model here\n         * assumes there will not be a retry until the target reaches the suspend\n         * point.  Xref i#2779.\n         */\n#define SUSPEND_DEBUG_TIMEOUT_MS 5000\n        if (ksynch_wait(&ostd->suspended, 0, SUSPEND_DEBUG_TIMEOUT_MS) == -ETIMEDOUT) {\n            ASSERT_CURIOSITY(false && \"failed to suspend thread in 5s\");\n        }\n        if (ksynch_get_value(&ostd->suspended) == 0) {\n            /* If it still has to wait, give up the cpu. */\n            os_thread_yield();\n        }\n    }\n    return true;\n}\n\nbool\nos_thread_resume(thread_record_t *tr)\n{\n    os_thread_data_t *ostd = (os_thread_data_t *)tr->dcontext->os_field;\n    ASSERT(ostd != NULL);\n    /* This mutex prevents sending a re-suspend signal before the target\n     * reaches a safe post-resume point from a first suspend signal.\n     * Given that race, we can't just use atomic_add_exchange_int +\n     * atomic_dec_becomes_zero on suspend_count.\n     */\n    d_r_mutex_lock(&ostd->suspend_lock);\n    ASSERT(ostd->suspend_count > 0);\n    /* PR 479750: if do get here and target is not suspended then abort\n     * to avoid possible deadlocks\n     */\n    if (ostd->suspend_count == 0) {\n        d_r_mutex_unlock(&ostd->suspend_lock);\n        return true; /* the thread is \"resumed\", so success status */\n    }\n    ostd->suspend_count--;\n    if (ostd->suspend_count > 0) {\n        d_r_mutex_unlock(&ostd->suspend_lock);\n        return true; /* still suspended */\n    }\n    ksynch_set_value(&ostd->wakeup, 1);\n    ksynch_wake(&ostd->wakeup);\n    while (ksynch_get_value(&ostd->resumed) == 0) {\n        /* For Linux, waits only if the resumed flag is not set as 1.  Return value\n         * doesn't matter because the flag will be re-checked.\n         */\n        ksynch_wait(&ostd->resumed, 0, 0);\n        if (ksynch_get_value(&ostd->resumed) == 0) {\n            /* If it still has to wait, give up the cpu. */\n            os_thread_yield();\n        }\n    }\n    ksynch_set_value(&ostd->wakeup, 0);\n    ksynch_set_value(&ostd->resumed, 0);\n    d_r_mutex_unlock(&ostd->suspend_lock);\n    return true;\n}\n\nbool\nos_thread_terminate(thread_record_t *tr)\n{\n    /* PR 297902: for NPTL sending SIGKILL will take down the whole group:\n     * so instead we send SIGUSR2 and have a flag set telling\n     * target thread to execute SYS_exit\n     */\n    os_thread_data_t *ostd = (os_thread_data_t *)tr->dcontext->os_field;\n    ASSERT(ostd != NULL);\n    ostd->terminate = true;\n    /* Even if the thread is currently suspended, it's simpler to send it\n     * another signal than to resume it.\n     */\n    return known_thread_signal(tr, SUSPEND_SIGNAL);\n}\n\nbool\nis_thread_terminated(dcontext_t *dcontext)\n{\n    os_thread_data_t *ostd = (os_thread_data_t *)dcontext->os_field;\n    ASSERT(ostd != NULL);\n    return (ksynch_get_value(&ostd->terminated) == 1);\n}\n\nstatic void\nos_wait_thread_futex(KSYNCH_TYPE *var)\n{\n    while (ksynch_get_value(var) == 0) {\n        /* On Linux, waits only if var is not set as 1. Return value\n         * doesn't matter because var will be re-checked.\n         */\n        ksynch_wait(var, 0, 0);\n        if (ksynch_get_value(var) == 0) {\n            /* If it still has to wait, give up the cpu. */\n            os_thread_yield();\n        }\n    }\n}\n\nvoid\nos_wait_thread_terminated(dcontext_t *dcontext)\n{\n    os_thread_data_t *ostd = (os_thread_data_t *)dcontext->os_field;\n    ASSERT(ostd != NULL);\n    os_wait_thread_futex(&ostd->terminated);\n}\n\nvoid\nos_wait_thread_detached(dcontext_t *dcontext)\n{\n    os_thread_data_t *ostd = (os_thread_data_t *)dcontext->os_field;\n    ASSERT(ostd != NULL);\n    os_wait_thread_futex(&ostd->detached);\n}\n\nvoid\nos_signal_thread_detach(dcontext_t *dcontext)\n{\n    os_thread_data_t *ostd = (os_thread_data_t *)dcontext->os_field;\n    ASSERT(ostd != NULL);\n    ostd->do_detach = true;\n}\n\nbool\nthread_get_mcontext(thread_record_t *tr, priv_mcontext_t *mc)\n{\n    /* PR 212090: only works when target is suspended by us, and\n     * we then take the signal context\n     */\n    os_thread_data_t *ostd = (os_thread_data_t *)tr->dcontext->os_field;\n    ASSERT(ostd != NULL);\n    ASSERT(ostd->suspend_count > 0);\n    if (ostd->suspend_count == 0)\n        return false;\n    ASSERT(ostd->suspended_sigcxt != NULL);\n    sigcontext_to_mcontext(mc, ostd->suspended_sigcxt, DR_MC_ALL);\n    IF_ARM(dr_set_isa_mode(tr->dcontext, get_sigcontext_isa_mode(ostd->suspended_sigcxt),\n                           NULL));\n    return true;\n}\n\nbool\nthread_set_mcontext(thread_record_t *tr, priv_mcontext_t *mc)\n{\n    /* PR 212090: only works when target is suspended by us, and\n     * we then replace the signal context\n     */\n    os_thread_data_t *ostd = (os_thread_data_t *)tr->dcontext->os_field;\n    ASSERT(ostd != NULL);\n    ASSERT(ostd->suspend_count > 0);\n    if (ostd->suspend_count == 0)\n        return false;\n    ASSERT(ostd->suspended_sigcxt != NULL);\n    mcontext_to_sigcontext(ostd->suspended_sigcxt, mc, DR_MC_ALL);\n    IF_ARM(\n        set_sigcontext_isa_mode(ostd->suspended_sigcxt, dr_get_isa_mode(tr->dcontext)));\n    return true;\n}\n\n/* Only one of mc and dmc can be non-NULL. */\nbool\nos_context_to_mcontext(dr_mcontext_t *dmc, priv_mcontext_t *mc, os_cxt_ptr_t osc)\n{\n    if (dmc != NULL)\n        sigcontext_to_mcontext(dr_mcontext_as_priv_mcontext(dmc), &osc, dmc->flags);\n    else if (mc != NULL)\n        sigcontext_to_mcontext(mc, &osc, DR_MC_ALL);\n    else\n        return false;\n    return true;\n}\n\n/* Only one of mc and dmc can be non-NULL. */\nbool\nmcontext_to_os_context(os_cxt_ptr_t osc, dr_mcontext_t *dmc, priv_mcontext_t *mc)\n{\n    if (dmc != NULL)\n        mcontext_to_sigcontext(&osc, dr_mcontext_as_priv_mcontext(dmc), dmc->flags);\n    else if (mc != NULL)\n        mcontext_to_sigcontext(&osc, mc, DR_MC_ALL);\n    else\n        return false;\n    return true;\n}\n\nbool\nis_thread_currently_native(thread_record_t *tr)\n{\n    return (!tr->under_dynamo_control ||\n            /* start/stop doesn't change under_dynamo_control and has its own field */\n            (tr->dcontext != NULL && tr->dcontext->currently_stopped));\n}\n\n#ifdef LINUX /* XXX i#58: just until we have Mac support */\nstatic void\nclient_thread_run(void)\n{\n    void (*func)(void *param);\n    dcontext_t *dcontext;\n    byte *xsp;\n    GET_STACK_PTR(xsp);\n    void *crec = get_clone_record((reg_t)xsp);\n    /* i#2335: we support setup separate from start, and we want to allow a client\n     * to create a client thread during init, but we do not support that thread\n     * executing until the app has started (b/c we have no signal handlers in place).\n     */\n    /* i#3973: in addition to _executing_ a client thread before the\n     * app has started, if we even create the thread before\n     * dynamo_initialized is set, we will not copy tls blocks.  By\n     * waiting for the app to be started before dynamo_thread_init is\n     * called, we ensure this race condition can never happen, since\n     * dynamo_initialized will always be set before the app is started.\n     */\n    wait_for_event(dr_app_started, 0);\n    IF_DEBUG(int rc =)\n    dynamo_thread_init(get_clone_record_dstack(crec), NULL, crec, true);\n    ASSERT(rc != -1); /* this better be a new thread */\n    dcontext = get_thread_private_dcontext();\n    ASSERT(dcontext != NULL);\n    LOG(THREAD, LOG_ALL, 1, \"\\n***** CLIENT THREAD %d *****\\n\\n\", d_r_get_thread_id());\n    /* We stored the func and args in particular clone record fields */\n    func = (void (*)(void *param))dcontext->next_tag;\n    /* Reset any inherited mask (i#2337). */\n    signal_swap_mask(dcontext, false /*to DR*/);\n\n    void *arg = (void *)get_clone_record_app_xsp(crec);\n    LOG(THREAD, LOG_ALL, 1, \"func=\" PFX \", arg=\" PFX \"\\n\", func, arg);\n\n    (*func)(arg);\n\n    LOG(THREAD, LOG_ALL, 1, \"\\n***** CLIENT THREAD %d EXITING *****\\n\\n\",\n        d_r_get_thread_id());\n    block_cleanup_and_terminate(dcontext, SYS_exit, 0, 0, false /*just thread*/,\n                                IF_MACOS_ELSE(dcontext->thread_port, 0), 0);\n}\n#endif\n\n/* i#41/PR 222812: client threads\n * * thread must have dcontext since many API routines require one and we\n *   don't expose GLOBAL_DCONTEXT (xref PR 243008, PR 216936, PR 536058)\n * * reversed the old design of not using dstack (partly b/c want dcontext)\n *   and I'm using the same parent-creates-dstack and clone_record_t design\n *   to create linux threads: dstack should be big enough for client threads\n *   (xref PR 202669)\n * * reversed the old design of explicit dr_terminate_client_thread(): now\n *   the thread is auto-terminated and stack cleaned up on return from run\n *   function\n */\nDR_API bool\ndr_create_client_thread(void (*func)(void *param), void *arg)\n{\n#ifdef LINUX\n    dcontext_t *dcontext = get_thread_private_dcontext();\n    byte *xsp;\n    /* We do not pass SIGCHLD since don't want signal to parent and don't support\n     * waiting on child.\n     * We do not pass CLONE_THREAD so that the new thread is in its own thread\n     * group, allowing it to have private itimers and not receive any signals\n     * sent to the app's thread groups.  It also makes the thread not show up in\n     * the thread list for the app, making it more invisible.\n     */\n    uint flags = CLONE_VM | CLONE_FS | CLONE_FILES |\n        CLONE_SIGHAND\n            /* CLONE_THREAD required.  Signals and itimers are private anyway. */\n            IF_VMX86(| (os_in_vmkernel_userworld() ? CLONE_THREAD : 0));\n    pre_second_thread();\n    /* need to share signal handler table, prior to creating clone record */\n    handle_clone(dcontext, flags);\n    ATOMIC_INC(int, uninit_thread_count);\n    void *crec = create_clone_record(dcontext, (reg_t *)&xsp, NULL, NULL);\n    /* make sure client_thread_run can get the func and arg, and that\n     * signal_thread_inherit gets the right syscall info\n     */\n    set_clone_record_fields(crec, (reg_t)arg, (app_pc)func, SYS_clone, flags);\n    LOG(THREAD, LOG_ALL, 1, \"dr_create_client_thread xsp=\" PFX \" dstack=\" PFX \"\\n\", xsp,\n        get_clone_record_dstack(crec));\n    /* i#501 switch to app's tls before creating client thread.\n     * i#3526 switch DR's tls to an invalid one before cloning, and switch lib_tls\n     * to the app's.\n     */\n    os_clone_pre(dcontext);\n#    ifdef AARCHXX\n    /* We need to invalidate DR's TLS to avoid get_thread_private_dcontext() finding one\n     * and hitting asserts in dynamo_thread_init lock calls -- yet we don't want to for\n     * app threads, so we're doing this here and not in os_clone_pre().\n     * XXX: Find a way to put this in os_clone_* to simplify the code?\n     */\n    void *tls = (void *)read_thread_register(LIB_SEG_TLS);\n    write_thread_register(NULL);\n#    endif\n    thread_id_t newpid = dynamorio_clone(flags, xsp, NULL, NULL, NULL, client_thread_run);\n    /* i#3526 switch DR's tls back to the original one before cloning. */\n    os_clone_post(dcontext);\n#    ifdef AARCHXX\n    write_thread_register(tls);\n#    endif\n    /* i#501 the app's tls was switched in os_clone_pre. */\n    if (INTERNAL_OPTION(private_loader))\n        os_switch_lib_tls(dcontext, false /*to dr*/);\n    if (newpid < 0) {\n        LOG(THREAD, LOG_ALL, 1, \"client thread creation failed: %d\\n\", newpid);\n        return false;\n    } else if (newpid == 0) {\n        /* dynamorio_clone() should have called client_thread_run directly */\n        ASSERT_NOT_REACHED();\n        return false;\n    }\n    return true;\n#else\n    ASSERT_NOT_IMPLEMENTED(false); /* FIXME i#58: implement on Mac */\n    return false;\n#endif\n}\n\nint\nget_num_processors(void)\n{\n    static uint num_cpu = 0; /* cached value */\n    if (!num_cpu) {\n#ifdef MACOS\n        DEBUG_DECLARE(bool ok =)\n        sysctl_query(CTL_HW, HW_NCPU, &num_cpu, sizeof(num_cpu));\n        ASSERT(ok);\n#else\n        /* We used to use get_nprocs_conf, but that's in libc, so now we just\n         * look at the /sys filesystem ourselves, which is what glibc does.\n         */\n        uint local_num_cpus = 0;\n        file_t cpu_dir = os_open_directory(\"/sys/devices/system/cpu\", OS_OPEN_READ);\n        dir_iterator_t iter;\n        ASSERT(cpu_dir != INVALID_FILE &&\n               \"/sys must be mounted: mount -t sysfs sysfs /sys\");\n        os_dir_iterator_start(&iter, cpu_dir);\n        while (os_dir_iterator_next(&iter)) {\n            int dummy_num;\n            if (sscanf(iter.name, \"cpu%d\", &dummy_num) == 1)\n                local_num_cpus++;\n        }\n        os_close(cpu_dir);\n        num_cpu = local_num_cpus;\n#endif\n        ASSERT(num_cpu);\n    }\n    return num_cpu;\n}\n\n/* i#46: To support -no_private_loader, we have to call the dlfcn family of\n * routines in libdl.so.  When we do early injection, there is no loader to\n * resolve these imports, so they will crash.  Early injection is incompatible\n * with -no_private_loader, so this should never happen.\n */\n\nshlib_handle_t\nload_shared_library(const char *name, bool reachable)\n{\n#ifdef STATIC_LIBRARY\n    if (os_files_same(name, get_application_name())) {\n        /* The private loader falls back to dlsym() and friends for modules it\n         * doesn't recognize, so this works without disabling the private loader.\n         */\n        return dlopen(NULL, RTLD_LAZY); /* Gets a handle to the exe. */\n    }\n#endif\n    /* We call locate_and_load_private_library() to support searching for\n     * a pathless name.\n     */\n    if (INTERNAL_OPTION(private_loader))\n        return (shlib_handle_t)locate_and_load_private_library(name, reachable);\n#if defined(STATIC_LIBRARY) || defined(MACOS)\n    ASSERT(!DYNAMO_OPTION(early_inject));\n    return dlopen(name, RTLD_LAZY);\n#else\n    /* -no_private_loader is no longer supported in our default builds.\n     * If we want it for hybrid mode we should add a new build param and include\n     * the libdl calls here under that param.\n     */\n    ASSERT_NOT_REACHED();\n    return NULL;\n#endif\n}\n\nshlib_routine_ptr_t\nlookup_library_routine(shlib_handle_t lib, const char *name)\n{\n    if (INTERNAL_OPTION(private_loader)) {\n        return (shlib_routine_ptr_t)get_private_library_address((app_pc)lib, name);\n    }\n#if defined(STATIC_LIBRARY) || defined(MACOS)\n    ASSERT(!DYNAMO_OPTION(early_inject));\n    return dlsym(lib, name);\n#else\n    ASSERT_NOT_REACHED(); /* -no_private_loader is no longer supported: see above */\n    return NULL;\n#endif\n}\n\nvoid\nunload_shared_library(shlib_handle_t lib)\n{\n    if (INTERNAL_OPTION(private_loader)) {\n        unload_private_library(lib);\n    } else {\n#if defined(STATIC_LIBRARY) || defined(MACOS)\n        ASSERT(!DYNAMO_OPTION(early_inject));\n        if (!DYNAMO_OPTION(avoid_dlclose)) {\n            dlclose(lib);\n        }\n#else\n        ASSERT_NOT_REACHED(); /* -no_private_loader is no longer supported: see above  */\n#endif\n    }\n}\n\nvoid\nshared_library_error(char *buf, int maxlen)\n{\n    const char *err;\n    if (INTERNAL_OPTION(private_loader)) {\n        err = \"error in private loader\";\n    } else {\n#if defined(STATIC_LIBRARY) || defined(MACOS)\n        ASSERT(!DYNAMO_OPTION(early_inject));\n        err = dlerror();\n        if (err == NULL) {\n            err = \"dlerror returned NULL\";\n        }\n#else\n        ASSERT_NOT_REACHED(); /* -no_private_loader is no longer supported */\n        err = \"unknown error\";\n#endif\n    }\n    strncpy(buf, err, maxlen - 1);\n    buf[maxlen - 1] = '\\0'; /* strncpy won't put on trailing null if maxes out */\n}\n\n/* addr is any pointer known to lie within the library.\n * for linux, one of addr or name is needed; for windows, neither is needed.\n */\nbool\nshared_library_bounds(IN shlib_handle_t lib, IN byte *addr, IN const char *name,\n                      OUT byte **start, OUT byte **end)\n{\n    ASSERT(start != NULL && end != NULL);\n    /* PR 366195: dlopen() handle truly is opaque, so we have to use either\n     * addr or name\n     */\n    ASSERT(addr != NULL || name != NULL);\n    *start = addr;\n    if (INTERNAL_OPTION(private_loader)) {\n        privmod_t *mod;\n        /* look for private library first */\n        acquire_recursive_lock(&privload_lock);\n        mod = privload_lookup_by_base((app_pc)lib);\n        if (name != NULL && mod == NULL)\n            mod = privload_lookup(name);\n        if (mod != NULL && !mod->externally_loaded) {\n            *start = mod->base;\n            if (end != NULL)\n                *end = mod->base + mod->size;\n            release_recursive_lock(&privload_lock);\n            return true;\n        }\n        release_recursive_lock(&privload_lock);\n    }\n    return (memquery_library_bounds(name, start, end, NULL, 0, NULL, 0) > 0);\n}\n\nstatic int\nfcntl_syscall(int fd, int cmd, long arg)\n{\n    return dynamorio_syscall(SYSNUM_NO_CANCEL(SYS_fcntl), 3, fd, cmd, arg);\n}\n\n/* dups curfd to a private fd.\n * returns -1 if unsuccessful.\n */\nfile_t\nfd_priv_dup(file_t curfd)\n{\n    file_t newfd = -1;\n    if (DYNAMO_OPTION(steal_fds) > 0) {\n        /* RLIMIT_NOFILES is 1 greater than max and F_DUPFD starts at given value */\n        /* XXX: if > linux 2.6.24, can use F_DUPFD_CLOEXEC to avoid later call:\n         * so how do we tell if the flag is supported?  try calling once at init?\n         */\n        newfd = fcntl_syscall(curfd, F_DUPFD, min_dr_fd);\n        if (newfd < 0) {\n            /* We probably ran out of fds, esp if debug build and there are\n             * lots of threads.  Should we track how many we've given out to\n             * avoid a failed syscall every time after?\n             */\n            SYSLOG_INTERNAL_WARNING_ONCE(\"ran out of stolen fd space\");\n            /* Try again but this time in the app space, somewhere high up\n             * to avoid issues like tcsh assuming it can own fds 3-5 for\n             * piping std{in,out,err} (xref the old -open_tcsh_fds option).\n             */\n            newfd = fcntl_syscall(curfd, F_DUPFD, min_dr_fd / 2);\n        }\n    }\n    return newfd;\n}\n\nbool\nfd_mark_close_on_exec(file_t fd)\n{\n    /* we assume FD_CLOEXEC is the only flag and don't bother w/ F_GETFD */\n    if (fcntl_syscall(fd, F_SETFD, FD_CLOEXEC) != 0) {\n        SYSLOG_INTERNAL_WARNING(\"unable to mark file %d as close-on-exec\", fd);\n        return false;\n    }\n    return true;\n}\n\nvoid\nfd_table_add(file_t fd, uint flags)\n{\n    if (fd_table != NULL) {\n        TABLE_RWLOCK(fd_table, write, lock);\n        DODEBUG({\n            /* i#1010: If the fd is already in the table, chances are it's a\n             * stale logfile fd left behind by a vforked or cloned child that\n             * called execve.  Avoid an assert if that happens.\n             */\n            bool present = generic_hash_remove(GLOBAL_DCONTEXT, fd_table, (ptr_uint_t)fd);\n            ASSERT_CURIOSITY_ONCE(!present && \"stale fd not cleaned up\");\n        });\n        generic_hash_add(GLOBAL_DCONTEXT, fd_table, (ptr_uint_t)fd,\n                         /* store the flags, w/ a set bit to ensure not 0 */\n                         (void *)(ptr_uint_t)(flags | OS_OPEN_RESERVED));\n        TABLE_RWLOCK(fd_table, write, unlock);\n    } else {\n#ifdef DEBUG\n        num_fd_add_pre_heap++;\n        /* we add main_logfile in d_r_os_init() */\n        ASSERT(num_fd_add_pre_heap == 1 && \"only main_logfile should come here\");\n#endif\n    }\n}\n\nstatic bool\nfd_is_dr_owned(file_t fd)\n{\n    ptr_uint_t flags;\n    ASSERT(fd_table != NULL);\n    TABLE_RWLOCK(fd_table, read, lock);\n    flags = (ptr_uint_t)generic_hash_lookup(GLOBAL_DCONTEXT, fd_table, (ptr_uint_t)fd);\n    TABLE_RWLOCK(fd_table, read, unlock);\n    return (flags != 0);\n}\n\nstatic bool\nfd_is_in_private_range(file_t fd)\n{\n    return (DYNAMO_OPTION(steal_fds) > 0 && min_dr_fd > 0 && fd >= min_dr_fd);\n}\n\nfile_t\nos_open_protected(const char *fname, int os_open_flags)\n{\n    file_t dup;\n    file_t res = os_open(fname, os_open_flags);\n    if (res < 0)\n        return res;\n    /* we could have os_open() always switch to a private fd but it's probably\n     * not worth the extra syscall for temporary open/close sequences so we\n     * only use it for persistent files\n     */\n    dup = fd_priv_dup(res);\n    if (dup >= 0) {\n        close_syscall(res);\n        res = dup;\n        fd_mark_close_on_exec(res);\n    } /* else just keep original */\n\n    /* ditto here, plus for things like config.c opening files we can't handle\n     * grabbing locks and often don't have heap available so no fd_table\n     */\n    fd_table_add(res, os_open_flags);\n\n    return res;\n}\n\nvoid\nos_close_protected(file_t f)\n{\n    ASSERT(fd_table != NULL || dynamo_exited);\n    if (fd_table != NULL) {\n        TABLE_RWLOCK(fd_table, write, lock);\n        generic_hash_remove(GLOBAL_DCONTEXT, fd_table, (ptr_uint_t)f);\n        TABLE_RWLOCK(fd_table, write, unlock);\n    }\n    os_close(f);\n}\n\nbool\nos_get_current_dir(char *buf, size_t bufsz)\n{\n#ifdef MACOS\n    static char noheap_buf[MAXPATHLEN];\n    bool res = false;\n    file_t fd = os_open(\".\", OS_OPEN_READ);\n    int len;\n    /* F_GETPATH assumes a buffer of size MAXPATHLEN */\n    char *fcntl_buf;\n    if (dynamo_heap_initialized)\n        fcntl_buf = global_heap_alloc(MAXPATHLEN HEAPACCT(ACCT_OTHER));\n    else\n        fcntl_buf = noheap_buf;\n    if (fd == INVALID_FILE)\n        goto cwd_error;\n    if (fcntl_syscall(fd, F_GETPATH, (long)fcntl_buf) != 0)\n        goto cwd_error;\n    len = snprintf(buf, bufsz, \"%s\", fcntl_buf);\n    buf[bufsz - 1] = '\\0';\n    return (len > 0 && len < bufsz);\ncwd_error:\n    if (dynamo_heap_initialized)\n        global_heap_free(fcntl_buf, MAXPATHLEN HEAPACCT(ACCT_OTHER));\n    os_close(fd);\n    return res;\n#else\n    return (dynamorio_syscall(SYS_getcwd, 2, buf, bufsz) > 0);\n#endif\n}\n\nssize_t\nos_write(file_t f, const void *buf, size_t count)\n{\n    return write_syscall(f, buf, count);\n}\n\n/* There are enough differences vs the shared drlibc_os.c version that we override\n * it here.  We use a loop to ensure reachability for the core.\n */\nbyte *\nos_map_file(file_t f, size_t *size INOUT, uint64 offs, app_pc addr, uint prot,\n            map_flags_t map_flags)\n{\n    int flags;\n    byte *map = NULL;\n#if defined(X64)\n    bool loop = false;\n    uint iters = 0;\n#    define MAX_MMAP_LOOP_ITERS 100\n    byte *region_start = NULL, *region_end = NULL;\n#else\n    uint pg_offs;\n    ASSERT_TRUNCATE(pg_offs, uint, offs / PAGE_SIZE);\n    pg_offs = (uint)(offs / PAGE_SIZE);\n#endif\n#ifdef VMX86_SERVER\n    flags = MAP_PRIVATE; /* MAP_SHARED not supported yet */\n#else\n    flags = TEST(MAP_FILE_COPY_ON_WRITE, map_flags) ? MAP_PRIVATE : MAP_SHARED;\n#endif\n#if defined(X64)\n    /* Allocate memory from reachable range for image: or anything (pcache\n     * in particular): for low 4GB, easiest to just pass MAP_32BIT (which is\n     * low 2GB, but good enough).\n     */\n    if (DYNAMO_OPTION(heap_in_lower_4GB) &&\n        !TESTANY(MAP_FILE_FIXED | MAP_FILE_APP, map_flags))\n        flags |= MAP_32BIT;\n#endif\n    /* Allows memory request instead of mapping a file,\n     * so we can request memory from a particular address with fixed argument */\n    if (f == -1)\n        flags |= MAP_ANONYMOUS;\n    if (TEST(MAP_FILE_FIXED, map_flags))\n        flags |= MAP_FIXED;\n#if defined(X64)\n    if (!TEST(MAP_32BIT, flags) && TEST(MAP_FILE_REACHABLE, map_flags)) {\n        vmcode_get_reachable_region(&region_start, &region_end);\n        /* addr need not be NULL: we'll use it if it's in the region */\n        ASSERT(!TEST(MAP_FILE_FIXED, map_flags));\n        /* Loop to handle races */\n        loop = true;\n    }\n    if ((!TEST(MAP_32BIT, flags) && TEST(MAP_FILE_REACHABLE, map_flags) &&\n         (is_vmm_reserved_address(addr, *size, NULL, NULL) ||\n          /* Try to honor a library's preferred address.  This does open up a race\n           * window during attach where another thread could take this spot,\n           * and with this current code we'll never go back and try to get VMM\n           * memory.  We live with that as being rare rather than complicate the code.\n           */\n          !rel32_reachable_from_current_vmcode(addr))) ||\n        (TEST(MAP_FILE_FIXED, map_flags) && !TEST(MAP_FILE_VMM_COMMIT, map_flags) &&\n         is_vmm_reserved_address(addr, *size, NULL, NULL))) {\n        if (DYNAMO_OPTION(vm_reserve)) {\n            /* Try to get space inside the vmcode reservation. */\n            map = heap_reserve_for_external_mapping(addr, *size,\n                                                    VMM_SPECIAL_MMAP | VMM_REACHABLE);\n            if (map != NULL) {\n                addr = map;\n                flags |= MAP_FIXED;\n            }\n        }\n    }\n    while (!loop ||\n           (addr != NULL && addr >= region_start && addr + *size <= region_end) ||\n           find_free_memory_in_region(region_start, region_end, *size, &addr, NULL)) {\n#endif\n        map = mmap_syscall(addr, *size, memprot_to_osprot(prot), flags, f,\n                           /* x86 Linux mmap uses offset in pages */\n                           IF_LINUX_ELSE(IF_X64_ELSE(offs, pg_offs), offs));\n        if (!mmap_syscall_succeeded(map)) {\n            LOG(THREAD_GET, LOG_SYSCALLS, 2, \"%s failed: \" PIFX \"\\n\", __func__, map);\n            map = NULL;\n        }\n#if defined(X64)\n        else if (loop && (map < region_start || map + *size > region_end)) {\n            /* Try again: probably a race.  Hopefully our notion of \"there's a free\n             * region big enough\" matches the kernel's, else we'll loop forever\n             * (which we try to catch w/ a max iters count).\n             */\n            munmap_syscall(map, *size);\n            map = NULL;\n        } else\n            break;\n        if (!loop)\n            break;\n        if (++iters > MAX_MMAP_LOOP_ITERS) {\n            ASSERT_NOT_REACHED();\n            map = NULL;\n            break;\n        }\n        addr = NULL; /* pick a new one */\n    }\n#endif\n    return map;\n}\n\nbool\nos_unmap_file(byte *map, size_t size)\n{\n    if (DYNAMO_OPTION(vm_reserve) && is_vmm_reserved_address(map, size, NULL, NULL)) {\n        /* XXX i#3570: We'd prefer to have the VMM perform this to ensure it matches\n         * how it originally reserved the memory.  To do that would we expose a way\n         * to ask for MAP_FIXED in os_heap_reserve*()?\n         */\n        byte *addr = mmap_syscall(map, size, PROT_NONE,\n                                  MAP_PRIVATE | MAP_ANONYMOUS | MAP_FIXED, -1, 0);\n        if (!mmap_syscall_succeeded(addr))\n            return false;\n        return heap_unreserve_for_external_mapping(map, size,\n                                                   VMM_SPECIAL_MMAP | VMM_REACHABLE);\n    }\n    long res = munmap_syscall(map, size);\n    return (res == 0);\n}\n\n#ifdef LINUX\nstatic void\nos_get_memory_file_shm_path(const char *name, OUT char *buf, size_t bufsz)\n{\n    snprintf(buf, bufsz, \"/dev/shm/%s.%d\", name, get_process_id());\n    buf[bufsz - 1] = '\\0';\n}\n#endif\n\nfile_t\nos_create_memory_file(const char *name, size_t size)\n{\n#ifdef LINUX\n    char path[MAXIMUM_PATH];\n    file_t fd;\n    /* We need an in-memory file. We prefer the new memfd_create over /dev/shm (it\n     * has no name conflict issues, stale files left around on a crash, or\n     * reliance on tmpfs).\n     */\n#    ifdef SYS_memfd_create\n    snprintf(path, BUFFER_SIZE_ELEMENTS(path), \"/%s.%d\", name, get_process_id());\n    NULL_TERMINATE_BUFFER(path);\n    fd = dynamorio_syscall(SYS_memfd_create, 2, path, 0);\n#    else\n    fd = -ENOSYS;\n#    endif\n    if (fd == -ENOSYS) {\n        /* Fall back on /dev/shm. */\n        os_get_memory_file_shm_path(name, path, BUFFER_SIZE_ELEMENTS(path));\n        NULL_TERMINATE_BUFFER(path);\n        fd = open_syscall(path, O_CREAT | O_EXCL | O_RDWR, S_IRUSR | S_IWUSR);\n        if (fd == -EEXIST) {\n            /* We assume a stale file from some prior crash. */\n            SYSLOG_INTERNAL_WARNING(\"Removing presumed-stale %s\", path);\n            os_delete_file(path);\n            fd = open_syscall(path, O_CREAT | O_EXCL | O_RDWR, S_IRUSR | S_IWUSR);\n        }\n    }\n    if (fd < 0)\n        return INVALID_FILE;\n\n    /* Work around an IMA (kernel optional feature \"Integrity Measurement\n     * Architecture\") slowdown where the first executable mmap causes a hash\n     * to be computed of the entire file size, which can take 5 or 10\n     * *seconds* for gigabyte files.  This is only done once, so if we\n     * trigger it while the file is tiny, we can avoid the delay later.\n     */\n    byte *temp_map = mmap_syscall(0, PAGE_SIZE, PROT_READ | PROT_EXEC, MAP_SHARED, fd, 0);\n    if (mmap_syscall_succeeded(temp_map))\n        munmap_syscall(temp_map, PAGE_SIZE);\n    /* Else, not fatal: this may not be destined for a later executable mapping anyway. */\n\n    if (dynamorio_syscall(SYS_ftruncate, 2, fd, size) < 0) {\n        close_syscall(fd);\n        return INVALID_FILE;\n    }\n    file_t priv_fd = fd_priv_dup(fd);\n    close_syscall(fd); /* Close the old descriptor on success *and* error. */\n    if (priv_fd < 0) {\n        return INVALID_FILE;\n    }\n    fd = priv_fd;\n    fd_mark_close_on_exec(fd); /* We could use MFD_CLOEXEC for memfd_create. */\n    return fd;\n#else\n    ASSERT_NOT_IMPLEMENTED(false && \"i#3556 NYI for Mac\");\n    return INVALID_FILE;\n#endif\n}\n\nvoid\nos_delete_memory_file(const char *name, file_t fd)\n{\n#ifdef LINUX\n    /* There is no need to delete a memfd_create path, but if we used shm we need\n     * to clean it up.  We blindly do this rather than trying to record whether\n     * we created this file.\n     */\n    char path[MAXIMUM_PATH];\n    os_get_memory_file_shm_path(name, path, BUFFER_SIZE_ELEMENTS(path));\n    NULL_TERMINATE_BUFFER(path);\n    os_delete_file(path);\n    close_syscall(fd);\n#else\n    ASSERT_NOT_IMPLEMENTED(false && \"i#3556 NYI for Mac\");\n#endif\n}\n\nbool\nos_get_disk_free_space(/*IN*/ file_t file_handle,\n                       /*OUT*/ uint64 *AvailableQuotaBytes /*OPTIONAL*/,\n                       /*OUT*/ uint64 *TotalQuotaBytes /*OPTIONAL*/,\n                       /*OUT*/ uint64 *TotalVolumeBytes /*OPTIONAL*/)\n{\n    /* libc struct seems to match kernel's */\n    struct statfs stat;\n    ptr_int_t res = dynamorio_syscall(SYS_fstatfs, 2, file_handle, &stat);\n    if (res != 0) {\n        LOG(THREAD_GET, LOG_SYSCALLS, 2, \"%s failed: \" PIFX \"\\n\", __func__, res);\n        return false;\n    }\n    LOG(GLOBAL, LOG_STATS, 3,\n        \"os_get_disk_free_space: avail=\" SZFMT \", free=\" SZFMT \", bsize=\" SZFMT \"\\n\",\n        stat.f_bavail, stat.f_bfree, stat.f_bsize);\n    if (AvailableQuotaBytes != NULL)\n        *AvailableQuotaBytes = ((uint64)stat.f_bavail * stat.f_bsize);\n    /* no support for quotas */\n    if (TotalQuotaBytes != NULL)\n        *TotalQuotaBytes = ((uint64)stat.f_bavail * stat.f_bsize);\n    if (TotalVolumeBytes != NULL) /* despite name this is how much is free */\n        *TotalVolumeBytes = ((uint64)stat.f_bfree * stat.f_bsize);\n    return true;\n}\n\n#ifdef LINUX\nstatic bool\nsymlink_is_self_exe(const char *path)\n{\n    /* Look for \"/proc/%d/exe\" where %d exists in /proc/self/task/%d,\n     * or \"/proc/self/exe\".  Rule out the exe link for another process\n     * (though it could also be under DR we have no simple way to obtain\n     * its actual app path).\n     */\n#    define SELF_LEN_LEADER 6  /* \"/proc/\" */\n#    define SELF_LEN_TRAILER 4 /* \"/exe\" */\n#    define SELF_LEN_MAX 18\n    size_t len = strlen(path);\n    if (strcmp(path, \"/proc/self/exe\") == 0)\n        return true;\n    if (len < SELF_LEN_MAX && /* /proc/nnnnnn/exe */\n        strncmp(path, \"/proc/\", SELF_LEN_LEADER) == 0 &&\n        strncmp(path + len - SELF_LEN_TRAILER, \"/exe\", SELF_LEN_TRAILER) == 0) {\n        int pid;\n        if (sscanf(path + SELF_LEN_LEADER, \"%d\", &pid) == 1) {\n            char task[32];\n            snprintf(task, BUFFER_SIZE_ELEMENTS(task), \"/proc/self/task/%d\", pid);\n            NULL_TERMINATE_BUFFER(task);\n            return os_file_exists(task, true /*dir*/);\n        }\n    }\n    return false;\n}\n#endif\n\nvoid\nexit_process_syscall(long status)\n{\n    /* We now assume SYS_exit_group is defined: not building on old machines,\n     * but will execute there.  We try exit_group and if it fails we use exit.\n     *\n     * FIXME: if no exit_group, kill all other threads (==processes in same addr\n     * space) manually?  Presumably we got here b/c at an unsafe point to do\n     * full exit?  Or is that not true: what about dr_abort()?\n     */\n    dynamorio_syscall(SYSNUM_EXIT_PROCESS, 1, status);\n    /* would assert that result is -ENOSYS but assert likely calls us => infinite loop */\n    exit_thread_syscall(status);\n    ASSERT_NOT_REACHED();\n}\n\nvoid\nexit_thread_syscall(long status)\n{\n#ifdef MACOS\n    mach_port_t thread_port = dynamorio_mach_syscall(MACH_thread_self_trap, 0);\n    /* FIXME i#1403: on MacOS we fail to free the app's stack: we need to pass it to\n     * bsdthread_terminate.\n     */\n    dynamorio_syscall(SYSNUM_EXIT_THREAD, 4, 0, 0, thread_port, 0);\n#else\n    dynamorio_syscall(SYSNUM_EXIT_THREAD, 1, status);\n#endif\n}\n\n/* FIXME: this one will not be easily internationalizable\n   yet it is easier to have a syslog based Unix implementation with real strings.\n */\n\nvoid\nos_syslog(syslog_event_type_t priority, uint message_id, uint substitutions_num,\n          va_list args)\n{\n    int native_priority;\n    switch (priority) {\n    case SYSLOG_INFORMATION: native_priority = LOG_INFO; break;\n    case SYSLOG_WARNING: native_priority = LOG_WARNING; break;\n    case SYSLOG_CRITICAL: native_priority = LOG_CRIT; break;\n    case SYSLOG_ERROR: native_priority = LOG_ERR; break;\n    default: ASSERT_NOT_REACHED();\n    }\n    /* can amount to passing a format string (careful here) to vsyslog */\n\n    /* Never let user controlled data in the format string! */\n    ASSERT_NOT_IMPLEMENTED(false);\n}\n\n/* This is subject to races, but should only happen at init/attach when\n * there should only be one live thread.\n */\nstatic bool\nsafe_read_via_query(const void *base, size_t size, void *out_buf, size_t *bytes_read)\n{\n    bool res = false;\n    size_t num_read = 0;\n    ASSERT(!fault_handling_initialized);\n    /* XXX: in today's init ordering, allmem will never be initialized when we come\n     * here, but we check it nevertheless to be general in case this routine is\n     * ever called at some later time\n     */\n    if (IF_MEMQUERY_ELSE(false, memcache_initialized()))\n        res = is_readable_without_exception_internal(base, size, false /*use allmem*/);\n    else\n        res = is_readable_without_exception_query_os((void *)base, size);\n    if (res) {\n        memcpy(out_buf, base, size);\n        num_read = size;\n    }\n    if (bytes_read != NULL)\n        *bytes_read = num_read;\n    return res;\n}\n\nbool\nsafe_read_ex(const void *base, size_t size, void *out_buf, size_t *bytes_read)\n{\n    STATS_INC(num_safe_reads);\n    /* XXX i#350: we'd like to always use safe_read_fast() and remove this extra\n     * call layer, but safe_read_fast() requires fault handling to be set up.\n     * We do set up an early signal handler in d_r_os_init(),\n     * but there is still be a window prior to that with no handler.\n     */\n    if (!fault_handling_initialized) {\n        return safe_read_via_query(base, size, out_buf, bytes_read);\n    } else {\n        return safe_read_fast(base, size, out_buf, bytes_read);\n    }\n}\n\nbool\nsafe_read_if_fast(const void *base, size_t size, void *out_buf)\n{\n    if (!fault_handling_initialized) {\n        memcpy(out_buf, base, size);\n        return true;\n    } else {\n        return safe_read_ex(base, size, out_buf, NULL);\n    }\n}\n\n/* FIXME - fold this together with safe_read_ex() (is a lot of places to update) */\nbool\nd_r_safe_read(const void *base, size_t size, void *out_buf)\n{\n    return safe_read_ex(base, size, out_buf, NULL);\n}\n\nbool\nsafe_write_ex(void *base, size_t size, const void *in_buf, size_t *bytes_written)\n{\n    return safe_write_try_except(base, size, in_buf, bytes_written);\n}\n\n/* is_readable_without_exception checks to see that all bytes with addresses\n * from pc to pc+size-1 are readable and that reading from there won't\n * generate an exception. if 'from_os' is true, check what the os thinks\n * the prot bits are instead of using the all memory list.\n */\nstatic bool\nis_readable_without_exception_internal(const byte *pc, size_t size, bool query_os)\n{\n    uint prot = MEMPROT_NONE;\n    byte *check_pc = (byte *)ALIGN_BACKWARD(pc, PAGE_SIZE);\n    if (size > ((byte *)POINTER_MAX - pc))\n        size = (byte *)POINTER_MAX - pc;\n    do {\n        bool rc = query_os ? get_memory_info_from_os(check_pc, NULL, NULL, &prot)\n                           : get_memory_info(check_pc, NULL, NULL, &prot);\n        if (!rc || !TESTANY(MEMPROT_READ | MEMPROT_EXEC, prot))\n            return false;\n        if (POINTER_OVERFLOW_ON_ADD(check_pc, PAGE_SIZE))\n            break;\n        check_pc += PAGE_SIZE;\n    } while (check_pc < pc + size);\n    return true;\n}\n\nbool\nis_readable_without_exception(const byte *pc, size_t size)\n{\n    /* case 9745 / i#853: We've had problems with all_memory_areas not being\n     * accurate in the past.  Parsing proc maps is too slow for some apps, so we\n     * use a runtime option.\n     */\n    bool query_os = IF_MEMQUERY_ELSE(true, !DYNAMO_OPTION(use_all_memory_areas));\n    return is_readable_without_exception_internal(pc, size, query_os);\n}\n\n/* Identical to is_readable_without_exception except that the os is queried\n * for info on the indicated region */\nbool\nis_readable_without_exception_query_os(byte *pc, size_t size)\n{\n    return is_readable_without_exception_internal(pc, size, true);\n}\n\nbool\nis_readable_without_exception_query_os_noblock(byte *pc, size_t size)\n{\n    if (memquery_from_os_will_block())\n        return false;\n    return is_readable_without_exception_internal(pc, size, true);\n}\n\nbool\nis_user_address(byte *pc)\n{\n    /* FIXME: NYI */\n    /* note returning true will always skip the case 9022 logic on Linux */\n    return true;\n}\n\n/* change protections on memory region starting at pc of length length\n * this does not update the all memory area info\n */\nbool\nos_set_protection(byte *pc, size_t length, uint prot /*MEMPROT_*/)\n{\n    app_pc start_page = (app_pc)PAGE_START(pc);\n    uint num_bytes = ALIGN_FORWARD(length + (pc - start_page), PAGE_SIZE);\n    long res = 0;\n    uint flags = memprot_to_osprot(prot);\n    DOSTATS({\n        /* once on each side of prot, to get on right side of writability */\n        if (!TEST(PROT_WRITE, flags)) {\n            STATS_INC(protection_change_calls);\n            STATS_ADD(protection_change_pages, num_bytes / PAGE_SIZE);\n        }\n    });\n    res = mprotect_syscall((void *)start_page, num_bytes, flags);\n    if (res != 0)\n        return false;\n    LOG(THREAD_GET, LOG_VMAREAS, 3,\n        \"change_prot(\" PFX \", \" PIFX \", %s) => \"\n        \"mprotect(\" PFX \", \" PIFX \", %d)==%d pages\\n\",\n        pc, length, memprot_string(prot), start_page, num_bytes, flags,\n        num_bytes / PAGE_SIZE);\n    DOSTATS({\n        /* once on each side of prot, to get on right side of writability */\n        if (TEST(PROT_WRITE, flags)) {\n            STATS_INC(protection_change_calls);\n            STATS_ADD(protection_change_pages, num_bytes / PAGE_SIZE);\n        }\n    });\n    return true;\n}\n\n/* change protections on memory region starting at pc of length length */\nbool\nset_protection(byte *pc, size_t length, uint prot /*MEMPROT_*/)\n{\n    if (os_set_protection(pc, length, prot) == false)\n        return false;\n#ifndef HAVE_MEMINFO_QUERY\n    else {\n        app_pc start_page = (app_pc)PAGE_START(pc);\n        uint num_bytes = ALIGN_FORWARD(length + (pc - start_page), PAGE_SIZE);\n        memcache_update_locked(start_page, start_page + num_bytes, prot,\n                               -1 /*type unchanged*/, true /*exists*/);\n    }\n#endif\n    return true;\n}\n\n/* change protections on memory region starting at pc of length length */\nbool\nchange_protection(byte *pc, size_t length, bool writable)\n{\n    if (writable)\n        return make_writable(pc, length);\n    else\n        make_unwritable(pc, length);\n    return true;\n}\n\n/* make pc's page writable */\nbool\nmake_writable(byte *pc, size_t size)\n{\n    long res;\n    app_pc start_page = (app_pc)PAGE_START(pc);\n    size_t prot_size = (size == 0) ? PAGE_SIZE : size;\n    uint prot = PROT_EXEC | PROT_READ | PROT_WRITE;\n    /* if can get current protection then keep old read/exec flags.\n     * this is crucial on modern linux kernels which refuse to mark stack +x.\n     */\n    if (!is_in_dynamo_dll(pc) /*avoid allmem assert*/ &&\n#ifdef STATIC_LIBRARY\n        /* FIXME i#975: is_in_dynamo_dll() is always false for STATIC_LIBRARY,\n         * but we can't call get_memory_info() until allmem is initialized.  Our\n         * uses before then are for patching x86.asm, which is OK.\n         */\n        IF_NO_MEMQUERY(memcache_initialized() &&)\n#endif\n            get_memory_info(pc, NULL, NULL, &prot))\n        prot |= PROT_WRITE;\n\n    ASSERT(start_page == pc && ALIGN_FORWARD(size, PAGE_SIZE) == size);\n    res = mprotect_syscall((void *)start_page, prot_size, prot);\n    LOG(THREAD_GET, LOG_VMAREAS, 3, \"make_writable: pc \" PFX \" -> \" PFX \"-\" PFX \" %d\\n\",\n        pc, start_page, start_page + prot_size, res);\n    ASSERT(res == 0);\n    if (res != 0)\n        return false;\n    STATS_INC(protection_change_calls);\n    STATS_ADD(protection_change_pages, size / PAGE_SIZE);\n\n#ifndef HAVE_MEMINFO_QUERY\n    /* update all_memory_areas list with the protection change */\n    if (memcache_initialized()) {\n        memcache_update_locked(start_page, start_page + prot_size,\n                               osprot_to_memprot(prot), -1 /*type unchanged*/,\n                               true /*exists*/);\n    }\n#endif\n    return true;\n}\n\n/* like make_writable but adds COW */\nbool\nmake_copy_on_writable(byte *pc, size_t size)\n{\n    /* FIXME: for current usage this should be fine */\n    return make_writable(pc, size);\n}\n\n/* make pc's page unwritable */\nvoid\nmake_unwritable(byte *pc, size_t size)\n{\n    long res;\n    app_pc start_page = (app_pc)PAGE_START(pc);\n    size_t prot_size = (size == 0) ? PAGE_SIZE : size;\n    uint prot = PROT_EXEC | PROT_READ;\n    /* if can get current protection then keep old read/exec flags.\n     * this is crucial on modern linux kernels which refuse to mark stack +x.\n     */\n    if (!is_in_dynamo_dll(pc) /*avoid allmem assert*/ &&\n#ifdef STATIC_LIBRARY\n        /* FIXME i#975: is_in_dynamo_dll() is always false for STATIC_LIBRARY,\n         * but we can't call get_memory_info() until allmem is initialized.  Our\n         * uses before then are for patching x86.asm, which is OK.\n         */\n        IF_NO_MEMQUERY(memcache_initialized() &&)\n#endif\n            get_memory_info(pc, NULL, NULL, &prot))\n        prot &= ~PROT_WRITE;\n\n    ASSERT(start_page == pc && ALIGN_FORWARD(size, PAGE_SIZE) == size);\n    /* inc stats before making unwritable, in case messing w/ data segment */\n    STATS_INC(protection_change_calls);\n    STATS_ADD(protection_change_pages, size / PAGE_SIZE);\n    res = mprotect_syscall((void *)start_page, prot_size, prot);\n    LOG(THREAD_GET, LOG_VMAREAS, 3, \"make_unwritable: pc \" PFX \" -> \" PFX \"-\" PFX \"\\n\",\n        pc, start_page, start_page + prot_size);\n    ASSERT(res == 0);\n\n#ifndef HAVE_MEMINFO_QUERY\n    /* update all_memory_areas list with the protection change */\n    if (memcache_initialized()) {\n        memcache_update_locked(start_page, start_page + prot_size,\n                               osprot_to_memprot(prot), -1 /*type unchanged*/,\n                               false /*!exists*/);\n    }\n#endif\n}\n\n/****************************************************************************/\n/* SYSTEM CALLS */\n\n/* SYS_ defines are in /usr/include/bits/syscall.h\n * numbers used by libc are in /usr/include/asm/unistd.h\n * kernel defines are in /usr/src/linux-2.4/include/asm-i386/unistd.h\n * kernel function names are in /usr/src/linux/arch/i386/kernel/entry.S\n *\n * For now, we've copied the SYS/NR defines from syscall.h and unistd.h\n * and put them in our own local syscall.h.\n */\n\n/* num_raw should be the xax register value.\n * For a live system call, dcontext_live should be passed (for examining\n * the dcontext->last_exit and exit_reason flags); otherwise, gateway should\n * be passed.\n */\nint\nos_normalized_sysnum(int num_raw, instr_t *gateway, dcontext_t *dcontext)\n{\n#ifdef MACOS\n    /* The x64 encoding indicates the syscall type in the top 8 bits.\n     * We drop the 0x2000000 for BSD so we can use the SYS_ enum constants.\n     * That leaves 0x1000000 for Mach and 0x3000000 for Machdep.\n     * On 32-bit, a different encoding is used: we transform that\n     * to the x64 encoding minus BSD.\n     */\n    int interrupt = 0;\n    int num = 0;\n    if (gateway != NULL) {\n        if (instr_is_interrupt(gateway))\n            interrupt = instr_get_interrupt_number(gateway);\n    } else {\n        ASSERT(dcontext != NULL);\n        if (TEST(LINK_SPECIAL_EXIT, dcontext->last_exit->flags)) {\n            if (dcontext->upcontext.upcontext.exit_reason ==\n                EXIT_REASON_NI_SYSCALL_INT_0x81)\n                interrupt = 0x81;\n            else {\n                ASSERT(dcontext->upcontext.upcontext.exit_reason ==\n                       EXIT_REASON_NI_SYSCALL_INT_0x82);\n                interrupt = 0x82;\n            }\n        }\n    }\n#    ifdef X64\n    if (num_raw >> 24 == 0x2)\n        return (int)(num_raw & 0xffffff); /* Drop BSD bit */\n    else\n        num = (int)num_raw; /* Keep Mach and Machdep bits */\n#    else\n    if ((ptr_int_t)num_raw < 0) /* Mach syscall */\n        return (SYSCALL_NUM_MARKER_MACH | -(int)num_raw);\n    else {\n        /* Bottom 16 bits are the number, top are arg size. */\n        num = (int)(num_raw & 0xffff);\n    }\n#    endif\n    if (interrupt == 0x81)\n        num |= SYSCALL_NUM_MARKER_MACH;\n    else if (interrupt == 0x82)\n        num |= SYSCALL_NUM_MARKER_MACHDEP;\n    return num;\n#else\n    return num_raw;\n#endif\n}\n\nstatic bool\nignorable_system_call_normalized(int num)\n{\n    switch (num) {\n#if defined(SYS_exit_group)\n    case SYS_exit_group:\n#endif\n    case SYS_exit:\n#ifdef MACOS\n    case SYS_bsdthread_terminate:\n#endif\n#ifdef LINUX\n    case SYS_brk:\n#    ifdef SYS_uselib\n    case SYS_uselib:\n#    endif\n#endif\n#if defined(X64) || !defined(ARM)\n    case SYS_mmap:\n#endif\n#if !defined(X64) && !defined(MACOS)\n    case SYS_mmap2:\n#endif\n    case SYS_munmap:\n#ifdef LINUX\n    case SYS_mremap:\n#endif\n    case SYS_mprotect:\n#ifdef ANDROID\n    case SYS_prctl:\n#endif\n    case SYS_execve:\n#ifdef LINUX\n    case SYS_clone3:\n    case SYS_clone:\n#elif defined(MACOS)\n    case SYS_bsdthread_create:\n    case SYS_posix_spawn:\n#endif\n#ifdef SYS_fork\n    case SYS_fork:\n#endif\n#ifdef SYS_vfork\n    case SYS_vfork:\n#endif\n    case SYS_kill:\n#if defined(SYS_tkill)\n    case SYS_tkill:\n#endif\n#if defined(SYS_tgkill)\n    case SYS_tgkill:\n#endif\n#if defined(LINUX) && !defined(X64) && !defined(ARM)\n    case SYS_signal:\n#endif\n#ifdef MACOS\n    case SYS_sigsuspend_nocancel:\n#endif\n#if !defined(X64) || defined(MACOS)\n    case SYS_sigaction:\n    case SYS_sigsuspend:\n    case SYS_sigpending:\n    case SYS_sigreturn:\n    case SYS_sigprocmask:\n#endif\n#ifdef LINUX\n    case SYS_rt_sigreturn:\n    case SYS_rt_sigaction:\n    case SYS_rt_sigprocmask:\n    case SYS_rt_sigpending:\n#    ifdef SYS_rt_sigtimedwait_time64\n    case SYS_rt_sigtimedwait_time64:\n#    endif\n    case SYS_rt_sigtimedwait:\n    case SYS_rt_sigqueueinfo:\n    case SYS_rt_sigsuspend:\n#    ifdef SYS_signalfd\n    case SYS_signalfd:\n#    endif\n    case SYS_signalfd4:\n#endif\n    case SYS_sigaltstack:\n#if defined(LINUX) && !defined(X64) && !defined(ARM)\n    case SYS_sgetmask:\n    case SYS_ssetmask:\n#endif\n    case SYS_setitimer:\n    case SYS_getitimer:\n#ifdef MACOS\n    case SYS_close_nocancel:\n#endif\n#ifdef SYS_close_range\n    case SYS_close_range:\n#endif\n    case SYS_close:\n#ifdef SYS_dup2\n    case SYS_dup2:\n#endif\n#ifdef LINUX\n    case SYS_dup3:\n#endif\n#ifdef MACOS\n    case SYS_fcntl_nocancel:\n#endif\n    case SYS_fcntl:\n#if defined(X64) || !defined(ARM)\n    case SYS_getrlimit:\n#endif\n#if defined(LINUX) && !defined(X64)\n    case SYS_ugetrlimit:\n#endif\n    case SYS_setrlimit:\n#ifdef LINUX\n    case SYS_prlimit64:\n#endif\n#if defined(LINUX) && defined(X86)\n    /* i#784: app may have behavior relying on SIGALRM */\n    case SYS_alarm:\n#endif\n        /* i#107: syscall might change/query app's seg memory\n         * need stop app from clobbering our GDT slot.\n         */\n#if defined(LINUX) && defined(X86) && defined(X64)\n    case SYS_arch_prctl:\n#endif\n#if defined(LINUX) && defined(X86)\n    case SYS_set_thread_area:\n    case SYS_get_thread_area:\n        /* FIXME: we might add SYS_modify_ldt later. */\n#endif\n#if defined(LINUX) && defined(ARM)\n    /* syscall changes app's thread register */\n    case SYS_set_tls:\n    case SYS_cacheflush:\n#endif\n#if defined(LINUX)\n/* Syscalls change procsigmask */\n#    ifdef SYS_pselect6_time64\n    case SYS_pselect6_time64:\n#    endif\n    case SYS_pselect6:\n#    ifdef SYS_ppoll_time64\n    case SYS_ppoll_time64:\n#    endif\n    case SYS_ppoll:\n    case SYS_epoll_pwait:\n    /* Used as a lazy trigger. */\n    case SYS_rseq:\n#endif\n#ifdef DEBUG\n#    ifdef MACOS\n    case SYS_open_nocancel:\n#    endif\n#    ifdef SYS_open\n    case SYS_open:\n#    endif\n#endif\n        return false;\n#ifdef LINUX\n#    ifdef SYS_readlink\n    case SYS_readlink:\n#    endif\n    case SYS_readlinkat: return !DYNAMO_OPTION(early_inject);\n#endif\n#ifdef SYS_openat2\n    case SYS_openat2:\n#endif\n    case SYS_openat: return IS_STRING_OPTION_EMPTY(xarch_root);\n    default:\n#ifdef VMX86_SERVER\n        if (is_vmkuw_sysnum(num))\n            return vmkuw_ignorable_system_call(num);\n#endif\n        return true;\n    }\n}\n\nbool\nignorable_system_call(int num_raw, instr_t *gateway, dcontext_t *dcontext_live)\n{\n    return ignorable_system_call_normalized(\n        os_normalized_sysnum(num_raw, gateway, dcontext_live));\n}\n\ntypedef struct {\n    unsigned long addr;\n    unsigned long len;\n    unsigned long prot;\n    unsigned long flags;\n    unsigned long fd;\n    unsigned long offset;\n} mmap_arg_struct_t;\n\nstatic inline reg_t *\nsys_param_addr(dcontext_t *dcontext, int num)\n{\n    /* we force-inline get_mcontext() and so don't take it as a param */\n    priv_mcontext_t *mc = get_mcontext(dcontext);\n#if defined(X86) && defined(X64)\n    switch (num) {\n    case 0: return &mc->xdi;\n    case 1: return &mc->xsi;\n    case 2: return &mc->xdx;\n    case 3: return &mc->r10; /* since rcx holds retaddr for syscall instr */\n    case 4: return &mc->r8;\n    case 5: return &mc->r9;\n    default: CLIENT_ASSERT(false, \"invalid system call parameter number\");\n    }\n#else\n#    ifdef MACOS\n    /* XXX: if we don't end up using dcontext->sys_was_int here, we could\n     * make that field Linux-only.\n     */\n    /* For 32-bit, the args are passed on the stack, above a retaddr slot\n     * (regardless of whether using a sysenter or int gateway).\n     */\n    return ((reg_t *)mc->esp) + 1 /*retaddr*/ + num;\n#    endif\n    /* even for vsyscall where ecx (syscall) or esp (sysenter) are saved into\n     * ebp, the original parameter registers are not yet changed pre-syscall,\n     * except for ebp, which is pushed on the stack:\n     *     0xffffe400  55                   push   %ebp %esp -> %esp (%esp)\n     *     0xffffe401  89 cd                mov    %ecx -> %ebp\n     *     0xffffe403  0f 05                syscall -> %ecx\n     *\n     *     0xffffe400  51                   push   %ecx %esp -> %esp (%esp)\n     *     0xffffe401  52                   push   %edx %esp -> %esp (%esp)\n     *     0xffffe402  55                   push   %ebp %esp -> %esp (%esp)\n     *     0xffffe403  89 e5                mov    %esp -> %ebp\n     *     0xffffe405  0f 34                sysenter -> %esp\n     */\n    switch (num) {\n    case 0: return &mc->IF_X86_ELSE(xbx, r0);\n    case 1: return &mc->IF_X86_ELSE(xcx, r1);\n    case 2: return &mc->IF_X86_ELSE(xdx, r2);\n    case 3: return &mc->IF_X86_ELSE(xsi, r3);\n    case 4: return &mc->IF_X86_ELSE(xdi, r4);\n    /* FIXME: do a safe_read: but what about performance?\n     * See the #if 0 below, as well. */\n    case 5:\n        return IF_X86_ELSE((dcontext->sys_was_int ? &mc->xbp : ((reg_t *)mc->xsp)),\n                           &mc->r5);\n#    ifdef ARM\n    /* AArch32 supposedly has 7 args in some cases. */\n    case 6: return &mc->r6;\n#    endif\n    default: CLIENT_ASSERT(false, \"invalid system call parameter number\");\n    }\n#endif\n    return 0;\n}\n\nstatic inline reg_t\nsys_param(dcontext_t *dcontext, int num)\n{\n    return *sys_param_addr(dcontext, num);\n}\n\nvoid\nset_syscall_param(dcontext_t *dcontext, int param_num, reg_t new_value)\n{\n    *sys_param_addr(dcontext, param_num) = new_value;\n}\n\nstatic inline bool\nsyscall_successful(priv_mcontext_t *mc, int normalized_sysnum)\n{\n#ifdef MACOS\n    if (TEST(SYSCALL_NUM_MARKER_MACH, normalized_sysnum)) {\n        /* XXX: Mach syscalls vary (for some KERN_SUCCESS=0 is success,\n         * for others that return mach_port_t 0 is failure (I think?).\n         * We defer to drsyscall.\n         */\n        return ((ptr_int_t)MCXT_SYSCALL_RES(mc) >= 0);\n    } else\n        return !TEST(EFLAGS_CF, mc->xflags);\n#else\n    if (normalized_sysnum == IF_X64_ELSE(SYS_mmap, SYS_mmap2) ||\n#    if !defined(ARM) && !defined(X64)\n        normalized_sysnum == SYS_mmap ||\n#    endif\n        normalized_sysnum == SYS_mremap)\n        return mmap_syscall_succeeded((byte *)MCXT_SYSCALL_RES(mc));\n    return ((ptr_int_t)MCXT_SYSCALL_RES(mc) >= 0);\n#endif\n}\n\n/* For non-Mac, this does nothing to indicate \"success\": you can pass -errno.\n * For Mac, this clears CF and just sets xax.  To return a 64-bit value in\n * 32-bit mode, the caller must explicitly set xdx as well (we don't always\n * do so b/c syscalls that just return 32-bit values do not touch xdx).\n */\nstatic inline void\nset_success_return_val(dcontext_t *dcontext, reg_t val)\n{\n    /* since always coming from d_r_dispatch now, only need to set mcontext */\n    priv_mcontext_t *mc = get_mcontext(dcontext);\n#ifdef MACOS\n    /* On MacOS, success is determined by CF, except for Mach syscalls, but\n     * there it doesn't hurt to set CF.\n     */\n    mc->xflags &= ~(EFLAGS_CF);\n#endif\n    MCXT_SYSCALL_RES(mc) = val;\n}\n\n/* Always pass a positive value for errno */\nstatic inline void\nset_failure_return_val(dcontext_t *dcontext, uint errno_val)\n{\n    priv_mcontext_t *mc = get_mcontext(dcontext);\n#ifdef MACOS\n    /* On MacOS, success is determined by CF, and errno is positive */\n    mc->xflags |= EFLAGS_CF;\n    MCXT_SYSCALL_RES(mc) = errno_val;\n#else\n    MCXT_SYSCALL_RES(mc) = -(int)errno_val;\n#endif\n}\n\nDR_API\nreg_t\ndr_syscall_get_param(void *drcontext, int param_num)\n{\n    dcontext_t *dcontext = (dcontext_t *)drcontext;\n    CLIENT_ASSERT(dcontext->client_data->in_pre_syscall,\n                  \"dr_syscall_get_param() can only be called from pre-syscall event\");\n    return sys_param(dcontext, param_num);\n}\n\nDR_API\nvoid\ndr_syscall_set_param(void *drcontext, int param_num, reg_t new_value)\n{\n    dcontext_t *dcontext = (dcontext_t *)drcontext;\n    CLIENT_ASSERT(dcontext->client_data->in_pre_syscall ||\n                      dcontext->client_data->in_post_syscall,\n                  \"dr_syscall_set_param() can only be called from a syscall event\");\n    *sys_param_addr(dcontext, param_num) = new_value;\n}\n\nDR_API\nreg_t\ndr_syscall_get_result(void *drcontext)\n{\n    dcontext_t *dcontext = (dcontext_t *)drcontext;\n    CLIENT_ASSERT(dcontext->client_data->in_post_syscall,\n                  \"dr_syscall_get_param() can only be called from post-syscall event\");\n    return MCXT_SYSCALL_RES(get_mcontext(dcontext));\n}\n\nDR_API\nbool\ndr_syscall_get_result_ex(void *drcontext, dr_syscall_result_info_t *info INOUT)\n{\n    dcontext_t *dcontext = (dcontext_t *)drcontext;\n    priv_mcontext_t *mc = get_mcontext(dcontext);\n    CLIENT_ASSERT(dcontext->client_data->in_post_syscall,\n                  \"only call dr_syscall_get_param_ex() from post-syscall event\");\n    CLIENT_ASSERT(info != NULL, \"invalid parameter\");\n    CLIENT_ASSERT(info->size == sizeof(*info), \"invalid dr_syscall_result_info_t size\");\n    if (info->size != sizeof(*info))\n        return false;\n    info->value = MCXT_SYSCALL_RES(mc);\n    info->succeeded = syscall_successful(mc, dcontext->sys_num);\n    if (info->use_high) {\n        /* MacOS has some 32-bit syscalls that return 64-bit values in\n         * xdx:xax, but the other syscalls don't clear xdx, so we can't easily\n         * return a 64-bit value all the time.\n         */\n        IF_X86_ELSE({ info->high = mc->xdx; }, { ASSERT_NOT_REACHED(); });\n    }\n    if (info->use_errno) {\n        if (info->succeeded)\n            info->errno_value = 0;\n        else {\n            info->errno_value = (uint)IF_LINUX(-(int)) MCXT_SYSCALL_RES(mc);\n        }\n    }\n    return true;\n}\n\nDR_API\nvoid\ndr_syscall_set_result(void *drcontext, reg_t value)\n{\n    dcontext_t *dcontext = (dcontext_t *)drcontext;\n    CLIENT_ASSERT(dcontext->client_data->in_pre_syscall ||\n                      dcontext->client_data->in_post_syscall,\n                  \"dr_syscall_set_result() can only be called from a syscall event\");\n    /* For non-Mac, the caller can still pass -errno and this will work */\n    set_success_return_val(dcontext, value);\n}\n\nDR_API\nbool\ndr_syscall_set_result_ex(void *drcontext, dr_syscall_result_info_t *info)\n{\n    dcontext_t *dcontext = (dcontext_t *)drcontext;\n    priv_mcontext_t *mc = get_mcontext(dcontext);\n    CLIENT_ASSERT(dcontext->client_data->in_pre_syscall ||\n                      dcontext->client_data->in_post_syscall,\n                  \"dr_syscall_set_result() can only be called from a syscall event\");\n    CLIENT_ASSERT(info->size == sizeof(*info), \"invalid dr_syscall_result_info_t size\");\n    if (info->size != sizeof(*info))\n        return false;\n    if (info->use_errno) {\n        if (info->succeeded) {\n            /* a weird case but we let the user combine these */\n            set_success_return_val(dcontext, info->errno_value);\n        } else\n            set_failure_return_val(dcontext, info->errno_value);\n    } else {\n        if (info->succeeded)\n            set_success_return_val(dcontext, info->value);\n        else {\n            /* use this to set CF, even though it might negate the value */\n            set_failure_return_val(dcontext, (uint)info->value);\n            /* now set the value, overriding set_failure_return_val() */\n            MCXT_SYSCALL_RES(mc) = info->value;\n        }\n        if (info->use_high) {\n            /* MacOS has some 32-bit syscalls that return 64-bit values in\n             * xdx:xax.\n             */\n            IF_X86_ELSE({ mc->xdx = info->high; }, { ASSERT_NOT_REACHED(); });\n        }\n    }\n    return true;\n}\n\nDR_API\nvoid\ndr_syscall_set_sysnum(void *drcontext, int new_num)\n{\n    dcontext_t *dcontext = (dcontext_t *)drcontext;\n    priv_mcontext_t *mc = get_mcontext(dcontext);\n    CLIENT_ASSERT(dcontext->client_data->in_pre_syscall ||\n                      dcontext->client_data->in_post_syscall,\n                  \"dr_syscall_set_sysnum() can only be called from a syscall event\");\n    MCXT_SYSNUM_REG(mc) = new_num;\n}\n\nDR_API\nvoid\ndr_syscall_invoke_another(void *drcontext)\n{\n    dcontext_t *dcontext = (dcontext_t *)drcontext;\n    CLIENT_ASSERT(dcontext->client_data->in_post_syscall,\n                  \"dr_syscall_invoke_another() can only be called from post-syscall \"\n                  \"event\");\n    LOG(THREAD, LOG_SYSCALLS, 2, \"invoking additional syscall on client request\\n\");\n    dcontext->client_data->invoke_another_syscall = true;\n#ifdef X86\n    if (get_syscall_method() == SYSCALL_METHOD_SYSENTER) {\n        priv_mcontext_t *mc = get_mcontext(dcontext);\n        /* restore xbp to xsp */\n        mc->xbp = mc->xsp;\n    }\n#endif /* X86 */\n    /* for x64 we don't need to copy xcx into r10 b/c we use r10 as our param */\n}\n\nstatic inline bool\nis_thread_create_syscall_helper(ptr_uint_t sysnum, uint64 flags)\n{\n#ifdef MACOS\n    /* XXX i#1403: we need earlier injection to intercept\n     * bsdthread_register in order to capture workqueue threads.\n     */\n    return (sysnum == SYS_bsdthread_create || sysnum == SYS_vfork);\n#else\n#    ifdef SYS_vfork\n    if (sysnum == SYS_vfork)\n        return true;\n#    endif\n#    ifdef LINUX\n    if ((sysnum == SYS_clone || sysnum == SYS_clone3) && TEST(CLONE_VM, flags))\n        return true;\n#    endif\n    return false;\n#endif\n}\n\nbool\nis_thread_create_syscall(dcontext_t *dcontext _IF_LINUX(void *maybe_clone_args))\n{\n    priv_mcontext_t *mc = get_mcontext(dcontext);\n    uint64 flags = sys_param(dcontext, 0);\n    ptr_uint_t sysnum = MCXT_SYSNUM_REG(mc);\n#ifdef LINUX\n    /* For clone3, we use flags from the clone_args that was obtained using a\n     * a safe read from the user-provided syscall args.\n     */\n    if (sysnum == SYS_clone3) {\n        ASSERT(maybe_clone_args != NULL);\n        flags = ((clone3_syscall_args_t *)maybe_clone_args)->flags;\n    }\n#endif\n    return is_thread_create_syscall_helper(sysnum, flags);\n}\n\n#ifdef LINUX\nstatic ptr_uint_t\nget_stored_clone3_flags(dcontext_t *dcontext)\n{\n    return ((uint64)dcontext->sys_param4 << 32) | dcontext->sys_param3;\n}\n#endif\n\nbool\nwas_thread_create_syscall(dcontext_t *dcontext)\n{\n    uint64 flags = dcontext->sys_param0;\n#ifdef LINUX\n    if (dcontext->sys_num == SYS_clone3)\n        flags = get_stored_clone3_flags(dcontext);\n#endif\n    return is_thread_create_syscall_helper(dcontext->sys_num, flags);\n}\n\nbool\nis_sigreturn_syscall_number(int sysnum)\n{\n#ifdef MACOS\n    return sysnum == SYS_sigreturn;\n#else\n    return (IF_NOT_X64(sysnum == SYS_sigreturn ||) sysnum == SYS_rt_sigreturn);\n#endif\n}\n\nbool\nis_sigreturn_syscall(dcontext_t *dcontext)\n{\n    priv_mcontext_t *mc = get_mcontext(dcontext);\n    return is_sigreturn_syscall_number(MCXT_SYSNUM_REG(mc));\n}\n\nbool\nwas_sigreturn_syscall(dcontext_t *dcontext)\n{\n    return is_sigreturn_syscall_number(dcontext->sys_num);\n}\n\n/* process a signal this process/thread is sending to itself */\nstatic void\nhandle_self_signal(dcontext_t *dcontext, uint sig)\n{\n    /* FIXME PR 297903: watch for all DEFAULT_TERMINATE signals,\n     * and for any thread in the group, not just self.\n     *\n     * FIXME PR 297033: watch for SIGSTOP and SIGCONT.\n     *\n     * With -intercept_all_signals, we only need to watch for SIGKILL\n     * and SIGSTOP here, and we avoid the FIXMEs below.  If it's fine\n     * for DR not to clean up on a SIGKILL, then SIGSTOP is all that's\n     * left (at least once we have PR 297033 and are intercepting the\n     * various STOP variations and CONT).\n     */\n    if (sig == SIGABRT && !DYNAMO_OPTION(intercept_all_signals)) {\n        LOG(GLOBAL, LOG_TOP | LOG_SYSCALLS, 1,\n            \"thread \" TIDFMT \" sending itself a SIGABRT\\n\", d_r_get_thread_id());\n        KSTOP(num_exits_dir_syscall);\n        /* FIXME: need to check whether app has a handler for SIGABRT! */\n        /* FIXME PR 211180/6723: this will do SYS_exit rather than the SIGABRT.\n         * Should do set_default_signal_action(SIGABRT) (and set a flag so\n         * no races w/ another thread re-installing?) and then SYS_kill.\n         */\n        block_cleanup_and_terminate(dcontext, SYSNUM_EXIT_THREAD, -1, 0,\n                                    (is_last_app_thread() && !dynamo_exited),\n                                    IF_MACOS_ELSE(dcontext->thread_port, 0), 0);\n        ASSERT_NOT_REACHED();\n    }\n}\n\n/***************************************************************************\n * EXECVE\n */\n\n/* when adding here, also add to the switch in handle_execve if necessary */\nenum {\n    ENV_PROP_RUNUNDER,\n    ENV_PROP_OPTIONS,\n    ENV_PROP_EXECVE_LOGDIR,\n    ENV_PROP_EXE_PATH,\n    ENV_PROP_CONFIGDIR,\n};\n\nstatic const char *const env_to_propagate[] = {\n    /* these must line up with the enum */\n    DYNAMORIO_VAR_RUNUNDER,\n    DYNAMORIO_VAR_OPTIONS,\n    /* DYNAMORIO_VAR_EXECVE_LOGDIR is different from DYNAMORIO_VAR_LOGDIR:\n     * - DYNAMORIO_VAR_LOGDIR: a parent dir inside which a new dir will be created;\n     * - DYNAMORIO_VAR_EXECVE_LOGDIR: the same subdir with the pre-execve process.\n     * Xref comment in create_log_dir about their precedence.\n     */\n    DYNAMORIO_VAR_EXECVE_LOGDIR,\n    /* i#909: needed for early injection */\n    DYNAMORIO_VAR_EXE_PATH,\n    /* these will only be propagated if they exist */\n    DYNAMORIO_VAR_CONFIGDIR,\n};\n#define NUM_ENV_TO_PROPAGATE (sizeof(env_to_propagate) / sizeof(env_to_propagate[0]))\n\n/* Called at pre-SYS_execve to append DR vars in the target process env vars list.\n * For late injection via libdrpreload, we call this for *all children, because\n * even if -no_follow_children is specified, a whitelist will still ask for takeover\n * and it's libdrpreload who checks the whitelist.\n * For -early, however, we check the config ahead of time and only call this routine\n * if we in fact want to inject.\n * XXX i#1679: these parent vs child differences bring up corner cases of which\n * config dir takes precedence (if the child clears the HOME env var, e.g.).\n */\nstatic void\nadd_dr_env_vars(dcontext_t *dcontext, char *inject_library_path, const char *app_path)\n{\n    char **envp = (char **)sys_param(dcontext, 2);\n    int idx, j, preload = -1, ldpath = -1;\n    int num_old, num_new, sz;\n    bool need_var[NUM_ENV_TO_PROPAGATE];\n    int prop_idx[NUM_ENV_TO_PROPAGATE];\n    bool ldpath_us = false, preload_us = false;\n    char **new_envp, *var, *old;\n\n    /* check if any var needs to be propagated */\n    for (j = 0; j < NUM_ENV_TO_PROPAGATE; j++) {\n        prop_idx[j] = -1;\n        if (get_config_val(env_to_propagate[j]) == NULL)\n            need_var[j] = false;\n        else\n            need_var[j] = true;\n    }\n    /* Special handling for DYNAMORIO_VAR_EXECVE_LOGDIR:\n     * we only need it if follow_children is true and PROCESS_DIR exists.\n     */\n    if (DYNAMO_OPTION(follow_children) && get_log_dir(PROCESS_DIR, NULL, NULL))\n        need_var[ENV_PROP_EXECVE_LOGDIR] = true;\n    else\n        need_var[ENV_PROP_EXECVE_LOGDIR] = false;\n\n    if (DYNAMO_OPTION(early_inject))\n        need_var[ENV_PROP_EXE_PATH] = true;\n\n    /* iterate the env in target process  */\n    if (envp == NULL) {\n        LOG(THREAD, LOG_SYSCALLS, 3, \"\\tenv is NULL\\n\");\n        idx = 0;\n    } else {\n        for (idx = 0; envp[idx] != NULL; idx++) {\n            /* execve env vars should never be set here */\n            ASSERT(strstr(envp[idx], DYNAMORIO_VAR_EXECVE) != envp[idx]);\n            for (j = 0; j < NUM_ENV_TO_PROPAGATE; j++) {\n                if (strstr(envp[idx], env_to_propagate[j]) == envp[idx]) {\n                    /* If conflict between env and cfg, we assume those env vars\n                     * are for DR usage only, and replace them with cfg value.\n                     */\n                    prop_idx[j] = idx; /* remember the index for replacing later */\n                    break;\n                }\n            }\n            if (!DYNAMO_OPTION(early_inject) &&\n                strstr(envp[idx], \"LD_LIBRARY_PATH=\") == envp[idx]) {\n                ldpath = idx;\n                if (strstr(envp[idx], inject_library_path) != NULL)\n                    ldpath_us = true;\n            }\n            if (!DYNAMO_OPTION(early_inject) &&\n                strstr(envp[idx], \"LD_PRELOAD=\") == envp[idx]) {\n                preload = idx;\n                if (strstr(envp[idx], DYNAMORIO_PRELOAD_NAME) != NULL &&\n                    strstr(envp[idx], get_dynamorio_library_path()) != NULL) {\n                    preload_us = true;\n                }\n            }\n            LOG(THREAD, LOG_SYSCALLS, 3, \"\\tenv %d: %s\\n\", idx, envp[idx]);\n        }\n    }\n\n    /* We want to add new env vars, so we create a new envp\n     * array.  We have to deallocate them and restore the old\n     * envp if execve fails; if execve succeeds, the address\n     * space is reset so we don't need to do anything.\n     */\n    num_old = idx;\n    /* how many new env vars we need add */\n    num_new = 2 + /* execve indicator var plus final NULL */\n        (DYNAMO_OPTION(early_inject)\n             ? 0\n             : (((preload < 0) ? 1 : 0) + ((ldpath < 0) ? 1 : 0)));\n\n    for (j = 0; j < NUM_ENV_TO_PROPAGATE; j++) {\n        if ((DYNAMO_OPTION(follow_children) || j == ENV_PROP_EXE_PATH) && need_var[j] &&\n            prop_idx[j] < 0)\n            num_new++;\n    }\n    /* setup new envp */\n    new_envp =\n        heap_alloc(dcontext, sizeof(char *) * (num_old + num_new) HEAPACCT(ACCT_OTHER));\n    /* copy old envp */\n    memcpy(new_envp, envp, sizeof(char *) * num_old);\n    /* change/add preload and ldpath if necessary */\n    if (!DYNAMO_OPTION(early_inject) && !preload_us) {\n        int idx_preload;\n        LOG(THREAD, LOG_SYSCALLS, 1,\n            \"WARNING: execve env does NOT preload DynamoRIO, forcing it!\\n\");\n        if (preload >= 0) {\n            /* replace the existing preload */\n            const char *dr_lib_path = get_dynamorio_library_path();\n            sz = strlen(envp[preload]) + strlen(DYNAMORIO_PRELOAD_NAME) +\n                strlen(dr_lib_path) + 3;\n            var = heap_alloc(dcontext, sizeof(char) * sz HEAPACCT(ACCT_OTHER));\n            old = envp[preload] + strlen(\"LD_PRELOAD=\");\n            snprintf(var, sz, \"LD_PRELOAD=%s %s %s\", DYNAMORIO_PRELOAD_NAME, dr_lib_path,\n                     old);\n            idx_preload = preload;\n        } else {\n            /* add new preload */\n            const char *dr_lib_path = get_dynamorio_library_path();\n            sz = strlen(\"LD_PRELOAD=\") + strlen(DYNAMORIO_PRELOAD_NAME) +\n                strlen(dr_lib_path) + 2;\n            var = heap_alloc(dcontext, sizeof(char) * sz HEAPACCT(ACCT_OTHER));\n            snprintf(var, sz, \"LD_PRELOAD=%s %s\", DYNAMORIO_PRELOAD_NAME, dr_lib_path);\n            idx_preload = idx++;\n        }\n        *(var + sz - 1) = '\\0'; /* null terminate */\n        new_envp[idx_preload] = var;\n        LOG(THREAD, LOG_SYSCALLS, 2, \"\\tnew env %d: %s\\n\", idx_preload,\n            new_envp[idx_preload]);\n    }\n    if (!DYNAMO_OPTION(early_inject) && !ldpath_us) {\n        int idx_ldpath;\n        if (ldpath >= 0) {\n            sz = strlen(envp[ldpath]) + strlen(inject_library_path) + 2;\n            var = heap_alloc(dcontext, sizeof(char) * sz HEAPACCT(ACCT_OTHER));\n            old = envp[ldpath] + strlen(\"LD_LIBRARY_PATH=\");\n            snprintf(var, sz, \"LD_LIBRARY_PATH=%s:%s\", inject_library_path, old);\n            idx_ldpath = ldpath;\n        } else {\n            sz = strlen(\"LD_LIBRARY_PATH=\") + strlen(inject_library_path) + 1;\n            var = heap_alloc(dcontext, sizeof(char) * sz HEAPACCT(ACCT_OTHER));\n            snprintf(var, sz, \"LD_LIBRARY_PATH=%s\", inject_library_path);\n            idx_ldpath = idx++;\n        }\n        *(var + sz - 1) = '\\0'; /* null terminate */\n        new_envp[idx_ldpath] = var;\n        LOG(THREAD, LOG_SYSCALLS, 2, \"\\tnew env %d: %s\\n\", idx_ldpath,\n            new_envp[idx_ldpath]);\n    }\n    /* propagating DR env vars */\n    for (j = 0; j < NUM_ENV_TO_PROPAGATE; j++) {\n        const char *val = \"\";\n        if (!need_var[j])\n            continue;\n        if (!DYNAMO_OPTION(follow_children) && j != ENV_PROP_EXE_PATH)\n            continue;\n        switch (j) {\n        case ENV_PROP_RUNUNDER:\n            ASSERT(strcmp(env_to_propagate[j], DYNAMORIO_VAR_RUNUNDER) == 0);\n            /* Must pass RUNUNDER_ALL to get child injected if has no app config.\n             * If rununder var is already set we assume it's set to 1.\n             */\n            ASSERT((RUNUNDER_ON | RUNUNDER_ALL) == 0x3); /* else, update \"3\" */\n            val = \"3\";\n            break;\n        case ENV_PROP_OPTIONS:\n            ASSERT(strcmp(env_to_propagate[j], DYNAMORIO_VAR_OPTIONS) == 0);\n            val = d_r_option_string;\n            break;\n        case ENV_PROP_EXECVE_LOGDIR:\n            /* we use PROCESS_DIR for DYNAMORIO_VAR_EXECVE_LOGDIR */\n            ASSERT(strcmp(env_to_propagate[j], DYNAMORIO_VAR_EXECVE_LOGDIR) == 0);\n            ASSERT(get_log_dir(PROCESS_DIR, NULL, NULL));\n            break;\n        case ENV_PROP_EXE_PATH:\n            ASSERT(strcmp(env_to_propagate[j], DYNAMORIO_VAR_EXE_PATH) == 0);\n            val = app_path;\n            break;\n        default:\n            val = getenv(env_to_propagate[j]);\n            if (val == NULL)\n                val = \"\";\n            break;\n        }\n        if (j == ENV_PROP_EXECVE_LOGDIR) {\n            uint logdir_length;\n            get_log_dir(PROCESS_DIR, NULL, &logdir_length);\n            /* logdir_length includes the terminating NULL */\n            sz = strlen(DYNAMORIO_VAR_EXECVE_LOGDIR) + logdir_length + 1 /* '=' */;\n            var = heap_alloc(dcontext, sizeof(char) * sz HEAPACCT(ACCT_OTHER));\n            snprintf(var, sz, \"%s=\", DYNAMORIO_VAR_EXECVE_LOGDIR);\n            get_log_dir(PROCESS_DIR, var + strlen(var), &logdir_length);\n        } else {\n            sz = strlen(env_to_propagate[j]) + strlen(val) + 2 /* '=' + null */;\n            var = heap_alloc(dcontext, sizeof(char) * sz HEAPACCT(ACCT_OTHER));\n            snprintf(var, sz, \"%s=%s\", env_to_propagate[j], val);\n        }\n        *(var + sz - 1) = '\\0'; /* null terminate */\n        prop_idx[j] = (prop_idx[j] >= 0) ? prop_idx[j] : idx++;\n        new_envp[prop_idx[j]] = var;\n        LOG(THREAD, LOG_SYSCALLS, 2, \"\\tnew env %d: %s\\n\", prop_idx[j],\n            new_envp[prop_idx[j]]);\n    }\n    if (!DYNAMO_OPTION(follow_children) && !DYNAMO_OPTION(early_inject)) {\n        if (prop_idx[ENV_PROP_RUNUNDER] >= 0) {\n            /* disable auto-following of this execve, yet still allow preload\n             * on other side to inject if config file exists.\n             * kind of hacky mangle here:\n             */\n            ASSERT(!need_var[ENV_PROP_RUNUNDER]);\n            ASSERT(new_envp[prop_idx[ENV_PROP_RUNUNDER]][0] == 'D');\n            new_envp[prop_idx[ENV_PROP_RUNUNDER]][0] = 'X';\n        }\n    }\n\n    sz = strlen(DYNAMORIO_VAR_EXECVE) + 4;\n    /* we always pass this var to indicate \"post-execve\" */\n    var = heap_alloc(dcontext, sizeof(char) * sz HEAPACCT(ACCT_OTHER));\n    /* PR 458917: we overload this to also pass our gdt index */\n    ASSERT(os_tls_get_gdt_index(dcontext) < 100 &&\n           os_tls_get_gdt_index(dcontext) >= -1); /* only 2 chars allocated */\n    snprintf(var, sz, \"%s=%02d\", DYNAMORIO_VAR_EXECVE, os_tls_get_gdt_index(dcontext));\n    *(var + sz - 1) = '\\0'; /* null terminate */\n    new_envp[idx++] = var;\n    LOG(THREAD, LOG_SYSCALLS, 2, \"\\tnew env %d: %s\\n\", idx - 1, new_envp[idx - 1]);\n    /* must end with NULL */\n    new_envp[idx++] = NULL;\n    ASSERT((num_new + num_old) == idx);\n\n    /* update syscall param */\n    *sys_param_addr(dcontext, 2) = (reg_t)new_envp; /* OUT */\n    /* store for reset in case execve fails, and for cleanup if\n     * this is a vfork thread\n     */\n    dcontext->sys_param0 = (reg_t)envp;\n    dcontext->sys_param1 = (reg_t)new_envp;\n}\n\nstatic ssize_t\nscript_file_reader(const char *pathname, void *buf, size_t count)\n{\n    /* FIXME i#2090: Check file is executable. */\n    file_t file = os_open(pathname, OS_OPEN_READ);\n    size_t len;\n\n    if (file == INVALID_FILE)\n        return -1;\n    len = os_read(file, buf, count);\n    os_close(file);\n    return len;\n}\n\n/* For early injection, recognise when the executable is a script (\"#!\") and\n * modify the syscall parameters to invoke a script interpreter instead. In\n * this case we will have allocated memory here but we expect the caller to\n * do a non-failing execve of libdynamorio.so and therefore not to have to\n * free the memory. That is one reason for checking that the (final) script\n * interpreter really is an executable binary.\n * We recognise one error case here and return the non-zero error code (ELOOP)\n * but in other cases we leave it up to the caller to detect the error, which\n * it may do by attempting to exec the path natively, expecting this to fail,\n * though there is the obvious danger that the file might have been modified\n * just before the exec.\n * We do not, and cannot easily, handle a file that is executable but not\n * readable. Currently such files will be executed without DynamoRIO though\n * in some situations it would be more helpful to stop with an error.\n *\n * XXX: There is a minor transparency bug with misformed binaries. For example,\n * execve can return EINVAL if the ELF executable has more than one PT_INTERP\n * segment but we do not check this and so under DynamoRIO the error would be\n * detected only after the exec, if we are following the child.\n *\n * FIXME i#2091: There is a memory leak if a script is recognised, and it is\n * later decided not to inject (see where should_inject is set), and the exec\n * fails, because in this case there is no mechanism for freeing the memory\n * allocated in this function. This function should return sufficient information\n * for the caller to free the memory, which it can do so before the exec if it\n * reverts to the original syscall arguments and execs the script.\n */\nstatic int\nhandle_execve_script(dcontext_t *dcontext)\n{\n    char *fname = (char *)sys_param(dcontext, 0);\n    char **orig_argv = (char **)sys_param(dcontext, 1);\n    script_interpreter_t *script;\n    int ret = 0;\n\n    script = global_heap_alloc(sizeof(*script) HEAPACCT(ACCT_OTHER));\n    if (!find_script_interpreter(script, fname, script_file_reader))\n        goto free_and_return;\n\n    if (script->argc == 0) {\n        ret = ELOOP;\n        goto free_and_return;\n    }\n\n    /* Check that the final interpreter is an executable binary. */\n    {\n        file_t file = os_open(script->argv[0], OS_OPEN_READ);\n        bool is64;\n        if (file == INVALID_FILE)\n            goto free_and_return;\n        if (!module_file_is_module64(file, &is64, NULL)) {\n            os_close(file);\n            goto free_and_return;\n        }\n    }\n\n    {\n        size_t i, orig_argc = 0;\n        char **new_argv;\n\n        /* Concatenate new arguments and original arguments. */\n        while (orig_argv[orig_argc] != NULL)\n            ++orig_argc;\n        if (orig_argc == 0)\n            orig_argc = 1;\n        new_argv = global_heap_alloc((script->argc + orig_argc + 1) *\n                                     sizeof(char *) HEAPACCT(ACCT_OTHER));\n        for (i = 0; i < script->argc; i++)\n            new_argv[i] = script->argv[i];\n        new_argv[script->argc] = fname; /* replaces orig_argv[0] */\n        for (i = 1; i < orig_argc; i++)\n            new_argv[script->argc + i] = orig_argv[i];\n        new_argv[script->argc + orig_argc] = NULL;\n\n        /* Modify syscall parameters. */\n        *sys_param_addr(dcontext, 0) = (reg_t)new_argv[0];\n        *sys_param_addr(dcontext, 1) = (reg_t)new_argv;\n    }\n    return 0;\n\nfree_and_return:\n    global_heap_free(script, sizeof(*script) HEAPACCT(ACCT_OTHER));\n    return ret;\n}\n\nstatic int\nhandle_execve(dcontext_t *dcontext)\n{\n    /* in /usr/src/linux/arch/i386/kernel/process.c:\n     *  asmlinkage int sys_execve(struct pt_regs regs) { ...\n     *  error = do_execve(filename, (char **) regs.xcx, (char **) regs.xdx, &regs);\n     * in fs/exec.c:\n     *  int do_execve(char * filename, char ** argv, char ** envp, struct pt_regs * regs)\n     */\n    /* We need to make sure we get injected into the new image:\n     * we simply make sure LD_PRELOAD contains us, and that our directory\n     * is on LD_LIBRARY_PATH (seems not to work to put absolute paths in\n     * LD_PRELOAD).\n     * FIXME: this doesn't work for setuid programs\n     *\n     * For -follow_children we also pass the current DYNAMORIO_RUNUNDER and\n     * DYNAMORIO_OPTIONS and logdir to the new image to support a simple\n     * run-all-children model without bothering w/ setting up config files for\n     * children, and to support injecting across execve that does not\n     * preserve $HOME.\n     * FIXME i#287/PR 546544: we'll need to propagate DYNAMORIO_AUTOINJECT too\n     * once we use it in preload\n     */\n    /* FIXME i#191: supposed to preserve things like pending signal\n     * set across execve: going to ignore for now\n     */\n    char *fname;\n    bool x64 = IF_X64_ELSE(true, false);\n    bool expect_to_fail = false;\n    bool should_inject;\n    file_t file;\n    char *inject_library_path;\n    char rununder_buf[16]; /* just an integer printed in ascii */\n    bool app_specific, from_env, rununder_on;\n#if defined(LINUX) || defined(DEBUG)\n    const char **argv;\n#endif\n\n    if (DYNAMO_OPTION(follow_children) && DYNAMO_OPTION(early_inject)) {\n        int ret = handle_execve_script(dcontext);\n        if (ret != 0)\n            return ret;\n    }\n\n    fname = (char *)sys_param(dcontext, 0);\n#if defined(LINUX) || defined(DEBUG)\n    argv = (const char **)sys_param(dcontext, 1);\n#endif\n\n#ifdef LINUX\n    if (DYNAMO_OPTION(early_inject) && symlink_is_self_exe(fname)) {\n        /* i#907: /proc/self/exe points at libdynamorio.so.  Make sure we run\n         * the right thing here.\n         */\n        fname = get_application_name();\n    }\n#endif\n\n    LOG(GLOBAL, LOG_ALL, 1,\n        \"\\n---------------------------------------------------------------------------\"\n        \"\\n\");\n    LOG(THREAD, LOG_ALL, 1,\n        \"\\n---------------------------------------------------------------------------\"\n        \"\\n\");\n    DODEBUG({\n        int i;\n        SYSLOG_INTERNAL_INFO(\"-- execve %s --\", fname);\n        LOG(THREAD, LOG_SYSCALLS, 1, \"syscall: execve %s\\n\", fname);\n        LOG(GLOBAL, LOG_TOP | LOG_SYSCALLS, 1, \"execve %s\\n\", fname);\n        if (d_r_stats->loglevel >= 3) {\n            if (argv == NULL) {\n                LOG(THREAD, LOG_SYSCALLS, 3, \"\\targs are NULL\\n\");\n            } else {\n                for (i = 0; argv[i] != NULL; i++) {\n                    LOG(THREAD, LOG_SYSCALLS, 2, \"\\targ %d: len=%d\\n\", i,\n                        strlen(argv[i]));\n                    LOG(THREAD, LOG_SYSCALLS, 3, \"\\targ %d: %s\\n\", i, argv[i]);\n                }\n            }\n        }\n    });\n\n    /* i#237/PR 498284: if we're a vfork \"thread\" we're really in a different\n     * process and if we exec then the parent process will still be alive.  We\n     * can't easily clean our own state (dcontext, dstack, etc.) up in our\n     * parent process: we need it to invoke the syscall and the syscall might\n     * fail.  We could expand cleanup_and_terminate to also be able to invoke\n     * SYS_execve: but execve seems more likely to fail than termination\n     * syscalls.  Our solution is to mark this thread as \"execve\" and hide it\n     * from regular thread queries; we clean it up in the process-exiting\n     * synch_with_thread(), or if the same parent thread performs another vfork\n     * (to prevent heap accumulation from repeated vfork+execve).  Since vfork\n     * on linux suspends the parent, there cannot be any races with the execve\n     * syscall completing: there can't even be peer vfork threads, so we could\n     * set a flag and clean up in d_r_dispatch, but that seems overkill.  (If vfork\n     * didn't suspend the parent we'd need to touch a marker file or something\n     * to know the execve was finished.)\n     */\n    mark_thread_execve(dcontext->thread_record, true);\n\n#ifdef STATIC_LIBRARY\n    /* no way we can inject, we just lose control */\n    SYSLOG_INTERNAL_WARNING(\"WARNING: static DynamoRIO library, losing control on \"\n                            \"execve\");\n    return 0;\n#endif\n\n    /* Issue 20: handle cross-architecture execve */\n    file = os_open(fname, OS_OPEN_READ);\n    if (file != INVALID_FILE) {\n        if (!module_file_is_module64(file, &x64,\n                                     NULL /*only care about primary==execve*/))\n            expect_to_fail = true;\n        os_close(file);\n    } else\n        expect_to_fail = true;\n    inject_library_path =\n        IF_X64_ELSE(x64, !x64) ? dynamorio_library_path : dynamorio_alt_arch_path;\n\n    should_inject = DYNAMO_OPTION(follow_children);\n    if (get_config_val_other_app(get_short_name(fname), get_process_id(),\n                                 x64 ? DR_PLATFORM_64BIT : DR_PLATFORM_32BIT,\n                                 DYNAMORIO_VAR_RUNUNDER, rununder_buf,\n                                 BUFFER_SIZE_ELEMENTS(rununder_buf), &app_specific,\n                                 &from_env, NULL /* 1config is ok */)) {\n        if (should_inject_from_rununder(rununder_buf, app_specific, from_env,\n                                        &rununder_on))\n            should_inject = rununder_on;\n    }\n\n    if (should_inject)\n        add_dr_env_vars(dcontext, inject_library_path, fname);\n    else {\n        dcontext->sys_param0 = 0;\n        dcontext->sys_param1 = 0;\n    }\n\n#ifdef LINUX\n    /* We have to be accurate with expect_to_fail as we cannot come back\n     * and fail the syscall once the kernel execs DR!\n     */\n    if (should_inject && DYNAMO_OPTION(early_inject) && !expect_to_fail) {\n        /* i#909: change the target image to libdynamorio.so */\n        const char *drpath = IF_X64_ELSE(x64, !x64) ? dynamorio_library_filepath\n                                                    : dynamorio_alt_arch_filepath;\n        TRY_EXCEPT(dcontext, /* try */\n                   {\n                       if (symlink_is_self_exe(argv[0])) {\n                           /* we're out of sys_param entries so we assume argv[0] == fname\n                            */\n                           dcontext->sys_param3 = (reg_t)argv;\n                           argv[0] = fname; /* XXX: handle readable but not writable! */\n                       } else\n                           dcontext->sys_param3 = 0; /* no restore in post */\n                       dcontext->sys_param4 =\n                           (reg_t)fname; /* store for restore in post */\n                       *sys_param_addr(dcontext, 0) = (reg_t)drpath;\n                       LOG(THREAD, LOG_SYSCALLS, 2, \"actual execve on: %s\\n\",\n                           (char *)sys_param(dcontext, 0));\n                   },\n                   /* except */\n                   {\n                       dcontext->sys_param3 = 0; /* no restore in post */\n                       dcontext->sys_param4 = 0; /* no restore in post */\n                       LOG(THREAD, LOG_SYSCALLS, 2,\n                           \"argv is unreadable, expect execve to fail\\n\");\n                   });\n    } else {\n        dcontext->sys_param3 = 0; /* no restore in post */\n        dcontext->sys_param4 = 0; /* no restore in post */\n    }\n#endif\n\n    /* we need to clean up the .1config file here.  if the execve fails,\n     * we'll just live w/o dynamic option re-read.\n     */\n    d_r_config_exit();\n    return 0;\n}\n\nstatic void\nhandle_execve_post(dcontext_t *dcontext)\n{\n    /* if we get here it means execve failed (doesn't return on success),\n     * or we did an execve from a vfork and its memory changes are visible\n     * in the parent process.\n     * we have to restore env to how it was and free the allocated heap.\n     */\n    char **old_envp = (char **)dcontext->sys_param0;\n    char **new_envp = (char **)dcontext->sys_param1;\n#ifdef STATIC_LIBRARY\n    /* nothing to clean up */\n    return;\n#endif\n#ifdef LINUX\n    if (dcontext->sys_param4 != 0) {\n        /* restore original /proc/.../exe */\n        *sys_param_addr(dcontext, 0) = dcontext->sys_param4;\n        if (dcontext->sys_param3 != 0) {\n            /* restore original argv[0] */\n            const char **argv = (const char **)dcontext->sys_param3;\n            argv[0] = (const char *)dcontext->sys_param4;\n        }\n    }\n#endif\n    if (new_envp != NULL) {\n        int i;\n        LOG(THREAD, LOG_SYSCALLS, 2, \"\\tcleaning up our env vars\\n\");\n        /* we replaced existing ones and/or added new ones.\n         * we can't compare to old_envp b/c it may have changed by now.\n         */\n        for (i = 0; new_envp[i] != NULL; i++) {\n            if (is_dynamo_address((byte *)new_envp[i])) {\n                heap_free(dcontext, new_envp[i],\n                          sizeof(char) * (strlen(new_envp[i]) + 1) HEAPACCT(ACCT_OTHER));\n            }\n        }\n        i++; /* need to de-allocate final null slot too */\n        heap_free(dcontext, new_envp, sizeof(char *) * i HEAPACCT(ACCT_OTHER));\n        /* restore prev envp if we're post-syscall */\n        if (!dcontext->thread_record->execve)\n            *sys_param_addr(dcontext, 2) = (reg_t)old_envp;\n    }\n}\n\n/* i#237/PR 498284: to avoid accumulation of thread state we clean up a vfork\n * child who invoked execve here so we have at most one outstanding thread.  we\n * also clean up at process exit and before thread creation.  we could do this\n * in d_r_dispatch but too rare to be worth a flag check there.\n */\nstatic void\ncleanup_after_vfork_execve(dcontext_t *dcontext)\n{\n    thread_record_t **threads;\n    int num_threads, i;\n    if (num_execve_threads == 0)\n        return;\n\n    d_r_mutex_lock(&thread_initexit_lock);\n    get_list_of_threads_ex(&threads, &num_threads, true /*include execve*/);\n    for (i = 0; i < num_threads; i++) {\n        if (threads[i]->execve) {\n            LOG(THREAD, LOG_SYSCALLS, 2, \"cleaning up earlier vfork thread \" TIDFMT \"\\n\",\n                threads[i]->id);\n            dynamo_other_thread_exit(threads[i]);\n        }\n    }\n    d_r_mutex_unlock(&thread_initexit_lock);\n    global_heap_free(threads,\n                     num_threads * sizeof(thread_record_t *) HEAPACCT(ACCT_THREAD_MGT));\n}\n\nstatic void\nset_stdfile_fileno(stdfile_t **stdfile, file_t file_no)\n{\n#ifdef STDFILE_FILENO\n    (*stdfile)->STDFILE_FILENO = file_no;\n#else\n#    warning stdfile_t is opaque; DynamoRIO will not set fds of libc FILEs.\n    /* i#1973: musl libc support (and potentially other non-glibcs) */\n    /* only called by handle_close_pre(), so warning is specific to that. */\n    SYSLOG_INTERNAL_WARNING_ONCE(\n        \"DynamoRIO cannot set the file descriptors of private libc FILEs on \"\n        \"this platform. Client usage of stdio.h stdin, stdout, or stderr may \"\n        \"no longer work as expected, because the app is closing the UNIX fds \"\n        \"backing these.\");\n#endif\n}\n\n/* returns whether to execute syscall */\nstatic bool\nhandle_close_generic_pre(dcontext_t *dcontext, file_t fd, bool set_return_val)\n{\n    LOG(THREAD, LOG_SYSCALLS, 3, \"syscall: close fd %d\\n\", fd);\n\n    /* prevent app from closing our files */\n    if (fd_is_dr_owned(fd)) {\n        SYSLOG_INTERNAL_WARNING_ONCE(\"app trying to close DR file(s)\");\n        LOG(THREAD, LOG_TOP | LOG_SYSCALLS, 1,\n            \"WARNING: app trying to close DR file %d!  Not allowing it.\\n\", fd);\n        if (set_return_val) {\n            if (DYNAMO_OPTION(fail_on_stolen_fds)) {\n                set_failure_return_val(dcontext, EBADF);\n                DODEBUG({ dcontext->expect_last_syscall_to_fail = true; });\n            } else\n                set_success_return_val(dcontext, 0);\n        }\n        return false; /* do not execute syscall */\n    }\n\n    /* Xref PR 258731 - duplicate STDOUT/STDERR when app closes them so we (or\n     * a client) can continue to use them for logging. */\n    if (DYNAMO_OPTION(dup_stdout_on_close) && fd == STDOUT) {\n        our_stdout = fd_priv_dup(fd);\n        if (our_stdout < 0) /* no private fd available */\n            our_stdout = dup_syscall(fd);\n        if (our_stdout >= 0)\n            fd_mark_close_on_exec(our_stdout);\n        fd_table_add(our_stdout, 0);\n        LOG(THREAD, LOG_TOP | LOG_SYSCALLS, 1,\n            \"WARNING: app is closing stdout=%d - duplicating descriptor for \"\n            \"DynamoRIO usage got %d.\\n\",\n            fd, our_stdout);\n        if (privmod_stdout != NULL && INTERNAL_OPTION(private_loader)) {\n            /* update the privately loaded libc's stdout _fileno. */\n            set_stdfile_fileno(privmod_stdout, our_stdout);\n        }\n    }\n    if (DYNAMO_OPTION(dup_stderr_on_close) && fd == STDERR) {\n        our_stderr = fd_priv_dup(fd);\n        if (our_stderr < 0) /* no private fd available */\n            our_stderr = dup_syscall(fd);\n        if (our_stderr >= 0)\n            fd_mark_close_on_exec(our_stderr);\n        fd_table_add(our_stderr, 0);\n        LOG(THREAD, LOG_TOP | LOG_SYSCALLS, 1,\n            \"WARNING: app is closing stderr=%d - duplicating descriptor for \"\n            \"DynamoRIO usage got %d.\\n\",\n            fd, our_stderr);\n        if (privmod_stderr != NULL && INTERNAL_OPTION(private_loader)) {\n            /* update the privately loaded libc's stderr _fileno. */\n            set_stdfile_fileno(privmod_stderr, our_stderr);\n        }\n    }\n    if (DYNAMO_OPTION(dup_stdin_on_close) && fd == STDIN) {\n        our_stdin = fd_priv_dup(fd);\n        if (our_stdin < 0) /* no private fd available */\n            our_stdin = dup_syscall(fd);\n        if (our_stdin >= 0)\n            fd_mark_close_on_exec(our_stdin);\n        fd_table_add(our_stdin, 0);\n        LOG(THREAD, LOG_TOP | LOG_SYSCALLS, 1,\n            \"WARNING: app is closing stdin=%d - duplicating descriptor for \"\n            \"DynamoRIO usage got %d.\\n\",\n            fd, our_stdin);\n        if (privmod_stdin != NULL && INTERNAL_OPTION(private_loader)) {\n            /* update the privately loaded libc's stdout _fileno. */\n            set_stdfile_fileno(privmod_stdin, our_stdin);\n        }\n    }\n    return true;\n}\n\nstatic bool\nhandle_close_pre(dcontext_t *dcontext)\n{\n    return handle_close_generic_pre(dcontext, (uint)sys_param(dcontext, 0),\n                                    true /*set_return_val*/);\n}\n\n#ifdef SYS_close_range\nstatic bool\nhandle_close_range_pre(dcontext_t *dcontext, file_t fd)\n{\n    return handle_close_generic_pre(dcontext, fd, false /*set_return_val*/);\n}\n#endif\n\n/***************************************************************************/\n\n/* Used to obtain the pc of the syscall instr itself when the dcontext dc\n * is currently in a syscall handler.\n * Alternatively for sysenter we could set app_sysenter_instr_addr for Linux.\n */\n#define SYSCALL_PC(dc)                                                              \\\n    ((get_syscall_method() == SYSCALL_METHOD_INT ||                                 \\\n      get_syscall_method() == SYSCALL_METHOD_SYSCALL)                               \\\n         ? (ASSERT(SYSCALL_LENGTH == INT_LENGTH), POST_SYSCALL_PC(dc) - INT_LENGTH) \\\n         : (vsyscall_syscall_end_pc - SYSENTER_LENGTH))\n\nstatic void\nhandle_exit(dcontext_t *dcontext)\n{\n    priv_mcontext_t *mc = get_mcontext(dcontext);\n    bool exit_process = false;\n\n    if (dcontext->sys_num == SYSNUM_EXIT_PROCESS) {\n        /* We can have multiple thread groups within the same address space.\n         * We need to know whether this is the only group left.\n         * FIXME: we can have races where new threads are created after our\n         * check: we'll live with that for now, but the right approach is to\n         * suspend all threads via synch_with_all_threads(), do the check,\n         * and if exit_process then exit w/o resuming: though have to\n         * coordinate lock access w/ cleanup_and_terminate.\n         * Xref i#94.  Xref PR 541760.\n         */\n        process_id_t mypid = get_process_id();\n        thread_record_t **threads;\n        int num_threads, i;\n        exit_process = true;\n        d_r_mutex_lock(&thread_initexit_lock);\n        get_list_of_threads(&threads, &num_threads);\n        for (i = 0; i < num_threads; i++) {\n            if (threads[i]->pid != mypid && !IS_CLIENT_THREAD(threads[i]->dcontext)) {\n                exit_process = false;\n                break;\n            }\n        }\n        if (!exit_process) {\n            /* We need to clean up the other threads in our group here. */\n            thread_id_t myid = d_r_get_thread_id();\n            priv_mcontext_t mcontext;\n            DEBUG_DECLARE(thread_synch_result_t synch_res;)\n            LOG(THREAD, LOG_TOP | LOG_SYSCALLS, 1,\n                \"SYS_exit_group %d not final group: %d cleaning up just \"\n                \"threads in group\\n\",\n                get_process_id(), d_r_get_thread_id());\n            /* Set where we are to handle reciprocal syncs */\n            copy_mcontext(mc, &mcontext);\n            mc->pc = SYSCALL_PC(dcontext);\n            for (i = 0; i < num_threads; i++) {\n                if (threads[i]->id != myid && threads[i]->pid == mypid) {\n                    /* See comments in dynamo_process_exit_cleanup(): we terminate\n                     * to make cleanup easier, but may want to switch to shifting\n                     * the target thread to a stack-free loop.\n                     */\n                    DEBUG_DECLARE(synch_res =)\n                    synch_with_thread(\n                        threads[i]->id, true /*block*/, true /*have initexit lock*/,\n                        THREAD_SYNCH_VALID_MCONTEXT, THREAD_SYNCH_TERMINATED_AND_CLEANED,\n                        THREAD_SYNCH_SUSPEND_FAILURE_IGNORE);\n                    /* initexit lock may be released and re-acquired in course of\n                     * doing the synch so we may have races where the thread\n                     * exits on its own (or new threads appear): we'll live\n                     * with those for now.\n                     */\n                    ASSERT(synch_res == THREAD_SYNCH_RESULT_SUCCESS);\n                }\n            }\n            copy_mcontext(&mcontext, mc);\n        }\n        d_r_mutex_unlock(&thread_initexit_lock);\n        global_heap_free(\n            threads, num_threads * sizeof(thread_record_t *) HEAPACCT(ACCT_THREAD_MGT));\n    }\n\n    if (is_last_app_thread() && !dynamo_exited) {\n        LOG(THREAD, LOG_TOP | LOG_SYSCALLS, 1,\n            \"SYS_exit%s(%d) in final thread \" TIDFMT \" of \" PIDFMT\n            \" => exiting DynamoRIO\\n\",\n            (dcontext->sys_num == SYSNUM_EXIT_PROCESS) ? \"_group\" : \"\",\n            MCXT_SYSNUM_REG(mc), d_r_get_thread_id(), get_process_id());\n        /* we want to clean up even if not automatic startup! */\n        automatic_startup = true;\n        exit_process = true;\n    } else {\n        LOG(THREAD, LOG_TOP | LOG_THREADS | LOG_SYSCALLS, 1,\n            \"SYS_exit%s(%d) in thread \" TIDFMT \" of \" PIDFMT \" => cleaning up %s\\n\",\n            (dcontext->sys_num == SYSNUM_EXIT_PROCESS) ? \"_group\" : \"\",\n            MCXT_SYSNUM_REG(mc), d_r_get_thread_id(), get_process_id(),\n            exit_process ? \"process\" : \"thread\");\n    }\n    KSTOP(num_exits_dir_syscall);\n\n    block_cleanup_and_terminate(dcontext, MCXT_SYSNUM_REG(mc), sys_param(dcontext, 0),\n                                sys_param(dcontext, 1), exit_process,\n                                /* SYS_bsdthread_terminate has 2 more args */\n                                sys_param(dcontext, 2), sys_param(dcontext, 3));\n}\n\n#if defined(LINUX) && defined(X86) /* XXX i#58: until we have Mac support */\nstatic bool\nos_set_app_thread_area(dcontext_t *dcontext, our_modify_ldt_t *user_desc)\n{\n#    ifdef X86\n    int i;\n    os_thread_data_t *ostd = dcontext->os_field;\n    our_modify_ldt_t *desc = (our_modify_ldt_t *)ostd->app_thread_areas;\n\n    if (user_desc->seg_not_present == 1) {\n        /* find an empty one to update */\n        for (i = 0; i < GDT_NUM_TLS_SLOTS; i++) {\n            if (desc[i].seg_not_present == 1)\n                break;\n        }\n        if (i < GDT_NUM_TLS_SLOTS) {\n            user_desc->entry_number = GDT_SELECTOR(i + tls_min_index());\n            memcpy(&desc[i], user_desc, sizeof(*user_desc));\n        } else\n            return false;\n    } else {\n        /* If we used early injection, this might be ld.so trying to set up TLS.  We\n         * direct the app to use the GDT entry we already set up for our private\n         * libraries, but only the first time it requests TLS.\n         */\n        if (user_desc->entry_number == -1 && return_stolen_lib_tls_gdt) {\n            d_r_mutex_lock(&set_thread_area_lock);\n            if (return_stolen_lib_tls_gdt) {\n                uint selector = read_thread_register(LIB_SEG_TLS);\n                uint index = SELECTOR_INDEX(selector);\n                SELF_UNPROTECT_DATASEC(DATASEC_RARELY_PROT);\n                return_stolen_lib_tls_gdt = false;\n                SELF_PROTECT_DATASEC(DATASEC_RARELY_PROT);\n                user_desc->entry_number = index;\n                LOG(GLOBAL, LOG_THREADS, 2,\n                    \"%s: directing app to use \"\n                    \"selector 0x%x for first call to set_thread_area\\n\",\n                    __FUNCTION__, selector);\n            }\n            d_r_mutex_unlock(&set_thread_area_lock);\n        }\n\n        /* update the specific one */\n        i = user_desc->entry_number - tls_min_index();\n        if (i < 0 || i >= GDT_NUM_TLS_SLOTS)\n            return false;\n        LOG(GLOBAL, LOG_THREADS, 2,\n            \"%s: change selector 0x%x base from \" PFX \" to \" PFX \"\\n\", __FUNCTION__,\n            GDT_SELECTOR(user_desc->entry_number), desc[i].base_addr,\n            user_desc->base_addr);\n        memcpy(&desc[i], user_desc, sizeof(*user_desc));\n    }\n    /* if not conflict with dr's tls, perform the syscall */\n    if (!INTERNAL_OPTION(private_loader) &&\n        GDT_SELECTOR(user_desc->entry_number) != read_thread_register(SEG_TLS) &&\n        GDT_SELECTOR(user_desc->entry_number) != read_thread_register(LIB_SEG_TLS))\n        return false;\n#    elif defined(ARM)\n    /* FIXME i#1551: NYI on ARM */\n    ASSERT_NOT_IMPLEMENTED(false);\n#    endif /* X86/ARM */\n    return true;\n}\n\nstatic bool\nos_get_app_thread_area(dcontext_t *dcontext, our_modify_ldt_t *user_desc)\n{\n#    ifdef X86\n    os_thread_data_t *ostd = (os_thread_data_t *)dcontext->os_field;\n    our_modify_ldt_t *desc = (our_modify_ldt_t *)ostd->app_thread_areas;\n    int i = user_desc->entry_number - tls_min_index();\n    if (i < 0 || i >= GDT_NUM_TLS_SLOTS)\n        return false;\n    if (desc[i].seg_not_present == 1)\n        return false;\n#    elif defined(ARM)\n    /* FIXME i#1551: NYI on ARM */\n    ASSERT_NOT_IMPLEMENTED(false);\n#    endif /* X86/ARM */\n    return true;\n}\n#endif\n\n/* This function is used for switch lib tls segment on creating thread.\n * We switch to app's lib tls seg before thread creation system call, i.e.\n * clone and vfork, and switch back to dr's lib tls seg after the system call.\n * They are only called on parent thread, not the child thread.\n * The child thread's tls is setup in os_tls_app_seg_init.\n */\n/* XXX: It looks like the Linux kernel has some dependency on the segment\n * descriptor. If using dr's segment descriptor, the created thread will have\n * access violation for tls not being setup. However, it works fine if we switch\n * the descriptor to app's segment descriptor before creating the thread.\n * We should be able to remove this function later if we find the problem.\n */\nstatic bool\nos_switch_lib_tls(dcontext_t *dcontext, bool to_app)\n{\n    return os_switch_seg_to_context(dcontext, LIB_SEG_TLS, to_app);\n}\n\n#ifdef X86\n/* dcontext can be NULL if !to_app */\nstatic bool\nos_switch_seg_to_base(dcontext_t *dcontext, os_local_state_t *os_tls, reg_id_t seg,\n                      bool to_app, app_pc base)\n{\n    bool res = false;\n    ASSERT(dcontext != NULL);\n    ASSERT(IF_X86_ELSE((seg == SEG_FS || seg == SEG_GS),\n                       (seg == DR_REG_TPIDRURW || DR_REG_TPIDRURO)));\n    switch (os_tls->tls_type) {\n#    if defined(X64) && !defined(MACOS)\n    case TLS_TYPE_ARCH_PRCTL: {\n        res = tls_set_fs_gs_segment_base(os_tls->tls_type, seg, base, NULL);\n        ASSERT(res);\n        LOG(GLOBAL, LOG_THREADS, 2,\n            \"%s %s: arch_prctl successful for thread \" TIDFMT \" base \" PFX \"\\n\",\n            __FUNCTION__, to_app ? \"to app\" : \"to DR\", d_r_get_thread_id(), base);\n        if (seg == SEG_TLS && base == NULL) {\n            /* Set the selector to 0 so we don't think TLS is available. */\n            /* FIXME i#107: Still assumes app isn't using SEG_TLS. */\n            reg_t zero = 0;\n            WRITE_DR_SEG(zero);\n        }\n        break;\n    }\n#    endif\n    case TLS_TYPE_GDT: {\n        our_modify_ldt_t desc;\n        uint index;\n        uint selector;\n        if (to_app) {\n            selector = os_tls->app_lib_tls_reg;\n            index = SELECTOR_INDEX(selector);\n        } else {\n            index = (seg == LIB_SEG_TLS ? tls_priv_lib_index() : tls_dr_index());\n            ASSERT(index != -1 && \"TLS indices not initialized\");\n            selector = GDT_SELECTOR(index);\n        }\n        if (selector != 0) {\n            if (to_app) {\n                our_modify_ldt_t *areas =\n                    ((os_thread_data_t *)dcontext->os_field)->app_thread_areas;\n                ASSERT((index >= tls_min_index()) &&\n                       ((index - tls_min_index()) <= GDT_NUM_TLS_SLOTS));\n                desc = areas[index - tls_min_index()];\n            } else {\n                tls_init_descriptor(&desc, base, GDT_NO_SIZE_LIMIT, index);\n            }\n            res = tls_set_fs_gs_segment_base(os_tls->tls_type, seg, NULL, &desc);\n            ASSERT(res);\n        } else {\n            /* For a selector of zero, we just reset the segment to zero.  We\n             * don't need to call set_thread_area.\n             */\n            res = true; /* Indicate success. */\n        }\n        /* XXX i#2098: it's unsafe to call LOG here in between GDT and register changes */\n        /* i558 update lib seg reg to enforce the segment changes */\n        if (seg == SEG_TLS)\n            WRITE_DR_SEG(selector);\n        else\n            WRITE_LIB_SEG(selector);\n        LOG(THREAD, LOG_LOADER, 2, \"%s: switching to %s, setting %s to 0x%x\\n\",\n            __FUNCTION__, (to_app ? \"app\" : \"dr\"), reg_names[seg], selector);\n        LOG(THREAD, LOG_LOADER, 2,\n            \"%s %s: set_thread_area successful for thread \" TIDFMT \" base \" PFX \"\\n\",\n            __FUNCTION__, to_app ? \"to app\" : \"to DR\", d_r_get_thread_id(), base);\n        break;\n    }\n    case TLS_TYPE_LDT: {\n        uint index;\n        uint selector;\n        if (to_app) {\n            selector = os_tls->app_lib_tls_reg;\n            index = SELECTOR_INDEX(selector);\n        } else {\n            index = (seg == LIB_SEG_TLS ? tls_priv_lib_index() : tls_dr_index());\n            ASSERT(index != -1 && \"TLS indices not initialized\");\n            selector = LDT_SELECTOR(index);\n        }\n        LOG(THREAD, LOG_LOADER, 2, \"%s: switching to %s, setting %s to 0x%x\\n\",\n            __FUNCTION__, (to_app ? \"app\" : \"dr\"), reg_names[seg], selector);\n        if (seg == SEG_TLS)\n            WRITE_DR_SEG(selector);\n        else\n            WRITE_LIB_SEG(selector);\n        LOG(THREAD, LOG_LOADER, 2,\n            \"%s %s: ldt selector swap successful for thread \" TIDFMT \"\\n\", __FUNCTION__,\n            to_app ? \"to app\" : \"to DR\", d_r_get_thread_id());\n        break;\n    }\n    default: ASSERT_NOT_REACHED(); return false;\n    }\n    ASSERT((!to_app && seg == SEG_TLS) ||\n           BOOLS_MATCH(to_app, os_using_app_state(dcontext)));\n    return res;\n}\n\nstatic bool\nos_set_dr_tls_base(dcontext_t *dcontext, os_local_state_t *tls, byte *base)\n{\n    if (tls == NULL) {\n        ASSERT(dcontext != NULL);\n        tls = get_os_tls_from_dc(dcontext);\n    }\n    return os_switch_seg_to_base(dcontext, tls, SEG_TLS, false, base);\n}\n#endif /* X86 */\n\nstatic bool\nos_switch_seg_to_context(dcontext_t *dcontext, reg_id_t seg, bool to_app)\n{\n    os_local_state_t *os_tls = get_os_tls_from_dc(dcontext);\n#ifdef X86\n    app_pc base;\n    /* we can only update the executing thread's segment (i#920) */\n    ASSERT_MESSAGE(CHKLVL_ASSERTS + 1 /*expensive*/, \"can only act on executing thread\",\n                   /* i#2089: a clone syscall, or when native, temporarily puts in\n                    * invalid TLS, so we don't check get_thread_private_dcontext().\n                    */\n                   is_thread_tls_allocated() &&\n                       dcontext->owning_thread == get_sys_thread_id());\n    if (to_app) {\n        base = os_get_app_tls_base(dcontext, seg);\n    } else {\n        base = os_get_priv_tls_base(dcontext, seg);\n    }\n    return os_switch_seg_to_base(dcontext, os_tls, seg, to_app, base);\n#elif defined(AARCHXX)\n    bool res = false;\n    os_thread_data_t *ostd = (os_thread_data_t *)dcontext->os_field;\n    ASSERT(INTERNAL_OPTION(private_loader));\n    if (to_app) {\n        /* We need to handle being called when we're already in the requested state. */\n        ptr_uint_t cur_seg = read_thread_register(LIB_SEG_TLS);\n        if ((void *)cur_seg == os_tls->app_lib_tls_base)\n            return true;\n        bool app_mem_valid = true;\n        if (os_tls->app_lib_tls_base == NULL)\n            app_mem_valid = false;\n        else {\n            uint prot;\n            bool rc = get_memory_info(os_tls->app_lib_tls_base, NULL, NULL, &prot);\n            /* Rule out a garbage value, which happens in our own test\n             * common.allasm_aarch_isa.\n             * Also rule out an unwritable region, which seems to happen on arm\n             * where at process init the thread reg points at rodata in libc\n             * until properly set to a writable mmap later.\n             */\n            if (!rc || !TESTALL(MEMPROT_READ | MEMPROT_WRITE, prot))\n                app_mem_valid = false;\n        }\n        if (!app_mem_valid) {\n            /* XXX i#1578: For pure-asm apps that do not use libc, the app may have no\n             * thread register value.  For detach we would like to write a 0 back into\n             * the thread register, but it complicates our exit code, which wants access\n             * to DR's TLS between dynamo_thread_exit_common()'s call to\n             * dynamo_thread_not_under_dynamo() and its call to\n             * set_thread_private_dcontext(NULL).  For now we just leave our privlib\n             * segment in there.  It seems rather unlikely to cause a problem: app code\n             * is unlikely to read the thread register; it's going to assume it owns it\n             * and will just blindly write to it.\n             */\n            return true;\n        }\n        /* On switching to app's TLS, we need put DR's TLS base into app's TLS\n         * at the same offset so it can be loaded on entering code cache.\n         * Otherwise, the context switch code on entering fcache will fault on\n         * accessing DR's TLS.\n         * The app's TLS slot value is stored into privlib's TLS slot for\n         * later restore on switching back to privlib's TLS.\n         */\n        byte **priv_lib_tls_swap_slot =\n            (byte **)(ostd->priv_lib_tls_base + DR_TLS_BASE_OFFSET);\n        byte **app_lib_tls_swap_slot =\n            (byte **)(os_tls->app_lib_tls_base + DR_TLS_BASE_OFFSET);\n        LOG(THREAD, LOG_LOADER, 3,\n            \"%s: switching to app: app slot=&\" PFX \" *\" PFX \", priv slot=&\" PFX \" *\" PFX\n            \"\\n\",\n            __FUNCTION__, app_lib_tls_swap_slot, *app_lib_tls_swap_slot,\n            priv_lib_tls_swap_slot, *priv_lib_tls_swap_slot);\n        byte *dr_tls_base = *priv_lib_tls_swap_slot;\n        *priv_lib_tls_swap_slot = *app_lib_tls_swap_slot;\n        *app_lib_tls_swap_slot = dr_tls_base;\n        LOG(THREAD, LOG_LOADER, 2, \"%s: switching to %s, setting coproc reg to 0x%x\\n\",\n            __FUNCTION__, (to_app ? \"app\" : \"dr\"), os_tls->app_lib_tls_base);\n        res = write_thread_register(os_tls->app_lib_tls_base);\n    } else {\n        /* We need to handle being called when we're already in the requested state. */\n        ptr_uint_t cur_seg = read_thread_register(LIB_SEG_TLS);\n        if ((void *)cur_seg == ostd->priv_lib_tls_base)\n            return true;\n        /* Restore the app's TLS slot that we used for storing DR's TLS base,\n         * and put DR's TLS base back to privlib's TLS slot.\n         */\n        byte **priv_lib_tls_swap_slot =\n            (byte **)(ostd->priv_lib_tls_base + DR_TLS_BASE_OFFSET);\n        byte **app_lib_tls_swap_slot =\n            (byte **)(os_tls->app_lib_tls_base + DR_TLS_BASE_OFFSET);\n        byte *dr_tls_base = *app_lib_tls_swap_slot;\n        LOG(THREAD, LOG_LOADER, 3,\n            \"%s: switching to DR: app slot=&\" PFX \" *\" PFX \", priv slot=&\" PFX \" *\" PFX\n            \"\\n\",\n            __FUNCTION__, app_lib_tls_swap_slot, *app_lib_tls_swap_slot,\n            priv_lib_tls_swap_slot, *priv_lib_tls_swap_slot);\n        *app_lib_tls_swap_slot = *priv_lib_tls_swap_slot;\n        *priv_lib_tls_swap_slot = dr_tls_base;\n        LOG(THREAD, LOG_LOADER, 2, \"%s: switching to %s, setting coproc reg to 0x%x\\n\",\n            __FUNCTION__, (to_app ? \"app\" : \"dr\"), ostd->priv_lib_tls_base);\n        res = write_thread_register(ostd->priv_lib_tls_base);\n    }\n    LOG(THREAD, LOG_LOADER, 2, \"%s %s: set_tls swap success=%d for thread \" TIDFMT \"\\n\",\n        __FUNCTION__, to_app ? \"to app\" : \"to DR\", res, d_r_get_thread_id());\n    return res;\n#endif /* X86/AARCHXX */\n}\n\n#ifdef LINUX\nstatic bool\nhandle_clone_pre(dcontext_t *dcontext)\n{\n    /* For the clone syscall, in /usr/src/linux/arch/i386/kernel/process.c\n     * 32-bit params: flags, newsp, ptid, tls, ctid\n     * 64-bit params: should be the same yet tls (for ARCH_SET_FS) is in r8?!?\n     *   I don't see how sys_clone gets its special args: shouldn't it\n     *   just get pt_regs as a \"special system call\"?\n     *   sys_clone(unsigned long clone_flags, unsigned long newsp,\n     *     void __user *parent_tid, void __user *child_tid, struct pt_regs *regs)\n     */\n    uint64_t flags;\n    /* For the clone3 syscall, DR creates its own copy of clone_args for two\n     * reasons: to ensure that the app-provided clone_args is readable\n     * without any fault, and to avoid modifying the app's clone_args in the\n     * is_thread_create_syscall case (see below).\n     */\n    clone3_syscall_args_t *dr_clone_args = NULL, *app_clone_args = NULL;\n    uint app_clone_args_size = 0;\n    if (dcontext->sys_num == SYS_clone3) {\n        if (is_clone3_enosys) {\n            /* We know that clone3 will return ENOSYS, so we skip the pre-syscall\n             * handling and fail early.\n             */\n            LOG(THREAD, LOG_SYSCALLS, 2, \"\\treturning ENOSYS to app for clone3\\n\");\n            set_failure_return_val(dcontext, ENOSYS);\n            DODEBUG({ dcontext->expect_last_syscall_to_fail = true; });\n            return false;\n        }\n        app_clone_args_size =\n            (uint)sys_param(dcontext, SYSCALL_PARAM_CLONE3_CLONE_ARGS_SIZE);\n        if (app_clone_args_size < CLONE_ARGS_SIZE_VER0) {\n            LOG(THREAD, LOG_SYSCALLS, 2, \"\\treturning EINVAL to app for clone3\\n\");\n            set_failure_return_val(dcontext, EINVAL);\n            DODEBUG({ dcontext->expect_last_syscall_to_fail = true; });\n            return false;\n        }\n        app_clone_args =\n            (clone3_syscall_args_t *)sys_param(dcontext, SYSCALL_PARAM_CLONE3_CLONE_ARGS);\n        /* Note that the struct clone_args being used by the app may have\n         * less/more fields than DR's internal struct (clone3_syscall_args_t).\n         * For creating DR's copy of the app's clone_args object, we need to\n         * allocate as much space as specified by the app in the clone3\n         * syscall's args.\n         */\n        dr_clone_args = (clone3_syscall_args_t *)heap_alloc(\n            dcontext, app_clone_args_size HEAPACCT(ACCT_OTHER));\n        if (!d_r_safe_read(app_clone_args, app_clone_args_size, dr_clone_args)) {\n            LOG(THREAD, LOG_SYSCALLS, 2, \"\\treturning EFAULT to app for clone3\\n\");\n            set_failure_return_val(dcontext, EFAULT);\n            DODEBUG({ dcontext->expect_last_syscall_to_fail = true; });\n            heap_free(dcontext, dr_clone_args, app_clone_args_size HEAPACCT(ACCT_OTHER));\n            return false;\n        }\n        flags = dr_clone_args->flags;\n\n        /* Save for post_system_call */\n        /* We need to save the pointer to the app's clone_args so that we can restore it\n         * post-syscall.\n         */\n        dcontext->sys_param0 = (reg_t)app_clone_args;\n        /* For freeing the allocated memory. */\n        dcontext->sys_param1 = (reg_t)dr_clone_args;\n        dcontext->sys_param2 = (reg_t)app_clone_args_size;\n        /* clone3 flags are 64-bit even on 32-bit systems. So we need to split them across\n         * two reg_t vars on 32-bit. We do it on 64-bit systems as well for simpler code.\n         */\n        dcontext->sys_param3 = (reg_t)(flags & CLONE3_FLAGS_4_BYTE_MASK);\n        ASSERT((flags >> 32 & ~CLONE3_FLAGS_4_BYTE_MASK) == 0);\n        dcontext->sys_param4 = (reg_t)((flags >> 32));\n        LOG(THREAD, LOG_SYSCALLS, 2,\n            \"syscall: clone3 with args: flags = 0x\" HEX64_FORMAT_STRING\n            \", exit_signal = 0x\" HEX64_FORMAT_STRING \", stack = 0x\" HEX64_FORMAT_STRING\n            \", stack_size = 0x\" HEX64_FORMAT_STRING \"\\n\",\n            dr_clone_args->flags, dr_clone_args->exit_signal, dr_clone_args->stack,\n            dr_clone_args->stack_size);\n    } else {\n        flags = (uint)sys_param(dcontext, 0);\n        /* Save for post_system_call.\n         * Unlike clone3, here the flags are 32-bit, so truncation is okay.\n         */\n        dcontext->sys_param0 = (reg_t)flags;\n        LOG(THREAD, LOG_SYSCALLS, 2,\n            \"syscall: clone with args: flags = \" PFX \", stack = \" PFX\n            \", tid_field_parent = \" PFX \", tid_field_child = \" PFX \", thread_ptr = \" PFX\n            \"\\n\",\n            sys_param(dcontext, 0), sys_param(dcontext, 1), sys_param(dcontext, 2),\n            sys_param(dcontext, 3), sys_param(dcontext, 4));\n    }\n    handle_clone(dcontext, flags);\n    if ((flags & CLONE_VM) == 0) {\n        LOG(THREAD, LOG_SYSCALLS, 1, \"\\tWARNING: CLONE_VM not set!\\n\");\n    }\n\n    /* i#1010: If we have private fds open (usually logfiles), we should\n     * clean those up before they get reused by a new thread.\n     * XXX: Ideally we'd do this in fd_table_add(), but we can't acquire\n     * thread_initexit_lock there.\n     */\n    cleanup_after_vfork_execve(dcontext);\n\n    /* For thread creation clone syscalls a clone_record_t structure\n     * containing the pc after the app's syscall instr and other data\n     * (see i#27) is placed at the bottom of the dstack (which is allocated\n     * by create_clone_record() - it also saves app stack and switches\n     * to dstack).  xref i#149/PR 403015.\n     * Note: This must be done after sys_param0 is set.\n     */\n    if (is_thread_create_syscall(dcontext, dr_clone_args)) {\n        if (dcontext->sys_num == SYS_clone3) {\n            /* create_clone_record modifies some fields in clone_args for the\n             * clone3 syscall. Instead of reusing the app's copy of\n             * clone_args and modifying it, we choose to use our own copy.\n             * Under CLONE_VM, the parent and child threads have a pointer to\n             * the same app clone_args. By using our own copy of clone_args\n             * for the syscall, we obviate the need to restore the modified\n             * fields in the app's copy after the syscall in either the parent\n             * or the child thread, which can be racy under CLONE_VM as the\n             * parent and/or child threads may need to access/modify it. By\n             * using a copy instead, both parent and child threads only\n             * need to restore their own SYSCALL_PARAM_CLONE3_CLONE_ARGS reg\n             * to the pointer to the app's clone_args. It is saved in the\n             * clone record for the child thread, and in sys_param0 for the\n             * parent thread. The DR copy of clone_args is freed by the parent\n             * thread in the post-syscall handling of clone3; as it is used\n             * only by the parent thread, there is no use-after-free danger here.\n             */\n            ASSERT(app_clone_args != NULL && dr_clone_args != NULL);\n            *sys_param_addr(dcontext, SYSCALL_PARAM_CLONE3_CLONE_ARGS) =\n                (reg_t)dr_clone_args;\n            /* The pointer to the app's clone_args was saved in sys_param0 above. */\n            create_clone_record(dcontext, NULL, dr_clone_args, app_clone_args);\n        } else {\n            /* We replace the app-provided stack pointer with our own stack\n             * pointer in create_clone_record. Save the original pointer so\n             * that we can restore it post-syscall in the parent. The same is\n             * restored in the child in restore_clone_param_from_clone_record.\n             */\n            dcontext->sys_param1 = sys_param(dcontext, SYSCALL_PARAM_CLONE_STACK);\n            create_clone_record(dcontext,\n                                sys_param_addr(dcontext, SYSCALL_PARAM_CLONE_STACK), NULL,\n                                NULL);\n        }\n        os_clone_pre(dcontext);\n        os_new_thread_pre();\n    } else {\n        /* This is really a fork. */\n        if (dcontext->sys_num == SYS_clone3) {\n            /* We free this memory before the actual fork, to avoid having to free\n             * it in the parent *and* the child later.\n             */\n            ASSERT(app_clone_args_size == (uint)dcontext->sys_param2);\n            ASSERT(dr_clone_args == (clone3_syscall_args_t *)dcontext->sys_param1);\n            heap_free(dcontext, dr_clone_args, app_clone_args_size HEAPACCT(ACCT_OTHER));\n            /* We do not need these anymore for the fork case. */\n            dcontext->sys_param1 = 0;\n            dcontext->sys_param2 = 0;\n        }\n        os_fork_pre(dcontext);\n    }\n    return true;\n}\n#endif\n\n/* System call interception: put any special handling here\n * Arguments come from the pusha right before the call\n */\n\n/* WARNING: flush_fragments_and_remove_region assumes that pre and post system\n * call handlers do not examine or modify fcache or its fragments in any\n * way except for calling flush_fragments_and_remove_region!\n */\n\n/* WARNING: All registers are IN values, but NOT OUT values --\n * must set mcontext's register for that.\n */\n\n/* Returns false if system call should NOT be executed (in which case,\n * post_system_call() will *not* be called!).\n * Returns true if system call should go ahead\n */\n/* XXX: split out specific handlers into separate routines\n */\nbool\npre_system_call(dcontext_t *dcontext)\n{\n    priv_mcontext_t *mc = get_mcontext(dcontext);\n    bool execute_syscall = true;\n    dr_where_am_i_t old_whereami = dcontext->whereami;\n    dcontext->whereami = DR_WHERE_SYSCALL_HANDLER;\n    /* FIXME We haven't yet done the work to detect which syscalls we\n     * can determine a priori will fail. Once we do, we will set the\n     * expect_last_syscall_to_fail to true for those case, and can\n     * confirm in post_system_call() that the syscall failed as\n     * expected.\n     */\n    DODEBUG(dcontext->expect_last_syscall_to_fail = false;);\n\n    /* save key register values for post_system_call (they get clobbered\n     * in syscall itself)\n     */\n    dcontext->sys_num = os_normalized_sysnum((int)MCXT_SYSNUM_REG(mc), NULL, dcontext);\n\n    RSTATS_INC(pre_syscall);\n    DOSTATS({\n        if (ignorable_system_call_normalized(dcontext->sys_num))\n            STATS_INC(pre_syscall_ignorable);\n    });\n    LOG(THREAD, LOG_SYSCALLS, 2, \"system call %d\\n\", dcontext->sys_num);\n\n#if defined(LINUX) && defined(X86)\n    /* PR 313715: If we fail to hook the vsyscall page (xref PR 212570, PR 288330)\n     * we fall back on int, but we have to tweak syscall param #5 (ebp)\n     * Once we have PR 288330 we can remove this.\n     */\n    if (should_syscall_method_be_sysenter() && !dcontext->sys_was_int) {\n        dcontext->sys_xbp = mc->xbp;\n        /* not using SAFE_READ due to performance concerns (we do this for\n         * every single system call on systems where we can't hook vsyscall!)\n         */\n        TRY_EXCEPT(dcontext, /* try */ { mc->xbp = *(reg_t *)mc->xsp; }, /* except */\n                   {\n                       ASSERT_NOT_REACHED();\n                       mc->xbp = 0;\n                   });\n    }\n#endif\n\n    switch (dcontext->sys_num) {\n\n    case SYSNUM_EXIT_PROCESS:\n#if defined(LINUX) && VMX86_SERVER\n        if (os_in_vmkernel_32bit()) {\n            /* on esx 3.5 => ENOSYS, so wait for SYS_exit */\n            LOG(THREAD, LOG_SYSCALLS, 2, \"on esx35 => ignoring exitgroup\\n\");\n            DODEBUG({ dcontext->expect_last_syscall_to_fail = true; });\n            break;\n        }\n#endif\n        /* fall-through */\n    case SYSNUM_EXIT_THREAD: {\n        handle_exit(dcontext);\n        break;\n    }\n\n    /****************************************************************************/\n    /* MEMORY REGIONS */\n\n#if defined(LINUX) && !defined(X64) && !defined(ARM)\n    case SYS_mmap: {\n        /* in /usr/src/linux/arch/i386/kernel/sys_i386.c:\n           asmlinkage int old_mmap(struct mmap_arg_struct_t *arg)\n         */\n        mmap_arg_struct_t *arg = (mmap_arg_struct_t *)sys_param(dcontext, 0);\n        mmap_arg_struct_t arg_buf;\n        if (d_r_safe_read(arg, sizeof(mmap_arg_struct_t), &arg_buf)) {\n            void *addr = (void *)arg->addr;\n            size_t len = (size_t)arg->len;\n            uint prot = (uint)arg->prot;\n            LOG(THREAD, LOG_SYSCALLS, 2,\n                \"syscall: mmap addr=\" PFX \" size=\" PIFX \" prot=0x%x\"\n                \" flags=\" PIFX \" offset=\" PIFX \" fd=%d\\n\",\n                addr, len, prot, arg->flags, arg->offset, arg->fd);\n            /* Check for overlap with existing code or patch-proof regions */\n            if (addr != NULL &&\n                !app_memory_pre_alloc(dcontext, addr, len, osprot_to_memprot(prot),\n                                      !TEST(MAP_FIXED, arg->flags),\n                                      false /*we'll update in post*/,\n                                      false /*unknown*/)) {\n                /* Rather than failing or skipping the syscall we'd like to just\n                 * remove the hint -- but we don't want to write to app memory, so\n                 * we do fail.  We could set up our own mmap_arg_struct_t but\n                 * we'd need dedicate per-thread storage, and SYS_mmap is obsolete.\n                 */\n                execute_syscall = false;\n                set_failure_return_val(dcontext, ENOMEM);\n                DODEBUG({ dcontext->expect_last_syscall_to_fail = true; });\n                break;\n            }\n        }\n        /* post_system_call does the work */\n        dcontext->sys_param0 = (reg_t)arg;\n        break;\n    }\n#endif\n    case IF_MACOS_ELSE(SYS_mmap, IF_X64_ELSE(SYS_mmap, SYS_mmap2)): {\n        /* in /usr/src/linux/arch/i386/kernel/sys_i386.c:\n           asmlinkage long sys_mmap2(unsigned long addr, unsigned long len,\n             unsigned long prot, unsigned long flags,\n             unsigned long fd, unsigned long pgoff)\n         */\n        void *addr = (void *)sys_param(dcontext, 0);\n        size_t len = (size_t)sys_param(dcontext, 1);\n        uint prot = (uint)sys_param(dcontext, 2);\n        uint flags = (uint)sys_param(dcontext, 3);\n        LOG(THREAD, LOG_SYSCALLS, 2,\n            \"syscall: mmap2 addr=\" PFX \" size=\" PIFX \" prot=0x%x\"\n            \" flags=\" PIFX \" offset=\" PIFX \" fd=%d\\n\",\n            addr, len, prot, flags, sys_param(dcontext, 5), sys_param(dcontext, 4));\n        /* Check for overlap with existing code or patch-proof regions */\n        /* Try to see whether it's an image, though we can't tell for addr==NULL\n         * (typical for 1st mmap).\n         */\n        bool image = addr != NULL && !TEST(MAP_ANONYMOUS, flags) &&\n            mmap_check_for_module_overlap(addr, len, TEST(PROT_READ, prot), 0, true);\n        if (addr != NULL &&\n            !app_memory_pre_alloc(dcontext, addr, len, osprot_to_memprot(prot),\n                                  !TEST(MAP_FIXED, flags), false /*we'll update in post*/,\n                                  image /*best estimate*/)) {\n            if (!TEST(MAP_FIXED, flags)) {\n                /* Rather than failing or skipping the syscall we just remove\n                 * the hint which should eliminate any overlap.\n                 */\n                *sys_param_addr(dcontext, 0) = 0;\n            } else {\n                execute_syscall = false;\n                set_failure_return_val(dcontext, ENOMEM);\n                DODEBUG({ dcontext->expect_last_syscall_to_fail = true; });\n                break;\n            }\n        }\n        /* post_system_call does the work */\n        dcontext->sys_param0 = (reg_t)addr;\n        dcontext->sys_param1 = len;\n        dcontext->sys_param2 = prot;\n        dcontext->sys_param3 = flags;\n        break;\n    }\n    /* must flush stale fragments when we see munmap/mremap */\n    case SYS_munmap: {\n        /* in /usr/src/linux/mm/mmap.c:\n           asmlinkage long sys_munmap(unsigned long addr, uint len)\n         */\n        app_pc addr = (void *)sys_param(dcontext, 0);\n        size_t len = (size_t)sys_param(dcontext, 1);\n        LOG(THREAD, LOG_SYSCALLS, 2, \"syscall: munmap addr=\" PFX \" size=\" PFX \"\\n\", addr,\n            len);\n        RSTATS_INC(num_app_munmaps);\n        /* FIXME addr is supposed to be on a page boundary so we\n         * could detect that condition here and set\n         * expect_last_syscall_to_fail.\n         */\n        /* save params in case an undo is needed in post_system_call */\n        dcontext->sys_param0 = (reg_t)addr;\n        dcontext->sys_param1 = len;\n        /* We assume that the unmap will succeed and so are conservative\n         * and remove the region from exec areas and flush all fragments\n         * prior to issuing the syscall. If the unmap fails, we try to\n         * recover in post_system_call() by re-adding the region. This\n         * approach has its shortcomings -- see comments below in\n         * post_system_call().\n         */\n        /* Check for unmapping a module. */\n        os_get_module_info_lock();\n        if (module_overlaps(addr, len)) {\n            /* FIXME - handle unmapping more than one module at once, or only unmapping\n             * part of a module (for which case should adjust view size? or treat as full\n             * unmap?). Theoretical for now as we haven't seen this. */\n            module_area_t *ma = module_pc_lookup(addr);\n            ASSERT_CURIOSITY(ma != NULL);\n            ASSERT_CURIOSITY(addr == ma->start);\n            /* XREF 307599 on rounding module end to the next PAGE boundary */\n            ASSERT_CURIOSITY((app_pc)ALIGN_FORWARD(addr + len, PAGE_SIZE) == ma->end);\n            os_get_module_info_unlock();\n            /* i#210:\n             * we only think a module is removed if its first memory region\n             * is unloaded (unmapped).\n             * XREF i#160 to fix the real problem of handling module splitting.\n             */\n            if (ma != NULL && ma->start == addr)\n                module_list_remove(addr, ALIGN_FORWARD(len, PAGE_SIZE));\n        } else\n            os_get_module_info_unlock();\n        app_memory_deallocation(dcontext, (app_pc)addr, len,\n                                false /* don't own thread_initexit_lock */,\n                                true /* image, FIXME: though not necessarily */);\n        /* FIXME: case 4983 use is_elf_so_header() */\n#ifndef HAVE_MEMINFO_QUERY\n        memcache_lock();\n        memcache_remove(addr, addr + len);\n        memcache_unlock();\n#endif\n        break;\n    }\n#ifdef LINUX\n    case SYS_mremap: {\n        /* in /usr/src/linux/mm/mmap.c:\n           asmlinkage unsigned long sys_mremap(unsigned long addr,\n             unsigned long old_len, unsigned long new_len,\n             unsigned long flags, unsigned long new_addr)\n        */\n        dr_mem_info_t info;\n        app_pc addr = (void *)sys_param(dcontext, 0);\n        size_t old_len = (size_t)sys_param(dcontext, 1);\n        size_t new_len = (size_t)sys_param(dcontext, 2);\n        DEBUG_DECLARE(bool ok;)\n        LOG(THREAD, LOG_SYSCALLS, 2, \"syscall: mremap addr=\" PFX \" size=\" PFX \"\\n\", addr,\n            old_len);\n        /* post_system_call does the work */\n        dcontext->sys_param0 = (reg_t)addr;\n        dcontext->sys_param1 = old_len;\n        dcontext->sys_param2 = new_len;\n        /* i#173\n         * we need memory type and prot to set the\n         * new memory region in the post_system_call\n         */\n        DEBUG_DECLARE(ok =)\n        query_memory_ex(addr, &info);\n        ASSERT(ok);\n        dcontext->sys_param3 = info.prot;\n        dcontext->sys_param4 = info.type;\n        DOCHECK(1, {\n            /* we don't expect to see remappings of modules */\n            os_get_module_info_lock();\n            ASSERT_CURIOSITY(!module_overlaps(addr, old_len));\n            os_get_module_info_unlock();\n        });\n        break;\n    }\n#endif\n    case SYS_mprotect: {\n        /* in /usr/src/linux/mm/mprotect.c:\n           asmlinkage long sys_mprotect(unsigned long start, uint len,\n           unsigned long prot)\n        */\n        uint res;\n        DEBUG_DECLARE(size_t size;)\n        app_pc addr = (void *)sys_param(dcontext, 0);\n        size_t len = (size_t)sys_param(dcontext, 1);\n        uint prot = (uint)sys_param(dcontext, 2);\n        uint old_memprot = MEMPROT_NONE, new_memprot;\n        bool exists = true;\n        /* save params in case an undo is needed in post_system_call */\n        dcontext->sys_param0 = (reg_t)addr;\n        dcontext->sys_param1 = len;\n        dcontext->sys_param2 = prot;\n        LOG(THREAD, LOG_SYSCALLS, 2,\n            \"syscall: mprotect addr=\" PFX \" size=\" PFX \" prot=%s\\n\", addr, len,\n            memprot_string(osprot_to_memprot(prot)));\n\n        if (!get_memory_info(addr, NULL, IF_DEBUG_ELSE(&size, NULL), &old_memprot)) {\n            exists = false;\n            /* Xref PR 413109, PR 410921: if the start, or any page, is not mapped,\n             * this should fail with ENOMEM.  We used to force-fail it to avoid\n             * asserts in our own allmem update code, but there are cases where a\n             * seemingly unmapped page succeeds (i#1912: next page of grows-down\n             * initial stack).  Thus we let it go through.\n             */\n            LOG(THREAD, LOG_SYSCALLS, 2,\n                \"\\t\" PFX \" isn't mapped: probably mprotect will fail\\n\", addr);\n        } else {\n            /* If mprotect region spans beyond the end of the vmarea then it\n             * spans 2 or more vmareas with dissimilar protection (xref\n             * PR 410921) or has unallocated regions in between (PR 413109).\n             */\n            DOCHECK(1, dcontext->mprot_multi_areas = len > size ? true : false;);\n        }\n\n        new_memprot = osprot_to_memprot(prot) |\n            /* mprotect won't change meta flags */\n            (old_memprot & MEMPROT_META_FLAGS);\n        res = app_memory_protection_change(dcontext, addr, len, new_memprot, &new_memprot,\n                                           NULL, false /*!image*/);\n        if (res != DO_APP_MEM_PROT_CHANGE) {\n            if (res == FAIL_APP_MEM_PROT_CHANGE) {\n                ASSERT_NOT_IMPLEMENTED(false); /* return code? */\n            } else {\n                ASSERT_NOT_IMPLEMENTED(res != SUBSET_APP_MEM_PROT_CHANGE);\n                ASSERT_NOT_REACHED();\n            }\n            execute_syscall = false;\n        } else {\n            /* FIXME Store state for undo if the syscall fails. */\n            IF_NO_MEMQUERY(memcache_update_locked(addr, addr + len, new_memprot,\n                                                  -1 /*type unchanged*/, exists));\n        }\n        break;\n    }\n#ifdef ANDROID\n    case SYS_prctl:\n        dcontext->sys_param0 = sys_param(dcontext, 0);\n        dcontext->sys_param1 = sys_param(dcontext, 1);\n        dcontext->sys_param2 = sys_param(dcontext, 2);\n        dcontext->sys_param3 = sys_param(dcontext, 3);\n        dcontext->sys_param4 = sys_param(dcontext, 4);\n        break;\n#endif\n#ifdef LINUX\n    case SYS_brk: {\n        if (DYNAMO_OPTION(emulate_brk)) {\n            /* i#1004: emulate brk via a separate mmap */\n            byte *new_val = (byte *)sys_param(dcontext, 0);\n            byte *res = emulate_app_brk(dcontext, new_val);\n            execute_syscall = false;\n            /* SYS_brk returns old brk on failure */\n            set_success_return_val(dcontext, (reg_t)res);\n        } else {\n            /* i#91/PR 396352: need to watch SYS_brk to maintain all_memory_areas.\n             * We store the old break in the param1 slot.\n             */\n            DODEBUG(dcontext->sys_param0 = (reg_t)sys_param(dcontext, 0););\n            dcontext->sys_param1 = dynamorio_syscall(SYS_brk, 1, 0);\n        }\n        break;\n    }\n#    ifdef SYS_uselib\n    case SYS_uselib: {\n        /* Used to get the kernel to load a share library (legacy system call).\n         * Was primarily used when statically linking to dynamically loaded shared\n         * libraries that were loaded at known locations.  Shouldn't be used by\n         * applications using the dynamic loader (ld) which is currently the only\n         * way we can inject so we don't expect to see this.  PR 307621. */\n        ASSERT_NOT_IMPLEMENTED(false);\n        break;\n    }\n#    endif\n#endif\n\n    /****************************************************************************/\n    /* SPAWNING */\n\n#ifdef LINUX\n    case SYS_clone3:\n    case SYS_clone: execute_syscall = handle_clone_pre(dcontext); break;\n#elif defined(MACOS)\n    case SYS_bsdthread_create: {\n        /* XXX i#1403: we need earlier injection to intercept\n         * bsdthread_register in order to capture workqueue threads.\n         * For now we settle for intercepting bsd threads at the user thread func.\n         * We miss a little user-mode code but this is enough to get started.\n         */\n        app_pc func = (app_pc)sys_param(dcontext, 0);\n        void *func_arg = (void *)sys_param(dcontext, 1);\n        void *clone_rec;\n        LOG(THREAD, LOG_SYSCALLS, 1,\n            \"bsdthread_create: thread func \" PFX \", arg \" PFX \"\\n\", func, func_arg);\n        handle_clone(dcontext, CLONE_THREAD | CLONE_VM | CLONE_SIGHAND | SIGCHLD);\n        clone_rec = create_clone_record(dcontext, NULL, func, func_arg);\n        dcontext->sys_param0 = (reg_t)func;\n        dcontext->sys_param1 = (reg_t)func_arg;\n        *sys_param_addr(dcontext, 0) = (reg_t)new_bsdthread_intercept;\n        *sys_param_addr(dcontext, 1) = (reg_t)clone_rec;\n        os_new_thread_pre();\n        break;\n    }\n    case SYS_posix_spawn: {\n        /* FIXME i#1644: monitor this call which can be fork or exec */\n        ASSERT_NOT_IMPLEMENTED(false);\n        break;\n    }\n#endif\n\n#ifdef SYS_vfork\n    case SYS_vfork: {\n        /* treat as if sys_clone with flags just as sys_vfork does */\n        /* in /usr/src/linux/arch/i386/kernel/process.c */\n        uint flags = CLONE_VFORK | CLONE_VM | SIGCHLD;\n        LOG(THREAD, LOG_SYSCALLS, 2, \"syscall: vfork\\n\");\n        handle_clone(dcontext, flags);\n        cleanup_after_vfork_execve(dcontext);\n\n        /* save for post_system_call, treated as if SYS_clone */\n        dcontext->sys_param0 = (reg_t)flags;\n\n        /* vfork has the same needs as clone.  Pass info via a clone_record_t\n         * structure to child.  See SYS_clone for info about i#149/PR 403015.\n         */\n        IF_LINUX(ASSERT(is_thread_create_syscall(dcontext, NULL)));\n        dcontext->sys_param1 = mc->xsp; /* for restoring in parent */\n#    ifdef MACOS\n        create_clone_record(dcontext, (reg_t *)&mc->xsp, NULL, NULL);\n#    else\n        create_clone_record(dcontext, (reg_t *)&mc->xsp /*child uses parent sp*/, NULL,\n                            NULL);\n#    endif\n        os_clone_pre(dcontext);\n        os_new_thread_pre();\n        break;\n    }\n#endif\n\n#ifdef SYS_fork\n    case SYS_fork: {\n        LOG(THREAD, LOG_SYSCALLS, 2, \"syscall: fork\\n\");\n        os_fork_pre(dcontext);\n        break;\n    }\n#endif\n\n    case SYS_execve: {\n        int ret = handle_execve(dcontext);\n        if (ret != 0) {\n            execute_syscall = false;\n            set_failure_return_val(dcontext, ret);\n        }\n        break;\n    }\n\n        /****************************************************************************/\n        /* SIGNALS */\n\n    case IF_MACOS_ELSE(SYS_sigaction, SYS_rt_sigaction): { /* 174 */\n        /* in /usr/src/linux/kernel/signal.c:\n           asmlinkage long\n           sys_rt_sigaction(int sig, const struct sigaction *act,\n             struct sigaction *oact, size_t sigsetsize)\n         */\n        int sig = (int)sys_param(dcontext, 0);\n        const kernel_sigaction_t *act =\n            (const kernel_sigaction_t *)sys_param(dcontext, 1);\n        prev_sigaction_t *oact = (prev_sigaction_t *)sys_param(dcontext, 2);\n        size_t sigsetsize = (size_t)\n            /* On Mac there is no size arg (but it doesn't use old sigaction, so\n             * closer to rt_ than non-rt_ below).\n             */\n            IF_MACOS_ELSE(sizeof(kernel_sigset_t), sys_param(dcontext, 3));\n        uint res;\n        LOG(THREAD, LOG_SYSCALLS, 2, \"syscall: %ssigaction %d \" PFX \" \" PFX \" %d\\n\",\n            IF_MACOS_ELSE(\"\", \"rt_\"), sig, act, oact, sigsetsize);\n        /* post_syscall does some work as well */\n        dcontext->sys_param0 = (reg_t)sig;\n        dcontext->sys_param1 = (reg_t)act;\n        dcontext->sys_param2 = (reg_t)oact;\n        dcontext->sys_param3 = (reg_t)sigsetsize;\n        execute_syscall = handle_sigaction(dcontext, sig, act, oact, sigsetsize, &res);\n        if (!execute_syscall) {\n            LOG(THREAD, LOG_SYSCALLS, 2, \"sigaction emulation => %d\\n\", -res);\n            if (res == 0)\n                set_success_return_val(dcontext, 0);\n            else\n                set_failure_return_val(dcontext, res);\n        }\n        break;\n    }\n#if defined(LINUX) && !defined(X64)\n    case SYS_sigaction: { /* 67 */\n        /* sys_sigaction(int sig, const struct old_sigaction *act,\n         *               struct old_sigaction *oact)\n         */\n        int sig = (int)sys_param(dcontext, 0);\n        const old_sigaction_t *act = (const old_sigaction_t *)sys_param(dcontext, 1);\n        old_sigaction_t *oact = (old_sigaction_t *)sys_param(dcontext, 2);\n        uint res;\n        LOG(THREAD, LOG_SYSCALLS, 2, \"syscall: sigaction %d \" PFX \" \" PFX \"\\n\", sig, act,\n            oact);\n        dcontext->sys_param0 = (reg_t)sig;\n        dcontext->sys_param1 = (reg_t)act;\n        dcontext->sys_param2 = (reg_t)oact;\n        execute_syscall = handle_old_sigaction(dcontext, sig, act, oact, &res);\n        if (!execute_syscall) {\n            LOG(THREAD, LOG_SYSCALLS, 2, \"sigaction emulation => %d\\n\", -res);\n            if (res == 0)\n                set_success_return_val(dcontext, 0);\n            else\n                set_failure_return_val(dcontext, res);\n        }\n        break;\n    }\n#endif\n#if defined(LINUX) && !defined(X64)\n    case SYS_sigreturn: { /* 119 */\n        /* in /usr/src/linux/arch/i386/kernel/signal.c:\n           asmlinkage int sys_sigreturn(unsigned long __unused)\n         */\n        execute_syscall = handle_sigreturn(dcontext, false);\n        /* app will not expect syscall to return, so when handle_sigreturn\n         * returns false it always redirects the context, and thus no\n         * need to set return val here.\n         */\n        break;\n    }\n#endif\n#ifdef LINUX\n    case SYS_rt_sigreturn: { /* 173 */\n        /* in /usr/src/linux/arch/i386/kernel/signal.c:\n           asmlinkage int sys_rt_sigreturn(unsigned long __unused)\n         */\n        execute_syscall = handle_sigreturn(dcontext, true);\n        /* see comment for SYS_sigreturn on return val */\n        break;\n    }\n#endif\n#ifdef MACOS\n    case SYS_sigreturn: {\n        /* int sigreturn(struct ucontext *uctx, int infostyle) */\n        execute_syscall = handle_sigreturn(dcontext, (void *)sys_param(dcontext, 0),\n                                           (int)sys_param(dcontext, 1));\n        /* see comment for SYS_sigreturn on return val */\n        break;\n    }\n#endif\n    case SYS_sigaltstack: { /* 186 */\n        /* in /usr/src/linux/arch/i386/kernel/signal.c:\n           asmlinkage int\n           sys_sigaltstack(const stack_t *uss, stack_t *uoss)\n        */\n        const stack_t *uss = (const stack_t *)sys_param(dcontext, 0);\n        stack_t *uoss = (stack_t *)sys_param(dcontext, 1);\n        uint res;\n        LOG(THREAD, LOG_SYSCALLS, 2, \"syscall: sigaltstack \" PFX \" \" PFX \"\\n\", uss, uoss);\n        execute_syscall =\n            handle_sigaltstack(dcontext, uss, uoss, get_mcontext(dcontext)->xsp, &res);\n        if (!execute_syscall) {\n            LOG(THREAD, LOG_SYSCALLS, 2, \"sigaltstack emulation => %d\\n\", -res);\n            if (res == 0)\n                set_success_return_val(dcontext, res);\n            else\n                set_failure_return_val(dcontext, res);\n        }\n        break;\n    }\n    case IF_MACOS_ELSE(SYS_sigprocmask, SYS_rt_sigprocmask): { /* 175 */\n        /* TODO i#5256: Fx this path and enable linux.sigaction on MacOS. */\n        /* in /usr/src/linux/kernel/signal.c:\n           asmlinkage long\n           sys_rt_sigprocmask(int how, sigset_t *set, sigset_t *oset,\n             size_t sigsetsize)\n         */\n        /* we also need access to the params in post_system_call */\n        uint error_code = 0;\n        dcontext->sys_param0 = sys_param(dcontext, 0);\n        dcontext->sys_param1 = sys_param(dcontext, 1);\n        dcontext->sys_param2 = sys_param(dcontext, 2);\n        /* SYS_sigprocmask on MacOS does not have a size arg. So we use the\n         * kernel_sigset_t size instead.\n         */\n        size_t sigsetsize =\n            (size_t)IF_MACOS_ELSE(sizeof(kernel_sigset_t), sys_param(dcontext, 3));\n        dcontext->sys_param3 = (reg_t)sigsetsize;\n        execute_syscall = handle_sigprocmask(dcontext, (int)sys_param(dcontext, 0),\n                                             (kernel_sigset_t *)sys_param(dcontext, 1),\n                                             (kernel_sigset_t *)sys_param(dcontext, 2),\n                                             sigsetsize, &error_code);\n        if (!execute_syscall) {\n            if (error_code == 0)\n                set_success_return_val(dcontext, 0);\n            else\n                set_failure_return_val(dcontext, error_code);\n        }\n        break;\n    }\n#ifdef MACOS\n    case SYS_sigsuspend_nocancel:\n#endif\n    case IF_MACOS_ELSE(SYS_sigsuspend, SYS_rt_sigsuspend): { /* 179 */\n        /* in /usr/src/linux/kernel/signal.c:\n           asmlinkage int\n           sys_rt_sigsuspend(sigset_t *unewset, size_t sigsetsize)\n         */\n        handle_sigsuspend(dcontext, (kernel_sigset_t *)sys_param(dcontext, 0),\n                          (size_t)sys_param(dcontext, 1));\n        break;\n    }\n#ifdef LINUX\n#    ifdef SYS_signalfd\n    case SYS_signalfd: /* 282/321 */\n#    endif\n    case SYS_signalfd4: { /* 289 */\n        /* int signalfd (int fd, const sigset_t *mask, size_t sizemask) */\n        /* int signalfd4(int fd, const sigset_t *mask, size_t sizemask, int flags) */\n        ptr_int_t new_result;\n        dcontext->sys_param0 = sys_param(dcontext, 0);\n        dcontext->sys_param1 = sys_param(dcontext, 1);\n        dcontext->sys_param2 = sys_param(dcontext, 2);\n#    ifdef SYS_signalfd\n        if (dcontext->sys_num == SYS_signalfd)\n            dcontext->sys_param3 = 0;\n        else\n#    endif\n            dcontext->sys_param3 = sys_param(dcontext, 3);\n        new_result = handle_pre_signalfd(\n            dcontext, (int)dcontext->sys_param0, (kernel_sigset_t *)dcontext->sys_param1,\n            (size_t)dcontext->sys_param2, (int)dcontext->sys_param3);\n        execute_syscall = false;\n        /* since non-Mac, we can use this even if the call failed */\n        set_success_return_val(dcontext, new_result);\n        break;\n    }\n#endif\n    case SYS_kill: { /* 37 */\n        /* in /usr/src/linux/kernel/signal.c:\n         * asmlinkage long sys_kill(int pid, int sig)\n         */\n        pid_t pid = (pid_t)sys_param(dcontext, 0);\n        uint sig = (uint)sys_param(dcontext, 1);\n        LOG(GLOBAL, LOG_TOP | LOG_SYSCALLS, 2,\n            \"thread \" TIDFMT \" sending signal %d to pid \" PIDFMT \"\\n\",\n            d_r_get_thread_id(), sig, pid);\n        /* We check whether targeting this process or this process group */\n        if (pid == get_process_id() || pid == 0 || pid == -get_process_group_id()) {\n            handle_self_signal(dcontext, sig);\n        }\n        break;\n    }\n#if defined(SYS_tkill)\n    case SYS_tkill: { /* 238 */\n        /* in /usr/src/linux/kernel/signal.c:\n         * asmlinkage long sys_tkill(int pid, int sig)\n         */\n        pid_t tid = (pid_t)sys_param(dcontext, 0);\n        uint sig = (uint)sys_param(dcontext, 1);\n        LOG(GLOBAL, LOG_TOP | LOG_SYSCALLS, 2,\n            \"thread \" TIDFMT \" sending signal %d to tid %d\\n\", d_r_get_thread_id(), sig,\n            tid);\n        if (tid == d_r_get_thread_id()) {\n            handle_self_signal(dcontext, sig);\n        }\n        break;\n    }\n#endif\n#if defined(SYS_tgkill)\n    case SYS_tgkill: { /* 270 */\n        /* in /usr/src/linux/kernel/signal.c:\n         * asmlinkage long sys_tgkill(int tgid, int pid, int sig)\n         */\n        pid_t tgid = (pid_t)sys_param(dcontext, 0);\n        pid_t tid = (pid_t)sys_param(dcontext, 1);\n        uint sig = (uint)sys_param(dcontext, 2);\n        LOG(GLOBAL, LOG_TOP | LOG_SYSCALLS, 2,\n            \"thread \" TIDFMT \" sending signal %d to tid %d tgid %d\\n\",\n            d_r_get_thread_id(), sig, tid, tgid);\n        /* some kernels support -1 values:\n         +   tgkill(-1, tid, sig)  == tkill(tid, sig)\n         *   tgkill(tgid, -1, sig) == kill(tgid, sig)\n         * the 2nd was proposed but is not in 2.6.20 so I'm ignoring it, since\n         * I don't want to kill the thread when the signal is never sent!\n         * FIXME: the 1st is in my tkill manpage, but not my 2.6.20 kernel sources!\n         */\n        if ((tgid == -1 || tgid == get_process_id()) && tid == d_r_get_thread_id()) {\n            handle_self_signal(dcontext, sig);\n        }\n        break;\n    }\n#endif\n    case SYS_setitimer: /* 104 */\n        dcontext->sys_param0 = sys_param(dcontext, 0);\n        dcontext->sys_param1 = sys_param(dcontext, 1);\n        dcontext->sys_param2 = sys_param(dcontext, 2);\n        handle_pre_setitimer(dcontext, (int)sys_param(dcontext, 0),\n                             (const struct itimerval *)sys_param(dcontext, 1),\n                             (struct itimerval *)sys_param(dcontext, 2));\n        break;\n    case SYS_getitimer: /* 105 */\n        dcontext->sys_param0 = sys_param(dcontext, 0);\n        dcontext->sys_param1 = sys_param(dcontext, 1);\n        break;\n#if defined(LINUX) && defined(X86)\n    case SYS_alarm: /* 27 on x86 and 37 on x64 */\n        dcontext->sys_param0 = sys_param(dcontext, 0);\n        handle_pre_alarm(dcontext, (unsigned int)dcontext->sys_param0);\n        break;\n#endif\n#if 0\n#    ifndef X64\n    case SYS_signal: {         /* 48 */\n        /* in /usr/src/linux/kernel/signal.c:\n           asmlinkage unsigned long\n           sys_signal(int sig, __sighandler_t handler)\n         */\n        break;\n    }\n    case SYS_sigsuspend: {     /* 72 */\n        /* in /usr/src/linux/arch/i386/kernel/signal.c:\n           asmlinkage int\n           sys_sigsuspend(int history0, int history1, old_sigset_t mask)\n         */\n        break;\n    }\n    case SYS_sigprocmask: {    /* 126 */\n        /* in /usr/src/linux/kernel/signal.c:\n           asmlinkage long\n           sys_sigprocmask(int how, old_sigset_t *set, old_sigset_t *oset)\n         */\n        break;\n    }\n#    endif\n#else\n        /* until we've implemented them, keep down here to get warning: */\n#    if defined(LINUX) && !defined(X64)\n#        ifndef ARM\n    case SYS_signal:\n#        endif\n    case SYS_sigsuspend:\n    case SYS_sigprocmask:\n#    endif\n#endif\n\n#if defined(LINUX) && !defined(X64)\n    case SYS_sigpending: /* 73 */\n#    ifndef ARM\n    case SYS_sgetmask: /* 68 */\n    case SYS_ssetmask: /* 69 */\n#    endif\n#endif\n#ifdef LINUX\n#    ifdef SYS_rt_sigtimedwait_time64\n    case SYS_rt_sigtimedwait_time64: /* 421 */\n#    endif\n    case SYS_rt_sigtimedwait: /* 177 */\n    case SYS_rt_sigqueueinfo: /* 178 */\n#endif\n    case IF_MACOS_ELSE(SYS_sigpending, SYS_rt_sigpending): { /* 176 */\n        /* FIXME i#92: handle all of these syscalls! */\n        LOG(THREAD, LOG_ASYNCH | LOG_SYSCALLS, 1,\n            \"WARNING: unhandled signal system call %d\\n\", dcontext->sys_num);\n        SYSLOG_INTERNAL_WARNING_ONCE(\"unhandled signal system call %d\",\n                                     dcontext->sys_num);\n        break;\n    }\n#ifdef LINUX\n#    ifdef SYS_ppoll_time64\n    case SYS_ppoll_time64:\n#    endif\n    case SYS_ppoll: {\n        kernel_sigset_t *sigmask = (kernel_sigset_t *)sys_param(dcontext, 3);\n        dcontext->sys_param3 = (reg_t)sigmask;\n        if (sigmask == NULL)\n            break;\n        size_t sizemask = (size_t)sys_param(dcontext, 4);\n        /* The original app's sigmask parameter is now NULL effectively making the syscall\n         * a non p* version, and the mask's semantics are emulated by DR instead.\n         */\n        set_syscall_param(dcontext, 3, (reg_t)NULL);\n        bool sig_pending = false;\n        if (!handle_pre_extended_syscall_sigmasks(dcontext, sigmask, sizemask,\n                                                  &sig_pending)) {\n            /* In old kernels with sizeof(kernel_sigset_t) != sizemask, we're forcing\n             * failure. We're already violating app transparency in other places in DR.\n             */\n            set_failure_return_val(dcontext, EINVAL);\n            DODEBUG({ dcontext->expect_last_syscall_to_fail = true; });\n            execute_syscall = false;\n        }\n        if (sig_pending) {\n            /* If there had been pending signals, we revert re-writing the app's\n             * parameter, but we leave the modified signal mask.\n             */\n            set_syscall_param(dcontext, 3, dcontext->sys_param3);\n            set_failure_return_val(dcontext, EINTR);\n            DODEBUG({ dcontext->expect_last_syscall_to_fail = true; });\n            execute_syscall = false;\n        }\n        break;\n    }\n#    ifdef SYS_pselect6_time64\n    case SYS_pselect6_time64:\n#    endif\n    case SYS_pselect6: {\n        typedef struct {\n            kernel_sigset_t *sigmask;\n            size_t sizemask;\n        } data_t;\n        dcontext->sys_param3 = sys_param(dcontext, 5);\n        data_t *data_param = (data_t *)dcontext->sys_param3;\n        data_t data;\n        if (data_param == NULL) {\n            /* The kernel does not consider a NULL 6th+7th-args struct to be an error but\n             * just a NULL sigmask.\n             */\n            dcontext->sys_param4 = (reg_t)NULL;\n            break;\n        }\n        /* Refer to comments in SYS_ppoll above. Taking extra steps here due to struct\n         * argument in pselect6.\n         */\n        if (!d_r_safe_read(data_param, sizeof(data), &data)) {\n            LOG(THREAD, LOG_SYSCALLS, 2, \"\\treturning EFAULT to app for pselect6\\n\");\n            set_failure_return_val(dcontext, EFAULT);\n            DODEBUG({ dcontext->expect_last_syscall_to_fail = true; });\n            execute_syscall = false;\n            break;\n        }\n        dcontext->sys_param4 = (reg_t)data.sigmask;\n        if (data.sigmask == NULL)\n            break;\n        kernel_sigset_t *nullsigmaskptr = NULL;\n        if (!safe_write_ex((void *)&data_param->sigmask, sizeof(data_param->sigmask),\n                           &nullsigmaskptr, NULL)) {\n            set_failure_return_val(dcontext, EFAULT);\n            DODEBUG({ dcontext->expect_last_syscall_to_fail = true; });\n            execute_syscall = false;\n            break;\n        }\n        bool sig_pending = false;\n        if (!handle_pre_extended_syscall_sigmasks(dcontext, data.sigmask, data.sizemask,\n                                                  &sig_pending)) {\n            set_failure_return_val(dcontext, EINVAL);\n            DODEBUG({ dcontext->expect_last_syscall_to_fail = true; });\n            execute_syscall = false;\n        }\n        if (sig_pending) {\n            if (!safe_write_ex((void *)&data_param->sigmask, sizeof(data_param->sigmask),\n                               &dcontext->sys_param4, NULL)) {\n                set_failure_return_val(dcontext, EFAULT);\n                DODEBUG({ dcontext->expect_last_syscall_to_fail = true; });\n                execute_syscall = false;\n                break;\n            }\n            set_failure_return_val(dcontext, EINTR);\n            DODEBUG({ dcontext->expect_last_syscall_to_fail = true; });\n            execute_syscall = false;\n        }\n        break;\n    }\n    case SYS_epoll_pwait: {\n        kernel_sigset_t *sigmask = (kernel_sigset_t *)sys_param(dcontext, 4);\n        dcontext->sys_param4 = (reg_t)sigmask;\n        if (sigmask == NULL)\n            break;\n        size_t sizemask = (size_t)sys_param(dcontext, 5);\n        /* Refer to comments in SYS_ppoll above. */\n        set_syscall_param(dcontext, 4, (reg_t)NULL);\n        bool sig_pending = false;\n        if (!handle_pre_extended_syscall_sigmasks(dcontext, sigmask, sizemask,\n                                                  &sig_pending)) {\n            set_failure_return_val(dcontext, EINVAL);\n            DODEBUG({ dcontext->expect_last_syscall_to_fail = true; });\n            execute_syscall = false;\n        }\n        if (sig_pending) {\n            set_syscall_param(dcontext, 4, dcontext->sys_param4);\n            set_failure_return_val(dcontext, EINTR);\n            DODEBUG({ dcontext->expect_last_syscall_to_fail = true; });\n            execute_syscall = false;\n        }\n        break;\n    }\n#endif\n\n    /****************************************************************************/\n    /* FILES */\n    /* prevent app from closing our files or opening a new file in our fd space.\n     * it's not worth monitoring all syscalls that take in fds from affecting ours.\n     */\n\n#ifdef MACOS\n    case SYS_close_nocancel:\n#endif\n#ifdef SYS_close_range\n    case SYS_close_range: {\n        /* client.file_io indeed tests this for all arch, but it hasn't yet been\n         * run on an AArchXX machine that has close_range available.\n         */\n        IF_AARCHXX(ASSERT_NOT_TESTED());\n        uint first_fd = sys_param(dcontext, 0), last_fd = sys_param(dcontext, 1);\n        uint flags = sys_param(dcontext, 2);\n        bool is_cloexec = TEST(CLOSE_RANGE_CLOEXEC, flags);\n        if (is_cloexec) {\n            /* client.file_io has a test for CLOSE_RANGE_CLOEXEC, but it hasn't been\n             * verified on a system with kernel version >= 5.11 yet.\n             */\n            ASSERT_NOT_TESTED();\n        }\n        /* We do not let the app execute their own close_range ever. Instead we\n         * make multiple close_range syscalls ourselves, one for each contiguous\n         * sub-range of non-DR-private fds in [first, last].\n         */\n        execute_syscall = false;\n        if (first_fd > last_fd) {\n            set_failure_return_val(dcontext, EINVAL);\n            DODEBUG({ dcontext->expect_last_syscall_to_fail = true; });\n            break;\n        }\n        uint cur_range_first_fd, cur_range_last_fd;\n        bool cur_range_valid = false;\n        int ret = 0;\n        for (int i = first_fd; i <= last_fd; i++) {\n            /* Do not allow any changes to DR-owned FDs. */\n            if ((is_cloexec && fd_is_dr_owned(i)) ||\n                (!is_cloexec && !handle_close_range_pre(dcontext, i))) {\n                SYSLOG_INTERNAL_WARNING_ONCE(\"app trying to close private fd(s)\");\n                if (cur_range_valid) {\n                    cur_range_valid = false;\n                    ret = dynamorio_syscall(SYS_close_range, 3, cur_range_first_fd,\n                                            cur_range_last_fd, flags);\n                    if (ret != 0)\n                        break;\n                }\n            } else {\n#    ifdef LINUX\n                if (!is_cloexec) {\n                    signal_handle_close(dcontext, i);\n                }\n#    endif\n                if (cur_range_valid) {\n                    ASSERT(cur_range_last_fd == i - 1);\n                    cur_range_last_fd = i;\n                } else {\n                    cur_range_first_fd = i;\n                    cur_range_last_fd = i;\n                    cur_range_valid = true;\n                }\n            }\n        }\n        if (cur_range_valid) {\n            ret = dynamorio_syscall(SYS_close_range, 3, cur_range_first_fd,\n                                    cur_range_last_fd, flags);\n        }\n        if (ret != 0) {\n            set_failure_return_val(dcontext, ret);\n            DODEBUG({ dcontext->expect_last_syscall_to_fail = true; });\n        } else {\n            set_success_return_val(dcontext, 0);\n        }\n        break;\n    }\n#endif\n    case SYS_close: {\n        execute_syscall = handle_close_pre(dcontext);\n#ifdef LINUX\n        if (execute_syscall)\n            signal_handle_close(dcontext, (file_t)sys_param(dcontext, 0));\n#endif\n        break;\n    }\n#if defined(SYS_dup2) || defined(SYS_dup3)\n#    ifdef SYS_dup3\n    case SYS_dup3:\n#    endif\n#    ifdef SYS_dup2\n    case SYS_dup2:\n#    endif\n    {\n        file_t newfd = (file_t)sys_param(dcontext, 1);\n        if (fd_is_dr_owned(newfd) || fd_is_in_private_range(newfd)) {\n            SYSLOG_INTERNAL_WARNING_ONCE(\"app trying to dup-close DR file(s)\");\n            LOG(THREAD, LOG_TOP | LOG_SYSCALLS, 1,\n                \"WARNING: app trying to dup2/dup3 to %d.  Disallowing.\\n\", newfd);\n            if (DYNAMO_OPTION(fail_on_stolen_fds)) {\n                set_failure_return_val(dcontext, EBADF);\n                DODEBUG({ dcontext->expect_last_syscall_to_fail = true; });\n            } else\n                set_success_return_val(dcontext, 0);\n            execute_syscall = false;\n        }\n        break;\n    }\n#endif\n\n#ifdef MACOS\n    case SYS_fcntl_nocancel:\n#endif\n    case SYS_fcntl: {\n        int cmd = (int)sys_param(dcontext, 1);\n        long arg = (long)sys_param(dcontext, 2);\n        /* we only check for asking for min in private space: not min below\n         * but actual will be above (see notes in os_file_init())\n         */\n        if ((cmd == F_DUPFD || cmd == F_DUPFD_CLOEXEC) && fd_is_in_private_range(arg)) {\n            SYSLOG_INTERNAL_WARNING_ONCE(\"app trying to open private fd(s)\");\n            LOG(THREAD, LOG_TOP | LOG_SYSCALLS, 1,\n                \"WARNING: app trying to dup to >= %d.  Disallowing.\\n\", arg);\n            set_failure_return_val(dcontext, EINVAL);\n            DODEBUG({ dcontext->expect_last_syscall_to_fail = true; });\n            execute_syscall = false;\n        } else {\n            dcontext->sys_param0 = sys_param(dcontext, 0);\n            dcontext->sys_param1 = cmd;\n        }\n        break;\n    }\n\n#if defined(X64) || !defined(ARM) || defined(MACOS)\n    case SYS_getrlimit:\n#endif\n#if defined(LINUX) && !defined(X64)\n    case SYS_ugetrlimit:\n#endif\n        /* save for post */\n        dcontext->sys_param0 = sys_param(dcontext, 0); /* resource */\n        dcontext->sys_param1 = sys_param(dcontext, 1); /* rlimit */\n        break;\n\n    case SYS_setrlimit: {\n        int resource = (int)sys_param(dcontext, 0);\n        if (resource == RLIMIT_NOFILE && DYNAMO_OPTION(steal_fds) > 0) {\n#if !defined(ARM) && !defined(X64) && !defined(MACOS)\n            struct compat_rlimit rlim;\n#else\n            struct rlimit rlim;\n#endif\n            if (!d_r_safe_read((void *)sys_param(dcontext, 1), sizeof(rlim), &rlim)) {\n                LOG(THREAD, LOG_SYSCALLS, 2, \"\\treturning EFAULT to app for prlimit64\\n\");\n                set_failure_return_val(dcontext, EFAULT);\n                DODEBUG({ dcontext->expect_last_syscall_to_fail = true; });\n            } else if (rlim.rlim_cur > rlim.rlim_max) {\n                LOG(THREAD, LOG_SYSCALLS, 2, \"\\treturning EINVAL for prlimit64\\n\");\n                set_failure_return_val(dcontext, EINVAL);\n                DODEBUG({ dcontext->expect_last_syscall_to_fail = true; });\n            } else if (rlim.rlim_max <= min_dr_fd &&\n                       /* Can't raise hard unless have CAP_SYS_RESOURCE capability.\n                        * XXX i#2980: should query for that capability.\n                        */\n                       rlim.rlim_max <= app_rlimit_nofile.rlim_max) {\n                /* if the new rlimit is lower, pretend succeed */\n                app_rlimit_nofile.rlim_cur = rlim.rlim_cur;\n                app_rlimit_nofile.rlim_max = rlim.rlim_max;\n                set_success_return_val(dcontext, 0);\n            } else {\n                LOG(THREAD, LOG_SYSCALLS, 2, \"\\treturning EPERM to app for setrlimit\\n\");\n                /* don't let app raise limits as that would mess up our fd space */\n                set_failure_return_val(dcontext, EPERM);\n                DODEBUG({ dcontext->expect_last_syscall_to_fail = true; });\n            }\n            execute_syscall = false;\n        }\n        break;\n    }\n\n#ifdef LINUX\n    case SYS_prlimit64:\n        /* save for post */\n        dcontext->sys_param0 = sys_param(dcontext, 0); /* pid */\n        dcontext->sys_param1 = sys_param(dcontext, 1); /* resource */\n        dcontext->sys_param2 = sys_param(dcontext, 2); /* new rlimit */\n        dcontext->sys_param3 = sys_param(dcontext, 3); /* old rlimit */\n        if (/* XXX: how do we handle the case of setting rlimit.nofile on another\n             * process that is running with DynamoRIO?\n             */\n            /* XXX: CLONE_FILES allows different processes to share the same file\n             * descriptor table, and different threads of the same process have\n             * separate file descriptor tables.  POSIX specifies that rlimits are\n             * per-process, not per-thread, and Linux follows suit, so the threads\n             * with different descriptors will not matter, and the pids sharing\n             * descriptors turns into the hard-to-solve IPC problem.\n             */\n            (dcontext->sys_param0 == 0 || dcontext->sys_param0 == get_process_id()) &&\n            dcontext->sys_param1 == RLIMIT_NOFILE &&\n            dcontext->sys_param2 != (reg_t)NULL && DYNAMO_OPTION(steal_fds) > 0) {\n            rlimit64_t rlim;\n            if (!d_r_safe_read((void *)(dcontext->sys_param2), sizeof(rlim), &rlim)) {\n                LOG(THREAD, LOG_SYSCALLS, 2, \"\\treturning EFAULT to app for prlimit64\\n\");\n                set_failure_return_val(dcontext, EFAULT);\n                DODEBUG({ dcontext->expect_last_syscall_to_fail = true; });\n            } else {\n                LOG(THREAD, LOG_SYSCALLS, 2,\n                    \"syscall: prlimit64 soft=\" INT64_FORMAT_STRING\n                    \" hard=\" INT64_FORMAT_STRING \" vs DR %d\\n\",\n                    rlim.rlim_cur, rlim.rlim_max, min_dr_fd);\n                if (rlim.rlim_cur > rlim.rlim_max) {\n                    LOG(THREAD, LOG_SYSCALLS, 2, \"\\treturning EINVAL for prlimit64\\n\");\n                    set_failure_return_val(dcontext, EINVAL);\n                    DODEBUG({ dcontext->expect_last_syscall_to_fail = true; });\n                } else if (rlim.rlim_max <= min_dr_fd &&\n                           /* Can't raise hard unless have CAP_SYS_RESOURCE capability.\n                            * XXX i#2980: should query for that capability.\n                            */\n                           rlim.rlim_max <= app_rlimit_nofile.rlim_max) {\n                    /* if the new rlimit is lower, pretend succeed */\n                    app_rlimit_nofile.rlim_cur = rlim.rlim_cur;\n                    app_rlimit_nofile.rlim_max = rlim.rlim_max;\n                    set_success_return_val(dcontext, 0);\n                    /* set old rlimit if necessary */\n                    if (dcontext->sys_param3 != (reg_t)NULL) {\n                        safe_write_ex((void *)(dcontext->sys_param3), sizeof(rlim),\n                                      &app_rlimit_nofile, NULL);\n                    }\n                } else {\n                    /* don't let app raise limits as that would mess up our fd space */\n                    LOG(THREAD, LOG_SYSCALLS, 2,\n                        \"\\treturning EPERM to app for prlimit64\\n\");\n                    set_failure_return_val(dcontext, EPERM);\n                    DODEBUG({ dcontext->expect_last_syscall_to_fail = true; });\n                }\n            }\n            execute_syscall = false;\n        }\n        break;\n#endif\n\n#ifdef LINUX\n#    ifdef SYS_readlink\n    case SYS_readlink:\n#    endif\n    case SYS_readlinkat:\n        if (DYNAMO_OPTION(early_inject)) {\n            dcontext->sys_param0 = sys_param(dcontext, 0);\n            dcontext->sys_param1 = sys_param(dcontext, 1);\n            dcontext->sys_param2 = sys_param(dcontext, 2);\n            if (dcontext->sys_num == SYS_readlinkat)\n                dcontext->sys_param3 = sys_param(dcontext, 3);\n        }\n        break;\n\n        /* i#107 syscalls that might change/query app's segment */\n\n#    if defined(X86) && defined(X64)\n    case SYS_arch_prctl: {\n        /* we handle arch_prctl in post_syscall */\n        dcontext->sys_param0 = sys_param(dcontext, 0);\n        dcontext->sys_param1 = sys_param(dcontext, 1);\n        break;\n    }\n#    endif\n#    ifdef X86\n    case SYS_set_thread_area: {\n        our_modify_ldt_t desc;\n        if (INTERNAL_OPTION(mangle_app_seg) &&\n            d_r_safe_read((void *)sys_param(dcontext, 0), sizeof(desc), &desc)) {\n            if (os_set_app_thread_area(dcontext, &desc) &&\n                safe_write_ex((void *)sys_param(dcontext, 0), sizeof(desc), &desc,\n                              NULL)) {\n                /* check if the range is unlimited */\n                ASSERT_CURIOSITY(desc.limit == 0xfffff);\n                execute_syscall = false;\n                set_success_return_val(dcontext, 0);\n            }\n        }\n        break;\n    }\n    case SYS_get_thread_area: {\n        our_modify_ldt_t desc;\n        if (INTERNAL_OPTION(mangle_app_seg) &&\n            d_r_safe_read((const void *)sys_param(dcontext, 0), sizeof(desc), &desc)) {\n            if (os_get_app_thread_area(dcontext, &desc) &&\n                safe_write_ex((void *)sys_param(dcontext, 0), sizeof(desc), &desc,\n                              NULL)) {\n                execute_syscall = false;\n                set_success_return_val(dcontext, 0);\n            }\n        }\n        break;\n    }\n#    endif /* X86 */\n#    ifdef ARM\n    case SYS_set_tls: {\n        LOG(THREAD, LOG_VMAREAS | LOG_SYSCALLS, 2, \"syscall: set_tls \" PFX \"\\n\",\n            sys_param(dcontext, 0));\n        if (os_set_app_tls_base(dcontext, TLS_REG_LIB, (void *)sys_param(dcontext, 0))) {\n            execute_syscall = false;\n            set_success_return_val(dcontext, 0);\n        } else {\n            ASSERT_NOT_REACHED();\n        }\n        break;\n    }\n    case SYS_cacheflush: {\n        /* We assume we don't want to change the executable_areas list or change\n         * the selfmod status of this region: else we should call something\n         * that invokes handle_modified_code() in a way that handles a bigger\n         * region than a single write.\n         */\n        app_pc start = (app_pc)sys_param(dcontext, 0);\n        app_pc end = (app_pc)sys_param(dcontext, 1);\n        LOG(THREAD, LOG_VMAREAS | LOG_SYSCALLS, 2,\n            \"syscall: cacheflush \" PFX \"-\" PFX \"\\n\", start, end);\n        flush_fragments_from_region(dcontext, start, end - start,\n                                    /* An unlink flush should be fine: the app must\n                                     * use synch to ensure other threads see the\n                                     * new code.\n                                     */\n                                    false /*don't force synchall*/,\n                                    NULL /*flush_completion_callback*/,\n                                    NULL /*user_data*/);\n        break;\n    }\n#    endif /* ARM */\n#elif defined(MACOS)\n    /* FIXME i#58: handle i386_{get,set}_ldt and thread_fast_set_cthread_self64 */\n#endif\n\n#ifdef DEBUG\n#    ifdef MACOS\n    case SYS_open_nocancel:\n#    endif\n#    ifdef SYS_open\n    case SYS_open: {\n        dcontext->sys_param0 = sys_param(dcontext, 0);\n        break;\n    }\n#    endif\n#endif\n#ifdef SYS_openat2\n    case SYS_openat2:\n#endif\n    case SYS_openat: {\n        /* XXX: For completeness we might want to replace paths for SYS_open and\n         * possibly others, but SYS_openat is all we need on modern systems so we\n         * limit syscall overhead to this single point for now.\n         */\n        dcontext->sys_param0 = 0;\n        dcontext->sys_param1 = sys_param(dcontext, 1);\n        const char *path = (const char *)dcontext->sys_param1;\n        if (!IS_STRING_OPTION_EMPTY(xarch_root) && !os_file_exists(path, false)) {\n            char *buf = heap_alloc(dcontext, MAXIMUM_PATH HEAPACCT(ACCT_OTHER));\n            string_option_read_lock();\n            snprintf(buf, MAXIMUM_PATH, \"%s/%s\", DYNAMO_OPTION(xarch_root), path);\n            buf[MAXIMUM_PATH - 1] = '\\0';\n            string_option_read_unlock();\n            if (os_file_exists(buf, false)) {\n                LOG(THREAD, LOG_SYSCALLS, 2, \"SYS_openat: replacing |%s| with |%s|\\n\",\n                    path, buf);\n                set_syscall_param(dcontext, 1, (reg_t)buf);\n                /* Save for freeing in post. */\n                dcontext->sys_param0 = (reg_t)buf;\n            } else\n                heap_free(dcontext, buf, MAXIMUM_PATH HEAPACCT(ACCT_OTHER));\n        }\n        break;\n    }\n#ifdef LINUX\n    case SYS_rseq:\n        LOG(THREAD, LOG_VMAREAS | LOG_SYSCALLS, 2, \"syscall: rseq \" PFX \" %d %d %d\\n\",\n            sys_param(dcontext, 0), sys_param(dcontext, 1), sys_param(dcontext, 2),\n            sys_param(dcontext, 3));\n        if (DYNAMO_OPTION(disable_rseq)) {\n            set_failure_return_val(dcontext, ENOSYS);\n            DODEBUG({ dcontext->expect_last_syscall_to_fail = true; });\n            execute_syscall = false;\n        } else {\n            dcontext->sys_param0 = sys_param(dcontext, 0);\n        }\n        break;\n#endif\n    default: {\n#ifdef VMX86_SERVER\n        if (is_vmkuw_sysnum(dcontext->sys_num)) {\n            execute_syscall = vmkuw_pre_system_call(dcontext);\n            break;\n        }\n#endif\n        break;\n    }\n\n    } /* end switch */\n\n    dcontext->whereami = old_whereami;\n    return execute_syscall;\n}\n\nvoid\nall_memory_areas_lock(void)\n{\n    IF_NO_MEMQUERY(memcache_lock());\n}\n\nvoid\nall_memory_areas_unlock(void)\n{\n    IF_NO_MEMQUERY(memcache_unlock());\n}\n\nvoid\nupdate_all_memory_areas(app_pc start, app_pc end, uint prot, int type)\n{\n    IF_NO_MEMQUERY(memcache_update(start, end, prot, type));\n}\n\nbool\nremove_from_all_memory_areas(app_pc start, app_pc end)\n{\n    IF_NO_MEMQUERY(return memcache_remove(start, end));\n    return true;\n}\n\n/* We consider a module load to happen at the first mmap, so we check on later\n * overmaps to ensure things look consistent. */\nstatic bool\nmmap_check_for_module_overlap(app_pc base, size_t size, bool readable, uint64 inode,\n                              bool at_map)\n{\n    module_area_t *ma;\n\n    os_get_module_info_lock();\n    ma = module_pc_lookup(base);\n    if (ma != NULL) {\n        /* FIXME - how can we distinguish between the loader mapping the segments\n         * over the initial map from someone just mapping over part of a module? If\n         * is the latter case need to adjust the view size or remove from module list. */\n        LOG(GLOBAL, LOG_VMAREAS, 2,\n            \"%s mmap overlapping module area : \\n\"\n            \"\\tmap : base=\" PFX \" base+size=\" PFX \" inode=\" UINT64_FORMAT_STRING \"\\n\"\n            \"\\tmod : start=\" PFX \" end=\" PFX \" inode=\" UINT64_FORMAT_STRING \"\\n\",\n            at_map ? \"new\" : \"existing\", base, base + size, inode, ma->start, ma->end,\n            ma->names.inode);\n        ASSERT_CURIOSITY(base >= ma->start);\n        if (at_map) {\n            ASSERT_CURIOSITY(base + size <= ma->end);\n        } else {\n            /* FIXME - I'm having problems with this check for existing maps.  I\n             * haven't been able to get gdb to break in early enough to really get a good\n             * look at the early loader behavior.  Two issues:  One case is with our .so\n             * for which the anonymous .bss mapping is one page larger than expected\n             * (which might be some loader bug in the size calculation? or something? if\n             * so should see it trigger the at_map curiosity on some dll and can address\n             * then) and the other is that for a few executables the .bss mapping is much\n             * larger (~0x20000 larger) then expected when running under DR (but not\n             * running natively where it is instead the expected size).  Both could just\n             * be the loader merging adjacent identically protected regions though I\n             * can't explain the discrepancy between DR and native given that our vmmheap\n             * is elsewhere in the address space (so who and how allocated that adjacent\n             * memory). I've yet to see any issue with dynamically loaded modules so\n             * it's probably the loader merging regions.  Still worth investigating. */\n            ASSERT_CURIOSITY(inode == 0 /*see above comment*/ ||\n                             module_contains_addr(ma, base + size - 1));\n        }\n        /* Handle cases like transparent huge pages where there are anon regions on top\n         * of the file mapping (i#2566).\n         */\n        if (ma->names.inode == 0)\n            ma->names.inode = inode;\n        ASSERT_CURIOSITY(ma->names.inode == inode || inode == 0 /* for .bss */);\n        DOCHECK(1, {\n            if (readable && module_is_header(base, size)) {\n                /* Case 8879: For really small modules, to save disk space, the same\n                 * disk page could hold both RO and .data, occupying just 1 page of\n                 * disk space, e.g. /usr/lib/httpd/modules/mod_auth_anon.so.  When\n                 * such a module is mapped in, the os maps the same disk page twice,\n                 * one readonly and one copy-on-write (see pg.  96, Sec 4.4 from\n                 * Linkers and Loaders by John R.  Levine). It also possible for\n                 * such small modules to have multiple LOAD data segments. Since all\n                 * these segments are mapped from a single disk page they will all have an\n                 * elf_header satisfying the check above. So, if the new mmap overlaps an\n                 * elf_area and it is also a header, then make sure the offsets (from the\n                 * beginning of the backing file) of all the segments up to the currect\n                 * one are within the page size. Note, if it is a header of a different\n                 * module, then we'll not have an overlap, so we will not hit this case.\n                 */\n                bool cur_seg_found = false;\n                int seg_id = 0;\n                while (seg_id < ma->os_data.num_segments &&\n                       ma->os_data.segments[seg_id].start <= base) {\n                    cur_seg_found = ma->os_data.segments[seg_id].start == base;\n                    ASSERT_CURIOSITY(\n                        ma->os_data.segments[seg_id].offset <\n                        PAGE_SIZE\n                            /* On Mac we walk the dyld module list before the\n                             * address space, so we often hit modules we already\n                             * know about. */\n                            IF_MACOS(|| !dynamo_initialized && ma->start == base));\n                    ++seg_id;\n                }\n                ASSERT_CURIOSITY(cur_seg_found);\n            }\n        });\n    }\n    os_get_module_info_unlock();\n#ifdef ANDROID\n    /* i#1860: we need to keep looking for the segment with .dynamic as Android's\n     * loader does not map the whole file up front.\n     */\n    if (ma != NULL && at_map && readable)\n        os_module_update_dynamic_info(base, size, at_map);\n#endif\n    return ma != NULL;\n}\n\nstatic void\nos_add_new_app_module(dcontext_t *dcontext, bool at_map, app_pc base, size_t size,\n                      uint memprot)\n{\n    memquery_iter_t iter;\n    bool found_map = false;\n    uint64 inode = 0;\n    const char *filename = \"\";\n    size_t mod_size = size;\n\n    if (!at_map) {\n        /* the size is the first seg size, get the whole module size instead */\n        app_pc first_seg_base = NULL;\n        app_pc first_seg_end = NULL;\n        app_pc last_seg_end = NULL;\n        if (module_walk_program_headers(base, size, at_map, false, &first_seg_base,\n                                        &first_seg_end, &last_seg_end, NULL, NULL)) {\n            ASSERT_CURIOSITY(size ==\n                                 (ALIGN_FORWARD(first_seg_end, PAGE_SIZE) -\n                                  (ptr_uint_t)first_seg_base) ||\n                             base == vdso_page_start || base == vsyscall_page_start);\n            mod_size =\n                ALIGN_FORWARD(last_seg_end, PAGE_SIZE) - (ptr_uint_t)first_seg_base;\n        }\n    }\n    LOG(THREAD, LOG_SYSCALLS | LOG_VMAREAS, 2, \"dlopen \" PFX \"-\" PFX \"%s\\n\", base,\n        base + mod_size, TEST(MEMPROT_EXEC, memprot) ? \" +x\" : \"\");\n\n    /* Mapping in a new module.  From what we've observed of the loader's\n     * behavior, it first maps the file in with size equal to the final\n     * memory image size (I'm not sure how it gets that size without reading\n     * in the elf header and then walking through all the program headers to\n     * get the largest virtual offset).  This is necessary to reserve all the\n     * space that will be needed.  It then walks through the program headers\n     * mapping over the the previously mapped space with the appropriate\n     * permissions and offsets.  Note that the .bss portion is mapped over\n     * as anonymous.  It may also, depending on the program headers, make some\n     * areas read-only after fixing up their relocations etc. NOTE - at\n     * no point are the section headers guaranteed to be mapped in so we can't\n     * reliably walk sections (only segments) without looking to disk.\n     */\n    /* FIXME - when should we add the module to our list?  At the first map\n     * seems to be the best choice as we know the bounds and it's difficult to\n     * tell when the loader is finished.  The downside is that at the initial map\n     * the memory layout isn't finalized (memory beyond the first segment will\n     * be shifted for page alignment reasons), so we have to be careful and\n     * make adjustments to read anything beyond the first segment until the\n     * loader finishes. This goes for the client too as it gets notified when we\n     * add to the list.  FIXME we could try to track the expected segment overmaps\n     * and only notify the client after the last one (though that's still before\n     * linking and relocation, but that's true on Windows too). */\n    /* Get filename & inode for the list. */\n    memquery_iterator_start(&iter, base, true /* plan to alloc a module_area_t */);\n    while (memquery_iterator_next(&iter)) {\n        if (iter.vm_start == base) {\n            ASSERT_CURIOSITY(iter.inode != 0 || base == vdso_page_start ||\n                             base == vsyscall_page_start);\n            ASSERT_CURIOSITY(iter.offset == 0); /* first map shouldn't have offset */\n            /* XREF 307599 on rounding module end to the next PAGE boundary */\n            ASSERT_CURIOSITY(\n                (iter.vm_end - iter.vm_start == ALIGN_FORWARD(size, PAGE_SIZE)));\n            inode = iter.inode;\n            filename = dr_strdup(iter.comment HEAPACCT(ACCT_OTHER));\n            found_map = true;\n            break;\n        }\n    }\n    memquery_iterator_stop(&iter);\n#ifdef HAVE_MEMINFO\n    /* barring weird races we should find this map except */\n    ASSERT_CURIOSITY(found_map);\n#else  /* HAVE_MEMINFO */\n    /* Without /proc/maps or other memory querying interface available at\n     * library map time, there is no way to find out the name of the file\n     * that was mapped, thus its inode isn't available either.\n     *\n     * Just module_list_add with no filename will still result in\n     * library name being extracted from the .dynamic section and added\n     * to the module list.  However, this name may not always exist, thus\n     * we might have a library with no file name available at all!\n     *\n     * Note: visor implements vsi mem maps that give file info, but, no\n     *       path, should be ok.  xref PR 401580.\n     *\n     * Once PR 235433 is implemented in visor then fix memquery_iterator*() to\n     * use vsi to find out page protection info, file name & inode.\n     */\n#endif /* HAVE_MEMINFO */\n    /* XREF 307599 on rounding module end to the next PAGE boundary */\n    if (found_map) {\n        module_list_add(base, ALIGN_FORWARD(mod_size, PAGE_SIZE), at_map, filename,\n                        inode);\n        dr_strfree(filename HEAPACCT(ACCT_OTHER));\n    }\n}\n\nvoid\nos_check_new_app_module(dcontext_t *dcontext, app_pc pc)\n{\n    module_area_t *ma;\n    os_get_module_info_lock();\n    ma = module_pc_lookup(pc);\n    /* ma might be NULL due to dynamic generated code or custom loaded modules */\n    if (ma == NULL) {\n        dr_mem_info_t info;\n        /* i#1760: an app module loaded by custom loader (e.g., bionic libc)\n         * might not be detected by DynamoRIO in process_mmap.\n         */\n        if (query_memory_ex_from_os(pc, &info) && info.type == DR_MEMTYPE_IMAGE) {\n            /* add the missing module */\n            os_get_module_info_unlock();\n            os_add_new_app_module(get_thread_private_dcontext(), false /*!at_map*/,\n                                  info.base_pc, info.size, info.prot);\n            os_get_module_info_lock();\n        }\n    }\n    os_get_module_info_unlock();\n}\n\n/* All processing for mmap and mmap2. */\nstatic void\nprocess_mmap(dcontext_t *dcontext, app_pc base, size_t size, uint prot,\n             uint flags _IF_DEBUG(const char *map_type))\n{\n    bool image = false;\n    uint memprot = osprot_to_memprot(prot);\n#ifdef ANDROID\n    /* i#1861: avoid merging file-backed w/ anon regions */\n    if (!TEST(MAP_ANONYMOUS, flags))\n        memprot |= MEMPROT_HAS_COMMENT;\n#endif\n\n    LOG(THREAD, LOG_SYSCALLS, 4, \"process_mmap(\" PFX \",\" PFX \",0x%x,%s,%s)\\n\", base, size,\n        flags, memprot_string(memprot), map_type);\n    /* Notes on how ELF SOs are mapped in.\n     *\n     * o The initial mmap for an ELF file specifies enough space for\n     *   all segments (and their constituent sections) in the file.\n     *   The protection bits for that section are used for the entire\n     *   region, and subsequent mmaps for subsequent segments within\n     *   the region modify their portion's protection bits as needed.\n     *   So if the prot bits for the first segment are +x, the entire\n     *   region is +x. ** Note that our primary concern is adjusting\n     *   exec areas to reflect the prot bits of subsequent\n     *   segments. ** The region is added to the all-memory areas\n     *   and also to exec areas (as determined by app_memory_allocation()).\n     *\n     * o Any subsequent segment sub-mappings specify their own protection\n     *   bits and therefore are added to the exec areas via normal\n     *   processing. They are also \"naturally\" added to the all-mems list.\n     *   We do a little extra processing when mapping into a previously\n     *   mapped region and the prot bits mismatch; if the new mapping is\n     *   not +x, flushing needs to occur.\n     */\n    /* process_mmap can be called with PROT_NONE, so we need to check if we\n     * can read the memory to see if it is a elf_header\n     */\n    /* XXX: get inode for check */\n    if (TEST(MAP_ANONYMOUS, flags)) {\n        /* not an ELF mmap */\n        LOG(THREAD, LOG_SYSCALLS, 4, \"mmap \" PFX \": anon\\n\", base);\n    } else if (mmap_check_for_module_overlap(base, size, TEST(MEMPROT_READ, memprot), 0,\n                                             true)) {\n        /* FIXME - how can we distinguish between the loader mapping the segments\n         * over the initial map from someone just mapping over part of a module? If\n         * is the latter case need to adjust the view size or remove from module list. */\n        image = true;\n        DODEBUG({ map_type = \"ELF SO\"; });\n        LOG(THREAD, LOG_SYSCALLS, 4, \"mmap \" PFX \": overlaps image\\n\", base);\n    } else if (TEST(MEMPROT_READ, memprot) &&\n               /* i#727: We can still get SIGBUS on mmap'ed files that can't be\n                * read, so pass size=0 to use a safe_read.\n                */\n               module_is_header(base, 0)) {\n#ifdef ANDROID\n        /* The Android loader's initial all-segment-covering mmap is anonymous */\n        dr_mem_info_t info;\n        if (query_memory_ex_from_os((byte *)ALIGN_FORWARD(base + size, PAGE_SIZE),\n                                    &info) &&\n            info.prot == MEMPROT_NONE && info.type == DR_MEMTYPE_DATA) {\n            LOG(THREAD, LOG_SYSCALLS, 4, \"mmap \" PFX \": Android elf\\n\", base);\n            image = true;\n            DODEBUG({ map_type = \"ELF SO\"; });\n            os_add_new_app_module(dcontext, true /*at_map*/, base,\n                                  /* pass segment size, not whole module size */\n                                  size, memprot);\n        } else\n#endif\n            if (module_is_partial_map(base, size, memprot)) {\n            /* i#1240: App might read first page of ELF header using mmap, which\n             * might accidentally be treated as a module load. Heuristically\n             * distinguish this by saying that if this is the first mmap for an ELF\n             * (i.e., it doesn't overlap with a previous map), and if it's small,\n             * then don't treat it as a module load.\n             */\n            LOG(THREAD, LOG_SYSCALLS, 4, \"mmap \" PFX \": partial\\n\", base);\n        } else {\n            LOG(THREAD, LOG_SYSCALLS, 4, \"mmap \" PFX \": elf header\\n\", base);\n            image = true;\n            DODEBUG({ map_type = \"ELF SO\"; });\n            os_add_new_app_module(dcontext, true /*at_map*/, base, size, memprot);\n        }\n    }\n\n    LOG(THREAD, LOG_SYSCALLS, 4, \"\\t try app_mem_alloc\\n\");\n    IF_NO_MEMQUERY(memcache_handle_mmap(dcontext, base, size, memprot, image));\n    if (app_memory_allocation(dcontext, base, size, memprot, image _IF_DEBUG(map_type)))\n        STATS_INC(num_app_code_modules);\n    LOG(THREAD, LOG_SYSCALLS, 4, \"\\t app_mem_alloc -- DONE\\n\");\n}\n\n#ifdef LINUX\n/* Call right after the system call.\n * i#173: old_prot and old_type should be from before the system call\n */\nstatic bool\nhandle_app_mremap(dcontext_t *dcontext, byte *base, size_t size, byte *old_base,\n                  size_t old_size, uint old_prot, uint old_type)\n{\n    if (!mmap_syscall_succeeded(base))\n        return false;\n    if (base != old_base || size < old_size) { /* take action only if\n                                                * there was a change */\n        DEBUG_DECLARE(bool ok;)\n        /* fragments were shifted...don't try to fix them, just flush */\n        app_memory_deallocation(dcontext, (app_pc)old_base, old_size,\n                                false /* don't own thread_initexit_lock */,\n                                false /* not image, FIXME: somewhat arbitrary */);\n        DOCHECK(1, {\n            /* we don't expect to see remappings of modules */\n            os_get_module_info_lock();\n            ASSERT_CURIOSITY(!module_overlaps(base, size));\n            os_get_module_info_unlock();\n        });\n        /* Verify that the current prot on the new region (according to\n         * the os) is the same as what the prot used to be for the old\n         * region.\n         */\n        DOCHECK(1, {\n            uint memprot;\n            ok = get_memory_info_from_os(base, NULL, NULL, &memprot);\n            /* allow maps to have +x,\n             * +x may be caused by READ_IMPLIES_EXEC set in personality flag (i#262)\n             */\n            ASSERT(ok &&\n                   (memprot == old_prot || (memprot & (~MEMPROT_EXEC)) == old_prot));\n        });\n        app_memory_allocation(dcontext, base, size, old_prot,\n                              old_type == DR_MEMTYPE_IMAGE _IF_DEBUG(\"mremap\"));\n        IF_NO_MEMQUERY(memcache_handle_mremap(dcontext, base, size, old_base, old_size,\n                                              old_prot, old_type));\n    }\n    return true;\n}\n\nstatic void\nhandle_app_brk(dcontext_t *dcontext, byte *lowest_brk /*if known*/, byte *old_brk,\n               byte *new_brk)\n{\n    /* i#851: the brk might not be page aligned */\n    old_brk = (app_pc)ALIGN_FORWARD(old_brk, PAGE_SIZE);\n    new_brk = (app_pc)ALIGN_FORWARD(new_brk, PAGE_SIZE);\n    if (new_brk < old_brk) {\n        /* Usually the heap is writable, so we don't really need to call\n         * this here: but seems safest to do so, esp if someone made part of\n         * the heap read-only and then put code there.\n         */\n        app_memory_deallocation(dcontext, new_brk, old_brk - new_brk,\n                                false /* don't own thread_initexit_lock */,\n                                false /* not image */);\n    } else if (new_brk > old_brk) {\n        /* No need to call app_memory_allocation() as doesn't interact\n         * w/ security policies.\n         */\n    }\n    IF_NO_MEMQUERY(memcache_handle_app_brk(lowest_brk, old_brk, new_brk));\n}\n#endif\n\n/* This routine is *not* called is pre_system_call() returns false to skip\n * the syscall.\n */\n/* XXX: split out specific handlers into separate routines\n */\nvoid\npost_system_call(dcontext_t *dcontext)\n{\n    priv_mcontext_t *mc = get_mcontext(dcontext);\n    /* registers have been clobbered, so sysnum is kept in dcontext */\n    int sysnum = dcontext->sys_num;\n    /* We expect most syscall failures to return < 0, so >= 0 is success.\n     * Some syscall return addresses that have the sign bit set and so\n     * appear to be failures but are not. They are handled on a\n     * case-by-case basis in the switch statement below.\n     */\n    ptr_int_t result = (ptr_int_t)MCXT_SYSCALL_RES(mc); /* signed */\n    bool success = syscall_successful(mc, sysnum);\n    app_pc base;\n    size_t size;\n    uint prot;\n    dr_where_am_i_t old_whereami;\n    DEBUG_DECLARE(bool ok;)\n\n    RSTATS_INC(post_syscall);\n\n    old_whereami = dcontext->whereami;\n    dcontext->whereami = DR_WHERE_SYSCALL_HANDLER;\n\n#if defined(LINUX) && defined(X86)\n    /* PR 313715: restore xbp since for some vsyscall sequences that use\n     * the syscall instruction its value is needed:\n     *   0xffffe400 <__kernel_vsyscall+0>:       push   %ebp\n     *   0xffffe401 <__kernel_vsyscall+1>:       mov    %ecx,%ebp\n     *   0xffffe403 <__kernel_vsyscall+3>:       syscall\n     *   0xffffe405 <__kernel_vsyscall+5>:       mov    $0x2b,%ecx\n     *   0xffffe40a <__kernel_vsyscall+10>:      movl   %ecx,%ss\n     *   0xffffe40c <__kernel_vsyscall+12>:      mov    %ebp,%ecx\n     *   0xffffe40e <__kernel_vsyscall+14>:      pop    %ebp\n     *   0xffffe40f <__kernel_vsyscall+15>:      ret\n     */\n    if (should_syscall_method_be_sysenter() && !dcontext->sys_was_int) {\n        mc->xbp = dcontext->sys_xbp;\n    }\n#endif\n\n    /* handle fork, try to do it early before too much logging occurs */\n    if (false\n#ifdef SYS_fork\n        || sysnum ==\n            SYS_fork\n#endif\n                IF_LINUX(||\n                         (sysnum == SYS_clone && !TEST(CLONE_VM, dcontext->sys_param0)) ||\n                         (sysnum == SYS_clone3 &&\n                          !TEST(CLONE_VM, get_stored_clone3_flags(dcontext))))) {\n        if (result == 0) {\n            /* we're the child */\n            thread_id_t child = get_sys_thread_id();\n#ifdef DEBUG\n            thread_id_t parent = get_parent_id();\n            SYSLOG_INTERNAL_INFO(\"-- parent %d forked child %d --\", parent, child);\n#endif\n            /* first, fix TLS of dcontext */\n            ASSERT(parent != 0);\n            /* change parent pid to our pid */\n            replace_thread_id(dcontext->owning_thread, child);\n            dcontext->owning_thread = child;\n            dcontext->owning_process = get_process_id();\n\n            /* now let dynamo initialize new shared memory, logfiles, etc.\n             * need access to static vars in dynamo.c, that's why we don't do it. */\n            /* FIXME - xref PR 246902 - d_r_dispatch runs a lot of code before\n             * getting to post_system_call() is any of that going to be messed up\n             * by waiting till here to fixup the child logfolder/file and tid?\n             */\n            dynamorio_fork_init(dcontext);\n\n            LOG(THREAD, LOG_SYSCALLS, 1,\n                \"after fork-like syscall: parent is %d, child is %d\\n\", parent, child);\n        } else {\n            /* we're the parent */\n            os_fork_post(dcontext, true /*parent*/);\n        }\n    }\n\n    LOG(THREAD, LOG_SYSCALLS, 2, \"post syscall: sysnum=\" PFX \", result=\" PFX \" (%d)\\n\",\n        sysnum, MCXT_SYSCALL_RES(mc), (int)MCXT_SYSCALL_RES(mc));\n\n    switch (sysnum) {\n\n        /****************************************************************************/\n        /* MEMORY REGIONS */\n\n#ifdef DEBUG\n#    ifdef MACOS\n    case SYS_open_nocancel:\n#    endif\n#    ifdef SYS_open\n    case SYS_open: {\n        if (success) {\n            /* useful for figuring out what module was loaded that then triggers\n             * module.c elf curiosities\n             */\n            LOG(THREAD, LOG_SYSCALLS, 2, \"SYS_open %s => %d\\n\", dcontext->sys_param0,\n                (int)result);\n        }\n        break;\n    }\n#    endif\n#endif\n\n#if defined(LINUX) && !defined(X64) && !defined(ARM)\n    case SYS_mmap:\n#endif\n    case IF_MACOS_ELSE(SYS_mmap, IF_X64_ELSE(SYS_mmap, SYS_mmap2)): {\n        uint flags;\n        DEBUG_DECLARE(const char *map_type;)\n        RSTATS_INC(num_app_mmaps);\n        base = (app_pc)MCXT_SYSCALL_RES(mc); /* For mmap, it's NOT arg->addr! */\n        /* mmap isn't simply a user-space wrapper for mmap2. It's called\n         * directly when dynamically loading an SO, i.e., dlopen(). */\n#ifdef LINUX /* MacOS success is in CF */\n        success = mmap_syscall_succeeded((app_pc)result);\n        /* The syscall either failed OR the retcode is less than the\n         * largest uint value of any errno and the addr returned is\n         * page-aligned.\n         */\n        ASSERT_CURIOSITY(\n            !success ||\n            ((app_pc)result < (app_pc)(ptr_int_t)-0x1000 && ALIGNED(base, PAGE_SIZE)));\n#else\n        ASSERT_CURIOSITY(!success || ALIGNED(base, PAGE_SIZE));\n#endif\n        if (!success)\n            goto exit_post_system_call;\n#if defined(LINUX) && !defined(X64) && !defined(ARM)\n        if (sysnum == SYS_mmap) {\n            /* The syscall succeeded so the read of 'arg' should be\n             * safe. */\n            mmap_arg_struct_t *arg = (mmap_arg_struct_t *)dcontext->sys_param0;\n            size = (size_t)arg->len;\n            prot = (uint)arg->prot;\n            flags = (uint)arg->flags;\n            DEBUG_DECLARE(map_type = \"mmap\";)\n        } else {\n#endif\n            size = (size_t)dcontext->sys_param1;\n            prot = (uint)dcontext->sys_param2;\n            flags = (uint)dcontext->sys_param3;\n            DEBUG_DECLARE(map_type = IF_X64_ELSE(\"mmap2\", \"mmap\");)\n#if defined(LINUX) && !defined(X64) && !defined(ARM)\n        }\n#endif\n        process_mmap(dcontext, base, size, prot, flags _IF_DEBUG(map_type));\n        break;\n    }\n    case SYS_munmap: {\n        app_pc addr = (app_pc)dcontext->sys_param0;\n        size_t len = (size_t)dcontext->sys_param1;\n        /* We assumed in pre_system_call() that the unmap would succeed\n         * and flushed fragments and removed the region from exec areas.\n         * If the unmap failed, we re-add the region to exec areas.\n         * For zero-length unmaps we don't need to re-add anything,\n         * and we hit an assert in vmareas.c if we try (i#4031).\n         *\n         * The same logic can be used on Windows (but isn't yet).\n         */\n        /* FIXME There are shortcomings to the approach. If another thread\n         * executes in the region after our pre_system_call processing\n         * but before the re-add below, it will get a security violation.\n         * That's less than ideal but at least isn't a security hole.\n         * The overall shortcoming is that we lose the state from our\n         * stateful security policies -- future exec list, tables used\n         * for RCT (.C/.E/.F) -- which can't be easily restored. Also,\n         * the re-add could add a region that wasn't on the exec list\n         * previously.\n         *\n         * See case 7559 for a better approach.\n         */\n        if (!success && len != 0) {\n            dr_mem_info_t info;\n            /* must go to os to get real memory since we already removed */\n            DEBUG_DECLARE(ok =)\n            query_memory_ex_from_os(addr, &info);\n            ASSERT(ok);\n            app_memory_allocation(dcontext, addr, len, info.prot,\n                                  info.type ==\n                                      DR_MEMTYPE_IMAGE _IF_DEBUG(\"failed munmap\"));\n            IF_NO_MEMQUERY(\n                memcache_update_locked((app_pc)ALIGN_BACKWARD(addr, PAGE_SIZE),\n                                       (app_pc)ALIGN_FORWARD(addr + len, PAGE_SIZE),\n                                       info.prot, info.type, false /*add back*/));\n        }\n        break;\n    }\n#ifdef LINUX\n    case SYS_mremap: {\n        app_pc old_base = (app_pc)dcontext->sys_param0;\n        size_t old_size = (size_t)dcontext->sys_param1;\n        base = (app_pc)MCXT_SYSCALL_RES(mc);\n        size = (size_t)dcontext->sys_param2;\n        /* even if no shift, count as munmap plus mmap */\n        RSTATS_INC(num_app_munmaps);\n        RSTATS_INC(num_app_mmaps);\n        success =\n            handle_app_mremap(dcontext, base, size, old_base, old_size,\n                              /* i#173: use memory prot and type\n                               * obtained from pre_system_call\n                               */\n                              (uint)dcontext->sys_param3, (uint)dcontext->sys_param4);\n        /* The syscall either failed OR the retcode is less than the\n         * largest uint value of any errno and the addr returned is\n         * is page-aligned.\n         */\n        ASSERT_CURIOSITY(\n            !success ||\n            ((app_pc)result < (app_pc)(ptr_int_t)-0x1000 && ALIGNED(base, PAGE_SIZE)));\n        if (!success)\n            goto exit_post_system_call;\n        break;\n    }\n#endif\n    case SYS_mprotect: {\n        base = (app_pc)dcontext->sys_param0;\n        size = dcontext->sys_param1;\n        prot = dcontext->sys_param2;\n#ifdef VMX86_SERVER\n        /* PR 475111: workaround for PR 107872 */\n        if (os_in_vmkernel_userworld() && result == -EBUSY && prot == PROT_NONE) {\n            result = mprotect_syscall(base, size, PROT_READ);\n            /* since non-Mac, we can use this even if the call failed */\n            set_success_return_val(dcontext, result);\n            success = (result >= 0);\n            LOG(THREAD, LOG_VMAREAS, 1,\n                \"re-doing mprotect -EBUSY for \" PFX \"-\" PFX \" => %d\\n\", base, base + size,\n                (int)result);\n            SYSLOG_INTERNAL_WARNING_ONCE(\"re-doing mprotect for PR 475111, PR 107872\");\n        }\n#endif\n        /* FIXME i#143: we need to tweak the returned oldprot for\n         * writable areas we've made read-only\n         */\n        if (!success) {\n            uint memprot = 0;\n            /* Revert the prot bits if needed. */\n            if (!get_memory_info_from_os(base, NULL, NULL, &memprot))\n                memprot = PROT_NONE;\n            LOG(THREAD, LOG_SYSCALLS, 3,\n                \"syscall: mprotect failed: \" PFX \"-\" PFX \" prot->%d\\n\", base, base + size,\n                osprot_to_memprot(prot));\n            LOG(THREAD, LOG_SYSCALLS, 3, \"\\told prot->%d\\n\", memprot);\n            if (prot != memprot_to_osprot(memprot)) {\n                /* We're trying to reverse the prot change, assuming that\n                 * this action doesn't have any unexpected side effects\n                 * when doing so (such as not reversing some bit of internal\n                 * state).\n                 */\n                uint new_memprot;\n                DEBUG_DECLARE(uint res =)\n                app_memory_protection_change(dcontext, base, size,\n                                             osprot_to_memprot(prot), &new_memprot, NULL,\n                                             false /*!image*/);\n                ASSERT_NOT_IMPLEMENTED(res != SUBSET_APP_MEM_PROT_CHANGE);\n                ASSERT(res == DO_APP_MEM_PROT_CHANGE ||\n                       res == PRETEND_APP_MEM_PROT_CHANGE);\n\n                /* PR 410921 - Revert the changes to all-mems list.\n                 * FIXME: This fix assumes the whole region had the prot &\n                 * type, which is true in the cases we have seen so far, but\n                 * theoretically may not be true.  If it isn't true, multiple\n                 * memory areas with different types/protections might have\n                 * been changed in pre_system_call(), so will have to keep a\n                 * list of all vmareas changed.  This might be expensive for\n                 * each mprotect syscall to guard against a rare theoretical bug.\n                 */\n                ASSERT_CURIOSITY(!dcontext->mprot_multi_areas);\n                IF_NO_MEMQUERY(memcache_update_locked(\n                    base, base + size, memprot, -1 /*type unchanged*/, true /*exists*/));\n            }\n        }\n        break;\n    }\n#ifdef ANDROID\n    case SYS_prctl: {\n        int code = (int)dcontext->sys_param0;\n        int subcode = (ulong)dcontext->sys_param1;\n        if (success && code == PR_SET_VMA && subcode == PR_SET_VMA_ANON_NAME) {\n            byte *addr = (byte *)dcontext->sys_param2;\n            size_t len = (size_t)dcontext->sys_param3;\n            IF_DEBUG(const char *comment = (const char *)dcontext->sys_param4;)\n            uint memprot = 0;\n            if (!get_memory_info_from_os(addr, NULL, NULL, &memprot))\n                memprot = MEMPROT_NONE;\n            /* We're post-syscall so from_os should match the prctl */\n            ASSERT((comment == NULL && !TEST(MEMPROT_HAS_COMMENT, memprot)) ||\n                   (comment != NULL && TEST(MEMPROT_HAS_COMMENT, memprot)));\n            LOG(THREAD, LOG_SYSCALLS, 2,\n                \"syscall: prctl PR_SET_VMA_ANON_NAME base=\" PFX \" size=\" PFX\n                \" comment=%s\\n\",\n                addr, len, comment == NULL ? \"<null>\" : comment);\n            IF_NO_MEMQUERY(memcache_update_locked(\n                addr, addr + len, memprot, -1 /*type unchanged*/, true /*exists*/));\n        }\n        break;\n    }\n#endif\n#ifdef LINUX\n    case SYS_brk: {\n        /* i#91/PR 396352: need to watch SYS_brk to maintain all_memory_areas.\n         * This code should work regardless of whether syscall failed\n         * (if it failed, the old break will be returned).  We stored\n         * the old break in sys_param1 in pre-syscall.\n         */\n        app_pc old_brk = (app_pc)dcontext->sys_param1;\n        app_pc new_brk = (app_pc)result;\n        DEBUG_DECLARE(app_pc req_brk = (app_pc)dcontext->sys_param0;);\n        ASSERT(!DYNAMO_OPTION(emulate_brk)); /* shouldn't get here */\n#    ifdef DEBUG\n        if (DYNAMO_OPTION(early_inject) &&\n            req_brk != NULL /* Ignore calls that don't increase brk. */) {\n            DO_ONCE({\n                ASSERT_CURIOSITY(new_brk > old_brk &&\n                                 \"i#1004: first brk() \"\n                                 \"allocation failed with -early_inject\");\n            });\n        }\n#    endif\n        handle_app_brk(dcontext, NULL, old_brk, new_brk);\n        break;\n    }\n#endif\n\n    /****************************************************************************/\n    /* SPAWNING -- fork mostly handled above */\n\n#ifdef LINUX\n    case SYS_clone3:\n    case SYS_clone: {\n        /* in /usr/src/linux/arch/i386/kernel/process.c */\n        LOG(THREAD, LOG_SYSCALLS, 2, \"syscall: clone returned \" PFX \"\\n\",\n            MCXT_SYSCALL_RES(mc));\n        /* TODO i#5221: Handle clone3 returning errors other than ENOSYS. */\n        /* We switch the lib tls segment back to dr's privlib segment.\n         * Please refer to comment on os_switch_lib_tls.\n         * It is only called in parent thread.\n         * The child thread's tls setup is done in os_tls_app_seg_init.\n         */\n        if (was_thread_create_syscall(dcontext)) {\n            if (INTERNAL_OPTION(private_loader))\n                os_switch_lib_tls(dcontext, false /*to dr*/);\n            /* i#2089: we already restored the DR tls in os_clone_post() */\n\n            if (sysnum == SYS_clone3) {\n                /* Free DR's copy of clone_args and restore the pointer to the\n                 * app's copy in the SYSCALL_PARAM_CLONE3_CLONE_ARGS reg.\n                 * sys_param1 contains the pointer to DR's clone_args, and\n                 * sys_param0 contains the pointer to the app's original\n                 * clone_args.\n                 */\n#    ifdef X86\n                ASSERT(sys_param(dcontext, SYSCALL_PARAM_CLONE3_CLONE_ARGS) ==\n                       dcontext->sys_param1);\n                set_syscall_param(dcontext, SYSCALL_PARAM_CLONE3_CLONE_ARGS,\n                                  dcontext->sys_param0);\n#    else\n                /* On AArchXX r0 is used to pass the first arg to the syscall as well as\n                 * to hold its return value. As the clone_args pointer isn't available\n                 * post-syscall natively anyway, there's no need to restore here.\n                 */\n#    endif\n                uint app_clone_args_size = (uint)dcontext->sys_param2;\n                heap_free(dcontext, (clone3_syscall_args_t *)dcontext->sys_param1,\n                          app_clone_args_size HEAPACCT(ACCT_OTHER));\n            } else if (sysnum == SYS_clone) {\n                set_syscall_param(dcontext, SYSCALL_PARAM_CLONE_STACK,\n                                  dcontext->sys_param1);\n            }\n        }\n        break;\n    }\n#elif defined(MACOS) && !defined(X64)\n    case SYS_bsdthread_create: {\n        /* restore stack values we clobbered */\n        ASSERT(*sys_param_addr(dcontext, 0) == (reg_t)new_bsdthread_intercept);\n        *sys_param_addr(dcontext, 0) = dcontext->sys_param0;\n        *sys_param_addr(dcontext, 1) = dcontext->sys_param1;\n        break;\n    }\n#endif\n\n#ifdef SYS_fork\n    case SYS_fork: {\n        LOG(THREAD, LOG_SYSCALLS, 2, \"syscall: fork returned \" PFX \"\\n\",\n            MCXT_SYSCALL_RES(mc));\n        break;\n    }\n#endif\n\n#ifdef SYS_vfork\n    case SYS_vfork: {\n        LOG(THREAD, LOG_SYSCALLS, 2, \"syscall: vfork returned \" PFX \"\\n\",\n            MCXT_SYSCALL_RES(mc));\n        IF_LINUX(ASSERT(was_thread_create_syscall(dcontext)));\n        /* restore xsp in parent */\n        LOG(THREAD, LOG_SYSCALLS, 2, \"vfork: restoring xsp from \" PFX \" to \" PFX \"\\n\",\n            mc->xsp, dcontext->sys_param1);\n        mc->xsp = dcontext->sys_param1;\n\n        if (MCXT_SYSCALL_RES(mc) != 0) {\n            /* We switch the lib tls segment back to dr's segment.\n             * Please refer to comment on os_switch_lib_tls.\n             * It is only called in parent thread.\n             * The child thread's tls setup is done in os_tls_app_seg_init.\n             */\n            if (INTERNAL_OPTION(private_loader)) {\n                os_switch_lib_tls(dcontext, false /*to dr*/);\n            }\n            /* i#2089: we already restored the DR tls in os_clone_post() */\n        }\n        break;\n    }\n#endif\n\n    case SYS_execve: {\n        /* if we get here it means execve failed (doesn't return on success) */\n        success = false;\n        mark_thread_execve(dcontext->thread_record, false);\n        ASSERT(result < 0);\n        LOG(THREAD, LOG_SYSCALLS, 2, \"syscall: execve failed\\n\");\n        handle_execve_post(dcontext);\n        /* Don't 'break' as we have an ASSERT(success) just below\n         * the switch(). */\n        goto exit_post_system_call;\n        break; /* unnecessary but good form so keep it */\n    }\n\n        /****************************************************************************/\n        /* SIGNALS */\n\n    case IF_MACOS_ELSE(SYS_sigaction, SYS_rt_sigaction): { /* 174 */\n        /* in /usr/src/linux/kernel/signal.c:\n           asmlinkage long\n           sys_rt_sigaction(int sig, const struct sigaction *act,\n             struct sigaction *oact, size_t sigsetsize)\n         */\n        /* FIXME i#148: Handle syscall failure. */\n        int sig = (int)dcontext->sys_param0;\n        const kernel_sigaction_t *act = (const kernel_sigaction_t *)dcontext->sys_param1;\n        prev_sigaction_t *oact = (prev_sigaction_t *)dcontext->sys_param2;\n        size_t sigsetsize = (size_t)dcontext->sys_param3;\n        uint res;\n        res = handle_post_sigaction(dcontext, success, sig, act, oact, sigsetsize);\n        LOG(THREAD, LOG_SYSCALLS, 2, \"syscall: %ssigaction => %d\\n\",\n            IF_MACOS_ELSE(\"\", \"rt_\"), -res);\n        if (res != 0)\n            set_failure_return_val(dcontext, res);\n        if (!success || res != 0)\n            goto exit_post_system_call;\n        break;\n    }\n#if defined(LINUX) && !defined(X64)\n    case SYS_sigaction: { /* 67 */\n        int sig = (int)dcontext->sys_param0;\n        const old_sigaction_t *act = (const old_sigaction_t *)dcontext->sys_param1;\n        old_sigaction_t *oact = (old_sigaction_t *)dcontext->sys_param2;\n        uint res = handle_post_old_sigaction(dcontext, success, sig, act, oact);\n        LOG(THREAD, LOG_SYSCALLS, 2, \"syscall: sigaction => %d\\n\", -res);\n        if (res != 0)\n            set_failure_return_val(dcontext, res);\n        if (!success || res != 0)\n            goto exit_post_system_call;\n        break;\n    }\n#endif\n    case IF_MACOS_ELSE(SYS_sigprocmask, SYS_rt_sigprocmask): { /* 175 */\n        /* in /usr/src/linux/kernel/signal.c:\n           asmlinkage long\n           sys_rt_sigprocmask(int how, sigset_t *set, sigset_t *oset,\n             size_t sigsetsize)\n         */\n        /* FIXME i#148: Handle syscall failure. */\n        handle_post_sigprocmask(\n            dcontext, (int)dcontext->sys_param0, (kernel_sigset_t *)dcontext->sys_param1,\n            (kernel_sigset_t *)dcontext->sys_param2, (size_t)dcontext->sys_param3);\n        break;\n    }\n#if defined(LINUX) && !defined(X64)\n    case SYS_sigreturn: /* 119 */\n#endif\n    case IF_MACOS_ELSE(SYS_sigreturn, SYS_rt_sigreturn): /* 173 */\n        /* there is no return value: it's just the value of eax, so avoid\n         * assert below\n         */\n        success = true;\n        break;\n\n    case SYS_setitimer: /* 104 */\n        handle_post_setitimer(dcontext, success, (int)dcontext->sys_param0,\n                              (const struct itimerval *)dcontext->sys_param1,\n                              (struct itimerval *)dcontext->sys_param2);\n        break;\n    case SYS_getitimer: /* 105 */\n        handle_post_getitimer(dcontext, success, (int)dcontext->sys_param0,\n                              (struct itimerval *)dcontext->sys_param1);\n        break;\n#if defined(LINUX) && defined(X86)\n    case SYS_alarm: /* 27 on x86 and 37 on x64 */\n        handle_post_alarm(dcontext, success, (unsigned int)dcontext->sys_param0);\n        break;\n#endif\n#if defined(LINUX) && defined(X86) && defined(X64)\n    case SYS_arch_prctl: {\n        if (success && INTERNAL_OPTION(mangle_app_seg)) {\n            tls_handle_post_arch_prctl(dcontext, dcontext->sys_param0,\n                                       dcontext->sys_param1);\n        }\n        break;\n    }\n#endif\n#ifdef LINUX\n#    ifdef SYS_ppoll_time64\n    case SYS_ppoll_time64:\n#    endif\n    case SYS_ppoll: {\n        if (dcontext->sys_param3 == (reg_t)NULL)\n            break;\n        handle_post_extended_syscall_sigmasks(dcontext, success);\n        set_syscall_param(dcontext, 3, dcontext->sys_param3);\n        break;\n    }\n#    ifdef SYS_pselect6_time64\n    case SYS_pselect6_time64:\n#    endif\n    case SYS_pselect6: {\n        if (dcontext->sys_param4 == (reg_t)NULL)\n            break;\n        typedef struct {\n            kernel_sigset_t *sigmask;\n            size_t sizemask;\n        } data_t;\n        data_t *data_param = (data_t *)dcontext->sys_param3;\n        handle_post_extended_syscall_sigmasks(dcontext, success);\n        if (!safe_write_ex((void *)&data_param->sigmask, sizeof(data_param->sigmask),\n                           &dcontext->sys_param4, NULL)) {\n            LOG(THREAD, LOG_SYSCALLS, 2, \"\\tEFAULT for pselect6 post syscall\\n\");\n        }\n        break;\n    }\n    case SYS_epoll_pwait: {\n        if (dcontext->sys_param4 == (reg_t)NULL)\n            break;\n        handle_post_extended_syscall_sigmasks(dcontext, success);\n        set_syscall_param(dcontext, 4, dcontext->sys_param4);\n        break;\n    }\n#endif\n\n    /****************************************************************************/\n    /* FILES */\n\n#ifdef SYS_dup2\n    case SYS_dup2: IF_LINUX(case SYS_dup3:) {\n#    ifdef LINUX\n            if (success) {\n                signal_handle_dup(dcontext, (file_t)sys_param(dcontext, 1),\n                                  (file_t)result);\n            }\n#    endif\n            break;\n        }\n#endif\n\n#ifdef MACOS\n    case SYS_fcntl_nocancel:\n#endif\n    case SYS_fcntl: {\n#ifdef LINUX /* Linux-only since only for signalfd */\n        if (success) {\n            file_t fd = (long)dcontext->sys_param0;\n            int cmd = (int)dcontext->sys_param1;\n            if ((cmd == F_DUPFD || cmd == F_DUPFD_CLOEXEC))\n                signal_handle_dup(dcontext, fd, (file_t)result);\n        }\n        break;\n#endif\n    }\n\n    case IF_MACOS_ELSE(SYS_getrlimit, IF_X64_ELSE(SYS_getrlimit, SYS_ugetrlimit)): {\n        int resource = dcontext->sys_param0;\n        if (success && resource == RLIMIT_NOFILE) {\n            /* we stole some space: hide it from app */\n            struct rlimit *rlim = (struct rlimit *)dcontext->sys_param1;\n            safe_write_ex(&rlim->rlim_cur, sizeof(rlim->rlim_cur),\n                          &app_rlimit_nofile.rlim_cur, NULL);\n            safe_write_ex(&rlim->rlim_max, sizeof(rlim->rlim_max),\n                          &app_rlimit_nofile.rlim_max, NULL);\n        }\n        break;\n    }\n#if !defined(ARM) && !defined(X64) && !defined(MACOS)\n    /* Old struct w/ smaller fields */\n    case SYS_getrlimit: {\n        int resource = dcontext->sys_param0;\n        if (success && resource == RLIMIT_NOFILE) {\n            struct compat_rlimit *rlim = (struct compat_rlimit *)dcontext->sys_param1;\n            safe_write_ex(&rlim->rlim_cur, sizeof(rlim->rlim_cur),\n                          &app_rlimit_nofile.rlim_cur, NULL);\n            safe_write_ex(&rlim->rlim_max, sizeof(rlim->rlim_max),\n                          &app_rlimit_nofile.rlim_max, NULL);\n        }\n        break;\n    }\n#endif\n\n#ifdef LINUX\n    case SYS_prlimit64: {\n        int resource = dcontext->sys_param1;\n        rlimit64_t *rlim = (rlimit64_t *)dcontext->sys_param3;\n        if (success && resource == RLIMIT_NOFILE && rlim != NULL &&\n            /* XXX: xref pid discussion in pre_system_call SYS_prlimit64 */\n            (dcontext->sys_param0 == 0 || dcontext->sys_param0 == get_process_id())) {\n            safe_write_ex(rlim, sizeof(*rlim), &app_rlimit_nofile, NULL);\n        }\n        break;\n    }\n#endif\n\n#ifdef LINUX\n#    ifdef SYS_readlink\n    case SYS_readlink:\n#    endif\n    case SYS_readlinkat:\n        if (success && DYNAMO_OPTION(early_inject)) {\n            bool is_at = (sysnum == SYS_readlinkat);\n            /* i#907: /proc/self/exe is a symlink to libdynamorio.so.  We need\n             * to fix it up if the app queries.  Any thread id can be passed to\n             * /proc/%d/exe, so we have to check.  We could instead look for\n             * libdynamorio.so in the result but we've tweaked our injector\n             * in the past to exec different binaries so this seems more robust.\n             */\n            if (symlink_is_self_exe((const char *)(is_at ? dcontext->sys_param1\n                                                         : dcontext->sys_param0))) {\n                char *tgt = (char *)(is_at ? dcontext->sys_param2 : dcontext->sys_param1);\n                size_t tgt_sz =\n                    (size_t)(is_at ? dcontext->sys_param3 : dcontext->sys_param2);\n                int len = snprintf(tgt, tgt_sz, \"%s\", get_application_name());\n                if (len > 0)\n                    set_success_return_val(dcontext, len);\n                else {\n                    set_failure_return_val(dcontext, EINVAL);\n                    DODEBUG({ dcontext->expect_last_syscall_to_fail = true; });\n                }\n            }\n        }\n        break;\n#    ifdef SYS_openat2\n    case SYS_openat2:\n#    endif\n    case SYS_openat:\n        if (dcontext->sys_param0 != 0) {\n            heap_free(dcontext, (void *)dcontext->sys_param0,\n                      MAXIMUM_PATH HEAPACCT(ACCT_OTHER));\n        }\n        break;\n    case SYS_rseq:\n        /* Lazy rseq handling. */\n        if (success) {\n            rseq_process_syscall(dcontext);\n            rseq_locate_rseq_regions();\n        }\n        break;\n#endif\n    default:\n#ifdef VMX86_SERVER\n        if (is_vmkuw_sysnum(sysnum)) {\n            vmkuw_post_system_call(dcontext);\n            break;\n        }\n#endif\n        break;\n\n    } /* switch */\n\n    DODEBUG({\n        if (ignorable_system_call_normalized(sysnum)) {\n            STATS_INC(post_syscall_ignorable);\n        } else {\n            /* Many syscalls can fail though they aren't ignored.  However, they\n             * shouldn't happen without us knowing about them.  See PR 402769\n             * for SYS_close case.\n             */\n            if (!(success || sysnum == SYS_close ||\n                  IF_MACOS(sysnum == SYS_close_nocancel ||)\n                      dcontext->expect_last_syscall_to_fail)) {\n                LOG(THREAD, LOG_SYSCALLS, 1,\n                    \"Unexpected failure of non-ignorable syscall %d\\n\", sysnum);\n            }\n        }\n    });\n\nexit_post_system_call:\n\n    /* The instrument_post_syscall should be called after DR finishes all\n     * its operations, since DR needs to know the real syscall results,\n     * and any changes made by the client are simply to fool the app.\n     * Also, dr_syscall_invoke_another() needs to set eax, which shouldn't\n     * affect the result of the 1st syscall. Xref i#1.\n     */\n    /* after restore of xbp so client sees it as though was sysenter */\n    instrument_post_syscall(dcontext, sysnum);\n\n    dcontext->whereami = old_whereami;\n}\n\n#ifdef LINUX\n#    ifdef STATIC_LIBRARY\n/* Static libraries may optionally define two linker variables\n * (dynamorio_so_start and dynamorio_so_end) to help mitigate\n * edge cases in detecting DR's library bounds. They are optional.\n *\n * If not specified, the variables' location will default to\n * weak_dynamorio_so_bounds_filler and they will not be used.\n * Note that referencing the value of these symbols will crash:\n * always use the address only.\n */\nextern int dynamorio_so_start WEAK\n    __attribute__((alias(\"weak_dynamorio_so_bounds_filler\")));\nextern int dynamorio_so_end WEAK\n    __attribute__((alias(\"weak_dynamorio_so_bounds_filler\")));\nstatic int weak_dynamorio_so_bounds_filler;\n\n#    else  /* !STATIC_LIBRARY */\n/* For non-static linux we always get our bounds from linker-provided symbols.\n * Note that referencing the value of these symbols will crash: always use the\n * address only.\n */\nextern int dynamorio_so_start, dynamorio_so_end;\n#    endif /* STATIC_LIBRARY */\n#endif     /* LINUX */\n\n/* get_dynamo_library_bounds initializes dynamorio library bounds, using a\n * release-time assert if there is a problem doing so. It does not use any\n * heap, and we assume it is called prior to find_executable_vm_areas in a\n * single thread.\n */\nstatic void\nget_dynamo_library_bounds(void)\n{\n    /* Note that we're not counting DYNAMORIO_PRELOAD_NAME as a DR area, to match\n     * Windows, so we should unload it like we do there. The other reason not to\n     * count it is so is_in_dynamo_dll() can be the only exception to the\n     * never-execute-from-DR-areas list rule\n     */\n    int res;\n    app_pc check_start, check_end;\n    char *libdir;\n    const char *dynamorio_libname = NULL;\n    bool do_memquery = true;\n#ifdef STATIC_LIBRARY\n#    ifdef LINUX\n    /* For static+linux, we might have linker vars to help us and we definitely\n     * know our \"library name\" since we are in the app. When we have both we\n     * don't need to do a memquery.\n     */\n    if (&dynamorio_so_start != &weak_dynamorio_so_bounds_filler &&\n        &dynamorio_so_end != &weak_dynamorio_so_bounds_filler) {\n\n        do_memquery = false;\n        dynamo_dll_start = (app_pc)&dynamorio_so_start;\n        dynamo_dll_end = (app_pc)ALIGN_FORWARD(&dynamorio_so_end, PAGE_SIZE);\n        LOG(GLOBAL, LOG_VMAREAS, 2,\n            \"Using dynamorio_so_start and dynamorio_so_end for library bounds\"\n            \"\\n\");\n        const char *dr_path = get_application_name();\n        strncpy(dynamorio_library_filepath, dr_path,\n                BUFFER_SIZE_ELEMENTS(dynamorio_library_filepath));\n        NULL_TERMINATE_BUFFER(dynamorio_library_filepath);\n\n        const char *slash = strrchr(dr_path, '/');\n        ASSERT(slash != NULL);\n        /* Include the slash in the library path */\n        size_t copy_chars = 1 + slash - dr_path;\n        ASSERT(copy_chars < BUFFER_SIZE_ELEMENTS(dynamorio_library_path));\n        strncpy(dynamorio_library_path, dr_path, copy_chars);\n        dynamorio_library_path[copy_chars] = '\\0';\n    }\n#    endif\n    if (do_memquery) {\n        /* No linker vars, so we need to find bound using an internal PC */\n        check_start = (app_pc)&get_dynamo_library_bounds;\n    }\n#else /* !STATIC_LIBRARY */\n#    ifdef LINUX\n    /* PR 361594: we get our bounds from linker-provided symbols.\n     * Note that referencing the value of these symbols will crash:\n     * always use the address only.\n     */\n    extern int dynamorio_so_start, dynamorio_so_end;\n    dynamo_dll_start = (app_pc)&dynamorio_so_start;\n    dynamo_dll_end = (app_pc)ALIGN_FORWARD(&dynamorio_so_end, PAGE_SIZE);\n#    elif defined(MACOS)\n    dynamo_dll_start = module_dynamorio_lib_base();\n#    endif\n    check_start = dynamo_dll_start;\n#endif /* STATIC_LIBRARY */\n\n    if (do_memquery) {\n        static char dynamorio_libname_buf[MAXIMUM_PATH];\n        res = memquery_library_bounds(\n            NULL, &check_start, &check_end, dynamorio_library_path,\n            BUFFER_SIZE_ELEMENTS(dynamorio_library_path), dynamorio_libname_buf,\n            BUFFER_SIZE_ELEMENTS(dynamorio_libname_buf));\n        ASSERT(res > 0);\n#ifndef STATIC_LIBRARY\n        dynamorio_libname = IF_UNIT_TEST_ELSE(UNIT_TEST_EXE_NAME, dynamorio_libname_buf);\n#endif /* STATIC_LIBRARY */\n\n        snprintf(dynamorio_library_filepath,\n                 BUFFER_SIZE_ELEMENTS(dynamorio_library_filepath), \"%s%s\",\n                 dynamorio_library_path, dynamorio_libname);\n        NULL_TERMINATE_BUFFER(dynamorio_library_filepath);\n#if !defined(STATIC_LIBRARY) && defined(LINUX)\n        ASSERT(check_start == dynamo_dll_start && check_end == dynamo_dll_end);\n#elif defined(MACOS)\n        ASSERT(check_start == dynamo_dll_start);\n        dynamo_dll_end = check_end;\n#else\n        dynamo_dll_start = check_start;\n        dynamo_dll_end = check_end;\n#endif\n    }\n\n    LOG(GLOBAL, LOG_VMAREAS, 1, PRODUCT_NAME \" library path: %s\\n\",\n        dynamorio_library_path);\n    LOG(GLOBAL, LOG_VMAREAS, 1, PRODUCT_NAME \" library file path: %s\\n\",\n        dynamorio_library_filepath);\n    LOG(GLOBAL, LOG_VMAREAS, 1, \"DR library bounds: \" PFX \" to \" PFX \"\\n\",\n        dynamo_dll_start, dynamo_dll_end);\n\n    /* Issue 20: we need the path to the alt arch */\n    strncpy(dynamorio_alt_arch_path, dynamorio_library_path,\n            BUFFER_SIZE_ELEMENTS(dynamorio_alt_arch_path));\n    /* Assumption: libdir name is not repeated elsewhere in path */\n    libdir = strstr(dynamorio_alt_arch_path, IF_X64_ELSE(DR_LIBDIR_X64, DR_LIBDIR_X86));\n    if (libdir != NULL) {\n        const char *newdir = IF_X64_ELSE(DR_LIBDIR_X86, DR_LIBDIR_X64);\n        /* do NOT place the NULL */\n        strncpy(libdir, newdir, strlen(newdir));\n    } else {\n        SYSLOG_INTERNAL_WARNING(\"unable to determine lib path for cross-arch execve\");\n    }\n    NULL_TERMINATE_BUFFER(dynamorio_alt_arch_path);\n    LOG(GLOBAL, LOG_VMAREAS, 1, PRODUCT_NAME \" alt arch path: %s\\n\",\n        dynamorio_alt_arch_path);\n    snprintf(dynamorio_alt_arch_filepath,\n             BUFFER_SIZE_ELEMENTS(dynamorio_alt_arch_filepath), \"%s%s\",\n             dynamorio_alt_arch_path, dynamorio_libname);\n    NULL_TERMINATE_BUFFER(dynamorio_alt_arch_filepath);\n\n    if (dynamo_dll_start == NULL || dynamo_dll_end == NULL) {\n        REPORT_FATAL_ERROR_AND_EXIT(FAILED_TO_FIND_DR_BOUNDS, 2, get_application_name(),\n                                    get_application_pid());\n    }\n}\n\n/* get full path to our own library, (cached), used for forking and message file name */\nchar *\nget_dynamorio_library_path(void)\n{\n    if (!dynamorio_library_filepath[0]) { /* not cached */\n        get_dynamo_library_bounds();\n    }\n    return dynamorio_library_filepath;\n}\n\n#ifdef LINUX\n/* Get full path+name of executable file from /proc/self/exe.  Returns an empty\n * string on error.\n * FIXME i#47: This will return DR's path when using early injection.\n */\nstatic char *\nread_proc_self_exe(bool ignore_cache)\n{\n    static char exepath[MAXIMUM_PATH];\n    static bool tried = false;\n#    ifdef MACOS\n    ASSERT_NOT_IMPLEMENTED(false);\n#    endif\n    if (!tried || ignore_cache) {\n        tried = true;\n        /* assume we have /proc/self/exe symlink: could add HAVE_PROC_EXE\n         * but we have no alternative solution except assuming the first\n         * /proc/self/maps entry is the executable\n         */\n        ssize_t res;\n        DEBUG_DECLARE(int len =)\n        snprintf(exepath, BUFFER_SIZE_ELEMENTS(exepath), \"/proc/%d/exe\",\n                 get_process_id());\n        ASSERT(len > 0);\n        NULL_TERMINATE_BUFFER(exepath);\n        /* i#960: readlink does not null terminate, so we do it. */\n#    ifdef SYS_readlink\n        res = dynamorio_syscall(SYS_readlink, 3, exepath, exepath,\n                                BUFFER_SIZE_ELEMENTS(exepath) - 1);\n#    else\n        res = dynamorio_syscall(SYS_readlinkat, 4, AT_FDCWD, exepath, exepath,\n                                BUFFER_SIZE_ELEMENTS(exepath) - 1);\n#    endif\n        ASSERT(res < BUFFER_SIZE_ELEMENTS(exepath));\n        exepath[MAX(res, 0)] = '\\0';\n        NULL_TERMINATE_BUFFER(exepath);\n    }\n    return exepath;\n}\n#endif /* LINUX */\n\napp_pc\nget_application_base(void)\n{\n    if (executable_start == NULL) {\n#if defined(STATIC_LIBRARY)\n        /* When compiled statically, the app and the DR's \"library\" are the same. */\n        executable_start = get_dynamorio_dll_start();\n        executable_end = get_dynamorio_dll_end();\n#elif defined(HAVE_MEMINFO)\n        /* Haven't done find_executable_vm_areas() yet so walk maps ourselves */\n        const char *name = get_application_name();\n        if (name != NULL && name[0] != '\\0') {\n            DEBUG_DECLARE(int count =)\n            memquery_library_bounds(name, &executable_start, &executable_end, NULL, 0,\n                                    NULL, 0);\n            ASSERT(count > 0 && executable_start != NULL);\n        }\n#else\n        /* We have to fail.  Should we dl_iterate this early? */\n#endif\n    }\n    return executable_start;\n}\n\napp_pc\nget_application_end(void)\n{\n    if (executable_end == NULL)\n        get_application_base();\n    return executable_end;\n}\n\napp_pc\nget_image_entry()\n{\n    static app_pc image_entry_point = NULL;\n    if (image_entry_point == NULL && executable_start != NULL) {\n        module_area_t *ma;\n        os_get_module_info_lock();\n        ma = module_pc_lookup(executable_start);\n        ASSERT(ma != NULL);\n        if (ma != NULL) {\n            ASSERT(executable_start == ma->start);\n            SELF_UNPROTECT_DATASEC(DATASEC_RARELY_PROT);\n            image_entry_point = ma->entry_point;\n            SELF_PROTECT_DATASEC(DATASEC_RARELY_PROT);\n        }\n        os_get_module_info_unlock();\n    }\n    return image_entry_point;\n}\n\n#ifdef DEBUG\nvoid\nmem_stats_snapshot()\n{\n    /* FIXME: NYI */\n}\n#endif\n\nbool\nis_in_dynamo_dll(app_pc pc)\n{\n    ASSERT(dynamo_dll_start != NULL);\n#ifdef VMX86_SERVER\n    /* We want to consider vmklib as part of the DR lib for allowing\n     * execution (_init calls os_in_vmkernel_classic()) and for\n     * reporting crashes as our fault\n     */\n    if (vmk_in_vmklib(pc))\n        return true;\n#endif\n    return (pc >= dynamo_dll_start && pc < dynamo_dll_end);\n}\n\napp_pc\nget_dynamorio_dll_start()\n{\n    if (dynamo_dll_start == NULL)\n        get_dynamo_library_bounds();\n    ASSERT(dynamo_dll_start != NULL);\n    return dynamo_dll_start;\n}\n\napp_pc\nget_dynamorio_dll_end()\n{\n    if (dynamo_dll_end == NULL)\n        get_dynamo_library_bounds();\n    ASSERT(dynamo_dll_end != NULL);\n    return dynamo_dll_end;\n}\n\napp_pc\nget_dynamorio_dll_preferred_base()\n{\n    /* on Linux there is no preferred base if we're PIC,\n     * therefore is always equal to dynamo_dll_start  */\n    return get_dynamorio_dll_start();\n}\n\nstatic void\nfound_vsyscall_page(memquery_iter_t *iter _IF_DEBUG(OUT const char **map_type))\n{\n#ifndef X64\n    /* We assume no vsyscall page for x64; thus, checking the\n     * hardcoded address shouldn't have any false positives.\n     */\n    ASSERT(iter->vm_end - iter->vm_start == PAGE_SIZE ||\n           /* i#1583: recent kernels have 2-page vdso */\n           iter->vm_end - iter->vm_start == 2 * PAGE_SIZE);\n    ASSERT(!dynamo_initialized); /* .data should be +w */\n    /* we're not considering as \"image\" even if part of ld.so (xref i#89) and\n     * thus we aren't adjusting our code origins policies to remove the\n     * vsyscall page exemption.\n     */\n    DODEBUG({ *map_type = \"VDSO\"; });\n    /* On re-attach, the vdso can be split into two entries (from DR's hook),\n     * so take just the first one as the start (xref i#2157).\n     */\n    if (vdso_page_start == NULL) {\n        vdso_page_start = iter->vm_start;\n        vdso_size = iter->vm_end - iter->vm_start;\n    }\n    /* The vsyscall page can be on the 2nd page inside the vdso, but until we\n     * see a syscall we don't know and we point it at the vdso start.\n     */\n    if (vsyscall_page_start == NULL)\n        vsyscall_page_start = iter->vm_start;\n    LOG(GLOBAL, LOG_VMAREAS, 1, \"found vdso/vsyscall pages @ \" PFX \" %s\\n\",\n        vsyscall_page_start, iter->comment);\n#else\n    /* i#172\n     * fix bugs for OS where vdso page is set unreadable as below\n     * ffffffffff600000-ffffffffffe00000 ---p 00000000 00:00 0 [vdso]\n     * but it is readable indeed.\n     */\n    /* i#430\n     * fix bugs for OS where vdso page is set unreadable as below\n     * ffffffffff600000-ffffffffffe00000 ---p 00000000 00:00 0 [vsyscall]\n     * but it is readable indeed.\n     */\n    if (!TESTALL((PROT_READ | PROT_EXEC), iter->prot))\n        iter->prot |= (PROT_READ | PROT_EXEC);\n    /* i#1908: vdso and vsyscall pages are now split */\n    if (strncmp(iter->comment, VSYSCALL_PAGE_MAPS_NAME,\n                strlen(VSYSCALL_PAGE_MAPS_NAME)) == 0)\n        vdso_page_start = iter->vm_start;\n    else if (strncmp(iter->comment, VSYSCALL_REGION_MAPS_NAME,\n                     strlen(VSYSCALL_REGION_MAPS_NAME)) == 0)\n        vsyscall_page_start = iter->vm_start;\n#endif\n}\n\n#ifndef HAVE_MEMINFO_QUERY\nstatic void\nadd_to_memcache(byte *region_start, byte *region_end, void *user_data)\n{\n    memcache_update_locked(region_start, region_end, MEMPROT_NONE, DR_MEMTYPE_DATA,\n                           false /*!exists*/);\n}\n#endif\n\nint\nos_walk_address_space(memquery_iter_t *iter, bool add_modules)\n{\n    int count = 0;\n#ifdef MACOS\n    app_pc shared_start, shared_end;\n    bool have_shared = module_dyld_shared_region(&shared_start, &shared_end);\n#endif\n#ifdef RETURN_AFTER_CALL\n    dcontext_t *dcontext = get_thread_private_dcontext();\n    os_thread_data_t *ostd = (os_thread_data_t *)dcontext->os_field;\n#endif\n\n#ifndef HAVE_MEMINFO_QUERY\n    /* We avoid tracking the innards of vmheap for all_memory_areas by\n     * adding a single no-access region for the whole vmheap.\n     * Queries from heap routines use _from_os.\n     * Queries in check_thread_vm_area are fine getting \"noaccess\": wants\n     * any DR memory not on exec areas list to be noaccess.\n     * Queries from clients: should be ok to hide innards.  Marking noaccess\n     * should be safer than marking free, as unruly client might try to mmap\n     * something in the free space: better to have it think it's reserved but\n     * not yet used memory.  FIXME: we're not marking beyond-vmheap DR regions\n     * as noaccess!\n     */\n    iterate_vmm_regions(add_to_memcache, NULL);\n#endif\n\n#ifndef HAVE_MEMINFO\n    count = find_vm_areas_via_probe();\n#else\n    while (memquery_iterator_next(iter)) {\n        bool image = false;\n        size_t size = iter->vm_end - iter->vm_start;\n        /* i#479, hide private module and match Windows's behavior */\n        bool skip = dynamo_vm_area_overlap(iter->vm_start, iter->vm_end) &&\n            !is_in_dynamo_dll(iter->vm_start) /* our own text section is ok */\n            /* client lib text section is ok (xref i#487) */\n            && !is_in_client_lib(iter->vm_start);\n        DEBUG_DECLARE(const char *map_type = \"Private\");\n        /* we can't really tell what's a stack and what's not, but we rely on\n         * our passing NULL preventing rwx regions from being added to executable\n         * or future list, even w/ -executable_if_alloc\n         */\n\n        LOG(GLOBAL, LOG_VMAREAS, 2, \"start=\" PFX \" end=\" PFX \" prot=%x comment=%s\\n\",\n            iter->vm_start, iter->vm_end, iter->prot, iter->comment);\n        /* Issue 89: the vdso might be loaded inside ld.so as below,\n         * which causes ASSERT_CURIOSITY in mmap_check_for_module_overlap fail.\n         * b7fa3000-b7fbd000 r-xp 00000000 08:01 108679     /lib/ld-2.8.90.so\n         * b7fbd000-b7fbe000 r-xp b7fbd000 00:00 0          [vdso]\n         * b7fbe000-b7fbf000 r--p 0001a000 08:01 108679     /lib/ld-2.8.90.so\n         * b7fbf000-b7fc0000 rw-p 0001b000 08:01 108679     /lib/ld-2.8.90.so\n         * So we always first check if it is a vdso page before calling\n         * mmap_check_for_module_overlap.\n         * Update: with i#160/PR 562667 handling non-contiguous modules like\n         * ld.so we now gracefully handle other objects like vdso in gaps in\n         * module, but it's simpler to leave this ordering here.\n         */\n        if (skip) {\n            /* i#479, hide private module and match Windows's behavior */\n            LOG(GLOBAL, LOG_VMAREAS, 2, PFX \"-\" PFX \" skipping: internal DR region\\n\",\n                iter->vm_start, iter->vm_end);\n#    ifdef MACOS\n        } else if (have_shared && iter->vm_start >= shared_start &&\n                   iter->vm_start < shared_end) {\n            /* Skip modules we happen to find inside the dyld shared cache,\n             * as we'll fail to identify the library.  We add them\n             * in module_walk_dyld_list instead.\n             */\n            image = true;\n#    endif\n        } else if (strncmp(iter->comment, VSYSCALL_PAGE_MAPS_NAME,\n                           strlen(VSYSCALL_PAGE_MAPS_NAME)) == 0 ||\n                   IF_X64_ELSE(strncmp(iter->comment, VSYSCALL_REGION_MAPS_NAME,\n                                       strlen(VSYSCALL_REGION_MAPS_NAME)) == 0,\n                               /* Older kernels do not label it as \"[vdso]\", but it is\n                                * hardcoded there.\n                                */\n                               /* 32-bit */\n                               iter->vm_start == VSYSCALL_PAGE_START_HARDCODED)) {\n            if (add_modules) {\n                found_vsyscall_page(iter _IF_DEBUG(&map_type));\n                /* We'd like to add vsyscall to the module list too but when it's\n                 * separate from vdso it has no ELF header which is too complex\n                 * to force into the module list.\n                 */\n                if (module_is_header(iter->vm_start, iter->vm_end - iter->vm_start)) {\n                    module_list_add(iter->vm_start, iter->vm_end - iter->vm_start, false,\n                                    iter->comment, iter->inode);\n                }\n            }\n        } else if (add_modules &&\n                   mmap_check_for_module_overlap(iter->vm_start, size,\n                                                 TEST(MEMPROT_READ, iter->prot),\n                                                 iter->inode, false)) {\n            /* we already added the whole image region when we hit the first map for it */\n            image = true;\n            DODEBUG({ map_type = \"ELF SO\"; });\n        } else if (TEST(MEMPROT_READ, iter->prot) &&\n                   module_is_header(iter->vm_start, size)) {\n            size_t image_size = size;\n            app_pc mod_base, mod_first_end, mod_max_end;\n            char *exec_match;\n            bool found_exec = false;\n            image = true;\n            DODEBUG({ map_type = \"ELF SO\"; });\n            LOG(GLOBAL, LOG_VMAREAS, 2,\n                \"Found already mapped module first segment :\\n\"\n                \"\\t\" PFX \"-\" PFX \"%s inode=\" UINT64_FORMAT_STRING \" name=%s\\n\",\n                iter->vm_start, iter->vm_end, TEST(MEMPROT_EXEC, iter->prot) ? \" +x\" : \"\",\n                iter->inode, iter->comment);\n#    ifdef LINUX\n            /* Mapped images should have inodes, except for cases where an anon\n             * map is placed on top (i#2566)\n             */\n            ASSERT_CURIOSITY(iter->inode != 0 || iter->comment[0] == '\\0');\n#    endif\n            ASSERT_CURIOSITY(iter->offset == 0); /* first map shouldn't have offset */\n            /* Get size by walking the program headers.  This includes .bss. */\n            if (module_walk_program_headers(iter->vm_start, size, false,\n                                            true, /* i#1589: ld.so relocated .dynamic */\n                                            &mod_base, &mod_first_end, &mod_max_end, NULL,\n                                            NULL)) {\n                image_size = mod_max_end - mod_base;\n            } else {\n                ASSERT_NOT_REACHED();\n            }\n            LOG(GLOBAL, LOG_VMAREAS, 2,\n                \"Found already mapped module total module :\\n\"\n                \"\\t\" PFX \"-\" PFX \" inode=\" UINT64_FORMAT_STRING \" name=%s\\n\",\n                iter->vm_start, iter->vm_start + image_size, iter->inode, iter->comment);\n\n            if (add_modules) {\n                const char *modpath = iter->comment;\n                /* look for executable */\n#    ifdef LINUX\n                exec_match = get_application_name();\n                if (exec_match != NULL && exec_match[0] != '\\0')\n                    found_exec = (strcmp(iter->comment, exec_match) == 0);\n                /* Handle an anon region for the header (i#2566) */\n                if (!found_exec && executable_start != NULL &&\n                    executable_start == iter->vm_start) {\n                    found_exec = true;\n                    /* The maps file's first entry may not have the path, in the\n                     * presence of mremapping for hugepages (i#2566; i#3387) (this\n                     * could happen for libraries too, but we don't have alternatives\n                     * there).  Or, it may have an incorrect path.  Prefer the path\n                     * we recorded in early injection or obtained from\n                     * /proc/self/exe.\n                     */\n                    modpath = get_application_name();\n                }\n#    else\n                /* We don't have a nice normalized name: it can have ./ or ../ inside\n                 * it.  But, we can distinguish an exe from a lib here, even for PIE,\n                 * so we go with that plus a basename comparison.\n                 */\n                exec_match = (char *)get_application_short_name();\n                if (module_is_executable(iter->vm_start) && exec_match != NULL &&\n                    exec_match[0] != '\\0') {\n                    const char *iter_basename = strrchr(iter->comment, '/');\n                    if (iter_basename == NULL)\n                        iter_basename = iter->comment;\n                    else\n                        iter_basename++;\n                    found_exec = (strcmp(iter_basename, exec_match) == 0);\n                }\n#    endif\n                if (found_exec) {\n                    if (executable_start == NULL)\n                        executable_start = iter->vm_start;\n                    else\n                        ASSERT(iter->vm_start == executable_start);\n                    LOG(GLOBAL, LOG_VMAREAS, 2,\n                        \"Found executable %s @\" PFX \"-\" PFX \" %s\\n\",\n                        get_application_name(), iter->vm_start,\n                        iter->vm_start + image_size, iter->comment);\n                }\n                /* We don't yet know whether contiguous so we have to settle for the\n                 * first segment's size.  We'll update it in module_list_add().\n                 */\n                module_list_add(iter->vm_start, mod_first_end - mod_base, false, modpath,\n                                iter->inode);\n\n#    ifdef MACOS\n                /* look for dyld */\n                if (strcmp(iter->comment, \"/usr/lib/dyld\") == 0)\n                    module_walk_dyld_list(iter->vm_start);\n#    endif\n            }\n        } else if (iter->inode != 0) {\n            DODEBUG({ map_type = \"Mapped File\"; });\n        }\n\n        /* add all regions (incl. dynamo_areas and stack) to all_memory_areas */\n#    ifndef HAVE_MEMINFO_QUERY\n        /* Don't add if we're using one single vmheap entry. */\n        if (!is_vmm_reserved_address(iter->vm_start, iter->vm_end - iter->vm_start, NULL,\n                                     NULL)) {\n            LOG(GLOBAL, LOG_VMAREAS, 4,\n                \"os_walk_address_space: adding: \" PFX \"-\" PFX \" prot=%d\\n\",\n                iter->vm_start, iter->vm_end, iter->prot);\n            memcache_update_locked(iter->vm_start, iter->vm_end, iter->prot,\n                                   image ? DR_MEMTYPE_IMAGE : DR_MEMTYPE_DATA,\n                                   false /*!exists*/);\n        }\n#    endif\n\n        /* FIXME: best if we could pass every region to vmareas, but\n         * it has no way of determining if this is a stack b/c we don't have\n         * a dcontext at this point -- so we just don't pass the stack\n         */\n        if (!skip /* i#479, hide private module and match Windows's behavior */ &&\n            add_modules &&\n            app_memory_allocation(NULL, iter->vm_start, (iter->vm_end - iter->vm_start),\n                                  iter->prot, image _IF_DEBUG(map_type))) {\n            count++;\n        }\n    }\n#endif /* !HAVE_MEMINFO */\n\n#ifndef HAVE_MEMINFO_QUERY\n    DOLOG(4, LOG_VMAREAS, memcache_print(GLOBAL, \"init: all memory areas:\\n\"););\n#endif\n\n#ifdef RETURN_AFTER_CALL\n    /* Find the bottom of the stack of the initial (native) entry */\n    ostd->stack_bottom_pc = find_stack_bottom();\n    LOG(THREAD, LOG_ALL, 1, \"Stack bottom pc = \" PFX \"\\n\", ostd->stack_bottom_pc);\n#endif\n\n    /* now that we've walked memory print all modules */\n    LOG(GLOBAL, LOG_VMAREAS, 2, \"Module list after memory walk\\n\");\n    DOLOG(1, LOG_VMAREAS, {\n        if (add_modules)\n            print_modules(GLOBAL, DUMP_NOT_XML);\n    });\n\n    return count;\n}\n\n/* assumed to be called after find_dynamo_library_vm_areas() */\nint\nfind_executable_vm_areas(void)\n{\n    int count;\n    memquery_iter_t iter;\n    memquery_iterator_start(&iter, NULL, true /*may alloc*/);\n    count = os_walk_address_space(&iter, true);\n    memquery_iterator_stop(&iter);\n\n    STATS_ADD(num_app_code_modules, count);\n\n    /* now that we have the modules set up, query libc */\n    get_libc_errno_location(true /*force init*/);\n\n    return count;\n}\n\n/* initializes dynamorio library bounds.\n * does not use any heap.\n * assumed to be called prior to find_executable_vm_areas.\n */\nint\nfind_dynamo_library_vm_areas(void)\n{\n#ifndef STATIC_LIBRARY\n    /* We didn't add inside get_dynamo_library_bounds b/c it was called pre-alloc.\n     * We don't bother to break down the sub-regions.\n     * Assumption: we don't need to have the protection flags for DR sub-regions.\n     * For static library builds, DR's code is in the exe and isn't considered\n     * to be a DR area.\n     */\n    add_dynamo_vm_area(get_dynamorio_dll_start(), get_dynamorio_dll_end(),\n                       MEMPROT_READ | MEMPROT_WRITE | MEMPROT_EXEC,\n                       true /* from image */ _IF_DEBUG(dynamorio_library_filepath));\n#endif\n#ifdef VMX86_SERVER\n    if (os_in_vmkernel_userworld())\n        vmk_add_vmklib_to_dynamo_areas();\n#endif\n    return 1;\n}\n\nbool\nget_stack_bounds(dcontext_t *dcontext, byte **base, byte **top)\n{\n    os_thread_data_t *ostd = (os_thread_data_t *)dcontext->os_field;\n    if (ostd->stack_base == NULL) {\n        /* initialize on-demand since don't have app esp handy in os_thread_init()\n         * FIXME: the comment here -- ignoring it for now, if hit cases confirming\n         * it the right thing will be to merge adjacent rwx regions and assume\n         * their union is the stack -- otherwise have to have special stack init\n         * routine called from x86.asm new_thread_dynamo_start and internal_dynamo_start,\n         * and the latter is not a do-once...\n         */\n        size_t size = 0;\n        bool ok;\n        /* store stack info at thread startup, since stack can get fragmented in\n         * /proc/self/maps w/ later mprotects and it can be hard to piece together later\n         */\n        if (IF_MEMQUERY_ELSE(false, DYNAMO_OPTION(use_all_memory_areas))) {\n            ok = get_memory_info((app_pc)get_mcontext(dcontext)->xsp, &ostd->stack_base,\n                                 &size, NULL);\n        } else {\n            ok = get_memory_info_from_os((app_pc)get_mcontext(dcontext)->xsp,\n                                         &ostd->stack_base, &size, NULL);\n        }\n        if (!ok) {\n            /* This can happen with dr_prepopulate_cache() before we start running\n             * the app.\n             */\n            ASSERT(!dynamo_started);\n            return false;\n        }\n        ostd->stack_top = ostd->stack_base + size;\n        LOG(THREAD, LOG_THREADS, 1, \"App stack is \" PFX \"-\" PFX \"\\n\", ostd->stack_base,\n            ostd->stack_top);\n    }\n    if (base != NULL)\n        *base = ostd->stack_base;\n    if (top != NULL)\n        *top = ostd->stack_top;\n    return true;\n}\n\n#ifdef RETURN_AFTER_CALL\ninitial_call_stack_status_t\nat_initial_stack_bottom(dcontext_t *dcontext, app_pc target_pc)\n{\n    /* We can't rely exclusively on finding the true stack bottom\n     * b/c we can't always walk the call stack (PR 608990) so we\n     * use the image entry as our primary trigger\n     */\n    if (executable_start != NULL /*defensive*/ && reached_image_entry_yet()) {\n        return INITIAL_STACK_EMPTY;\n    } else {\n        /* If our stack walk ends early we could have false positives, but\n         * that's better than false negatives if we miss the image entry\n         * or we were unable to find the executable_start\n         */\n        os_thread_data_t *ostd = (os_thread_data_t *)dcontext->os_field;\n        if (target_pc == ostd->stack_bottom_pc) {\n            return INITIAL_STACK_BOTTOM_REACHED;\n        } else {\n            return INITIAL_STACK_BOTTOM_NOT_REACHED;\n        }\n    }\n}\n#endif /* RETURN_AFTER_CALL */\n\n/* Uses our cached data structures (if in use, else raw query) to retrieve memory info */\nbool\nquery_memory_ex(const byte *pc, OUT dr_mem_info_t *out_info)\n{\n#ifdef HAVE_MEMINFO_QUERY\n    return query_memory_ex_from_os(pc, out_info);\n#else\n    return memcache_query_memory(pc, out_info);\n#endif\n}\n\nbool\nquery_memory_cur_base(const byte *pc, OUT dr_mem_info_t *info)\n{\n    return query_memory_ex(pc, info);\n}\n\n/* Use our cached data structures (if in use, else raw query) to retrieve memory info */\nbool\nget_memory_info(const byte *pc, byte **base_pc, size_t *size,\n                uint *prot /* OUT optional, returns MEMPROT_* value */)\n{\n    dr_mem_info_t info;\n    if (is_vmm_reserved_address((byte *)pc, 1, NULL, NULL)) {\n        if (!query_memory_ex_from_os(pc, &info) || info.type == DR_MEMTYPE_FREE)\n            return false;\n    } else {\n        if (!query_memory_ex(pc, &info) || info.type == DR_MEMTYPE_FREE)\n            return false;\n    }\n    if (base_pc != NULL)\n        *base_pc = info.base_pc;\n    if (size != NULL)\n        *size = info.size;\n    if (prot != NULL)\n        *prot = info.prot;\n    return true;\n}\n\n/* We assume that this routine might be called instead of query_memory_ex()\n * b/c the caller is in a fragile location and cannot acquire locks, so\n * we try to do the same here.\n */\nbool\nquery_memory_ex_from_os(const byte *pc, OUT dr_mem_info_t *info)\n{\n    bool have_type = false;\n    bool res = memquery_from_os(pc, info, &have_type);\n    if (!res) {\n        /* No other failure types for now */\n        info->type = DR_MEMTYPE_ERROR;\n    } else if (res && !have_type) {\n        /* We pass 0 instead of info->size b/c even if marked as +r we can still\n         * get SIGBUS if beyond end of mmapped file: not uncommon if querying\n         * in middle of library load before .bss fully set up (PR 528744).\n         * However, if there is no fault handler, is_elf_so_header's safe_read will\n         * recurse to here, so in that case we use info->size but we assume\n         * it's only at init or exit and so not in the middle of a load\n         * and less likely to be querying a random mmapped file.\n         * The cleaner fix is to allow safe_read to work w/o a dcontext or\n         * fault handling: i#350/PR 529066.\n         */\n        if (TEST(MEMPROT_READ, info->prot) &&\n            module_is_header(info->base_pc, fault_handling_initialized ? 0 : info->size))\n            info->type = DR_MEMTYPE_IMAGE;\n        else {\n            /* FIXME: won't quite match find_executable_vm_areas marking as\n             * image: can be doubly-mapped so; don't want to count vdso; etc.\n             */\n            info->type = DR_MEMTYPE_DATA;\n        }\n    }\n    return res;\n}\n\nbool\nget_memory_info_from_os(const byte *pc, byte **base_pc, size_t *size,\n                        uint *prot /* OUT optional, returns MEMPROT_* value */)\n{\n    dr_mem_info_t info;\n    if (!query_memory_ex_from_os(pc, &info) || info.type == DR_MEMTYPE_FREE)\n        return false;\n    if (base_pc != NULL)\n        *base_pc = info.base_pc;\n    if (size != NULL)\n        *size = info.size;\n    if (prot != NULL)\n        *prot = info.prot;\n    return true;\n}\n\n/* in utils.c, exported only for our hack! */\nextern void\ndeadlock_avoidance_unlock(mutex_t *lock, bool ownable);\n\nvoid\nmutex_wait_contended_lock(mutex_t *lock, priv_mcontext_t *mc)\n{\n    dcontext_t *dcontext = get_thread_private_dcontext();\n    bool set_client_safe_for_synch =\n        ((dcontext != NULL) && IS_CLIENT_THREAD(dcontext) &&\n         ((mutex_t *)dcontext->client_data->client_grab_mutex == lock));\n    if (mc != NULL) {\n        ASSERT(dcontext != NULL);\n        /* set_safe_for_sync can't be true at the same time as passing\n         * an mcontext to return into: nothing would be able to reset the\n         * client_thread_safe_for_sync flag.\n         */\n        ASSERT(!set_client_safe_for_synch);\n        *get_mcontext(dcontext) = *mc;\n    }\n\n    /* i#96/PR 295561: use futex(2) if available */\n    if (ksynch_kernel_support()) {\n        /* Try to get the lock.  If already held, it's fine to store any value\n         * > LOCK_SET_STATE (we don't rely on paired incs/decs) so that\n         * the next unlocker will call mutex_notify_released_lock().\n         */\n        ptr_int_t res;\n#ifndef LINUX /* we actually don't use this for Linux: see below */\n        KSYNCH_TYPE *event = mutex_get_contended_event(lock);\n        ASSERT(event != NULL && ksynch_var_initialized(event));\n#endif\n        while (atomic_exchange_int(&lock->lock_requests, LOCK_CONTENDED_STATE) !=\n               LOCK_FREE_STATE) {\n            if (set_client_safe_for_synch)\n                dcontext->client_data->client_thread_safe_for_synch = true;\n            if (mc != NULL)\n                set_synch_state(dcontext, THREAD_SYNCH_VALID_MCONTEXT);\n\n                /* Unfortunately the synch semantics are different for Linux vs Mac.\n                 * We have to use lock_requests as the futex to avoid waiting if\n                 * lock_requests changes, while on Mac the underlying synch prevents\n                 * a wait there.\n                 */\n#ifdef LINUX\n            /* We'll abort the wait if lock_requests has changed at all.\n             * We can't have a series of changes that result in no apparent\n             * change w/o someone acquiring the lock, b/c\n             * mutex_notify_released_lock() sets lock_requests to LOCK_FREE_STATE.\n             */\n            res = ksynch_wait(&lock->lock_requests, LOCK_CONTENDED_STATE, 0);\n#else\n            res = ksynch_wait(event, 0, 0);\n#endif\n            if (res != 0 && res != -EWOULDBLOCK)\n                os_thread_yield();\n            if (set_client_safe_for_synch)\n                dcontext->client_data->client_thread_safe_for_synch = false;\n            if (mc != NULL)\n                set_synch_state(dcontext, THREAD_SYNCH_NONE);\n\n            /* we don't care whether properly woken (res==0), var mismatch\n             * (res==-EWOULDBLOCK), or error: regardless, someone else\n             * could have acquired the lock, so we try again\n             */\n        }\n    } else {\n        /* we now have to undo our earlier request */\n        atomic_dec_and_test(&lock->lock_requests);\n\n        while (!d_r_mutex_trylock(lock)) {\n            if (set_client_safe_for_synch)\n                dcontext->client_data->client_thread_safe_for_synch = true;\n            if (mc != NULL)\n                set_synch_state(dcontext, THREAD_SYNCH_VALID_MCONTEXT);\n\n            os_thread_yield();\n            if (set_client_safe_for_synch)\n                dcontext->client_data->client_thread_safe_for_synch = false;\n            if (mc != NULL)\n                set_synch_state(dcontext, THREAD_SYNCH_NONE);\n        }\n\n#ifdef DEADLOCK_AVOIDANCE\n        /* HACK: trylock's success causes it to do DEADLOCK_AVOIDANCE_LOCK, so to\n         * avoid two in a row (causes assertion on owner) we unlock here\n         * In the future we will remove the trylock here and this will go away.\n         */\n        deadlock_avoidance_unlock(lock, true);\n#endif\n    }\n\n    return;\n}\n\nvoid\nmutex_notify_released_lock(mutex_t *lock)\n{\n    /* i#96/PR 295561: use futex(2) if available. */\n    if (ksynch_kernel_support()) {\n        /* Set to LOCK_FREE_STATE to avoid concurrent lock attempts from\n         * resulting in a futex_wait value match w/o anyone owning the lock\n         */\n        lock->lock_requests = LOCK_FREE_STATE;\n        /* No reason to wake multiple threads: just one */\n#ifdef LINUX\n        ksynch_wake(&lock->lock_requests);\n#else\n        ksynch_wake(&lock->contended_event);\n#endif\n    } /* else nothing to do */\n}\n\n/* read_write_lock_t implementation doesn't expect the contention path\n   helpers to guarantee the lock is held (unlike mutexes) so simple\n   yields are still acceptable.\n*/\nvoid\nrwlock_wait_contended_writer(read_write_lock_t *rwlock)\n{\n    os_thread_yield();\n}\n\nvoid\nrwlock_notify_writer(read_write_lock_t *rwlock)\n{\n    /* nothing to do here */\n}\n\nvoid\nrwlock_wait_contended_reader(read_write_lock_t *rwlock)\n{\n    os_thread_yield();\n}\n\nvoid\nrwlock_notify_readers(read_write_lock_t *rwlock)\n{\n    /* nothing to do here */\n}\n\n/***************************************************************************/\n\n/* events are un-signaled when successfully waited upon. */\ntypedef struct linux_event_t {\n    /* Any function that sets this flag must also notify possibly waiting\n     * thread(s). See i#96/PR 295561.\n     */\n    KSYNCH_TYPE signaled;\n    mutex_t lock;\n    bool broadcast;\n} linux_event_t;\n\n/* FIXME: this routine will need to have a macro wrapper to let us\n * assign different ranks to all events for DEADLOCK_AVOIDANCE.\n * Currently a single rank seems to work.\n */\nevent_t\ncreate_event(void)\n{\n    event_t e = (event_t)global_heap_alloc(sizeof(linux_event_t) HEAPACCT(ACCT_OTHER));\n    ksynch_init_var(&e->signaled);\n    ASSIGN_INIT_LOCK_FREE(e->lock, event_lock); /* FIXME: pass the event name here */\n    e->broadcast = false;\n    return e;\n}\n\nevent_t\ncreate_broadcast_event(void)\n{\n    event_t e = create_event();\n    e->broadcast = true;\n    return e;\n}\n\nvoid\ndestroy_event(event_t e)\n{\n    DELETE_LOCK(e->lock);\n    ksynch_free_var(&e->signaled);\n    global_heap_free(e, sizeof(linux_event_t) HEAPACCT(ACCT_OTHER));\n}\n\nvoid\nsignal_event(event_t e)\n{\n    d_r_mutex_lock(&e->lock);\n    ksynch_set_value(&e->signaled, 1);\n    if (e->broadcast)\n        ksynch_wake_all(&e->signaled);\n    else\n        ksynch_wake(&e->signaled);\n    LOG(THREAD_GET, LOG_THREADS, 3, \"thread \" TIDFMT \" signalling event \" PFX \"\\n\",\n        d_r_get_thread_id(), e);\n    d_r_mutex_unlock(&e->lock);\n}\n\nvoid\nreset_event(event_t e)\n{\n    d_r_mutex_lock(&e->lock);\n    ksynch_set_value(&e->signaled, 0);\n    LOG(THREAD_GET, LOG_THREADS, 3, \"thread \" TIDFMT \" resetting event \" PFX \"\\n\",\n        d_r_get_thread_id(), e);\n    d_r_mutex_unlock(&e->lock);\n}\n\nbool\nwait_for_event(event_t e, int timeout_ms)\n{\n#ifdef DEBUG\n    dcontext_t *dcontext = get_thread_private_dcontext();\n#endif\n    uint64 start_time, cur_time;\n    if (timeout_ms > 0)\n        start_time = query_time_millis();\n    /* Use a user-space event on Linux, a kernel event on Windows. */\n    LOG(THREAD, LOG_THREADS, 3, \"thread \" TIDFMT \" waiting for event \" PFX \"\\n\",\n        d_r_get_thread_id(), e);\n    do {\n        if (ksynch_get_value(&e->signaled) == 1) {\n            d_r_mutex_lock(&e->lock);\n            if (ksynch_get_value(&e->signaled) == 0) {\n                /* some other thread beat us to it */\n                LOG(THREAD, LOG_THREADS, 3,\n                    \"thread \" TIDFMT \" was beaten to event \" PFX \"\\n\",\n                    d_r_get_thread_id(), e);\n                d_r_mutex_unlock(&e->lock);\n            } else {\n                if (!e->broadcast) {\n                    /* reset the event */\n                    ksynch_set_value(&e->signaled, 0);\n                }\n                d_r_mutex_unlock(&e->lock);\n                LOG(THREAD, LOG_THREADS, 3,\n                    \"thread \" TIDFMT \" finished waiting for event \" PFX \"\\n\",\n                    d_r_get_thread_id(), e);\n                return true;\n            }\n        } else {\n            /* Waits only if the signaled flag is not set as 1. Return value\n             * doesn't matter because the flag will be re-checked.\n             */\n            ksynch_wait(&e->signaled, 0, timeout_ms);\n        }\n        if (ksynch_get_value(&e->signaled) == 0) {\n            /* If it still has to wait, give up the cpu. */\n            os_thread_yield();\n        }\n        if (timeout_ms > 0)\n            cur_time = query_time_millis();\n    } while (timeout_ms <= 0 || cur_time - start_time < timeout_ms);\n    return false;\n}\n\n/***************************************************************************\n * DIRECTORY ITERATOR\n */\n\n/* These structs are written to the buf that we pass to getdents.  We can\n * iterate them by adding d_reclen to the current buffer offset and interpreting\n * that as the next entry.\n */\nstruct linux_dirent {\n#ifdef SYS_getdents\n    /* Adapted from struct old_linux_dirent in linux/fs/readdir.c: */\n    unsigned long d_ino;\n    unsigned long d_off;\n    unsigned short d_reclen;\n    char d_name[];\n#else\n    /* Adapted from struct linux_dirent64 in linux/include/linux/dirent.h: */\n    uint64 d_ino;\n    int64 d_off;\n    unsigned short d_reclen;\n    unsigned char d_type;\n    char d_name[];\n#endif\n};\n\n#define CURRENT_DIRENT(iter) ((struct linux_dirent *)(&iter->buf[iter->off]))\n\nstatic void\nos_dir_iterator_start(dir_iterator_t *iter, file_t fd)\n{\n    iter->fd = fd;\n    iter->off = 0;\n    iter->end = 0;\n}\n\nstatic bool\nos_dir_iterator_next(dir_iterator_t *iter)\n{\n#ifdef MACOS\n    /* We can use SYS_getdirentries, but do we even need a dir iterator?\n     * On Linux it's only used to enumerate /proc/pid/task.\n     */\n    ASSERT_NOT_IMPLEMENTED(false);\n    return false;\n#else\n    if (iter->off < iter->end) {\n        /* Have existing dents, get the next offset. */\n        iter->off += CURRENT_DIRENT(iter)->d_reclen;\n        ASSERT(iter->off <= iter->end);\n    }\n    if (iter->off == iter->end) {\n        /* Do a getdents syscall.  Unlike when reading a file, the kernel will\n         * not read a partial linux_dirent struct, so we don't need to shift the\n         * left over bytes to the buffer start.  See the getdents manpage for\n         * the example code that this is based on.\n         */\n        iter->off = 0;\n#    ifdef SYS_getdents\n        iter->end =\n            dynamorio_syscall(SYS_getdents, 3, iter->fd, iter->buf, sizeof(iter->buf));\n#    else\n        iter->end =\n            dynamorio_syscall(SYS_getdents64, 3, iter->fd, iter->buf, sizeof(iter->buf));\n#    endif\n        ASSERT(iter->end <= sizeof(iter->buf));\n        if (iter->end <= 0) { /* No more dents, or error. */\n            iter->name = NULL;\n            if (iter->end < 0) {\n                LOG(GLOBAL, LOG_SYSCALLS, 1, \"getdents syscall failed with errno %d\\n\",\n                    -iter->end);\n            }\n            return false;\n        }\n    }\n    iter->name = CURRENT_DIRENT(iter)->d_name;\n    return true;\n#endif\n}\n\n/***************************************************************************\n * THREAD TAKEOVER\n */\n\n/* Record used to synchronize thread takeover. */\ntypedef struct _takeover_record_t {\n    thread_id_t tid;\n    event_t event;\n} takeover_record_t;\n\n/* When attempting thread takeover, we store an array of thread id and event\n * pairs here.  Each thread we signal is supposed to enter DR control and signal\n * this event after it has added itself to all_threads.\n *\n * XXX: What we really want is to be able to use SYS_rt_tgsigqueueinfo (Linux >=\n * 2.6.31) to pass the event_t to each thread directly, rather than using this\n * side data structure.\n */\nstatic takeover_record_t *thread_takeover_records;\nstatic uint num_thread_takeover_records;\n\n/* This is the dcontext of the thread that initiated the takeover.  We read the\n * owning_thread and signal_field threads from it in the signaled threads to\n * set up siginfo sharing.\n */\nstatic dcontext_t *takeover_dcontext;\n\n/* Lists active threads in the process.\n * XXX: The /proc man page says /proc/pid/task is only available if the main\n * thread is still alive, but experiments on 2.6.38 show otherwise.\n */\nstatic thread_id_t *\nos_list_threads(dcontext_t *dcontext, uint *num_threads_out)\n{\n    dir_iterator_t iter;\n    file_t task_dir;\n    uint tids_alloced = 10;\n    uint num_threads = 0;\n    thread_id_t *new_tids;\n    thread_id_t *tids;\n\n    ASSERT(num_threads_out != NULL);\n\n#ifdef MACOS\n    /* XXX i#58: NYI.\n     * We may want SYS_proc_info with PROC_INFO_PID_INFO and PROC_PIDLISTTHREADS,\n     * or is that just BSD threads and instead we want process_set_tasks()\n     * and task_info() as in 7.3.1.3 in Singh's OSX book?\n     */\n    *num_threads_out = 0;\n    return NULL;\n#endif\n\n    tids =\n        HEAP_ARRAY_ALLOC(dcontext, thread_id_t, tids_alloced, ACCT_THREAD_MGT, PROTECTED);\n    task_dir = os_open_directory(\"/proc/self/task\", OS_OPEN_READ);\n    ASSERT(task_dir != INVALID_FILE);\n    os_dir_iterator_start(&iter, task_dir);\n    while (os_dir_iterator_next(&iter)) {\n        thread_id_t tid;\n        DEBUG_DECLARE(int r;)\n        if (strcmp(iter.name, \".\") == 0 || strcmp(iter.name, \"..\") == 0)\n            continue;\n        IF_DEBUG(r =)\n        sscanf(iter.name, \"%u\", &tid);\n        ASSERT_MESSAGE(CHKLVL_ASSERTS, \"failed to parse /proc/pid/task entry\", r == 1);\n        if (tid <= 0)\n            continue;\n        if (num_threads == tids_alloced) {\n            /* realloc, essentially.  Less expensive than counting first. */\n            new_tids = HEAP_ARRAY_ALLOC(dcontext, thread_id_t, tids_alloced * 2,\n                                        ACCT_THREAD_MGT, PROTECTED);\n            memcpy(new_tids, tids, sizeof(thread_id_t) * tids_alloced);\n            HEAP_ARRAY_FREE(dcontext, tids, thread_id_t, tids_alloced, ACCT_THREAD_MGT,\n                            PROTECTED);\n            tids = new_tids;\n            tids_alloced *= 2;\n        }\n        tids[num_threads++] = tid;\n    }\n    ASSERT(iter.end == 0); /* No reading errors. */\n    os_close(task_dir);\n\n    /* realloc back down to num_threads for caller simplicity. */\n    new_tids =\n        HEAP_ARRAY_ALLOC(dcontext, thread_id_t, num_threads, ACCT_THREAD_MGT, PROTECTED);\n    memcpy(new_tids, tids, sizeof(thread_id_t) * num_threads);\n    HEAP_ARRAY_FREE(dcontext, tids, thread_id_t, tids_alloced, ACCT_THREAD_MGT,\n                    PROTECTED);\n    tids = new_tids;\n    *num_threads_out = num_threads;\n    return tids;\n}\n\n/* List the /proc/self/task directory and add all unknown thread ids to the\n * all_threads hashtable in dynamo.c.  Returns true if we found any unknown\n * threads and false otherwise.  We assume that since we don't know about them\n * they are not under DR and have no dcontexts.\n */\nbool\nos_take_over_all_unknown_threads(dcontext_t *dcontext)\n{\n    uint i;\n    uint num_threads;\n    thread_id_t *tids;\n    uint threads_to_signal = 0, threads_timed_out = 0;\n\n    /* We do not want to re-takeover a thread that's in between notifying us on\n     * the last call to this routine and getting onto the all_threads list as\n     * we'll self-interpret our own code leading to a lot of problems.\n     * XXX: should we use an event to avoid this inefficient loop?  We expect\n     * this to only happen in rare cases during attach when threads are in flux.\n     */\n    while (uninit_thread_count > 0) /* relying on volatile */\n        os_thread_yield();\n\n    /* This can only happen if we had already taken over a thread, because there is\n     * full synchronization at detach. The same thread may now already be on its way\n     * to exit, and its thread record might be gone already and make it look like a\n     * new native thread below. If we rely on the thread to self-detect that it was\n     * interrupted at a DR address we may run into a deadlock (i#2694). In order to\n     * avoid this, we wait here. This is expected to be uncommon, and can only happen\n     * with very short-lived threads.\n     * XXX: if this loop turns out to be too inefficient, we could support detecting\n     * the lock function's address bounds along w/ is_dynamo_address.\n     */\n    while (exiting_thread_count > 0)\n        os_thread_yield();\n\n    d_r_mutex_lock(&thread_initexit_lock);\n    CLIENT_ASSERT(thread_takeover_records == NULL,\n                  \"Only one thread should attempt app take over!\");\n\n#ifdef LINUX\n    /* Check this thread for rseq in between setup and start. */\n    if (rseq_is_registered_for_current_thread())\n        rseq_locate_rseq_regions();\n#endif\n\n    /* Find tids for which we have no thread record, meaning they are not under\n     * our control.  Shift them to the beginning of the tids array.\n     */\n    tids = os_list_threads(dcontext, &num_threads);\n    if (tids == NULL) {\n        d_r_mutex_unlock(&thread_initexit_lock);\n        return false; /* have to assume no unknown */\n    }\n    for (i = 0; i < num_threads; i++) {\n        thread_record_t *tr = thread_lookup(tids[i]);\n        if (tr == NULL ||\n            /* Re-takeover known threads that are currently native as well.\n             * XXX i#95: we need a synchall-style loop for known threads as\n             * they can be in DR for syscall hook handling.\n             * Update: we now remove the hook for start/stop: but native_exec\n             * or other individual threads going native could still hit this.\n             */\n            (is_thread_currently_native(tr) && !IS_CLIENT_THREAD(tr->dcontext)))\n            tids[threads_to_signal++] = tids[i];\n    }\n\n    LOG(GLOBAL, LOG_THREADS, 1, \"TAKEOVER: %d threads to take over\\n\", threads_to_signal);\n    if (threads_to_signal > 0) {\n        takeover_record_t *records;\n\n        /* Assuming pthreads, prepare signal_field for sharing. */\n        handle_clone(dcontext, PTHREAD_CLONE_FLAGS);\n\n        /* Create records with events for all the threads we want to signal. */\n        LOG(GLOBAL, LOG_THREADS, 1, \"TAKEOVER: publishing takeover records\\n\");\n        records = HEAP_ARRAY_ALLOC(dcontext, takeover_record_t, threads_to_signal,\n                                   ACCT_THREAD_MGT, PROTECTED);\n        for (i = 0; i < threads_to_signal; i++) {\n            LOG(GLOBAL, LOG_THREADS, 1, \"TAKEOVER: will signal thread \" TIDFMT \"\\n\",\n                tids[i]);\n            records[i].tid = tids[i];\n            records[i].event = create_event();\n        }\n\n        /* Publish the records and the initial take over dcontext. */\n        thread_takeover_records = records;\n        num_thread_takeover_records = threads_to_signal;\n        takeover_dcontext = dcontext;\n\n        /* Signal the other threads. */\n        for (i = 0; i < threads_to_signal; i++) {\n            thread_signal(get_process_id(), records[i].tid, SUSPEND_SIGNAL);\n        }\n        d_r_mutex_unlock(&thread_initexit_lock);\n\n        /* Wait for all the threads we signaled. */\n        ASSERT_OWN_NO_LOCKS();\n        for (i = 0; i < threads_to_signal; i++) {\n            static const int progress_period = 50;\n            if (i % progress_period == 0) {\n                char buf[16];\n                /* +1 to include the attach request thread to match the final msg. */\n                snprintf(buf, BUFFER_SIZE_ELEMENTS(buf), \"%d/%d\", i + 1,\n                         threads_to_signal + 1);\n                NULL_TERMINATE_BUFFER(buf);\n                SYSLOG(SYSLOG_VERBOSE, INFO_ATTACHED, 3, buf, get_application_name(),\n                       get_application_pid());\n            }\n            /* We split the wait up so that we'll break early on an exited thread. */\n            static const int wait_ms = 25;\n            int max_attempts =\n                /* Integer division rounding down is fine since we always wait 25ms. */\n                DYNAMO_OPTION(takeover_timeout_ms) / wait_ms;\n            int attempts = 0;\n            while (!wait_for_event(records[i].event, wait_ms)) {\n                /* The thread may have exited (i#2601).  We assume no tid re-use. */\n                char task[64];\n                snprintf(task, BUFFER_SIZE_ELEMENTS(task), \"/proc/self/task/%d\", tids[i]);\n                NULL_TERMINATE_BUFFER(task);\n                if (!os_file_exists(task, false /*!is dir*/)) {\n                    SYSLOG_INTERNAL_WARNING_ONCE(\"thread exited while attaching\");\n                    break;\n                }\n                if (++attempts > max_attempts) {\n                    if (DYNAMO_OPTION(unsafe_ignore_takeover_timeout)) {\n                        SYSLOG(\n                            SYSLOG_VERBOSE, THREAD_TAKEOVER_TIMED_OUT, 3,\n                            get_application_name(), get_application_pid(),\n                            \"Continuing since -unsafe_ignore_takeover_timeout is set.\");\n                        ++threads_timed_out;\n                    } else {\n                        SYSLOG(\n                            SYSLOG_VERBOSE, THREAD_TAKEOVER_TIMED_OUT, 3,\n                            get_application_name(), get_application_pid(),\n                            \"Aborting. Use -unsafe_ignore_takeover_timeout to ignore.\");\n                        REPORT_FATAL_ERROR_AND_EXIT(FAILED_TO_TAKE_OVER_THREADS, 2,\n                                                    get_application_name(),\n                                                    get_application_pid());\n                    }\n                    break;\n                }\n                /* Else try again. */\n            }\n        }\n\n        /* Now that we've taken over the other threads, we can safely free the\n         * records and reset the shared globals.\n         */\n        d_r_mutex_lock(&thread_initexit_lock);\n        LOG(GLOBAL, LOG_THREADS, 1,\n            \"TAKEOVER: takeover complete, unpublishing records\\n\");\n        thread_takeover_records = NULL;\n        num_thread_takeover_records = 0;\n        takeover_dcontext = NULL;\n        for (i = 0; i < threads_to_signal; i++) {\n            destroy_event(records[i].event);\n        }\n        HEAP_ARRAY_FREE(dcontext, records, takeover_record_t, threads_to_signal,\n                        ACCT_THREAD_MGT, PROTECTED);\n    }\n\n    d_r_mutex_unlock(&thread_initexit_lock);\n    HEAP_ARRAY_FREE(dcontext, tids, thread_id_t, num_threads, ACCT_THREAD_MGT, PROTECTED);\n\n    ASSERT(threads_to_signal >= threads_timed_out);\n    return (threads_to_signal - threads_timed_out) > 0;\n}\n\nbool\nos_thread_re_take_over(void)\n{\n#ifdef X86\n    /* i#2089: is_thread_initialized() will fail for a currently-native app.\n     * We bypass the magic field checks here of is_thread_tls_initialized().\n     * XXX: should this be inside is_thread_initialized()?  But that may mislead\n     * other callers: the caller has to restore the TLs.  Some old code also\n     * used get_thread_private_dcontext() being NULL to indicate an unknown thread:\n     * that should also call here.\n     */\n    if (!is_thread_initialized() && is_thread_tls_allocated()) {\n        /* It's safe to call thread_lookup() for ourself. */\n        thread_record_t *tr = thread_lookup(get_sys_thread_id());\n        if (tr != NULL) {\n            ASSERT(is_thread_currently_native(tr));\n            LOG(GLOBAL, LOG_THREADS, 1, \"\\tretakeover for cur-native thread \" TIDFMT \"\\n\",\n                get_sys_thread_id());\n            LOG(tr->dcontext->logfile, LOG_THREADS, 1,\n                \"\\nretakeover for cur-native thread \" TIDFMT \"\\n\", get_sys_thread_id());\n            os_swap_dr_tls(tr->dcontext, false /*to dr*/);\n            ASSERT(is_thread_initialized());\n            return true;\n        }\n    }\n#endif\n    return false;\n}\n\nstatic void\nos_thread_signal_taken_over(void)\n{\n    thread_id_t mytid;\n    event_t event = NULL;\n    uint i;\n    /* Wake up the thread that initiated the take over. */\n    mytid = d_r_get_thread_id();\n    ASSERT(thread_takeover_records != NULL);\n    for (i = 0; i < num_thread_takeover_records; i++) {\n        if (thread_takeover_records[i].tid == mytid) {\n            event = thread_takeover_records[i].event;\n            break;\n        }\n    }\n    ASSERT_MESSAGE(CHKLVL_ASSERTS, \"mytid not present in takeover records!\",\n                   event != NULL);\n    signal_event(event);\n}\n\n/* Takes over the current thread from the signal handler.  We notify the thread\n * that signaled us by signalling our event in thread_takeover_records.\n * If it returns, it returns false, and the thread should be let go.\n */\nbool\nos_thread_take_over(priv_mcontext_t *mc, kernel_sigset_t *sigset)\n{\n    dcontext_t *dcontext;\n    priv_mcontext_t *dc_mc;\n\n    LOG(GLOBAL, LOG_THREADS, 1, \"TAKEOVER: received signal in thread \" TIDFMT \"\\n\",\n        get_sys_thread_id());\n\n    /* Do standard DR thread initialization.  Mirrors code in\n     * create_clone_record and new_thread_setup, except we're not putting a\n     * clone record on the dstack.\n     */\n    os_thread_re_take_over();\n    if (!is_thread_initialized()) {\n        /* If this is a thread on its way to init, don't self-interp (i#2688). */\n        if (is_dynamo_address(mc->pc)) {\n            os_thread_signal_taken_over();\n            return false;\n        }\n        dcontext = init_thread_with_shared_siginfo(mc, takeover_dcontext);\n        ASSERT(dcontext != NULL);\n    } else {\n        /* Re-takeover a thread that we let go native */\n        dcontext = get_thread_private_dcontext();\n        ASSERT(dcontext != NULL);\n    }\n    signal_set_mask(dcontext, sigset);\n    signal_swap_mask(dcontext, true /*to app*/);\n    dynamo_thread_under_dynamo(dcontext);\n    dc_mc = get_mcontext(dcontext);\n    *dc_mc = *mc;\n    dcontext->whereami = DR_WHERE_APP;\n    dcontext->next_tag = mc->pc;\n\n    os_thread_signal_taken_over();\n\n    DOLOG(2, LOG_TOP, {\n        byte *cur_esp;\n        GET_STACK_PTR(cur_esp);\n        LOG(THREAD, LOG_TOP, 2,\n            \"%s: next_tag=\" PFX \", cur xsp=\" PFX \", mc->xsp=\" PFX \"\\n\", __FUNCTION__,\n            dcontext->next_tag, cur_esp, mc->xsp);\n    });\n#ifdef LINUX\n    /* See whether we should initiate lazy rseq handling, and avoid treating\n     * regions as rseq when the rseq syscall is never set up.\n     */\n    if (rseq_is_registered_for_current_thread()) {\n        rseq_locate_rseq_regions();\n        rseq_thread_attach(dcontext);\n    }\n#endif\n\n    /* Start interpreting from the signal context. */\n    call_switch_stack(dcontext, dcontext->dstack, (void (*)(void *))d_r_dispatch,\n                      NULL /*not on d_r_initstack*/, false /*shouldn't return*/);\n    ASSERT_NOT_REACHED();\n    return true; /* make compiler happy */\n}\n\nbool\nos_thread_take_over_suspended_native(dcontext_t *dcontext)\n{\n    os_thread_data_t *ostd = (os_thread_data_t *)dcontext->os_field;\n    if (!is_thread_currently_native(dcontext->thread_record) ||\n        ksynch_get_value(&ostd->suspended) < 0)\n        return false;\n    /* Thread is sitting in suspend signal loop so we just set a flag\n     * for when it resumes:\n     */\n    /* XXX: there's no event for a client to trigger this on so not yet\n     * tested.  i#721 may help.\n     */\n    ASSERT_NOT_TESTED();\n    ostd->retakeover = true;\n    return true;\n}\n\n/* Called for os-specific takeover of a secondary thread from the one\n * that called dr_app_setup().\n */\ndcontext_t *\nos_thread_take_over_secondary(priv_mcontext_t *mc)\n{\n    thread_record_t **list;\n    int num_threads;\n    int i;\n    dcontext_t *dcontext;\n    /* We want to share with the thread that called dr_app_setup. */\n    d_r_mutex_lock(&thread_initexit_lock);\n    get_list_of_threads(&list, &num_threads);\n    ASSERT(num_threads >= 1);\n    for (i = 0; i < num_threads; i++) {\n        /* Find a thread that's already set up */\n        if (is_thread_signal_info_initialized(list[i]->dcontext))\n            break;\n    }\n    ASSERT(i < num_threads);\n    ASSERT(list[i]->id != get_sys_thread_id());\n    /* Assuming pthreads, prepare signal_field for sharing. */\n    handle_clone(list[i]->dcontext, PTHREAD_CLONE_FLAGS);\n    dcontext = init_thread_with_shared_siginfo(mc, list[i]->dcontext);\n    d_r_mutex_unlock(&thread_initexit_lock);\n    global_heap_free(list,\n                     num_threads * sizeof(thread_record_t *) HEAPACCT(ACCT_THREAD_MGT));\n    return dcontext;\n}\n\n/***************************************************************************/\n\nuint\nos_random_seed(void)\n{\n    uint seed;\n    /* reading from /dev/urandom for a non-blocking random */\n    int urand = os_open(\"/dev/urandom\", OS_OPEN_READ);\n    DEBUG_DECLARE(int read =) os_read(urand, &seed, sizeof(seed));\n    ASSERT(read == sizeof(seed));\n    os_close(urand);\n\n    return seed;\n}\n\n#ifdef RCT_IND_BRANCH\n/* Analyze a range in a possibly new module\n * return false if not a code section in a module\n * otherwise returns true and adds all valid targets for rct_ind_branch_check\n */\nbool\nrct_analyze_module_at_violation(dcontext_t *dcontext, app_pc target_pc)\n{\n    /* FIXME: note that this will NOT find the data section corresponding to the given PC\n     * we don't yet have a corresponding get_allocation_size or an ELF header walk routine\n     * on linux\n     */\n    app_pc code_start;\n    size_t code_size;\n    uint prot;\n\n    if (!get_memory_info(target_pc, &code_start, &code_size, &prot))\n        return false;\n    /* TODO: in almost all cases expect the region at module_base+module_size to be\n     * the corresponding data section.\n     * Writable yet initialized data indeed needs to be processed.\n     */\n\n    if (code_size > 0) {\n        app_pc code_end = code_start + code_size;\n\n        app_pc data_start;\n        size_t data_size;\n\n        ASSERT(TESTALL(MEMPROT_READ | MEMPROT_EXEC, prot)); /* code */\n\n        if (!get_memory_info(code_end, &data_start, &data_size, &prot))\n            return false;\n\n        ASSERT(data_start == code_end);\n        ASSERT(TESTALL(MEMPROT_READ | MEMPROT_WRITE, prot)); /* data */\n\n        app_pc text_start = code_start;\n        app_pc text_end = data_start + data_size;\n\n        /* TODO: performance: do this only in case relocation info is not present */\n        DEBUG_DECLARE(uint found =)\n        find_address_references(dcontext, text_start, text_end, code_start, code_end);\n        LOG(GLOBAL, LOG_RCT, 2, PFX \"-\" PFX \" : %d ind targets of %d code size\",\n            text_start, text_end, found, code_size);\n        return true;\n    }\n    return false;\n}\n\n#    ifdef X64\nbool\nrct_add_rip_rel_addr(dcontext_t *dcontext, app_pc tgt _IF_DEBUG(app_pc src))\n{\n    /* FIXME PR 276762: not implemented */\n    return false;\n}\n#    endif\n#endif /* RCT_IND_BRANCH */\n\n#ifdef HOT_PATCHING_INTERFACE\nvoid *\nget_drmarker_hotp_policy_status_table()\n{\n    ASSERT_NOT_IMPLEMENTED(false);\n    return NULL;\n}\n\nvoid\nset_drmarker_hotp_policy_status_table(void *new_table)\n{\n    ASSERT_NOT_IMPLEMENTED(false);\n}\n\nbyte *\nhook_text(byte *hook_code_buf, const app_pc image_addr, intercept_function_t hook_func,\n          const void *callee_arg, const after_intercept_action_t action_after,\n          const bool abort_if_hooked, const bool ignore_cti, byte **app_code_copy_p,\n          byte **alt_exit_tgt_p)\n{\n    ASSERT_NOT_IMPLEMENTED(false);\n    return NULL;\n}\n\nvoid\nunhook_text(byte *hook_code_buf, app_pc image_addr)\n{\n    ASSERT_NOT_IMPLEMENTED(false);\n}\n\nvoid\ninsert_jmp_at_tramp_entry(dcontext_t *dcontext, byte *trampoline, byte *target)\n{\n    ASSERT_NOT_IMPLEMENTED(false);\n}\n#endif /* HOT_PATCHING_INTERFACE */\n\nbool\naslr_is_possible_attack(app_pc target)\n{\n    /* FIXME: ASLR not implemented */\n    return false;\n}\n\napp_pc\naslr_possible_preferred_address(app_pc target_addr)\n{\n    /* FIXME: ASLR not implemented */\n    return NULL;\n}\n\nvoid\ntake_over_primary_thread()\n{\n    /* nothing to do here */\n}\n\nbool\nos_current_user_directory(char *directory_prefix /* INOUT */, uint directory_len,\n                          bool create)\n{\n    /* XXX: could share some of this code w/ corresponding windows routine */\n    uid_t uid = dynamorio_syscall(SYS_getuid, 0);\n    char *directory = directory_prefix;\n    char *dirend = directory_prefix + strlen(directory_prefix);\n    snprintf(dirend, directory_len - (dirend - directory_prefix), \"%cdpc-%d\", DIRSEP,\n             uid);\n    directory_prefix[directory_len - 1] = '\\0';\n    if (!os_file_exists(directory, true /*is dir*/) && create) {\n        /* XXX: we should ensure we do not follow symlinks */\n        /* XXX: should add support for CREATE_DIR_FORCE_OWNER */\n        if (!os_create_dir(directory, CREATE_DIR_REQUIRE_NEW)) {\n            LOG(GLOBAL, LOG_CACHE, 2, \"\\terror creating per-user dir %s\\n\", directory);\n            return false;\n        } else {\n            LOG(GLOBAL, LOG_CACHE, 2, \"\\tcreated per-user dir %s\\n\", directory);\n        }\n    }\n    return true;\n}\n\nbool\nos_validate_user_owned(file_t file_or_directory_handle)\n{\n    /* note on Linux this scheme should never be used */\n    ASSERT(false && \"chown Alice evilfile\");\n    return false;\n}\n\nbool\nos_check_option_compatibility(void)\n{\n    /* no options are Linux OS version dependent */\n    return false;\n}\n\n#ifdef X86_32\n/* Emulate uint64 modulo and division by uint32 on ia32.\n * XXX: Does *not* handle 64-bit divisors!\n */\nstatic uint64\nuint64_divmod(uint64 dividend, uint64 divisor64, uint32 *remainder)\n{\n    /* Assumes little endian, which x86 is. */\n    union {\n        uint64 v64;\n        struct {\n            uint32 lo;\n            uint32 hi;\n        };\n    } res;\n    uint32 upper;\n    uint32 divisor = (uint32)divisor64;\n\n    /* Our uses don't use large divisors. */\n    ASSERT(divisor64 <= UINT_MAX && \"divisor is larger than uint32 can hold\");\n\n    /* Divide out the high bits first. */\n    res.v64 = dividend;\n    upper = res.hi;\n    res.hi = upper / divisor;\n    upper %= divisor;\n\n    /* Use the unsigned div instruction, which uses EDX:EAX to form a 64-bit\n     * dividend.  We only get a 32-bit quotient out, which is why we divide out\n     * the high bits first.  The quotient will fit in EAX.\n     *\n     * DIV r/m32    F7 /6  Unsigned divide EDX:EAX by r/m32, with result stored\n     *                     in EAX <- Quotient, EDX <- Remainder.\n     * inputs:\n     *   EAX = res.lo\n     *   EDX = upper\n     *   rm = divisor\n     * outputs:\n     *   res.lo = EAX\n     *   *remainder = EDX\n     * The outputs precede the inputs in gcc inline asm syntax, and so to put\n     * inputs in EAX and EDX we use \"0\" and \"1\".\n     */\n    asm(\"divl %2\"\n        : \"=a\"(res.lo), \"=d\"(*remainder)\n        : \"rm\"(divisor), \"0\"(res.lo), \"1\"(upper));\n    return res.v64;\n}\n\n/* Match libgcc's prototype. */\nuint64\n__udivdi3(uint64 dividend, uint64 divisor)\n{\n    uint32 remainder;\n    return uint64_divmod(dividend, divisor, &remainder);\n}\n\n/* Match libgcc's prototype. */\nuint64\n__umoddi3(uint64 dividend, uint64 divisor)\n{\n    uint32 remainder;\n    uint64_divmod(dividend, divisor, &remainder);\n    return (uint64)remainder;\n}\n\n/* Same thing for signed. */\nstatic int64\nint64_divmod(int64 dividend, int64 divisor64, int *remainder)\n{\n    union {\n        int64 v64;\n        struct {\n            int lo;\n            int hi;\n        };\n    } res;\n    int upper;\n    int divisor = (int)divisor64;\n\n    /* Our uses don't use large divisors. */\n    ASSERT(divisor64 <= INT_MAX && divisor64 >= INT_MIN && \"divisor too large for int\");\n\n    /* Divide out the high bits first. */\n    res.v64 = dividend;\n    upper = res.hi;\n    res.hi = upper / divisor;\n    upper %= divisor;\n\n    /* Like above but with the signed div instruction, which does a signed divide\n     * on edx:eax by r/m32 => quotient in eax, remainder in edx.\n     */\n    asm(\"idivl %2\"\n        : \"=a\"(res.lo), \"=d\"(*remainder)\n        : \"rm\"(divisor), \"0\"(res.lo), \"1\"(upper));\n    return res.v64;\n}\n\n/* Match libgcc's prototype. */\nint64\n__divdi3(int64 dividend, int64 divisor)\n{\n    int remainder;\n    return int64_divmod(dividend, divisor, &remainder);\n}\n\n/* __moddi3 is coming from third_party/libgcc for x86 as well as arm. */\n\n#elif defined(ARM)\n/* i#1566: for ARM, __aeabi versions are used instead of udivdi3 and umoddi3.\n * We link with __aeabi routines from libgcc via third_party/libgcc.\n */\n#endif /* X86_32 */\n\n/****************************************************************************\n * Tests\n */\n\n#if defined(STANDALONE_UNIT_TEST)\n\nvoid\ntest_uint64_divmod(void)\n{\n#    ifdef X86_32\n    uint64 quotient;\n    uint32 remainder;\n\n    /* Simple division below 2^32. */\n    quotient = uint64_divmod(9, 3, &remainder);\n    EXPECT(quotient == 3, true);\n    EXPECT(remainder == 0, true);\n    quotient = uint64_divmod(10, 3, &remainder);\n    EXPECT(quotient == 3, true);\n    EXPECT(remainder == 1, true);\n\n    /* Division when upper bits are less than the divisor. */\n    quotient = uint64_divmod(45ULL << 31, 1U << 31, &remainder);\n    EXPECT(quotient == 45, true);\n    EXPECT(remainder == 0, true);\n\n    /* Division when upper bits are greater than the divisor. */\n    quotient = uint64_divmod(45ULL << 32, 15, &remainder);\n    EXPECT(quotient == 3ULL << 32, true);\n    EXPECT(remainder == 0, true);\n    quotient = uint64_divmod((45ULL << 32) + 13, 15, &remainder);\n    EXPECT(quotient == 3ULL << 32, true);\n    EXPECT(remainder == 13, true);\n\n    /* Try calling the intrinsics.  Don't divide by powers of two, gcc will\n     * lower that to a shift.\n     */\n    quotient = (45ULL << 32);\n    quotient /= 15;\n    EXPECT(quotient == (3ULL << 32), true);\n    quotient = (45ULL << 32) + 13;\n    remainder = quotient % 15;\n    EXPECT(remainder == 13, true);\n#    endif /* X86_32 */\n}\n\nvoid\nunit_test_os(void)\n{\n    test_uint64_divmod();\n}\n\n#endif /* STANDALONE_UNIT_TEST */\n", "idx": 1, "id": 25793, "msg": "Convention is to use TEST", "proj": "DynamoRIO-dynamorio", "lang": "c"}
{"patch": "@@ -202,6 +202,12 @@ public class JavaContextCommon {\n \n     public abstract String getReturnType();\n \n+    public String getGenericAwareReturnType() {\n+      String returnType = getReturnType();\n+      if (returnType == null || returnType.isEmpty()) return \"Void\";\n+      else return returnType;\n+    }\n+\n     public abstract ImmutableList<Variable> getParams();\n \n     public abstract ImmutableList<Variable> getRequiredParams();", "y": 1, "oldf": "/* Copyright 2016 Google Inc\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.google.api.codegen.java;\n\nimport com.google.api.codegen.CollectionConfig;\nimport com.google.api.codegen.LanguageUtil;\nimport com.google.api.tools.framework.model.Field;\nimport com.google.api.tools.framework.model.Interface;\nimport com.google.api.tools.framework.model.TypeRef;\nimport com.google.auto.value.AutoValue;\nimport com.google.common.base.Splitter;\nimport com.google.common.collect.BiMap;\nimport com.google.common.collect.HashBiMap;\nimport com.google.common.collect.ImmutableList;\nimport com.google.common.collect.ImmutableMap;\nimport com.google.common.collect.Maps;\nimport com.google.common.escape.Escaper;\nimport com.google.common.escape.Escapers;\n\nimport java.util.ArrayList;\nimport java.util.Collections;\nimport java.util.List;\nimport java.util.Map;\n\nimport javax.annotation.Nullable;\n\n/**\n * A class that provides helper methods for snippet files generating Java code to get data and\n * perform data transformations that are difficult or messy to do in the snippets themselves.\n */\npublic class JavaContextCommon {\n\n  /**\n   * A regexp to match types from java.lang. Assumes well-formed qualified type names.\n   */\n  private static final String JAVA_LANG_TYPE_PREFIX = \"java.lang.\";\n\n  /**\n   * Escaper for formatting javadoc strings.\n   */\n  private static final Escaper JAVADOC_ESCAPER =\n      Escapers.builder()\n          .addEscape('&', \"&amp;\")\n          .addEscape('<', \"&lt;\")\n          .addEscape('>', \"&gt;\")\n          .addEscape('*', \"&ast;\")\n          .build();\n\n  /**\n   * A map from unboxed Java primitive type name to boxed counterpart.\n   */\n  private static final ImmutableMap<String, String> BOXED_TYPE_MAP =\n      ImmutableMap.<String, String>builder()\n          .put(\"boolean\", \"Boolean\")\n          .put(\"int\", \"Integer\")\n          .put(\"long\", \"Long\")\n          .put(\"float\", \"Float\")\n          .put(\"double\", \"Double\")\n          .build();\n\n  /**\n   * A bi-map from full names to short names indicating the import map.\n   */\n  private final BiMap<String, String> imports = HashBiMap.create();\n\n  /**\n   * A map from simple type name to a boolean, indicating whether its in java.lang or not. If a\n   * simple type name is not in the map, this information is unknown.\n   */\n  private final Map<String, Boolean> implicitImports = Maps.newHashMap();\n\n  private final String defaultPackagePrefix;\n\n  public JavaContextCommon(String defaultPackagePrefix) {\n    this.defaultPackagePrefix = defaultPackagePrefix;\n  }\n\n  /**\n   * Returns the Java representation of a basic type in boxed form.\n   */\n  public String boxedTypeName(String typeName) {\n    return LanguageUtil.getRename(typeName, BOXED_TYPE_MAP);\n  }\n\n  public String getMinimallyQualifiedName(String fullName, String shortName) {\n    // Derive a short name if possible\n    if (imports.containsKey(fullName)) {\n      // Short name already there.\n      return imports.get(fullName);\n    }\n    if (imports.containsValue(shortName)\n        || !fullName.startsWith(JAVA_LANG_TYPE_PREFIX) && isImplicitImport(shortName)) {\n      // Short name clashes, use long name.\n      return fullName;\n    }\n    imports.put(fullName, shortName);\n    return shortName;\n  }\n\n  /**\n   * Checks whether the simple type name is implicitly imported from java.lang.\n   */\n  private boolean isImplicitImport(String name) {\n    Boolean yes = implicitImports.get(name);\n    if (yes != null) {\n      return yes;\n    }\n    // Use reflection to determine whether the name exists in java.lang.\n    try {\n      Class.forName(\"java.lang.\" + name);\n      yes = true;\n    } catch (Exception e) {\n      yes = false;\n    }\n    implicitImports.put(name, yes);\n    return yes;\n  }\n\n  /**\n   * Splits given text into lines and returns an iterable of strings each one representing a line\n   * decorated for a javadoc documentation comment. Markdown will be translated to javadoc.\n   */\n  public Iterable<String> getJavaDocLines(String text) {\n    return getJavaDocLinesWithPrefix(text, \"\");\n  }\n\n  /**\n   * Splits given text into lines and returns an iterable of strings each one representing a line\n   * decorated for a javadoc documentation comment, with the first line prefixed with\n   * firstLinePrefix. Markdown will be translated to javadoc.\n   */\n  public Iterable<String> getJavaDocLinesWithPrefix(String text, String firstLinePrefix) {\n    // TODO(wgg): convert markdown to javadoc\n    List<String> result = new ArrayList<>();\n    String linePrefix = firstLinePrefix;\n    text = JAVADOC_ESCAPER.escape(text);\n    for (String line : Splitter.on(String.format(\"%n\")).split(text)) {\n      result.add(\" * \" + linePrefix + line);\n      linePrefix = \"\";\n    }\n    return result;\n  }\n\n  @AutoValue\n  abstract static class Variable {\n    public abstract TypeRef getType();\n\n    public abstract String getUnformattedName();\n\n    public abstract String getDescription();\n\n    public abstract String getName();\n\n    @Nullable\n    public abstract CollectionConfig getFormattingConfig();\n\n    // This function is necessary for use in snippets\n    public boolean hasFormattingConfig() {\n      return getFormattingConfig() != null;\n    }\n  }\n\n  // This member function is necessary to provide access to snippets for\n  // the functionality, since snippets can't call static functions.\n  public Variable newVariable(TypeRef type, String name, String description) {\n    return s_newVariable(type, name, description);\n  }\n\n  // This function is necessary to provide a static entry point for the same-named\n  // member function.\n  public static Variable s_newVariable(TypeRef type, String name, String description) {\n    return s_newVariable(type, name, description, name, null);\n  }\n\n  public static Variable s_newVariable(\n      TypeRef type,\n      String unformattedName,\n      String description,\n      String name,\n      CollectionConfig formattingConfig) {\n    return new AutoValue_JavaContextCommon_Variable(\n        type, unformattedName, description, name, formattingConfig);\n  }\n\n  @AutoValue\n  abstract static class JavaDocConfig {\n    public abstract String getApiName();\n\n    public abstract String getMethodName();\n\n    public abstract String getReturnType();\n\n    public abstract ImmutableList<Variable> getParams();\n\n    public abstract ImmutableList<Variable> getRequiredParams();\n\n    public abstract boolean isPagedVariant();\n\n    public abstract boolean isCallableVariant();\n\n    @AutoValue.Builder\n    abstract static class Builder {\n      public abstract Builder setApiName(String serviceName);\n\n      public abstract Builder setMethodName(String methodName);\n\n      public abstract Builder setReturnType(String returnType);\n\n      public abstract Builder setParams(ImmutableList<Variable> params);\n\n      public Builder setParams(JavaGapicContext context, Iterable<Field> fields) {\n        return setParams(fieldsToParams(context, fields));\n      }\n\n      public Builder setParamsWithFormatting(\n          JavaGapicContext context,\n          Interface service,\n          Iterable<Field> fields,\n          ImmutableMap<String, String> fieldNamePatterns) {\n        return setParams(fieldsToParamsWithFormatting(context, service, fields, fieldNamePatterns));\n      }\n\n      public Builder setSingleParam(\n          JavaGapicContext context, TypeRef requestType, String name, String doc) {\n        return setParams(ImmutableList.of(s_newVariable(requestType, name, doc)));\n      }\n\n      public abstract Builder setRequiredParams(ImmutableList<Variable> params);\n\n      public Builder setRequiredParams(JavaGapicContext context, Iterable<Field> fields) {\n        return setRequiredParams(fieldsToParams(context, fields));\n      }\n\n      public Builder setRequiredParamsWithFormatting(\n          JavaGapicContext context,\n          Interface service,\n          Iterable<Field> fields,\n          ImmutableMap<String, String> fieldNamePatterns) {\n        return setRequiredParams(\n            fieldsToParamsWithFormatting(context, service, fields, fieldNamePatterns));\n      }\n\n      public Builder setRequiredParamsEmpty() {\n        return setRequiredParams(ImmutableList.<Variable>of());\n      }\n\n      public abstract Builder setPagedVariant(boolean paged);\n\n      public abstract Builder setCallableVariant(boolean callable);\n\n      public abstract JavaDocConfig build();\n\n      private static ImmutableList<Variable> fieldsToParams(\n          JavaGapicContext context, Iterable<Field> fields) {\n        ImmutableList.Builder<Variable> params = ImmutableList.<Variable>builder();\n        for (Field field : fields) {\n          params.add(\n              s_newVariable(\n                  field.getType(),\n                  LanguageUtil.lowerUnderscoreToLowerCamel(field.getSimpleName()),\n                  context.getDescription(field)));\n        }\n        return params.build();\n      }\n\n      private static ImmutableList<Variable> fieldsToParamsWithFormatting(\n          JavaGapicContext context,\n          Interface service,\n          Iterable<Field> fields,\n          ImmutableMap<String, String> fieldNamePatterns) {\n        ImmutableList.Builder<Variable> params = ImmutableList.<Variable>builder();\n        for (Field field : fields) {\n          if (fieldNamePatterns.containsKey(field.getSimpleName())) {\n            params.add(\n                s_newVariable(\n                    field.getType(),\n                    LanguageUtil.lowerUnderscoreToLowerCamel(field.getSimpleName()),\n                    context.getDescription(field),\n                    \"formatted\" + LanguageUtil.lowerUnderscoreToUpperCamel(field.getSimpleName()),\n                    context.getCollectionConfig(\n                        service, fieldNamePatterns.get(field.getSimpleName()))));\n          } else {\n            params.add(\n                s_newVariable(\n                    field.getType(),\n                    LanguageUtil.lowerUnderscoreToLowerCamel(field.getSimpleName()),\n                    context.getDescription(field)));\n          }\n        }\n        return params.build();\n      }\n    }\n  }\n\n  public JavaDocConfig.Builder newJavaDocConfigBuilder() {\n    return new AutoValue_JavaContextCommon_JavaDocConfig.Builder();\n  }\n\n  public boolean getTrue() {\n    return true;\n  }\n\n  public boolean getFalse() {\n    return false;\n  }\n\n  public String requestParamDoc() {\n    return \"The request object containing all of the parameters for the API call.\";\n  }\n\n  public String requestParam() {\n    return \"request\";\n  }\n\n  public List<String> getImports() {\n    // Clean up the imports.\n    List<String> cleanedImports = new ArrayList<>();\n    for (String imported : imports.keySet()) {\n      if (imported.startsWith(JAVA_LANG_TYPE_PREFIX)\n          || defaultPackagePrefix != null && imported.startsWith(defaultPackagePrefix)) {\n        // Imported type is in java.lang or in package, can be ignored.\n        continue;\n      }\n      cleanedImports.add(imported);\n    }\n    Collections.sort(cleanedImports);\n    return cleanedImports;\n  }\n}\n", "idx": 1, "id": 14902, "msg": "always use brackets for if statements", "proj": "googleapis-gapic-generator", "lang": "java"}
{"patch": "@@ -44,6 +44,10 @@ function UndoRedo(instance) {\n       return;\n     }\n \n+    arrayEach(changes, (change) => {\n+      change[1] = instance.propToCol(change[1]);\n+    });\n+\n     const selected = changesLen > 1 ? this.getSelected() : [[changes[0][0], changes[0][1]]];\n \n     plugin.done(new UndoRedo.ChangeAction(changes, selected));", "y": 1, "oldf": "/**\n * Handsontable UndoRedo class\n */\nimport Hooks from './../../pluginHooks';\nimport { arrayMap, arrayEach } from './../../helpers/array';\nimport { rangeEach } from './../../helpers/number';\nimport { inherit, deepClone } from './../../helpers/object';\nimport { stopImmediatePropagation, isImmediatePropagationStopped } from './../../helpers/dom/event';\nimport { align } from './../contextMenu/utils';\n\n/**\n * @description\n * Handsontable UndoRedo plugin allows to undo and redo certain actions done in the table.\n *\n * __Note__, that not all actions are currently undo-able. The UndoRedo plugin is enabled by default.\n *\n * @example\n * ```js\n * undo: true\n * ```\n * @class UndoRedo\n * @plugin UndoRedo\n */\nfunction UndoRedo(instance) {\n  const plugin = this;\n  this.instance = instance;\n  this.doneActions = [];\n  this.undoneActions = [];\n  this.ignoreNewActions = false;\n\n  instance.addHook('afterChange', function(changes, source) {\n    const changesLen = changes && changes.length;\n\n    if (!changesLen || ['UndoRedo.undo', 'UndoRedo.redo', 'MergeCells'].includes(source)) {\n      return;\n    }\n    const hasDifferences = changes.find((change) => {\n      const [,, oldValue, newValue] = change;\n\n      return oldValue !== newValue;\n    });\n\n    if (!hasDifferences) {\n      return;\n    }\n\n    const selected = changesLen > 1 ? this.getSelected() : [[changes[0][0], changes[0][1]]];\n\n    plugin.done(new UndoRedo.ChangeAction(changes, selected));\n  });\n\n  instance.addHook('afterCreateRow', (index, amount, source) => {\n    if (source === 'UndoRedo.undo' || source === 'UndoRedo.undo' || source === 'auto') {\n      return;\n    }\n\n    const action = new UndoRedo.CreateRowAction(index, amount);\n    plugin.done(action);\n  });\n\n  instance.addHook('beforeRemoveRow', (index, amount, logicRows, source) => {\n    if (source === 'UndoRedo.undo' || source === 'UndoRedo.redo' || source === 'auto') {\n      return;\n    }\n\n    const originalData = plugin.instance.getSourceDataArray();\n    const rowIndex = (originalData.length + index) % originalData.length;\n    const physicalRowIndex = instance.toPhysicalRow(rowIndex);\n    const removedData = deepClone(originalData.slice(physicalRowIndex, physicalRowIndex + amount));\n\n    plugin.done(new UndoRedo.RemoveRowAction(rowIndex, removedData));\n  });\n\n  instance.addHook('afterCreateCol', (index, amount, source) => {\n    if (source === 'UndoRedo.undo' || source === 'UndoRedo.redo' || source === 'auto') {\n      return;\n    }\n\n    plugin.done(new UndoRedo.CreateColumnAction(index, amount));\n  });\n\n  instance.addHook('beforeRemoveCol', (index, amount, logicColumns, source) => {\n    if (source === 'UndoRedo.undo' || source === 'UndoRedo.redo' || source === 'auto') {\n      return;\n    }\n\n    const originalData = plugin.instance.getSourceDataArray();\n    const columnIndex = (plugin.instance.countCols() + index) % plugin.instance.countCols();\n    const removedData = [];\n    const headers = [];\n    const indexes = [];\n\n    rangeEach(originalData.length - 1, (i) => {\n      const column = [];\n      const origRow = originalData[i];\n\n      rangeEach(columnIndex, columnIndex + (amount - 1), (j) => {\n        column.push(origRow[instance.runHooks('modifyCol', j)]);\n      });\n      removedData.push(column);\n    });\n\n    rangeEach(amount - 1, (i) => {\n      indexes.push(instance.runHooks('modifyCol', columnIndex + i));\n    });\n\n    if (Array.isArray(instance.getSettings().colHeaders)) {\n      rangeEach(amount - 1, (i) => {\n        headers.push(instance.getSettings().colHeaders[instance.runHooks('modifyCol', columnIndex + i)] || null);\n      });\n    }\n\n    const manualColumnMovePlugin = plugin.instance.getPlugin('manualColumnMove');\n    const columnsMap = manualColumnMovePlugin.isEnabled() ? manualColumnMovePlugin.columnsMapper.__arrayMap : [];\n    const action = new UndoRedo.RemoveColumnAction(columnIndex, indexes, removedData, headers, columnsMap);\n\n    plugin.done(action);\n  });\n\n  instance.addHook('beforeCellAlignment', (stateBefore, range, type, alignment) => {\n    const action = new UndoRedo.CellAlignmentAction(stateBefore, range, type, alignment);\n    plugin.done(action);\n  });\n\n  instance.addHook('beforeFilter', (conditionsStack) => {\n    plugin.done(new UndoRedo.FiltersAction(conditionsStack));\n  });\n\n  instance.addHook('beforeRowMove', (movedRows, target) => {\n    if (movedRows === false) {\n      return;\n    }\n\n    plugin.done(new UndoRedo.RowMoveAction(movedRows, target));\n  });\n\n  instance.addHook('beforeMergeCells', (cellRange, auto) => {\n    if (auto) {\n      return;\n    }\n\n    plugin.done(new UndoRedo.MergeCellsAction(instance, cellRange));\n  });\n\n  instance.addHook('afterUnmergeCells', (cellRange, auto) => {\n    if (auto) {\n      return;\n    }\n\n    plugin.done(new UndoRedo.UnmergeCellsAction(instance, cellRange));\n  });\n\n}\n\nUndoRedo.prototype.done = function(action) {\n  if (!this.ignoreNewActions) {\n    this.doneActions.push(action);\n    this.undoneActions.length = 0;\n  }\n};\n\n/**\n * Undo the last action performed to the table.\n *\n * @function undo\n * @memberof UndoRedo#\n * @fires Hooks#beforeUndo\n * @fires Hooks#afterUndo\n */\nUndoRedo.prototype.undo = function() {\n  if (this.isUndoAvailable()) {\n    const action = this.doneActions.pop();\n    const actionClone = deepClone(action);\n    const instance = this.instance;\n\n    const continueAction = instance.runHooks('beforeUndo', actionClone);\n\n    if (continueAction === false) {\n      return;\n    }\n\n    this.ignoreNewActions = true;\n    const that = this;\n    action.undo(this.instance, () => {\n      that.ignoreNewActions = false;\n      that.undoneActions.push(action);\n    });\n\n    instance.runHooks('afterUndo', actionClone);\n  }\n};\n\n/**\n * Redo the previous action performed to the table (used to reverse an undo).\n *\n * @function redo\n * @memberof UndoRedo#\n * @fires Hooks#beforeRedo\n * @fires Hooks#afterRedo\n */\nUndoRedo.prototype.redo = function() {\n  if (this.isRedoAvailable()) {\n    const action = this.undoneActions.pop();\n    const actionClone = deepClone(action);\n    const instance = this.instance;\n\n    const continueAction = instance.runHooks('beforeRedo', actionClone);\n\n    if (continueAction === false) {\n      return;\n    }\n\n    this.ignoreNewActions = true;\n    const that = this;\n    action.redo(this.instance, () => {\n      that.ignoreNewActions = false;\n      that.doneActions.push(action);\n    });\n\n    instance.runHooks('afterRedo', actionClone);\n  }\n};\n\n/**\n * Checks if undo action is available.\n *\n * @function isUndoAvailable\n * @memberof UndoRedo#\n * @return {Boolean} Return `true` if undo can be performed, `false` otherwise.\n */\nUndoRedo.prototype.isUndoAvailable = function() {\n  return this.doneActions.length > 0;\n};\n\n/**\n * Checks if redo action is available.\n *\n * @function isRedoAvailable\n * @memberof UndoRedo#\n * @return {Boolean} Return `true` if redo can be performed, `false` otherwise.\n */\nUndoRedo.prototype.isRedoAvailable = function() {\n  return this.undoneActions.length > 0;\n};\n\n/**\n * Clears undo history.\n *\n * @function clear\n * @memberof UndoRedo#\n */\nUndoRedo.prototype.clear = function() {\n  this.doneActions.length = 0;\n  this.undoneActions.length = 0;\n};\n\nUndoRedo.Action = function() {};\nUndoRedo.Action.prototype.undo = function() {};\nUndoRedo.Action.prototype.redo = function() {};\n\n/**\n * Change action.\n *\n * @private\n */\nUndoRedo.ChangeAction = function(changes, selected) {\n  this.changes = changes;\n  this.selected = selected;\n  this.actionType = 'change';\n};\ninherit(UndoRedo.ChangeAction, UndoRedo.Action);\n\nUndoRedo.ChangeAction.prototype.undo = function(instance, undoneCallback) {\n  const data = deepClone(this.changes);\n  const emptyRowsAtTheEnd = instance.countEmptyRows(true);\n  const emptyColsAtTheEnd = instance.countEmptyCols(true);\n\n  for (let i = 0, len = data.length; i < len; i++) {\n    data[i].splice(3, 1);\n  }\n\n  instance.addHookOnce('afterChange', undoneCallback);\n\n  instance.setDataAtRowProp(data, null, null, 'UndoRedo.undo');\n\n  for (let i = 0, len = data.length; i < len; i++) {\n    const [row, column] = data[i];\n\n    if (instance.getSettings().minSpareRows && row + 1 + instance.getSettings().minSpareRows === instance.countRows() &&\n      emptyRowsAtTheEnd === instance.getSettings().minSpareRows) {\n\n      instance.alter('remove_row', parseInt(row + 1, 10), instance.getSettings().minSpareRows);\n      instance.undoRedo.doneActions.pop();\n    }\n\n    if (instance.getSettings().minSpareCols && column + 1 + instance.getSettings().minSpareCols === instance.countCols() &&\n      emptyColsAtTheEnd === instance.getSettings().minSpareCols) {\n\n      instance.alter('remove_col', parseInt(column + 1, 10), instance.getSettings().minSpareCols);\n      instance.undoRedo.doneActions.pop();\n    }\n  }\n\n  instance.selectCells(this.selected, false, false);\n};\nUndoRedo.ChangeAction.prototype.redo = function(instance, onFinishCallback) {\n  const data = deepClone(this.changes);\n\n  for (let i = 0, len = data.length; i < len; i++) {\n    data[i].splice(2, 1);\n  }\n\n  instance.addHookOnce('afterChange', onFinishCallback);\n  instance.setDataAtRowProp(data, null, null, 'UndoRedo.redo');\n\n  if (this.selected) {\n    instance.selectCells(this.selected, false, false);\n  }\n};\n\n/**\n * Create row action.\n *\n * @private\n */\nUndoRedo.CreateRowAction = function(index, amount) {\n  this.index = index;\n  this.amount = amount;\n  this.actionType = 'insert_row';\n};\ninherit(UndoRedo.CreateRowAction, UndoRedo.Action);\n\nUndoRedo.CreateRowAction.prototype.undo = function(instance, undoneCallback) {\n  const rowCount = instance.countRows();\n  const minSpareRows = instance.getSettings().minSpareRows;\n\n  if (this.index >= rowCount && this.index - minSpareRows < rowCount) {\n    this.index -= minSpareRows; // work around the situation where the needed row was removed due to an 'undo' of a made change\n  }\n\n  instance.addHookOnce('afterRemoveRow', undoneCallback);\n  instance.alter('remove_row', this.index, this.amount, 'UndoRedo.undo');\n};\nUndoRedo.CreateRowAction.prototype.redo = function(instance, redoneCallback) {\n  instance.addHookOnce('afterCreateRow', redoneCallback);\n  instance.alter('insert_row', this.index, this.amount, 'UndoRedo.redo');\n};\n\n/**\n * Remove row action.\n *\n * @private\n */\nUndoRedo.RemoveRowAction = function(index, data) {\n  this.index = index;\n  this.data = data;\n  this.actionType = 'remove_row';\n};\ninherit(UndoRedo.RemoveRowAction, UndoRedo.Action);\n\nUndoRedo.RemoveRowAction.prototype.undo = function(instance, undoneCallback) {\n  instance.alter('insert_row', this.index, this.data.length, 'UndoRedo.undo');\n  instance.addHookOnce('afterRender', undoneCallback);\n  instance.populateFromArray(this.index, 0, this.data, void 0, void 0, 'UndoRedo.undo');\n};\nUndoRedo.RemoveRowAction.prototype.redo = function(instance, redoneCallback) {\n  instance.addHookOnce('afterRemoveRow', redoneCallback);\n  instance.alter('remove_row', this.index, this.data.length, 'UndoRedo.redo');\n};\n\n/**\n * Create column action.\n *\n * @private\n */\nUndoRedo.CreateColumnAction = function(index, amount) {\n  this.index = index;\n  this.amount = amount;\n  this.actionType = 'insert_col';\n};\ninherit(UndoRedo.CreateColumnAction, UndoRedo.Action);\n\nUndoRedo.CreateColumnAction.prototype.undo = function(instance, undoneCallback) {\n  instance.addHookOnce('afterRemoveCol', undoneCallback);\n  instance.alter('remove_col', this.index, this.amount, 'UndoRedo.undo');\n};\nUndoRedo.CreateColumnAction.prototype.redo = function(instance, redoneCallback) {\n  instance.addHookOnce('afterCreateCol', redoneCallback);\n  instance.alter('insert_col', this.index, this.amount, 'UndoRedo.redo');\n};\n\n/**\n * Remove column action.\n *\n * @private\n */\nUndoRedo.RemoveColumnAction = function(index, indexes, data, headers, columnPositions) {\n  this.index = index;\n  this.indexes = indexes;\n  this.data = data;\n  this.amount = this.data[0].length;\n  this.headers = headers;\n  this.columnPositions = columnPositions.slice(0);\n  this.actionType = 'remove_col';\n};\ninherit(UndoRedo.RemoveColumnAction, UndoRedo.Action);\n\nUndoRedo.RemoveColumnAction.prototype.undo = function(instance, undoneCallback) {\n  let row;\n  const ascendingIndexes = this.indexes.slice(0).sort();\n  const sortByIndexes = (elem, j, arr) => arr[this.indexes.indexOf(ascendingIndexes[j])];\n\n  const sortedData = [];\n  rangeEach(this.data.length - 1, (i) => {\n    sortedData[i] = arrayMap(this.data[i], sortByIndexes);\n  });\n\n  let sortedHeaders = [];\n  sortedHeaders = arrayMap(this.headers, sortByIndexes);\n\n  const changes = [];\n\n  // TODO: Temporary hook for undo/redo mess\n  instance.runHooks('beforeCreateCol', this.indexes[0], this.indexes.length, 'UndoRedo.undo');\n\n  rangeEach(this.data.length - 1, (i) => {\n    row = instance.getSourceDataAtRow(i);\n\n    rangeEach(ascendingIndexes.length - 1, (j) => {\n      row.splice(ascendingIndexes[j], 0, sortedData[i][j]);\n      changes.push([i, ascendingIndexes[j], null, sortedData[i][j]]);\n    });\n  });\n\n  // TODO: Temporary hook for undo/redo mess\n  if (instance.getPlugin('formulas')) {\n    instance.getPlugin('formulas').onAfterSetDataAtCell(changes);\n  }\n\n  if (typeof this.headers !== 'undefined') {\n    rangeEach(sortedHeaders.length - 1, (j) => {\n      instance.getSettings().colHeaders.splice(ascendingIndexes[j], 0, sortedHeaders[j]);\n    });\n  }\n\n  if (instance.getPlugin('manualColumnMove')) {\n    instance.getPlugin('manualColumnMove').columnsMapper.__arrayMap = this.columnPositions;\n  }\n\n  instance.addHookOnce('afterRender', undoneCallback);\n\n  // TODO: Temporary hook for undo/redo mess\n  instance.runHooks('afterCreateCol', this.indexes[0], this.indexes.length, 'UndoRedo.undo');\n\n  if (instance.getPlugin('formulas')) {\n    instance.getPlugin('formulas').recalculateFull();\n  }\n\n  instance.render();\n};\n\nUndoRedo.RemoveColumnAction.prototype.redo = function(instance, redoneCallback) {\n  instance.addHookOnce('afterRemoveCol', redoneCallback);\n  instance.alter('remove_col', this.index, this.amount, 'UndoRedo.redo');\n};\n\n/**\n * Cell alignment action.\n *\n * @private\n */\nUndoRedo.CellAlignmentAction = function(stateBefore, range, type, alignment) {\n  this.stateBefore = stateBefore;\n  this.range = range;\n  this.type = type;\n  this.alignment = alignment;\n};\nUndoRedo.CellAlignmentAction.prototype.undo = function(instance, undoneCallback) {\n  arrayEach(this.range, ({ from, to }) => {\n    for (let row = from.row; row <= to.row; row += 1) {\n      for (let col = from.col; col <= to.col; col += 1) {\n        instance.setCellMeta(row, col, 'className', this.stateBefore[row][col] || ' htLeft');\n      }\n    }\n  });\n\n  instance.addHookOnce('afterRender', undoneCallback);\n  instance.render();\n};\nUndoRedo.CellAlignmentAction.prototype.redo = function(instance, undoneCallback) {\n  align(this.range, this.type, this.alignment, (row, col) => instance.getCellMeta(row, col),\n    (row, col, key, value) => instance.setCellMeta(row, col, key, value));\n\n  instance.addHookOnce('afterRender', undoneCallback);\n  instance.render();\n};\n\n/**\n * Filters action.\n *\n * @private\n */\nUndoRedo.FiltersAction = function(conditionsStack) {\n  this.conditionsStack = conditionsStack;\n  this.actionType = 'filter';\n};\ninherit(UndoRedo.FiltersAction, UndoRedo.Action);\n\nUndoRedo.FiltersAction.prototype.undo = function(instance, undoneCallback) {\n  const filters = instance.getPlugin('filters');\n\n  instance.addHookOnce('afterRender', undoneCallback);\n\n  filters.conditionCollection.importAllConditions(this.conditionsStack.slice(0, this.conditionsStack.length - 1));\n  filters.filter();\n};\nUndoRedo.FiltersAction.prototype.redo = function(instance, redoneCallback) {\n  const filters = instance.getPlugin('filters');\n\n  instance.addHookOnce('afterRender', redoneCallback);\n\n  filters.conditionCollection.importAllConditions(this.conditionsStack);\n  filters.filter();\n};\n\n/**\n * Merge Cells action.\n * @util\n */\nclass MergeCellsAction extends UndoRedo.Action {\n  constructor(instance, cellRange) {\n    super();\n    this.cellRange = cellRange;\n    this.rangeData = instance.getData(cellRange.from.row, cellRange.from.col, cellRange.to.row, cellRange.to.col);\n  }\n\n  undo(instance, undoneCallback) {\n    const mergeCellsPlugin = instance.getPlugin('mergeCells');\n    instance.addHookOnce('afterRender', undoneCallback);\n\n    mergeCellsPlugin.unmergeRange(this.cellRange, true);\n    instance.populateFromArray(this.cellRange.from.row, this.cellRange.from.col, this.rangeData, void 0, void 0, 'MergeCells');\n  }\n\n  redo(instance, redoneCallback) {\n    const mergeCellsPlugin = instance.getPlugin('mergeCells');\n    instance.addHookOnce('afterRender', redoneCallback);\n\n    mergeCellsPlugin.mergeRange(this.cellRange);\n  }\n}\nUndoRedo.MergeCellsAction = MergeCellsAction;\n\n/**\n * Unmerge Cells action.\n * @util\n */\nclass UnmergeCellsAction extends UndoRedo.Action {\n  constructor(instance, cellRange) {\n    super();\n    this.cellRange = cellRange;\n  }\n\n  undo(instance, undoneCallback) {\n    const mergeCellsPlugin = instance.getPlugin('mergeCells');\n    instance.addHookOnce('afterRender', undoneCallback);\n\n    mergeCellsPlugin.mergeRange(this.cellRange, true);\n  }\n\n  redo(instance, redoneCallback) {\n    const mergeCellsPlugin = instance.getPlugin('mergeCells');\n    instance.addHookOnce('afterRender', redoneCallback);\n\n    mergeCellsPlugin.unmergeRange(this.cellRange, true);\n    instance.render();\n  }\n}\nUndoRedo.UnmergeCellsAction = UnmergeCellsAction;\n\n/**\n * ManualRowMove action.\n *\n * @private\n * @TODO: removeRow undo should works on logical index\n */\nUndoRedo.RowMoveAction = function(movedRows, target) {\n  this.rows = movedRows.slice();\n  this.target = target;\n};\ninherit(UndoRedo.RowMoveAction, UndoRedo.Action);\n\nUndoRedo.RowMoveAction.prototype.undo = function(instance, undoneCallback) {\n  const manualRowMove = instance.getPlugin('manualRowMove');\n\n  instance.addHookOnce('afterRender', undoneCallback);\n\n  const mod = this.rows[0] < this.target ? -1 * this.rows.length : 0;\n  const newTarget = this.rows[0] > this.target ? this.rows[0] + this.rows.length : this.rows[0];\n  const newRows = [];\n  const rowsLen = this.rows.length + mod;\n\n  for (let i = mod; i < rowsLen; i += 1) {\n    newRows.push(this.target + i);\n  }\n\n  manualRowMove.moveRows(newRows.slice(), newTarget);\n  instance.render();\n\n  instance.selectCell(this.rows[0], 0, this.rows[this.rows.length - 1], instance.countCols() - 1, false, false);\n};\nUndoRedo.RowMoveAction.prototype.redo = function(instance, redoneCallback) {\n  const manualRowMove = instance.getPlugin('manualRowMove');\n\n  instance.addHookOnce('afterRender', redoneCallback);\n  manualRowMove.moveRows(this.rows.slice(), this.target);\n  instance.render();\n  const startSelection = this.rows[0] < this.target ? this.target - this.rows.length : this.target;\n\n  instance.selectCell(startSelection, 0, startSelection + this.rows.length - 1, instance.countCols() - 1, false, false);\n};\n\nfunction init() {\n  const instance = this;\n  const pluginEnabled = typeof instance.getSettings().undo === 'undefined' || instance.getSettings().undo;\n\n  if (pluginEnabled) {\n    if (!instance.undoRedo) {\n      /**\n       * Instance of Handsontable.UndoRedo Plugin {@link Handsontable.UndoRedo}\n       *\n       * @alias undoRedo\n       * @memberof! Handsontable.Core#\n       * @type {UndoRedo}\n       */\n      instance.undoRedo = new UndoRedo(instance);\n\n      exposeUndoRedoMethods(instance);\n\n      instance.addHook('beforeKeyDown', onBeforeKeyDown);\n      instance.addHook('afterChange', onAfterChange);\n    }\n  } else if (instance.undoRedo) {\n    delete instance.undoRedo;\n\n    removeExposedUndoRedoMethods(instance);\n\n    instance.removeHook('beforeKeyDown', onBeforeKeyDown);\n    instance.removeHook('afterChange', onAfterChange);\n  }\n}\n\nfunction onBeforeKeyDown(event) {\n  if (isImmediatePropagationStopped(event)) {\n    return;\n  }\n\n  const instance = this;\n  const editor = instance.getActiveEditor();\n\n  if (editor && editor.isOpened()) {\n    return;\n  }\n\n  const {\n    altKey,\n    ctrlKey,\n    keyCode,\n    metaKey,\n    shiftKey,\n  } = event;\n  const isCtrlDown = (ctrlKey || metaKey) && !altKey;\n\n  if (!isCtrlDown) {\n    return;\n  }\n\n  const isRedoHotkey = keyCode === 89 || (shiftKey && keyCode === 90);\n\n  if (isRedoHotkey) { // CTRL + Y or CTRL + SHIFT + Z\n    instance.undoRedo.redo();\n    stopImmediatePropagation(event);\n\n  } else if (keyCode === 90) { // CTRL + Z\n    instance.undoRedo.undo();\n    stopImmediatePropagation(event);\n  }\n}\n\nfunction onAfterChange(changes, source) {\n  const instance = this;\n  if (source === 'loadData') {\n    return instance.undoRedo.clear();\n  }\n}\n\nfunction exposeUndoRedoMethods(instance) {\n  /**\n   * {@link UndoRedo#undo}\n   * @alias undo\n   * @memberof! Handsontable.Core#\n   */\n  instance.undo = function() {\n    return instance.undoRedo.undo();\n  };\n\n  /**\n   * {@link UndoRedo#redo}\n   * @alias redo\n   * @memberof! Handsontable.Core#\n   */\n  instance.redo = function() {\n    return instance.undoRedo.redo();\n  };\n\n  /**\n   * {@link UndoRedo#isUndoAvailable}\n   * @alias isUndoAvailable\n   * @memberof! Handsontable.Core#\n   */\n  instance.isUndoAvailable = function() {\n    return instance.undoRedo.isUndoAvailable();\n  };\n\n  /**\n   * {@link UndoRedo#isRedoAvailable}\n   * @alias isRedoAvailable\n   * @memberof! Handsontable.Core#\n   */\n  instance.isRedoAvailable = function() {\n    return instance.undoRedo.isRedoAvailable();\n  };\n\n  /**\n   * {@link UndoRedo#clear}\n   * @alias clearUndo\n   * @memberof! Handsontable.Core#\n   */\n  instance.clearUndo = function() {\n    return instance.undoRedo.clear();\n  };\n}\n\nfunction removeExposedUndoRedoMethods(instance) {\n  delete instance.undo;\n  delete instance.redo;\n  delete instance.isUndoAvailable;\n  delete instance.isRedoAvailable;\n  delete instance.clearUndo;\n}\n\nconst hook = Hooks.getSingleton();\n\nhook.add('afterInit', init);\nhook.add('afterUpdateSettings', init);\n\nhook.register('beforeUndo');\nhook.register('afterUndo');\nhook.register('beforeRedo');\nhook.register('afterRedo');\n\nexport default UndoRedo;\n", "idx": 1, "id": 15930, "msg": "Changing `prop`=>`col` by reference?   I think you can prepare map `prop`=>`col` in L51.", "proj": "handsontable-handsontable", "lang": "js"}
{"patch": "@@ -129,6 +129,14 @@ public class Product implements Serializable {\n     private String nutritionDataPer;\n     @JsonProperty(\"no_nutrition_data\")\n     private String noNutritionData;\n+    @JsonProperty(\"other_information_fr\")\n+    private String otherInformation;\n+    @JsonProperty(\"conservation_conditions_fr\")\n+    private String conservationConditions;\n+    @JsonProperty(\"recycling_instructions_to_discard_fr\")\n+    private String recyclingInstructionsToDiscard;\n+    @JsonProperty(\"recycling_instructions_to_recycle_fr\")\n+    private String recyclingInstructionsToRecycle;\n     @JsonProperty(\"warning\")\n     private String warning;\n     @JsonProperty(\"customer_service\")", "y": 1, "oldf": "package openfoodfacts.github.scrachx.openfood.models;\n\nimport com.fasterxml.jackson.annotation.JsonAnyGetter;\nimport com.fasterxml.jackson.annotation.JsonAnySetter;\nimport com.fasterxml.jackson.annotation.JsonIgnoreProperties;\nimport com.fasterxml.jackson.annotation.JsonInclude;\nimport com.fasterxml.jackson.annotation.JsonProperty;\nimport com.fasterxml.jackson.databind.annotation.JsonDeserialize;\nimport com.fasterxml.jackson.databind.util.StdConverter;\n\nimport org.apache.commons.lang3.builder.ToStringBuilder;\nimport org.apache.commons.text.StringEscapeUtils;\n\nimport java.io.Serializable;\nimport java.util.ArrayList;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\n\nclass ProductStringConverter extends StdConverter<String, String> {\n    public String convert(String value) {\n        return StringEscapeUtils.unescapeHtml4(value).replace(\"\\\\'\", \"'\").replace(\"&quot\", \"'\");\n    }\n}\n\n@JsonInclude(JsonInclude.Include.NON_NULL)\n@JsonIgnoreProperties(ignoreUnknown = true)\npublic class Product implements Serializable {\n\n    private static final long serialVersionUID = 1L;\n\n    @JsonProperty(\"image_small_url\")\n    private String imageSmallUrl;\n    @JsonProperty(\"image_nutrition_url\")\n    private String imageNutritionUrl;\n    @JsonProperty(\"image_front_url\")\n    private String imageFrontUrl;\n    @JsonProperty(\"image_ingredients_url\")\n    private String imageIngredientsUrl;\n    @JsonProperty(\"link\")\n    private String manufactureUrl;\n    private String url;\n    private String code;\n    @JsonProperty(\"traces_tags\")\n    private List<String> tracesTags = new ArrayList<>();\n    @JsonProperty(\"ingredients_that_may_be_from_palm_oil_tags\")\n    private List<String> ingredientsThatMayBeFromPalmOilTags = new ArrayList<>();\n    @JsonProperty(\"additives_tags\")\n    private List<String> additivesTags = new ArrayList<>();\n    @JsonProperty(\"allergens_hierarchy\")\n    private List<String> allergensHierarchy = new ArrayList<>();\n    @JsonProperty(\"manufacturing_places\")\n    private String manufacturingPlaces;\n    private Nutriments nutriments;\n    @JsonProperty(\"ingredients_from_palm_oil_tags\")\n    private List<Object> ingredientsFromPalmOilTags = new ArrayList<>();\n    @JsonProperty(\"brands_tags\")\n    private List<String> brandsTags = new ArrayList<>();\n    private String traces;\n    @JsonProperty(\"categories_tags\")\n    private List<String> categoriesTags;\n    @JsonProperty(\"ingredients_text\")\n    @JsonDeserialize(converter = ProductStringConverter.class)\n    private String ingredientsText;\n    @JsonProperty(\"product_name\")\n    @JsonDeserialize(converter = ProductStringConverter.class)\n    private String productName;\n    @JsonProperty(\"generic_name\")\n    @JsonDeserialize(converter = ProductStringConverter.class)\n    private String genericName;\n    @JsonProperty(\"ingredients_from_or_that_may_be_from_palm_oil_n\")\n    private long ingredientsFromOrThatMayBeFromPalmOilN;\n    @JsonProperty(\"serving_size\")\n    private String servingSize;\n    @JsonProperty(\"last_modified_by\")\n    private String lastModifiedBy;\n    @JsonProperty(\"allergens_tags\")\n    private List<String> allergensTags;\n    private String allergens;\n    private String origins;\n    private String stores;\n    @JsonProperty(\"nutrition_grade_fr\")\n    private String nutritionGradeFr;\n    @JsonProperty(\"nutrient_levels\")\n    private NutrientLevels nutrientLevels;\n    private String countries;\n    @JsonProperty(\"countries_tags\")\n    private List<String> countriesTags;\n    private String brands;\n    private String packaging;\n    @JsonProperty(\"labels_hierarchy\")\n    private List<String> labelsHierarchy;\n    @JsonProperty(\"labels_tags\")\n    private List<String> labelsTags;\n    @JsonProperty(\"cities_tags\")\n    private List<Object> citiesTags = new ArrayList<>();\n    private String quantity;\n    @JsonProperty(\"ingredients_from_palm_oil_n\")\n    private long ingredientsFromPalmOilN;\n    @JsonProperty(\"image_url\")\n    private String imageUrl;\n    @JsonProperty(\"emb_codes_tags\")\n    private List<Object> embTags = new ArrayList<>();\n    @JsonProperty(\"states_tags\")\n    private List<String> statesTags = new ArrayList<>();\n    @JsonProperty(\"vitamins_tags\")\n    private List<String> vitaminTags = new ArrayList<>();\n    @JsonProperty(\"minerals_tags\")\n    private List<String> mineralTags = new ArrayList<>();\n    @JsonProperty(\"amino_acids_tags\")\n    private List<String> aminoAcidTags = new ArrayList<>();\n    @JsonProperty(\"other_nutritional_substances_tags\")\n    private List<String> otherNutritionTags = new ArrayList<>();\n    @JsonProperty(\"created_t\")\n    private String createdDateTime;\n    @JsonProperty(\"creator\")\n    private String creator;\n    @JsonProperty(\"last_modified_t\")\n    private String lastModifiedTime;\n    @JsonProperty(\"editors_tags\")\n    private List<String> editorsTags = new ArrayList<>();\n    @JsonProperty(\"nova_groups\")\n    private String novaGroups;\n    @JsonProperty(\"lang\")\n    private String lang;\n    @JsonProperty(\"purchase_places\")\n    private String purchasePlaces;\n    @JsonProperty(\"nutrition_data_per\")\n    private String nutritionDataPer;\n    @JsonProperty(\"no_nutrition_data\")\n    private String noNutritionData;\n    @JsonProperty(\"warning\")\n    private String warning;\n    @JsonProperty(\"customer_service\")\n    private String customerService;\n\n\n    private Map<String, Object> additionalProperties = new HashMap<>();\n\n    @JsonAnyGetter\n    public Map<String, Object> getAdditionalProperties() {\n        return this.additionalProperties;\n    }\n\n    @JsonAnySetter\n    public void setAdditionalProperty(String name, Object value) {\n        this.additionalProperties.put(name, value);\n    }\n\n    public String getProductName(String languageCode) {\n        if (additionalProperties.get(\"product_name_\" + languageCode) != null) {\n            return additionalProperties.get(\"product_name_\" + languageCode)\n                    .toString()\n                    .replace(\"\\\\'\", \"'\")\n                    .replace(\"&quot\", \"'\");\n        }\n        return null;\n    }\n\n    public String getIngredientsText(String languageCode) {\n        if (additionalProperties.get(\"ingredients_text_\" + languageCode) != null) {\n            return additionalProperties.get(\"ingredients_text_\" + languageCode).toString();\n        }\n        return null;\n    }\n\n    /**\n     * @return The statesTags\n     */\n    public List<String> getStatesTags() {\n        return statesTags;\n    }\n\n    public String getLastModifiedBy() {\n        return lastModifiedBy;\n    }\n\n\n    public String getCustomerService() {\n        return customerService;\n    }\n    public String getWarning() {\n        return warning;\n    }\n\n\n    /**\n     * @return The vitaminTags\n     */\n\n    public List<String> getVitaminTags() {\n        return vitaminTags;\n    }\n\n    public void setVitaminTags(List<String> vitaminTags) {\n        this.vitaminTags = vitaminTags;\n    }\n\n    /**\n     * @return The mineralsTags\n     */\n\n    public List<String> getMineralTags() {\n        return mineralTags;\n    }\n\n    public void setMineralTags(List<String> mineralTags) {\n        this.mineralTags = mineralTags;\n    }\n\n    /**\n     * @return The aminoAcidTags\n     */\n\n    public List<String> getAminoAcidTags() {\n        return aminoAcidTags;\n    }\n\n    public void setAminoAcidTags(List<String> aminoAcidTags) {\n        this.aminoAcidTags = aminoAcidTags;\n    }\n\n\n    /**\n     * @return The otherNutritionTags\n     */\n\n    public List<String> getOtherNutritionTags() {\n        return otherNutritionTags;\n    }\n\n    public void setOtherNutritionTags(List<String> otherNutritionTags) {\n        this.otherNutritionTags = otherNutritionTags;\n    }\n\n    /**\n     * @return The imageSmallUrl\n     */\n    public String getImageSmallUrl() {\n        return imageSmallUrl;\n    }\n\n    /**\n     * @return The imageFrontUrl\n     */\n    public String getImageFrontUrl() {\n        return imageFrontUrl;\n    }\n\n    /**\n     * @return The imageIngredientsUrl\n     */\n    public String getImageIngredientsUrl() {\n        return imageIngredientsUrl;\n    }\n\n\n    /**\n     * @return The imageNutritionUrl\n     */\n    public String getImageNutritionUrl() {\n        return imageNutritionUrl;\n    }\n\n    /**\n     * @return The manufactureUrl\n     */\n    public String getManufactureUrl() {\n        return manufactureUrl;\n    }\n\n    /**\n     * @return The url\n     */\n    public String getUrl() {\n        return url;\n    }\n\n    /**\n     * @return The code\n     */\n    public String getCode() {\n        return code;\n    }\n\n    public void setCode(String code) {\n        this.code = code;\n    }\n\n    /**\n     * @return The tracesTags\n     */\n    public List<String> getTracesTags() {\n        return tracesTags;\n    }\n\n    /**\n     * @return The ingredientsThatMayBeFromPalmOilTags\n     */\n    public List<String> getIngredientsThatMayBeFromPalmOilTags() {\n        return ingredientsThatMayBeFromPalmOilTags;\n    }\n\n    /**\n     * @return The additivesTags\n     */\n    public List<String> getAdditivesTags() {\n        return additivesTags;\n    }\n\n    /**\n     * @return The allergensHierarchy\n     */\n    public List<String> getAllergensHierarchy() {\n        return allergensHierarchy;\n    }\n\n    /**\n     * @return The manufacturingPlaces\n     */\n    public String getManufacturingPlaces() {\n        return manufacturingPlaces;\n    }\n\n    /**\n     * @return The nutriments\n     */\n    public Nutriments getNutriments() {\n        return nutriments;\n    }\n\n    /**\n     * @return The ingredientsFromPalmOilTags\n     */\n    public List<Object> getIngredientsFromPalmOilTags() {\n        return ingredientsFromPalmOilTags;\n    }\n\n    /**\n     * @return The brandsTags\n     */\n    public List<String> getBrandsTags() {\n        return brandsTags;\n    }\n\n    /**\n     * @return The traces\n     */\n    public String getTraces() {\n        return traces;\n    }\n\n    /**\n     * @return The categoriesTags\n     */\n    public List<String> getCategoriesTags() {\n        return categoriesTags;\n    }\n\n    /**\n     * @return The ingredientsText\n     */\n    public String getIngredientsText() {\n        return ingredientsText;\n    }\n\n    /**\n     * @return The productName\n     */\n    public String getProductName() {\n        return productName;\n    }\n\n    /**\n     * @return The genericName\n     */\n    public String getGenericName() {\n        return genericName;\n    }\n\n    /**\n     * @return The ingredientsFromOrThatMayBeFromPalmOilN\n     */\n    public long getIngredientsFromOrThatMayBeFromPalmOilN() {\n        return ingredientsFromOrThatMayBeFromPalmOilN;\n    }\n\n    /**\n     * @return The servingSize\n     */\n\n\n    public String getServingSize() {\n        return servingSize;\n    }\n\n    public List<String> getAllergensTags() {\n        return allergensTags;\n    }\n\n    /**\n     * @return The allergens\n     */\n    public String getAllergens() {\n        return allergens;\n    }\n\n    /**\n     * @return The origins\n     */\n    public String getOrigins() {\n        return origins;\n    }\n\n    /**\n     * @return The stores\n     */\n    public String getStores() {\n        if (stores == null)\n            return null;\n        return stores.replace(\",\", \", \");\n    }\n\n    /**\n     * @return The nutritionGradeFr\n     */\n    public String getNutritionGradeFr() {\n        return nutritionGradeFr;\n    }\n\n    /**\n     * @return The nutrientLevels\n     */\n    public NutrientLevels getNutrientLevels() {\n        return nutrientLevels;\n    }\n\n    /**\n     * @return The countries\n     */\n    public String getCountries() {\n        if (countries == null)\n            return null;\n        return countries.replace(\",\", \", \");\n    }\n\n    /**\n     * @return The brands\n     */\n    public String getBrands() {\n        if (brands == null)\n            return null;\n        return brands.replace(\",\", \", \");\n    }\n\n    /**\n     * @return The packaging\n     */\n    public String getPackaging() {\n        if (packaging == null)\n            return null;\n        return packaging.replace(\",\", \", \");\n    }\n\n    /**\n     * @return The labels tags\n     */\n    public List<String> getLabelsTags() {\n        return labelsTags;\n    }\n\n    /**\n     * @return The labels hierarchy\n     */\n    public List<String> getLabelsHierarchy() {\n        return labelsHierarchy;\n    }\n\n    /**\n     * @return The citiesTags\n     */\n    public List<Object> getCitiesTags() {\n        return citiesTags;\n    }\n\n    /**\n     * @return The quantity\n     */\n    public String getQuantity() {\n        return quantity;\n    }\n\n    /**\n     * @return The ingredientsFromPalmOilN\n     */\n    public long getIngredientsFromPalmOilN() {\n        return ingredientsFromPalmOilN;\n    }\n\n    /**\n     * @return The imageUrl\n     */\n    public String getImageUrl() {\n        return imageUrl;\n    }\n\n    /**\n     * @return The Emb_codes\n     */\n    public List<Object> getEmbTags() {\n        return embTags;\n    }\n\n    public List<String> getCountriesTags() {\n        return countriesTags;\n    }\n\n    public String getCreator() {\n        return creator;\n    }\n\n    public String getCreatedDateTime() {\n        return createdDateTime;\n    }\n\n    public String getLastModifiedTime() {\n        return lastModifiedTime;\n    }\n\n    public List<String> getEditors() {\n        return editorsTags;\n    }\n\n    public String getNovaGroups() {\n        return novaGroups;\n    }\n\n    public String getLang() {\n        return lang;\n    }\n\n    public String getPurchasePlaces() {\n        return purchasePlaces;\n    }\n\n    public String getNutritionDataPer() {\n        return nutritionDataPer;\n    }\n\n    public String getNoNutritionData() {\n        return noNutritionData;\n    }\n\n    @Override\n    public String toString() {\n        return new ToStringBuilder(this)\n                .append(\"code\", code)\n                .append(\"productName\", productName)\n                .toString();\n    }\n}", "idx": 1, "id": 66525, "msg": "Please use properties without suffix `_fr` so they can work across different languages as @teolemon mentioned", "proj": "openfoodfacts-openfoodfacts-androidapp", "lang": "java"}
{"patch": "@@ -234,3 +234,17 @@ def repeat_command(win_id, count=None):\n     cmd = runners.last_command[mode_manager.mode]\n     commandrunner = runners.CommandRunner(win_id)\n     commandrunner.run(cmd[0], count if count is not None else cmd[1])\n+\n+@cmdutils.register(debug=True,name='debug-log-capacity')\n+def log_capacity(capacity: int):\n+    \"\"\"Choose number of lines for your log.\n+\n+    Args:\n+       capacity: Number of lines for the log.       \n+    \"\"\"\n+    if capacity < 0:\n+        raise cmdexc.CommandError(\"Please choose log capacity above 0.\")\n+    else:        \n+        log.ram_handler.change_log_capacity(capacity)\n+\n+", "y": 1, "oldf": "# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:\n\n# Copyright 2014-2016 Florian Bruhin (The Compiler) <mail@qutebrowser.org>\n#\n# This file is part of qutebrowser.\n#\n# qutebrowser is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# qutebrowser is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with qutebrowser.  If not, see <http://www.gnu.org/licenses/>.\n\n\"\"\"Misc. utility commands exposed to the user.\"\"\"\n\nimport functools\nimport types\nimport traceback\n\ntry:\n    import hunter\nexcept ImportError:\n    hunter = None\n\nfrom qutebrowser.browser.webkit.network import qutescheme\nfrom qutebrowser.utils import log, objreg, usertypes, message, debug, utils\nfrom qutebrowser.commands import cmdutils, runners, cmdexc\nfrom qutebrowser.config import style\nfrom qutebrowser.misc import consolewidget\n\nfrom PyQt5.QtCore import QUrl\n# so it's available for :debug-pyeval\nfrom PyQt5.QtWidgets import QApplication  # pylint: disable=unused-import\n\n\n@cmdutils.register(maxsplit=1, no_cmd_split=True)\n@cmdutils.argument('win_id', win_id=True)\ndef later(ms: int, command, win_id):\n    \"\"\"Execute a command after some time.\n\n    Args:\n        ms: How many milliseconds to wait.\n        command: The command to run, with optional args.\n    \"\"\"\n    if ms < 0:\n        raise cmdexc.CommandError(\"I can't run something in the past!\")\n    commandrunner = runners.CommandRunner(win_id)\n    app = objreg.get('app')\n    timer = usertypes.Timer(name='later', parent=app)\n    try:\n        timer.setSingleShot(True)\n        try:\n            timer.setInterval(ms)\n        except OverflowError:\n            raise cmdexc.CommandError(\"Numeric argument is too large for \"\n                                      \"internal int representation.\")\n        timer.timeout.connect(\n            functools.partial(commandrunner.run_safely, command))\n        timer.timeout.connect(timer.deleteLater)\n        timer.start()\n    except:\n        timer.deleteLater()\n        raise\n\n\n@cmdutils.register(maxsplit=1, no_cmd_split=True)\n@cmdutils.argument('win_id', win_id=True)\ndef repeat(times: int, command, win_id):\n    \"\"\"Repeat a given command.\n\n    Args:\n        times: How many times to repeat.\n        command: The command to run, with optional args.\n    \"\"\"\n    if times < 0:\n        raise cmdexc.CommandError(\"A negative count doesn't make sense.\")\n    commandrunner = runners.CommandRunner(win_id)\n    for _ in range(times):\n        commandrunner.run_safely(command)\n\n\n@cmdutils.register(hide=True)\n@cmdutils.argument('win_id', win_id=True)\ndef message_error(win_id, text):\n    \"\"\"Show an error message in the statusbar.\n\n    Args:\n        text: The text to show.\n    \"\"\"\n    message.error(win_id, text)\n\n\n@cmdutils.register(hide=True)\n@cmdutils.argument('win_id', win_id=True)\ndef message_info(win_id, text):\n    \"\"\"Show an info message in the statusbar.\n\n    Args:\n        text: The text to show.\n    \"\"\"\n    message.info(win_id, text)\n\n\n@cmdutils.register(hide=True)\n@cmdutils.argument('win_id', win_id=True)\ndef message_warning(win_id, text):\n    \"\"\"Show a warning message in the statusbar.\n\n    Args:\n        text: The text to show.\n    \"\"\"\n    message.warning(win_id, text)\n\n\n@cmdutils.register(debug=True)\n@cmdutils.argument('typ', choices=['exception', 'segfault'])\ndef debug_crash(typ='exception'):\n    \"\"\"Crash for debugging purposes.\n\n    Args:\n        typ: either 'exception' or 'segfault'.\n    \"\"\"\n    if typ == 'segfault':\n        # From python's Lib/test/crashers/bogus_code_obj.py\n        co = types.CodeType(0, 0, 0, 0, 0, b'\\x04\\x71\\x00\\x00', (), (), (),\n                            '', '', 1, b'')\n        exec(co)\n        raise Exception(\"Segfault failed (wat.)\")\n    else:\n        raise Exception(\"Forced crash\")\n\n\n@cmdutils.register(debug=True)\ndef debug_all_objects():\n    \"\"\"Print a list of  all objects to the debug log.\"\"\"\n    s = debug.get_all_objects()\n    log.misc.debug(s)\n\n\n@cmdutils.register(debug=True)\ndef debug_cache_stats():\n    \"\"\"Print LRU cache stats.\"\"\"\n    config_info = objreg.get('config').get.cache_info()\n    style_info = style.get_stylesheet.cache_info()\n    log.misc.debug('config: {}'.format(config_info))\n    log.misc.debug('style: {}'.format(style_info))\n\n\n@cmdutils.register(debug=True)\ndef debug_console():\n    \"\"\"Show the debugging console.\"\"\"\n    try:\n        con_widget = objreg.get('debug-console')\n    except KeyError:\n        con_widget = consolewidget.ConsoleWidget()\n        objreg.register('debug-console', con_widget)\n\n    if con_widget.isVisible():\n        con_widget.hide()\n    else:\n        con_widget.show()\n\n\n@cmdutils.register(debug=True, maxsplit=0, no_cmd_split=True)\ndef debug_trace(expr=\"\"):\n    \"\"\"Trace executed code via hunter.\n\n    Args:\n        expr: What to trace, passed to hunter.\n    \"\"\"\n    if hunter is None:\n        raise cmdexc.CommandError(\"You need to install 'hunter' to use this \"\n                                  \"command!\")\n    try:\n        eval('hunter.trace({})'.format(expr))\n    except Exception as e:\n        raise cmdexc.CommandError(\"{}: {}\".format(e.__class__.__name__, e))\n\n\n@cmdutils.register(maxsplit=0, debug=True, no_cmd_split=True)\ndef debug_pyeval(s, quiet=False):\n    \"\"\"Evaluate a python string and display the results as a web page.\n\n    Args:\n        s: The string to evaluate.\n        quiet: Don't show the output in a new tab.\n    \"\"\"\n    try:\n        r = eval(s)\n        out = repr(r)\n    except Exception:\n        out = traceback.format_exc()\n\n    qutescheme.pyeval_output = out\n    if quiet:\n        log.misc.debug(\"pyeval output: {}\".format(out))\n    else:\n        tabbed_browser = objreg.get('tabbed-browser', scope='window',\n                                    window='last-focused')\n        tabbed_browser.openurl(QUrl('qute:pyeval'), newtab=True)\n\n\n@cmdutils.register(debug=True)\ndef debug_set_fake_clipboard(s=None):\n    \"\"\"Put data into the fake clipboard and enable logging, used for tests.\n\n    Args:\n        s: The text to put into the fake clipboard, or unset to enable logging.\n    \"\"\"\n    if s is None:\n        utils.log_clipboard = True\n    else:\n        utils.fake_clipboard = s\n\n\n@cmdutils.register(hide=True)\n@cmdutils.argument('win_id', win_id=True)\n@cmdutils.argument('count', count=True)\ndef repeat_command(win_id, count=None):\n    \"\"\"Repeat the last executed command.\n\n    Args:\n        count: Which count to pass the command.\n    \"\"\"\n    mode_manager = objreg.get('mode-manager', scope='window', window=win_id)\n    if mode_manager.mode not in runners.last_command:\n        raise cmdexc.CommandError(\"You didn't do anything yet.\")\n    cmd = runners.last_command[mode_manager.mode]\n    commandrunner = runners.CommandRunner(win_id)\n    commandrunner.run(cmd[0], count if count is not None else cmd[1])\n", "idx": 1, "id": 15574, "msg": "Please add a space after the comma here (generally, with arguments there's always a space after commas).", "proj": "qutebrowser-qutebrowser", "lang": "py"}
{"patch": "@@ -539,7 +539,10 @@ class WebElement(object):\n     @property\n     def rect(self):\n         \"\"\"A dictionary with the size and location of the element.\"\"\"\n-        return self._execute(Command.GET_ELEMENT_RECT)['value']\n+        if self._w3c:\n+            return self._execute(Command.GET_ELEMENT_RECT)['value']\n+        else:\n+            return self.size, self.location\n \n     @property\n     def screenshot_as_base64(self):", "y": 1, "oldf": "# Licensed to the Software Freedom Conservancy (SFC) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The SFC licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\nimport base64\nimport hashlib\nimport os\nimport pkgutil\nimport warnings\nimport zipfile\n\nfrom selenium.common.exceptions import WebDriverException\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.common.utils import keys_to_typing\nfrom .command import Command\n\n# Python 3 imports\ntry:\n    str = basestring\nexcept NameError:\n    pass\n\ntry:\n    from StringIO import StringIO as IOStream\nexcept ImportError:  # 3+\n    from io import BytesIO as IOStream\n\n# not relying on __package__ here as it can be `None` in some situations (see #4558)\n_pkg = '.'.join(__name__.split('.')[:-1])\ngetAttribute_js = pkgutil.get_data(_pkg, 'getAttribute.js').decode('utf8')\nisDisplayed_js = pkgutil.get_data(_pkg, 'isDisplayed.js').decode('utf8')\n\n\nclass WebElement(object):\n    \"\"\"Represents a DOM element.\n\n    Generally, all interesting operations that interact with a document will be\n    performed through this interface.\n\n    All method calls will do a freshness check to ensure that the element\n    reference is still valid.  This essentially determines whether or not the\n    element is still attached to the DOM.  If this test fails, then an\n    ``StaleElementReferenceException`` is thrown, and all future calls to this\n    instance will fail.\"\"\"\n\n    def __init__(self, parent, id_, w3c=False):\n        self._parent = parent\n        self._id = id_\n        self._w3c = w3c\n\n    def __repr__(self):\n        return '<{0.__module__}.{0.__name__} (session=\"{1}\", element=\"{2}\")>'.format(\n            type(self), self._parent.session_id, self._id)\n\n    @property\n    def tag_name(self):\n        \"\"\"This element's ``tagName`` property.\"\"\"\n        return self._execute(Command.GET_ELEMENT_TAG_NAME)['value']\n\n    @property\n    def text(self):\n        \"\"\"The text of the element.\"\"\"\n        return self._execute(Command.GET_ELEMENT_TEXT)['value']\n\n    def click(self):\n        \"\"\"Clicks the element.\"\"\"\n        self._execute(Command.CLICK_ELEMENT)\n\n    def submit(self):\n        \"\"\"Submits a form.\"\"\"\n        if self._w3c:\n            form = self.find_element(By.XPATH, \"./ancestor-or-self::form\")\n            self._parent.execute_script(\n                \"var e = arguments[0].ownerDocument.createEvent('Event');\"\n                \"e.initEvent('submit', true, true);\"\n                \"if (arguments[0].dispatchEvent(e)) { arguments[0].submit() }\", form)\n        else:\n            self._execute(Command.SUBMIT_ELEMENT)\n\n    def clear(self):\n        \"\"\"Clears the text if it's a text entry element.\"\"\"\n        self._execute(Command.CLEAR_ELEMENT)\n\n    def get_property(self, name):\n        \"\"\"\n        Gets the given property of the element.\n\n        :Args:\n            - name - Name of the property to retrieve.\n\n        Example::\n\n            text_length = target_element.get_property(\"text_length\")\n        \"\"\"\n        try:\n            return self._execute(Command.GET_ELEMENT_PROPERTY, {\"name\": name})[\"value\"]\n        except WebDriverException:\n            # if we hit an end point that doesnt understand getElementProperty lets fake it\n            return self.parent.execute_script('return arguments[0][arguments[1]]', self, name)\n\n    def get_attribute(self, name):\n        \"\"\"Gets the given attribute or property of the element.\n\n        This method will first try to return the value of a property with the\n        given name. If a property with that name doesn't exist, it returns the\n        value of the attribute with the same name. If there's no attribute with\n        that name, ``None`` is returned.\n\n        Values which are considered truthy, that is equals \"true\" or \"false\",\n        are returned as booleans.  All other non-``None`` values are returned\n        as strings.  For attributes or properties which do not exist, ``None``\n        is returned.\n\n        :Args:\n            - name - Name of the attribute/property to retrieve.\n\n        Example::\n\n            # Check if the \"active\" CSS class is applied to an element.\n            is_active = \"active\" in target_element.get_attribute(\"class\")\n\n        \"\"\"\n\n        attributeValue = ''\n        if self._w3c:\n            attributeValue = self.parent.execute_script(\n                \"return (%s).apply(null, arguments);\" % getAttribute_js,\n                self, name)\n        else:\n            resp = self._execute(Command.GET_ELEMENT_ATTRIBUTE, {'name': name})\n            attributeValue = resp.get('value')\n            if attributeValue is not None:\n                if name != 'value' and attributeValue.lower() in ('true', 'false'):\n                    attributeValue = attributeValue.lower()\n        return attributeValue\n\n    def is_selected(self):\n        \"\"\"Returns whether the element is selected.\n\n        Can be used to check if a checkbox or radio button is selected.\n        \"\"\"\n        return self._execute(Command.IS_ELEMENT_SELECTED)['value']\n\n    def is_enabled(self):\n        \"\"\"Returns whether the element is enabled.\"\"\"\n        return self._execute(Command.IS_ELEMENT_ENABLED)['value']\n\n    def find_element_by_id(self, id_):\n        \"\"\"Finds element within this element's children by ID.\n\n        :Args:\n         - id\\_ - ID of child element to locate.\n\n        :Returns:\n         - WebElement - the element if it was found\n\n        :Raises:\n         - NoSuchElementException - if the element wasn't found\n\n        :Usage:\n            foo_element = element.find_element_by_id('foo')\n        \"\"\"\n        return self.find_element(by=By.ID, value=id_)\n\n    def find_elements_by_id(self, id_):\n        \"\"\"Finds a list of elements within this element's children by ID.\n        Will return a list of webelements if found, or an empty list if not.\n\n        :Args:\n         - id\\_ - Id of child element to find.\n\n        :Returns:\n         - list of WebElement - a list with elements if any was found.  An\n           empty list if not\n\n        :Usage:\n            elements = element.find_elements_by_id('foo')\n        \"\"\"\n        return self.find_elements(by=By.ID, value=id_)\n\n    def find_element_by_name(self, name):\n        \"\"\"Finds element within this element's children by name.\n\n        :Args:\n         - name - name property of the element to find.\n\n        :Returns:\n         - WebElement - the element if it was found\n\n        :Raises:\n         - NoSuchElementException - if the element wasn't found\n\n        :Usage:\n            element = element.find_element_by_name('foo')\n        \"\"\"\n        return self.find_element(by=By.NAME, value=name)\n\n    def find_elements_by_name(self, name):\n        \"\"\"Finds a list of elements within this element's children by name.\n\n        :Args:\n         - name - name property to search for.\n\n        :Returns:\n         - list of webelement - a list with elements if any was found.  an\n           empty list if not\n\n        :Usage:\n            elements = element.find_elements_by_name('foo')\n        \"\"\"\n        return self.find_elements(by=By.NAME, value=name)\n\n    def find_element_by_link_text(self, link_text):\n        \"\"\"Finds element within this element's children by visible link text.\n\n        :Args:\n         - link_text - Link text string to search for.\n\n        :Returns:\n         - WebElement - the element if it was found\n\n        :Raises:\n         - NoSuchElementException - if the element wasn't found\n\n        :Usage:\n            element = element.find_element_by_link_text('Sign In')\n        \"\"\"\n        return self.find_element(by=By.LINK_TEXT, value=link_text)\n\n    def find_elements_by_link_text(self, link_text):\n        \"\"\"Finds a list of elements within this element's children by visible link text.\n\n        :Args:\n         - link_text - Link text string to search for.\n\n        :Returns:\n         - list of webelement - a list with elements if any was found.  an\n           empty list if not\n\n        :Usage:\n            elements = element.find_elements_by_link_text('Sign In')\n        \"\"\"\n        return self.find_elements(by=By.LINK_TEXT, value=link_text)\n\n    def find_element_by_partial_link_text(self, link_text):\n        \"\"\"Finds element within this element's children by partially visible link text.\n\n        :Args:\n         - link_text: The text of the element to partially match on.\n\n        :Returns:\n         - WebElement - the element if it was found\n\n        :Raises:\n         - NoSuchElementException - if the element wasn't found\n\n        :Usage:\n            element = element.find_element_by_partial_link_text('Sign')\n        \"\"\"\n        return self.find_element(by=By.PARTIAL_LINK_TEXT, value=link_text)\n\n    def find_elements_by_partial_link_text(self, link_text):\n        \"\"\"Finds a list of elements within this element's children by link text.\n\n        :Args:\n         - link_text: The text of the element to partial match on.\n\n        :Returns:\n         - list of webelement - a list with elements if any was found.  an\n           empty list if not\n\n        :Usage:\n            elements = element.find_elements_by_partial_link_text('Sign')\n        \"\"\"\n        return self.find_elements(by=By.PARTIAL_LINK_TEXT, value=link_text)\n\n    def find_element_by_tag_name(self, name):\n        \"\"\"Finds element within this element's children by tag name.\n\n        :Args:\n         - name - name of html tag (eg: h1, a, span)\n\n        :Returns:\n         - WebElement - the element if it was found\n\n        :Raises:\n         - NoSuchElementException - if the element wasn't found\n\n        :Usage:\n            element = element.find_element_by_tag_name('h1')\n        \"\"\"\n        return self.find_element(by=By.TAG_NAME, value=name)\n\n    def find_elements_by_tag_name(self, name):\n        \"\"\"Finds a list of elements within this element's children by tag name.\n\n        :Args:\n         - name - name of html tag (eg: h1, a, span)\n\n        :Returns:\n         - list of WebElement - a list with elements if any was found.  An\n           empty list if not\n\n        :Usage:\n            elements = element.find_elements_by_tag_name('h1')\n        \"\"\"\n        return self.find_elements(by=By.TAG_NAME, value=name)\n\n    def find_element_by_xpath(self, xpath):\n        \"\"\"Finds element by xpath.\n\n        :Args:\n         - xpath - xpath of element to locate.  \"//input[@class='myelement']\"\n\n        Note: The base path will be relative to this element's location.\n\n        This will select the first link under this element.\n\n        ::\n\n            myelement.find_element_by_xpath(\".//a\")\n\n        However, this will select the first link on the page.\n\n        ::\n\n            myelement.find_element_by_xpath(\"//a\")\n\n        :Returns:\n         - WebElement - the element if it was found\n\n        :Raises:\n         - NoSuchElementException - if the element wasn't found\n\n        :Usage:\n            element = element.find_element_by_xpath('//div/td[1]')\n        \"\"\"\n        return self.find_element(by=By.XPATH, value=xpath)\n\n    def find_elements_by_xpath(self, xpath):\n        \"\"\"Finds elements within the element by xpath.\n\n        :Args:\n         - xpath - xpath locator string.\n\n        Note: The base path will be relative to this element's location.\n\n        This will select all links under this element.\n\n        ::\n\n            myelement.find_elements_by_xpath(\".//a\")\n\n        However, this will select all links in the page itself.\n\n        ::\n\n            myelement.find_elements_by_xpath(\"//a\")\n\n        :Returns:\n         - list of WebElement - a list with elements if any was found.  An\n           empty list if not\n\n        :Usage:\n            elements = element.find_elements_by_xpath(\"//div[contains(@class, 'foo')]\")\n\n        \"\"\"\n        return self.find_elements(by=By.XPATH, value=xpath)\n\n    def find_element_by_class_name(self, name):\n        \"\"\"Finds element within this element's children by class name.\n\n        :Args:\n         - name: The class name of the element to find.\n\n        :Returns:\n         - WebElement - the element if it was found\n\n        :Raises:\n         - NoSuchElementException - if the element wasn't found\n\n        :Usage:\n            element = element.find_element_by_class_name('foo')\n        \"\"\"\n        return self.find_element(by=By.CLASS_NAME, value=name)\n\n    def find_elements_by_class_name(self, name):\n        \"\"\"Finds a list of elements within this element's children by class name.\n\n        :Args:\n         - name: The class name of the elements to find.\n\n        :Returns:\n         - list of WebElement - a list with elements if any was found.  An\n           empty list if not\n\n        :Usage:\n            elements = element.find_elements_by_class_name('foo')\n        \"\"\"\n        return self.find_elements(by=By.CLASS_NAME, value=name)\n\n    def find_element_by_css_selector(self, css_selector):\n        \"\"\"Finds element within this element's children by CSS selector.\n\n        :Args:\n         - css_selector - CSS selector string, ex: 'a.nav#home'\n\n        :Returns:\n         - WebElement - the element if it was found\n\n        :Raises:\n         - NoSuchElementException - if the element wasn't found\n\n        :Usage:\n            element = element.find_element_by_css_selector('#foo')\n        \"\"\"\n        return self.find_element(by=By.CSS_SELECTOR, value=css_selector)\n\n    def find_elements_by_css_selector(self, css_selector):\n        \"\"\"Finds a list of elements within this element's children by CSS selector.\n\n        :Args:\n         - css_selector - CSS selector string, ex: 'a.nav#home'\n\n        :Returns:\n         - list of WebElement - a list with elements if any was found.  An\n           empty list if not\n\n        :Usage:\n            elements = element.find_elements_by_css_selector('.foo')\n        \"\"\"\n        return self.find_elements(by=By.CSS_SELECTOR, value=css_selector)\n\n    def send_keys(self, *value):\n        \"\"\"Simulates typing into the element.\n\n        :Args:\n            - value - A string for typing, or setting form fields.  For setting\n              file inputs, this could be a local file path.\n\n        Use this to send simple key events or to fill out form fields::\n\n            form_textfield = driver.find_element_by_name('username')\n            form_textfield.send_keys(\"admin\")\n\n        This can also be used to set file inputs.\n\n        ::\n\n            file_input = driver.find_element_by_name('profilePic')\n            file_input.send_keys(\"path/to/profilepic.gif\")\n            # Generally it's better to wrap the file path in one of the methods\n            # in os.path to return the actual path to support cross OS testing.\n            # file_input.send_keys(os.path.abspath(\"path/to/profilepic.gif\"))\n\n        \"\"\"\n        # transfer file to another machine only if remote driver is used\n        # the same behaviour as for java binding\n        if self.parent._is_remote:\n            local_file = self.parent.file_detector.is_local_file(*value)\n            if local_file is not None:\n                value = self._upload(local_file)\n\n        self._execute(Command.SEND_KEYS_TO_ELEMENT,\n                      {'text': \"\".join(keys_to_typing(value)),\n                       'value': keys_to_typing(value)})\n\n    # RenderedWebElement Items\n    def is_displayed(self):\n        \"\"\"Whether the element is visible to a user.\"\"\"\n        # Only go into this conditional for browsers that don't use the atom themselves\n        if self._w3c and self.parent.capabilities['browserName'] == 'safari':\n            return self.parent.execute_script(\n                \"return (%s).apply(null, arguments);\" % isDisplayed_js,\n                self)\n        else:\n            return self._execute(Command.IS_ELEMENT_DISPLAYED)['value']\n\n    @property\n    def location_once_scrolled_into_view(self):\n        \"\"\"THIS PROPERTY MAY CHANGE WITHOUT WARNING. Use this to discover\n        where on the screen an element is so that we can click it. This method\n        should cause the element to be scrolled into view.\n\n        Returns the top lefthand corner location on the screen, or ``None`` if\n        the element is not visible.\n\n        \"\"\"\n        if self._w3c:\n            old_loc = self._execute(Command.W3C_EXECUTE_SCRIPT, {\n                'script': \"arguments[0].scrollIntoView(true); return arguments[0].getBoundingClientRect()\",\n                'args': [self]})['value']\n            return {\"x\": round(old_loc['x']),\n                    \"y\": round(old_loc['y'])}\n        else:\n            return self._execute(Command.GET_ELEMENT_LOCATION_ONCE_SCROLLED_INTO_VIEW)['value']\n\n    @property\n    def size(self):\n        \"\"\"The size of the element.\"\"\"\n        size = {}\n        if self._w3c:\n            size = self._execute(Command.GET_ELEMENT_RECT)['value']\n        else:\n            size = self._execute(Command.GET_ELEMENT_SIZE)['value']\n        new_size = {\"height\": size[\"height\"],\n                    \"width\": size[\"width\"]}\n        return new_size\n\n    def value_of_css_property(self, property_name):\n        \"\"\"The value of a CSS property.\"\"\"\n        return self._execute(Command.GET_ELEMENT_VALUE_OF_CSS_PROPERTY, {\n            'propertyName': property_name})['value']\n\n    @property\n    def location(self):\n        \"\"\"The location of the element in the renderable canvas.\"\"\"\n        if self._w3c:\n            old_loc = self._execute(Command.GET_ELEMENT_RECT)['value']\n        else:\n            old_loc = self._execute(Command.GET_ELEMENT_LOCATION)['value']\n        new_loc = {\"x\": round(old_loc['x']),\n                   \"y\": round(old_loc['y'])}\n        return new_loc\n\n    @property\n    def rect(self):\n        \"\"\"A dictionary with the size and location of the element.\"\"\"\n        return self._execute(Command.GET_ELEMENT_RECT)['value']\n\n    @property\n    def screenshot_as_base64(self):\n        \"\"\"\n        Gets the screenshot of the current element as a base64 encoded string.\n\n        :Usage:\n            img_b64 = element.screenshot_as_base64\n        \"\"\"\n        return self._execute(Command.ELEMENT_SCREENSHOT)['value']\n\n    @property\n    def screenshot_as_png(self):\n        \"\"\"\n        Gets the screenshot of the current element as a binary data.\n\n        :Usage:\n            element_png = element.screenshot_as_png\n        \"\"\"\n        return base64.b64decode(self.screenshot_as_base64.encode('ascii'))\n\n    def screenshot(self, filename):\n        \"\"\"\n        Saves a screenshot of the current element to a PNG image file. Returns\n           False if there is any IOError, else returns True. Use full paths in\n           your filename.\n\n        :Args:\n         - filename: The full path you wish to save your screenshot to. This\n           should end with a `.png` extension.\n\n        :Usage:\n            element.screenshot('/Screenshots/foo.png')\n        \"\"\"\n        if not filename.lower().endswith('.png'):\n            warnings.warn(\"name used for saved screenshot does not match file \"\n                          \"type. It should end with a `.png` extension\", UserWarning)\n        png = self.screenshot_as_png\n        try:\n            with open(filename, 'wb') as f:\n                f.write(png)\n        except IOError:\n            return False\n        finally:\n            del png\n        return True\n\n    @property\n    def parent(self):\n        \"\"\"Internal reference to the WebDriver instance this element was found from.\"\"\"\n        return self._parent\n\n    @property\n    def id(self):\n        \"\"\"Internal ID used by selenium.\n\n        This is mainly for internal use. Simple use cases such as checking if 2\n        webelements refer to the same element, can be done using ``==``::\n\n            if element1 == element2:\n                print(\"These 2 are equal\")\n\n        \"\"\"\n        return self._id\n\n    def __eq__(self, element):\n        return hasattr(element, 'id') and self._id == element.id\n\n    def __ne__(self, element):\n        return not self.__eq__(element)\n\n    # Private Methods\n    def _execute(self, command, params=None):\n        \"\"\"Executes a command against the underlying HTML element.\n\n        Args:\n          command: The name of the command to _execute as a string.\n          params: A dictionary of named parameters to send with the command.\n\n        Returns:\n          The command's JSON response loaded into a dictionary object.\n        \"\"\"\n        if not params:\n            params = {}\n        params['id'] = self._id\n        return self._parent.execute(command, params)\n\n    def find_element(self, by=By.ID, value=None):\n        \"\"\"\n        Find an element given a By strategy and locator. Prefer the find_element_by_* methods when\n        possible.\n\n        :Usage:\n            element = element.find_element(By.ID, 'foo')\n\n        :rtype: WebElement\n        \"\"\"\n        if self._w3c:\n            if by == By.ID:\n                by = By.CSS_SELECTOR\n                value = '[id=\"%s\"]' % value\n            elif by == By.TAG_NAME:\n                by = By.CSS_SELECTOR\n            elif by == By.CLASS_NAME:\n                by = By.CSS_SELECTOR\n                value = \".%s\" % value\n            elif by == By.NAME:\n                by = By.CSS_SELECTOR\n                value = '[name=\"%s\"]' % value\n\n        return self._execute(Command.FIND_CHILD_ELEMENT,\n                             {\"using\": by, \"value\": value})['value']\n\n    def find_elements(self, by=By.ID, value=None):\n        \"\"\"\n        Find elements given a By strategy and locator. Prefer the find_elements_by_* methods when\n        possible.\n\n        :Usage:\n            element = element.find_elements(By.CLASS_NAME, 'foo')\n\n        :rtype: list of WebElement\n        \"\"\"\n        if self._w3c:\n            if by == By.ID:\n                by = By.CSS_SELECTOR\n                value = '[id=\"%s\"]' % value\n            elif by == By.TAG_NAME:\n                by = By.CSS_SELECTOR\n            elif by == By.CLASS_NAME:\n                by = By.CSS_SELECTOR\n                value = \".%s\" % value\n            elif by == By.NAME:\n                by = By.CSS_SELECTOR\n                value = '[name=\"%s\"]' % value\n\n        return self._execute(Command.FIND_CHILD_ELEMENTS,\n                             {\"using\": by, \"value\": value})['value']\n\n    def __hash__(self):\n        return int(hashlib.md5(self._id.encode('utf-8')).hexdigest(), 16)\n\n    def _upload(self, filename):\n        fp = IOStream()\n        zipped = zipfile.ZipFile(fp, 'w', zipfile.ZIP_DEFLATED)\n        zipped.write(filename, os.path.split(filename)[1])\n        zipped.close()\n        content = base64.encodestring(fp.getvalue())\n        if not isinstance(content, str):\n            content = content.decode('utf-8')\n        try:\n            return self._execute(Command.UPLOAD_FILE, {'file': content})['value']\n        except WebDriverException as e:\n            if \"Unrecognized command: POST\" in e.__str__():\n                return filename\n            elif \"Command not found: POST \" in e.__str__():\n                return filename\n            elif '{\"status\":405,\"value\":[\"GET\",\"HEAD\",\"DELETE\"]}' in e.__str__():\n                return filename\n            else:\n                raise e\n", "idx": 1, "id": 15812, "msg": "This would return a tuple of two dictionaries. You need to combine them and return a dictionary", "proj": "SeleniumHQ-selenium", "lang": "js"}
{"patch": "@@ -180,7 +180,7 @@ static const char *const PORT_ERROR[PORT_ERROR_COUNT] = {\n /*\n  * errors command configuration, set during parse_args()\n  */\n-static struct errors_config {\n+STATIC struct errors_config {\n \tbool clear;\n \tint force_count;\n \tenum verbs_index which;", "y": 1, "oldf": "// Copyright(c) 2018, Intel Corporation\n//\n// Redistribution  and  use  in source  and  binary  forms,  with  or  without\n// modification, are permitted provided that the following conditions are met:\n//\n// * Redistributions of  source code  must retain the  above copyright notice,\n//   this list of conditions and the following disclaimer.\n// * Redistributions in binary form must reproduce the above copyright notice,\n//   this list of conditions and the following disclaimer in the documentation\n//   and/or other materials provided with the distribution.\n// * Neither the name  of Intel Corporation  nor the names of its contributors\n//   may be used to  endorse or promote  products derived  from this  software\n//   without specific prior written permission.\n//\n// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,  BUT NOT LIMITED TO,  THE\n// IMPLIED WARRANTIES OF  MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n// ARE DISCLAIMED.  IN NO EVENT  SHALL THE COPYRIGHT OWNER  OR CONTRIBUTORS BE\n// LIABLE  FOR  ANY  DIRECT,  INDIRECT,  INCIDENTAL,  SPECIAL,  EXEMPLARY,  OR\n// CONSEQUENTIAL  DAMAGES  (INCLUDING,  BUT  NOT LIMITED  TO,  PROCUREMENT  OF\n// SUBSTITUTE GOODS OR SERVICES;  LOSS OF USE,  DATA, OR PROFITS;  OR BUSINESS\n// INTERRUPTION)  HOWEVER CAUSED  AND ON ANY THEORY  OF LIABILITY,  WHETHER IN\n// CONTRACT,  STRICT LIABILITY,  OR TORT  (INCLUDING NEGLIGENCE  OR OTHERWISE)\n// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,  EVEN IF ADVISED OF THE\n// POSSIBILITY OF SUCH DAMAGE.\n/*\n * @file errors.c\n *\n * @brief fpga error reporting\n *\n */\n#include <getopt.h>\n#include <stdbool.h>\n#include <stdio.h>\n#include <string.h>\n#include <stdlib.h>\n\n#include \"fpgainfo.h\"\n#include \"safe_string/safe_string.h\"\n#include <opae/properties.h>\n#include \"errors.h\"\n\n#define FPGA_BIT_IS_SET(val, index) (((val) >> (index)) & 1)\n\nconst char *supported_verbs[] = {\"all\", \"fme\", \"port\"};\nenum verbs_index { VERB_ALL = 0, VERB_FME, VERB_PORT, VERB_MAX };\n\n#define FME_ERROR_COUNT 7\nstatic const char *const FME_ERROR[FME_ERROR_COUNT] = {\n\t\"Fabric error detected\",\n\t\"Fabric fifo under / overflow error detected\",\n\t\"KTI CDC Parity Error detected\",\n\t\"KTI CDC Parity Error detected\",\n\t\"IOMMU Parity error detected\",\n\t\"AFU PF/VF access mismatch detected\",\n\t\"Indicates an MBP event error detected\"};\n\n#define PCIE0_ERROR_COUNT 10\nstatic const char *const PCIE0_ERROR[PCIE0_ERROR_COUNT] = {\n\t\"TLP format/type error detected\",   \"TTLP MW address error detected\",\n\t\"TLP MW length error detected\",     \"TLP MR address error detected\",\n\t\"TLP MR length error detected\",     \"TLP CPL tag error detected\",\n\t\"TLP CPL status error detected\",    \"TLP CPL timeout error detected\",\n\t\"CCI bridge parity error detected\", \"TLP with EP  error  detected\"};\n\n#define PCIE1_ERROR_COUNT 10\nstatic const char *const PCIE1_ERROR[PCIE1_ERROR_COUNT] = {\n\t\"TLP format/type error detected\",   \"TTLP MW address error detected\",\n\t\"TLP MW length error detected\",     \"TLP MR address error detected\",\n\t\"TLP MR length error detected\",     \"TLP CPL tag error detected\",\n\t\"TLP CPL status error detected\",    \"TLP CPL timeout error detected\",\n\t\"CCI bridge parity error detected\", \"TLP with EP  error  detected\"};\n\n#define NONFATAL_ERROR_COUNT 13\nstatic const char *const NONFATAL_ERROR[NONFATAL_ERROR_COUNT] = {\n\t\"Temperature threshold triggered AP1 detected\",\n\t\"Temperature threshold triggered AP2 detected\",\n\t\"PCIe error detected\",\n\t\"AFU port Fatal error detected\",\n\t\"ProcHot event error detected\",\n\t\"AFU PF/VF access mismatch error detected\",\n\t\"Injected Warning Error detected\",\n\t\"Reserved\",\n\t\"Reserved\",\n\t\"Temperature threshold triggered AP6 detected\",\n\t\"Power threshold triggered AP1 error detected\",\n\t\"Power threshold triggered AP2 error detected\",\n\t\"MBP event error detected\"};\n\n#define CATFATAL_ERROR_COUNT 12\nstatic const char *const CATFATAL_ERROR[CATFATAL_ERROR_COUNT] = {\n\t\"KTI link layer error detected.\",\n\t\"tag-n-cache error detected.\",\n\t\"CCI error detected.\",\n\t\"KTI protocol error detected.\",\n\t\"Fatal DRAM error detected\",\n\t\"IOMMU fatal parity error detected.\",\n\t\"Fabric fatal error detected\",\n\t\"Poison error from any of PCIe ports detected\",\n\t\"Injected Fatal Error detected\",\n\t\"Catastrophic CRC error detected\",\n\t\"Catastrophic thermal runaway event detected\",\n\t\"Injected Catastrophic Error detected\"};\n\n#define INJECT_ERROR_COUNT 3\nstatic const char *const INJECT_ERROR[INJECT_ERROR_COUNT] = {\n\t\"Set Catastrophic  error .\", \"Set Fatal error.\",\n\t\"Ser Non-fatal error .\"};\n\n#define PORT_ERROR_COUNT 60\nstatic const char *const PORT_ERROR[PORT_ERROR_COUNT] = {\n\t// 0\n\t\"Tx Channel 0 overflow error detected.\",\n\t\"Tx Channel 0 invalid request encoding error detected.\",\n\t\"Tx Channel 0 cl_len=3 not supported error detected.\",\n\t\"Tx Channel 0 request with cl_len=2 does NOT have a 2CL aligned address error detected.\",\n\t\"Tx Channel 0 request with cl_len=4 does NOT have a 4CL aligned address error detected.\",\n\t\"RSVD.\",\n\t\"RSVD.\",\n\t\"RSVD.\",\n\t\"RSVD.\",\n\t\"AFU MMIO RD received while PORT is in reset error detected\",\n\t// 10\n\t\"AFU MMIO WR received while PORT is in reset error detected\",\n\t\"RSVD.\",\n\t\"RSVD.\",\n\t\"RSVD.\",\n\t\"RSVD.\",\n\t\"RSVD.\",\n\t\"Tx Channel 1 invalid request encoding error detected\",\n\t\"Tx Channel 1 cl_len=3 not supported error detected.\",\n\t\"Tx Channel 1 request with cl_len=2 does NOT have a 2CL aligned address error detected\",\n\t\"Tx Channel 1 request with cl_len=4 does NOT have a 4CL aligned address error detected\",\n\t// 20\n\t\"Tx Channel 1 insufficient data payload Error detected\",\n\t\"Tx Channel 1 data payload overrun error detected\",\n\t\"Tx Channel 1 incorrect address on subsequent payloads error detected\",\n\t\"Tx Channel 1 Non-zero SOP detected for requests!=WrLine_* error detected\",\n\t\"Tx Channel 1 SOP expected to be 0 for req_type!=WrLine_*\",\n\t\"Tx Channel 1 Illegal VC_SEL. Atomic request is only supported on VL0 error detected\",\n\t\"RSVD.\",\n\t\"RSVD.\",\n\t\"RSVD.\",\n\t\"RSVD.\",\n\t// 30\n\t\"RSVD.\",\n\t\"RSVD.\",\n\t\"MMIO TimedOut error detected\",\n\t\"Tx Channel 2 fifo overflo error detected\",\n\t\"MMIO Read response received, with no matching request pending error detected\",\n\t\"RSVD.\",\n\t\"RSVD.\",\n\t\"RSVD.\",\n\t\"RSVD.\",\n\t\"RSVD.\",\n\t// 40\n\t\"Number of pending requests: counter overflow error detected\",\n\t\"Request with Address violating SMM range error detected\",\n\t\"Request with Address violating second SMM range error detected\",\n\t\"Request with Address violating ME stolen range\",\n\t\"Request with Address violating Generic protected range error detected \",\n\t\"Request with Address violating Legacy Range Low error detected\",\n\t\"Request with Address violating Legacy Range High error detected\",\n\t\"Request with Address violating VGA memory range error detected\",\n\t\"Page Fault error detected\",\n\t\"PMR Erro error detected\",\n\t// 50\n\t\"AP6 event detected\",\n\t\"VF FLR detected on port when PORT configured in PF access mode error detected \",\n\t\"RSVD.\",\n\t\"RSVD.\",\n\t\"RSVD.\",\n\t\"RSVD.\",\n\t\"Tx Channel 1 byte_len cannot be zero\",\n\t\"Tx Channel 1 illegal operation: sum of byte_len and byte_start should be less than or equal to 64\",\n\t\"Tx Channel 1 illegal operation: cl_len cannot be non-zero when mode is eMOD_BYTE\",\n\t\"Tx Channel 1 byte_len and byte_start should be zero when mode is not eMOD_BYTE\"\n};\n\n/*\n * errors command configuration, set during parse_args()\n */\nstatic struct errors_config {\n\tbool clear;\n\tint force_count;\n\tenum verbs_index which;\n\tint help_only;\n} errors_config = {.clear = false, .which = VERB_ALL, .help_only = false};\n\n/*\n * Print help\n */\nvoid errors_help(void)\n{\n\tunsigned int i;\n\n\tprintf(\"\\nPrint and clear errors\\n\"\n\t       \"        fpgainfo errors [-h] [-c] {\");\n\tprintf(\"%s\", supported_verbs[0]);\n\tfor (i = 1; i < sizeof(supported_verbs) / sizeof(supported_verbs[0]);\n\t     i++) {\n\t\tprintf(\",%s\", supported_verbs[i]);\n\t}\n\tprintf(\"}\\n\\n\"\n\t       \"                -h,--help           Print this help\\n\"\n\t       \"                -c,--clear          Clear all errors\\n\"\n\t       \"                --force             Retry clearing errors 64 times\\n\"\n\t       \"                                    to clear certain error conditions\\n\"\n\t       \"\\n\");\n\terrors_config.help_only = true;\n}\n\n#define ERRORS_GETOPT_STRING \":chf\"\nint parse_error_args(int argc, char *argv[])\n{\n\toptind = 0;\n\tstruct option longopts[] = {\n\t\t{\"clear\", no_argument, NULL, 'c'},\n\t\t{\"force\", no_argument, NULL, 'f'},\n\t\t{\"help\", no_argument, NULL, 'h'},\n\t\t{0, 0, 0, 0},\n\t};\n\n\tint getopt_ret;\n\tint option_index;\n\terrors_config.force_count = 1;\n\n\twhile (-1\n\t       != (getopt_ret = getopt_long(argc, argv, ERRORS_GETOPT_STRING,\n\t\t\t\t\t    longopts, &option_index))) {\n\t\tconst char *tmp_optarg = optarg;\n\n\t\tif ((optarg) && ('=' == *tmp_optarg)) {\n\t\t\t++tmp_optarg;\n\t\t}\n\n\t\tswitch (getopt_ret) {\n\t\tcase 'c': /* clear */\n\t\t\terrors_config.clear = true;\n\t\t\tbreak;\n\n\t\tcase 'f': /* Force */\n\t\t\terrors_config.clear = true;\n\t\t\terrors_config.force_count = 64;\n\t\t\tbreak;\n\n\t\tcase 'h': /* help */\n\t\t\terrors_help();\n\t\t\treturn -1;\n\n\t\tcase ':': /* missing option argument */\n\t\t\tOPAE_ERR(\"Missing option argument\\n\");\n\t\t\terrors_help();\n\t\t\treturn -1;\n\n\t\tcase '?':\n\t\tdefault: /* invalid option */\n\t\t\tOPAE_ERR(\"Invalid cmdline options\\n\");\n\t\t\terrors_help();\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\t// The word after 'errors' should be what to operate on (\"all\", \"fme\",\n\t// or \"port\")\n\toptind++;\n\tif (argc < optind + 1) {\n\t\tOPAE_ERR(\"Not enough parameters\\n\");\n\t\terrors_help();\n\t\treturn -1;\n\t}\n\n\tint cmp = 0;\n\tif ((optind < argc) && \n\t\tstrcmp_s(argv[optind - 1], RSIZE_MAX_STR, \"errors\", &cmp) == EOK &&\n\t\tcmp == 0) {\n\t\tchar *verb = argv[optind];\n\t\tsize_t idx = str_in_list(verb, supported_verbs, VERB_MAX);\n\t\tif (idx < VERB_MAX) {\n\t\t\terrors_config.which = idx;\n\t\t} else {\n\t\t\tOPAE_ERR(\"Not a valid errors resource spec: %s\\n\", verb);\n\t\t\terrors_help();\n\t\t\treturn -1;\n\t\t}\n\t} else {\n\t\tOPAE_ERR(\"Not a valid errors resource spec: %s\\n\",\n\t\t\targv[optind - 1]);\n\t\terrors_help();\n\t\treturn -1;\n\t}\n\n\treturn 0;\n}\n\nfpga_result errors_filter(fpga_properties *filter, int argc, char *argv[])\n{\n\tfpga_result res = FPGA_OK;\n\tif (0 == parse_error_args(argc, argv)) {\n\t\tswitch (errors_config.which) {\n\t\tcase VERB_FME:\n\t\t\tres = fpgaPropertiesSetObjectType(*filter, FPGA_DEVICE);\n\t\t\tON_FPGAINFO_ERR_GOTO(res, out,\n\t\t\t\t\t     \"setting type to FPGA_DEVICE\");\n\t\t\tbreak;\n\t\tcase VERB_PORT:\n\t\t\tres = fpgaPropertiesSetObjectType(*filter,\n\t\t\t\t\t\t\t  FPGA_ACCELERATOR);\n\t\t\tON_FPGAINFO_ERR_GOTO(\n\t\t\t\tres, out, \"setting type to FPGA_ACCELERATOR\");\n\t\t\tbreak;\n\t\tcase VERB_ALL:\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\nout:\n\treturn res;\n}\n\nstatic void print_errors_info(fpga_token token, fpga_properties props,\n\t\t\t      struct fpga_error_info *errinfos,\n\t\t\t      uint32_t num_errors)\n{\n\tint i;\n\tint j;\n\tfpga_result res = FPGA_OK;\n\tfpga_objtype objtype;\n\tconst char *const *error_string = NULL;\n\tint size = 0;\n\n\tif ((NULL == errinfos) || (0 == num_errors)) {\n\t\treturn;\n\t}\n\n\tif (errors_config.clear) {\n\t\tfor (i = 0; i < errors_config.force_count; i++) {\n\t\t\tfpgaClearAllErrors(token);\n\t\t}\n\t}\n\n\tres = fpgaPropertiesGetObjectType(props, &objtype);\n\tfpgainfo_print_err(\"reading objtype from properties\", res);\n\n\tif (((VERB_ALL == errors_config.which)\n\t     || (VERB_FME == errors_config.which))\n\t    && (FPGA_DEVICE == objtype)) {\n\t\tfpgainfo_print_common(\"//****** FME ERRORS ******//\", props);\n\n\t\tfor (i = 0; i < (int)num_errors; i++) {\n\t\t\tuint64_t error_value = 0;\n\n\t\t\tres = fpgaReadError(token, i, &error_value);\n\t\t\tfpgainfo_print_err(\"reading error for FME\", res);\n\n\t\t\tprintf(\"%-32s : 0x%\" PRIX64 \"\\n\", errinfos[i].name,\n\t\t\t       error_value);\n\n\t\t\tint cmp = 0;\n\t\t\tif (strcmp_s(errinfos[i].name, RSIZE_MAX_STR, \n\t\t\t\t    \"Errors\", &cmp) == EOK && cmp == 0) {\n\t\t\t\tsize = FME_ERROR_COUNT;\n\t\t\t\terror_string = FME_ERROR;\n\t\t\t} else if (strcmp_s(errinfos[i].name, RSIZE_MAX_STR,\n\t\t\t\t    \"Next Error\", &cmp) == EOK && cmp == 0) {\n\t\t\t\tsize = 0;\n\t\t\t\terror_string = NULL;\n\t\t\t} else if (strcmp_s(errinfos[i].name, RSIZE_MAX_STR,\n\t\t\t\t    \"First Error\", &cmp) == EOK && cmp == 0) {\n\t\t\t\tsize = 0;\n\t\t\t\terror_string = NULL;\n\t\t\t} else if (strcmp_s(errinfos[i].name, RSIZE_MAX_STR,\n\t\t\t\t    \"PCIe0 Errors\", &cmp) == EOK && cmp == 0) {\n\t\t\t\tsize = PCIE0_ERROR_COUNT;\n\t\t\t\terror_string = PCIE0_ERROR;\n\t\t\t} else if (strcmp_s(errinfos[i].name, RSIZE_MAX_STR,\n\t\t\t\t    \"Inject Error\", &cmp) == EOK && cmp == 0) {\n\t\t\t\tsize = INJECT_ERROR_COUNT;\n\t\t\t\terror_string = INJECT_ERROR;\n\t\t\t} else if (strcmp_s(errinfos[i].name, RSIZE_MAX_STR,\n\t\t\t\t    \"Catfatal Errors\", &cmp) == EOK && cmp == 0) {\n\t\t\t\tsize = CATFATAL_ERROR_COUNT;\n\t\t\t\terror_string = CATFATAL_ERROR;\n\t\t\t} else if (strcmp_s(errinfos[i].name, RSIZE_MAX_STR,\n\t\t\t\t    \"Nonfatal Errors\", &cmp) == EOK && cmp == 0) {\n\t\t\t\tsize = NONFATAL_ERROR_COUNT;\n\t\t\t\terror_string = NONFATAL_ERROR;\n\t\t\t} else if (strcmp_s(errinfos[i].name, RSIZE_MAX_STR,\n\t\t\t\t    \"PCIe1 Errors\", &cmp) == EOK && cmp == 0) {\n\t\t\t\tsize = PCIE1_ERROR_COUNT;\n\t\t\t\terror_string = PCIE1_ERROR;\n\t\t\t}\n\n\t\t\tfor (j = 0; (j < size) && (NULL != error_string); j++) {\n\t\t\t\tif (FPGA_BIT_IS_SET(error_value, j)) {\n\t\t\t\t\tprintf(\"\\t %s \\n\", error_string[j]);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else if (((VERB_ALL == errors_config.which)\n\t\t    || (VERB_PORT == errors_config.which))\n\t\t   && (FPGA_ACCELERATOR == objtype)) {\n\t\tfpgainfo_print_common(\"//****** PORT ERRORS ******//\", props);\n\n\t\tfor (i = 0; i < (int)num_errors; i++) {\n\t\t\tuint64_t error_value = 0;\n\t\t\tres = fpgaReadError(token, i, &error_value);\n\t\t\tfpgainfo_print_err(\"reading error for PORT\", res);\n\n\t\t\tprintf(\"%-32s : 0x%\" PRIX64 \"\\n\", errinfos[i].name,\n\t\t\t       error_value);\n\n\t\t\tint cmp = 0;\n\t\t\tif (strcmp_s(errinfos[i].name, RSIZE_MAX_STR,\n\t\t\t\t    \"Errors\", &cmp) == EOK && cmp == 0) {\n\t\t\t\tsize = PORT_ERROR_COUNT;\n\t\t\t\terror_string = PORT_ERROR;\n\t\t\t} else if (strcmp_s(errinfos[i].name, RSIZE_MAX_STR,\n\t\t\t\t    \"First Malformed Req\", &cmp) == EOK && cmp == 0) {\n\t\t\t\tsize = 0;\n\t\t\t\terror_string = NULL;\n\t\t\t} else if (strcmp_s(errinfos[i].name, RSIZE_MAX_STR,\n\t\t\t\t    \"First Error\", &cmp) == EOK && cmp == 0) {\n\t\t\t\tsize = 0;\n\t\t\t\terror_string = NULL;\n\t\t\t}\n\n\t\t\tfor (j = 0; (j < size) && (NULL != error_string); j++) {\n\t\t\t\tif (FPGA_BIT_IS_SET(error_value, j)) {\n\t\t\t\t\tprintf(\"\\t %s \\n\", error_string[j]);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n\nfpga_result errors_command(fpga_token *tokens, int num_tokens, int argc,\n\t\t\t   char *argv[])\n{\n\t(void)argc;\n\t(void)argv;\n\tfpga_result res = FPGA_OK;\n\tfpga_properties props;\n\tstruct fpga_error_info *errinfos = NULL;\n\n\tif (errors_config.help_only) {\n\t\treturn res;\n\t}\n\n\tint i = 0;\n\tfor (i = 0; i < num_tokens; ++i) {\n\t\tuint32_t num_errors;\n\n\t\tres = fpgaGetProperties(tokens[i], &props);\n\t\tif (res == FPGA_OK) {\n\t\t\tres = fpgaPropertiesGetNumErrors(props, &num_errors);\n\t\t\tfpgainfo_print_err(\"reading errors from properties\", res);\n\n\t\t\tif (num_errors != 0) {\n\t\t\t\tint j;\n\t\t\t\terrinfos = (struct fpga_error_info *)calloc(\n\t\t\t\t\tnum_errors, sizeof(*errinfos));\n\t\t\t\tif (!errinfos) {\n\t\t\t\t\tres = FPGA_NO_MEMORY;\n\t\t\t\t\tOPAE_ERR(\"Error allocating memory\");\n\t\t\t\t\tgoto destroy_and_free;\n\t\t\t\t}\n\n\t\t\t\tfor (j = 0; j < (int)num_errors; j++) {\n\t\t\t\t\tres = fpgaGetErrorInfo(tokens[i], j,\n\t\t\t\t\t\t\t       &errinfos[j]);\n\t\t\t\t\tfpgainfo_print_err(\n\t\t\t\t\t\t\"reading error info structure\", res);\n\t\t\t\t\treplace_chars(errinfos[j].name, '_', ' ');\n\t\t\t\t\tupcase_pci(errinfos[j].name, \n\t\t\t\t\t\t    strnlen_s(errinfos[j].name, RSIZE_MAX_STR));\n\t\t\t\t\tupcase_first(errinfos[j].name);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tprint_errors_info(tokens[i], props, errinfos, num_errors);\n\t\tdestroy_and_free:\n\t\t\tfree(errinfos);\n\t\t\terrinfos = NULL;\n\t\t\tfpgaDestroyProperties(&props);\n\t\t\tif (res == FPGA_NO_MEMORY) {\n\t\t\t    break;\n\t\t\t}\n\t\t} else {\n\t\t\tfpgainfo_print_err(\"reading properties from token\", res);\n\t\t}\n\t}\n\n\treturn res;\n}\n", "idx": 1, "id": 19096, "msg": "Is this needed after all? Looks like the struct was re-defined inside the test file.", "proj": "OPAE-opae-sdk", "lang": "c"}
{"patch": "@@ -93,7 +93,7 @@ public class Docker {\n       throw new WebDriverException(\"Unable to pull container: \" + name);\n     }\n \n-    LOG.info(String.format(\"Pull of %s:%s complete\", name, tag));\n+    LOG.fine(String.format(\"Pull of %s:%s complete\", name, tag));\n \n     return findImage(new ImageNamePredicate(name, tag))\n         .orElseThrow(() -> new DockerException(", "y": 1, "oldf": "// Licensed to the Software Freedom Conservancy (SFC) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The SFC licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\n\npackage org.openqa.selenium.docker;\n\nimport com.google.common.reflect.TypeToken;\nimport org.openqa.selenium.WebDriverException;\nimport org.openqa.selenium.json.Json;\nimport org.openqa.selenium.json.JsonException;\nimport org.openqa.selenium.json.JsonOutput;\nimport org.openqa.selenium.remote.http.HttpHandler;\nimport org.openqa.selenium.remote.http.HttpRequest;\nimport org.openqa.selenium.remote.http.HttpResponse;\n\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Objects;\nimport java.util.Optional;\nimport java.util.function.Predicate;\nimport java.util.logging.Logger;\n\nimport static com.google.common.collect.ImmutableList.toImmutableList;\nimport static java.net.HttpURLConnection.HTTP_OK;\nimport static org.openqa.selenium.json.Json.MAP_TYPE;\nimport static org.openqa.selenium.remote.http.Contents.string;\nimport static org.openqa.selenium.remote.http.Contents.utf8String;\nimport static org.openqa.selenium.remote.http.HttpMethod.GET;\nimport static org.openqa.selenium.remote.http.HttpMethod.POST;\n\npublic class Docker {\n\n  private static final Logger LOG = Logger.getLogger(Docker.class.getName());\n  private static final Json JSON = new Json();\n\n  private final HttpHandler client;\n\n  public Docker(HttpHandler client) {\n    Objects.requireNonNull(client, \"Docker HTTP client must be set.\");\n\n    this.client = req -> {\n      HttpResponse resp = client.execute(req);\n\n      if (resp.getStatus() < 200 && resp.getStatus() > 200) {\n        String value = string(resp);\n        try {\n          Object obj = JSON.toType(value, Object.class);\n          if (obj instanceof Map) {\n            Map<?, ?> map = (Map<?, ?>) obj;\n            String message = map.get(\"message\") instanceof String ?\n                             (String) map.get(\"message\") :\n                             value;\n            throw new RuntimeException(message);\n          }\n\n          throw new RuntimeException(value);\n        } catch (JsonException e) {\n          throw new RuntimeException(value);\n        }\n      }\n\n      return resp;\n    };\n  }\n\n  public Image pull(String name, String tag) {\n    Objects.requireNonNull(name);\n    Objects.requireNonNull(tag);\n\n    findImage(new ImageNamePredicate(name, tag));\n\n    LOG.info(String.format(\"Pulling %s:%s\", name, tag));\n\n    HttpRequest request = new HttpRequest(POST, \"/images/create\")\n        .addQueryParameter(\"fromImage\", name)\n        .addQueryParameter(\"tag\", tag);\n\n    HttpResponse res = client.execute(request);\n    if (res.getStatus() != HTTP_OK) {\n      throw new WebDriverException(\"Unable to pull container: \" + name);\n    }\n\n    LOG.info(String.format(\"Pull of %s:%s complete\", name, tag));\n\n    return findImage(new ImageNamePredicate(name, tag))\n        .orElseThrow(() -> new DockerException(\n            String.format(\"Cannot find image matching: %s:%s\", name, tag)));\n  }\n\n  public List<Image> listImages() {\n    LOG.fine(\"Listing images\");\n    HttpResponse response = client.execute(new HttpRequest(GET, \"/images/json\"));\n\n    List<ImageSummary> images =\n        JSON.toType(string(response), new TypeToken<List<ImageSummary>>() {}.getType());\n\n    return images.stream()\n        .map(Image::new)\n        .collect(toImmutableList());\n  }\n\n  public Optional<Image> findImage(Predicate<Image> filter) {\n    Objects.requireNonNull(filter);\n\n    LOG.fine(\"Finding image: \" + filter);\n\n    return listImages().stream()\n        .filter(filter)\n        .findFirst();\n  }\n\n  public Container create(ContainerInfo info) {\n    StringBuilder json = new StringBuilder();\n\n    try (JsonOutput output = JSON.newOutput(json)) {\n      output.setPrettyPrint(false);\n      output.write(info);\n    }\n\n    LOG.info(\"Creating container: \" + json);\n\n    HttpRequest request = new HttpRequest(POST, \"/containers/create\");\n    request.setContent(utf8String(json));\n\n    HttpResponse response = client.execute(request);\n\n    Map<String, Object> toRead = JSON.toType(string(response), MAP_TYPE);\n\n    return new Container(client, new ContainerId((String) toRead.get(\"Id\")));\n  }\n\n}\n", "idx": 1, "id": 17123, "msg": "Waiting for the pull takes a long time. This message informs the user that at least one of the images being pulled is available. Please leave.", "proj": "SeleniumHQ-selenium", "lang": "py"}
{"patch": "@@ -9,12 +9,12 @@ namespace Microsoft.CodeAnalysis.Sarif\n     /// <summary>\n     /// The state of a result relative to a baseline of a previous run.\n     /// </summary>\n-    [GeneratedCode(\"Microsoft.Json.Schema.ToDotNet\", \"0.28.0.0\")]\n     [Flags]\n+    [GeneratedCode(\"Microsoft.Json.Schema.ToDotNet\", \"0.30.0.0\")]\n     public enum SuppressionStates\n     {\n         None,\n-        SuppressedInSource = 0x1,\n-        SuppressedInBaseline = 0x2\n+        SuppressedInSource = 1,\n+        SuppressedInBaseline = 2\n     }\n }", "y": 1, "oldf": "// Copyright (c) Microsoft.  All Rights Reserved.\n// Licensed under the Apache License, Version 2.0.  See License.txt in the project root for license information.\n\nusing System;\nusing System.CodeDom.Compiler;\n\nnamespace Microsoft.CodeAnalysis.Sarif\n{\n    /// <summary>\n    /// The state of a result relative to a baseline of a previous run.\n    /// </summary>\n    [GeneratedCode(\"Microsoft.Json.Schema.ToDotNet\", \"0.28.0.0\")]\n    [Flags]\n    public enum SuppressionStates\n    {\n        None,\n        SuppressedInSource = 0x1,\n        SuppressedInBaseline = 0x2\n    }\n}", "idx": 1, "id": 10780, "msg": "`[Flags]` is now auto-generated by an argument to the `EnumHint`. (The attributes happen to come out in this order. I don't think it's worth controlling the order.) #Resolved", "proj": "microsoft-sarif-sdk", "lang": ".cs"}
{"patch": "@@ -156,6 +156,13 @@ func identifyUID(ctx context.Context, nug normalizedUsernameGetter,\n func identifyUser(ctx context.Context, nug normalizedUsernameGetter,\n \tidentifier identifier, username libkb.NormalizedUsername,\n \tuid keybase1.UID, isPublic bool) error {\n+\n+\t// check to see if identify should be skipped altogether\n+\tei := getExtendedIdentify(ctx)\n+\tif ei.behavior == keybase1.TLFIdentifyBehavior_CHAT_SKIP {\n+\t\treturn nil\n+\t}\n+\n \tvar reason string\n \tif isPublic {\n \t\treason = \"You accessed a public folder.\"", "y": 1, "oldf": "// Copyright 2016 Keybase Inc. All rights reserved.\n// Use of this source code is governed by a BSD\n// license that can be found in the LICENSE file.\n\npackage libkbfs\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"sync\"\n\n\t\"github.com/keybase/client/go/libkb\"\n\t\"github.com/keybase/client/go/protocol/keybase1\"\n\t\"golang.org/x/net/context\"\n\t\"golang.org/x/sync/errgroup\"\n)\n\ntype extendedIdentify struct {\n\tbehavior keybase1.TLFIdentifyBehavior\n\n\t// lock guards userBreaks and tlfBreaks\n\tlock       sync.Mutex\n\tuserBreaks chan keybase1.TLFIdentifyFailure\n\ttlfBreaks  *keybase1.TLFBreak\n}\n\nfunc (ei *extendedIdentify) userBreak(username libkb.NormalizedUsername, uid keybase1.UID, breaks *keybase1.IdentifyTrackBreaks) {\n\tif ei.userBreaks == nil {\n\t\treturn\n\t}\n\n\tei.userBreaks <- keybase1.TLFIdentifyFailure{\n\t\tBreaks: breaks,\n\t\tUser: keybase1.User{\n\t\t\tUid:      uid,\n\t\t\tUsername: string(username),\n\t\t},\n\t}\n}\n\nfunc (ei *extendedIdentify) makeTlfBreaksIfNeeded(\n\tctx context.Context, numUserInTlf int) error {\n\tif ei.userBreaks == nil {\n\t\treturn nil\n\t}\n\n\tei.lock.Lock()\n\tdefer ei.lock.Unlock()\n\n\tb := &keybase1.TLFBreak{}\n\tfor i := 0; i < numUserInTlf; i++ {\n\t\tselect {\n\t\tcase ub, ok := <-ei.userBreaks:\n\t\t\tif !ok {\n\t\t\t\treturn errors.New(\"makeTlfBreaksIfNeeded called on extendedIdentify\" +\n\t\t\t\t\t\" with closed userBreaks channel.\")\n\t\t\t}\n\t\t\tif ub.Breaks != nil {\n\t\t\t\tb.Breaks = append(b.Breaks, ub)\n\t\t\t}\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\t}\n\t}\n\tei.tlfBreaks = b\n\n\treturn nil\n}\n\n// getTlfBreakOrBust returns a keybase1.TLFBreak. This should only be called\n// for behavior.WarningInsteadOfErrorOnBrokenTracks() == true, and after\n// makeTlfBreaksIfNeeded is called, to make sure user proof breaks get\n// populated in GUI mode.\n//\n// If called otherwise, we don't panic here anymore, since we can't panic on\n// nil ei.tlfBreaks. The reason is if a previous successful identify has\n// already happened recently, it could cause this identify to be skipped, which\n// means ei.tlfBreaks is never populated. In this case, it's safe to return an\n// empty keybase1.TLFBreak.\nfunc (ei *extendedIdentify) getTlfBreakAndClose() keybase1.TLFBreak {\n\tei.lock.Lock()\n\tdefer ei.lock.Unlock()\n\n\tif ei.userBreaks != nil {\n\t\tclose(ei.userBreaks)\n\t\tei.userBreaks = nil\n\t}\n\tif ei.tlfBreaks != nil {\n\t\treturn *ei.tlfBreaks\n\t}\n\n\treturn keybase1.TLFBreak{}\n}\n\n// ctxExtendedIdentifyKeyType is a type for the context key for using\n// extendedIdentify\ntype ctxExtendedIdentifyKeyType int\n\nconst (\n\t// ctxExtendedIdentifyKeyType is a context key for using extendedIdentify\n\tctxExtendedIdentifyKey ctxExtendedIdentifyKeyType = iota\n)\n\n// ExtendedIdentifyAlreadyExists is returned when makeExtendedIdentify is\n// called on a context already with extendedIdentify.\ntype ExtendedIdentifyAlreadyExists struct{}\n\nfunc (e ExtendedIdentifyAlreadyExists) Error() string {\n\treturn \"extendedIdentify already exists\"\n}\n\nfunc makeExtendedIdentify(ctx context.Context,\n\tbehavior keybase1.TLFIdentifyBehavior) (context.Context, error) {\n\tif _, ok := ctx.Value(ctxExtendedIdentifyKey).(*extendedIdentify); ok {\n\t\treturn nil, ExtendedIdentifyAlreadyExists{}\n\t}\n\n\tif !behavior.WarningInsteadOfErrorOnBrokenTracks() {\n\t\treturn NewContextReplayable(ctx, func(ctx context.Context) context.Context {\n\t\t\treturn context.WithValue(ctx, ctxExtendedIdentifyKey, &extendedIdentify{\n\t\t\t\tbehavior: behavior,\n\t\t\t})\n\t\t}), nil\n\t}\n\n\tch := make(chan keybase1.TLFIdentifyFailure)\n\treturn NewContextReplayable(ctx, func(ctx context.Context) context.Context {\n\t\treturn context.WithValue(ctx, ctxExtendedIdentifyKey, &extendedIdentify{\n\t\t\tbehavior:   behavior,\n\t\t\tuserBreaks: ch,\n\t\t})\n\t}), nil\n}\n\nfunc getExtendedIdentify(ctx context.Context) (ei *extendedIdentify) {\n\tif ei, ok := ctx.Value(ctxExtendedIdentifyKey).(*extendedIdentify); ok {\n\t\treturn ei\n\t}\n\treturn &extendedIdentify{\n\t\tbehavior: keybase1.TLFIdentifyBehavior_DEFAULT_KBFS,\n\t}\n}\n\n// identifyUID performs identify based only on UID. It should be\n// used only if the username is not known - as e.g. when rekeying.\nfunc identifyUID(ctx context.Context, nug normalizedUsernameGetter,\n\tidentifier identifier, uid keybase1.UID, isPublic bool) error {\n\tusername, err := nug.GetNormalizedUsername(ctx, uid)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn identifyUser(ctx, nug, identifier, username, uid, isPublic)\n}\n\n// identifyUser is the preferred way to run identifies.\nfunc identifyUser(ctx context.Context, nug normalizedUsernameGetter,\n\tidentifier identifier, username libkb.NormalizedUsername,\n\tuid keybase1.UID, isPublic bool) error {\n\tvar reason string\n\tif isPublic {\n\t\treason = \"You accessed a public folder.\"\n\t} else {\n\t\treason = fmt.Sprintf(\"You accessed a private folder with %s.\", username.String())\n\t}\n\tuserInfo, err := identifier.Identify(ctx, username.String(), reason)\n\tif err != nil {\n\t\t// Convert libkb.NoSigChainError into one we can report.  (See\n\t\t// KBFS-1252).\n\t\tif _, ok := err.(libkb.NoSigChainError); ok {\n\t\t\treturn NoSigChainError{username}\n\t\t}\n\t\treturn err\n\t}\n\tif userInfo.Name != username {\n\t\treturn fmt.Errorf(\"Identify returned name=%s, expected %s\", userInfo.Name, username)\n\t}\n\tif userInfo.UID != uid {\n\t\treturn fmt.Errorf(\"Identify returned uid=%s, expected %s\", userInfo.UID, uid)\n\t}\n\treturn nil\n}\n\n// identifyUserToChan calls identifyUser and plugs the result into the error channnel.\nfunc identifyUserToChan(ctx context.Context, nug normalizedUsernameGetter,\n\tidentifier identifier, name libkb.NormalizedUsername, uid keybase1.UID,\n\tisPublic bool, errChan chan error) {\n\terrChan <- identifyUser(ctx, nug, identifier, name, uid, isPublic)\n}\n\n// identifyUsers identifies the users in the given maps.\nfunc identifyUsers(ctx context.Context, nug normalizedUsernameGetter,\n\tidentifier identifier, users map[keybase1.UID]libkb.NormalizedUsername,\n\tpublic bool) error {\n\teg, ctx := errgroup.WithContext(ctx)\n\n\t// TODO: limit the number of concurrent identifies?\n\t// TODO: implement a version of errgroup with limited concurrency.\n\tfor uid, name := range users {\n\t\t// Capture range variables.\n\t\tuid, name := uid, name\n\t\teg.Go(func() error {\n\t\t\treturn identifyUser(ctx, nug, identifier, name, uid, public)\n\t\t})\n\t}\n\n\treturn eg.Wait()\n}\n\n// identifyUserList identifies the users in the given list.\n// Only use this when the usernames are not known - like when rekeying.\nfunc identifyUserList(ctx context.Context, nug normalizedUsernameGetter, identifier identifier, uids []keybase1.UID, public bool) error {\n\teg, ctx := errgroup.WithContext(ctx)\n\n\t// TODO: limit the number of concurrent identifies?\n\t// TODO: implement concurrency limited version of errgroup.\n\tfor _, uid := range uids {\n\t\t// Capture range variable.\n\t\tuid := uid\n\t\teg.Go(func() error {\n\t\t\treturn identifyUID(ctx, nug, identifier, uid, public)\n\t\t})\n\t}\n\n\treturn eg.Wait()\n}\n\n// identifyUsersForTLF is a helper for identifyHandle for easier testing.\nfunc identifyUsersForTLF(ctx context.Context, nug normalizedUsernameGetter,\n\tidentifier identifier, users map[keybase1.UID]libkb.NormalizedUsername,\n\tpublic bool) error {\n\teg, ctx := errgroup.WithContext(ctx)\n\n\teg.Go(func() error {\n\t\tei := getExtendedIdentify(ctx)\n\t\treturn ei.makeTlfBreaksIfNeeded(ctx, len(users))\n\t})\n\n\teg.Go(func() error {\n\t\treturn identifyUsers(ctx, nug, identifier, users, public)\n\t})\n\n\treturn eg.Wait()\n}\n\n// identifyHandle identifies the canonical names in the given handle.\nfunc identifyHandle(ctx context.Context, nug normalizedUsernameGetter, identifier identifier, h *TlfHandle) error {\n\treturn identifyUsersForTLF(ctx, nug, identifier,\n\t\th.ResolvedUsersMap(), h.IsPublic())\n}\n", "idx": 1, "id": 16329, "msg": "We usually avoid blank lines at the start of functions.", "proj": "keybase-kbfs", "lang": "go"}
{"patch": "@@ -58,6 +58,14 @@ Puppet::Functions.create_function(:run_task) do\n     end || (raise Puppet::ParseError, 'Task parameters did not match')\n     task = task_signature.task\n \n+    if executor.noop\n+      if task.supports_noop\n+        use_args['_noop'] = true\n+      else\n+        raise Puppet::ParseError, 'Task does not support noop'\n+      end\n+    end\n+\n     # Ensure that that given targets are all Target instances\n     targets = [targets] unless targets.is_a?(Array)\n     targets = targets.flatten.map { |t| t.is_a?(String) ? Puppet::Pops::Types::TypeFactory.target.create(t) : t }", "y": 1, "oldf": "# Runs a given instance of a `Task` on the given set of targets and returns the result from each.\n#\n# * This function does nothing if the list of targets is empty.\n# * It is possible to run on the target 'localhost'\n# * A target is a String with a targets's hostname or a Target.\n# * The returned value contains information about the result per target.\n#\nPuppet::Functions.create_function(:run_task) do\n  local_types do\n    type 'TargetOrTargets = Variant[String[1], Target, Array[TargetOrTargets]]'\n  end\n\n  dispatch :run_task do\n    param 'String[1]', :task_name\n    param 'TargetOrTargets', :targets\n    optional_param 'Hash[String[1], Any]', :task_args\n  end\n\n  # this is used from 'bolt task run'\n  dispatch :run_task_raw do\n    param 'String[1]', :task_name\n    param 'TargetOrTargets', :targets\n    optional_param 'Hash[String[1], Any]', :task_args\n    block_param\n  end\n\n  def run_task(task_name, targets, task_args = nil)\n    Puppet::Pops::Types::ExecutionResult.from_bolt(\n      run_task_raw(task_name, targets, task_args)\n    )\n  end\n\n  def run_task_raw(task_name, targets, task_args = nil, &block)\n    unless Puppet[:tasks]\n      raise Puppet::ParseErrorWithIssue.from_issue_and_stack(\n        Puppet::Pops::Issues::TASK_OPERATION_NOT_SUPPORTED_WHEN_COMPILING, operation: 'run_task'\n      )\n    end\n\n    # TODO: use the compiler injection once PUP-8237 lands\n    task_signature = Puppet::Pal::ScriptCompiler.new(closure_scope.compiler).task_signature(task_name)\n    if task_signature.nil?\n      raise Puppet::ParseErrorWithIssue.from_issue_and_stack(\n        Puppet::Pops::Issues::UNKNOWN_TASK, type_name: task_name\n      )\n    end\n\n    executor = Puppet.lookup(:bolt_executor) { nil }\n    unless executor && Puppet.features.bolt?\n      raise Puppet::ParseErrorWithIssue.from_issue_and_stack(\n        Puppet::Pops::Issues::TASK_MISSING_BOLT, action: _('run a task')\n      )\n    end\n\n    use_args = task_args.nil? ? {} : task_args\n    task_signature.runnable_with?(use_args) do |mismatch|\n      raise Puppet::ParseError, mismatch\n    end || (raise Puppet::ParseError, 'Task parameters did not match')\n    task = task_signature.task\n\n    # Ensure that that given targets are all Target instances\n    targets = [targets] unless targets.is_a?(Array)\n    targets = targets.flatten.map { |t| t.is_a?(String) ? Puppet::Pops::Types::TypeFactory.target.create(t) : t }\n    if targets.empty?\n      call_function('debug', \"Simulating run of task #{task.name} - no targets given - no action taken\")\n      Puppet::Pops::EMPTY_HASH\n    else\n      # TODO: Awaits change in the executor, enabling it receive Target instances\n      hosts = targets.map(&:host)\n\n      # TODO: separate handling of default since it's platform specific\n      input_method = task.input_method\n\n      executor.run_task(executor.from_uris(hosts), task.executable, input_method, use_args, &block)\n    end\n  end\nend\n", "idx": 1, "id": 7260, "msg": "I think logic will have to move to bolt since the vague discussions around bolt run plan --noop is that it would just skip any tasks that don't support_noop rather than error. This is fine until we actually elaborate that though.", "proj": "puppetlabs-bolt", "lang": "rb"}
{"patch": "@@ -175,7 +175,7 @@ class FastTemporalMemory(TemporalMemory):\n     \"\"\"\n     self._validateCell(cell)\n \n-    return int(cell.idx / self.cellsPerColumn)\n+    return int(cell / self.cellsPerColumn)\n \n \n   def cellsForColumn(self, column):", "y": 1, "oldf": "# ----------------------------------------------------------------------\n# Numenta Platform for Intelligent Computing (NuPIC)\n# Copyright (C) 2014, Numenta, Inc.  Unless you have an agreement\n# with Numenta, Inc., for a separate license for this software code, the\n# following terms and conditions apply:\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU Affero Public License version 3 as\n# published by the Free Software Foundation.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n# See the GNU Affero Public License for more details.\n#\n# You should have received a copy of the GNU Affero Public License\n# along with this program.  If not, see http://www.gnu.org/licenses.\n#\n# http://numenta.org/licenses/\n# ----------------------------------------------------------------------\n\n\"\"\"\nTemporal Memory implementation in Python.\n\"\"\"\n\nfrom nupic.research.temporal_memory import TemporalMemory\nfrom nupic.bindings.algorithms import Connections, ConnectionsCell\n\n\n\nclass FastTemporalMemory(TemporalMemory):\n  \"\"\"\n  Class implementing the Temporal Memory algorithm.\n\n  Uses C++ Connections data structure for optimization.\n  \"\"\"\n\n  def __init__(self, *args, **kwargs):\n    maxSegmentsPerCell = kwargs.get(\"maxSegmentsPerCell\", 255)\n    maxSynapsesPerSegment = kwargs.get(\"maxSynapsesPerSegment\", 255)\n\n    super(FastTemporalMemory, self).__init__(*args, **kwargs)\n    self.connections = Connections(\n      self.numberOfCells(),\n      maxSegmentsPerCell=maxSegmentsPerCell,\n      maxSynapsesPerSegment=maxSynapsesPerSegment)\n\n\n  def burstColumns(self,\n                   activeColumns,\n                   predictedColumns,\n                   prevActiveCells,\n                   prevWinnerCells,\n                   connections):\n    \"\"\"\n    Phase 2: Burst unpredicted columns.\n\n    Pseudocode:\n\n      - for each unpredicted active column\n        - mark all cells as active\n        - mark the best matching cell as winner cell\n          - (learning)\n            - if it has no matching segment\n              - (optimization) if there are prev winner cells\n                - add a segment to it\n            - mark the segment as learning\n\n    @param activeColumns                   (set)         Indices of active columns in `t`\n    @param predictedColumns                (set)         Indices of predicted columns in `t`\n    @param prevActiveCells                 (set)         Indices of active cells in `t-1`\n    @param prevWinnerCells                 (set)         Indices of winner cells in `t-1`\n    @param connections                     (Connections) Connectivity of layer\n\n    @return (tuple) Contains:\n                      `activeCells`      (set),\n                      `winnerCells`      (set),\n                      `learningSegments` (set)\n    \"\"\"\n    activeCells = set()\n    winnerCells = set()\n    learningSegments = set()\n\n    unpredictedColumns = activeColumns - predictedColumns\n\n    for column in unpredictedColumns:\n      cells = self.cellsForColumn(column)\n      activeCells.update(cells)\n\n      bestSegment = connections.mostActiveSegmentForCells(\n        list(cells), list(prevActiveCells), self.minThreshold)\n\n      if bestSegment is None:\n        bestCell = self.leastUsedCell(cells, connections)\n        if len(prevWinnerCells):\n          bestSegment = connections.createSegment(bestCell)\n      else:\n        # TODO: For some reason, bestSegment.cell is garbage-collected after\n        # this function returns. So we have to use the below hack. Figure out\n        # why and clean up.\n        bestCell = ConnectionsCell(bestSegment.cell.idx)\n\n      winnerCells.add(bestCell)\n\n      if bestSegment:\n        learningSegments.add(bestSegment)\n\n    return activeCells, winnerCells, learningSegments\n\n\n  def computePredictiveCells(self, activeCells, connections):\n    \"\"\"\n    Phase 4: Compute predictive cells due to lateral input\n    on distal dendrites.\n\n    Pseudocode:\n\n      - for each distal dendrite segment with activity >= activationThreshold\n        - mark the segment as active\n        - mark the cell as predictive\n\n      - for each distal dendrite segment with unconnected\n        activity >=  minThreshold\n        - mark the segment as matching\n        - mark the cell as matching\n\n    Forward propagates activity from active cells to the synapses that touch\n    them, to determine which synapses are active.\n\n    @param activeCells (set)         Indices of active cells in `t`\n    @param connections (Connections) Connectivity of layer\n\n    @return (tuple) Contains:\n                      `activeSegments`   (set),\n                      `predictiveCells`  (set),\n                      `matchingSegments` (set),\n                      `matchingCells`    (set)\n    \"\"\"\n    activity = connections.computeActivity(list(activeCells),\n                                           self.connectedPermanence,\n                                           self.activationThreshold)\n    activeSegments = set(connections.activeSegments(activity))\n    predictiveCells = set(connections.activeCells(activity))\n\n    if self.predictedSegmentDecrement > 0:\n      activity = connections.computeActivity(list(activeCells),\n                                             0,\n                                             self.minThreshold)\n\n      matchingSegments = set(connections.activeSegments(activity))\n      matchingCells = set(connections.activeCells(activity))\n    else:\n      matchingSegments = set()\n      matchingCells = set()\n\n    return activeSegments, predictiveCells, matchingSegments, matchingCells\n\n\n  @staticmethod\n  def getCellIndex(cell):\n    return cell.idx\n\n\n  # ==============================\n  # Helper functions\n  # ==============================\n\n  def columnForCell(self, cell):\n    \"\"\"\n    Returns the index of the column that a cell belongs to.\n\n    @param cell (int) Cell index\n\n    @return (int) Column index\n    \"\"\"\n    self._validateCell(cell)\n\n    return int(cell.idx / self.cellsPerColumn)\n\n\n  def cellsForColumn(self, column):\n    \"\"\"\n    Returns the indices of cells that belong to a column.\n\n    @param column (int) Column index\n\n    @return (set) Cell indices\n    \"\"\"\n    self._validateColumn(column)\n\n    start = self.cellsPerColumn * column\n    end = start + self.cellsPerColumn\n    return set([ConnectionsCell(idx) for idx in xrange(start, end)])\n\n\n  def _validateCell(self, cell):\n    \"\"\"\n    Raises an error if cell index is invalid.\n\n    @param cell (int) Cell index\n    \"\"\"\n    if cell.idx >= self.numberOfCells() or cell.idx < 0:\n      raise IndexError(\"Invalid cell\")\n", "idx": 1, "id": 20522, "msg": "Why was this change necessary?", "proj": "numenta-nupic", "lang": "py"}
{"patch": "@@ -127,6 +127,10 @@ class StepDelegatingExecutor(Executor):\n                     running_steps[step.key] = step\n \n             last_check_step_health_time = pendulum.now(\"UTC\")\n+\n+            # Order of events is important here. During an interation, we call handle_event, then get_steps_to_execute,\n+            # then is_complete. get_steps_to_execute updates the state of ActiveExecution, and without it\n+            # is_complete can return true when we're just between steps.\n             while not active_execution.is_complete:\n \n                 if active_execution.check_for_interrupts():", "y": 1, "oldf": "import time\nfrom typing import Dict, List, Optional, cast\n\nimport pendulum\nfrom dagster import check\nfrom dagster.core.events import DagsterEvent, EngineEventData, EventMetadataEntry, log_step_event\nfrom dagster.core.execution.context.system import PlanOrchestrationContext\nfrom dagster.core.execution.plan.plan import ExecutionPlan\nfrom dagster.core.execution.plan.step import ExecutionStep\nfrom dagster.core.execution.retries import RetryMode\nfrom dagster.core.executor.step_delegating.step_handler.base import StepHandler, StepHandlerContext\nfrom dagster.grpc.types import ExecuteStepArgs\n\nfrom ..base import Executor\n\n\nclass StepDelegatingExecutor(Executor):\n    def __init__(\n        self,\n        step_handler: StepHandler,\n        retries: RetryMode,\n        sleep_seconds: Optional[float] = None,\n        check_step_health_interval_seconds: Optional[int] = None,\n    ):\n        self._step_handler = step_handler\n        self._retries = retries\n        self._sleep_seconds = cast(\n            float, check.opt_float_param(sleep_seconds, \"sleep_seconds\", default=0.1)\n        )\n        self._check_step_health_interval_seconds = cast(\n            int,\n            check.opt_int_param(\n                check_step_health_interval_seconds, \"check_step_health_interval_seconds\", default=20\n            ),\n        )\n\n    @property\n    def retries(self):\n        return self._retries\n\n    def _pop_events(self, instance, run_id) -> List[DagsterEvent]:\n        events = instance.logs_after(run_id, self._event_cursor)\n        self._event_cursor += len(events)\n        return [event.dagster_event for event in events if event.is_dagster_event]\n\n    def _get_step_handler_context(\n        self, plan_context, steps, active_execution\n    ) -> StepHandlerContext:\n        return StepHandlerContext(\n            instance=plan_context.plan_data.instance,\n            execute_step_args=ExecuteStepArgs(\n                pipeline_origin=plan_context.reconstructable_pipeline.get_python_origin(),\n                pipeline_run_id=plan_context.pipeline_run.run_id,\n                step_keys_to_execute=[step.key for step in steps],\n                instance_ref=plan_context.plan_data.instance.get_ref(),\n                retry_mode=self.retries.for_inner_plan(),\n                known_state=active_execution.get_known_state(),\n            ),\n            step_tags={step.key: step.tags for step in steps},\n            pipeline_run=plan_context.pipeline_run,\n        )\n\n    def _log_new_events(self, events, plan_context, running_steps):\n        # Note: this could lead to duplicated events if the returned events were already logged\n        # (they shouldn't be)\n        for event in events:\n            log_step_event(\n                plan_context.for_step(running_steps[event.step_key]),\n                event,\n            )\n\n    def execute(self, plan_context: PlanOrchestrationContext, execution_plan: ExecutionPlan):\n        check.inst_param(plan_context, \"plan_context\", PlanOrchestrationContext)\n        check.inst_param(execution_plan, \"execution_plan\", ExecutionPlan)\n\n        self._event_cursor = -1  # pylint: disable=attribute-defined-outside-init\n\n        yield DagsterEvent.engine_event(\n            plan_context,\n            f\"Starting execution with step handler {self._step_handler.name}\",\n            EngineEventData(),\n        )\n\n        with execution_plan.start(retry_mode=self.retries) as active_execution:\n            running_steps: Dict[str, ExecutionStep] = {}\n\n            if plan_context.resume_from_failure:\n                yield DagsterEvent.engine_event(\n                    plan_context,\n                    \"Resuming execution from failure\",\n                    EngineEventData(),\n                )\n\n                prior_events = self._pop_events(\n                    plan_context.instance,\n                    plan_context.run_id,\n                )\n                for dagster_event in prior_events:\n                    yield dagster_event\n\n                possibly_in_flight_steps = active_execution.rebuild_from_events(prior_events)\n                for step in possibly_in_flight_steps:\n\n                    yield DagsterEvent.engine_event(\n                        plan_context,\n                        \"Checking on status of possibly launched steps\",\n                        EngineEventData(),\n                        step.handle,\n                    )\n\n                    # TODO: check if failure event included. For now, hacky assumption that\n                    # we don't log anything on successful check\n                    if self._step_handler.check_step_health(\n                        self._get_step_handler_context(plan_context, [step], active_execution)\n                    ):\n                        # health check failed, launch the step\n                        self._log_new_events(\n                            self._step_handler.launch_step(\n                                self._get_step_handler_context(\n                                    plan_context, [step], active_execution\n                                )\n                            ),\n                            plan_context,\n                            {step.key: step for step in possibly_in_flight_steps},\n                        )\n\n                    running_steps[step.key] = step\n\n            last_check_step_health_time = pendulum.now(\"UTC\")\n            while not active_execution.is_complete:\n\n                if active_execution.check_for_interrupts():\n                    if not plan_context.instance.run_will_resume(plan_context.run_id):\n                        yield DagsterEvent.engine_event(\n                            plan_context,\n                            \"Executor received termination signal, forwarding to steps\",\n                            EngineEventData.interrupted(list(running_steps.keys())),\n                        )\n                        active_execution.mark_interrupted()\n                        for _, step in running_steps.items():\n                            self._log_new_events(\n                                self._step_handler.terminate_step(\n                                    self._get_step_handler_context(\n                                        plan_context, [step], active_execution\n                                    )\n                                ),\n                                plan_context,\n                                running_steps,\n                            )\n\n                    else:\n                        yield DagsterEvent.engine_event(\n                            plan_context,\n                            \"Executor received termination signal, not forwarding to steps because \"\n                            \"run will be resumed\",\n                            EngineEventData(\n                                metadata_entries=[\n                                    EventMetadataEntry.text(\n                                        str(running_steps.keys()), \"steps_in_flight\"\n                                    )\n                                ]\n                            ),\n                        )\n                        active_execution.mark_interrupted()\n\n                    return\n\n                curr_time = pendulum.now(\"UTC\")\n                if (\n                    curr_time - last_check_step_health_time\n                ).total_seconds() >= self._check_step_health_interval_seconds:\n                    last_check_step_health_time = curr_time\n                    for _, step in running_steps.items():\n                        self._log_new_events(\n                            self._step_handler.check_step_health(\n                                self._get_step_handler_context(\n                                    plan_context, [step], active_execution\n                                )\n                            ),\n                            plan_context,\n                            running_steps,\n                        )\n\n                for step in active_execution.get_steps_to_execute():\n                    running_steps[step.key] = step\n                    self._log_new_events(\n                        self._step_handler.launch_step(\n                            self._get_step_handler_context(plan_context, [step], active_execution)\n                        ),\n                        plan_context,\n                        running_steps,\n                    )\n\n                # process skips from failures or uncovered inputs\n                for event in active_execution.plan_events_iterator(plan_context):\n                    yield event\n\n                for dagster_event in self._pop_events(\n                    plan_context.instance,\n                    plan_context.run_id,\n                ):  # type: ignore\n                    yield dagster_event\n                    active_execution.handle_event(dagster_event)\n\n                    if (\n                        dagster_event.is_step_success\n                        or dagster_event.is_step_failure\n                        or dagster_event.is_step_skipped\n                    ):\n                        assert isinstance(dagster_event.step_key, str)\n                        del running_steps[dagster_event.step_key]\n                        active_execution.verify_complete(plan_context, dagster_event.step_key)\n\n                time.sleep(self._sleep_seconds)\n", "idx": 1, "id": 16961, "msg": "Could also consider modifying the ActiveExecution...", "proj": "dagster-io-dagster", "lang": "py"}
{"patch": "@@ -46,13 +46,13 @@ module Bolt\n         @logger = Logging.logger[self]\n       end\n \n-      def with_events(target, callback)\n+      def with_events(target, callback, action)\n         callback&.call(type: :node_start, target: target)\n \n         result = begin\n                    yield\n                  rescue StandardError, NotImplementedError => e\n-                   Bolt::Result.from_exception(target, e)\n+                   Bolt::Result.from_exception(target, e, action: action)\n                  end\n \n         callback&.call(type: :node_result, result: result)", "y": 1, "oldf": "# frozen_string_literal: true\n\nrequire 'logging'\nrequire 'bolt/result'\n\nmodule Bolt\n  module Transport\n    # This class provides the default behavior for Transports. A Transport is\n    # responsible for uploading files and running commands, scripts, and tasks\n    # on Targets.\n    #\n    # Bolt executes work on the Transport in \"batches\". To do that, it calls\n    # the batches() method, which is responsible for dividing the list of\n    # Targets into batches according to how it wants to handle them. It will\n    # then call Transport#batch_task, or the corresponding method for another\n    # operation, passing a list of Targets. The Transport returns a list of\n    # Bolt::Result objects, one per Target. Each batch is executed on a\n    # separate thread, controlled by the `concurrency` setting, so many batches\n    # may be running in parallel.\n    #\n    # The default batch implementation splits the list of Targets into batches\n    # of 1. It then calls run_task(), or a corresponding method for other\n    # operations, passing in the single Target.\n    #\n    # Most Transport implementations, like the SSH and WinRM transports, don't\n    # need to do their own batching, since they only operate on a single Target\n    # at a time. Those Transports can implement the run_task() and related\n    # methods, which will automatically handle running many Targets in\n    # parallel, and will handle publishing start and finish events for each\n    # Target.\n    #\n    # Transports that need their own batching, like the Orch transport, can\n    # instead override the batches() method to split Targets into sets that can\n    # be executed together, and override the batch_task() and related methods\n    # to execute a batch of nodes. In that case, those Transports should accept\n    # a block argument and call it with a :node_start event for each Target\n    # before executing, and a :node_result event for each Target after\n    # execution.\n    class Base\n      STDIN_METHODS       = %w[both stdin].freeze\n      ENVIRONMENT_METHODS = %w[both environment].freeze\n\n      attr_reader :logger\n\n      def initialize\n        @logger = Logging.logger[self]\n      end\n\n      def with_events(target, callback)\n        callback&.call(type: :node_start, target: target)\n\n        result = begin\n                   yield\n                 rescue StandardError, NotImplementedError => e\n                   Bolt::Result.from_exception(target, e)\n                 end\n\n        callback&.call(type: :node_result, result: result)\n        result\n      end\n\n      def provided_features\n        []\n      end\n\n      def default_input_method(_executable)\n        'both'\n      end\n\n      def select_implementation(target, task)\n        impl = task.select_implementation(target, provided_features)\n        impl['input_method'] ||= default_input_method(impl['path'])\n        impl\n      end\n\n      def select_interpreter(executable, interpreters)\n        interpreters[Pathname(executable).extname] if interpreters\n      end\n\n      # Transform a parameter map to an environment variable map, with parameter names prefixed\n      # with 'PT_' and values transformed to JSON unless they're strings.\n      def envify_params(params)\n        params.each_with_object({}) do |(k, v), h|\n          v = v.to_json unless v.is_a?(String)\n          h[\"PT_#{k}\"] = v\n        end\n      end\n\n      # Raises an error if more than one target was given in the batch.\n      #\n      # The default implementations of batch_* strictly assume the transport is\n      # using the default batch size of 1. This method ensures that is the\n      # case and raises an error if it's not.\n      def assert_batch_size_one(method, targets)\n        if targets.length > 1\n          message = \"#{self.class.name} must implement #{method} to support batches (got #{targets.length} nodes)\"\n          raise NotImplementedError, message\n        end\n      end\n\n      # Runs the given task on a batch of nodes.\n      #\n      # The default implementation only supports batches of size 1 and will fail otherwise.\n      #\n      # Transports may override this method to implement their own batch processing.\n      def batch_task(targets, task, arguments, options = {}, &callback)\n        assert_batch_size_one(\"batch_task()\", targets)\n        target = targets.first\n        with_events(target, callback) do\n          @logger.debug { \"Running task run '#{task}' on #{target.safe_name}\" }\n          run_task(target, task, arguments, options)\n        end\n      end\n\n      # Runs the given command on a batch of nodes.\n      #\n      # The default implementation only supports batches of size 1 and will fail otherwise.\n      #\n      # Transports may override this method to implement their own batch processing.\n      def batch_command(targets, command, options = {}, &callback)\n        assert_batch_size_one(\"batch_command()\", targets)\n        target = targets.first\n        with_events(target, callback) do\n          @logger.debug(\"Running command '#{command}' on #{target.safe_name}\")\n          run_command(target, command, options)\n        end\n      end\n\n      # Runs the given script on a batch of nodes.\n      #\n      # The default implementation only supports batches of size 1 and will fail otherwise.\n      #\n      # Transports may override this method to implement their own batch processing.\n      def batch_script(targets, script, arguments, options = {}, &callback)\n        assert_batch_size_one(\"batch_script()\", targets)\n        target = targets.first\n        with_events(target, callback) do\n          @logger.debug { \"Running script '#{script}' on #{target.safe_name}\" }\n          run_script(target, script, arguments, options)\n        end\n      end\n\n      # Uploads the given source file to the destination location on a batch of nodes.\n      #\n      # The default implementation only supports batches of size 1 and will fail otherwise.\n      #\n      # Transports may override this method to implement their own batch processing.\n      def batch_upload(targets, source, destination, options = {}, &callback)\n        assert_batch_size_one(\"batch_upload()\", targets)\n        target = targets.first\n        with_events(target, callback) do\n          @logger.debug { \"Uploading: '#{source}' to #{destination} on #{target.safe_name}\" }\n          upload(target, source, destination, options)\n        end\n      end\n\n      def batch_connected?(targets)\n        assert_batch_size_one(\"connected?()\", targets)\n        connected?(targets.first)\n      end\n\n      # Split the given list of targets into a list of batches. The default\n      # implementation returns single-node batches.\n      #\n      # Transports may override this method, and the corresponding batch_*\n      # methods, to implement their own batch processing.\n      def batches(targets)\n        targets.map { |target| [target] }\n      end\n\n      # Transports should override this method with their own implementation of running a command.\n      def run_command(*_args)\n        raise NotImplementedError, \"run_command() must be implemented by the transport class\"\n      end\n\n      # Transports should override this method with their own implementation of running a script.\n      def run_script(*_args)\n        raise NotImplementedError, \"run_script() must be implemented by the transport class\"\n      end\n\n      # Transports should override this method with their own implementation of running a task.\n      def run_task(*_args)\n        raise NotImplementedError, \"run_task() must be implemented by the transport class\"\n      end\n\n      # Transports should override this method with their own implementation of file upload.\n      def upload(*_args)\n        raise NotImplementedError, \"upload() must be implemented by the transport class\"\n      end\n\n      # Transports should override this method with their own implementation of a connection test.\n      def connected?(_targets)\n        raise NotImplementedError, \"connected?() must be implemented by the transport class\"\n      end\n\n      # Unwraps any Sensitive data in an arguments Hash, so the plain-text is passed\n      # to the Task/Script.\n      #\n      # This works on deeply nested data structures composed of Hashes, Arrays, and\n      # and plain-old data types (int, string, etc).\n      def unwrap_sensitive_args(arguments)\n        # Skip this if Puppet isn't loaded\n        return arguments unless defined?(Puppet::Pops::Types::PSensitiveType::Sensitive)\n\n        case arguments\n        when Array\n          # iterate over the array, unwrapping all elements\n          arguments.map { |x| unwrap_sensitive_args(x) }\n        when Hash\n          # iterate over the arguments hash and unwrap all keys and values\n          arguments.each_with_object({}) { |(k, v), h|\n            h[unwrap_sensitive_args(k)] = unwrap_sensitive_args(v)\n          }\n        when Puppet::Pops::Types::PSensitiveType::Sensitive\n          # this value is Sensitive, unwrap it\n          unwrap_sensitive_args(arguments.unwrap)\n        else\n          # unknown data type, just return it\n          arguments\n        end\n      end\n    end\n  end\nend\n", "idx": 1, "id": 14415, "msg": "Should this be optional, or default to 'action' as well?", "proj": "puppetlabs-bolt", "lang": "rb"}
{"patch": "@@ -299,6 +299,7 @@ Blockly.Variables.createVariable = function(workspace, opt_callback, opt_type) {\n   // Prompt the user to enter a name for the variable\n   Blockly.prompt(newMsg, '',\n       function(text, additionalVars, variableOptions) {\n+        variableOptions = variableOptions || {};\n         var scope = variableOptions.scope;\n         var isLocal = (scope === 'local') || false;\n         var isCloud = variableOptions.isCloud || false;", "y": 1, "oldf": "/**\n * @license\n * Visual Blocks Editor\n *\n * Copyright 2012 Google Inc.\n * https://developers.google.com/blockly/\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * @fileoverview Utility functions for handling variables.\n * @author fraser@google.com (Neil Fraser)\n */\n'use strict';\n\n/**\n * @name Blockly.Variables\n * @namespace\n **/\ngoog.provide('Blockly.Variables');\n\ngoog.require('Blockly.Blocks');\ngoog.require('Blockly.constants');\ngoog.require('Blockly.VariableModel');\ngoog.require('Blockly.Workspace');\ngoog.require('goog.string');\n\n\n/**\n * Constant to separate variable names from procedures and generated functions\n * when running generators.\n * @deprecated Use Blockly.VARIABLE_CATEGORY_NAME\n */\nBlockly.Variables.NAME_TYPE = Blockly.VARIABLE_CATEGORY_NAME;\n\n/**\n * Constant prefix to differentiate cloud variable names from other types\n * of variables.\n * This is the \\u2601 cloud unicode character followed by a space.\n * @type {string}\n * @package\n */\nBlockly.Variables.CLOUD_PREFIX = '\u2601 ';\n\n/**\n * Find all user-created variables that are in use in the workspace.\n * For use by generators.\n * @param {!Blockly.Block|!Blockly.Workspace} root Root block or workspace.\n * @return {!Array.<string>} Array of variable names.\n */\nBlockly.Variables.allUsedVariables = function(root) {\n  var blocks;\n  if (root instanceof Blockly.Block) {\n    // Root is Block.\n    blocks = root.getDescendants(false);\n  } else if (root instanceof Blockly.Workspace ||\n      root instanceof Blockly.WorkspaceSvg) {\n    // Root is Workspace.\n    blocks = root.getAllBlocks();\n  } else {\n    throw 'Not Block or Workspace: ' + root;\n  }\n\n  var ignorableName = Blockly.Variables.noVariableText();\n\n  var variableHash = Object.create(null);\n  // Iterate through every block and add each variable to the hash.\n  for (var x = 0; x < blocks.length; x++) {\n    var blockVariables = blocks[x].getVarModels();\n    if (blockVariables) {\n      for (var y = 0; y < blockVariables.length; y++) {\n        var variable = blockVariables[y];\n        // Variable ID may be null if the block is only half-built.\n        if (variable.getId() && variable.name.toLowerCase() != ignorableName) {\n          variableHash[variable.name.toLowerCase()] = variable.name;\n        }\n      }\n    }\n  }\n  // Flatten the hash into a list.\n  var variableList = [];\n  for (var name in variableHash) {\n    variableList.push(variableHash[name]);\n  }\n  return variableList;\n};\n\n/**\n * Find all variables that the user has created through the workspace or\n * toolbox.  For use by generators.\n * @param {!Blockly.Workspace} root The workspace to inspect.\n * @return {!Array.<Blockly.VariableModel>} Array of variable models.\n */\nBlockly.Variables.allVariables = function(root) {\n  if (root instanceof Blockly.Block) {\n    // Root is Block.\n    console.warn('Deprecated call to Blockly.Variables.allVariables ' +\n                 'with a block instead of a workspace.  You may want ' +\n                 'Blockly.Variables.allUsedVariables');\n    return {};\n  }\n  return root.getAllVariables();\n};\n\n/**\n * Find all developer variables used by blocks in the workspace.\n * Developer variables are never shown to the user, but are declared as global\n * variables in the generated code.\n * To declare developer variables, define the getDeveloperVariables function on\n * your block and return a list of variable names.\n * For use by generators.\n * @param {!Blockly.Workspace} workspace The workspace to search.\n * @return {!Array.<string>} A list of non-duplicated variable names.\n * @package\n */\nBlockly.Variables.allDeveloperVariables = function(workspace) {\n  var blocks = workspace.getAllBlocks();\n  var hash = {};\n  for (var i = 0; i < blocks.length; i++) {\n    var block = blocks[i];\n    if (block.getDeveloperVars) {\n      var devVars = block.getDeveloperVars();\n      for (var j = 0; j < devVars.length; j++) {\n        hash[devVars[j]] = devVars[j];\n      }\n    }\n  }\n\n  // Flatten the hash into a list.\n  var list = [];\n  for (var name in hash) {\n    list.push(hash[name]);\n  }\n  return list;\n};\n\n/**\n* Return the text that should be used in a field_variable or\n* field_variable_getter when no variable exists.\n* TODO: #572\n* @return {string} The text to display.\n */\nBlockly.Variables.noVariableText = function() {\n  return \"No variable selected\";\n};\n\n/**\n* Return a new variable name that is not yet being used. This will try to\n* generate single letter variable names in the range 'i' to 'z' to start with.\n* If no unique name is located it will try 'i' to 'z', 'a' to 'h',\n* then 'i2' to 'z2' etc.  Skip 'l'.\n * @param {!Blockly.Workspace} workspace The workspace to be unique in.\n* @return {string} New variable name.\n*/\nBlockly.Variables.generateUniqueName = function(workspace) {\n  var variableList = workspace.getAllVariables();\n  var newName = '';\n  if (variableList.length) {\n    var nameSuffix = 1;\n    var letters = 'ijkmnopqrstuvwxyzabcdefgh';  // No 'l'.\n    var letterIndex = 0;\n    var potName = letters.charAt(letterIndex);\n    while (!newName) {\n      var inUse = false;\n      for (var i = 0; i < variableList.length; i++) {\n        if (variableList[i].name.toLowerCase() == potName) {\n          // This potential name is already used.\n          inUse = true;\n          break;\n        }\n      }\n      if (inUse) {\n        // Try the next potential name.\n        letterIndex++;\n        if (letterIndex == letters.length) {\n          // Reached the end of the character sequence so back to 'i'.\n          // a new suffix.\n          letterIndex = 0;\n          nameSuffix++;\n        }\n        potName = letters.charAt(letterIndex);\n        if (nameSuffix > 1) {\n          potName += nameSuffix;\n        }\n      } else {\n        // We can use the current potential name.\n        newName = potName;\n      }\n    }\n  } else {\n    newName = 'i';\n  }\n  return newName;\n};\n\n/**\n * Remove any possiblity of conflict/duplication between a real and potential variable.\n * When creating a new variable, checks whether the desired name and type already exists\n * as a real or potential variable.\n * If 'checkReal' is true, checks whether a real variable with the given\n * name and type already exists.\n * Checks whether a potential variable (using the given 'potentialVarWs') exists.\n * If a potential var exists and a real var also exists, discards the potential var\n * and returns the real var.\n * If a potential var exists and a real var does not exist (or 'checkReal'\n * was false), creates the potential var as a real var,\n * discards the potential var, and returns the newly created real var.\n * If a potential var does not exist, returns null.\n *\n * @param {string} varName The name of the variable to check for.\n * @param {string} varType The type of the variable to check for.\n * @param {!Blockly.Workspace} potentialVarWs The workspace containing the\n *     potential variable map we want to check against.\n * @param {boolean} checkReal Whether or not to check if a variable of the given\n *     name and type exists as a real variable.\n * @return {?Blockly.VariableModel} The matching variable, if one already existed\n *     in the real workspace; the newly transformed variable, if one already\n *     existed as a potential variable. Null, if no matching variable, real or\n *     potential, was found.\n */\nBlockly.Variables.realizePotentialVar = function(varName, varType, potentialVarWs,\n    checkReal) {\n  var potentialVarMap = potentialVarWs.getPotentialVariableMap();\n  var realWs = potentialVarWs.targetWorkspace;\n  if (!potentialVarMap) {\n    console.warn('Called Blockly.Variables.realizePotentialVar with incorrect ' +\n        'workspace. The provided workspace does not have a potential variable map.');\n    return;\n  }\n  // First check if a variable with the same name and type already exists as a\n  // real variable.\n  var realVar;\n  if (checkReal) {\n    realVar = Blockly.Variables.getVariable(realWs, null, varName, varType);\n  }\n\n  // Check if variable with same name and type exists as a potential var\n  var potentialVar = potentialVarMap.getVariable(varName, varType);\n  if (!potentialVar) {\n    return null;\n  }\n\n  // The potential var exists, so save its id and delete it from the potential\n  // variable map.\n  var id = potentialVar.getId();\n  potentialVarMap.deleteVariable(potentialVar);\n\n  // Depending on whether a real var already exists or not, either return the\n  // existing real var or turn the potential var into a new one using its id.\n  if (realVar) {\n    return realVar;\n  }\n  return realWs.createVariable(varName, varType, id);\n};\n\n/**\n * Create a new variable on the given workspace.\n * @param {!Blockly.Workspace} workspace The workspace on which to create the\n *     variable.\n * @param {function(?string=)=} opt_callback An optional callback function to act\n *     on the id of the variable that is created from the user's input, or null\n *     if the change is to be aborted (cancel button or an invalid name was provided).\n * @param {string} opt_type Optional type of the variable to be created,\n *     like 'string' or 'list'.\n */\nBlockly.Variables.createVariable = function(workspace, opt_callback, opt_type) {\n  // Decide on a modal message based on the opt_type. If opt_type was not\n  // provided, default to the original message for scalar variables.\n  var newMsg, modalTitle;\n  if (opt_type == Blockly.BROADCAST_MESSAGE_VARIABLE_TYPE) {\n    newMsg = Blockly.Msg.NEW_BROADCAST_MESSAGE_TITLE;\n    modalTitle = Blockly.Msg.BROADCAST_MODAL_TITLE;\n  } else if (opt_type == Blockly.LIST_VARIABLE_TYPE) {\n    newMsg = Blockly.Msg.NEW_LIST_TITLE;\n    modalTitle = Blockly.Msg.LIST_MODAL_TITLE;\n  } else {\n    // Note: this case covers 1) scalar variables, 2) any new type of\n    // variable not explicitly checked for above, and 3) a null or undefined\n    // opt_type -- turns a falsey opt_type into ''\n    // TODO (#1251) Warn developers that they didn't provide an opt_type/provided\n    // a falsey opt_type\n    opt_type = opt_type ? opt_type : '';\n    newMsg = Blockly.Msg.NEW_VARIABLE_TITLE;\n    modalTitle = Blockly.Msg.VARIABLE_MODAL_TITLE;\n  }\n  var validate = Blockly.Variables.nameValidator_.bind(null, opt_type);\n\n  // Prompt the user to enter a name for the variable\n  Blockly.prompt(newMsg, '',\n      function(text, additionalVars, variableOptions) {\n        var scope = variableOptions.scope;\n        var isLocal = (scope === 'local') || false;\n        var isCloud = variableOptions.isCloud || false;\n        // Default to [] if additionalVars is not provided\n        additionalVars = additionalVars || [];\n        // Only use additionalVars for global variable creation.\n        var additionalVarNames = isLocal ? [] : additionalVars;\n\n        var validatedText = validate(text, workspace, additionalVarNames, isCloud, opt_callback);\n        if (validatedText) {\n          // The name is valid according to the type, create the variable\n          var potentialVarMap = workspace.getPotentialVariableMap();\n          var variable;\n          // This check ensures that if a new variable is being created from a\n          // workspace that already has a variable of the same name and type as\n          // a potential variable, that potential variable gets turned into a\n          // real variable and thus there aren't duplicate options in the field_variable\n          // dropdown.\n          if (potentialVarMap && opt_type) {\n            variable = Blockly.Variables.realizePotentialVar(validatedText,\n                opt_type, workspace, false);\n          }\n          if (!variable) {\n            variable = workspace.createVariable(validatedText, opt_type, null, isLocal, isCloud);\n          }\n\n          var flyout = workspace.isFlyout ? workspace : workspace.getFlyout();\n          var variableBlockId = variable.getId();\n          if (flyout.setCheckboxState) {\n            flyout.setCheckboxState(variableBlockId, true);\n          }\n\n          if (opt_callback) {\n            opt_callback(variableBlockId);\n          }\n        } else {\n          // User canceled prompt without a value.\n          if (opt_callback) {\n            opt_callback(null);\n          }\n        }\n      }, modalTitle, opt_type);\n};\n\n/**\n * This function provides a common interface for variable name validation agnostic\n * of type. This is so that functions like Blockly.Variables.createVariable and\n * Blockly.Variables.renameVariable can call a single function (with a single\n * type signature) to validate the user-provided name for a variable.\n * @param {string} type The type of the variable for which the provided name\n *     should be validated.\n * @param {string} text The user-provided text that should be validated as a\n *     variable name.\n * @param {!Blockly.Workspace} workspace The workspace on which to validate the\n *     variable name. This is the workspace used to check whether the variable\n *     already exists.\n * @param {Array<string>} additionalVars A list of additional var names to check\n *     for conflicts against.\n * @param {boolean} isCloud Whether the variable is a cloud variable.\n * @param {function(?string=)=} opt_callback An optional function to be called on\n *     a pre-existing variable of the user-provided name. This function is currently\n *     only used for broadcast messages.\n * @return {string} The validated name according to the parameters given, if\n *     the name is determined to be valid, or null if the name\n *     is determined to be invalid/in-use, and the calling function should not\n *     proceed with creating or renaming the variable.\n * @private\n */\nBlockly.Variables.nameValidator_ = function(type, text, workspace, additionalVars,\n    isCloud, opt_callback) {\n  // The validators for the different variable types require slightly different arguments.\n  // For broadcast messages, if a broadcast message of the provided name already exists,\n  // the validator needs to call a function that updates the selected\n  // field option of the dropdown menu of the block that was used to create the new message.\n  // For scalar variables and lists, the validator has the same validation behavior, but needs\n  // to know which type of variable to check for and needs a type-specific error message\n  // that is displayed when a variable of the given name and type already exists.\n\n  if (type == Blockly.BROADCAST_MESSAGE_VARIABLE_TYPE) {\n    return Blockly.Variables.validateBroadcastMessageName_(text, workspace, opt_callback);\n  } else if (type == Blockly.LIST_VARIABLE_TYPE) {\n    return Blockly.Variables.validateScalarVarOrListName_(text, workspace, additionalVars, false, type,\n        Blockly.Msg.LIST_ALREADY_EXISTS);\n  } else {\n    return Blockly.Variables.validateScalarVarOrListName_(text, workspace, additionalVars, isCloud, type,\n        Blockly.Msg.VARIABLE_ALREADY_EXISTS);\n  }\n};\n\n/**\n * Validate the given name as a broadcast message type.\n * @param {string} name The name to validate\n * @param {!Blockly.Workspace} workspace The workspace the name should be validated\n *     against.\n * @param {function(?string=)=} opt_callback An optional function to call if a broadcast\n *     message already exists with the given name. This function will be called on the id\n *     of the existing variable.\n * @return {string} The validated name, or null if invalid.\n * @private\n */\nBlockly.Variables.validateBroadcastMessageName_ = function(name, workspace, opt_callback) {\n  if (!name) { // no name was provided or the user cancelled the prompt\n    return null;\n  }\n  var variable = workspace.getVariable(name, Blockly.BROADCAST_MESSAGE_VARIABLE_TYPE);\n  if (variable) {\n    // If the user provided a name for a broadcast message that already exists,\n    // use the provided callback function to update the selected option in\n    // the field of the block that was used to create\n    // this message.\n    if (opt_callback) {\n      opt_callback(variable.getId());\n    }\n    // Return null to signal to the calling function that we do not want to create\n    // a new variable since one already exists.\n    return null;\n  } else {\n    // The name provided is actually a new name, so the calling\n    // function should go ahead and create it as a new variable.\n    return name;\n  }\n};\n\n/**\n * Validate the given name as a scalar variable or list type.\n * This function is also responsible for any user facing error-handling.\n * @param {string} name The name to validate\n * @param {!Blockly.Workspace} workspace The workspace the name should be validated\n *     against.\n * @param {Array<string>} additionalVars A list of additional variable names to check\n *     for conflicts against.\n * @param {boolean} isCloud Whether the variable is a cloud variable.\n * @param {string} type The type to validate the variable as. This should be one of\n *     Blockly.SCALAR_VARIABLE_TYPE or Blockly.LIST_VARIABLE_TYPE.\n * @param {string} errorMsg The type-specific error message the user should see\n *     if a variable of the validated, given name and type already exists.\n * @return {string} The validated name, or null if invalid.\n * @private\n */\nBlockly.Variables.validateScalarVarOrListName_ = function(name, workspace, additionalVars,\n    isCloud, type, errorMsg) {\n  // For scalar variables, we don't want leading or trailing white space\n  name = Blockly.Variables.trimName_(name);\n  if (!name) {\n    return null;\n  }\n  if (isCloud) {\n    name = Blockly.Variables.CLOUD_PREFIX + name;\n  }\n  if (workspace.getVariable(name, type) || additionalVars.indexOf(name) >= 0) {\n    // error\n    Blockly.alert(errorMsg.replace('%1', name));\n    return null;\n  } else { // trimmed name is valid\n    return name;\n  }\n};\n\n/**\n * Rename a variable with the given workspace, variableType, and oldName.\n * @param {!Blockly.Workspace} workspace The workspace on which to rename the\n *     variable.\n * @param {Blockly.VariableModel} variable Variable to rename.\n * @param {function(?string=)=} opt_callback A callback. It will\n *     be passed an acceptable new variable name, or null if change is to be\n *     aborted (cancel button), or undefined if an existing variable was chosen.\n */\nBlockly.Variables.renameVariable = function(workspace, variable,\n    opt_callback) {\n  // Validation and modal message/title depends on the variable type\n  var promptMsg, modalTitle;\n  var varType = variable.type;\n  if (varType == Blockly.BROADCAST_MESSAGE_VARIABLE_TYPE) {\n    console.warn('Unexpected attempt to rename a broadcast message with ' +\n        'id: ' + variable.getId() + ' and name: ' + variable.name);\n    return;\n  }\n  if (varType == Blockly.LIST_VARIABLE_TYPE) {\n    promptMsg = Blockly.Msg.RENAME_LIST_TITLE;\n    modalTitle = Blockly.Msg.RENAME_LIST_MODAL_TITLE;\n  } else {\n    // Default for all other types of variables\n    promptMsg = Blockly.Msg.RENAME_VARIABLE_TITLE;\n    modalTitle = Blockly.Msg.RENAME_VARIABLE_MODAL_TITLE;\n  }\n  var validate = Blockly.Variables.nameValidator_.bind(null, varType);\n\n  var promptText = promptMsg.replace('%1', variable.name);\n  Blockly.prompt(promptText, '',\n      function(newName, additionalVars) {\n        if (variable.isCloud &&\n            newName.length > 0 && newName.indexOf(Blockly.Variables.CLOUD_PREFIX) == 0 ) {\n          newName = newName.substring(2); // The name validator will add the prefix back\n        }\n        additionalVars = additionalVars || [];\n        var additionalVarNames = variable.isLocal ? [] : additionalVars;\n        var validatedText = validate(newName, workspace, additionalVarNames, variable.isCloud);\n        if (validatedText) {\n          workspace.renameVariableById(variable.getId(), validatedText);\n          if (opt_callback) {\n            opt_callback(newName);\n          }\n        } else {\n          // User canceled prompt without a value.\n          if (opt_callback) {\n            opt_callback(null);\n          }\n        }\n      }, modalTitle, varType);\n};\n\n/**\n * Strip leading and trailing whitespace from the given name, for use with\n * user provided name for scalar variables and lists.\n * @param {string} name The user-provided name of the variable.\n * @return {string} The trimmed name, or whatever falsey value was originally provided.\n */\nBlockly.Variables.trimName_ = function(name) {\n  if (name) {\n    return goog.string.trim(name);\n  } else {\n    // Return whatever was provided\n    return name;\n  }\n};\n\n/**\n * Generate XML string for variable field.\n * @param {!Blockly.VariableModel} variableModel The variable model to generate\n *     an XML string from.\n * @param {?string} opt_name The optional name of the field, such as \"VARIABLE\"\n *     or \"LIST\". Defaults to \"VARIABLE\".\n * @return {string} The generated XML.\n * @private\n */\nBlockly.Variables.generateVariableFieldXml_ = function(variableModel, opt_name) {\n  // The variable name may be user input, so it may contain characters that need\n  // to be escaped to create valid XML.\n  var typeString = variableModel.type;\n  if (typeString == '') {\n    typeString = '\\'\\'';\n  }\n  var fieldName = opt_name || 'VARIABLE';\n  var text = '<field name=\"' + fieldName + '\" id=\"' + variableModel.getId() +\n    '\" variabletype=\"' + goog.string.htmlEscape(typeString) +\n    '\">' + goog.string.htmlEscape(variableModel.name) + '</field>';\n  return text;\n};\n\n/**\n * Helper function to look up or create a variable on the given workspace.\n * If no variable exists, creates and returns it.\n * @param {!Blockly.Workspace} workspace The workspace to search for the\n *     variable.  It may be a flyout workspace or main workspace.\n * @param {string} id The ID to use to look up or create the variable, or null.\n * @param {string=} opt_name The string to use to look up or create the\n *     variable.\n * @param {string=} opt_type The type to use to look up or create the variable.\n * @return {!Blockly.VariableModel} The variable corresponding to the given ID\n *     or name + type combination.\n * @package\n */\nBlockly.Variables.getOrCreateVariablePackage = function(workspace, id, opt_name,\n    opt_type) {\n  var variable = Blockly.Variables.getVariable(workspace, id, opt_name,\n      opt_type);\n  if (!variable) {\n    variable = Blockly.Variables.createVariable_(workspace, id, opt_name,\n        opt_type);\n  }\n  return variable;\n};\n\n/**\n * Look up  a variable on the given workspace.\n * Always looks in the main workspace before looking in the flyout workspace.\n * Always prefers lookup by ID to lookup by name + type.\n * @param {!Blockly.Workspace} workspace The workspace to search for the\n *     variable.  It may be a flyout workspace or main workspace.\n * @param {string} id The ID to use to look up the variable, or null.\n * @param {string=} opt_name The string to use to look up the variable.  Only\n *     used if lookup by ID fails.\n * @param {string=} opt_type The type to use to look up the variable.  Only used\n *     if lookup by ID fails.\n * @return {?Blockly.VariableModel} The variable corresponding to the given ID\n *     or name + type combination, or null if not found.\n * @package\n */\nBlockly.Variables.getVariable = function(workspace, id, opt_name, opt_type) {\n  var potentialVariableMap = workspace.getPotentialVariableMap();\n  // Try to just get the variable, by ID if possible.\n  if (id) {\n    // Look in the real variable map before checking the potential variable map.\n    var variable = workspace.getVariableById(id);\n    if (!variable && potentialVariableMap) {\n      variable = potentialVariableMap.getVariableById(id);\n    }\n  } else if (opt_name) {\n    if (opt_type == undefined) {\n      throw new Error('Tried to look up a variable by name without a type');\n    }\n    // Otherwise look up by name and type.\n    var variable = workspace.getVariable(opt_name, opt_type);\n    if (!variable && potentialVariableMap) {\n      variable = potentialVariableMap.getVariable(opt_name, opt_type);\n    }\n  }\n  return variable;\n};\n\n/**\n * Helper function to create a variable on the given workspace.\n * @param {!Blockly.Workspace} workspace The workspace in which to create the\n * variable.  It may be a flyout workspace or main workspace.\n * @param {string} id The ID to use to create the variable, or null.\n * @param {string=} opt_name The string to use to create the variable.\n * @param {string=} opt_type The type to use to create the variable.\n * @return {!Blockly.VariableModel} The variable corresponding to the given ID\n *     or name + type combination.\n * @private\n */\nBlockly.Variables.createVariable_ = function(workspace, id, opt_name,\n    opt_type) {\n  var potentialVariableMap = workspace.getPotentialVariableMap();\n  // Variables without names get uniquely named for this workspace.\n  if (!opt_name) {\n    var ws = workspace.isFlyout ? workspace.targetWorkspace : workspace;\n    opt_name = Blockly.Variables.generateUniqueName(ws);\n  }\n\n  // Create a potential variable if in the flyout.\n  if (potentialVariableMap) {\n    var variable = potentialVariableMap.createVariable(opt_name, opt_type, id);\n  } else {  // In the main workspace, create a real variable.\n    var variable = workspace.createVariable(opt_name, opt_type, id);\n  }\n  return variable;\n};\n\n/**\n * Helper function to get the list of variables that have been added to the\n * workspace after adding a new block, using the given list of variables that\n * were in the workspace before the new block was added.\n * @param {!Blockly.Workspace} workspace The workspace to inspect.\n * @param {!Array.<!Blockly.VariableModel>} originalVariables The array of\n *     variables that existed in the workspace before adding the new block.\n * @return {!Array.<!Blockly.VariableModel>} The new array of variables that were\n *     freshly added to the workspace after creating the new block, or [] if no\n *     new variables were added to the workspace.\n * @package\n */\nBlockly.Variables.getAddedVariables = function(workspace, originalVariables) {\n  var allCurrentVariables = workspace.getAllVariables();\n  var addedVariables = [];\n  if (originalVariables.length != allCurrentVariables.length) {\n    for (var i = 0; i < allCurrentVariables.length; i++) {\n      var variable = allCurrentVariables[i];\n      // For any variable that is present in allCurrentVariables but not\n      // present in originalVariables, add the variable to addedVariables.\n      if (!originalVariables.includes(variable)) {\n        addedVariables.push(variable);\n      }\n    }\n  }\n  return addedVariables;\n};\n", "idx": 1, "id": 9860, "msg": "Thanks for fixing this! I probably didn't test the playground when making changes here for cloud variables.", "proj": "LLK-scratch-blocks", "lang": "js"}
{"patch": "@@ -110,13 +110,13 @@ def _create_user(username, password='', email=None, is_admin=False,\n                  requires_activation=True, requires_reset=False):\n     def check_conflicts(username, email):\n         if not VALID_USERNAME_RE.match(username):\n-            raise ValidationException(\"Unacceptable username.\")\n+            raise ValidationException(\"Invalid username.\")\n         if blacklisted_name(username):\n-            raise ValidationException(\"Unacceptable username.\")\n+            raise ValidationException(\"Invalid username.\")\n         if email is None:\n             raise ValidationException(\"Must provide email.\")\n         if not VALID_EMAIL_RE.match(email):\n-            raise ValidationException(\"Unacceptable email.\")\n+            raise ValidationException(\"Invalid email.\")\n         if User.query.filter_by(name=username).one_or_none():\n             raise ConflictException(\"Username already taken.\")\n         if User.query.filter_by(email=email).one_or_none():", "y": 1, "oldf": "import base64\nfrom datetime import datetime, timedelta\nimport json\nimport uuid\n\nfrom flask import redirect, request\nimport itsdangerous\nimport jwt\nfrom passlib.context import CryptContext\nfrom sqlalchemy import func\n\nfrom . import app, db\nfrom .const import (VALID_EMAIL_RE, VALID_USERNAME_RE, blacklisted_name,\n                    ACTIVATE_SALT, PASSWORD_RESET_SALT, MAX_LINK_AGE,\n                    CODE_EXP_MINUTES)\nfrom .mail import (send_activation_email, send_reset_email, send_new_user_email,\n                   send_welcome_email)\nfrom .models import ActivationToken, Code, PasswordResetToken, Token, User\n\nCATALOG_URL = app.config['CATALOG_URL']\n\npwd_context = CryptContext(\n    schemes=['pbkdf2_sha512', 'django_pbkdf2_sha256'],\n    pbkdf2_sha512__default_rounds=500000\n    )\n# Each round should take about half a second,\n# 500000 rounds experimentally determined\n\nclass AuthException(Exception):\n    \"\"\"\n    Base class for Auth exceptions.\n    \"\"\"\n    def __init__(self, msg):\n        super().__init__()\n        self.message = msg\n\n\nclass ValidationException(AuthException):\n    \"\"\"\n    Represents a failure to deserialize a signed link,\n    a password that is too short, etc.\n    \"\"\"\n    pass\n\n\nclass ConflictException(AuthException):\n    \"\"\"\n    Represents an exception involving an attempt to register a\n    username that already exists, etc.\n    \"\"\"\n    pass\n\n\nclass NotFoundException(AuthException):\n    \"\"\"\n    Represents an exception involving an attempted operation on an entity\n    that could not be located.\n    \"\"\"\n    pass\n\n\nclass CredentialException(AuthException):\n    \"\"\"\n    Represents an exception involving things like an incorrect token,\n    an incorrect password, etc.\n    \"\"\"\n    pass\n\n\ndef generate_uuid():\n    return str(uuid.uuid4())\n\ndef hash_password(password):\n    return pwd_context.hash(password)\n\ndef get_admins():\n    return [user.email for user in User.query.filter_by(is_admin=True).all()]\n\ndef activate_response(link):\n    payload = verify_activation_link(link)\n    if payload:\n        _activate_user(User.query.filter_by(id=payload['id']).with_for_update().one_or_none())\n        db.session.commit()\n        return redirect(\"{CATALOG_URL}/signin\".format(CATALOG_URL=CATALOG_URL), code=302)\n\n    return redirect(\"{CATALOG_URL}/activation_error\".format(CATALOG_URL=CATALOG_URL), code=302)\n\ndef validate_password(password):\n    if len(password) < 8:\n        raise ValidationException(\"Password must be at least 8 characters long.\")\n\ndef reset_password_from_email(email):\n    user = User.query.filter_by(email=email).with_for_update().one_or_none()\n    if user:\n        reset_password(user)\n\ndef change_password(raw_password, link):\n    validate_password(raw_password)\n    payload = verify_reset_link(link)\n    if not payload:\n        raise CredentialException(\"Reset token invalid\")\n    user_id = payload['id']\n    user = User.query.filter_by(id=user_id).with_for_update().one_or_none()\n    if not user:\n        raise NotFoundException(\"User not found\")\n    user.password = hash_password(raw_password)\n    db.session.add(user)\n\ndef _create_user(username, password='', email=None, is_admin=False,\n                 requires_activation=True, requires_reset=False):\n    def check_conflicts(username, email):\n        if not VALID_USERNAME_RE.match(username):\n            raise ValidationException(\"Unacceptable username.\")\n        if blacklisted_name(username):\n            raise ValidationException(\"Unacceptable username.\")\n        if email is None:\n            raise ValidationException(\"Must provide email.\")\n        if not VALID_EMAIL_RE.match(email):\n            raise ValidationException(\"Unacceptable email.\")\n        if User.query.filter_by(name=username).one_or_none():\n            raise ConflictException(\"Username already taken.\")\n        if User.query.filter_by(email=email).one_or_none():\n            raise ConflictException(\"Email already taken.\")\n\n    check_conflicts(username, email)\n    validate_password(password)\n\n    new_password = \"\" if requires_reset else hash_password(password)\n\n    if requires_activation:\n        is_active = False\n    else:\n        is_active = True\n\n    user = User(\n        id=generate_uuid(),\n        name=username,\n        password=new_password,\n        email=email,\n        is_active=is_active,\n        is_admin=is_admin\n        )\n\n    db.session.add(user)\n\n    if requires_activation:\n        db.session.flush() # necessary due to link token foreign key relationship with User\n        send_activation_email(user, generate_activation_link(user.id))\n\n    if requires_reset:\n        db.session.flush() # necessary due to link token foreign key relationship with User\n        send_welcome_email(user, user.email, generate_reset_link(user.id))\n\ndef _update_user(username, password=None, email=None, is_admin=None, is_active=None):\n    existing_user = User.query.filter_by(name=username).with_for_update().one_or_none()\n    if not existing_user:\n        raise NotFoundException(\"User to update not found\")\n    if password is not None:\n        new_password = hash_password(password)\n        existing_user.password = new_password\n    if email is not None:\n        existing_user.email = email\n    if is_admin is not None:\n        existing_user.is_admin = is_admin\n    if is_active is not None:\n        existing_user.is_active = is_active\n\n    db.session.add(existing_user)\n\ndef _activate_user(user):\n    if user is None:\n        raise NotFoundException(\"User not found\")\n    user.is_active = True\n    db.session.add(user)\n    admins = get_admins()\n    if admins:\n        send_new_user_email(user.name, user.email, admins)\n\ndef update_last_login(user):\n    user.last_login = func.now()\n    db.session.add(user)\n\ndef _delete_user(user):\n    if user:\n        revoke_user_code_tokens(user)\n        db.session.delete(user)\n    else:\n        raise NotFoundException(\"User to delete not found\")\n    return user\n\ndef _enable_user(user):\n    if user:\n        user.is_active = True\n        db.session.add(user)\n    else:\n        raise NotFoundException(\"User to enable not found\")\n\ndef _disable_user(user):\n    if user:\n        revoke_user_code_tokens(user)\n        user.is_active = False\n        db.session.add(user)\n    else:\n        raise NotFoundException(\"User to disable not found\")\n\ndef issue_code(user):\n    user_id = user.id\n    expires = datetime.utcnow() + timedelta(minutes=CODE_EXP_MINUTES)\n    code = Code(user_id=user_id, code=generate_uuid(), expires=expires)\n    db.session.add(code)\n    return encode_code({'id': user_id, 'code': code.code})\n\ndef encode_code(code_dict):\n    return base64.b64encode(bytes(json.dumps(code_dict), 'utf-8')).decode('utf8')\n\ndef decode_code(code_str):\n    try:\n        return json.loads(base64.b64decode(code_str).decode('utf8'))\n    except Exception:\n        raise ValidationException(\"Decoding code failed\")\n\ndef decode_token(token_str):\n    try:\n        return jwt.decode(token_str, app.secret_key, algorithm='HS256')\n    except jwt.exceptions.InvalidTokenError:\n        raise ValidationException(\"Token could not be deserialized\")\n\ndef check_token(user_id, token):\n    return Token.query.filter_by(user_id=user_id, token=token).one_or_none() is not None\n\ndef _verify(payload):\n    user_id = payload['id']\n    uuid = payload['uuid']\n    user = User.query.filter_by(id=user_id).one_or_none()\n    if user is None:\n        raise CredentialException('User ID invalid')\n\n    if not check_token(user_id, uuid):\n        raise CredentialException('Token invalid')\n    return user\n\ndef verify_token_string(token_string):\n    token = decode_token(token_string)\n    user = _verify(token)\n    return user\n\ndef exp_from_token(token):\n    token = decode_token(token)\n    return token['exp']\n\ndef revoke_token_string(token_str):\n    token = decode_token(token_str)\n    user_id = token['id']\n    uuid = token['uuid']\n    return revoke_token(user_id, uuid)\n\ndef revoke_token(user_id, token):\n    found = Token.query.filter_by(user_id=user_id, token=token).with_for_update().one_or_none()\n    if found is None:\n        return False\n    db.session.delete(found)\n    return True\n\ndef revoke_tokens(user):\n    tokens = Token.query.filter_by(user_id=user.id).with_for_update().all()\n    for token in tokens:\n        db.session.delete(token)\n\ndef revoke_user_code_tokens(user):\n    codes = Code.query.filter_by(user_id=user.id).with_for_update().all()\n    for code in codes:\n        db.session.delete(code)\n    revoke_tokens(user)\n\ndef get_exp(mins=30):\n    return datetime.utcnow() + timedelta(minutes=mins)\n\ndef issue_token(user, exp=None):\n    uuid = generate_uuid()\n    token = Token(user_id=user.id, token=uuid)\n    db.session.add(token)\n\n    exp = exp or get_exp()\n    payload = {'id': user.id, 'uuid': uuid, 'exp': exp}\n    token = jwt.encode(payload, app.secret_key, algorithm='HS256')\n    return token.decode('utf-8')\n\ndef consume_code_string(code_str):\n    code = decode_code(code_str)\n    return consume_code(code['id'], code['code'])\n\ndef consume_code(user_id, code):\n    found = Code.query.filter_by(user_id=user_id, code=code).with_for_update().one_or_none()\n    if found is None:\n        raise ValidationException(\"Code not found\")\n    if found.expires.timetuple() < datetime.utcnow().timetuple():\n        db.session.delete(found)\n        raise CredentialException(\"Code expired\")\n    db.session.delete(found)\n    return User.query.filter_by(id=user_id).one_or_none()\n\ndef verify_hash(password, pw_hash):\n    try:\n        if not pwd_context.verify(password, pw_hash):\n            raise CredentialException('Password verification failed')\n    except ValueError:\n        raise CredentialException('Password verification failed')\n\ndef try_login(user, password):\n    if not user.is_active:\n        return False\n\n    try:\n        verify_hash(password, user.password)\n    except CredentialException:\n        return False\n    update_last_login(user)\n    return True\n\nlinkgenerator = itsdangerous.URLSafeTimedSerializer(\n    app.secret_key,\n    salt='quilt'\n    )\n\ndef dump_link(payload, salt=None):\n    link = linkgenerator.dumps(payload, salt=salt)\n    return link.replace('.', '~')\n\ndef load_link(link, max_age, salt=None):\n    payload = link.replace('~', '.')\n    return linkgenerator.loads(payload, max_age=max_age, salt=salt)\n\ndef generate_activation_token(user_id):\n    new_token = ActivationToken(user_id=user_id, token=generate_uuid())\n    db.session.add(new_token)\n    return new_token.token\n\ndef consume_activation_token(user_id, token):\n    found = (\n        ActivationToken.query\n        .filter_by(user_id=user_id, token=token)\n        .with_for_update()\n        .one_or_none()\n    )\n    if not found:\n        return False\n    db.session.delete(found)\n    return True\n\ndef generate_reset_token(user_id):\n    reset_token = generate_uuid()\n    PasswordResetToken.upsert(user_id, reset_token)\n    return reset_token\n\ndef consume_reset_token(user_id, token):\n    found = (\n        PasswordResetToken\n        .query\n        .filter_by(user_id=user_id, token=token)\n        .with_for_update()\n        .one_or_none()\n    )\n    if not found:\n        return False\n    db.session.delete(found)\n    return True\n\ndef generate_activation_link(user_id):\n    token = generate_activation_token(user_id)\n    payload = {'id': user_id, 'token': token}\n    return dump_link(payload, ACTIVATE_SALT)\n\ndef generate_reset_link(user_id):\n    token = generate_reset_token(user_id)\n    payload = {'id': user_id, 'token': token}\n    return dump_link(payload, PASSWORD_RESET_SALT)\n\ndef verify_activation_link(link, max_age=None):\n    max_age = max_age if max_age is not None else MAX_LINK_AGE\n    try:\n        payload = load_link(link, max_age=max_age, salt=ACTIVATE_SALT)\n        if not consume_activation_token(payload['id'], payload['token']):\n            return None\n        return payload\n    except (TypeError, KeyError, ValueError, itsdangerous.BadData):\n        return None\n\ndef verify_reset_link(link, max_age=None):\n    max_age = max_age if max_age is not None else MAX_LINK_AGE\n    try:\n        payload = load_link(link, max_age=max_age, salt=PASSWORD_RESET_SALT)\n        if not consume_reset_token(payload['id'], payload['token']):\n            return None\n        return payload\n    except (TypeError, KeyError, ValueError, itsdangerous.BadData):\n        return None\n\ndef reset_password(user, set_unusable=False):\n    if set_unusable:\n        user.password = ''\n        db.session.add(user)\n\n    link = generate_reset_link(user.id)\n    send_reset_email(user, link)\n", "idx": 1, "id": 16867, "msg": "@akarve this breaks error catching logic on the front end, I'll fix this. That's why I prefer to use some machine-friendly error codes that won't change frequently.", "proj": "quiltdata-quilt", "lang": "py"}
{"patch": "@@ -0,0 +1,7 @@\n+if (node.getAttribute('onFocus') === 'this.blur()') {\n+  return false;\n+}\n+if (node.getAttribute('onFocus').indexOf('this.blur()') > -1) {\n+  return undefined;\n+}\n+return true;", "y": 1, "oldf": "", "idx": 1, "id": 13307, "msg": "This should account for whitespace. Simply putting `.trim()` on the attribute value should do.", "proj": "dequelabs-axe-core", "lang": "js"}
{"patch": "@@ -171,8 +171,8 @@ bool CliManager::readLine(std::string &line, bool linebreak) {\n         if (!isInteractive_) {\n             break;\n         }\n-        auto purePrompt = folly::stringPrintf(\"(%s@%s:%d) [%s]> \",\n-                                              username_.c_str(), addr_.c_str(), port_,\n+        auto purePrompt = folly::stringPrintf(\"(%s@) [%s]> \",\n+                                              username_.c_str(),\n                                               cmdProcessor_->getSpaceName().c_str());\n         if (linebreak) {\n             purePrompt.assign(purePrompt.size() - 3, ' ');", "y": 1, "oldf": "/* Copyright (c) 2018 vesoft inc. All rights reserved.\n *\n * This source code is licensed under Apache 2.0 License,\n * attached with Common Clause Condition 1.0, found in the LICENSES directory.\n */\n\n#include \"base/Base.h\"\n#include \"base/Status.h\"\n#include <termios.h>\n#include <unistd.h>\n#include \"readline/readline.h\"\n#include \"readline/history.h\"\n#include \"console/CliManager.h\"\n#include \"client/cpp/GraphClient.h\"\n#include \"fs/FileUtils.h\"\n\nDECLARE_string(u);\nDECLARE_string(p);\nDEFINE_bool(enable_history, false, \"Whether to force saving the command history\");\n\nnamespace nebula {\nnamespace graph {\n\nconst int32_t kMaxAuthInfoRetries = 3;\nconst int32_t kMaxUsernameLen = 16;\nconst int32_t kMaxPasswordLen = 24;\n\nCliManager::CliManager() {\n    if (!fs::FileUtils::isStdinTTY()) {\n        enableHistroy_ = false;\n        isInteractive_ = false;\n    }\n\n    if (FLAGS_enable_history) {\n        enableHistroy_ = true;\n    }\n\n    if (enableHistroy_) {\n        ::using_history();\n    }\n\n    if (isInteractive_) {\n        initAutoCompletion();\n    }\n}\n\n\nbool CliManager::connect(const std::string& addr,\n                         uint16_t port,\n                         const std::string& username,\n                         const std::string& password) {\n    char user[kMaxUsernameLen + 1];\n    char pass[kMaxPasswordLen + 1];\n\n    strncpy(user, username.c_str(), kMaxUsernameLen);\n    user[kMaxUsernameLen] = '\\0';\n    strncpy(pass, password.c_str(), kMaxPasswordLen);\n    pass[kMaxPasswordLen] = '\\0';\n\n    // Make sure username is not empty\n    if (FLAGS_u.empty()) {\n        for (int32_t i = 0; i < kMaxAuthInfoRetries && !strlen(user); i++) {\n            // Need to interactively get the username\n            std::cout << \"Username: \";\n            std::cin.getline(user, kMaxUsernameLen);\n            user[kMaxUsernameLen] = '\\0';\n        }\n    } else {\n        strcpy(user, FLAGS_u.c_str());  // NOLINT\n    }\n    if (!strlen(user)) {\n        std::cout << \"Authentication failed: \"\n                     \"Need a valid username to authenticate\\n\\n\";\n        return false;\n    }\n\n    // Make sure password is not empty\n    if (FLAGS_p.empty()) {\n        for (int32_t i = 0; i < kMaxAuthInfoRetries && !strlen(pass); i++) {\n            // Need to interactively get the password\n            std::cout << \"Password: \";\n            termios oldTerminal;\n            tcgetattr(STDIN_FILENO, &oldTerminal);\n            termios newTerminal = oldTerminal;\n            newTerminal.c_lflag &= ~ECHO;\n            tcsetattr(STDIN_FILENO, TCSANOW, &newTerminal);\n            std::cin.getline(pass, kMaxPasswordLen);\n            pass[kMaxPasswordLen] = '\\0';\n            tcsetattr(STDIN_FILENO, TCSANOW, &oldTerminal);\n        }\n    } else {\n        strcpy(pass, FLAGS_p.c_str());  // NOLINT\n    }\n    if (!strlen(pass)) {\n        std::cout << \"Authentication failed: \"\n                     \"Need a valid password\\n\\n\";\n        return false;\n    }\n\n    addr_ = addr;\n    port_ = port;\n    username_ = user;\n\n    auto client = std::make_unique<GraphClient>(addr_, port_);\n    cpp2::ErrorCode res = client->connect(user, pass);\n    if (res == cpp2::ErrorCode::SUCCEEDED) {\n#if defined(NEBULA_BUILD_VERSION)\n        std::cerr << \"\\nWelcome to Nebula Graph (Version \"\n                  << NEBULA_STRINGIFY(NEBULA_BUILD_VERSION) << \")\\n\\n\";\n#else\n        std::cerr << \"\\nWelcome to Nebula Graph\\n\\n\";\n#endif\n        cmdProcessor_ = std::make_unique<CmdProcessor>(std::move(client));\n        return true;\n    } else {\n        // There is an error\n        std::cout << \"Connection failed\\n\";\n        return false;\n    }\n}\n\n\nvoid CliManager::batch(const std::string& filename) {\n    UNUSED(filename);\n}\n\n\nvoid CliManager::loop() {\n    loadHistory();\n\n    while (true) {\n        std::string cmd;\n        std::string line;\n        auto quit = !this->readLine(line, false/*linebreak*/);\n        // EOF\n        if (quit) {\n            break;\n        }\n        // Empty line\n        if (line.empty()) {\n            continue;\n        }\n        // Line break\n        while (!quit && !line.empty() && line.back() == '\\\\') {\n            line.resize(line.size() - 1);\n            cmd += line;\n            quit = !this->readLine(line, true/*linebreak*/);\n            continue;\n        }\n        // EOF\n        if (quit) {\n            break;\n        }\n        // Execute the whole command\n        cmd += line;\n        if (!cmdProcessor_->process(cmd)) {\n            break;\n        }\n    }\n\n    saveHistory();\n    fprintf(stderr, \"Bye!\\n\");\n}\n\n\nbool CliManager::readLine(std::string &line, bool linebreak) {\n    // Setup the prompt\n    std::string prompt;\n    static auto color = 0u;\n    do {\n        if (!isInteractive_) {\n            break;\n        }\n        auto purePrompt = folly::stringPrintf(\"(%s@%s:%d) [%s]> \",\n                                              username_.c_str(), addr_.c_str(), port_,\n                                              cmdProcessor_->getSpaceName().c_str());\n        if (linebreak) {\n            purePrompt.assign(purePrompt.size() - 3, ' ');\n            purePrompt += \"-> \";\n        } else {\n            color++;\n        }\n\n        prompt = folly::stringPrintf(\n                   \"\\001\"              // RL_PROMPT_START_IGNORE\n                   \"\\033[1;%um\"        // color codes start\n                   \"\\002\"              // RL_PROMPT_END_IGNORE\n                   \"%s\"                // prompt \"(user@host:port) [spaceName]\"\n                   \"\\001\"              // RL_PROMPT_START_IGNORE\n                   \"\\033[0m\"           // restore color code\n                   \"\\002\",             // RL_PROMPT_END_IGNORE\n                   color % 6 + 31,\n                   purePrompt.c_str());\n    } while (false);\n\n    // Read one line\n    auto *input = ::readline(prompt.c_str());\n    auto ok = true;\n    do {\n        // EOF\n        if (input == nullptr) {\n            fprintf(stdout, \"\\n\");\n            ok = false;\n            break;\n        }\n        // Empty line\n        if (input[0] == '\\0') {\n            line.clear();\n            break;\n        }\n        line = folly::trimWhitespace(input).str();\n        if (!line.empty()) {\n            // Update command history\n            updateHistory(input);\n        }\n    } while (false);\n\n    ::free(input);\n\n    return ok;\n}\n\n\nvoid CliManager::updateHistory(const char *line) {\n    if (!enableHistroy_) {\n        return;\n    }\n    auto **hists = ::history_list();\n    auto i = 0;\n    // Search in history\n    for (; i < ::history_length; i++) {\n        auto *hist = hists[i];\n        if (::strcmp(line, hist->line) == 0) {\n            break;\n        }\n    }\n    // New command\n    if (i == ::history_length) {\n        ::add_history(line);\n        return;\n    }\n    // Found in history, make it lastest\n    auto *hist = hists[i];\n    for (; i < ::history_length - 1; i++) {\n        hists[i] = hists[i + 1];\n    }\n    hists[i] = hist;\n}\n\n\nvoid CliManager::saveHistory() {\n    if (!enableHistroy_) {\n        return;\n    }\n    std::string histfile;\n    histfile += ::getenv(\"HOME\");\n    histfile += \"/.nebula_history\";\n    auto *file = ::fopen(histfile.c_str(), \"w+\");\n    if (file == nullptr) {\n        return;     // fail silently\n    }\n    auto **hists = ::history_list();\n    for (auto i = 0; i < ::history_length; i++) {\n        fprintf(file, \"%s\\n\", hists[i]->line);\n    }\n    ::fflush(file);\n    ::fclose(file);\n}\n\n\nvoid CliManager::loadHistory() {\n    if (!enableHistroy_) {\n        return;\n    }\n    std::string histfile;\n    histfile += ::getenv(\"HOME\");\n    histfile += \"/.nebula_history\";\n    auto *file = ::fopen(histfile.c_str(), \"r\");\n    if (file == nullptr) {\n        return;     // fail silently\n    }\n    char *line = nullptr;\n    size_t size = 0;\n    ssize_t read = 0;\n    while ((read = ::getline(&line, &size, file)) != -1) {\n        line[read - 1] = '\\0';  // remove the trailing newline\n        updateHistory(line);\n    }\n    ::free(line);\n    ::fclose(file);\n}\n\n\nstruct StringCaseEqual {\n    bool operator()(const std::string &lhs, const std::string &rhs) const {\n        return ::strcasecmp(lhs.c_str(), rhs.c_str()) == 0;\n    }\n};\n\n\nstruct StringCaseHash {\n    size_t operator()(const std::string &lhs) const {\n        std::string upper;\n        upper.resize(lhs.size());\n        auto toupper = [] (auto c) { return ::toupper(c); };\n        std::transform(lhs.begin(), lhs.end(), upper.begin(), toupper);\n        return std::hash<std::string>()(upper);\n    }\n};\n\n// Primary keywords, like `GO' `CREATE', etc.\nstatic std::vector<std::string> primaryKeywords;\n\n// Keywords along with their sub-keywords, like `SHOW': `TAGS', `SPACES'\nstatic std::unordered_map<std::string, std::vector<std::string>,\n                          StringCaseHash, StringCaseEqual> subKeywords;\n// Typenames, like `int', `double', `string', etc.\nstatic std::vector<std::string> typeNames;\n\n\n// To fill the containers above from a json file.\nstatic Status loadCompletions();\nstatic Status parseKeywordsFromJson(const folly::dynamic &json);\n\n// To retrieve matches from within the `primaryKeywords'\nstatic std::vector<std::string>\nmatchFromPrimaryKeywords(const std::string &text);\n\n// To retrieve matches from within the `subKeywords'\nstatic std::vector<std::string> matchFromSubKeywords(const std::string &text,\n                                                     const std::string &primaryKeyword);\n\n// Given a collection of keywords, retrieve matches that prefixed with `text'\nstatic std::vector<std::string> matchFromKeywords(const std::string &text,\n                                                  const std::vector<std::string> &keywords);\n\n// To tell if the current `text' is at the start position of a statement.\n// If so, we should do completion with primary keywords.\n// Otherwise, the primary keyword of the current statement\n// will be set, thus we will do completion with its sub keywords.\nstatic bool isStartOfStatement(std::string &primaryKeyword);\n\n// Given the prefix and a collection of keywords, retrieve the longest common prefix\n// e.g. given `u' as the prefix and [USE, USER, USERS] as the collection, will return `USE'\nstatic auto longestCommonPrefix(std::string prefix,\n                                const std::vector<std::string>& words);\n\n// Callback by realine if an auto completion is triggered\nstatic char** completer(const char *text, int start, int end);\n\n\nauto longestCommonPrefix(std::string prefix,\n                         const std::vector<std::string>& words) {\n    if (words.size() == 1) {\n        return words[0];\n    }\n\n    while (true) {\n        char nextChar = 0;\n        for (auto &word : words) {\n            if (word.size() <= prefix.size()) {\n                return word;\n            }\n            if (nextChar == 0) {\n                nextChar = word[prefix.size()];\n                continue;\n            }\n            if (::toupper(nextChar) != ::toupper(word[prefix.size()])) {\n                return word.substr(0, prefix.size());\n            }\n        }\n        prefix = words[0].substr(0, prefix.size() + 1);\n    }\n}\n\n\nchar** completer(const char *text, int start, int end) {\n    UNUSED(start);\n    UNUSED(end);\n\n    // Dont do filename completion even there is no match.\n    ::rl_attempted_completion_over = 1;\n\n    // Dont do completion if in quotes\n    if (::rl_completion_quote_character != 0) {\n        return nullptr;\n    }\n\n    std::vector<std::string> matches;\n\n    std::string primaryKeyword;  // The current primary keyword\n    if (isStartOfStatement(primaryKeyword)) {\n        matches = matchFromPrimaryKeywords(text);\n    } else {\n        matches = matchFromSubKeywords(text, primaryKeyword);\n    }\n\n    if (matches.empty()) {\n        return nullptr;\n    }\n\n    char **results = reinterpret_cast<char**>(malloc((2 + matches.size()) * sizeof(char*)));\n\n    // Get the longest common prefix of all matches as the echo back of this completion action\n    results[0] = ::strdup(longestCommonPrefix(text, matches).c_str());\n\n    auto i = 1;\n    for (auto &word : matches) {\n        results[i++] = ::strdup(word.c_str());\n    }\n    results[i] = nullptr;\n\n    return results;\n}\n\n\nbool isStartOfStatement(std::string &primaryKeyword) {\n    // If there is no input\n    if (::rl_line_buffer == nullptr || *::rl_line_buffer == '\\0') {\n        return true;\n    }\n\n    std::string line = ::rl_line_buffer;\n\n    auto piece = folly::trimWhitespace(line);\n    // If the inputs are all white spaces\n    if (piece.empty()) {\n        return true;\n    }\n\n    // If the inputs are terminated with ';' or '|', i.e. complete statements\n    // Additionally, there is an incomplete primary keyword for the next statement\n    {\n        static const std::regex pattern(R\"((\\s*\\w+[^;|]*[;|]\\s*)*(\\w+)?)\");\n        std::smatch result;\n\n        if (std::regex_match(line, result, pattern)) {\n            return true;\n        }\n    }\n\n    // The same to the occasion above, except that the primary keyword is complete\n    // This is where sub keywords shall be completed\n    {\n        static const std::regex pattern(R\"((\\s*\\w+[^;|]*[;|]\\s*)*(\\w+)[^;|]+)\");\n        std::smatch result;\n\n        if (std::regex_match(line, result, pattern)) {\n            primaryKeyword = result[result.size() - 1].str();\n            return false;\n        }\n    }\n\n    // TODO(dutor) There are still many scenarios we cannot cover with regular expressions.\n    // We have to accomplish this with the help of the actual parser.\n\n    return false;\n}\n\n\nstd::vector<std::string> matchFromPrimaryKeywords(const std::string &text) {\n    return matchFromKeywords(text, primaryKeywords);\n}\n\n\nstd::vector<std::string> matchFromSubKeywords(const std::string &text,\n                                              const std::string &primaryKeyword) {\n    std::vector<std::string> matches = typeNames;\n    auto iter = subKeywords.find(primaryKeyword);\n    if (iter != subKeywords.end()) {\n        matches.insert(matches.end(), iter->second.begin(), iter->second.end());\n    }\n    return matchFromKeywords(text, matches);\n}\n\n\nstd::vector<std::string>\nmatchFromKeywords(const std::string &text, const std::vector<std::string> &keywords) {\n    if (keywords.empty()) {\n        return {};\n    }\n\n    std::vector<std::string> matches;\n    for (auto &word : keywords) {\n        if (text.size() > word.size()) {\n            continue;\n        }\n        if (::strncasecmp(text.c_str(), word.c_str(), text.size()) == 0) {\n            matches.emplace_back(word);\n        }\n    }\n\n    return matches;\n}\n\n\nStatus loadCompletions() {\n    using fs::FileUtils;\n    auto dir = FileUtils::readLink(\"/proc/self/exe\").value();\n    dir = FileUtils::dirname(dir.c_str()) + \"/../share/resources\";\n    std::string file = dir + \"/\" + \"completion.json\";\n    auto status = Status::OK();\n    int fd = -1;\n    do {\n        fd = ::open(file.c_str(), O_RDONLY);\n        if (fd == -1) {\n            status = Status::Error(\"Failed to open `%s': %s\",\n                                    file.c_str(), ::strerror(errno));\n            break;\n        }\n\n        auto len = ::lseek(fd, 0, SEEK_END);\n        if (len == 0) {\n            status = Status::Error(\"File `%s' is empty\", file.c_str());\n            break;\n        }\n\n        auto buffer = std::make_unique<char[]>(len + 1);\n        ::lseek(fd, 0, SEEK_SET);\n        auto ll = ::read(fd, buffer.get(), len);\n        UNUSED(ll);\n        buffer[len] = '\\0';\n\n        std::string content;\n        content.assign(buffer.get(), len);\n\n        try {\n            status = parseKeywordsFromJson(folly::parseJson(content));\n        } catch (const std::exception &e) {\n            status = Status::Error(\"Illegal json `%s': %s\", file.c_str(), e.what());\n            break;\n        }\n\n        if (!status.ok()) {\n            break;\n        }\n    } while (false);\n\n    if (fd != -1) {\n        ::close(fd);\n    }\n\n    return status;\n}\n\n\nStatus parseKeywordsFromJson(const folly::dynamic &json) {\n    auto iter = json.find(\"keywords\");\n    if (iter == json.items().end()) {\n        fprintf(stderr, \"completions: no `keywords' found\\n\");\n        return Status::OK();\n    }\n\n    for (auto &pair : iter->second.items()) {\n        auto &pkw = pair.first;\n        primaryKeywords.emplace_back(pkw.asString());\n        auto subIter = pair.second.find(\"sub_keywords\");\n        if (subIter == pair.second.items().end()) {\n            continue;\n        }\n        if (!subIter->second.isArray()) {\n            fprintf(stderr, \"sub-keywords for `%s' should be an array\\n\",\n                    pkw.asString().c_str());\n            continue;\n        }\n        for (auto &subKey : subIter->second) {\n            if (!subKey.isString()) {\n                fprintf(stderr, \"keyword name should be of type string\\n\");\n                break;\n            }\n            subKeywords[pkw.asString()].emplace_back(subKey.asString());\n        }\n    }\n\n    iter = json.find(\"typenames\");\n    if (iter == json.items().end()) {\n        fprintf(stderr, \"completions: no `typenames' found\\n\");\n        return Status::OK();\n    }\n\n    for (auto &tname : iter->second) {\n        typeNames.emplace_back(tname.asString());\n    }\n\n    return Status::OK();\n}\n\n\nvoid CliManager::initAutoCompletion() {\n    // The completion function\n    ::rl_attempted_completion_function = completer;\n    // Characters that indicates begin or end of a quote\n    ::rl_completer_quote_characters = \"\\\"\";\n    // Allow conditional parsing of the ~/.inputrc file\n    ::rl_readline_name = \"nebula-graph\";\n    auto status = loadCompletions();\n    if (!status.ok()) {\n        fprintf(stderr, \"%s\\n\", status.toString().c_str());\n    }\n}\n\n}  // namespace graph\n}  // namespace nebula\n", "idx": 1, "id": 28362, "msg": "You can replace IP by hostname.", "proj": "vesoft-inc-nebula", "lang": "cpp"}
{"patch": "@@ -123,6 +123,12 @@ public class DatabaseHelper extends DaoMaster.OpenHelper {\n                     }\n                 }\n                 break;\n+            case 10:\n+                AllergenDao.dropTable(db, true);\n+                AllergenDao.createTable(db, true);\n+                AllergenNameDao.dropTable(db, true);\n+                AllergenNameDao.createTable(db, true);\n+                break;\n         }\n     }\n ", "y": 1, "oldf": "package openfoodfacts.github.scrachx.openfood.models;\n\nimport android.content.Context;\nimport android.content.SharedPreferences;\nimport android.database.Cursor;\nimport android.database.sqlite.SQLiteDatabase;\nimport android.util.Log;\n\nimport org.greenrobot.greendao.database.Database;\n\nimport openfoodfacts.github.scrachx.openfood.utils.Utils;\n\npublic class DatabaseHelper extends DaoMaster.OpenHelper {\n\n    private SharedPreferences settings;\n\n    public DatabaseHelper(Context context, String name, SQLiteDatabase.CursorFactory factory) {\n        super(context, name, factory);\n\n        settings = context.getSharedPreferences(\"prefs\", 0);\n    }\n\n    public DatabaseHelper(Context context, String name) {\n        super(context, name);\n\n        settings = context.getSharedPreferences(\"prefs\", 0);\n    }\n\n\n    @Override\n    public void onCreate(Database db) {\n        Log.i(\"greenDAO\", \"Creating tables for schema version \" + DaoMaster.SCHEMA_VERSION);\n        DaoMaster.createAllTables(db, true);\n    }\n\n    @Override\n    public void onUpgrade(Database db, int oldVersion, int newVersion) {\n        Log.i(\"greenDAO\", \"migrating schema from version \" + oldVersion + \" to \" + newVersion);\n        //dropAllTables(db, true);\n        for (int migrateVersion = oldVersion + 1; migrateVersion <= newVersion; migrateVersion++) {\n            upgrade(db, migrateVersion);\n        }\n\n        //db model has changed we need to invalidate and reload taxonomies\n        if( settings != null && oldVersion != newVersion )\n        {\n            settings.edit().putLong( Utils.LAST_REFRESH_DATE, 0 ).apply();\n        }\n    }\n\n    /**\n     * in case of android.database.sqlite.SQLiteException, the schema version is\n     * left untouched just fix the code in the version case and push a new\n     * release\n     *\n     * @param db             database\n     * @param migrateVersion\n     */\n    private void upgrade(Database db, int migrateVersion) {\n        Log.e(\"MIGRATE VERSION\", \"\" + migrateVersion);\n        switch (migrateVersion) {\n            case 2:\n                db.execSQL(\"ALTER TABLE send_product ADD COLUMN 'lang' TEXT NOT NULL DEFAULT 'fr';\");\n                break;\n            case 3:\n                ToUploadProductDao.createTable(db, true);\n                break;\n            case 4:\n                TagDao.createTable(db, true);\n                break;\n            case 5: {\n                db.execSQL(\"ALTER TABLE history_product ADD COLUMN 'quantity' TEXT NOT NULL DEFAULT '';\");\n                db.execSQL(\"ALTER TABLE history_product ADD COLUMN 'nutrition_grade' TEXT NOT NULL DEFAULT '';\");\n                break;\n            }\n            case 6: {\n                LabelDao.createTable(db, true);\n                LabelNameDao.createTable(db, true);\n\n                AllergenDao.dropTable(db, true);\n                AllergenDao.createTable(db, true);\n                AllergenNameDao.createTable(db, true);\n\n                AdditiveDao.dropTable(db, true);\n                AdditiveDao.createTable(db, true);\n                AdditiveNameDao.createTable(db, true);\n\n                CountryDao.createTable(db, true);\n                CountryNameDao.createTable(db, true);\n\n                CategoryDao.createTable(db, true);\n                CategoryNameDao.createTable(db, true);\n                break;\n            }\n            case 7: {\n                String newColumns[] = new String[]{\"wiki_data_id\", \"is_wiki_data_id_present\"};\n                String updatedTables[] = new String[]{\"additive_name\", \"additive\", \"category_name\", \"category\", \"label_name\", \"label\"};\n                for (String table : updatedTables) {\n                    for (String column : newColumns) {\n                        if (!isFieldExist(db, table, column)) {\n                            db.execSQL(String.format(\"ALTER TABLE %s ADD COLUMN '%s' TEXT NOT NULL DEFAULT '';\", table, column));\n                        }\n                    }\n                }\n\n                break;\n            }\n            case 8:\n                OfflineSavedProductDao.createTable(db, true);\n                break;\n            case 9:\n                String newColumns[] = new String[]{ \"overexposure_risk\", \"exposure_mean_greater_than_adi\", \"exposure_mean_greater_than_noael\",\n                        \"exposure95_th_greater_than_adi\", \"exposure95_th_greater_than_noael\" };\n                String updatedTables[] = new String[]{ \"additive_name\", \"additive\" };\n                for( String table : updatedTables )\n                {\n                    for( String column : newColumns )\n                    {\n                        if (!isFieldExist(db, table, column))\n                        {\n                            db.execSQL( String.format( \"ALTER TABLE %s ADD COLUMN '%s' TEXT;\", table, column ) );\n                        }\n                    }\n                }\n                break;\n        }\n    }\n\n    private boolean isFieldExist(Database db, String tableName, String fieldName) {\n        boolean isExist = false;\n        String query = String.format(\"PRAGMA table_info(%s)\", tableName);\n        Cursor res = db.rawQuery(query, null);\n        res.moveToFirst();\n        do {\n            String currentColumn = res.getString(1);\n            if (currentColumn.equals(fieldName)) {\n                isExist = true;\n            }\n        } while (res.moveToNext());\n\n        return isExist;\n    }\n}", "idx": 1, "id": 65977, "msg": "Is dropping the **Allergen table** necessary? Can't we just add the two new columns to the existing table using a raw query?", "proj": "openfoodfacts-openfoodfacts-androidapp", "lang": "java"}
{"patch": "@@ -1,7 +1,7 @@\n class FollowUp < ActiveRecord::Base\n   belongs_to :course\n-  validates_presence_of :email\n-  validates_format_of :email, with: /\\A([^@\\s]+)@((?:[-a-z0-9]+\\.)+[a-z]{2,})\\Z/i, on: :create\n+  EMAIL_FORMAT = /\\A([^@\\s]+)@((?:[-a-z0-9]+\\.)+[a-z]{2,})\\Z/i\n+  validates :email, presence: true, format: { with: EMAIL_FORMAT }, on: :create\n \n   scope :have_not_notified, where(notified_at: nil)\n ", "y": 1, "oldf": "class FollowUp < ActiveRecord::Base\n  belongs_to :course\n  validates_presence_of :email\n  validates_format_of :email, with: /\\A([^@\\s]+)@((?:[-a-z0-9]+\\.)+[a-z]{2,})\\Z/i, on: :create\n\n  scope :have_not_notified, where(notified_at: nil)\n\n  def notify(section)\n    Mailer.follow_up(self, section).deliver\n    self.notified_at = Time.now\n    self.save\n  end\nend\n", "idx": 1, "id": 6764, "msg": "Not sure if this constant is defined at the right place style-wise. Maybe move it up to before 'belongs_to' like DISCOUNT_TYPES in coupon.rb?", "proj": "thoughtbot-upcase", "lang": "rb"}
{"patch": "@@ -11,7 +11,7 @@ if (typeof define === 'function' && define.amd) {\n \t});\n }\n if (typeof module === 'object' && module.exports && typeof axeFunction.toString === 'function') {\n-    axe.source = '(' + axeFunction.toString() + ')(this, this.document);';\n+    axe.source = '(' + axeFunction.toString() + ')(typeof window === \"object\" ? window : this);';\n     module.exports = axe;\n }\n if (typeof window.getComputedStyle === 'function') {", "y": 1, "oldf": "/*exported axe, commons */\n/*global axeFunction, module, define */\n// exported namespace for aXe\nvar axe = axe || {};\naxe.version = '<%= pkg.version %>';\n\nif (typeof define === 'function' && define.amd) {\n\tdefine([], function () {\n\t\t'use strict';\n\t\treturn axe;\n\t});\n}\nif (typeof module === 'object' && module.exports && typeof axeFunction.toString === 'function') {\n    axe.source = '(' + axeFunction.toString() + ')(this, this.document);';\n    module.exports = axe;\n}\nif (typeof window.getComputedStyle === 'function') {\n    window.axe = axe;\n}\n// local namespace for common functions\nvar commons;\n\nfunction SupportError(error) {\n\tthis.name = 'SupportError';\n\tthis.cause = error.cause;\n\tthis.message = `\\`${error.cause}\\` - feature unsupported in your environment.`;\n\tif (error.ruleId) {\n\t\tthis.ruleId = error.ruleId;\n\t\tthis.message += ` Skipping ${this.ruleId} rule.`;\n\t}\n\tthis.stack = (new Error()).stack;\n}\nSupportError.prototype = Object.create(Error.prototype);\nSupportError.prototype.constructor = SupportError;\n", "idx": 1, "id": 11121, "msg": "hey, aren't we supposed to be passing in two parameters here?", "proj": "dequelabs-axe-core", "lang": "js"}
{"patch": "@@ -19,4 +19,15 @@ module IntegrationSpecHelper\n       }\n     )\n   end\n+\n+  def with_18f_procurement_env_variables(setup_vars=nil)\n+    old_approver_email = ENV['GSA18F_APPROVER_EMAIL']\n+    old_purchaser_email = ENV['GSA18F_PURCHASER_EMAIL']\n+\n+    ENV['GSA18F_APPROVER_EMAIL'] = 'test_approver@some-dot-gov.gov'\n+    ENV['GSA18F_PURCHASER_EMAIL'] = 'test_purchaser@some-dot-gov.gov'\n+    yield\n+    ENV['GSA18F_APPROVER_EMAIL'] = old_approver_email\n+    ENV['GSA18F_PURCHASER_EMAIL'] = old_purchaser_email\n+  end\n end", "y": 1, "oldf": "module IntegrationSpecHelper\n  def setup_mock_auth(service_name=:myusa, user=FactoryGirl.create(:user))\n    OmniAuth.config.mock_auth[service_name] = OmniAuth::AuthHash.new(\n      provider: service_name.to_s,\n      raw_info: {\n        'name' => \"George Jetson\"\n      },\n      uid: '12345',\n      nickname: 'georgejetsonmyusa',\n      extra: {\n        'raw_info' => {\n          'email' => user.email_address,\n          'first_name' => user.first_name,\n          'last_name' => user.last_name\n        }\n      },\n      credentials: {\n        'token' => '1a2b3c4d'\n      }\n    )\n  end\nend\n", "idx": 1, "id": 13225, "msg": "Can we put this in a different helper?", "proj": "18F-C2", "lang": "rb"}
{"patch": "@@ -1,5 +1,9 @@\n 'use strict';\n \n+const parseConnectionString = require('./core/uri_parser');\n+\n+const writeConcernKeys = new Set(['w', 'wtimeout', 'j', 'fsync', 'wtimeoutMS', 'journal']);\n+\n /**\n  * The **WriteConcern** class is a class that represents a MongoDB WriteConcern.\n  * @class", "y": 1, "oldf": "'use strict';\n\n/**\n * The **WriteConcern** class is a class that represents a MongoDB WriteConcern.\n * @class\n * @property {(number|string)} w The write concern\n * @property {number} wtimeout The write concern timeout\n * @property {boolean} j The journal write concern\n * @property {boolean} fsync The file sync write concern\n * @see https://docs.mongodb.com/manual/reference/write-concern/index.html\n */\nclass WriteConcern {\n  /**\n   * Constructs a WriteConcern from the write concern properties.\n   * @param {(number|string)} [w] The write concern\n   * @param {number} [wtimeout] The write concern timeout\n   * @param {boolean} [j] The journal write concern\n   * @param {boolean} [fsync] The file sync write concern\n   */\n  constructor(w, wtimeout, j, fsync) {\n    if (w != null) {\n      this.w = w;\n    }\n    if (wtimeout != null) {\n      this.wtimeout = wtimeout;\n    }\n    if (j != null) {\n      this.j = j;\n    }\n    if (fsync != null) {\n      this.fsync = fsync;\n    }\n  }\n\n  /**\n   * Construct a WriteConcern given an options object.\n   *\n   * @param {object} options The options object from which to extract the write concern.\n   * @return {WriteConcern}\n   */\n  static fromOptions(options) {\n    if (\n      options == null ||\n      (options.writeConcern == null &&\n        options.w == null &&\n        options.wtimeout == null &&\n        options.j == null &&\n        options.fsync == null)\n    ) {\n      return;\n    }\n\n    if (options.writeConcern) {\n      return new WriteConcern(\n        options.writeConcern.w,\n        options.writeConcern.wtimeout,\n        options.writeConcern.j,\n        options.writeConcern.fsync\n      );\n    }\n\n    return new WriteConcern(options.w, options.wtimeout, options.j, options.fsync);\n  }\n}\n\nmodule.exports = WriteConcern;\n", "idx": 1, "id": 16463, "msg": "if we keep this, can we stick to our convention of using UPPER_CASE for constants? Otherwise this looks like a floating variable to me.", "proj": "mongodb-node-mongodb-native", "lang": "js"}
{"patch": "@@ -1,3 +1,19 @@\n+/*\n+ * Copyright 2012 LinkedIn Corp.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n package azkaban.user;\n \n /**", "y": 1, "oldf": "package azkaban.user;\n\n/**\n * Lambda interface for parsing user config file.\n */\npublic interface ParseConfigFile {\n  void parseConfigFile();\n}\n", "idx": 1, "id": 17973, "msg": "please update the year. it can be setup in intellij template.", "proj": "azkaban-azkaban", "lang": "java"}
{"patch": "@@ -159,6 +159,17 @@ public final class Require {\n     return number;\n   }\n \n+  public static double positive(String argName, double number, String message) {\n+    if (number <= 0) {\n+      if (message == null) {\n+        throw new IllegalArgumentException(argName + \" must be greater than 0\");\n+      } else {\n+        throw new IllegalArgumentException(message);\n+      }\n+    }\n+    return number;\n+  }\n+\n   public static int positive(String argName, Integer number) {\n     return positive(argName, number, null);\n   }", "y": 1, "oldf": "// Licensed to the Software Freedom Conservancy (SFC) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The SFC licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\n\npackage org.openqa.selenium.internal;\n\nimport java.io.File;\nimport java.nio.file.Files;\nimport java.nio.file.Path;\nimport java.time.Duration;\nimport java.util.Objects;\n\n/**\n * A utility class to check arguments (preconditions) and state.\n * <p>\n * Examples of use:\n * <pre>\n *   public void setActionWithTimeout(Action action delegate, int timeout) {\n *     this.action = Require.nonNull(\"Action\", action);\n *     this.timeout = Require.positive(\"Timeout\", timeout);\n *   }\n * </pre>\n */\npublic final class Require {\n\n  private static final String ARG_MUST_BE_SET = \"%s must be set\";\n  private static final String MUST_EXIST = \"%s must exist: %s\";\n  private static final String MUST_BE_DIR = \"%s must be a directory: %s\";\n  private static final String MUST_BE_FILE = \"%s must be a regular file: %s\";\n\n  private Require() {\n    // An utility class\n  }\n\n  public static void precondition(boolean condition, String message, Object... args) {\n    if (!condition) {\n      throw new IllegalArgumentException(String.format(message, args));\n    }\n  }\n\n  public static <T> T nonNull(String argName, T arg) {\n    if (arg == null) {\n      throw new IllegalArgumentException(String.format(ARG_MUST_BE_SET, argName));\n    }\n    return arg;\n  }\n\n  public static <T> T nonNull(String argName, T arg, String message, Object... args) {\n    if (arg == null) {\n      throw new IllegalArgumentException(\n        String.join(\" \", argName, String.format(message, args)));\n    }\n    return arg;\n  }\n\n  public static <T> ArgumentChecker<T> argument(String argName, T arg) {\n    return new ArgumentChecker<>(argName, arg);\n  }\n\n  public static class ArgumentChecker<T> {\n\n    private final String argName;\n    private final T arg;\n\n    ArgumentChecker(String argName, T arg) {\n      this.argName = argName;\n      this.arg = arg;\n    }\n\n    public T nonNull() {\n      if (arg == null) {\n        throw new IllegalArgumentException(String.format(ARG_MUST_BE_SET, argName));\n      }\n      return arg;\n    }\n\n    public T nonNull(String message, Object... args) {\n      if (arg == null) {\n        throw new IllegalArgumentException(String.format(message, args));\n      }\n      return arg;\n    }\n\n    public T equalTo(Object other) {\n      if (arg == null) {\n        throw new IllegalArgumentException(String.format(ARG_MUST_BE_SET, argName));\n      }\n      if (!Objects.equals(arg, other)) {\n        throw new IllegalArgumentException(argName + \" must be equal to `\" + other + \"`\");\n      }\n      return arg;\n    }\n\n    public T instanceOf(Class<?> cls) {\n      if (arg == null) {\n        throw new IllegalArgumentException(String.format(ARG_MUST_BE_SET, argName));\n      }\n      if (!cls.isInstance(arg)) {\n        throw new IllegalArgumentException(argName + \" must be an instance of \" + cls);\n      }\n      return arg;\n    }\n  }\n\n  public static Duration nonNegative(String argName, Duration arg) {\n    if (arg == null) {\n      throw new IllegalArgumentException(String.format(ARG_MUST_BE_SET, argName));\n    }\n    if (arg.isNegative()) {\n      throw new IllegalArgumentException(argName + \" must be set to 0 or more\");\n    }\n    return arg;\n  }\n\n  public static Duration nonNegative(Duration arg) {\n    if (arg == null) {\n      throw new IllegalArgumentException(\"Duration must be set\");\n    }\n    if (arg.isNegative()) {\n      throw new IllegalArgumentException(\"Duration must be set to 0 or more\");\n    }\n    return arg;\n  }\n\n  public static int nonNegative(String argName, Integer number) {\n    if (number == null) {\n      throw new IllegalArgumentException(String.format(ARG_MUST_BE_SET, argName));\n    }\n    if (number < 0) {\n      throw new IllegalArgumentException(argName + \" cannot be less than 0\");\n    }\n    return number;\n  }\n\n  public static int positive(String argName, Integer number, String message) {\n    if (number == null) {\n      throw new IllegalArgumentException(String.format(ARG_MUST_BE_SET, argName));\n    }\n    if (number <= 0) {\n      if (message == null) {\n        throw new IllegalArgumentException(argName + \" must be greater than 0\");\n      } else {\n        throw new IllegalArgumentException(message);\n      }\n    }\n    return number;\n  }\n\n  public static int positive(String argName, Integer number) {\n    return positive(argName, number, null);\n  }\n\n  public static IntChecker argument(String argName, Integer number) {\n    return new IntChecker(argName, number);\n  }\n\n  public static class IntChecker {\n\n    private final String argName;\n    private final Integer number;\n\n    IntChecker(String argName, Integer number) {\n      this.argName = argName;\n      this.number = number;\n    }\n\n    public int greaterThan(int max, String message) {\n      if (number == null) {\n        throw new IllegalArgumentException(String.format(ARG_MUST_BE_SET, argName));\n      }\n      if (number <= max) {\n        throw new IllegalArgumentException(message);\n      }\n      return number;\n    }\n  }\n\n  public static FileChecker argument(String argName, File file) {\n    return new FileChecker(argName, file);\n  }\n\n  public static class FileChecker {\n\n    private final String argName;\n    private final File file;\n\n    FileChecker(String argName, File file) {\n      this.argName = argName;\n      this.file = file;\n    }\n\n    public File isFile() {\n      if (file == null) {\n        throw new IllegalArgumentException(String.format(ARG_MUST_BE_SET, argName));\n      }\n      if (!file.exists()) {\n        throw new IllegalArgumentException(\n          String.format(MUST_EXIST, argName, file.getAbsolutePath()));\n      }\n      if (!file.isFile()) {\n        throw new IllegalArgumentException(\n          String.format(MUST_BE_FILE, argName, file.getAbsolutePath()));\n      }\n      return file;\n    }\n\n    public File isDirectory() {\n      if (file == null) {\n        throw new IllegalArgumentException(String.format(ARG_MUST_BE_SET, argName));\n      }\n      if (!file.exists()) {\n        throw new IllegalArgumentException(\n          String.format(MUST_EXIST, argName, file.getAbsolutePath()));\n      }\n      if (!file.isDirectory()) {\n        throw new IllegalArgumentException(\n          String.format(MUST_BE_DIR, argName, file.getAbsolutePath()));\n      }\n      return file;\n    }\n  }\n\n  public static void stateCondition(boolean state, String message, Object... args) {\n    if (!state) {\n      throw new IllegalStateException(String.format(message, args));\n    }\n  }\n\n  public static <T> StateChecker<T> state(String name, T state) {\n    return new StateChecker<>(name, state);\n  }\n\n  public static class StateChecker<T> {\n\n    private final String name;\n    private final T state;\n\n    StateChecker(String name, T state) {\n      this.name = name;\n      this.state = state;\n    }\n\n    public T nonNull() {\n      if (state == null) {\n        throw new IllegalStateException(name + \" must not be null\");\n      }\n      return state;\n    }\n\n    public T nonNull(String message, Object... args) {\n      if (state == null) {\n        throw new IllegalStateException(String.join(\" \", name, String.format(message, args)));\n      }\n      return state;\n    }\n\n    public T instanceOf(Class<?> cls) {\n      if (state == null) {\n        throw new IllegalStateException(String.format(ARG_MUST_BE_SET, name));\n      }\n      if (!cls.isInstance(state)) {\n        throw new IllegalStateException(name + \" must be an instance of \" + cls);\n      }\n      return state;\n    }\n  }\n\n  public static FileStateChecker state(String name, File file) {\n    return new FileStateChecker(name, file);\n  }\n\n  public static class FileStateChecker {\n\n    private final String name;\n    private final File file;\n\n    FileStateChecker(String name, File file) {\n      this.name = name;\n      this.file = file;\n    }\n\n    public File isFile() {\n      if (file == null) {\n        throw new IllegalStateException(String.format(ARG_MUST_BE_SET, name));\n      }\n      if (!file.exists()) {\n        throw new IllegalStateException(String.format(MUST_EXIST, name, file.getAbsolutePath()));\n      }\n      if (!file.isFile()) {\n        throw new IllegalStateException(String.format(MUST_BE_FILE, name, file.getAbsolutePath()));\n      }\n      return file;\n    }\n\n    public File isDirectory() {\n      if (file == null) {\n        throw new IllegalStateException(String.format(ARG_MUST_BE_SET, name));\n      }\n      if (!file.exists()) {\n        throw new IllegalStateException(String.format(MUST_EXIST, name, file.getAbsolutePath()));\n      }\n      if (!file.isDirectory()) {\n        throw new IllegalStateException(String.format(MUST_BE_DIR, name, file.getAbsolutePath()));\n      }\n      return file;\n    }\n  }\n\n  public static PathStateChecker state(String name, Path path) {\n    return new PathStateChecker(name, path);\n  }\n\n  public static class PathStateChecker {\n\n    private final String name;\n    private final Path path;\n\n    PathStateChecker(String name, Path path) {\n      this.name = name;\n      this.path = path;\n    }\n\n    public Path isFile() {\n      if (path == null) {\n        throw new IllegalStateException(String.format(ARG_MUST_BE_SET, name));\n      }\n      if (!Files.exists(path)) {\n        throw new IllegalStateException(String.format(MUST_EXIST, name, path));\n      }\n      if (!Files.isRegularFile(path)) {\n        throw new IllegalStateException(String.format(MUST_BE_FILE, name, path));\n      }\n      return path;\n    }\n\n    public Path isDirectory() {\n      if (path == null) {\n        throw new IllegalStateException(String.format(ARG_MUST_BE_SET, name));\n      }\n      if (!Files.exists(path)) {\n        throw new IllegalStateException(String.format(MUST_EXIST, name, path));\n      }\n      if (!Files.isDirectory(path)) {\n        throw new IllegalStateException(String.format(MUST_BE_DIR, name, path));\n      }\n      return path;\n    }\n  }\n}\n", "idx": 1, "id": 18469, "msg": "Prefer adding a second `positive(String, double)` that delegates down to this three-param version. Using `null` in code is generally Not A Great Idea, and it looks ugly.", "proj": "SeleniumHQ-selenium", "lang": "rb"}
{"patch": "@@ -79,6 +79,12 @@ func (i *Inbound) SetRegistry(registry transport.Registry) {\n \ti.registry = registry\n }\n \n+// Transports returns the inbound's HTTP transport.\n+func (i *Inbound) Transports() []transport.Transport {\n+\t// TODO factor out transport and return it here.\n+\treturn []transport.Transport{}\n+}\n+\n // Start starts the inbound with a given service detail, opening a listening\n // socket.\n func (i *Inbound) Start() error {", "y": 1, "oldf": "// Copyright (c) 2016 Uber Technologies, Inc.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n// THE SOFTWARE.\n\npackage http\n\nimport (\n\t\"net\"\n\t\"net/http\"\n\n\t\"go.uber.org/yarpc/internal/errors\"\n\tintnet \"go.uber.org/yarpc/internal/net\"\n\t\"go.uber.org/yarpc/transport\"\n\n\t\"github.com/opentracing/opentracing-go\"\n)\n\n// NewInbound builds a new HTTP inbound that listens on the given address.\nfunc NewInbound(addr string) *Inbound {\n\treturn &Inbound{\n\t\taddr:   addr,\n\t\ttracer: opentracing.GlobalTracer(),\n\t}\n}\n\n// Inbound represents an HTTP Inbound. It is the same as the transport Inbound\n// except it exposes the address on which the system is listening for\n// connections.\ntype Inbound struct {\n\taddr       string\n\tmux        *http.ServeMux\n\tmuxPattern string\n\tserver     *intnet.HTTPServer\n\tregistry   transport.Registry\n\ttracer     opentracing.Tracer\n}\n\n// WithMux specifies the ServeMux that the HTTP server should use and the\n// pattern under which the YARPC endpoint should be registered.\nfunc (i *Inbound) WithMux(pattern string, mux *http.ServeMux) *Inbound {\n\ti.mux = mux\n\ti.muxPattern = pattern\n\treturn i\n}\n\n// WithTracer configures a tracer on this inbound.\nfunc (i *Inbound) WithTracer(tracer opentracing.Tracer) *Inbound {\n\ti.tracer = tracer\n\treturn i\n}\n\n// WithRegistry configures a registry to handle incoming requests,\n// as a chained method for convenience.\nfunc (i *Inbound) WithRegistry(registry transport.Registry) *Inbound {\n\ti.registry = registry\n\treturn i\n}\n\n// SetRegistry configures a registry to handle incoming requests.\n// This satisfies the transport.Inbound interface, and would be called\n// by a dispatcher when it starts.\nfunc (i *Inbound) SetRegistry(registry transport.Registry) {\n\ti.registry = registry\n}\n\n// Start starts the inbound with a given service detail, opening a listening\n// socket.\nfunc (i *Inbound) Start() error {\n\n\tif i.registry == nil {\n\t\treturn errors.NoRegistryError{}\n\t}\n\n\tvar httpHandler http.Handler = handler{\n\t\tregistry: i.registry,\n\t\ttracer:   i.tracer,\n\t}\n\tif i.mux != nil {\n\t\ti.mux.Handle(i.muxPattern, httpHandler)\n\t\thttpHandler = i.mux\n\t}\n\n\ti.server = intnet.NewHTTPServer(&http.Server{\n\t\tAddr:    i.addr,\n\t\tHandler: httpHandler,\n\t})\n\tif err := i.server.ListenAndServe(); err != nil {\n\t\treturn err\n\t}\n\n\ti.addr = i.server.Listener().Addr().String() // in case it changed\n\treturn nil\n}\n\n// Stop the inbound, closing the listening socket.\nfunc (i *Inbound) Stop() error {\n\tif i.server == nil {\n\t\treturn nil\n\t}\n\treturn i.server.Stop()\n}\n\n// Addr returns the address on which the server is listening. Returns nil if\n// Start has not been called yet.\nfunc (i *Inbound) Addr() net.Addr {\n\tif i.server == nil {\n\t\treturn nil\n\t}\n\n\tlistener := i.server.Listener()\n\tif listener == nil {\n\t\treturn nil\n\t}\n\n\treturn listener.Addr()\n}\n", "idx": 1, "id": 11567, "msg": "Should we put a TODO here to route the http.Transport through here?", "proj": "yarpc-yarpc-go", "lang": "go"}
{"patch": "@@ -65,7 +65,9 @@ namespace Microsoft.AspNetCore.Connections\n \n         public CancellationToken ConnectionClosed { get; set; }\n \n-        public virtual void Abort()\n+        public void Abort() => Abort(abortReason: null);\n+\n+        public virtual void Abort(ConnectionAbortedException abortReason)\n         {\n             ThreadPool.QueueUserWorkItem(cts => ((CancellationTokenSource)cts).Cancel(), _connectionClosedTokenSource);\n         }", "y": 1, "oldf": "// Copyright (c) .NET Foundation. All rights reserved.\n// Licensed under the Apache License, Version 2.0. See License.txt in the project root for license information.\n\nusing System;\nusing System.Collections.Generic;\nusing System.IO.Pipelines;\nusing System.Security.Claims;\nusing System.Threading;\nusing Microsoft.AspNetCore.Connections.Features;\nusing Microsoft.AspNetCore.Http.Features;\n\nnamespace Microsoft.AspNetCore.Connections\n{\n    public class DefaultConnectionContext : ConnectionContext,\n                                            IDisposable,\n                                            IConnectionIdFeature,\n                                            IConnectionItemsFeature,\n                                            IConnectionTransportFeature,\n                                            IConnectionUserFeature,\n                                            IConnectionLifetimeFeature\n    {\n        private CancellationTokenSource _connectionClosedTokenSource = new CancellationTokenSource();\n\n        public DefaultConnectionContext() :\n            this(Guid.NewGuid().ToString())\n        {\n            ConnectionClosed = _connectionClosedTokenSource.Token;\n        }\n\n        /// <summary>\n        /// Creates the DefaultConnectionContext without Pipes to avoid upfront allocations.\n        /// The caller is expected to set the <see cref=\"Transport\"/> and <see cref=\"Application\"/> pipes manually.\n        /// </summary>\n        /// <param name=\"id\"></param>\n        public DefaultConnectionContext(string id)\n        {\n            ConnectionId = id;\n\n            Features = new FeatureCollection();\n            Features.Set<IConnectionUserFeature>(this);\n            Features.Set<IConnectionItemsFeature>(this);\n            Features.Set<IConnectionIdFeature>(this);\n            Features.Set<IConnectionTransportFeature>(this);\n            Features.Set<IConnectionLifetimeFeature>(this);\n        }\n\n        public DefaultConnectionContext(string id, IDuplexPipe transport, IDuplexPipe application)\n            : this(id)\n        {\n            Transport = transport;\n            Application = application;\n        }\n\n        public override string ConnectionId { get; set; }\n\n        public override IFeatureCollection Features { get; }\n\n        public ClaimsPrincipal User { get; set; }\n\n        public override IDictionary<object, object> Items { get; set; } = new ConnectionItems();\n\n        public IDuplexPipe Application { get; set; }\n\n        public override IDuplexPipe Transport { get; set; }\n\n        public CancellationToken ConnectionClosed { get; set; }\n\n        public virtual void Abort()\n        {\n            ThreadPool.QueueUserWorkItem(cts => ((CancellationTokenSource)cts).Cancel(), _connectionClosedTokenSource);\n        }\n\n        public void Dispose()\n        {\n            _connectionClosedTokenSource.Dispose();\n        }\n    }\n}\n", "idx": 1, "id": 15815, "msg": "Ugh, if we're going to make a breaking change, I'd like this to be moved to ConnectionContext.", "proj": "aspnet-KestrelHttpServer", "lang": ".cs"}
{"patch": "@@ -162,14 +162,14 @@ class Cart\n     /**\n      * @return \\Shopsys\\FrameworkBundle\\Model\\Order\\Item\\QuantifiedProduct[]\n      */\n-    public function getQuantifiedProductsIndexedByItemId()\n+    public function getQuantifiedProducts()\n     {\n-        $quantifiedProductsByItemId = [];\n+        $quantifiedProducts = [];\n         foreach ($this->items as $item) {\n-            $quantifiedProductsByItemId[$item->getId()] = new QuantifiedProduct($item->getProduct(), $item->getQuantity());\n+            $quantifiedProducts[] = new QuantifiedProduct($item->getProduct(), $item->getQuantity());\n         }\n \n-        return $quantifiedProductsByItemId;\n+        return $quantifiedProducts;\n     }\n \n     /**", "y": 1, "oldf": "<?php\n\nnamespace Shopsys\\FrameworkBundle\\Model\\Cart;\n\nuse DateTime;\nuse Doctrine\\Common\\Collections\\ArrayCollection;\nuse Doctrine\\ORM\\Mapping as ORM;\nuse Shopsys\\FrameworkBundle\\Model\\Cart\\Item\\CartItem;\nuse Shopsys\\FrameworkBundle\\Model\\Cart\\Item\\CartItemFactoryInterface;\nuse Shopsys\\FrameworkBundle\\Model\\Customer\\User;\nuse Shopsys\\FrameworkBundle\\Model\\Order\\Item\\QuantifiedProduct;\nuse Shopsys\\FrameworkBundle\\Model\\Product\\Pricing\\ProductPriceCalculationForUser;\nuse Shopsys\\FrameworkBundle\\Model\\Product\\Product;\n\n/**\n * @ORM\\Table(name=\"carts\")\n * @ORM\\Entity\n */\nclass Cart\n{\n    /**\n     * @var int\n     *\n     * @ORM\\Column(type=\"integer\")\n     * @ORM\\Id\n     * @ORM\\GeneratedValue(strategy=\"IDENTITY\")\n     */\n    protected $id;\n\n    /**\n     * @var string\n     *\n     * @ORM\\Column(type=\"string\", length=127)\n     */\n    protected $cartIdentifier;\n\n    /**\n     * @var \\Shopsys\\FrameworkBundle\\Model\\Customer\\User|null\n     *\n     * @ORM\\ManyToOne(targetEntity=\"Shopsys\\FrameworkBundle\\Model\\Customer\\User\")\n     * @ORM\\JoinColumn(name=\"user_id\", referencedColumnName=\"id\", nullable = true, onDelete=\"CASCADE\")\n     */\n    protected $user;\n\n    /**\n     * @var \\Shopsys\\FrameworkBundle\\Model\\Cart\\Item\\CartItem[]\n     *\n     * @ORM\\OneToMany(\n     *     targetEntity=\"Shopsys\\FrameworkBundle\\Model\\Cart\\Item\\CartItem\",\n     *     mappedBy=\"cart\",\n     *     cascade={\"remove\"},\n     *     orphanRemoval=true\n     * )\n     * @ORM\\OrderBy({\"id\" = \"DESC\"})\n     */\n    protected $items;\n\n    /**\n     * @var \\DateTime\n     *\n     * @ORM\\Column(type=\"datetime\")\n     */\n    protected $modifiedAt;\n\n    /**\n     * @param string $cartIdentifier\n     * @param \\Shopsys\\FrameworkBundle\\Model\\Customer\\User|null $user\n     */\n    public function __construct(string $cartIdentifier, User $user = null)\n    {\n        $this->cartIdentifier = $cartIdentifier;\n        $this->user = $user;\n        $this->items = new ArrayCollection();\n        $this->modifiedAt = new DateTime();\n    }\n\n    /**\n     * @param \\Shopsys\\FrameworkBundle\\Model\\Cart\\Item\\CartItem $item\n     */\n    public function addItem(CartItem $item)\n    {\n        if (!$this->items->contains($item)) {\n            $this->items->add($item);\n            $this->setModifiedNow();\n        }\n    }\n\n    /**\n     * @param int $itemId\n     */\n    public function removeItemById($itemId)\n    {\n        foreach ($this->items as $key => $item) {\n            if ($item->getId() === $itemId) {\n                $this->items->removeElement($item);\n                $this->setModifiedNow();\n                return;\n            }\n        }\n        $message = 'Cart item with ID = ' . $itemId . ' is not in cart for remove.';\n        throw new \\Shopsys\\FrameworkBundle\\Model\\Cart\\Exception\\InvalidCartItemException($message);\n    }\n\n    public function clean()\n    {\n        $this->items->clear();\n    }\n\n    /**\n     * @return \\Shopsys\\FrameworkBundle\\Model\\Cart\\Item\\CartItem[]\n     */\n    public function getItems()\n    {\n        return $this->items->toArray();\n    }\n\n    /**\n     * @return int\n     */\n    public function getItemsCount()\n    {\n        return $this->items->count();\n    }\n\n    /**\n     * @return bool\n     */\n    public function isEmpty()\n    {\n        return $this->getItemsCount() === 0;\n    }\n\n    /**\n     * @param array $quantitiesByItemId\n     */\n    public function changeQuantities(array $quantitiesByItemId)\n    {\n        foreach ($this->items as $item) {\n            if (array_key_exists($item->getId(), $quantitiesByItemId)) {\n                $item->changeQuantity($quantitiesByItemId[$item->getId()]);\n            }\n        }\n\n        $this->setModifiedNow();\n    }\n\n    /**\n     * @param int $itemId\n     * @return \\Shopsys\\FrameworkBundle\\Model\\Cart\\Item\\CartItem\n     */\n    public function getItemById($itemId)\n    {\n        foreach ($this->items as $item) {\n            if ($item->getId() === $itemId) {\n                return $item;\n            }\n        }\n        $message = 'CartItem with id = ' . $itemId . ' not found in cart.';\n        throw new \\Shopsys\\FrameworkBundle\\Model\\Cart\\Exception\\InvalidCartItemException($message);\n    }\n\n    /**\n     * @return \\Shopsys\\FrameworkBundle\\Model\\Order\\Item\\QuantifiedProduct[]\n     */\n    public function getQuantifiedProductsIndexedByItemId()\n    {\n        $quantifiedProductsByItemId = [];\n        foreach ($this->items as $item) {\n            $quantifiedProductsByItemId[$item->getId()] = new QuantifiedProduct($item->getProduct(), $item->getQuantity());\n        }\n\n        return $quantifiedProductsByItemId;\n    }\n\n    /**\n     * @param \\Shopsys\\FrameworkBundle\\Model\\Cart\\Cart $cartToMerge\n     * @param \\Shopsys\\FrameworkBundle\\Model\\Cart\\Item\\CartItemFactoryInterface $cartItemFactory\n     */\n    public function mergeWithCart(self $cartToMerge, CartItemFactoryInterface $cartItemFactory)\n    {\n        foreach ($cartToMerge->getItems() as $itemToMerge) {\n            $similarItem = $this->findSimilarItemByItem($itemToMerge);\n            if ($similarItem instanceof CartItem) {\n                $similarItem->changeQuantity($similarItem->getQuantity() + $itemToMerge->getQuantity());\n            } else {\n                $newCartItem = $cartItemFactory->create(\n                    $this,\n                    $itemToMerge->getProduct(),\n                    $itemToMerge->getQuantity(),\n                    $itemToMerge->getWatchedPrice()\n                );\n                $this->addItem($newCartItem);\n            }\n        }\n\n        $this->setModifiedNow();\n    }\n\n    /**\n     * @param \\Shopsys\\FrameworkBundle\\Model\\Cart\\Item\\CartItem $item\n     * @return \\Shopsys\\FrameworkBundle\\Model\\Cart\\Item\\CartItem|null\n     */\n    protected function findSimilarItemByItem(CartItem $item)\n    {\n        foreach ($this->items as $similarItem) {\n            if ($similarItem->isSimilarItemAs($item)) {\n                return $similarItem;\n            }\n        }\n\n        return null;\n    }\n\n    /**\n     * @param \\Shopsys\\FrameworkBundle\\Model\\Product\\Product $product\n     * @param int $quantity\n     * @param \\Shopsys\\FrameworkBundle\\Model\\Product\\Pricing\\ProductPriceCalculationForUser $productPriceCalculation\n     * @param \\Shopsys\\FrameworkBundle\\Model\\Cart\\Item\\CartItemFactoryInterface $cartItemFactory\n     * @return \\Shopsys\\FrameworkBundle\\Model\\Cart\\AddProductResult\n     */\n    public function addProduct(\n        Product $product,\n        $quantity,\n        ProductPriceCalculationForUser $productPriceCalculation,\n        CartItemFactoryInterface $cartItemFactory\n    ) {\n        if (!is_int($quantity) || $quantity <= 0) {\n            throw new \\Shopsys\\FrameworkBundle\\Model\\Cart\\Exception\\InvalidQuantityException($quantity);\n        }\n\n        foreach ($this->items as $item) {\n            if ($item->getProduct() === $product) {\n                $item->changeQuantity($item->getQuantity() + $quantity);\n                $item->changeAddedAt(new DateTime());\n                return new AddProductResult($item, false, $quantity);\n            }\n        }\n\n        $productPrice = $productPriceCalculation->calculatePriceForCurrentUser($product);\n        $newCartItem = $cartItemFactory->create($this, $product, $quantity, $productPrice->getPriceWithVat()->toValue());\n        $this->addItem($newCartItem);\n        $this->setModifiedNow();\n\n        return new AddProductResult($newCartItem, true, $quantity);\n    }\n\n    /**\n     * @return string\n     */\n    public function getCartIdentifier()\n    {\n        return $this->cartIdentifier;\n    }\n\n    protected function setModifiedNow()\n    {\n        $this->modifiedAt = new DateTime();\n    }\n\n    /**\n     * @param \\DateTime $modifiedAt\n     */\n    public function setModifiedAt(DateTime $modifiedAt)\n    {\n        $this->modifiedAt = $modifiedAt;\n    }\n}\n", "idx": 1, "id": 14983, "msg": "I'm unfortunately unable to review whether you've changed everything that used to use cartIds", "proj": "shopsys-shopsys", "lang": "php"}
{"patch": "@@ -0,0 +1,10 @@\n+exports.featureFlags = {\n+\twidgets: {\n+\t\tdashboard: {\n+\t\t\tenabled: 'development',\n+\t\t},\n+\t\tpageDashboard: {\n+\t\t\tenabled: 'development',\n+\t\t},\n+\t},\n+};", "y": 1, "oldf": "", "idx": 1, "id": 30313, "msg": "This file should get a file header  ", "proj": "google-site-kit-wp", "lang": "js"}
{"patch": "@@ -39,13 +39,11 @@ namespace OpenTelemetry.Metrics\n             configure?.Invoke(options);\n \n             var exporter = new PrometheusExporter(options);\n-\n-            var metricReader = new BaseExportingMetricReader(exporter);\n-            exporter.CollectMetric = metricReader.Collect;\n+            var reader = new BaseExportingMetricReader(exporter);\n \n             var metricsHttpServer = new PrometheusExporterMetricsHttpServer(exporter);\n             metricsHttpServer.Start();\n-            return builder.AddMetricReader(metricReader);\n+            return builder.AddMetricReader(reader);\n         }\n     }\n }", "y": 1, "oldf": "// <copyright file=\"MeterProviderBuilderExtensions.cs\" company=\"OpenTelemetry Authors\">\n// Copyright The OpenTelemetry Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n// </copyright>\n\nusing System;\nusing OpenTelemetry.Exporter;\n\nnamespace OpenTelemetry.Metrics\n{\n    public static class MeterProviderBuilderExtensions\n    {\n        /// <summary>\n        /// Adds Console exporter to the TracerProvider.\n        /// </summary>\n        /// <param name=\"builder\"><see cref=\"MeterProviderBuilder\"/> builder to use.</param>\n        /// <param name=\"configure\">Exporter configuration options.</param>\n        /// <returns>The instance of <see cref=\"MeterProviderBuilder\"/> to chain the calls.</returns>\n        [System.Diagnostics.CodeAnalysis.SuppressMessage(\"Reliability\", \"CA2000:Dispose objects before losing scope\", Justification = \"The objects should not be disposed.\")]\n        public static MeterProviderBuilder AddPrometheusExporter(this MeterProviderBuilder builder, Action<PrometheusExporterOptions> configure = null)\n        {\n            if (builder == null)\n            {\n                throw new ArgumentNullException(nameof(builder));\n            }\n\n            var options = new PrometheusExporterOptions();\n            configure?.Invoke(options);\n\n            var exporter = new PrometheusExporter(options);\n\n            var metricReader = new BaseExportingMetricReader(exporter);\n            exporter.CollectMetric = metricReader.Collect;\n\n            var metricsHttpServer = new PrometheusExporterMetricsHttpServer(exporter);\n            metricsHttpServer.Start();\n            return builder.AddMetricReader(metricReader);\n        }\n    }\n}\n", "idx": 1, "id": 21550, "msg": "@alanwest I noticed this while changing the code. I think we _might_ run into some race condition - if a scraper happens to hit the HTTP server before we could add the reader, what would happen (I guess we will hit exception, which turns into HTTP 500)? I haven't looked into the HTTP server logic. I think it _might_ be OKAY. A better version could be - we only start the HTTP server once the exporter/reader are fully ready and both are hooked up to the provider.", "proj": "open-telemetry-opentelemetry-dotnet", "lang": ".cs"}
{"patch": "@@ -49,6 +49,16 @@ namespace Datadog.Trace\n \n         private TimeSpan Elapsed => StopwatchHelpers.GetElapsed(Stopwatch.GetTimestamp() - _timestamp);\n \n+        /// <summary>\n+        /// Gets or sets a collection of propagated internal Datadog tags,\n+        /// formatted as \"key1=value1,key2=value2\".\n+        /// </summary>\n+        /// <remarks>\n+        /// We're keeping this as the string representation to avoid having to parse.\n+        /// For now, it's relatively easy to append new values when needed.\n+        /// </remarks>\n+        public string DatadogTags { get; set; }\n+\n         public void AddSpan(Span span)\n         {\n             lock (this)", "y": 1, "oldf": "// <copyright file=\"TraceContext.cs\" company=\"Datadog\">\n// Unless explicitly stated otherwise all files in this repository are licensed under the Apache 2 License.\n// This product includes software developed at Datadog (https://www.datadoghq.com/). Copyright 2017 Datadog, Inc.\n// </copyright>\n\nusing System;\nusing System.Diagnostics;\nusing Datadog.Trace.ClrProfiler;\nusing Datadog.Trace.Logging;\nusing Datadog.Trace.PlatformHelpers;\nusing Datadog.Trace.Tagging;\nusing Datadog.Trace.Util;\n\nnamespace Datadog.Trace\n{\n    internal class TraceContext\n    {\n        private static readonly IDatadogLogger Log = DatadogLogging.GetLoggerFor<TraceContext>();\n\n        private readonly DateTimeOffset _utcStart = DateTimeOffset.UtcNow;\n        private readonly long _timestamp = Stopwatch.GetTimestamp();\n        private ArrayBuilder<Span> _spans;\n\n        private int _openSpans;\n        private SamplingPriority? _samplingPriority;\n\n        public TraceContext(IDatadogTracer tracer)\n        {\n            Tracer = tracer;\n        }\n\n        public Span RootSpan { get; private set; }\n\n        public DateTimeOffset UtcNow => _utcStart.Add(Elapsed);\n\n        public IDatadogTracer Tracer { get; }\n\n        /// <summary>\n        /// Gets or sets sampling priority.\n        /// </summary>\n        public SamplingPriority? SamplingPriority\n        {\n            get => _samplingPriority;\n            set\n            {\n                SetSamplingPriority(value);\n            }\n        }\n\n        private TimeSpan Elapsed => StopwatchHelpers.GetElapsed(Stopwatch.GetTimestamp() - _timestamp);\n\n        public void AddSpan(Span span)\n        {\n            lock (this)\n            {\n                if (RootSpan == null)\n                {\n                    // first span added is the root span\n                    RootSpan = span;\n                    DecorateRootSpan(span);\n\n                    if (_samplingPriority == null)\n                    {\n                        if (span.Context.Parent is SpanContext context && context.SamplingPriority != null)\n                        {\n                            // this is a root span created from a propagated context that contains a sampling priority.\n                            // lock sampling priority when a span is started from a propagated trace.\n                            _samplingPriority = context.SamplingPriority;\n                        }\n                        else\n                        {\n                            // this is a local root span (i.e. not propagated).\n                            // determine an initial sampling priority for this trace, but don't lock it yet\n                            _samplingPriority =\n                                Tracer.Sampler?.GetSamplingPriority(RootSpan);\n                        }\n                    }\n                }\n\n                _openSpans++;\n            }\n        }\n\n        public void CloseSpan(Span span)\n        {\n            bool ShouldTriggerPartialFlush() => Tracer.Settings.Exporter.PartialFlushEnabled && _spans.Count >= Tracer.Settings.Exporter.PartialFlushMinSpans;\n\n            if (span == RootSpan)\n            {\n                if (_samplingPriority == null)\n                {\n                    Log.Warning(\"Cannot set span metric for sampling priority before it has been set.\");\n                }\n                else\n                {\n                    SetSamplingPriority(span, _samplingPriority.Value);\n                }\n            }\n\n            ArraySegment<Span> spansToWrite = default;\n\n            bool shouldPropagateMetadata = false;\n\n            lock (this)\n            {\n                _spans.Add(span);\n                _openSpans--;\n\n                if (_openSpans == 0)\n                {\n                    spansToWrite = _spans.GetArray();\n                    _spans = default;\n                }\n                else if (ShouldTriggerPartialFlush())\n                {\n                    Log.Debug<ulong, ulong, int>(\n                        \"Closing span {spanId} triggered a partial flush of trace {traceId} with {spanCount} pending spans\",\n                        span.SpanId,\n                        span.TraceId,\n                        _spans.Count);\n\n                    // We may not be sending the root span, so we need to propagate the metadata to other spans of the partial trace\n                    // There's no point in doing that inside of the lock, so we set a flag for later\n                    shouldPropagateMetadata = true;\n\n                    spansToWrite = _spans.GetArray();\n\n                    // Making the assumption that, if the number of closed spans was big enough to trigger partial flush,\n                    // the number of remaining spans is probably big as well.\n                    // Therefore, we bypass the resize logic and immediately allocate the array to its maximum size\n                    _spans = new ArrayBuilder<Span>(spansToWrite.Count);\n                }\n            }\n\n            if (shouldPropagateMetadata)\n            {\n                PropagateMetadata(spansToWrite);\n            }\n\n            if (spansToWrite.Count > 0)\n            {\n                Tracer.Write(spansToWrite);\n            }\n        }\n\n        public void SetSamplingPriority(SamplingPriority? samplingPriority, bool notifyDistributedTracer = true)\n        {\n            _samplingPriority = samplingPriority;\n\n            if (notifyDistributedTracer)\n            {\n                DistributedTracer.Instance.SetSamplingPriority(samplingPriority);\n            }\n        }\n\n        public TimeSpan ElapsedSince(DateTimeOffset date)\n        {\n            return Elapsed + (_utcStart - date);\n        }\n\n        private static void SetSamplingPriority(Span span, SamplingPriority samplingPriority)\n        {\n            if (span.Tags is CommonTags tags)\n            {\n                tags.SamplingPriority = (int)samplingPriority;\n            }\n            else\n            {\n                span.Tags.SetMetric(Metrics.SamplingPriority, (int)samplingPriority);\n            }\n        }\n\n        private void PropagateMetadata(ArraySegment<Span> spans)\n        {\n            // The agent looks for the sampling priority on the first span that has no parent\n            // Finding those spans is not trivial, so instead we apply the priority to every span\n\n            var samplingPriority = _samplingPriority;\n\n            if (samplingPriority == null)\n            {\n                return;\n            }\n\n            // Using a for loop to avoid the boxing allocation on ArraySegment.GetEnumerator\n            for (int i = 0; i < spans.Count; i++)\n            {\n                SetSamplingPriority(spans.Array[i + spans.Offset], samplingPriority.Value);\n            }\n        }\n\n        private void DecorateRootSpan(Span span)\n        {\n            if (AzureAppServices.Metadata.IsRelevant)\n            {\n                span.SetTag(Tags.AzureAppServicesSiteName, AzureAppServices.Metadata.SiteName);\n                span.SetTag(Tags.AzureAppServicesSiteKind, AzureAppServices.Metadata.SiteKind);\n                span.SetTag(Tags.AzureAppServicesSiteType, AzureAppServices.Metadata.SiteType);\n                span.SetTag(Tags.AzureAppServicesResourceGroup, AzureAppServices.Metadata.ResourceGroup);\n                span.SetTag(Tags.AzureAppServicesSubscriptionId, AzureAppServices.Metadata.SubscriptionId);\n                span.SetTag(Tags.AzureAppServicesResourceId, AzureAppServices.Metadata.ResourceId);\n                span.SetTag(Tags.AzureAppServicesInstanceId, AzureAppServices.Metadata.InstanceId);\n                span.SetTag(Tags.AzureAppServicesInstanceName, AzureAppServices.Metadata.InstanceName);\n                span.SetTag(Tags.AzureAppServicesOperatingSystem, AzureAppServices.Metadata.OperatingSystem);\n                span.SetTag(Tags.AzureAppServicesRuntime, AzureAppServices.Metadata.Runtime);\n                span.SetTag(Tags.AzureAppServicesExtensionVersion, AzureAppServices.Metadata.SiteExtensionVersion);\n            }\n        }\n    }\n}\n", "idx": 1, "id": 25136, "msg": "Why not adding this to the interface and keep passing the interface (as the interface is internal I don't get why you're not adding it there)", "proj": "DataDog-dd-trace-dotnet", "lang": ".cs"}
{"patch": "@@ -53,7 +53,8 @@ enum Timestamps implements Transform<Long, Integer> {\n     OffsetDateTime timestamp = Instant\n         .ofEpochSecond(timestampMicros / 1_000_000)\n         .atOffset(ZoneOffset.UTC);\n-    return (int) granularity.between(EPOCH, timestamp);\n+    Integer year = Long.valueOf(granularity.between(EPOCH, timestamp)).intValue();\n+    return year;\n   }\n \n   @Override", "y": 1, "oldf": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\n\npackage org.apache.iceberg.transforms;\n\nimport java.time.Instant;\nimport java.time.OffsetDateTime;\nimport java.time.ZoneOffset;\nimport java.time.temporal.ChronoUnit;\nimport org.apache.iceberg.expressions.BoundPredicate;\nimport org.apache.iceberg.expressions.Expressions;\nimport org.apache.iceberg.expressions.UnboundPredicate;\nimport org.apache.iceberg.types.Type;\nimport org.apache.iceberg.types.Types;\n\nimport static org.apache.iceberg.expressions.Expression.Operation.IS_NULL;\nimport static org.apache.iceberg.expressions.Expression.Operation.NOT_NULL;\n\nenum Timestamps implements Transform<Long, Integer> {\n  YEAR(ChronoUnit.YEARS, \"year\"),\n  MONTH(ChronoUnit.MONTHS, \"month\"),\n  DAY(ChronoUnit.DAYS, \"day\"),\n  HOUR(ChronoUnit.HOURS, \"hour\");\n\n  private static final OffsetDateTime EPOCH = Instant.ofEpochSecond(0).atOffset(ZoneOffset.UTC);\n  private final ChronoUnit granularity;\n  private final String name;\n\n  Timestamps(ChronoUnit granularity, String name) {\n    this.granularity = granularity;\n    this.name = name;\n  }\n\n  @Override\n  public Integer apply(Long timestampMicros) {\n    // discards fractional seconds, not needed for calculation\n    OffsetDateTime timestamp = Instant\n        .ofEpochSecond(timestampMicros / 1_000_000)\n        .atOffset(ZoneOffset.UTC);\n    return (int) granularity.between(EPOCH, timestamp);\n  }\n\n  @Override\n  public boolean canTransform(Type type) {\n    return type.typeId() == Type.TypeID.TIMESTAMP;\n  }\n\n  @Override\n  public Type getResultType(Type sourceType) {\n    return Types.IntegerType.get();\n  }\n\n  @Override\n  public UnboundPredicate<Integer> project(String fieldName, BoundPredicate<Long> pred) {\n    if (pred.op() == NOT_NULL || pred.op() == IS_NULL) {\n      return Expressions.predicate(pred.op(), fieldName);\n    }\n    return ProjectionUtil.truncateLong(fieldName, pred, this);\n  }\n\n  @Override\n  public UnboundPredicate<Integer> projectStrict(String fieldName, BoundPredicate<Long> predicate) {\n    return null;\n  }\n\n  @Override\n  public String toHumanString(Integer value) {\n    if (value == null) {\n      return \"null\";\n    }\n\n    switch (granularity) {\n      case YEARS:\n        return TransformUtil.humanYear(value);\n      case MONTHS:\n        return TransformUtil.humanMonth(value);\n      case DAYS:\n        return TransformUtil.humanDay(value);\n      case HOURS:\n        return TransformUtil.humanHour(value);\n      default:\n        throw new UnsupportedOperationException(\"Unsupported time unit: \" + granularity);\n    }\n  }\n\n  @Override\n  public String toString() {\n    return name;\n  }\n}\n", "idx": 1, "id": 13192, "msg": "This isn't necessarily a year. It may be months, days, or hours. Can we return `intValue()` directly instead?", "proj": "apache-iceberg", "lang": "java"}
{"patch": "@@ -24,12 +24,12 @@ namespace OpenTelemetry.Metrics\n     public abstract class Meter\n     {\n         /// <summary>\n-        /// Creates a counter for long with given name.\n+        /// Creates a counter for Int64 with given name.\n         /// </summary>\n         /// <param name=\"name\">The name of the counter.</param>\n         /// <param name=\"monotonic\">indicates if only positive values are expected.</param>\n         /// <returns>The counter instance.</returns>\n-        public abstract Counter<long> CreateLongCounter(string name, bool monotonic = true);\n+        public Counter<long> CreateInt64Counter(string name, bool monotonic = true) => this.CreateCounter<long>(name, monotonic);\n \n         /// <summary>\n         /// Creates a counter for double with given name.", "y": 1, "oldf": "\ufeff// <copyright file=\"Meter.cs\" company=\"OpenTelemetry Authors\">\n// Copyright 2018, OpenTelemetry Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n// </copyright>\n\nusing System.Collections.Generic;\n\nnamespace OpenTelemetry.Metrics\n{\n    /// <summary>\n    /// Main interface to obtain metric instruments.\n    /// </summary>\n    public abstract class Meter\n    {\n        /// <summary>\n        /// Creates a counter for long with given name.\n        /// </summary>\n        /// <param name=\"name\">The name of the counter.</param>\n        /// <param name=\"monotonic\">indicates if only positive values are expected.</param>\n        /// <returns>The counter instance.</returns>\n        public abstract Counter<long> CreateLongCounter(string name, bool monotonic = true);\n\n        /// <summary>\n        /// Creates a counter for double with given name.\n        /// </summary>\n        /// <param name=\"name\">indicates if only positive values are expected.</param>\n        /// <param name=\"monotonic\">The name of the counter.</param>\n        /// <returns>The counter instance.</returns>\n        public abstract Counter<double> CreateDoubleCounter(string name, bool monotonic = true);\n\n        /// <summary>\n        /// Creates a Gauge for long with given name.\n        /// </summary>\n        /// <param name=\"name\">The name of the counter.</param>\n        /// <param name=\"monotonic\">indicates if only positive values are expected.</param>\n        /// <returns>The Gauge instance.</returns>\n        public abstract Gauge<long> CreateLongGauge(string name, bool monotonic = false);\n\n        /// <summary>\n        /// Creates a Gauge for long with given name.\n        /// </summary>\n        /// <param name=\"name\">The name of the counter.</param>\n        /// <param name=\"monotonic\">indicates if only positive values are expected.</param>\n        /// <returns>The Gauge instance.</returns>\n        public abstract Gauge<double> CreateDoubleGauge(string name, bool monotonic = false);\n\n        /// <summary>\n        /// Creates a measure for long with given name.\n        /// </summary>\n        /// <param name=\"name\">The name of the measure.</param>\n        /// <param name=\"absolute\">indicates if only positive values are expected.</param>\n        /// <returns>The measure instance.</returns>\n        public abstract Measure<long> CreateLongMeasure(string name, bool absolute = true);\n\n        /// <summary>\n        /// Creates a measure for long with given name.\n        /// </summary>\n        /// <param name=\"name\">The name of the measure.</param>\n        /// <param name=\"absolute\">indicates if only positive values are expected.</param>\n        /// <returns>The measure instance.</returns>\n        public abstract Measure<double> CreateDoubleMeasure(string name, bool absolute = true);\n\n        /// <summary>\n        /// Constructs or retrieves the <see cref=\"LabelSet\"/> from the given label key-value pairs.\n        /// </summary>\n        /// <param name=\"labels\">Label key value pairs.</param>\n        /// <returns>The <see cref=\"LabelSet\"/> with given label key value pairs.</returns>\n        public abstract LabelSet GetLabelSet(IEnumerable<KeyValuePair<string, string>> labels);\n    }\n}\n", "idx": 1, "id": 12613, "msg": "I think these method names would be clearer if written as \"Create a {type} counter|gauge|measure with given name\". eg \"Create a int64 counter with given name\" \"Create a double gauge with given name\"", "proj": "open-telemetry-opentelemetry-dotnet", "lang": ".cs"}
{"patch": "@@ -105,7 +105,7 @@ public class JavaRuleViolation extends ParametricRuleViolation<JavaNode> {\n     private void setClassNameFrom(JavaNode node) {\n         String qualifiedName = null;\n \n-        if (node.getScope() instanceof ClassScope) {\n+        if (node instanceof AbstractAnyTypeDeclaration && node.getScope() instanceof ClassScope) {\n             qualifiedName = ((ClassScope) node.getScope()).getClassName();\n         }\n ", "y": 1, "oldf": "/**\n * BSD-style license; for more info see http://pmd.sourceforge.net/license.html\n */\n\npackage net.sourceforge.pmd.lang.java.rule;\n\nimport java.util.Iterator;\nimport java.util.Set;\n\nimport net.sourceforge.pmd.Rule;\nimport net.sourceforge.pmd.RuleContext;\nimport net.sourceforge.pmd.RuleViolation;\nimport net.sourceforge.pmd.lang.ast.Node;\nimport net.sourceforge.pmd.lang.java.ast.ASTCompilationUnit;\nimport net.sourceforge.pmd.lang.java.ast.ASTFieldDeclaration;\nimport net.sourceforge.pmd.lang.java.ast.ASTFormalParameter;\nimport net.sourceforge.pmd.lang.java.ast.ASTLocalVariableDeclaration;\nimport net.sourceforge.pmd.lang.java.ast.ASTVariableDeclarator;\nimport net.sourceforge.pmd.lang.java.ast.ASTVariableDeclaratorId;\nimport net.sourceforge.pmd.lang.java.ast.AbstractAnyTypeDeclaration;\nimport net.sourceforge.pmd.lang.java.ast.AccessNode;\nimport net.sourceforge.pmd.lang.java.ast.CanSuppressWarnings;\nimport net.sourceforge.pmd.lang.java.ast.JavaNode;\nimport net.sourceforge.pmd.lang.java.symboltable.ClassNameDeclaration;\nimport net.sourceforge.pmd.lang.java.symboltable.ClassScope;\nimport net.sourceforge.pmd.lang.java.symboltable.MethodScope;\nimport net.sourceforge.pmd.lang.java.symboltable.SourceFileScope;\nimport net.sourceforge.pmd.lang.rule.ParametricRuleViolation;\nimport net.sourceforge.pmd.lang.symboltable.Scope;\n\n/**\n * This is a Java RuleViolation. It knows how to try to extract the following\n * extra information from the violation node:\n * <ul>\n * <li>Package name</li>\n * <li>Class name</li>\n * <li>Method name</li>\n * <li>Variable name</li>\n * <li>Suppression indicator</li>\n * </ul>\n * @deprecated See {@link RuleViolation}\n */\n@Deprecated\npublic class JavaRuleViolation extends ParametricRuleViolation<JavaNode> {\n\n    public JavaRuleViolation(Rule rule, RuleContext ctx, JavaNode node, String message, int beginLine, int endLine) {\n        this(rule, ctx, node, message);\n\n        setLines(beginLine, endLine);\n    }\n\n    public JavaRuleViolation(Rule rule, RuleContext ctx, JavaNode node, String message) {\n        super(rule, ctx, node, message);\n\n        if (node != null) {\n            final Scope scope = node.getScope();\n            final SourceFileScope sourceFileScope = scope.getEnclosingScope(SourceFileScope.class);\n\n            // Package name is on SourceFileScope\n            packageName = sourceFileScope.getPackageName() == null ? \"\" : sourceFileScope.getPackageName();\n\n            // Class name is built from enclosing ClassScopes\n            setClassNameFrom(node);\n\n            // Method name comes from 1st enclosing MethodScope\n            if (scope.getEnclosingScope(MethodScope.class) != null) {\n                methodName = scope.getEnclosingScope(MethodScope.class).getName();\n            }\n            // Variable name node specific\n            setVariableNameIfExists(node);\n\n            if (!suppressed) {\n                suppressed = isSupressed(node, getRule());\n            }\n        }\n    }\n\n    /**\n     * Check for suppression on this node, on parents, and on contained types\n     * for ASTCompilationUnit\n     *\n     * @param node\n     *\n     * @deprecated Is internal API, not useful, there's a typo. See <a href=\"https://github.com/pmd/pmd/pull/1927\">#1927</a>\n     */\n    @Deprecated\n    public static boolean isSupressed(Node node, Rule rule) {\n        boolean result = suppresses(node, rule);\n\n        if (!result && node instanceof ASTCompilationUnit) {\n            for (int i = 0; !result && i < node.jjtGetNumChildren(); i++) {\n                result = suppresses(node.jjtGetChild(i), rule);\n            }\n        }\n        if (!result) {\n            Node parent = node.jjtGetParent();\n            while (!result && parent != null) {\n                result = suppresses(parent, rule);\n                parent = parent.jjtGetParent();\n            }\n        }\n        return result;\n    }\n\n    private void setClassNameFrom(JavaNode node) {\n        String qualifiedName = null;\n\n        if (node.getScope() instanceof ClassScope) {\n            qualifiedName = ((ClassScope) node.getScope()).getClassName();\n        }\n\n        for (AbstractAnyTypeDeclaration parent : node.getParentsOfType(AbstractAnyTypeDeclaration.class)) {\n            String clsName = parent.getScope().getEnclosingScope(ClassScope.class).getClassName();\n            if (qualifiedName == null) {\n                qualifiedName = clsName;\n            } else {\n                qualifiedName = clsName + '$' + qualifiedName;\n            }\n        }\n\n        if (qualifiedName == null) {\n            Set<ClassNameDeclaration> classes = node.getScope().getEnclosingScope(SourceFileScope.class)\n                    .getClassDeclarations().keySet();\n            for (ClassNameDeclaration c : classes) {\n                // find the first public class/enum declaration\n                if (c.getAccessNodeParent() instanceof AccessNode) {\n                    if (((AccessNode) c.getAccessNodeParent()).isPublic()) {\n                        qualifiedName = c.getImage();\n                        break;\n                    }\n                }\n            }\n\n            // Still not found?\n            if (qualifiedName == null) {\n                for (ClassNameDeclaration c : classes) {\n                    // find the first package-private class/enum declaration\n                    if (c.getAccessNodeParent() instanceof AccessNode) {\n                        if (((AccessNode) c.getAccessNodeParent()).isPackagePrivate()) {\n                            qualifiedName = c.getImage();\n                            break;\n                        }\n                    }\n                }\n            }\n        }\n\n        if (qualifiedName != null) {\n            className = qualifiedName;\n        }\n    }\n\n    private static boolean suppresses(final Node node, Rule rule) {\n        return node instanceof CanSuppressWarnings\n                && ((CanSuppressWarnings) node).hasSuppressWarningsAnnotationFor(rule);\n    }\n\n    private String getVariableNames(Iterable<ASTVariableDeclaratorId> iterable) {\n\n        Iterator<ASTVariableDeclaratorId> it = iterable.iterator();\n        StringBuilder builder = new StringBuilder();\n        builder.append(it.next());\n\n        while (it.hasNext()) {\n            builder.append(\", \").append(it.next());\n        }\n        return builder.toString();\n    }\n\n    private void setVariableNameIfExists(Node node) {\n        if (node instanceof ASTFieldDeclaration) {\n            variableName = getVariableNames((ASTFieldDeclaration) node);\n        } else if (node instanceof ASTLocalVariableDeclaration) {\n            variableName = getVariableNames((ASTLocalVariableDeclaration) node);\n        } else if (node instanceof ASTVariableDeclarator) {\n            variableName = node.jjtGetChild(0).getImage();\n        } else if (node instanceof ASTVariableDeclaratorId) {\n            variableName = node.getImage();\n        } else if (node instanceof ASTFormalParameter) {\n            setVariableNameIfExists(node.getFirstChildOfType(ASTVariableDeclaratorId.class));\n        } else {\n            variableName = \"\";\n        }\n    }\n}\n", "idx": 1, "id": 16894, "msg": "Why not use ASTAnyTypeDeclaration? AbstractAnyTypeDeclaration is deprecated", "proj": "pmd-pmd", "lang": "java"}
{"patch": "@@ -48,8 +48,7 @@ import org.apache.iceberg.types.Types;\n  * represented by a named {@link PartitionField}.\n  */\n public class PartitionSpec implements Serializable {\n-  // start assigning IDs for partition fields at 1000\n-  private static final int PARTITION_DATA_ID_START = 1000;\n+  public static final int PARTITION_DATA_ID_START = 1000;\n \n   private final Schema schema;\n ", "y": 1, "oldf": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\n\npackage org.apache.iceberg;\n\nimport com.google.common.base.Preconditions;\nimport com.google.common.collect.ImmutableList;\nimport com.google.common.collect.ImmutableMap;\nimport com.google.common.collect.ListMultimap;\nimport com.google.common.collect.Lists;\nimport com.google.common.collect.Maps;\nimport com.google.common.collect.Multimaps;\nimport com.google.common.collect.Sets;\nimport java.io.Serializable;\nimport java.io.UnsupportedEncodingException;\nimport java.net.URLEncoder;\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Objects;\nimport java.util.Set;\nimport org.apache.iceberg.exceptions.ValidationException;\nimport org.apache.iceberg.transforms.Transforms;\nimport org.apache.iceberg.transforms.UnknownTransform;\nimport org.apache.iceberg.types.Type;\nimport org.apache.iceberg.types.Types;\n\n/**\n * Represents how to produce partition data for a table.\n * <p>\n * Partition data is produced by transforming columns in a table. Each column transform is\n * represented by a named {@link PartitionField}.\n */\npublic class PartitionSpec implements Serializable {\n  // start assigning IDs for partition fields at 1000\n  private static final int PARTITION_DATA_ID_START = 1000;\n\n  private final Schema schema;\n\n  // this is ordered so that DataFile has a consistent schema\n  private final int specId;\n  private final PartitionField[] fields;\n  private transient volatile ListMultimap<Integer, PartitionField> fieldsBySourceId = null;\n  private transient volatile Map<String, PartitionField> fieldsByName = null;\n  private transient volatile Class<?>[] lazyJavaClasses = null;\n  private transient volatile List<PartitionField> fieldList = null;\n\n  private PartitionSpec(Schema schema, int specId, List<PartitionField> fields) {\n    this.schema = schema;\n    this.specId = specId;\n    this.fields = new PartitionField[fields.size()];\n    for (int i = 0; i < this.fields.length; i += 1) {\n      this.fields[i] = fields.get(i);\n    }\n  }\n\n  /**\n   * @return the {@link Schema} for this spec.\n   */\n  public Schema schema() {\n    return schema;\n  }\n\n  /**\n   * @return the ID of this spec\n   */\n  public int specId() {\n    return specId;\n  }\n\n  /**\n   * @return the list of {@link PartitionField partition fields} for this spec.\n   */\n  public List<PartitionField> fields() {\n    return lazyFieldList();\n  }\n\n  /**\n   * @param fieldId a field id from the source schema\n   * @return the {@link PartitionField field} that partitions the given source field\n   */\n  public List<PartitionField> getFieldsBySourceId(int fieldId) {\n    return lazyFieldsBySourceId().get(fieldId);\n  }\n\n  /**\n   * @return a {@link Types.StructType} for partition data defined by this spec.\n   */\n  public Types.StructType partitionType() {\n    List<Types.NestedField> structFields = Lists.newArrayListWithExpectedSize(fields.length);\n\n    for (int i = 0; i < fields.length; i += 1) {\n      PartitionField field = fields[i];\n      Type sourceType = schema.findType(field.sourceId());\n      Type resultType = field.transform().getResultType(sourceType);\n      // assign ids for partition fields starting at PARTITION_DATA_ID_START to leave room for data file's other fields\n      structFields.add(\n          Types.NestedField.optional(PARTITION_DATA_ID_START + i, field.name(), resultType));\n    }\n\n    return Types.StructType.of(structFields);\n  }\n\n  public Class<?>[] javaClasses() {\n    if (lazyJavaClasses == null) {\n      synchronized (this) {\n        if (lazyJavaClasses == null) {\n          Class<?>[] classes = new Class<?>[fields.length];\n          for (int i = 0; i < fields.length; i += 1) {\n            PartitionField field = fields[i];\n            if (field.transform() instanceof UnknownTransform) {\n              classes[i] = Object.class;\n            } else {\n              Type sourceType = schema.findType(field.sourceId());\n              Type result = field.transform().getResultType(sourceType);\n              classes[i] = result.typeId().javaClass();\n            }\n          }\n\n          this.lazyJavaClasses = classes;\n        }\n      }\n    }\n\n    return lazyJavaClasses;\n  }\n\n  @SuppressWarnings(\"unchecked\")\n  private <T> T get(StructLike data, int pos, Class<?> javaClass) {\n    return data.get(pos, (Class<T>) javaClass);\n  }\n\n  private String escape(String string) {\n    try {\n      return URLEncoder.encode(string, \"UTF-8\");\n    } catch (UnsupportedEncodingException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n  public String partitionToPath(StructLike data) {\n    StringBuilder sb = new StringBuilder();\n    Class<?>[] javaClasses = javaClasses();\n    for (int i = 0; i < javaClasses.length; i += 1) {\n      PartitionField field = fields[i];\n      String valueString = field.transform().toHumanString(get(data, i, javaClasses[i]));\n\n      if (i > 0) {\n        sb.append(\"/\");\n      }\n      sb.append(field.name()).append(\"=\").append(escape(valueString));\n    }\n    return sb.toString();\n  }\n\n  /**\n   * Returns true if this spec is equivalent to the other, with field names ignored. That is, if\n   * both specs have the same number of fields, field order, source columns, and transforms.\n   *\n   * @param other another PartitionSpec\n   * @return true if the specs have the same fields, source columns, and transforms.\n   */\n  public boolean compatibleWith(PartitionSpec other) {\n    if (equals(other)) {\n      return true;\n    }\n\n    if (fields.length != other.fields.length) {\n      return false;\n    }\n\n    for (int i = 0; i < fields.length; i += 1) {\n      PartitionField thisField = fields[i];\n      PartitionField thatField = other.fields[i];\n      if (thisField.sourceId() != thatField.sourceId() ||\n          !thisField.transform().toString().equals(thatField.transform().toString())) {\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n  @Override\n  public boolean equals(Object other) {\n    if (this == other) {\n      return true;\n    }\n    if (other == null || getClass() != other.getClass()) {\n      return false;\n    }\n\n    PartitionSpec that = (PartitionSpec) other;\n    if (this.specId != that.specId) {\n      return false;\n    }\n    return Arrays.equals(fields, that.fields);\n  }\n\n  @Override\n  public int hashCode() {\n    return Objects.hashCode(Arrays.hashCode(fields));\n  }\n\n  private List<PartitionField> lazyFieldList() {\n    if (fieldList == null) {\n      synchronized (this) {\n        if (fieldList == null) {\n          this.fieldList = ImmutableList.copyOf(fields);\n        }\n      }\n    }\n    return fieldList;\n  }\n\n  private Map<String, PartitionField> lazyFieldsByName() {\n    if (fieldsByName == null) {\n      synchronized (this) {\n        if (fieldsByName == null) {\n          ImmutableMap.Builder<String, PartitionField> builder = ImmutableMap.builder();\n          for (PartitionField field : fields) {\n            builder.put(field.name(), field);\n          }\n          this.fieldsByName = builder.build();\n        }\n      }\n    }\n\n    return fieldsByName;\n  }\n\n  private ListMultimap<Integer, PartitionField> lazyFieldsBySourceId() {\n    if (fieldsBySourceId == null) {\n      synchronized (this) {\n        if (fieldsBySourceId == null) {\n          ListMultimap<Integer, PartitionField> multiMap = Multimaps\n              .newListMultimap(Maps.newHashMap(), () -> Lists.newArrayListWithCapacity(fields.length));\n          for (PartitionField field : fields) {\n            multiMap.put(field.sourceId(), field);\n          }\n          this.fieldsBySourceId = multiMap;\n        }\n      }\n    }\n\n    return fieldsBySourceId;\n  }\n\n  /**\n   * Returns the source field ids for identity partitions.\n   *\n   * @return a set of source ids for the identity partitions.\n   */\n  public Set<Integer> identitySourceIds() {\n    Set<Integer> sourceIds = Sets.newHashSet();\n    for (PartitionField field : fields()) {\n      if (\"identity\".equals(field.transform().toString())) {\n        sourceIds.add(field.sourceId());\n      }\n    }\n\n    return sourceIds;\n  }\n\n  @Override\n  public String toString() {\n    StringBuilder sb = new StringBuilder();\n    sb.append(\"[\");\n    for (PartitionField field : fields) {\n      sb.append(\"\\n\");\n      sb.append(\"  \").append(field);\n    }\n    if (fields.length > 0) {\n      sb.append(\"\\n\");\n    }\n    sb.append(\"]\");\n    return sb.toString();\n  }\n\n  private static final PartitionSpec UNPARTITIONED_SPEC =\n      new PartitionSpec(new Schema(), 0, ImmutableList.of());\n\n  /**\n   * Returns a spec for unpartitioned tables.\n   *\n   * @return a partition spec with no partitions\n   */\n  public static PartitionSpec unpartitioned() {\n    return UNPARTITIONED_SPEC;\n  }\n\n  /**\n   * Creates a new {@link Builder partition spec builder} for the given {@link Schema}.\n   *\n   * @param schema a schema\n   * @return a partition spec builder for the given schema\n   */\n  public static Builder builderFor(Schema schema) {\n    return new Builder(schema);\n  }\n\n  /**\n   * Used to create valid {@link PartitionSpec partition specs}.\n   * <p>\n   * Call {@link #builderFor(Schema)} to create a new builder.\n   */\n  public static class Builder {\n    private final Schema schema;\n    private final List<PartitionField> fields = Lists.newArrayList();\n    private final Set<String> partitionNames = Sets.newHashSet();\n    private Map<Integer, PartitionField> timeFields = Maps.newHashMap();\n    private int specId = 0;\n\n    private Builder(Schema schema) {\n      this.schema = schema;\n    }\n\n    private void checkAndAddPartitionName(String name) {\n      checkAndAddPartitionName(name, null);\n    }\n\n    private void checkAndAddPartitionName(String name, Integer identitySourceColumnId) {\n      Types.NestedField schemaField = schema.findField(name);\n      if (identitySourceColumnId != null) {\n        // for identity transform case we allow  conflicts between partition and schema field name as\n        //   long as they are sourced from the same schema field\n        Preconditions.checkArgument(schemaField == null || schemaField.fieldId() == identitySourceColumnId,\n            \"Cannot create identity partition sourced from different field in schema: %s\", name);\n      } else {\n        // for all other transforms we don't allow conflicts between partition name and schema field name\n        Preconditions.checkArgument(schemaField == null,\n            \"Cannot create partition from name that exists in schema: %s\", name);\n      }\n      Preconditions.checkArgument(name != null && !name.isEmpty(),\n          \"Cannot use empty or null partition name: %s\", name);\n      Preconditions.checkArgument(!partitionNames.contains(name),\n          \"Cannot use partition name more than once: %s\", name);\n      partitionNames.add(name);\n    }\n\n    private void checkForRedundantPartitions(PartitionField field) {\n      PartitionField timeField = timeFields.get(field.sourceId());\n      Preconditions.checkArgument(timeField == null,\n          \"Cannot add redundant partition: %s conflicts with %s\", timeField, field);\n      timeFields.put(field.sourceId(), field);\n    }\n\n    public Builder withSpecId(int newSpecId) {\n      this.specId = newSpecId;\n      return this;\n    }\n\n    private Types.NestedField findSourceColumn(String sourceName) {\n      Types.NestedField sourceColumn = schema.findField(sourceName);\n      Preconditions.checkArgument(sourceColumn != null, \"Cannot find source column: %s\", sourceName);\n      return sourceColumn;\n    }\n\n    Builder identity(String sourceName, String targetName) {\n      Types.NestedField sourceColumn = findSourceColumn(sourceName);\n      checkAndAddPartitionName(targetName, sourceColumn.fieldId());\n      fields.add(new PartitionField(\n          sourceColumn.fieldId(), targetName, Transforms.identity(sourceColumn.type())));\n      return this;\n    }\n\n    public Builder identity(String sourceName) {\n      return identity(sourceName, sourceName);\n    }\n\n    public Builder year(String sourceName, String targetName) {\n      checkAndAddPartitionName(targetName);\n      Types.NestedField sourceColumn = findSourceColumn(sourceName);\n      PartitionField field = new PartitionField(\n          sourceColumn.fieldId(), targetName, Transforms.year(sourceColumn.type()));\n      checkForRedundantPartitions(field);\n      fields.add(field);\n      return this;\n    }\n\n    public Builder year(String sourceName) {\n      return year(sourceName, sourceName + \"_year\");\n    }\n\n    public Builder month(String sourceName, String targetName) {\n      checkAndAddPartitionName(targetName);\n      Types.NestedField sourceColumn = findSourceColumn(sourceName);\n      PartitionField field = new PartitionField(\n          sourceColumn.fieldId(), targetName, Transforms.month(sourceColumn.type()));\n      checkForRedundantPartitions(field);\n      fields.add(field);\n      return this;\n    }\n\n    public Builder month(String sourceName) {\n      return month(sourceName, sourceName + \"_month\");\n    }\n\n    public Builder day(String sourceName, String targetName) {\n      checkAndAddPartitionName(targetName);\n      Types.NestedField sourceColumn = findSourceColumn(sourceName);\n      PartitionField field = new PartitionField(\n          sourceColumn.fieldId(), targetName, Transforms.day(sourceColumn.type()));\n      checkForRedundantPartitions(field);\n      fields.add(field);\n      return this;\n    }\n\n    public Builder day(String sourceName) {\n      return day(sourceName, sourceName + \"_day\");\n    }\n\n    public Builder hour(String sourceName, String targetName) {\n      checkAndAddPartitionName(targetName);\n      Types.NestedField sourceColumn = findSourceColumn(sourceName);\n      PartitionField field = new PartitionField(\n          sourceColumn.fieldId(), targetName, Transforms.hour(sourceColumn.type()));\n      checkForRedundantPartitions(field);\n      fields.add(field);\n      return this;\n    }\n\n    public Builder hour(String sourceName) {\n      return hour(sourceName, sourceName + \"_hour\");\n    }\n\n    public Builder bucket(String sourceName, int numBuckets, String targetName) {\n      checkAndAddPartitionName(targetName);\n      Types.NestedField sourceColumn = findSourceColumn(sourceName);\n      fields.add(new PartitionField(\n          sourceColumn.fieldId(), targetName, Transforms.bucket(sourceColumn.type(), numBuckets)));\n      return this;\n    }\n\n    public Builder bucket(String sourceName, int numBuckets) {\n      return bucket(sourceName, numBuckets, sourceName + \"_bucket\");\n    }\n\n    public Builder truncate(String sourceName, int width, String targetName) {\n      checkAndAddPartitionName(targetName);\n      Types.NestedField sourceColumn = findSourceColumn(sourceName);\n      fields.add(new PartitionField(\n          sourceColumn.fieldId(), targetName, Transforms.truncate(sourceColumn.type(), width)));\n      return this;\n    }\n\n    public Builder truncate(String sourceName, int width) {\n      return truncate(sourceName, width, sourceName + \"_trunc\");\n    }\n\n    Builder add(int sourceId, String name, String transform) {\n      Types.NestedField column = schema.findField(sourceId);\n      checkAndAddPartitionName(name, column.fieldId());\n      Preconditions.checkNotNull(column, \"Cannot find source column: %d\", sourceId);\n      fields.add(new PartitionField(sourceId, name, Transforms.fromString(column.type(), transform)));\n      return this;\n    }\n\n    public PartitionSpec build() {\n      PartitionSpec spec = new PartitionSpec(schema, specId, fields);\n      checkCompatibility(spec, schema);\n      return spec;\n    }\n  }\n\n  static void checkCompatibility(PartitionSpec spec, Schema schema) {\n    for (PartitionField field : spec.fields) {\n      Type sourceType = schema.findType(field.sourceId());\n      ValidationException.check(sourceType != null,\n          \"Cannot find source column for partition field: %s\", field);\n      ValidationException.check(sourceType.isPrimitiveType(),\n          \"Cannot partition by non-primitive source field: %s\", sourceType);\n      ValidationException.check(\n          field.transform().canTransform(sourceType),\n          \"Invalid source type %s for transform: %s\",\n          sourceType, field.transform());\n    }\n  }\n}\n", "idx": 1, "id": 15738, "msg": "Does this need to be public or can it be package-private?", "proj": "apache-iceberg", "lang": "java"}
{"patch": "@@ -46,11 +46,6 @@ class ModelRole(enum.IntEnum):\n \n     item = Qt.UserRole\n \n-\n-# Remember the last used directory\n-last_used_directory = None\n-\n-\n # All REFRESH_INTERVAL milliseconds, speeds will be recalculated and downloads\n # redrawn.\n _REFRESH_INTERVAL = 500", "y": 1, "oldf": "# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:\n\n# Copyright 2014-2019 Florian Bruhin (The Compiler) <mail@qutebrowser.org>\n#\n# This file is part of qutebrowser.\n#\n# qutebrowser is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# qutebrowser is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with qutebrowser.  If not, see <http://www.gnu.org/licenses/>.\n\n\"\"\"Shared QtWebKit/QtWebEngine code for downloads.\"\"\"\n\nimport re\nimport sys\nimport html\nimport os.path\nimport collections\nimport functools\nimport pathlib\nimport tempfile\nimport enum\n\nfrom PyQt5.QtCore import (pyqtSlot, pyqtSignal, Qt, QObject, QModelIndex,\n                          QTimer, QAbstractListModel, QUrl)\n\nfrom qutebrowser.browser import pdfjs\nfrom qutebrowser.api import cmdutils\nfrom qutebrowser.config import config\nfrom qutebrowser.utils import (usertypes, standarddir, utils, message, log,\n                               qtutils, objreg)\nfrom qutebrowser.qt import sip\n\n\nclass ModelRole(enum.IntEnum):\n\n    \"\"\"Custom download model roles.\"\"\"\n\n    item = Qt.UserRole\n\n\n# Remember the last used directory\nlast_used_directory = None\n\n\n# All REFRESH_INTERVAL milliseconds, speeds will be recalculated and downloads\n# redrawn.\n_REFRESH_INTERVAL = 500\n\n\nclass UnsupportedAttribute:\n\n    \"\"\"Class which is used to create attributes which are not supported.\n\n    This is used for attributes like \"fileobj\" for downloads which are not\n    supported with QtWebengine.\n    \"\"\"\n\n\nclass UnsupportedOperationError(Exception):\n\n    \"\"\"Raised when an operation is not supported with the given backend.\"\"\"\n\n\ndef download_dir():\n    \"\"\"Get the download directory to use.\"\"\"\n    directory = config.val.downloads.location.directory\n    remember_dir = config.val.downloads.location.remember\n\n    if remember_dir and last_used_directory is not None:\n        ddir = last_used_directory\n    elif directory is None:\n        ddir = standarddir.download()\n    else:\n        ddir = directory\n\n    try:\n        os.makedirs(ddir, exist_ok=True)\n    except OSError as e:\n        message.error(\"Failed to create download directory: {}\".format(e))\n\n    return ddir\n\n\ndef immediate_download_path(prompt_download_directory=None):\n    \"\"\"Try to get an immediate download path without asking the user.\n\n    If that's possible, we return a path immediately. If not, None is returned.\n\n    Args:\n        prompt_download_directory: If this is something else than None, it\n                                   will overwrite the\n                                   downloads.location.prompt setting.\n    \"\"\"\n    if prompt_download_directory is None:\n        prompt_download_directory = config.val.downloads.location.prompt\n\n    if not prompt_download_directory:\n        return download_dir()\n\n    return None\n\n\ndef _path_suggestion(filename):\n    \"\"\"Get the suggested file path.\n\n    Args:\n        filename: The filename to use if included in the suggestion.\n    \"\"\"\n    suggestion = config.val.downloads.location.suggestion\n    if suggestion == 'path':\n        # add trailing '/' if not present\n        return os.path.join(download_dir(), '')\n    elif suggestion == 'filename':\n        return filename\n    elif suggestion == 'both':\n        return os.path.join(download_dir(), filename)\n    else:  # pragma: no cover\n        raise ValueError(\"Invalid suggestion value {}!\".format(suggestion))\n\n\ndef create_full_filename(basename, filename):\n    \"\"\"Create a full filename based on the given basename and filename.\n\n    Args:\n        basename: The basename to use if filename is a directory.\n        filename: The path to a folder or file where you want to save.\n\n    Return:\n        The full absolute path, or None if filename creation was not possible.\n    \"\"\"\n    basename = utils.sanitize_filename(basename)\n    # Filename can be a full path so don't use sanitize_filename on it.\n    # Remove chars which can't be encoded in the filename encoding.\n    # See https://github.com/qutebrowser/qutebrowser/issues/427\n    encoding = sys.getfilesystemencoding()\n    filename = utils.force_encoding(filename, encoding)\n    if os.path.isabs(filename) and (os.path.isdir(filename) or\n                                    filename.endswith(os.sep)):\n        # We got an absolute directory from the user, so we save it under\n        # the default filename in that directory.\n        return os.path.join(filename, basename)\n    elif os.path.isabs(filename):\n        # We got an absolute filename from the user, so we save it under\n        # that filename.\n        return filename\n    return None\n\n\ndef get_filename_question(*, suggested_filename, url, parent=None):\n    \"\"\"Get a Question object for a download-path.\n\n    Args:\n        suggested_filename: The \"default\"-name that is pre-entered as path.\n        url: The URL the download originated from.\n        parent: The parent of the question (a QObject).\n    \"\"\"\n    suggested_filename = utils.sanitize_filename(suggested_filename)\n\n    q = usertypes.Question(parent)\n    q.title = \"Save file to:\"\n    q.text = \"Please enter a location for <b>{}</b>\".format(\n        html.escape(url.toDisplayString()))\n    q.url = url.toString(QUrl.RemovePassword | QUrl.FullyEncoded)\n    q.mode = usertypes.PromptMode.download\n    q.completed.connect(q.deleteLater)\n    q.default = _path_suggestion(suggested_filename)\n    return q\n\n\ndef transform_path(path):\n    r\"\"\"Do platform-specific transformations, like changing E: to E:\\.\n\n    Returns None if the path is invalid on the current platform.\n    \"\"\"\n    if not utils.is_windows:\n        return path\n    path = utils.expand_windows_drive(path)\n    # Drive dependent working directories are not supported, e.g.\n    # E:filename is invalid\n    if re.search(r'^[A-Z]:[^\\\\]', path, re.IGNORECASE):\n        return None\n    # Paths like COM1, ...\n    # See https://github.com/qutebrowser/qutebrowser/issues/82\n    if pathlib.Path(path).is_reserved():\n        return None\n    return path\n\n\ndef suggested_fn_from_title(url_path, title=None):\n    \"\"\"Suggest a filename depending on the URL extension and page title.\n\n    Args:\n        url_path: a string with the URL path\n        title: the page title string\n\n    Return:\n        The download filename based on the title, or None if the extension is\n        not found in the whitelist (or if there is no page title).\n    \"\"\"\n    ext_whitelist = [\".html\", \".htm\", \".php\", \"\"]\n    _, ext = os.path.splitext(url_path)\n    if ext.lower() in ext_whitelist and title:\n        suggested_fn = utils.sanitize_filename(title)\n        if not suggested_fn.lower().endswith((\".html\", \".htm\")):\n            suggested_fn += \".html\"\n    else:\n        suggested_fn = None\n    return suggested_fn\n\n\nclass NoFilenameError(Exception):\n\n    \"\"\"Raised when we can't find out a filename in DownloadTarget.\"\"\"\n\n\n# Where a download should be saved\nclass _DownloadTarget:\n\n    \"\"\"Abstract base class for different download targets.\"\"\"\n\n    def suggested_filename(self):\n        \"\"\"Get the suggested filename for this download target.\"\"\"\n        raise NotImplementedError\n\n\nclass FileDownloadTarget(_DownloadTarget):\n\n    \"\"\"Save the download to the given file.\n\n    Attributes:\n        filename: Filename where the download should be saved.\n        force_overwrite: Whether to overwrite the target without\n                         prompting the user.\n    \"\"\"\n\n    def __init__(self, filename, force_overwrite=False):\n        self.filename = filename\n        self.force_overwrite = force_overwrite\n\n    def suggested_filename(self):\n        return os.path.basename(self.filename)\n\n    def __str__(self):\n        return self.filename\n\n\nclass FileObjDownloadTarget(_DownloadTarget):\n\n    \"\"\"Save the download to the given file-like object.\n\n    Attributes:\n        fileobj: File-like object where the download should be written to.\n    \"\"\"\n\n    def __init__(self, fileobj):\n        self.fileobj = fileobj\n\n    def suggested_filename(self):\n        try:\n            return self.fileobj.name\n        except AttributeError:\n            raise NoFilenameError\n\n    def __str__(self):\n        try:\n            return 'file object at {}'.format(self.fileobj.name)\n        except AttributeError:\n            return 'anonymous file object'\n\n\nclass OpenFileDownloadTarget(_DownloadTarget):\n\n    \"\"\"Save the download in a temp dir and directly open it.\n\n    Attributes:\n        cmdline: The command to use as string. A `{}` is expanded to the\n                 filename. None means to use the system's default application.\n                 If no `{}` is found, the filename is appended to the cmdline.\n    \"\"\"\n\n    def __init__(self, cmdline=None):\n        self.cmdline = cmdline\n\n    def suggested_filename(self):\n        raise NoFilenameError\n\n    def __str__(self):\n        return 'temporary file'\n\n\nclass PDFJSDownloadTarget(_DownloadTarget):\n\n    \"\"\"Open the download via PDF.js.\"\"\"\n\n    def suggested_filename(self):\n        raise NoFilenameError\n\n    def __str__(self):\n        return 'temporary PDF.js file'\n\n\nclass DownloadItemStats(QObject):\n\n    \"\"\"Statistics (bytes done, total bytes, time, etc.) about a download.\n\n    Class attributes:\n        SPEED_AVG_WINDOW: How many seconds of speed data to average to\n                          estimate the remaining time.\n\n    Attributes:\n        done: How many bytes there are already downloaded.\n        total: The total count of bytes.  None if the total is unknown.\n        speed: The current download speed, in bytes per second.\n        _speed_avg: A rolling average of speeds.\n        _last_done: The count of bytes which where downloaded when calculating\n                    the speed the last time.\n    \"\"\"\n\n    SPEED_AVG_WINDOW = 30\n\n    def __init__(self, parent=None):\n        super().__init__(parent)\n        self.total = None\n        self.done = 0\n        self.speed = 0\n        self._last_done = 0\n        samples = int(self.SPEED_AVG_WINDOW * (1000 / _REFRESH_INTERVAL))\n        self._speed_avg = collections.deque(maxlen=samples)\n\n    def update_speed(self):\n        \"\"\"Recalculate the current download speed.\n\n        The caller needs to guarantee this is called all _REFRESH_INTERVAL ms.\n        \"\"\"\n        if self.done is None:\n            # this can happen for very fast downloads, e.g. when actually\n            # opening a file\n            return\n        delta = self.done - self._last_done\n        self.speed = delta * 1000 / _REFRESH_INTERVAL\n        self._speed_avg.append(self.speed)\n        self._last_done = self.done\n\n    def finish(self):\n        \"\"\"Set the download stats as finished.\"\"\"\n        self.done = self.total\n\n    def percentage(self):\n        \"\"\"The current download percentage, or None if unknown.\"\"\"\n        if self.done == self.total:\n            return 100\n        elif self.total == 0 or self.total is None:\n            return None\n        else:\n            return 100 * self.done / self.total\n\n    def remaining_time(self):\n        \"\"\"The remaining download time in seconds, or None.\"\"\"\n        if self.total is None or not self._speed_avg:\n            # No average yet or we don't know the total size.\n            return None\n        remaining_bytes = self.total - self.done\n        avg = sum(self._speed_avg) / len(self._speed_avg)\n        if avg == 0:\n            # Download stalled\n            return None\n        else:\n            return remaining_bytes / avg\n\n    @pyqtSlot('qint64', 'qint64')\n    def on_download_progress(self, bytes_done, bytes_total):\n        \"\"\"Update local variables when the download progress changed.\n\n        Args:\n            bytes_done: How many bytes are downloaded.\n            bytes_total: How many bytes there are to download in total.\n        \"\"\"\n        if bytes_total in [0, -1]:  # QtWebEngine, QtWebKit\n            bytes_total = None\n        self.done = bytes_done\n        self.total = bytes_total\n\n\nclass AbstractDownloadItem(QObject):\n\n    \"\"\"Shared QtNetwork/QtWebEngine part of a download item.\n\n    Attributes:\n        done: Whether the download is finished.\n        stats: A DownloadItemStats object.\n        index: The index of the download in the view.\n        successful: Whether the download has completed successfully.\n        error_msg: The current error message, or None\n        fileobj: The file object to download the file to.\n        raw_headers: The headers sent by the server.\n        _filename: The filename of the download.\n        _dead: Whether the Download has _die()'d.\n\n    Signals:\n        data_changed: The downloads metadata changed.\n        finished: The download was finished.\n        cancelled: The download was cancelled.\n        error: An error with the download occurred.\n               arg: The error message as string.\n        remove_requested: Emitted when the removal of this download was\n                          requested.\n        pdfjs_requested: Emitted when PDF.js should be opened with the given\n                         filename.\n    \"\"\"\n\n    data_changed = pyqtSignal()\n    finished = pyqtSignal()\n    error = pyqtSignal(str)\n    cancelled = pyqtSignal()\n    remove_requested = pyqtSignal()\n    pdfjs_requested = pyqtSignal(str)\n\n    def __init__(self, parent=None):\n        super().__init__(parent)\n        self.done = False\n        self.stats = DownloadItemStats(self)\n        self.index = 0\n        self.error_msg = None\n        self.basename = '???'\n        self.successful = False\n\n        self.fileobj = UnsupportedAttribute()\n        self.raw_headers = UnsupportedAttribute()\n\n        self._filename = None\n        self._dead = False\n\n    def __repr__(self):\n        return utils.get_repr(self, basename=self.basename)\n\n    def __str__(self):\n        \"\"\"Get the download as a string.\n\n        Example: foo.pdf [699.2kB/s|0.34|16%|4.253/25.124]\n        \"\"\"\n        speed = utils.format_size(self.stats.speed, suffix='B/s')\n        down = utils.format_size(self.stats.done, suffix='B')\n        perc = self.stats.percentage()\n        remaining = self.stats.remaining_time()\n        if self.error_msg is None:\n            errmsg = \"\"\n        else:\n            errmsg = \" - {}\".format(self.error_msg)\n\n        if all(e is None for e in [perc, remaining, self.stats.total]):\n            return ('{index}: {name} [{speed:>10}|{down}]{errmsg}'.format(\n                index=self.index, name=self.basename, speed=speed,\n                down=down, errmsg=errmsg))\n\n        perc = round(perc)\n        if remaining is None:\n            remaining = '?'\n        else:\n            remaining = utils.format_seconds(remaining)\n        total = utils.format_size(self.stats.total, suffix='B')\n        if self.done:\n            return ('{index}: {name} [{perc:>2}%|{total}]{errmsg}'.format(\n                index=self.index, name=self.basename, perc=perc,\n                total=total, errmsg=errmsg))\n        else:\n            return ('{index}: {name} [{speed:>10}|{remaining:>5}|{perc:>2}%|'\n                    '{down}/{total}]{errmsg}'.format(\n                        index=self.index, name=self.basename, speed=speed,\n                        remaining=remaining, perc=perc, down=down,\n                        total=total, errmsg=errmsg))\n\n    def _do_die(self):\n        \"\"\"Do cleanup steps after a download has died.\"\"\"\n        raise NotImplementedError\n\n    def _die(self, msg):\n        \"\"\"Abort the download and emit an error.\"\"\"\n        assert not self.successful\n        # Prevent actions if calling _die() twice.\n        #\n        # For QtWebKit, this might happen if the error handler correctly\n        # connects, and the error occurs in _init_reply between\n        # reply.error.connect and the reply.error() check. In this case, the\n        # connected error handlers will be called twice, once via the direct\n        # error.emit() and once here in _die(). The stacks look like this then:\n        #\n        #   <networkmanager error.emit> -> on_reply_error -> _die ->\n        #   self.error.emit()\n        #\n        # and\n        #\n        #   [_init_reply -> <single shot timer> ->] <lambda in _init_reply> ->\n        #   self.error.emit()\n        #\n        # which may lead to duplicate error messages (and failing tests)\n        if self._dead:\n            return\n        self._dead = True\n        self._do_die()\n        self.error_msg = msg\n        self.stats.finish()\n        self.error.emit(msg)\n        self.done = True\n        self.data_changed.emit()\n\n    def get_status_color(self, position):\n        \"\"\"Choose an appropriate color for presenting the download's status.\n\n        Args:\n            position: The color type requested, can be 'fg' or 'bg'.\n        \"\"\"\n        assert position in [\"fg\", \"bg\"]\n        # pylint: disable=bad-config-option\n        start = getattr(config.val.colors.downloads.start, position)\n        stop = getattr(config.val.colors.downloads.stop, position)\n        system = getattr(config.val.colors.downloads.system, position)\n        error = getattr(config.val.colors.downloads.error, position)\n        # pylint: enable=bad-config-option\n        if self.error_msg is not None:\n            assert not self.successful\n            return error\n        elif self.stats.percentage() is None:\n            return start\n        else:\n            return utils.interpolate_color(start, stop,\n                                           self.stats.percentage(), system)\n\n    def _do_cancel(self):\n        \"\"\"Actual cancel implementation.\"\"\"\n        raise NotImplementedError\n\n    @pyqtSlot()\n    def cancel(self, *, remove_data=True):\n        \"\"\"Cancel the download.\n\n        Args:\n            remove_data: Whether to remove the downloaded data.\n        \"\"\"\n        self._do_cancel()\n        log.downloads.debug(\"cancelled\")\n        if remove_data:\n            self.delete()\n        self.done = True\n        self.finished.emit()\n        self.data_changed.emit()\n\n    @pyqtSlot()\n    def remove(self):\n        \"\"\"Remove the download from the model.\"\"\"\n        self.remove_requested.emit()\n\n    def delete(self):\n        \"\"\"Delete the downloaded file.\"\"\"\n        try:\n            if self._filename is not None and os.path.exists(self._filename):\n                os.remove(self._filename)\n                log.downloads.debug(\"Deleted {}\".format(self._filename))\n            else:\n                log.downloads.debug(\"Not deleting {}\".format(self._filename))\n        except OSError:\n            log.downloads.exception(\"Failed to remove partial file\")\n\n    @pyqtSlot()\n    def retry(self):\n        \"\"\"Retry a failed download.\"\"\"\n        raise NotImplementedError\n\n    @pyqtSlot()\n    def try_retry(self):\n        \"\"\"Try to retry a download and show an error if it's unsupported.\"\"\"\n        try:\n            self.retry()\n        except UnsupportedOperationError as e:\n            message.error(str(e))\n\n    def _get_open_filename(self):\n        \"\"\"Get the filename to open a download.\n\n        Returns None if no suitable filename was found.\n        \"\"\"\n        raise NotImplementedError\n\n    @pyqtSlot()\n    def open_file(self, cmdline=None):\n        \"\"\"Open the downloaded file.\n\n        Args:\n            cmdline: The command to use as string. A `{}` is expanded to the\n                     filename. None means to use the system's default\n                     application or `downloads.open_dispatcher` if set. If no\n                     `{}` is found, the filename is appended to the cmdline.\n        \"\"\"\n        assert self.successful\n        filename = self._get_open_filename()\n        if filename is None:  # pragma: no cover\n            log.downloads.error(\"No filename to open the download!\")\n            return\n        # By using a singleshot timer, we ensure that we return fast. This\n        # is important on systems where process creation takes long, as\n        # otherwise the prompt might hang around and cause bugs\n        # (see issue #2296)\n        QTimer.singleShot(0, lambda: utils.open_file(filename, cmdline))\n\n    def _ensure_can_set_filename(self, filename):\n        \"\"\"Make sure we can still set a filename.\"\"\"\n        raise NotImplementedError\n\n    def _after_set_filename(self):\n        \"\"\"Finish initialization based on self._filename.\"\"\"\n        raise NotImplementedError\n\n    def _ask_confirm_question(self, title, msg):\n        \"\"\"Ask a confirmation question for the download.\"\"\"\n        raise NotImplementedError\n\n    def _ask_create_parent_question(self, title, msg,\n                                    force_overwrite, remember_directory):\n        \"\"\"Ask a confirmation question for the parent directory.\"\"\"\n        raise NotImplementedError\n\n    def _set_fileobj(self, fileobj, *, autoclose=True):\n        \"\"\"Set a file object to save the download to.\n\n        Not supported by QtWebEngine.\n\n        Args:\n            fileobj: The file object to download to.\n            autoclose: Close the file object automatically when it's done.\n        \"\"\"\n        raise NotImplementedError\n\n    def _set_tempfile(self, fileobj):\n        \"\"\"Set a temporary file when opening the download.\"\"\"\n        raise NotImplementedError\n\n    def _set_filename(self, filename, *, force_overwrite=False,\n                      remember_directory=True):\n        \"\"\"Set the filename to save the download to.\n\n        Args:\n            filename: The full filename to save the download to.\n                      None: special value to stop the download.\n            force_overwrite: Force overwriting existing files.\n            remember_directory: If True, remember the directory for future\n                                downloads.\n        \"\"\"\n        filename = os.path.expanduser(filename)\n        self._ensure_can_set_filename(filename)\n\n        self._filename = create_full_filename(self.basename, filename)\n        if self._filename is None:\n            # We only got a filename (without directory) or a relative path\n            # from the user, so we append that to the default directory and\n            # try again.\n            self._filename = create_full_filename(\n                self.basename, os.path.join(download_dir(), filename))\n\n        # At this point, we have a misconfigured XDG_DOWNLOAD_DIR, as\n        # download_dir() + filename is still no absolute path.\n        # The config value is checked for \"absoluteness\", but\n        # ~/.config/user-dirs.dirs may be misconfigured and a non-absolute path\n        # may be set for XDG_DOWNLOAD_DIR\n        if self._filename is None:\n            message.error(\n                \"XDG_DOWNLOAD_DIR points to a relative path - please check\"\n                \" your ~/.config/user-dirs.dirs. The download is saved in\"\n                \" your home directory.\",\n            )\n            # fall back to $HOME as download_dir\n            self._filename = create_full_filename(self.basename,\n                                                  os.path.expanduser('~'))\n\n        dirname = os.path.dirname(self._filename)\n        if not os.path.exists(dirname):\n            txt = (\"<b>{}</b> does not exist. Create it?\".\n                   format(html.escape(\n                       os.path.join(dirname, \"\"))))\n            self._ask_create_parent_question(\"Create directory?\", txt,\n                                             force_overwrite,\n                                             remember_directory)\n        else:\n            self._after_create_parent_question(force_overwrite,\n                                               remember_directory)\n\n    def _after_create_parent_question(self,\n                                      force_overwrite, remember_directory):\n        \"\"\"After asking about parent directory.\n\n        Args:\n            force_overwrite: Force overwriting existing files.\n            remember_directory: If True, remember the directory for future\n                                downloads.\n        \"\"\"\n        global last_used_directory\n\n        try:\n            os.makedirs(os.path.dirname(self._filename), exist_ok=True)\n        except OSError as e:\n            self._die(e.strerror)\n\n        self.basename = os.path.basename(self._filename)\n        if remember_directory:\n            last_used_directory = os.path.dirname(self._filename)\n\n        log.downloads.debug(\"Setting filename to {}\".format(self._filename))\n        if force_overwrite:\n            self._after_set_filename()\n        elif os.path.isfile(self._filename):\n            # The file already exists, so ask the user if it should be\n            # overwritten.\n            txt = \"<b>{}</b> already exists. Overwrite?\".format(\n                html.escape(self._filename))\n            self._ask_confirm_question(\"Overwrite existing file?\", txt)\n        # FIFO, device node, etc. Make sure we want to do this\n        elif (os.path.exists(self._filename) and\n              not os.path.isdir(self._filename)):\n            txt = (\"<b>{}</b> already exists and is a special file. Write to \"\n                   \"it anyways?\".format(html.escape(self._filename)))\n            self._ask_confirm_question(\"Overwrite special file?\", txt)\n        else:\n            self._after_set_filename()\n\n    def _open_if_successful(self, cmdline):\n        \"\"\"Open the downloaded file, but only if it was successful.\n\n        Args:\n            cmdline: Passed to DownloadItem.open_file().\n        \"\"\"\n        if not self.successful:\n            log.downloads.debug(\"{} finished but not successful, not opening!\"\n                                .format(self))\n            return\n        self.open_file(cmdline)\n\n    def _pdfjs_if_successful(self):\n        \"\"\"Open the file via PDF.js if downloading was successful.\"\"\"\n        if not self.successful:\n            log.downloads.debug(\"{} finished but not successful, not opening!\"\n                                .format(self))\n            return\n\n        filename = self._get_open_filename()\n        if filename is None:  # pragma: no cover\n            log.downloads.error(\"No filename to open the download!\")\n            return\n        self.pdfjs_requested.emit(os.path.basename(filename))\n\n    def set_target(self, target):\n        \"\"\"Set the target for a given download.\n\n        Args:\n            target: The DownloadTarget for this download.\n        \"\"\"\n        if isinstance(target, FileObjDownloadTarget):\n            self._set_fileobj(target.fileobj, autoclose=False)\n        elif isinstance(target, FileDownloadTarget):\n            self._set_filename(\n                target.filename, force_overwrite=target.force_overwrite)\n        elif isinstance(target, (OpenFileDownloadTarget, PDFJSDownloadTarget)):\n            try:\n                fobj = temp_download_manager.get_tmpfile(self.basename)\n            except OSError as exc:\n                msg = \"Download error: {}\".format(exc)\n                message.error(msg)\n                self.cancel()\n                return\n\n            if isinstance(target, OpenFileDownloadTarget):\n                self.finished.connect(functools.partial(\n                    self._open_if_successful, target.cmdline))\n            elif isinstance(target, PDFJSDownloadTarget):\n                self.finished.connect(self._pdfjs_if_successful)\n            else:\n                raise utils.Unreachable\n\n            self._set_tempfile(fobj)\n        else:  # pragma: no cover\n            raise ValueError(\"Unsupported download target: {}\".format(target))\n\n\nclass AbstractDownloadManager(QObject):\n\n    \"\"\"Backend-independent download manager code.\n\n    Attributes:\n        downloads: A list of active DownloadItems.\n        _networkmanager: A NetworkManager for generic downloads.\n\n    Signals:\n        begin_remove_row: Emitted before downloads are removed.\n        end_remove_row: Emitted after downloads are removed.\n        begin_insert_row: Emitted before downloads are inserted.\n        end_insert_row: Emitted after downloads are inserted.\n        data_changed: Emitted when the data of the model changed.\n                      The argument is the index of the changed download\n    \"\"\"\n\n    begin_remove_row = pyqtSignal(int)\n    end_remove_row = pyqtSignal()\n    begin_insert_row = pyqtSignal(int)\n    end_insert_row = pyqtSignal()\n    data_changed = pyqtSignal(int)\n\n    def __init__(self, parent=None):\n        super().__init__(parent)\n        self.downloads = []\n        self._update_timer = usertypes.Timer(self, 'download-update')\n        self._update_timer.timeout.connect(self._update_gui)\n        self._update_timer.setInterval(_REFRESH_INTERVAL)\n\n    def __repr__(self):\n        return utils.get_repr(self, downloads=len(self.downloads))\n\n    @pyqtSlot()\n    def _update_gui(self):\n        \"\"\"Periodical GUI update of all items.\"\"\"\n        assert self.downloads\n        for dl in self.downloads:\n            dl.stats.update_speed()\n        self.data_changed.emit(-1)\n\n    @pyqtSlot(str)\n    def _on_pdfjs_requested(self, filename):\n        \"\"\"Open PDF.js when a download requests it.\"\"\"\n        tabbed_browser = objreg.get('tabbed-browser', scope='window',\n                                    window='last-focused')\n        tabbed_browser.tabopen(pdfjs.get_main_url(filename), background=False)\n\n    def _init_item(self, download, auto_remove, suggested_filename):\n        \"\"\"Initialize a newly created DownloadItem.\"\"\"\n        download.cancelled.connect(download.remove)\n        download.remove_requested.connect(functools.partial(\n            self._remove_item, download))\n\n        delay = config.val.downloads.remove_finished\n        if delay > -1:\n            download.finished.connect(\n                lambda: QTimer.singleShot(delay, download.remove))\n        elif auto_remove:\n            download.finished.connect(download.remove)\n\n        download.data_changed.connect(\n            functools.partial(self._on_data_changed, download))\n        download.error.connect(self._on_error)\n        download.pdfjs_requested.connect(self._on_pdfjs_requested)\n\n        download.basename = suggested_filename\n        idx = len(self.downloads)\n        download.index = idx + 1  # \"Human readable\" index\n        self.begin_insert_row.emit(idx)\n        self.downloads.append(download)\n        self.end_insert_row.emit()\n\n        if not self._update_timer.isActive():\n            self._update_timer.start()\n\n    @pyqtSlot(AbstractDownloadItem)\n    def _on_data_changed(self, download):\n        \"\"\"Emit data_changed signal when download data changed.\"\"\"\n        try:\n            idx = self.downloads.index(download)\n        except ValueError:\n            # download has been deleted in the meantime\n            return\n        self.data_changed.emit(idx)\n\n    @pyqtSlot(str)\n    def _on_error(self, msg):\n        \"\"\"Display error message on download errors.\"\"\"\n        message.error(\"Download error: {}\".format(msg))\n\n    @pyqtSlot(AbstractDownloadItem)\n    def _remove_item(self, download):\n        \"\"\"Remove a given download.\"\"\"\n        if sip.isdeleted(self):\n            # https://github.com/qutebrowser/qutebrowser/issues/1242\n            return\n        try:\n            idx = self.downloads.index(download)\n        except ValueError:\n            # already removed\n            return\n        self.begin_remove_row.emit(idx)\n        del self.downloads[idx]\n        self.end_remove_row.emit()\n        download.deleteLater()\n        self._update_indexes()\n        if not self.downloads:\n            self._update_timer.stop()\n        log.downloads.debug(\"Removed download {}\".format(download))\n\n    def _update_indexes(self):\n        \"\"\"Update indexes of all DownloadItems.\"\"\"\n        for i, d in enumerate(self.downloads, 1):\n            d.index = i\n        self.data_changed.emit(-1)\n\n    def _init_filename_question(self, question, download):\n        \"\"\"Set up an existing filename question with a download.\"\"\"\n        question.answered.connect(download.set_target)\n        question.cancelled.connect(download.cancel)\n        download.cancelled.connect(question.abort)\n        download.error.connect(question.abort)\n\n\nclass DownloadModel(QAbstractListModel):\n\n    \"\"\"A list model showing downloads.\"\"\"\n\n    def __init__(self, qtnetwork_manager, webengine_manager=None, parent=None):\n        super().__init__(parent)\n        self._qtnetwork_manager = qtnetwork_manager\n        self._webengine_manager = webengine_manager\n\n        qtnetwork_manager.data_changed.connect(\n            functools.partial(self._on_data_changed, webengine=False))\n        qtnetwork_manager.begin_insert_row.connect(\n            functools.partial(self._on_begin_insert_row, webengine=False))\n        qtnetwork_manager.begin_remove_row.connect(\n            functools.partial(self._on_begin_remove_row, webengine=False))\n        qtnetwork_manager.end_insert_row.connect(self.endInsertRows)\n        qtnetwork_manager.end_remove_row.connect(self.endRemoveRows)\n\n        if webengine_manager is not None:\n            webengine_manager.data_changed.connect(\n                functools.partial(self._on_data_changed, webengine=True))\n            webengine_manager.begin_insert_row.connect(\n                functools.partial(self._on_begin_insert_row, webengine=True))\n            webengine_manager.begin_remove_row.connect(\n                functools.partial(self._on_begin_remove_row, webengine=True))\n            webengine_manager.end_insert_row.connect(self.endInsertRows)\n            webengine_manager.end_remove_row.connect(self.endRemoveRows)\n\n    def _all_downloads(self):\n        \"\"\"Combine downloads from both downloaders.\"\"\"\n        if self._webengine_manager is None:\n            return self._qtnetwork_manager.downloads[:]\n        else:\n            return (self._qtnetwork_manager.downloads +\n                    self._webengine_manager.downloads)\n\n    def __len__(self):\n        return len(self._all_downloads())\n\n    def __iter__(self):\n        return iter(self._all_downloads())\n\n    def __getitem__(self, idx):\n        return self._all_downloads()[idx]\n\n    def _on_begin_insert_row(self, idx, webengine=False):\n        log.downloads.debug(\"_on_begin_insert_row with idx {}, \"\n                            \"webengine {}\".format(idx, webengine))\n        if idx == -1:\n            self.beginInsertRows(QModelIndex(), 0, -1)\n            return\n\n        assert idx >= 0, idx\n        if webengine:\n            idx += len(self._qtnetwork_manager.downloads)\n        self.beginInsertRows(QModelIndex(), idx, idx)\n\n    def _on_begin_remove_row(self, idx, webengine=False):\n        log.downloads.debug(\"_on_begin_remove_row with idx {}, \"\n                            \"webengine {}\".format(idx, webengine))\n        if idx == -1:\n            self.beginRemoveRows(QModelIndex(), 0, -1)\n            return\n\n        assert idx >= 0, idx\n        if webengine:\n            idx += len(self._qtnetwork_manager.downloads)\n        self.beginRemoveRows(QModelIndex(), idx, idx)\n\n    def _on_data_changed(self, idx, *, webengine):\n        \"\"\"Called when a downloader's data changed.\n\n        Args:\n            start: The first changed index as int.\n            end: The last changed index as int, or -1 for all indices.\n            webengine: If given, the QtNetwork download length is added to the\n                      index.\n        \"\"\"\n        if idx == -1:\n            start_index = self.index(0, 0)\n            end_index = self.last_index()\n        else:\n            if webengine:\n                idx += len(self._qtnetwork_manager.downloads)\n            start_index = self.index(idx, 0)\n            end_index = self.index(idx, 0)\n            qtutils.ensure_valid(start_index)\n            qtutils.ensure_valid(end_index)\n        self.dataChanged.emit(start_index, end_index)\n\n    def _raise_no_download(self, count):\n        \"\"\"Raise an exception that the download doesn't exist.\n\n        Args:\n            count: The index of the download\n        \"\"\"\n        if not count:\n            raise cmdutils.CommandError(\"There's no download!\")\n        raise cmdutils.CommandError(\"There's no download {}!\".format(count))\n\n    @cmdutils.register(instance='download-model', scope='window')\n    @cmdutils.argument('count', value=cmdutils.Value.count)\n    def download_cancel(self, all_=False, count=0):\n        \"\"\"Cancel the last/[count]th download.\n\n        Args:\n            all_: Cancel all running downloads\n            count: The index of the download to cancel.\n        \"\"\"\n        downloads = self._all_downloads()\n        if all_:\n            for download in downloads:\n                if not download.done:\n                    download.cancel()\n        else:\n            try:\n                download = downloads[count - 1]\n            except IndexError:\n                self._raise_no_download(count)\n            if download.done:\n                if not count:\n                    count = len(self)\n                raise cmdutils.CommandError(\"Download {} is already done!\"\n                                            .format(count))\n            download.cancel()\n\n    @cmdutils.register(instance='download-model', scope='window')\n    @cmdutils.argument('count', value=cmdutils.Value.count)\n    def download_delete(self, count=0):\n        \"\"\"Delete the last/[count]th download from disk.\n\n        Args:\n            count: The index of the download to delete.\n        \"\"\"\n        try:\n            download = self[count - 1]\n        except IndexError:\n            self._raise_no_download(count)\n        if not download.successful:\n            if not count:\n                count = len(self)\n            raise cmdutils.CommandError(\"Download {} is not done!\"\n                                        .format(count))\n        download.delete()\n        download.remove()\n        log.downloads.debug(\"deleted download {}\".format(download))\n\n    @cmdutils.register(instance='download-model', scope='window', maxsplit=0)\n    @cmdutils.argument('count', value=cmdutils.Value.count)\n    def download_open(self, cmdline: str = None, count: int = 0) -> None:\n        \"\"\"Open the last/[count]th download.\n\n        If no specific command is given, this will use the system's default\n        application to open the file.\n\n        Args:\n            cmdline: The command which should be used to open the file. A `{}`\n                     is expanded to the temporary file name. If no `{}` is\n                     present, the filename is automatically appended to the\n                     cmdline.\n            count: The index of the download to open.\n        \"\"\"\n        try:\n            download = self[count - 1]\n        except IndexError:\n            self._raise_no_download(count)\n        if not download.successful:\n            if not count:\n                count = len(self)\n            raise cmdutils.CommandError(\"Download {} is not done!\"\n                                        .format(count))\n        download.open_file(cmdline)\n\n    @cmdutils.register(instance='download-model', scope='window')\n    @cmdutils.argument('count', value=cmdutils.Value.count)\n    def download_retry(self, count=0):\n        \"\"\"Retry the first failed/[count]th download.\n\n        Args:\n            count: The index of the download to retry.\n        \"\"\"\n        if count:\n            try:\n                download = self[count - 1]\n            except IndexError:\n                self._raise_no_download(count)\n            if download.successful or not download.done:\n                raise cmdutils.CommandError(\"Download {} did not fail!\"\n                                            .format(count))\n        else:\n            to_retry = [d for d in self if d.done and not d.successful]\n            if not to_retry:\n                raise cmdutils.CommandError(\"No failed downloads!\")\n            download = to_retry[0]\n        download.try_retry()\n\n    def can_clear(self):\n        \"\"\"Check if there are finished downloads to clear.\"\"\"\n        return any(download.done for download in self)\n\n    @cmdutils.register(instance='download-model', scope='window')\n    def download_clear(self):\n        \"\"\"Remove all finished downloads from the list.\"\"\"\n        for download in self:\n            if download.done:\n                download.remove()\n\n    @cmdutils.register(instance='download-model', scope='window')\n    @cmdutils.argument('count', value=cmdutils.Value.count)\n    def download_remove(self, all_=False, count=0):\n        \"\"\"Remove the last/[count]th download from the list.\n\n        Args:\n            all_: Remove all finished downloads.\n            count: The index of the download to remove.\n        \"\"\"\n        if all_:\n            self.download_clear()\n        else:\n            try:\n                download = self[count - 1]\n            except IndexError:\n                self._raise_no_download(count)\n            if not download.done:\n                if not count:\n                    count = len(self)\n                raise cmdutils.CommandError(\"Download {} is not done!\"\n                                            .format(count))\n            download.remove()\n\n    def running_downloads(self):\n        \"\"\"Return the amount of still running downloads.\n\n        Return:\n            The number of unfinished downloads.\n        \"\"\"\n        return sum(1 for download in self if not download.done)\n\n    def last_index(self):\n        \"\"\"Get the last index in the model.\n\n        Return:\n            A (possibly invalid) QModelIndex.\n        \"\"\"\n        idx = self.index(self.rowCount() - 1)\n        return idx\n\n    def headerData(self, section, orientation, role=Qt.DisplayRole):\n        \"\"\"Simple constant header.\"\"\"\n        if (section == 0 and orientation == Qt.Horizontal and\n                role == Qt.DisplayRole):\n            return \"Downloads\"\n        else:\n            return \"\"\n\n    def data(self, index, role):\n        \"\"\"Download data from DownloadManager.\"\"\"\n        if not index.isValid():\n            return None\n\n        if index.parent().isValid() or index.column() != 0:\n            return None\n\n        item = self[index.row()]\n        if role == Qt.DisplayRole:\n            data = str(item)\n        elif role == Qt.ForegroundRole:\n            data = item.get_status_color('fg')\n        elif role == Qt.BackgroundRole:\n            data = item.get_status_color('bg')\n        elif role == ModelRole.item:\n            data = item\n        elif role == Qt.ToolTipRole:\n            if item.error_msg is None:\n                data = None\n            else:\n                return item.error_msg\n        else:\n            data = None\n        return data\n\n    def flags(self, index):\n        \"\"\"Override flags so items aren't selectable.\n\n        The default would be Qt.ItemIsEnabled | Qt.ItemIsSelectable.\n        \"\"\"\n        if not index.isValid():\n            return Qt.ItemFlags()\n        return Qt.ItemIsEnabled | Qt.ItemNeverHasChildren\n\n    def rowCount(self, parent=QModelIndex()):\n        \"\"\"Get count of active downloads.\"\"\"\n        if parent.isValid():\n            # We don't have children\n            return 0\n        return len(self)\n\n\nclass TempDownloadManager:\n\n    \"\"\"Manager to handle temporary download files.\n\n    The downloads are downloaded to a temporary location and then openened with\n    the system standard application. The temporary files are deleted when\n    qutebrowser is shutdown.\n\n    Attributes:\n        files: A list of NamedTemporaryFiles of downloaded items.\n    \"\"\"\n\n    def __init__(self):\n        self.files = []\n        self._tmpdir = None\n\n    def cleanup(self):\n        \"\"\"Clean up any temporary files.\"\"\"\n        if self._tmpdir is not None:\n            try:\n                self._tmpdir.cleanup()\n            except OSError:\n                log.misc.exception(\"Failed to clean up temporary download \"\n                                   \"directory\")\n            self._tmpdir = None\n\n    def get_tmpdir(self):\n        \"\"\"Return the temporary directory that is used for downloads.\n\n        The directory is created lazily on first access.\n\n        Return:\n            The tempfile.TemporaryDirectory that is used.\n        \"\"\"\n        if self._tmpdir is None:\n            self._tmpdir = tempfile.TemporaryDirectory(\n                prefix='qutebrowser-downloads-')\n        return self._tmpdir\n\n    def get_tmpfile(self, suggested_name):\n        \"\"\"Return a temporary file in the temporary downloads directory.\n\n        The files are kept as long as qutebrowser is running and automatically\n        cleaned up at program exit.\n\n        Args:\n            suggested_name: str of the \"suggested\"/original filename. Used as a\n                            suffix, so any file extenions are preserved.\n\n        Return:\n            A tempfile.NamedTemporaryFile that should be used to save the file.\n        \"\"\"\n        tmpdir = self.get_tmpdir()\n        suggested_name = utils.sanitize_filename(suggested_name)\n        # Make sure that the filename is not too long\n        suggested_name = utils.elide_filename(suggested_name, 50)\n        fobj = tempfile.NamedTemporaryFile(dir=tmpdir.name, delete=False,\n                                           suffix='_' + suggested_name)\n        self.files.append(fobj)\n        return fobj\n\n\ntemp_download_manager = TempDownloadManager()\n", "idx": 1, "id": 23349, "msg": "I'm not sure if this is standard practice, but I would prefer to leave this initialization here, if only to show that such a variable exists in this file (instead of inferring it from the globals). It can also cause weird issues if, for example, `init` isn't run before other methods.", "proj": "qutebrowser-qutebrowser", "lang": "py"}
{"patch": "@@ -0,0 +1,11 @@\n+// <copyright file=\"IEvent.cs\" company=\"Datadog\">\n+// Unless explicitly stated otherwise all files in this repository are licensed under the Apache 2 License.\n+// This product includes software developed at Datadog (https://www.datadoghq.com/). Copyright 2017 Datadog, Inc.\n+// </copyright>\n+\n+namespace Datadog.Trace.Abstractions\n+{\n+    internal interface IEvent\n+    {\n+    }\n+}", "y": 1, "oldf": "", "idx": 1, "id": 21551, "msg": "This is an appsec concept right? Should it live in the Appsec namespace?", "proj": "DataDog-dd-trace-dotnet", "lang": ".cs"}
{"patch": "@@ -43,14 +43,14 @@ type ClusterEvent interface{}\n // Specific type of cluster event emitted when new member joins cluster\n type NewMemberEvent struct {\n \tendpointsInfo\n-\tId string\n+\tID string\n }\n \n // Specific type of cluster event emitted when leadership is transferred.\n // It is not always loss or acquire of leadership of this specific node\n type LeadershipEvent struct {\n \tHeld            bool\n-\tLeaderId        string\n+\tLeaderID        string\n \tLeaderEndpoints []string\n }\n ", "y": 1, "oldf": "package hub\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"crypto/tls\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"net\"\n\t\"reflect\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/docker/leadership\"\n\t\"github.com/docker/libkv\"\n\t\"github.com/docker/libkv/store\"\n\t\"github.com/docker/libkv/store/boltdb\"\n\t\"github.com/docker/libkv/store/consul\"\n\tlog \"github.com/noxiouz/zapctx/ctxlog\"\n\t\"github.com/pkg/errors\"\n\t\"github.com/satori/uuid\"\n\tpb \"github.com/sonm-io/core/proto\"\n\t\"github.com/sonm-io/core/util\"\n\t\"github.com/sonm-io/core/util/xgrpc\"\n\t\"go.uber.org/zap\"\n\t\"golang.org/x/sync/errgroup\"\n\t\"google.golang.org/grpc\"\n\t\"google.golang.org/grpc/credentials\"\n)\n\n// ClusterEvent describes an event that can produce the cluster.\n//\n// Possible types are:\n// - `NewMemberEvent` when new member joins cluster\n// - `LeadershipEvent` when leadership is transferred\n// - `T` types for other registered synchronizable entities.\n// - `error` on any unrecoverable error, after that channel is closed\n//   and the user should call Run once more to enable synchronization\n\ntype ClusterEvent interface{}\n\n// Specific type of cluster event emitted when new member joins cluster\ntype NewMemberEvent struct {\n\tendpointsInfo\n\tId string\n}\n\n// Specific type of cluster event emitted when leadership is transferred.\n// It is not always loss or acquire of leadership of this specific node\ntype LeadershipEvent struct {\n\tHeld            bool\n\tLeaderId        string\n\tLeaderEndpoints []string\n}\n\ntype Cluster interface {\n\t// Starts synchronization process. Can be called multiple times after error is received in EventChannel\n\tRun() error\n\n\tClose()\n\n\t// IsLeader returns true if this cluster is a leader, i.e. we rule the\n\t// synchronization process.\n\tIsLeader() bool\n\n\tLeaderClient() (pb.HubClient, error)\n\n\tRegisterAndLoadEntity(name string, prototype interface{}) error\n\n\tSynchronize(entity interface{}) error\n\n\t// Fetch current cluster members\n\tMembers() ([]NewMemberEvent, error)\n}\n\n// Returns a cluster writer interface if this node is a master, event channel\n// otherwise.\n// Should be recalled when a cluster's master/slave state changes.\n// The channel is closed when the specified context is canceled.\nfunc NewCluster(ctx context.Context, cfg *ClusterConfig, workerEndpoint string,\n\tcreds credentials.TransportCredentials) (Cluster, <-chan ClusterEvent, error) {\n\tclusterStore, err := makeStore(ctx, cfg)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\terr = clusterStore.Put(cfg.SynchronizableEntitiesPrefix, []byte{}, &store.WriteOptions{IsDir: true})\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tclientEndpoints, workerEndpoints, err := getEndpoints(cfg, workerEndpoint)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tc := cluster{\n\t\tparentCtx: ctx,\n\t\tcfg:       cfg,\n\n\t\tregisteredEntities: make(map[string]reflect.Type),\n\t\tentityNames:        make(map[reflect.Type]string),\n\n\t\tstore: clusterStore,\n\n\t\tisLeader: true,\n\t\tid:       uuid.NewV1().String(),\n\t\tendpoints: &endpointsInfo{\n\t\t\tClient: clientEndpoints,\n\t\t\tWorker: workerEndpoints,\n\t\t},\n\n\t\tclients:          make(map[string]*client),\n\t\tclusterEndpoints: make(map[string]*endpointsInfo),\n\n\t\teventChannel: make(chan ClusterEvent, 100),\n\n\t\tcreds: creds,\n\t}\n\n\tif cfg.Failover {\n\t\tc.isLeader = false\n\t}\n\n\tc.ctx, c.cancel = context.WithCancel(c.parentCtx)\n\n\tc.registerMember(c.id, clientEndpoints, workerEndpoints)\n\n\treturn &c, c.eventChannel, nil\n}\n\ntype client struct {\n\tclient pb.HubClient\n\tconn   *grpc.ClientConn\n}\n\ntype endpointsInfo struct {\n\tClient []string\n\tWorker []string\n}\n\ntype cluster struct {\n\tparentCtx context.Context\n\tctx       context.Context\n\tcancel    context.CancelFunc\n\tcfg       *ClusterConfig\n\n\tregisteredEntitiesMu sync.RWMutex\n\tregisteredEntities   map[string]reflect.Type\n\tentityNames          map[reflect.Type]string\n\n\tstore store.Store\n\n\t// self info\n\tisLeader  bool\n\tid        string\n\tendpoints *endpointsInfo\n\n\tleaderLock sync.RWMutex\n\n\tclients          map[string]*client\n\tclusterEndpoints map[string]*endpointsInfo\n\tleaderId         string\n\n\teventChannel chan ClusterEvent\n\n\tcreds credentials.TransportCredentials\n}\n\nfunc (c *cluster) Close() {\n\tif c.cancel != nil {\n\t\tc.cancel()\n\t}\n}\n\nfunc (c *cluster) Run() error {\n\tc.Close()\n\n\tw := errgroup.Group{}\n\n\tc.ctx, c.cancel = context.WithCancel(c.parentCtx)\n\tif c.cfg.Failover {\n\t\tc.isLeader = false\n\t\tw.Go(c.election)\n\t\tw.Go(c.announce)\n\t\tw.Go(c.hubWatch)\n\t\tw.Go(c.leaderWatch)\n\t\tw.Go(c.hubGC)\n\t} else {\n\t\tlog.G(c.ctx).Info(\"running in dev single-server mode\")\n\t}\n\n\tw.Go(c.watchEvents)\n\treturn w.Wait()\n}\n\nfunc (c *cluster) IsLeader() bool {\n\treturn c.isLeader\n}\n\n// Get GRPC hub client to current leader\nfunc (c *cluster) LeaderClient() (pb.HubClient, error) {\n\tlog.G(c.ctx).Debug(\"fetching leader client\")\n\tc.leaderLock.RLock()\n\tdefer c.leaderLock.RUnlock()\n\n\tendpts, ok := c.clusterEndpoints[c.leaderId]\n\tif !ok || len(endpts.Client) == 0 {\n\t\tlog.G(c.ctx).Warn(\"can not determine leader\")\n\t\treturn nil, errors.New(\"can not determine leader\")\n\t}\n\n\tclient, ok := c.clients[c.leaderId]\n\tif !ok || client == nil {\n\t\tlog.G(c.ctx).Warn(\"not connected to leader\")\n\t\treturn nil, errors.New(\"not connected to leader\")\n\t}\n\n\treturn client.client, nil\n}\n\nfunc (c *cluster) RegisterAndLoadEntity(name string, prototype interface{}) error {\n\tc.registeredEntitiesMu.Lock()\n\tdefer c.registeredEntitiesMu.Unlock()\n\tt := reflect.Indirect(reflect.ValueOf(prototype)).Type()\n\tc.registeredEntities[name] = t\n\tc.entityNames[t] = name\n\tkeyName := c.cfg.SynchronizableEntitiesPrefix + \"/\" + name\n\texists, err := c.store.Exists(keyName)\n\tif err != nil {\n\t\treturn errors.Wrap(err, fmt.Sprintf(\"could not check entity %s for existance in storage\", name))\n\t}\n\tif !exists {\n\t\treturn nil\n\t}\n\tkvPair, err := c.store.Get(keyName)\n\tif err != nil {\n\t\treturn errors.Wrap(err, fmt.Sprintf(\"could not fetch entity %s initial value from storage\", name))\n\t}\n\terr = json.Unmarshal(kvPair.Value, prototype)\n\tif err != nil {\n\t\treturn errors.Wrap(err, fmt.Sprintf(\"could not unmarshal entity %s from storage data\", name))\n\t}\n\treturn nil\n}\n\nfunc (c *cluster) Synchronize(entity interface{}) error {\n\tif !c.isLeader {\n\t\tlog.G(c.ctx).Warn(\"failed to synchronize entity - not a leader\")\n\t\treturn errors.New(\"not a leader\")\n\t}\n\tname, err := c.nameByEntity(entity)\n\tif err != nil {\n\t\tlog.G(c.ctx).Warn(\"unknown synchronizable entity\", zap.Any(\"entity\", entity))\n\t\treturn err\n\t}\n\tdata, err := json.Marshal(entity)\n\tif err != nil {\n\t\tlog.G(c.ctx).Warn(\"could not marshal entity\", zap.Error(err))\n\t\treturn err\n\t}\n\tlog.G(c.ctx).Debug(\"synchronizing entity\", zap.Any(\"entity\", entity), zap.ByteString(\"marshalled\", data))\n\tc.store.Put(c.cfg.SynchronizableEntitiesPrefix+\"/\"+name, data, &store.WriteOptions{})\n\treturn nil\n}\n\nfunc (c *cluster) Members() ([]NewMemberEvent, error) {\n\tresult := make([]NewMemberEvent, 0)\n\tc.leaderLock.RLock()\n\tdefer c.leaderLock.RUnlock()\n\n\tfor id, endpts := range c.clusterEndpoints {\n\t\tresult = append(result, NewMemberEvent{endpointsInfo: *endpts, Id: id})\n\t}\n\n\treturn result, nil\n}\n\nfunc (c *cluster) election() error {\n\tcandidate := leadership.NewCandidate(c.store, c.cfg.LeaderKey, c.id, c.cfg.LeaderTTL)\n\telectedCh, errCh := candidate.RunForElection()\n\tlog.G(c.ctx).Info(\"starting leader election goroutine\")\n\n\tfor {\n\t\tselect {\n\t\tcase c.isLeader = <-electedCh:\n\t\t\tlog.G(c.ctx).Debug(\"election event\", zap.Bool(\"isLeader\", c.isLeader))\n\t\t\t// Do not possibly block on event channel to prevent stale leadership data\n\t\t\tgo c.emitLeadershipEvent()\n\t\tcase err := <-errCh:\n\t\t\tlog.G(c.ctx).Error(\"election failure\", zap.Error(err))\n\t\t\tc.close(errors.WithStack(err))\n\t\t\treturn err\n\t\tcase <-c.ctx.Done():\n\t\t\tcandidate.Stop()\n\t\t\treturn nil\n\t\t}\n\t}\n}\n\n// Blocks in endless cycle watching for leadership.\n// When the leadership is changed stores new leader id in cluster\nfunc (c *cluster) leaderWatch() error {\n\tlog.G(c.ctx).Info(\"starting leader watch goroutine\")\n\tfollower := leadership.NewFollower(c.store, c.cfg.LeaderKey)\n\tleaderCh, errCh := follower.FollowElection()\n\tfor {\n\t\tselect {\n\t\tcase <-c.ctx.Done():\n\t\t\tfollower.Stop()\n\t\t\treturn nil\n\t\tcase err := <-errCh:\n\t\t\tlog.G(c.ctx).Error(\"leader watch failure\", zap.Error(err))\n\t\t\tc.close(errors.WithStack(err))\n\t\t\treturn err\n\t\tcase leaderId := <-leaderCh:\n\t\t\tc.leaderLock.Lock()\n\t\t\tc.leaderId = leaderId\n\t\t\tc.leaderLock.Unlock()\n\t\t\tc.emitLeadershipEvent()\n\t\t}\n\t}\n}\n\nfunc (c *cluster) announce() error {\n\tlog.G(c.ctx).Info(\"starting announce goroutine\", zap.Any(\"endpointsInfo\", c.endpoints), zap.String(\"ID\", c.id))\n\tendpointsData, _ := json.Marshal(c.endpoints)\n\tticker := time.NewTicker(c.cfg.AnnounceTTL)\n\tdefer ticker.Stop()\n\tfor {\n\t\tselect {\n\t\tcase <-ticker.C:\n\t\t\terr := c.store.Put(c.cfg.MemberListKey+\"/\"+c.id, endpointsData, &store.WriteOptions{TTL: c.cfg.AnnounceTTL})\n\t\t\tif err != nil {\n\t\t\t\tlog.G(c.ctx).Error(\"could not update announce\", zap.Error(err))\n\t\t\t\tc.close(errors.WithStack(err))\n\t\t\t\treturn err\n\t\t\t}\n\t\tcase <-c.ctx.Done():\n\t\t\treturn nil\n\t\t}\n\t}\n}\n\nfunc (c *cluster) hubWatch() error {\n\tlog.G(c.ctx).Info(\"starting member watch goroutine\")\n\tstopCh := make(chan struct{})\n\tlistener, err := c.store.WatchTree(c.cfg.MemberListKey, stopCh)\n\tif err != nil {\n\t\tc.close(err)\n\t}\n\tfor {\n\t\tselect {\n\t\tcase members, ok := <-listener:\n\t\t\tif !ok {\n\t\t\t\terr := errors.WithStack(errors.New(\"hub watcher closed\"))\n\t\t\t\tc.close(err)\n\t\t\t\treturn err\n\t\t\t} else {\n\t\t\t\tfor _, member := range members {\n\t\t\t\t\tif member.Value == nil {\n\t\t\t\t\t\tlog.G(c.ctx).Debug(\"received cluster member with nil Value, skipping (this can happen due to consul peculiarities)\", zap.Any(\"member\", member))\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\n\t\t\t\t\tlog.G(c.ctx).Debug(\"received cluster member, registering\", zap.Any(\"member\", member))\n\t\t\t\t\terr := c.registerMemberFromKV(member)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tlog.G(c.ctx).Warn(\"trash data in cluster members folder: \", zap.Any(\"kvPair\", member), zap.Error(err))\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\tcase <-c.ctx.Done():\n\t\t\tclose(stopCh)\n\t\t\treturn nil\n\t\t}\n\t}\n}\n\nfunc (c *cluster) checkHub(id string) error {\n\tif id == c.id {\n\t\treturn nil\n\t}\n\n\texists, err := c.store.Exists(c.cfg.MemberListKey + \"/\" + id)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif !exists {\n\t\tlog.G(c.ctx).Info(\"hub is offline, removing\", zap.String(\"hubId\", id))\n\t\tc.leaderLock.Lock()\n\t\tdefer c.leaderLock.Unlock()\n\n\t\tif cli, ok := c.clients[id]; ok {\n\t\t\tcli.conn.Close()\n\t\t\tdelete(c.clients, id)\n\t\t\tdelete(c.clusterEndpoints, id)\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (c *cluster) hubGC() error {\n\tlog.G(c.ctx).Info(\"starting hub GC goroutine\")\n\tt := time.NewTicker(c.cfg.MemberGCPeriod)\n\tdefer t.Stop()\n\n\tfor {\n\t\tselect {\n\t\tcase <-t.C:\n\t\t\tc.leaderLock.RLock()\n\t\t\tidsToCheck := make([]string, 0)\n\t\t\tfor id := range c.clients {\n\t\t\t\tidsToCheck = append(idsToCheck, id)\n\t\t\t}\n\t\t\tc.leaderLock.RUnlock()\n\n\t\t\tfor _, id := range idsToCheck {\n\t\t\t\terr := c.checkHub(id)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.G(c.ctx).Warn(\"failed to check hub\", zap.String(\"hubId\", id), zap.Error(err))\n\t\t\t\t} else {\n\t\t\t\t\tlog.G(c.ctx).Info(\"checked hub\", zap.String(\"hubId\", id))\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase <-c.ctx.Done():\n\t\t\treturn nil\n\t\t}\n\t}\n}\n\n//TODO: extract this to some kind of store wrapper over boltdb\nfunc (c *cluster) watchEventsTree(stopCh <-chan struct{}) (<-chan []*store.KVPair, error) {\n\tif c.cfg.Failover {\n\t\treturn c.store.WatchTree(c.cfg.SynchronizableEntitiesPrefix, stopCh)\n\t}\n\topts := store.WriteOptions{\n\t\tIsDir: true,\n\t}\n\tempty := make([]byte, 0)\n\tc.store.Put(c.cfg.SynchronizableEntitiesPrefix, empty, &opts)\n\tch := make(chan []*store.KVPair, 1)\n\n\tdata := make(map[string]*store.KVPair)\n\tupdater := func() error {\n\t\tchanged := false\n\t\tpairs, err := c.store.List(c.cfg.SynchronizableEntitiesPrefix)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tfilteredPairs := make([]*store.KVPair, 0)\n\t\tfor _, pair := range pairs {\n\t\t\tif pair.Key == c.cfg.SynchronizableEntitiesPrefix {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tfilteredPairs = append(filteredPairs, pair)\n\t\t\tcur, ok := data[pair.Key]\n\t\t\tif !ok || !bytes.Equal(cur.Value, pair.Value) {\n\t\t\t\tchanged = true\n\t\t\t\tdata[pair.Key] = pair\n\t\t\t}\n\t\t}\n\t\tif changed {\n\t\t\tch <- filteredPairs\n\t\t}\n\t\treturn nil\n\t}\n\n\tif err := updater(); err != nil {\n\t\treturn nil, err\n\t}\n\tgo func() {\n\t\tt := time.NewTicker(time.Second * 1)\n\t\tdefer t.Stop()\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-c.ctx.Done():\n\t\t\t\treturn\n\t\t\tcase <-t.C:\n\t\t\t\terr := updater()\n\t\t\t\tif err != nil {\n\t\t\t\t\tc.close(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\treturn ch, nil\n}\n\nfunc (c *cluster) watchEvents() error {\n\tlog.G(c.ctx).Info(\"subscribing on sync folder\")\n\twatchStopChannel := make(chan struct{})\n\tch, err := c.watchEventsTree(watchStopChannel)\n\tif err != nil {\n\t\tc.close(err)\n\t\treturn err\n\t}\n\tfor {\n\t\tselect {\n\t\tcase <-c.ctx.Done():\n\t\t\tclose(watchStopChannel)\n\t\t\treturn nil\n\t\tcase kvList, ok := <-ch:\n\t\t\tif !ok {\n\t\t\t\terr := errors.WithStack(errors.New(\"watch channel is closed\"))\n\t\t\t\tc.close(err)\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tfor _, kv := range kvList {\n\t\t\t\tname := fetchNameFromPath(kv.Key)\n\t\t\t\tt, err := c.typeByName(name)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.G(c.ctx).Warn(\"unknown synchronizable entity\", zap.String(\"entity\", name))\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tvalue := reflect.New(t)\n\t\t\t\terr = json.Unmarshal(kv.Value, value.Interface())\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.G(c.ctx).Warn(\"can not unmarshal entity\", zap.Error(err))\n\t\t\t\t} else {\n\t\t\t\t\tlog.G(c.ctx).Debug(\"received cluster event\", zap.String(\"name\", name), zap.Any(\"value\", value.Interface()))\n\t\t\t\t\tc.eventChannel <- reflect.Indirect(value).Interface()\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc (c *cluster) nameByEntity(entity interface{}) (string, error) {\n\tc.registeredEntitiesMu.RLock()\n\tdefer c.registeredEntitiesMu.RUnlock()\n\tt := reflect.Indirect(reflect.ValueOf(entity)).Type()\n\tname, ok := c.entityNames[t]\n\tif !ok {\n\t\treturn \"\", errors.New(\"entity \" + t.String() + \" is not registered\")\n\t}\n\treturn name, nil\n}\n\nfunc (c *cluster) typeByName(name string) (reflect.Type, error) {\n\tc.registeredEntitiesMu.RLock()\n\tdefer c.registeredEntitiesMu.RUnlock()\n\tt, ok := c.registeredEntities[name]\n\tif !ok {\n\t\treturn nil, errors.New(\"entity \" + name + \" is not registered\")\n\t}\n\treturn t, nil\n}\n\nfunc makeStore(ctx context.Context, cfg *ClusterConfig) (store.Store, error) {\n\tconsul.Register()\n\tboltdb.Register()\n\tlog.G(ctx).Info(\"creating store\", zap.Any(\"store\", cfg))\n\n\tvar (\n\t\tendpts  = []string{cfg.Store.Endpoint}\n\t\tbackend = store.Backend(cfg.Store.Type)\n\t\ttlsConf *tls.Config\n\t)\n\tif len(cfg.Store.CertFile) != 0 && len(cfg.Store.KeyFile) != 0 {\n\t\tcer, err := tls.LoadX509KeyPair(cfg.Store.CertFile, cfg.Store.KeyFile)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\ttlsConf = &tls.Config{\n\t\t\tCertificates: []tls.Certificate{cer},\n\t\t}\n\t}\n\tconfig := store.Config{\n\t\tTLS: tlsConf,\n\t}\n\tconfig.Bucket = cfg.Store.Bucket\n\n\treturn libkv.NewStore(backend, endpts, &config)\n}\n\nfunc (c *cluster) close(err error) {\n\tlog.G(c.ctx).Error(\"cluster failure\", zap.Error(err))\n\tc.leaderLock.Lock()\n\tc.leaderId = \"\"\n\tc.isLeader = false\n\tc.leaderLock.Unlock()\n\tc.Close()\n}\n\nfunc (c *cluster) emitLeadershipEvent() {\n\tc.leaderLock.Lock()\n\tdefer c.leaderLock.Unlock()\n\n\tendpoints, ok := c.clusterEndpoints[c.leaderId]\n\tif !ok {\n\t\tlog.G(c.ctx).Error(\"leader endpoint not found\", zap.String(\"leader_id\", c.leaderId))\n\t\treturn\n\t}\n\n\tc.eventChannel <- LeadershipEvent{\n\t\tHeld:            c.isLeader,\n\t\tLeaderId:        c.leaderId,\n\t\tLeaderEndpoints: endpoints.Client,\n\t}\n}\n\nfunc (c *cluster) memberExists(id string) bool {\n\tc.leaderLock.RLock()\n\tdefer c.leaderLock.RUnlock()\n\t_, ok := c.clients[id]\n\treturn ok\n}\n\nfunc (c *cluster) registerMemberFromKV(member *store.KVPair) error {\n\tid := fetchNameFromPath(member.Key)\n\tif id == c.id {\n\t\treturn nil\n\t}\n\n\tif c.memberExists(id) {\n\t\treturn nil\n\t}\n\n\tendpts := &endpointsInfo{}\n\terr := json.Unmarshal(member.Value, &endpts)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn c.registerMember(id, endpts.Client, endpts.Worker)\n}\n\nfunc (c *cluster) registerMember(id string, clientEndpoints, workerEndpoints []string) error {\n\tlog.G(c.ctx).Info(\"fetched endpointsInfo of new member\",\n\t\tzap.Any(\"client_endpoints\", clientEndpoints),\n\t\tzap.Any(\"worker_endpoints\", workerEndpoints))\n\tc.leaderLock.Lock()\n\tc.clusterEndpoints[id] = &endpointsInfo{Client: clientEndpoints, Worker: workerEndpoints}\n\tc.eventChannel <- NewMemberEvent{endpointsInfo: *c.clusterEndpoints[id], Id: id}\n\tc.leaderLock.Unlock()\n\n\tif id == c.id {\n\t\treturn nil\n\t}\n\n\tfor _, ep := range clientEndpoints {\n\t\tconn, err := xgrpc.NewClient(c.ctx, ep, c.creds, grpc.WithBlock(), grpc.WithTimeout(time.Second*5))\n\t\tif err != nil {\n\t\t\tlog.G(c.ctx).Warn(\"could not connect to hub\", zap.String(\"endpoint\", ep), zap.Error(err))\n\t\t\tcontinue\n\t\t} else {\n\t\t\tlog.G(c.ctx).Info(\"successfully connected to cluster member\")\n\t\t\tc.leaderLock.Lock()\n\n\t\t\t_, ok := c.clients[id]\n\t\t\tif ok {\n\t\t\t\tlog.G(c.ctx).Info(\"duplicated connection - dropping\")\n\t\t\t\tconn.Close()\n\t\t\t\tc.leaderLock.Unlock()\n\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tc.clients[id] = &client{pb.NewHubClient(conn), conn}\n\t\t\tc.leaderLock.Unlock()\n\n\t\t\treturn nil\n\t\t}\n\t}\n\n\treturn errors.New(\"could not connect to any provided member endpoint\")\n}\n\nfunc fetchNameFromPath(key string) string {\n\tparts := strings.Split(key, \"/\")\n\treturn parts[len(parts)-1]\n}\n\nfunc getEndpoints(config *ClusterConfig, workerEndpoint string) (clientEndpoints, workerEndpoints []string, err error) {\n\tclientEndpoint := config.AnnounceEndpoint\n\tif len(clientEndpoint) == 0 {\n\t\tclientEndpoint = config.Endpoint\n\t}\n\n\tclientEndpoints, err = parseEndpoints(clientEndpoint)\n\tif err != nil {\n\t\treturn nil, nil, errors.Wrap(err, \"failed to get client endpointsInfo\")\n\t}\n\n\tworkerEndpoints, err = parseEndpoints(workerEndpoint)\n\tif err != nil {\n\t\treturn nil, nil, errors.Wrap(err, \"failed to get worker endpointsInfo\")\n\t}\n\n\treturn\n}\n\nfunc parseEndpoints(endpoint string) (endpts []string, err error) {\n\tipAddr, port, err := net.SplitHostPort(endpoint)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif len(ipAddr) != 0 {\n\t\tip := net.ParseIP(ipAddr)\n\t\tif ip == nil {\n\t\t\treturn nil, fmt.Errorf(\n\t\t\t\t\"client endpoint %s must be a valid IP\", ipAddr)\n\t\t}\n\n\t\tif !ip.IsUnspecified() {\n\t\t\tendpts = append(endpts, endpoint)\n\n\t\t\treturn endpts, nil\n\t\t}\n\t}\n\tsystemIPs, err := util.GetAvailableIPs()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, ip := range systemIPs {\n\t\tendpts = append(endpts, net.JoinHostPort(ip.String(), port))\n\t}\n\n\treturn endpts, nil\n}\n", "idx": 1, "id": 6298, "msg": "Go standard linter hates `Id`s and likes `ID`s, please do not resist.", "proj": "sonm-io-core", "lang": "go"}
{"patch": "@@ -76,7 +76,8 @@ class Net(Gen):\n         self.repr=net\n         self.parsed,self.netmask = self._parse_net(net)\n \n-\n+    def __str__(self):\n+        return self.repr\n                                                                                                \n     def __iter__(self):\n         for d in xrange(*self.parsed[3]):", "y": 1, "oldf": "## This file is part of Scapy\n## See http://www.secdev.org/projects/scapy for more informations\n## Copyright (C) Philippe Biondi <phil@secdev.org>\n## This program is published under a GPLv2 license\n\n\"\"\"\nGenerators and packet meta classes.\n\"\"\"\n\n###############\n## Generators ##\n################\n\nimport re,random,socket\nimport types\n\nclass Gen(object):\n    __slots__ = []\n    def __iter__(self):\n        return iter([])\n    \nclass SetGen(Gen):\n    def __init__(self, values, _iterpacket=1):\n        self._iterpacket=_iterpacket\n        if isinstance(values, (list, BasePacketList)):\n            self.values = list(values)\n        elif (type(values) is tuple) and (2 <= len(values) <= 3) and \\\n             all(type(i) is int for i in values):\n            # We use values[1] + 1 as stop value for xrange to maintain\n            # the behavior of using tuples as field `values`\n            self.values = [xrange(*((values[0], values[1] + 1) + values[2:]))]\n        else:\n            self.values = [values]\n    def transf(self, element):\n        return element\n    def __iter__(self):\n        for i in self.values:\n            if (isinstance(i, Gen) and\n                (self._iterpacket or not isinstance(i,BasePacket))) or (\n                    isinstance(i, (xrange, types.GeneratorType))):\n                for j in i:\n                    yield j\n            else:\n                yield i\n    def __repr__(self):\n        return \"<SetGen %r>\" % self.values\n\nclass Net(Gen):\n    \"\"\"Generate a list of IPs from a network address or a name\"\"\"\n    name = \"ip\"\n    ipaddress = re.compile(r\"^(\\*|[0-2]?[0-9]?[0-9](-[0-2]?[0-9]?[0-9])?)\\.(\\*|[0-2]?[0-9]?[0-9](-[0-2]?[0-9]?[0-9])?)\\.(\\*|[0-2]?[0-9]?[0-9](-[0-2]?[0-9]?[0-9])?)\\.(\\*|[0-2]?[0-9]?[0-9](-[0-2]?[0-9]?[0-9])?)(/[0-3]?[0-9])?$\")\n\n    @staticmethod\n    def _parse_digit(a,netmask):\n        netmask = min(8,max(netmask,0))\n        if a == \"*\":\n            a = (0,256)\n        elif a.find(\"-\") >= 0:\n            x,y = map(int,a.split(\"-\"))\n            if x > y:\n                y = x\n            a = (x &  (0xffL<<netmask) , max(y, (x | (0xffL>>(8-netmask))))+1)\n        else:\n            a = (int(a) & (0xffL<<netmask),(int(a) | (0xffL>>(8-netmask)))+1)\n        return a\n\n    @classmethod\n    def _parse_net(cls, net):\n        tmp=net.split('/')+[\"32\"]\n        if not cls.ipaddress.match(net):\n            tmp[0]=socket.gethostbyname(tmp[0])\n        netmask = int(tmp[1])\n        return map(lambda x,y: cls._parse_digit(x,y), tmp[0].split(\".\"), map(lambda x,nm=netmask: x-nm, (8,16,24,32))),netmask\n\n    def __init__(self, net):\n        self.repr=net\n        self.parsed,self.netmask = self._parse_net(net)\n\n\n                                                                                               \n    def __iter__(self):\n        for d in xrange(*self.parsed[3]):\n            for c in xrange(*self.parsed[2]):\n                for b in xrange(*self.parsed[1]):\n                    for a in xrange(*self.parsed[0]):\n                        yield \"%i.%i.%i.%i\" % (a,b,c,d)\n    def choice(self):\n        ip = []\n        for v in self.parsed:\n            ip.append(str(random.randint(v[0],v[1]-1)))\n        return \".\".join(ip) \n                          \n    def __repr__(self):\n        return \"Net(%r)\" % self.repr\n    def __eq__(self, other):\n        if hasattr(other, \"parsed\"):\n            p2 = other.parsed\n        else:\n            p2,nm2 = self._parse_net(other)\n        return self.parsed == p2\n    def __contains__(self, other):\n        if hasattr(other, \"parsed\"):\n            p2 = other.parsed\n        else:\n            p2,nm2 = self._parse_net(other)\n        for (a1,b1),(a2,b2) in zip(self.parsed,p2):\n            if a1 > a2 or b1 < b2:\n                return False\n        return True\n    def __rcontains__(self, other):        \n        return self in self.__class__(other)\n        \n\nclass OID(Gen):\n    name = \"OID\"\n    def __init__(self, oid):\n        self.oid = oid        \n        self.cmpt = []\n        fmt = []        \n        for i in oid.split(\".\"):\n            if \"-\" in i:\n                fmt.append(\"%i\")\n                self.cmpt.append(tuple(map(int, i.split(\"-\"))))\n            else:\n                fmt.append(i)\n        self.fmt = \".\".join(fmt)\n    def __repr__(self):\n        return \"OID(%r)\" % self.oid\n    def __iter__(self):        \n        ii = [k[0] for k in self.cmpt]\n        while 1:\n            yield self.fmt % tuple(ii)\n            i = 0\n            while 1:\n                if i >= len(ii):\n                    raise StopIteration\n                if ii[i] < self.cmpt[i][1]:\n                    ii[i]+=1\n                    break\n                else:\n                    ii[i] = self.cmpt[i][0]\n                i += 1\n\n\n \n######################################\n## Packet abstract and base classes ##\n######################################\n\nclass Packet_metaclass(type):\n    def __new__(cls, name, bases, dct):\n        if \"fields_desc\" in dct: # perform resolution of references to other packets\n            current_fld = dct[\"fields_desc\"]\n            resolved_fld = []\n            for f in current_fld:\n                if isinstance(f, Packet_metaclass): # reference to another fields_desc\n                    for f2 in f.fields_desc:\n                        resolved_fld.append(f2)\n                else:\n                    resolved_fld.append(f)\n        else: # look for a field_desc in parent classes\n            resolved_fld = None\n            for b in bases:\n                if hasattr(b,\"fields_desc\"):\n                    resolved_fld = b.fields_desc\n                    break\n\n        if resolved_fld: # perform default value replacements\n            final_fld = []\n            for f in resolved_fld:\n                if f.name in dct:\n                    f = f.copy()\n                    f.default = dct[f.name]\n                    del(dct[f.name])\n                final_fld.append(f)\n\n            dct[\"fields_desc\"] = final_fld\n\n        if \"__slots__\" not in dct:\n            dct[\"__slots__\"] = []\n        for attr in [\"name\", \"overload_fields\"]:\n            try:\n                dct[\"_%s\" % attr] = dct.pop(attr)\n            except KeyError:\n                pass\n        newcls = super(Packet_metaclass, cls).__new__(cls, name, bases, dct)\n        newcls.__all_slots__ = set(\n            attr\n            for cls in newcls.__mro__ if hasattr(cls, \"__slots__\")\n            for attr in cls.__slots__\n        )\n\n        if hasattr(newcls, \"aliastypes\"):\n            newcls.aliastypes = [newcls] + newcls.aliastypes\n        else:\n            newcls.aliastypes = [newcls]\n\n        if hasattr(newcls,\"register_variant\"):\n            newcls.register_variant()\n        for f in newcls.fields_desc:\n            if hasattr(f, \"register_owner\"):\n                f.register_owner(newcls)\n        from scapy import config\n        config.conf.layers.register(newcls)\n        return newcls\n\n    def __getattr__(self, attr):\n        for k in self.fields_desc:\n            if k.name == attr:\n                return k\n        raise AttributeError(attr)\n\n    def __call__(cls, *args, **kargs):\n        if \"dispatch_hook\" in cls.__dict__:\n            try:\n                cls = cls.dispatch_hook(*args, **kargs)\n            except:\n                from scapy import config\n                if config.conf.debug_dissector:\n                    raise\n                cls = config.conf.raw_layer\n        i = cls.__new__(cls, cls.__name__, cls.__bases__, cls.__dict__)\n        i.__init__(*args, **kargs)\n        return i\n\nclass Field_metaclass(type):\n    def __new__(cls, name, bases, dct):\n        if \"__slots__\" not in dct:\n            dct[\"__slots__\"] = []\n        newcls = super(Field_metaclass, cls).__new__(cls, name, bases, dct)\n        return newcls\n\nclass NewDefaultValues(Packet_metaclass):\n    \"\"\"NewDefaultValues is deprecated (not needed anymore)\n    \n    remove this:\n        __metaclass__ = NewDefaultValues\n    and it should still work.\n    \"\"\"    \n    def __new__(cls, name, bases, dct):\n        from scapy.error import log_loading\n        import traceback\n        try:\n            for tb in traceback.extract_stack()+[(\"??\",-1,None,\"\")]:\n                f,l,_,line = tb\n                if line.startswith(\"class\"):\n                    break\n        except:\n            f,l=\"??\",-1\n            raise\n        log_loading.warning(\"Deprecated (no more needed) use of NewDefaultValues  (%s l. %i).\" % (f,l))\n        \n        return super(NewDefaultValues, cls).__new__(cls, name, bases, dct)\n\nclass BasePacket(Gen):\n    __slots__ = []\n\n\n#############################\n## Packet list base class  ##\n#############################\n\nclass BasePacketList(object):\n    __slots__ = []\n", "idx": 1, "id": 9265, "msg": "Why is this needed ?", "proj": "secdev-scapy", "lang": "py"}
{"patch": "@@ -25,6 +25,8 @@ import (\n // Stress chaos is a chaos to generate plenty of stresses over a collection of pods.\n \n // +kubebuilder:object:root=true\n+// +kubebuilder:printcolumn:name=\"action\",type=string,JSONPath=`.spec.action`\n+// +kubebuilder:printcolumn:name=\"duration\",type=string,JSONPath=`.spec.duration`\n // +chaos-mesh:experiment\n \n // StressChaos is the Schema for the stresschaos API", "y": 1, "oldf": "// Copyright 2021 Chaos Mesh Authors.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n// http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n//\n\npackage v1alpha1\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/docker/go-units\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n)\n\n// Stress chaos is a chaos to generate plenty of stresses over a collection of pods.\n\n// +kubebuilder:object:root=true\n// +chaos-mesh:experiment\n\n// StressChaos is the Schema for the stresschaos API\ntype StressChaos struct {\n\tmetav1.TypeMeta   `json:\",inline\"`\n\tmetav1.ObjectMeta `json:\"metadata,omitempty\"`\n\n\t// Spec defines the behavior of a time chaos experiment\n\tSpec StressChaosSpec `json:\"spec\"`\n\n\t// +optional\n\t// Most recently observed status of the time chaos experiment\n\tStatus StressChaosStatus `json:\"status\"`\n}\n\nvar _ InnerObjectWithCustomStatus = (*StressChaos)(nil)\nvar _ InnerObjectWithSelector = (*StressChaos)(nil)\nvar _ InnerObject = (*StressChaos)(nil)\n\n// StressChaosSpec defines the desired state of StressChaos\ntype StressChaosSpec struct {\n\tContainerSelector `json:\",inline\"`\n\n\t// Stressors defines plenty of stressors supported to stress system components out.\n\t// You can use one or more of them to make up various kinds of stresses. At least\n\t// one of the stressors should be specified.\n\t// +optional\n\tStressors *Stressors `json:\"stressors,omitempty\"`\n\n\t// StressngStressors defines plenty of stressors just like `Stressors` except that it's an experimental\n\t// feature and more powerful. You can define stressors in `stress-ng` (see also `man stress-ng`) dialect,\n\t// however not all of the supported stressors are well tested. It maybe retired in later releases. You\n\t// should always use `Stressors` to define the stressors and use this only when you want more stressors\n\t// unsupported by `Stressors`. When both `StressngStressors` and `Stressors` are defined, `StressngStressors`\n\t// wins.\n\t// +optional\n\tStressngStressors string `json:\"stressngStressors,omitempty\"`\n\n\t// Duration represents the duration of the chaos action\n\t// +optional\n\tDuration *string `json:\"duration,omitempty\" webhook:\"Duration\"`\n}\n\n// StressChaosStatus defines the observed state of StressChaos\ntype StressChaosStatus struct {\n\tChaosStatus `json:\",inline\"`\n\t// Instances always specifies stressing instances\n\t// +optional\n\tInstances map[string]StressInstance `json:\"instances,omitempty\"`\n}\n\n// StressInstance is an instance generates stresses\ntype StressInstance struct {\n\t// UID is the instance identifier\n\t// +optional\n\tUID string `json:\"uid\"`\n\t// StartTime specifies when the instance starts\n\t// +optional\n\tStartTime *metav1.Time `json:\"startTime\"`\n}\n\n// Stressors defines plenty of stressors supported to stress system components out.\n// You can use one or more of them to make up various kinds of stresses\ntype Stressors struct {\n\t// MemoryStressor stresses virtual memory out\n\t// +optional\n\tMemoryStressor *MemoryStressor `json:\"memory,omitempty\"`\n\t// CPUStressor stresses CPU out\n\t// +optional\n\tCPUStressor *CPUStressor `json:\"cpu,omitempty\"`\n}\n\n// Normalize the stressors to comply with stress-ng\nfunc (in *Stressors) Normalize() (string, error) {\n\tstressors := \"\"\n\tif in.MemoryStressor != nil && in.MemoryStressor.Workers != 0 {\n\t\tstressors += fmt.Sprintf(\" --vm %d --vm-keep\", in.MemoryStressor.Workers)\n\t\tif len(in.MemoryStressor.Size) != 0 {\n\t\t\tif in.MemoryStressor.Size[len(in.MemoryStressor.Size)-1] != '%' {\n\t\t\t\tsize, err := units.FromHumanSize(string(in.MemoryStressor.Size))\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn \"\", err\n\t\t\t\t}\n\t\t\t\tstressors += fmt.Sprintf(\" --vm-bytes %d\", size)\n\t\t\t} else {\n\t\t\t\tstressors += fmt.Sprintf(\" --vm-bytes %s\",\n\t\t\t\t\tin.MemoryStressor.Size)\n\t\t\t}\n\t\t}\n\n\t\tif in.MemoryStressor.Options != nil {\n\t\t\tfor _, v := range in.MemoryStressor.Options {\n\t\t\t\tstressors += fmt.Sprintf(\" %v \", v)\n\t\t\t}\n\t\t}\n\t}\n\tif in.CPUStressor != nil && in.CPUStressor.Workers != 0 {\n\t\tstressors += fmt.Sprintf(\" --cpu %d\", in.CPUStressor.Workers)\n\t\tif in.CPUStressor.Load != nil {\n\t\t\tstressors += fmt.Sprintf(\" --cpu-load %d\",\n\t\t\t\t*in.CPUStressor.Load)\n\t\t}\n\n\t\tif in.CPUStressor.Options != nil {\n\t\t\tfor _, v := range in.CPUStressor.Options {\n\t\t\t\tstressors += fmt.Sprintf(\" %v \", v)\n\t\t\t}\n\t\t}\n\t}\n\treturn stressors, nil\n}\n\n// Stressor defines common configurations of a stressor\ntype Stressor struct {\n\t// Workers specifies N workers to apply the stressor.\n\t// Maximum 8192 workers can run by stress-ng\n\t// +kubebuilder:validation:Maximum=8192\n\tWorkers int `json:\"workers\"`\n}\n\n// MemoryStressor defines how to stress memory out\ntype MemoryStressor struct {\n\tStressor `json:\",inline\"`\n\n\t// Size specifies N bytes consumed per vm worker, default is the total available memory.\n\t// One can specify the size as % of total available memory or in units of B, KB/KiB,\n\t// MB/MiB, GB/GiB, TB/TiB.\n\t// +optional\n\tSize string `json:\"size,omitempty\" webhook:\"Bytes\"`\n\n\t// extend stress-ng options\n\t// +optional\n\tOptions []string `json:\"options,omitempty\"`\n}\n\n// CPUStressor defines how to stress CPU out\ntype CPUStressor struct {\n\tStressor `json:\",inline\"`\n\t// Load specifies P percent loading per CPU worker. 0 is effectively a sleep (no load) and 100\n\t// is full loading.\n\t// +optional\n\tLoad *int `json:\"load,omitempty\"`\n\n\t// extend stress-ng options\n\t// +optional\n\tOptions []string `json:\"options,omitempty\"`\n}\n\nfunc (obj *StressChaos) GetSelectorSpecs() map[string]interface{} {\n\treturn map[string]interface{}{\n\t\t\".\": &obj.Spec.ContainerSelector,\n\t}\n}\n\nfunc (obj *StressChaos) GetCustomStatus() interface{} {\n\treturn &obj.Status.Instances\n}\n", "idx": 1, "id": 25451, "msg": "`StressChaos` does not contains a field .spec.action", "proj": "chaos-mesh-chaos-mesh", "lang": "go"}
{"patch": "@@ -18,6 +18,9 @@ public abstract class InsulinOrefBasePlugin implements PluginBase, InsulinInterf\n \n     public static double MIN_DIA = 5;\n \n+    protected static boolean fragmentEnabled = false;\n+    protected static boolean fragmentVisible = false;\n+\n     long lastWarned = 0;\n \n     @Override", "y": 1, "oldf": "package info.nightscout.androidaps.plugins.InsulinOrefCurves;\n\nimport info.nightscout.androidaps.Constants;\nimport info.nightscout.androidaps.MainApp;\nimport info.nightscout.androidaps.R;\nimport info.nightscout.androidaps.data.Iob;\nimport info.nightscout.androidaps.db.Treatment;\nimport info.nightscout.androidaps.interfaces.InsulinInterface;\nimport info.nightscout.androidaps.interfaces.PluginBase;\nimport info.nightscout.androidaps.plugins.Overview.Notification;\nimport info.nightscout.androidaps.plugins.Overview.events.EventNewNotification;\n\n/**\n * Created by adrian on 13.08.2017.\n */\n\npublic abstract class InsulinOrefBasePlugin implements PluginBase, InsulinInterface {\n\n    public static double MIN_DIA = 5;\n\n    long lastWarned = 0;\n\n    @Override\n    public int getType() {\n        return INSULIN;\n    }\n\n    @Override\n    public String getNameShort() {\n        return MainApp.sResources.getString(R.string.insulin_shortname);\n    }\n\n    @Override\n    public boolean canBeHidden(int type) {\n        return true;\n    }\n\n    @Override\n    public boolean hasFragment() {\n        return true;\n    }\n\n    @Override\n    public boolean showInList(int type) {\n        return true;\n    }\n\n    @Override\n    public double getDia() {\n        double dia = getUserDefinedDia();\n        if(dia >= MIN_DIA){\n            return dia;\n        } else {\n            if((System.currentTimeMillis() - lastWarned) > 60*1000) {\n                lastWarned = System.currentTimeMillis();\n                Notification notification = new Notification(Notification.SHORT_DIA, String.format(MainApp.sResources.getString(R.string.dia_too_short), dia, MIN_DIA), Notification.URGENT);\n                MainApp.bus().post(new EventNewNotification(notification));\n            }\n            return MIN_DIA;\n        }\n    }\n\n    public double getUserDefinedDia() {\n        return MainApp.getConfigBuilder().getProfile() != null ? MainApp.getConfigBuilder().getProfile().getDia() : Constants.defaultDIA;\n    }\n\n    @Override\n    public Iob iobCalcForTreatment(Treatment treatment, long time, Double dia) {\n        Iob result = new Iob();\n\n        int peak = getPeak();\n\n\n        if (treatment.insulin != 0d) {\n\n            long bolusTime = treatment.date;\n            double t = (time - bolusTime) / 1000d / 60d;\n\n            double td = getDia()*60; //getDIA() always > 5\n            double tp = peak;\n\n            // force the IOB to 0 if over DIA hours have passed\n            if (t < td) {\n                double tau = tp * (1 - tp / td) / (1 - 2 * tp / td);\n                double a = 2 * tau / td;\n                double S = 1 / (1 - a + (1 + a) * Math.exp(-td / tau));\n                result.activityContrib = treatment.insulin * (S / Math.pow(tau, 2)) * t * (1 - t / td) * Math.exp(-t / tau);\n                result.iobContrib = treatment.insulin * (1 - S * (1 - a) * ((Math.pow(t, 2) / (tau * td * (1 - a)) - t / tau - 1) * Math.exp(-t / tau) + 1));\n            }\n        }\n        return result;\n    }\n\n    @Override\n    public String getComment() {\n        String comment =  commentStandardText();\n        double userDia = getUserDefinedDia();\n        if(userDia < MIN_DIA){\n            comment += \"\\n\" + String.format(MainApp.sResources.getString(R.string.dia_too_short), userDia, MIN_DIA);\n        }\n        return comment;\n    }\n\n    abstract int getPeak();\n\n    abstract String commentStandardText();\n\n}\n", "idx": 1, "id": 29535, "msg": "Shouldn't this be in the child and not in the base plugin? Wouldn't having it here enable all derived plugins at once?", "proj": "MilosKozak-AndroidAPS", "lang": "java"}
{"patch": "@@ -19,6 +19,14 @@ class Product < ActiveRecord::Base\n     where product_type: 'book'\n   end\n \n+  def self.workshops\n+    where product_type: 'workshop'\n+  end\n+\n+  def self.videos\n+    where product_type: 'video'\n+  end\n+\n   def self.ordered\n     order(\"name asc\")\n   end", "y": 1, "oldf": "class Product < ActiveRecord::Base\n  has_many :purchases\n  has_many :downloads\n  has_many :classifications, as: :classifiable\n  has_many :topics, through: :classifications\n  has_many :videos\n\n  validates_presence_of :name, :sku, :individual_price, :company_price, :fulfillment_method\n  accepts_nested_attributes_for :downloads, :allow_destroy => true\n  has_attached_file :product_image, {\n    styles: { book: '230x300#', video: '153x100#' }\n  }.merge(PAPERCLIP_STORAGE_OPTIONS)\n\n  def self.active\n    where(active: true)\n  end\n\n  def self.books\n    where product_type: 'book'\n  end\n\n  def self.ordered\n    order(\"name asc\")\n  end\n\n  def self.promoted(location)\n    where(promo_location: location).first\n  end\n\n  def to_param\n    \"#{id}-#{name.parameterize}\"\n  end\n\n  def product_type_symbol\n    self.product_type.split(\" \")[0].downcase.to_sym\n  rescue\n    \"book\"\n  end\n\n  def image_url\n    raw_url = self.product_image.url(product_type_symbol)\n    product_image_file_name.nil? ? \"/assets/#{raw_url}\" : raw_url\n  end\n\n  def external?\n    fulfillment_method == 'external'\n  end\n\n  def self.videos\n    where product_type: 'video'\n  end\nend\n", "idx": 1, "id": 6564, "msg": "Any other possible names? Feels like going with \"workshop\" for this product_type could increase the confusion between course/workshop in the codebase.", "proj": "thoughtbot-upcase", "lang": "rb"}
{"patch": "@@ -113,7 +113,7 @@ func (i *interpreter) interpretStatements(s *scope, statements []*Statement) (re\n \t\t\t} else {\n \t\t\t\terr = fmt.Errorf(\"%s\", r)\n \t\t\t}\n-\t\t\tlog.Debug(\"%s\", debug.Stack())\n+\t\t\tlog.Debug(\"%v:\\n %s\", err,  debug.Stack())\n \t\t}\n \t}()\n \treturn s.interpretStatements(statements), nil // Would have panicked if there was an error", "y": 1, "oldf": "package asp\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"reflect\"\n\t\"runtime/debug\"\n\t\"runtime/pprof\"\n\t\"strings\"\n\t\"sync\"\n\n\t\"github.com/thought-machine/please/src/core\"\n\t\"github.com/thought-machine/please/src/fs\"\n)\n\n// An interpreter holds the package-independent state about our parsing process.\ntype interpreter struct {\n\tscope           *scope\n\tparser          *Parser\n\tsubincludes     map[string]pyDict\n\tconfig          map[*core.Configuration]*pyConfig\n\tmutex           sync.RWMutex\n\tconfigMutex     sync.RWMutex\n\tbreakpointMutex sync.Mutex\n\tlimiter         semaphore\n\tprofiling       bool\n}\n\n// newInterpreter creates and returns a new interpreter instance.\n// It loads all the builtin rules at this point.\nfunc newInterpreter(state *core.BuildState, p *Parser) *interpreter {\n\ts := &scope{\n\t\tctx:    context.Background(),\n\t\tstate:  state,\n\t\tlocals: map[string]pyObject{},\n\t}\n\ti := &interpreter{\n\t\tscope:       s,\n\t\tparser:      p,\n\t\tsubincludes: map[string]pyDict{},\n\t\tconfig:      map[*core.Configuration]*pyConfig{},\n\t\tlimiter:     make(semaphore, state.Config.Parse.NumThreads),\n\t\tprofiling:   state.Config.Profiling,\n\t}\n\ts.interpreter = i\n\ts.LoadSingletons(state)\n\treturn i\n}\n\n// LoadBuiltins loads a set of builtins from a file, optionally with its contents.\nfunc (i *interpreter) LoadBuiltins(filename string, contents []byte, statements []*Statement) error {\n\ts := i.scope.NewScope()\n\t// Gentle hack - attach the native code once we have loaded the correct file.\n\t// Needs to be after this file is loaded but before any of the others that will\n\t// use functions from it.\n\tif filename == \"builtins.build_defs\" {\n\t\tdefer registerBuiltins(s)\n\t} else if filename == \"misc_rules.build_defs\" {\n\t\tdefer registerSubincludePackage(s)\n\t} else if filename == \"config_rules.build_defs\" {\n\t\tdefer setNativeCode(s, \"select\", selectFunc)\n\t}\n\tdefer i.scope.SetAll(s.Freeze(), true)\n\tif statements != nil {\n\t\t_, err := i.interpretStatements(s, statements)\n\t\treturn err\n\t} else if len(contents) != 0 {\n\t\tstmts, err := i.parser.ParseData(contents, filename)\n\t\tfor _, stmt := range stmts {\n\t\t\tif stmt.FuncDef != nil {\n\t\t\t\tstmt.FuncDef.KeywordsOnly = !whitelistedKwargs(stmt.FuncDef.Name, filename)\n\t\t\t\tstmt.FuncDef.IsBuiltin = true\n\t\t\t}\n\t\t}\n\t\treturn i.loadBuiltinStatements(s, stmts, err)\n\t}\n\tstmts, err := i.parser.parse(filename)\n\treturn i.loadBuiltinStatements(s, stmts, err)\n}\n\n// loadBuiltinStatements loads statements as builtins.\nfunc (i *interpreter) loadBuiltinStatements(s *scope, statements []*Statement, err error) error {\n\tif err != nil {\n\t\treturn err\n\t}\n\ti.optimiseExpressions(statements)\n\t_, err = i.interpretStatements(s, i.parser.optimise(statements))\n\treturn err\n}\n\n// interpretAll runs a series of statements in the context of the given package.\n// The first return value is for testing only.\nfunc (i *interpreter) interpretAll(pkg *core.Package, statements []*Statement) (s *scope, err error) {\n\ts = i.scope.NewPackagedScope(pkg, 1)\n\t// Config needs a little separate tweaking.\n\t// Annoyingly we'd like to not have to do this at all, but it's very hard to handle\n\t// mutating operations like .setdefault() otherwise.\n\ts.config = i.pkgConfig(pkg).Copy()\n\ts.Set(\"CONFIG\", s.config)\n\t_, err = i.interpretStatements(s, statements)\n\tif err == nil {\n\t\ts.Callback = true // From here on, if anything else uses this scope, it's in a post-build callback.\n\t}\n\treturn s, err\n}\n\n// interpretStatements runs a series of statements in the context of the given scope.\nfunc (i *interpreter) interpretStatements(s *scope, statements []*Statement) (ret pyObject, err error) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tif e, ok := r.(error); ok {\n\t\t\t\terr = e\n\t\t\t} else {\n\t\t\t\terr = fmt.Errorf(\"%s\", r)\n\t\t\t}\n\t\t\tlog.Debug(\"%s\", debug.Stack())\n\t\t}\n\t}()\n\treturn s.interpretStatements(statements), nil // Would have panicked if there was an error\n}\n\n// Subinclude returns the global values corresponding to subincluding the given file.\nfunc (i *interpreter) Subinclude(path string, label core.BuildLabel, pkg *core.Package) pyDict {\n\ti.mutex.RLock()\n\tglobals, present := i.subincludes[path]\n\ti.mutex.RUnlock()\n\tif present {\n\t\treturn globals\n\t}\n\t// If we get here, it's not been subincluded already. Parse it now.\n\t// Note that there is a race here whereby it's possible for two packages to parse the same\n\t// subinclude simultaneously - this doesn't matter since they'll get different but equivalent\n\t// scopes, and sooner or later things will sort themselves out.\n\tstmts, err := i.parser.parse(path)\n\tif err != nil {\n\t\tpanic(err) // We're already inside another interpreter, which will handle this for us.\n\t}\n\tstmts = i.parser.optimise(stmts)\n\ts := i.scope.NewScope()\n\ts.contextPkg = pkg\n\ts.subincludeLabel = &label\n\t// Scope needs a local version of CONFIG\n\ts.config = i.scope.config.Copy()\n\ts.Set(\"CONFIG\", s.config)\n\ti.optimiseExpressions(stmts)\n\ts.interpretStatements(stmts)\n\tlocals := s.Freeze()\n\tif s.config.overlay == nil {\n\t\tdelete(locals, \"CONFIG\") // Config doesn't have any local modifications\n\t}\n\ti.mutex.Lock()\n\tdefer i.mutex.Unlock()\n\ti.subincludes[path] = locals\n\treturn s.locals\n}\n\n// getConfig returns a new configuration object for the given configuration object.\nfunc (i *interpreter) getConfig(state *core.BuildState) *pyConfig {\n\ti.configMutex.RLock()\n\tif c, present := i.config[state.Config]; present {\n\t\ti.configMutex.RUnlock()\n\t\treturn c\n\t}\n\ti.configMutex.RUnlock()\n\ti.configMutex.Lock()\n\tdefer i.configMutex.Unlock()\n\tc := newConfig(state)\n\ti.config[state.Config] = c\n\treturn c\n}\n\n// pkgConfig returns a new configuration object for the given package.\nfunc (i *interpreter) pkgConfig(pkg *core.Package) *pyConfig {\n\tif pkg.Subrepo != nil && pkg.Subrepo.State != nil {\n\t\treturn i.getConfig(pkg.Subrepo.State)\n\t}\n\treturn i.getConfig(i.scope.state)\n}\n\n// optimiseExpressions implements a peephole optimiser for expressions by precalculating constants\n// and identifying simple local variable lookups.\nfunc (i *interpreter) optimiseExpressions(stmts []*Statement) {\n\tWalkAST(stmts, func(expr *Expression) bool {\n\t\tif constant := i.scope.Constant(expr); constant != nil {\n\t\t\texpr.Optimised = &OptimisedExpression{Constant: constant} // Extract constant expression\n\t\t\texpr.Val = nil\n\t\t\treturn false\n\t\t} else if expr.Val != nil && expr.Val.Ident != nil && expr.Val.Call == nil && expr.Op == nil && expr.If == nil && len(expr.Val.Slices) == 0 {\n\t\t\tif expr.Val.Property == nil && len(expr.Val.Ident.Action) == 0 {\n\t\t\t\texpr.Optimised = &OptimisedExpression{Local: expr.Val.Ident.Name}\n\t\t\t\treturn false\n\t\t\t} else if expr.Val.Ident.Name == \"CONFIG\" && len(expr.Val.Ident.Action) == 1 && expr.Val.Ident.Action[0].Property != nil && len(expr.Val.Ident.Action[0].Property.Action) == 0 {\n\t\t\t\texpr.Optimised = &OptimisedExpression{Config: expr.Val.Ident.Action[0].Property.Name}\n\t\t\t\texpr.Val = nil\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t\treturn true\n\t})\n}\n\n// A scope contains all the information about a lexical scope.\ntype scope struct {\n\tctx         context.Context\n\tinterpreter *interpreter\n\tstate       *core.BuildState\n\tpkg         *core.Package\n\tparent      *scope\n\tlocals      pyDict\n\tconfig      *pyConfig\n\tglobber     *fs.Globber\n\t// True if this scope is for a pre- or post-build callback.\n\tCallback bool\n\n\t// used during subincludes\n\tcontextPkg *core.Package\n\t// The label that was passed to subinclude(...)\n\tsubincludeLabel *core.BuildLabel\n}\n\n// NewScope creates a new child scope of this one.\nfunc (s *scope) NewScope() *scope {\n\treturn s.NewPackagedScope(s.pkg, 0)\n}\n\n// NewPackagedScope creates a new child scope of this one pointing to the given package.\n// hint is a size hint for the new set of locals.\nfunc (s *scope) NewPackagedScope(pkg *core.Package, hint int) *scope {\n\ts2 := &scope{\n\t\tctx:         s.ctx,\n\t\tinterpreter: s.interpreter,\n\t\tstate:       s.state,\n\t\tpkg:         pkg,\n\t\tcontextPkg:  pkg,\n\t\tparent:      s,\n\t\tlocals:      make(pyDict, hint),\n\t\tconfig:      s.config,\n\t\tCallback:    s.Callback,\n\t}\n\tif pkg != nil && pkg.Subrepo != nil && pkg.Subrepo.State != nil {\n\t\ts2.state = pkg.Subrepo.State\n\t}\n\treturn s2\n}\n\n// Error emits an error that stops further interpretation.\n// For convenience it is declared to return a pyObject but it never actually returns.\nfunc (s *scope) Error(msg string, args ...interface{}) pyObject {\n\tpanic(fmt.Errorf(msg, args...))\n}\n\n// Assert emits an error that stops further interpretation if the given condition is false.\nfunc (s *scope) Assert(condition bool, msg string, args ...interface{}) {\n\tif !condition {\n\t\ts.Error(msg, args...)\n\t}\n}\n\n// NAssert is the inverse of Assert, it emits an error if the given condition is true.\nfunc (s *scope) NAssert(condition bool, msg string, args ...interface{}) {\n\tif condition {\n\t\ts.Error(msg, args...)\n\t}\n}\n\n// Lookup looks up a variable name in this scope, walking back up its ancestor scopes as needed.\n// It panics if the variable is not defined.\nfunc (s *scope) Lookup(name string) pyObject {\n\tif obj, present := s.locals[name]; present {\n\t\treturn obj\n\t} else if s.parent != nil {\n\t\treturn s.parent.Lookup(name)\n\t}\n\treturn s.Error(\"name '%s' is not defined\", name)\n}\n\n// LocalLookup looks up a variable name in the current scope.\n// It does *not* walk back up parent scopes and instead returns nil if the variable could not be found.\n// This is typically used for things like function arguments where we're only interested in variables\n// in immediate scope.\nfunc (s *scope) LocalLookup(name string) pyObject {\n\treturn s.locals[name]\n}\n\n// Set sets the given variable in this scope.\nfunc (s *scope) Set(name string, value pyObject) {\n\ts.locals[name] = value\n}\n\n// SetAll sets all contents of the given dict in this scope.\n// Optionally it can filter to just public objects (i.e. those not prefixed with an underscore)\nfunc (s *scope) SetAll(d pyDict, publicOnly bool) {\n\tfor k, v := range d {\n\t\tif k == \"CONFIG\" {\n\t\t\t// Special case; need to merge config entries rather than overwriting the entire object.\n\t\t\tc, ok := v.(*pyFrozenConfig)\n\t\t\ts.Assert(ok, \"incoming CONFIG isn't a config object\")\n\t\t\ts.config.Merge(c)\n\t\t} else if !publicOnly || k[0] != '_' {\n\t\t\ts.locals[k] = v\n\t\t}\n\t}\n}\n\n// Freeze freezes the contents of this scope, preventing mutable objects from being changed.\n// It returns the newly frozen set of locals.\nfunc (s *scope) Freeze() pyDict {\n\tfor k, v := range s.locals {\n\t\tif f, ok := v.(freezable); ok {\n\t\t\ts.locals[k] = f.Freeze()\n\t\t}\n\t}\n\treturn s.locals\n}\n\n// LoadSingletons loads the global builtin singletons into this scope.\nfunc (s *scope) LoadSingletons(state *core.BuildState) {\n\ts.Set(\"True\", True)\n\ts.Set(\"False\", False)\n\ts.Set(\"None\", None)\n\tif state != nil {\n\t\ts.config = s.interpreter.getConfig(state)\n\t\ts.Set(\"CONFIG\", s.config)\n\t}\n}\n\n// interpretStatements interprets a series of statements in a particular scope.\n// Note that the return value is only non-nil if a return statement is encountered;\n// it is not implicitly the result of the last statement or anything like that.\nfunc (s *scope) interpretStatements(statements []*Statement) pyObject {\n\tvar stmt *Statement\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tpanic(AddStackFrame(stmt.Pos, r))\n\t\t}\n\t}()\n\tfor _, stmt = range statements {\n\t\tif stmt.FuncDef != nil {\n\t\t\ts.Set(stmt.FuncDef.Name, newPyFunc(s, stmt.FuncDef))\n\t\t} else if stmt.If != nil {\n\t\t\tif ret := s.interpretIf(stmt.If); ret != nil {\n\t\t\t\treturn ret\n\t\t\t}\n\t\t} else if stmt.For != nil {\n\t\t\tif ret := s.interpretFor(stmt.For); ret != nil {\n\t\t\t\treturn ret\n\t\t\t}\n\t\t} else if stmt.Return != nil {\n\t\t\tif len(stmt.Return.Values) == 0 {\n\t\t\t\treturn None\n\t\t\t} else if len(stmt.Return.Values) == 1 {\n\t\t\t\treturn s.interpretExpression(stmt.Return.Values[0])\n\t\t\t}\n\t\t\treturn pyList(s.evaluateExpressions(stmt.Return.Values))\n\t\t} else if stmt.Ident != nil {\n\t\t\ts.interpretIdentStatement(stmt.Ident)\n\t\t} else if stmt.Assert != nil {\n\t\t\tif !s.interpretExpression(stmt.Assert.Expr).IsTruthy() {\n\t\t\t\tif stmt.Assert.Message == nil {\n\t\t\t\t\ts.Error(\"assertion failed\")\n\t\t\t\t} else {\n\t\t\t\t\ts.Error(s.interpretExpression(stmt.Assert.Message).String())\n\t\t\t\t}\n\t\t\t}\n\t\t} else if stmt.Raise != nil {\n\t\t\tlog.Warning(\"The raise keyword is deprecated, please use fail() instead. See https://github.com/thought-machine/please/issues/1598 for more information.\")\n\t\t\ts.Error(s.interpretExpression(stmt.Raise).String())\n\t\t} else if stmt.Literal != nil {\n\t\t\ts.interpretExpression(stmt.Literal)\n\t\t} else if stmt.Continue {\n\t\t\t// This is definitely awkward since we need to control a for loop that's happening in a function outside this scope.\n\t\t\treturn continueIteration\n\t\t} else if stmt.Pass {\n\t\t\tcontinue // Nothing to do...\n\t\t} else {\n\t\t\ts.Error(\"Unknown statement\") // Shouldn't happen, amirite?\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (s *scope) interpretIf(stmt *IfStatement) pyObject {\n\tif s.interpretExpression(&stmt.Condition).IsTruthy() {\n\t\treturn s.interpretStatements(stmt.Statements)\n\t}\n\tfor _, elif := range stmt.Elif {\n\t\tif s.interpretExpression(&elif.Condition).IsTruthy() {\n\t\t\treturn s.interpretStatements(elif.Statements)\n\t\t}\n\t}\n\treturn s.interpretStatements(stmt.ElseStatements)\n}\n\nfunc (s *scope) interpretFor(stmt *ForStatement) pyObject {\n\tfor _, li := range s.iterate(&stmt.Expr) {\n\t\ts.unpackNames(stmt.Names, li)\n\t\tif ret := s.interpretStatements(stmt.Statements); ret != nil {\n\t\t\tif s, ok := ret.(pySentinel); ok && s == continueIteration {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn ret\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (s *scope) interpretExpression(expr *Expression) pyObject {\n\t// Check the optimised sites first\n\tif expr.Optimised != nil {\n\t\tif expr.Optimised.Constant != nil {\n\t\t\treturn expr.Optimised.Constant\n\t\t} else if expr.Optimised.Local != \"\" {\n\t\t\treturn s.Lookup(expr.Optimised.Local)\n\t\t}\n\t\treturn s.config.Property(expr.Optimised.Config)\n\t}\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tpanic(AddStackFrame(expr.Pos, r))\n\t\t}\n\t}()\n\tif expr.If != nil && !s.interpretExpression(expr.If.Condition).IsTruthy() {\n\t\treturn s.interpretExpression(expr.If.Else)\n\t}\n\tvar obj pyObject\n\tif expr.Val != nil {\n\t\tobj = s.interpretValueExpression(expr.Val)\n\t} else if expr.UnaryOp != nil {\n\t\tobj = s.interpretValueExpression(&expr.UnaryOp.Expr)\n\t\tif expr.UnaryOp.Op == \"not\" {\n\t\t\tobj = s.negate(obj)\n\t\t} else {\n\t\t\ti, ok := obj.(pyInt)\n\t\t\ts.Assert(ok, \"Unary - can only be applied to an integer\")\n\t\t\tobj = pyInt(-int(i))\n\t\t}\n\t}\n\tfor _, op := range expr.Op {\n\t\tswitch op.Op {\n\t\tcase And, Or:\n\t\t\t// Careful here to mimic lazy-evaluation semantics (import for `x = x or []` etc)\n\t\t\tif obj.IsTruthy() == (op.Op == And) {\n\t\t\t\tobj = s.interpretExpression(op.Expr)\n\t\t\t}\n\t\tcase Equal:\n\t\t\tobj = newPyBool(reflect.DeepEqual(obj, s.interpretExpression(op.Expr)))\n\t\tcase NotEqual:\n\t\t\tobj = newPyBool(!reflect.DeepEqual(obj, s.interpretExpression(op.Expr)))\n\t\tcase Is:\n\t\t\tobj = s.interpretIs(obj, op)\n\t\tcase IsNot:\n\t\t\tobj = s.negate(s.interpretIs(obj, op))\n\t\tcase In, NotIn:\n\t\t\t// the implementation of in is defined by the right-hand side, not the left.\n\t\t\tobj = s.interpretExpression(op.Expr).Operator(op.Op, obj)\n\t\tdefault:\n\t\t\tobj = obj.Operator(op.Op, s.interpretExpression(op.Expr))\n\t\t}\n\t}\n\treturn obj\n}\n\nfunc (s *scope) interpretIs(obj pyObject, op OpExpression) pyObject {\n\t// Is only works None or boolean types.\n\texpr := s.interpretExpression(op.Expr)\n\tswitch tobj := obj.(type) {\n\tcase pyNone:\n\t\t_, ok := expr.(pyNone)\n\t\treturn newPyBool(ok)\n\tcase pyBool:\n\t\tb, ok := expr.(pyBool)\n\t\treturn newPyBool(ok && b == tobj)\n\tdefault:\n\t\treturn newPyBool(false)\n\t}\n}\n\nfunc (s *scope) negate(obj pyObject) pyBool {\n\tif obj.IsTruthy() {\n\t\treturn False\n\t}\n\treturn True\n}\n\nfunc (s *scope) interpretValueExpression(expr *ValueExpression) pyObject {\n\tobj := s.interpretValueExpressionPart(expr)\n\tfor _, sl := range expr.Slices {\n\t\tif sl.Colon == \"\" {\n\t\t\t// Indexing, much simpler...\n\t\t\ts.Assert(sl.End == nil, \"Invalid syntax\")\n\t\t\tobj = obj.Operator(Index, s.interpretExpression(sl.Start))\n\t\t} else {\n\t\t\tobj = s.interpretSlice(obj, sl)\n\t\t}\n\t}\n\tif expr.Property != nil {\n\t\tobj = s.interpretIdent(obj.Property(expr.Property.Name), expr.Property)\n\t} else if expr.Call != nil {\n\t\tobj = s.callObject(\"\", obj, expr.Call)\n\t}\n\treturn obj\n}\n\nfunc (s *scope) interpretValueExpressionPart(expr *ValueExpression) pyObject {\n\tif expr.Ident != nil {\n\t\tobj := s.Lookup(expr.Ident.Name)\n\t\tif len(expr.Ident.Action) == 0 {\n\t\t\treturn obj // fast path\n\t\t}\n\t\treturn s.interpretIdent(obj, expr.Ident)\n\t} else if expr.String != \"\" {\n\t\t// Strings are surrounded by quotes to make it easier for the parser; here they come off again.\n\t\treturn pyString(stringLiteral(expr.String))\n\t} else if expr.FString != nil {\n\t\treturn s.interpretFString(expr.FString)\n\t} else if expr.IsInt {\n\t\treturn pyInt(expr.Int)\n\t} else if expr.True {\n\t\treturn True\n\t} else if expr.False {\n\t\treturn False\n\t} else if expr.None {\n\t\treturn None\n\t} else if expr.List != nil {\n\t\treturn s.interpretList(expr.List)\n\t} else if expr.Dict != nil {\n\t\treturn s.interpretDict(expr.Dict)\n\t} else if expr.Tuple != nil {\n\t\t// Parentheses can also indicate precedence; a single parenthesised expression does not create a list object.\n\t\tl := s.interpretList(expr.Tuple)\n\t\tif len(l) == 1 && expr.Tuple.Comprehension == nil {\n\t\t\treturn l[0]\n\t\t}\n\t\treturn l\n\t} else if expr.Lambda != nil {\n\t\t// A lambda is just an inline function definition with a single return statement.\n\t\tstmt := &Statement{}\n\t\tstmt.Return = &ReturnStatement{\n\t\t\tValues: []*Expression{&expr.Lambda.Expr},\n\t\t}\n\t\treturn newPyFunc(s, &FuncDef{\n\t\t\tName:       \"<lambda>\",\n\t\t\tArguments:  expr.Lambda.Arguments,\n\t\t\tStatements: []*Statement{stmt},\n\t\t})\n\t}\n\treturn None\n}\n\nfunc (s *scope) interpretFString(f *FString) pyObject {\n\tstringVar := func(v FStringVar) string {\n\t\tif v.Config != \"\" {\n\t\t\treturn s.config.MustGet(v.Config).String()\n\t\t}\n\t\treturn s.Lookup(v.Var).String()\n\t}\n\tvar b strings.Builder\n\tsize := len(f.Suffix)\n\tfor _, v := range f.Vars {\n\t\tsize += len(v.Prefix) + len(stringVar(v))\n\t}\n\tb.Grow(size)\n\tfor _, v := range f.Vars {\n\t\tb.WriteString(v.Prefix)\n\t\tb.WriteString(stringVar(v))\n\t}\n\tb.WriteString(f.Suffix)\n\treturn pyString(b.String())\n}\n\nfunc (s *scope) interpretSlice(obj pyObject, sl *Slice) pyObject {\n\tstart := s.interpretSliceExpression(obj, sl.Start, 0)\n\tswitch t := obj.(type) {\n\tcase pyList:\n\t\tend := s.interpretSliceExpression(obj, sl.End, pyInt(len(t)))\n\t\treturn t[start:end]\n\tcase pyString:\n\t\tend := s.interpretSliceExpression(obj, sl.End, pyInt(len(t)))\n\t\treturn t[start:end]\n\t}\n\ts.Error(\"Unsliceable type %s\", obj.Type())\n\treturn nil\n}\n\n// interpretSliceExpression interprets one of the begin or end parts of a slice.\n// expr may be null, if it is the value of def is used instead.\nfunc (s *scope) interpretSliceExpression(obj pyObject, expr *Expression, def pyInt) pyInt {\n\tif expr == nil {\n\t\treturn def\n\t}\n\treturn pyIndex(obj, s.interpretExpression(expr), true)\n}\n\nfunc (s *scope) interpretIdent(obj pyObject, expr *IdentExpr) pyObject {\n\tname := expr.Name\n\tfor _, action := range expr.Action {\n\t\tif action.Property != nil {\n\t\t\tname = action.Property.Name\n\t\t\tobj = s.interpretIdent(obj.Property(name), action.Property)\n\t\t} else if action.Call != nil {\n\t\t\tobj = s.callObject(name, obj, action.Call)\n\t\t}\n\t}\n\treturn obj\n}\n\nfunc (s *scope) interpretIdentStatement(stmt *IdentStatement) pyObject {\n\tif stmt.Index != nil {\n\t\t// Need to special-case these, because types are immutable so we can't return a modifiable reference to them.\n\t\tobj := s.Lookup(stmt.Name)\n\t\tidx := s.interpretExpression(stmt.Index.Expr)\n\t\tif stmt.Index.Assign != nil {\n\t\t\tobj.IndexAssign(idx, s.interpretExpression(stmt.Index.Assign))\n\t\t} else {\n\t\t\tobj.IndexAssign(idx, obj.Operator(Index, idx).Operator(Add, s.interpretExpression(stmt.Index.AugAssign)))\n\t\t}\n\t} else if stmt.Unpack != nil {\n\t\tobj := s.interpretExpression(stmt.Unpack.Expr)\n\t\tl, ok := obj.(pyList)\n\t\ts.Assert(ok, \"Cannot unpack type %s\", l.Type())\n\t\t// This is a little awkward because the first item here is the name of the ident node.\n\t\ts.Assert(len(l) == len(stmt.Unpack.Names)+1, \"Wrong number of items to unpack; expected %d, got %d\", len(stmt.Unpack.Names)+1, len(l))\n\t\ts.Set(stmt.Name, l[0])\n\t\tfor i, name := range stmt.Unpack.Names {\n\t\t\ts.Set(name, l[i+1])\n\t\t}\n\t} else if stmt.Action != nil {\n\t\tif stmt.Action.Property != nil {\n\t\t\treturn s.interpretIdent(s.Lookup(stmt.Name).Property(stmt.Action.Property.Name), stmt.Action.Property)\n\t\t} else if stmt.Action.Call != nil {\n\t\t\treturn s.callObject(stmt.Name, s.Lookup(stmt.Name), stmt.Action.Call)\n\t\t} else if stmt.Action.Assign != nil {\n\t\t\ts.Set(stmt.Name, s.interpretExpression(stmt.Action.Assign))\n\t\t} else if stmt.Action.AugAssign != nil {\n\t\t\t// The only augmented assignment operation we support is +=, and it's implemented\n\t\t\t// exactly as x += y -> x = x + y since that matches the semantics of Go types.\n\t\t\ts.Set(stmt.Name, s.Lookup(stmt.Name).Operator(Add, s.interpretExpression(stmt.Action.AugAssign)))\n\t\t}\n\t} else {\n\t\treturn s.Lookup(stmt.Name)\n\t}\n\treturn nil\n}\n\nfunc (s *scope) interpretList(expr *List) pyList {\n\tif expr.Comprehension == nil {\n\t\treturn pyList(s.evaluateExpressions(expr.Values))\n\t}\n\tcs := s.NewScope()\n\tl := s.iterate(expr.Comprehension.Expr)\n\tret := make(pyList, 0, len(l))\n\tcs.evaluateComprehension(l, expr.Comprehension, func(li pyObject) {\n\t\tif len(expr.Values) == 1 {\n\t\t\tret = append(ret, cs.interpretExpression(expr.Values[0]))\n\t\t} else {\n\t\t\tret = append(ret, pyList(cs.evaluateExpressions(expr.Values)))\n\t\t}\n\t})\n\treturn ret\n}\n\nfunc (s *scope) interpretDict(expr *Dict) pyObject {\n\tif expr.Comprehension == nil {\n\t\td := make(pyDict, len(expr.Items))\n\t\tfor _, v := range expr.Items {\n\t\t\td.IndexAssign(s.interpretExpression(&v.Key), s.interpretExpression(&v.Value))\n\t\t}\n\t\treturn d\n\t}\n\tcs := s.NewScope()\n\tl := cs.iterate(expr.Comprehension.Expr)\n\tret := make(pyDict, len(l))\n\tcs.evaluateComprehension(l, expr.Comprehension, func(li pyObject) {\n\t\tret.IndexAssign(cs.interpretExpression(&expr.Items[0].Key), cs.interpretExpression(&expr.Items[0].Value))\n\t})\n\treturn ret\n}\n\n// evaluateComprehension handles iterating a comprehension's loops.\n// The provided callback function is called with each item to be added to the result.\nfunc (s *scope) evaluateComprehension(l pyList, comp *Comprehension, callback func(pyObject)) {\n\tif comp.Second != nil {\n\t\tfor _, li := range l {\n\t\t\ts.unpackNames(comp.Names, li)\n\t\t\tfor _, li := range s.iterate(comp.Second.Expr) {\n\t\t\t\tif s.evaluateComprehensionExpression(comp, comp.Second.Names, li) {\n\t\t\t\t\tcallback(li)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else {\n\t\tfor _, li := range l {\n\t\t\tif s.evaluateComprehensionExpression(comp, comp.Names, li) {\n\t\t\t\tcallback(li)\n\t\t\t}\n\t\t}\n\t}\n}\n\n// evaluateComprehensionExpression runs an expression from a list or dict comprehension, and returns true if the caller\n// should continue to use it, or false if it's been filtered out of the comprehension.\nfunc (s *scope) evaluateComprehensionExpression(comp *Comprehension, names []string, li pyObject) bool {\n\ts.unpackNames(names, li)\n\treturn comp.If == nil || s.interpretExpression(comp.If).IsTruthy()\n}\n\n// unpackNames unpacks the given object into this scope.\nfunc (s *scope) unpackNames(names []string, obj pyObject) {\n\tif len(names) == 1 {\n\t\ts.Set(names[0], obj)\n\t} else {\n\t\tl, ok := obj.(pyList)\n\t\ts.Assert(ok, \"Cannot unpack %s into %s\", obj.Type(), names)\n\t\ts.Assert(len(l) == len(names), \"Incorrect number of values to unpack; expected %d, got %d\", len(names), len(l))\n\t\tfor i, name := range names {\n\t\t\ts.Set(name, l[i])\n\t\t}\n\t}\n}\n\n// iterate returns the result of the given expression as a pyList, which is our only iterable type.\nfunc (s *scope) iterate(expr *Expression) pyList {\n\to := s.interpretExpression(expr)\n\tl, ok := o.(pyList)\n\tif !ok {\n\t\tif l, ok := o.(pyFrozenList); ok {\n\t\t\treturn l.pyList\n\t\t}\n\t}\n\ts.Assert(ok, \"Non-iterable type %s; must be a list\", o.Type())\n\treturn l\n}\n\n// evaluateExpressions runs a series of Python expressions in this scope and creates a series of concrete objects from them.\nfunc (s *scope) evaluateExpressions(exprs []*Expression) []pyObject {\n\tl := make(pyList, len(exprs))\n\tfor i, v := range exprs {\n\t\tl[i] = s.interpretExpression(v)\n\t}\n\treturn l\n}\n\n// stringLiteral converts a parsed string literal (which is still surrounded by quotes) to an unquoted version.\nfunc stringLiteral(s string) string {\n\treturn s[1 : len(s)-1]\n}\n\n// callObject attempts to call the given object\nfunc (s *scope) callObject(name string, obj pyObject, c *Call) pyObject {\n\t// We only allow function objects to be called, so don't bother making it part of the pyObject interface.\n\tf, ok := obj.(*pyFunc)\n\tif !ok {\n\t\ts.Error(\"Non-callable object '%s' (is a %s)\", name, obj.Type())\n\t}\n\tif !s.interpreter.profiling {\n\t\treturn f.Call(s.ctx, s, c)\n\t}\n\t// If the CPU profiler is being run, attach the name of the current function in context.\n\tvar ret pyObject\n\tpprof.Do(s.ctx, pprof.Labels(\"asp:func\", f.name), func(ctx context.Context) {\n\t\tret = f.Call(ctx, s, c)\n\t})\n\treturn ret\n}\n\n// Constant returns an object from an expression that describes a constant,\n// e.g. None, \"string\", 42, [], etc. It returns nil if the expression cannot be determined to be constant.\nfunc (s *scope) Constant(expr *Expression) pyObject {\n\t// Technically some of these might be constant (e.g. 'a,b,c'.split(',') or `1 if True else 2`.\n\t// That's probably unlikely to be common though - we could do a generalised constant-folding pass\n\t// but it's rare that people would write something of that nature in this language.\n\tif expr.Optimised != nil && expr.Optimised.Constant != nil {\n\t\treturn expr.Optimised.Constant\n\t} else if expr.Val == nil || len(expr.Val.Slices) != 0 || expr.Val.Property != nil || expr.Val.Call != nil || expr.Op != nil || expr.If != nil {\n\t\treturn nil\n\t} else if expr.Val.True || expr.Val.False || expr.Val.None || expr.Val.IsInt || expr.Val.String != \"\" {\n\t\treturn s.interpretValueExpression(expr.Val)\n\t} else if expr.Val.List != nil && expr.Val.List.Comprehension == nil {\n\t\t// Lists can be constant if all their elements are also.\n\t\tfor _, v := range expr.Val.List.Values {\n\t\t\tif s.Constant(v) == nil {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\treturn s.interpretValueExpression(expr.Val)\n\t} else if expr.Val.FString != nil && len(expr.Val.FString.Vars) == 0 {\n\t\treturn pyString(expr.Val.FString.Suffix)\n\t}\n\t// N.B. dicts are not optimised to constants currently because they are mutable (because Go maps have\n\t//      pointer semantics). It might be nice to be able to do that later but it is probably not critical -\n\t//      we might also be able to do a more aggressive pass in cases where we know we're passing a constant\n\t//      to a builtin that won't modify it (e.g. calling build_rule with a constant dict).\n\treturn nil\n}\n\n// pkgFilename returns the filename of the current package, or the empty string if there is none.\nfunc (s *scope) pkgFilename() string {\n\tif s.pkg != nil {\n\t\treturn s.pkg.Filename\n\t}\n\treturn \"\"\n}\n", "idx": 1, "id": 10020, "msg": "this got me a little confused when reading `build.log`. The err is printed with a log.Error later on but that ends up after the stack trace.", "proj": "thought-machine-please", "lang": "go"}
{"patch": "@@ -497,6 +497,10 @@ func generateAlertmanagerConfig(version semver.Version, am v1.AlertmanagerEndpoi\n \t\tcfg = append(cfg, k8sSDWithNamespaces([]string{am.Namespace}))\n \t}\n \n+\tif am.BearerTokenFile != \"\" {\n+\t\tcfg = append(cfg, yaml.MapItem{Key: \"bearer_token_file\", Value: am.BearerTokenFile})\n+\t}\n+\n \tvar relabelings []yaml.MapSlice\n \n \trelabelings = append(relabelings, yaml.MapSlice{", "y": 1, "oldf": "// Copyright 2016 The prometheus-operator Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage prometheus\n\nimport (\n\t\"fmt\"\n\t\"regexp\"\n\t\"sort\"\n\t\"strings\"\n\n\t\"github.com/blang/semver\"\n\t\"github.com/pkg/errors\"\n\t\"gopkg.in/yaml.v2\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\n\t\"github.com/coreos/prometheus-operator/pkg/client/monitoring/v1\"\n)\n\nvar (\n\tinvalidLabelCharRE = regexp.MustCompile(`[^a-zA-Z0-9_]`)\n)\n\nfunc sanitizeLabelName(name string) string {\n\treturn invalidLabelCharRE.ReplaceAllString(name, \"_\")\n}\n\nfunc configMapRuleFileFolder(configMapNumber int) string {\n\treturn fmt.Sprintf(\"/etc/prometheus/rules/rules-%d/\", configMapNumber)\n}\n\nfunc stringMapToMapSlice(m map[string]string) yaml.MapSlice {\n\tres := yaml.MapSlice{}\n\tks := make([]string, 0)\n\n\tfor k, _ := range m {\n\t\tks = append(ks, k)\n\t}\n\tsort.Strings(ks)\n\n\tfor _, k := range ks {\n\t\tres = append(res, yaml.MapItem{Key: k, Value: m[k]})\n\t}\n\n\treturn res\n}\n\nfunc addTLStoYaml(cfg yaml.MapSlice, tls *v1.TLSConfig) yaml.MapSlice {\n\tif tls != nil {\n\t\ttlsConfig := yaml.MapSlice{\n\t\t\t{Key: \"insecure_skip_verify\", Value: tls.InsecureSkipVerify},\n\t\t}\n\t\tif tls.CAFile != \"\" {\n\t\t\ttlsConfig = append(tlsConfig, yaml.MapItem{Key: \"ca_file\", Value: tls.CAFile})\n\t\t}\n\t\tif tls.CertFile != \"\" {\n\t\t\ttlsConfig = append(tlsConfig, yaml.MapItem{Key: \"cert_file\", Value: tls.CertFile})\n\t\t}\n\t\tif tls.KeyFile != \"\" {\n\t\t\ttlsConfig = append(tlsConfig, yaml.MapItem{Key: \"key_file\", Value: tls.KeyFile})\n\t\t}\n\t\tif tls.ServerName != \"\" {\n\t\t\ttlsConfig = append(tlsConfig, yaml.MapItem{Key: \"server_name\", Value: tls.ServerName})\n\t\t}\n\t\tcfg = append(cfg, yaml.MapItem{Key: \"tls_config\", Value: tlsConfig})\n\t}\n\treturn cfg\n}\n\nfunc generateConfig(p *v1.Prometheus, mons map[string]*v1.ServiceMonitor, ruleConfigMaps int, basicAuthSecrets map[string]BasicAuthCredentials) ([]byte, error) {\n\tversionStr := p.Spec.Version\n\tif versionStr == \"\" {\n\t\tversionStr = DefaultVersion\n\t}\n\n\tversion, err := semver.Parse(strings.TrimLeft(versionStr, \"v\"))\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"parse version\")\n\t}\n\n\tcfg := yaml.MapSlice{}\n\n\tscrapeInterval := \"30s\"\n\tif p.Spec.ScrapeInterval != \"\" {\n\t\tscrapeInterval = p.Spec.ScrapeInterval\n\t}\n\n\tevaluationInterval := \"30s\"\n\tif p.Spec.EvaluationInterval != \"\" {\n\t\tevaluationInterval = p.Spec.EvaluationInterval\n\t}\n\n\tcfg = append(cfg, yaml.MapItem{\n\t\tKey: \"global\",\n\t\tValue: yaml.MapSlice{\n\t\t\t{Key: \"evaluation_interval\", Value: evaluationInterval},\n\t\t\t{Key: \"scrape_interval\", Value: scrapeInterval},\n\t\t\t{Key: \"external_labels\", Value: stringMapToMapSlice(p.Spec.ExternalLabels)},\n\t\t},\n\t})\n\n\tif ruleConfigMaps > 0 {\n\t\tconfigMaps := make([]string, ruleConfigMaps)\n\t\tfor i := 0; i < ruleConfigMaps; i++ {\n\t\t\tconfigMaps[i] = configMapRuleFileFolder(i) + \"*\"\n\t\t}\n\t\tcfg = append(cfg, yaml.MapItem{\n\t\t\tKey:   \"rule_files\",\n\t\t\tValue: configMaps,\n\t\t})\n\t}\n\n\tidentifiers := make([]string, len(mons))\n\ti := 0\n\tfor k, _ := range mons {\n\t\tidentifiers[i] = k\n\t\ti++\n\t}\n\n\t// Sorting ensures, that we always generate the config in the same order.\n\tsort.Strings(identifiers)\n\n\tvar scrapeConfigs []yaml.MapSlice\n\tfor _, identifier := range identifiers {\n\t\tfor i, ep := range mons[identifier].Spec.Endpoints {\n\t\t\tscrapeConfigs = append(scrapeConfigs, generateServiceMonitorConfig(version, mons[identifier], ep, i, basicAuthSecrets))\n\t\t}\n\t}\n\tvar alertmanagerConfigs []yaml.MapSlice\n\tif p.Spec.Alerting != nil {\n\t\tfor _, am := range p.Spec.Alerting.Alertmanagers {\n\t\t\talertmanagerConfigs = append(alertmanagerConfigs, generateAlertmanagerConfig(version, am))\n\t\t}\n\t}\n\n\tcfg = append(cfg, yaml.MapItem{\n\t\tKey:   \"scrape_configs\",\n\t\tValue: scrapeConfigs,\n\t})\n\n\tcfg = append(cfg, yaml.MapItem{\n\t\tKey: \"alerting\",\n\t\tValue: yaml.MapSlice{\n\t\t\t{\n\t\t\t\tKey:   \"alertmanagers\",\n\t\t\t\tValue: alertmanagerConfigs,\n\t\t\t},\n\t\t},\n\t})\n\n\tif len(p.Spec.RemoteWrite) > 0 && version.Major >= 2 {\n\t\tcfg = append(cfg, generateRemoteWriteConfig(version, p.Spec.RemoteWrite, basicAuthSecrets))\n\t}\n\n\tif len(p.Spec.RemoteRead) > 0 && version.Major >= 2 {\n\t\tcfg = append(cfg, generateRemoteReadConfig(version, p.Spec.RemoteRead, basicAuthSecrets))\n\t}\n\n\treturn yaml.Marshal(cfg)\n}\n\nfunc generateServiceMonitorConfig(version semver.Version, m *v1.ServiceMonitor, ep v1.Endpoint, i int, basicAuthSecrets map[string]BasicAuthCredentials) yaml.MapSlice {\n\tcfg := yaml.MapSlice{\n\t\t{\n\t\t\tKey:   \"job_name\",\n\t\t\tValue: fmt.Sprintf(\"%s/%s/%d\", m.Namespace, m.Name, i),\n\t\t},\n\t\t{\n\t\t\tKey:   \"honor_labels\",\n\t\t\tValue: ep.HonorLabels,\n\t\t},\n\t}\n\n\tswitch version.Major {\n\tcase 1:\n\t\tif version.Minor < 7 {\n\t\t\tcfg = append(cfg, k8sSDAllNamespaces())\n\t\t} else {\n\t\t\tcfg = append(cfg, k8sSDFromServiceMonitor(m))\n\t\t}\n\tcase 2:\n\t\tcfg = append(cfg, k8sSDFromServiceMonitor(m))\n\t}\n\n\tif ep.Interval != \"\" {\n\t\tcfg = append(cfg, yaml.MapItem{Key: \"scrape_interval\", Value: ep.Interval})\n\t}\n\tif ep.ScrapeTimeout != \"\" {\n\t\tcfg = append(cfg, yaml.MapItem{Key: \"scrape_timeout\", Value: ep.ScrapeTimeout})\n\t}\n\tif ep.Path != \"\" {\n\t\tcfg = append(cfg, yaml.MapItem{Key: \"metrics_path\", Value: ep.Path})\n\t}\n\tif ep.Params != nil {\n\t\tcfg = append(cfg, yaml.MapItem{Key: \"params\", Value: ep.Params})\n\t}\n\tif ep.Scheme != \"\" {\n\t\tcfg = append(cfg, yaml.MapItem{Key: \"scheme\", Value: ep.Scheme})\n\t}\n\n\tcfg = addTLStoYaml(cfg, ep.TLSConfig)\n\n\tif ep.BearerTokenFile != \"\" {\n\t\tcfg = append(cfg, yaml.MapItem{Key: \"bearer_token_file\", Value: ep.BearerTokenFile})\n\t}\n\n\tif ep.BasicAuth != nil {\n\t\tif s, ok := basicAuthSecrets[fmt.Sprintf(\"serviceMonitor/%s/%s/%d\", m.Namespace, m.Name, i)]; ok {\n\t\t\tcfg = append(cfg, yaml.MapItem{\n\t\t\t\tKey: \"basic_auth\", Value: yaml.MapSlice{\n\t\t\t\t\t{Key: \"username\", Value: s.username},\n\t\t\t\t\t{Key: \"password\", Value: s.password},\n\t\t\t\t},\n\t\t\t})\n\t\t}\n\t}\n\n\tvar relabelings []yaml.MapSlice\n\n\t// Filter targets by services selected by the monitor.\n\n\t// Exact label matches.\n\tlabelKeys := make([]string, len(m.Spec.Selector.MatchLabels))\n\ti = 0\n\tfor k, _ := range m.Spec.Selector.MatchLabels {\n\t\tlabelKeys[i] = k\n\t\ti++\n\t}\n\tsort.Strings(labelKeys)\n\tfor i := range labelKeys {\n\t\tk := labelKeys[i]\n\t\tv := m.Spec.Selector.MatchLabels[k]\n\t\trelabelings = append(relabelings, yaml.MapSlice{\n\t\t\t{Key: \"action\", Value: \"keep\"},\n\t\t\t{Key: \"source_labels\", Value: []string{\"__meta_kubernetes_service_label_\" + sanitizeLabelName(k)}},\n\t\t\t{Key: \"regex\", Value: v},\n\t\t})\n\t}\n\t// Set based label matching. We have to map the valid relations\n\t// `In`, `NotIn`, `Exists`, and `DoesNotExist`, into relabeling rules.\n\tfor _, exp := range m.Spec.Selector.MatchExpressions {\n\t\tswitch exp.Operator {\n\t\tcase metav1.LabelSelectorOpIn:\n\t\t\trelabelings = append(relabelings, yaml.MapSlice{\n\t\t\t\t{Key: \"action\", Value: \"keep\"},\n\t\t\t\t{Key: \"source_labels\", Value: []string{\"__meta_kubernetes_service_label_\" + sanitizeLabelName(exp.Key)}},\n\t\t\t\t{Key: \"regex\", Value: strings.Join(exp.Values, \"|\")},\n\t\t\t})\n\t\tcase metav1.LabelSelectorOpNotIn:\n\t\t\trelabelings = append(relabelings, yaml.MapSlice{\n\t\t\t\t{Key: \"action\", Value: \"drop\"},\n\t\t\t\t{Key: \"source_labels\", Value: []string{\"__meta_kubernetes_service_label_\" + sanitizeLabelName(exp.Key)}},\n\t\t\t\t{Key: \"regex\", Value: strings.Join(exp.Values, \"|\")},\n\t\t\t})\n\t\tcase metav1.LabelSelectorOpExists:\n\t\t\trelabelings = append(relabelings, yaml.MapSlice{\n\t\t\t\t{Key: \"action\", Value: \"keep\"},\n\t\t\t\t{Key: \"source_labels\", Value: []string{\"__meta_kubernetes_service_label_\" + sanitizeLabelName(exp.Key)}},\n\t\t\t\t{Key: \"regex\", Value: \".+\"},\n\t\t\t})\n\t\tcase metav1.LabelSelectorOpDoesNotExist:\n\t\t\trelabelings = append(relabelings, yaml.MapSlice{\n\t\t\t\t{Key: \"action\", Value: \"drop\"},\n\t\t\t\t{Key: \"source_labels\", Value: []string{\"__meta_kubernetes_service_label_\" + sanitizeLabelName(exp.Key)}},\n\t\t\t\t{Key: \"regex\", Value: \".+\"},\n\t\t\t})\n\t\t}\n\t}\n\n\tif version.Major == 1 && version.Minor < 7 {\n\t\t// Filter targets based on the namespace selection configuration.\n\t\t// By default we only discover services within the namespace of the\n\t\t// ServiceMonitor.\n\t\t// Selections allow extending this to all namespaces or to a subset\n\t\t// of them specified by label or name matching.\n\t\t//\n\t\t// Label selections are not supported yet as they require either supported\n\t\t// in the upstream SD integration or require out-of-band implementation\n\t\t// in the operator with configuration reload.\n\t\t//\n\t\t// There's no explicit nil for the selector, we decide for the default\n\t\t// case if it's all zero values.\n\t\tnsel := m.Spec.NamespaceSelector\n\n\t\tif !nsel.Any && len(nsel.MatchNames) == 0 {\n\t\t\trelabelings = append(relabelings, yaml.MapSlice{\n\t\t\t\t{Key: \"action\", Value: \"keep\"},\n\t\t\t\t{Key: \"source_labels\", Value: []string{\"__meta_kubernetes_namespace\"}},\n\t\t\t\t{Key: \"regex\", Value: m.Namespace},\n\t\t\t})\n\t\t} else if len(nsel.MatchNames) > 0 {\n\t\t\trelabelings = append(relabelings, yaml.MapSlice{\n\t\t\t\t{Key: \"action\", Value: \"keep\"},\n\t\t\t\t{Key: \"source_labels\", Value: []string{\"__meta_kubernetes_namespace\"}},\n\t\t\t\t{Key: \"regex\", Value: strings.Join(nsel.MatchNames, \"|\")},\n\t\t\t})\n\t\t}\n\t}\n\n\t// Filter targets based on correct port for the endpoint.\n\tif ep.Port != \"\" {\n\t\trelabelings = append(relabelings, yaml.MapSlice{\n\t\t\t{Key: \"action\", Value: \"keep\"},\n\t\t\t{Key: \"source_labels\", Value: []string{\"__meta_kubernetes_endpoint_port_name\"}},\n\t\t\t{Key: \"regex\", Value: ep.Port},\n\t\t})\n\t} else if ep.TargetPort.StrVal != \"\" {\n\t\trelabelings = append(relabelings, yaml.MapSlice{\n\t\t\t{Key: \"action\", Value: \"keep\"},\n\t\t\t{Key: \"source_labels\", Value: []string{\"__meta_kubernetes_pod_container_port_name\"}},\n\t\t\t{Key: \"regex\", Value: ep.TargetPort.String()},\n\t\t})\n\t} else if ep.TargetPort.IntVal != 0 {\n\t\trelabelings = append(relabelings, yaml.MapSlice{\n\t\t\t{Key: \"action\", Value: \"keep\"},\n\t\t\t{Key: \"source_labels\", Value: []string{\"__meta_kubernetes_pod_container_port_number\"}},\n\t\t\t{Key: \"regex\", Value: ep.TargetPort.String()},\n\t\t})\n\t}\n\n\t// Relabel namespace and pod and service labels into proper labels.\n\trelabelings = append(relabelings, []yaml.MapSlice{\n\t\tyaml.MapSlice{\n\t\t\t{Key: \"source_labels\", Value: []string{\"__meta_kubernetes_namespace\"}},\n\t\t\t{Key: \"target_label\", Value: \"namespace\"},\n\t\t},\n\t\tyaml.MapSlice{\n\t\t\t{Key: \"source_labels\", Value: []string{\"__meta_kubernetes_pod_name\"}},\n\t\t\t{Key: \"target_label\", Value: \"pod\"},\n\t\t},\n\t\tyaml.MapSlice{\n\t\t\t{Key: \"source_labels\", Value: []string{\"__meta_kubernetes_service_name\"}},\n\t\t\t{Key: \"target_label\", Value: \"service\"},\n\t\t},\n\t}...)\n\n\t// By default, generate a safe job name from the service name.  We also keep\n\t// this around if a jobLabel is set in case the targets don't actually have a\n\t// value for it. A single service may potentially have multiple metrics\n\t// endpoints, therefore the endpoints labels is filled with the ports name or\n\t// as a fallback the port number.\n\n\trelabelings = append(relabelings, yaml.MapSlice{\n\t\t{Key: \"source_labels\", Value: []string{\"__meta_kubernetes_service_name\"}},\n\t\t{Key: \"target_label\", Value: \"job\"},\n\t\t{Key: \"replacement\", Value: \"${1}\"},\n\t})\n\tif m.Spec.JobLabel != \"\" {\n\t\trelabelings = append(relabelings, yaml.MapSlice{\n\t\t\t{Key: \"source_labels\", Value: []string{\"__meta_kubernetes_service_label_\" + sanitizeLabelName(m.Spec.JobLabel)}},\n\t\t\t{Key: \"target_label\", Value: \"job\"},\n\t\t\t{Key: \"regex\", Value: \"(.+)\"},\n\t\t\t{Key: \"replacement\", Value: \"${1}\"},\n\t\t})\n\t}\n\n\tif ep.Port != \"\" {\n\t\trelabelings = append(relabelings, yaml.MapSlice{\n\t\t\t{Key: \"target_label\", Value: \"endpoint\"},\n\t\t\t{Key: \"replacement\", Value: ep.Port},\n\t\t})\n\t} else if ep.TargetPort.String() != \"\" {\n\t\trelabelings = append(relabelings, yaml.MapSlice{\n\t\t\t{Key: \"target_label\", Value: \"endpoint\"},\n\t\t\t{Key: \"replacement\", Value: ep.TargetPort.String()},\n\t\t})\n\t}\n\n\tcfg = append(cfg, yaml.MapItem{Key: \"relabel_configs\", Value: relabelings})\n\n\tif ep.MetricRelabelConfigs != nil {\n\t\tvar metricRelabelings []yaml.MapSlice\n\t\tfor _, c := range ep.MetricRelabelConfigs {\n\t\t\trelabeling := yaml.MapSlice{\n\t\t\t\t{Key: \"source_labels\", Value: c.SourceLabels},\n\t\t\t}\n\n\t\t\tif c.Separator != \"\" {\n\t\t\t\trelabeling = append(relabeling, yaml.MapItem{Key: \"separator\", Value: c.Separator})\n\t\t\t}\n\n\t\t\tif c.TargetLabel != \"\" {\n\t\t\t\trelabeling = append(relabeling, yaml.MapItem{Key: \"target_label\", Value: c.TargetLabel})\n\t\t\t}\n\n\t\t\tif c.Regex != \"\" {\n\t\t\t\trelabeling = append(relabeling, yaml.MapItem{Key: \"regex\", Value: c.Regex})\n\t\t\t}\n\n\t\t\tif c.Modulus != uint64(0) {\n\t\t\t\trelabeling = append(relabeling, yaml.MapItem{Key: \"modulus\", Value: c.Modulus})\n\t\t\t}\n\n\t\t\tif c.Replacement != \"\" {\n\t\t\t\trelabeling = append(relabeling, yaml.MapItem{Key: \"replacement\", Value: c.Replacement})\n\t\t\t}\n\n\t\t\tif c.Action != \"\" {\n\t\t\t\trelabeling = append(relabeling, yaml.MapItem{Key: \"action\", Value: c.Action})\n\t\t\t}\n\n\t\t\tmetricRelabelings = append(metricRelabelings, relabeling)\n\t\t}\n\t\tcfg = append(cfg, yaml.MapItem{Key: \"metric_relabel_configs\", Value: metricRelabelings})\n\t}\n\n\treturn cfg\n}\n\nfunc k8sSDFromServiceMonitor(m *v1.ServiceMonitor) yaml.MapItem {\n\tnsel := m.Spec.NamespaceSelector\n\tnamespaces := []string{}\n\tif !nsel.Any && len(nsel.MatchNames) == 0 {\n\t\tnamespaces = append(namespaces, m.Namespace)\n\t}\n\tif !nsel.Any && len(nsel.MatchNames) > 0 {\n\t\tfor i := range nsel.MatchNames {\n\t\t\tnamespaces = append(namespaces, nsel.MatchNames[i])\n\t\t}\n\t}\n\n\treturn k8sSDWithNamespaces(namespaces)\n}\n\nfunc k8sSDWithNamespaces(namespaces []string) yaml.MapItem {\n\treturn yaml.MapItem{\n\t\tKey: \"kubernetes_sd_configs\",\n\t\tValue: []yaml.MapSlice{\n\t\t\tyaml.MapSlice{\n\t\t\t\t{\n\t\t\t\t\tKey:   \"role\",\n\t\t\t\t\tValue: \"endpoints\",\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tKey: \"namespaces\",\n\t\t\t\t\tValue: yaml.MapSlice{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tKey:   \"names\",\n\t\t\t\t\t\t\tValue: namespaces,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n}\n\nfunc k8sSDAllNamespaces() yaml.MapItem {\n\treturn yaml.MapItem{\n\t\tKey: \"kubernetes_sd_configs\",\n\t\tValue: []yaml.MapSlice{\n\t\t\tyaml.MapSlice{\n\t\t\t\t{\n\t\t\t\t\tKey:   \"role\",\n\t\t\t\t\tValue: \"endpoints\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n}\n\nfunc generateAlertmanagerConfig(version semver.Version, am v1.AlertmanagerEndpoints) yaml.MapSlice {\n\tif am.Scheme == \"\" {\n\t\tam.Scheme = \"http\"\n\t}\n\n\tif am.PathPrefix == \"\" {\n\t\tam.PathPrefix = \"/\"\n\t}\n\n\tcfg := yaml.MapSlice{\n\t\t{Key: \"path_prefix\", Value: am.PathPrefix},\n\t\t{Key: \"scheme\", Value: am.Scheme},\n\t}\n\n\tcfg = addTLStoYaml(cfg, am.TLSConfig)\n\n\tswitch version.Major {\n\tcase 1:\n\t\tif version.Minor < 7 {\n\t\t\tcfg = append(cfg, k8sSDAllNamespaces())\n\t\t} else {\n\t\t\tcfg = append(cfg, k8sSDWithNamespaces([]string{am.Namespace}))\n\t\t}\n\tcase 2:\n\t\tcfg = append(cfg, k8sSDWithNamespaces([]string{am.Namespace}))\n\t}\n\n\tvar relabelings []yaml.MapSlice\n\n\trelabelings = append(relabelings, yaml.MapSlice{\n\t\t{Key: \"action\", Value: \"keep\"},\n\t\t{Key: \"source_labels\", Value: []string{\"__meta_kubernetes_service_name\"}},\n\t\t{Key: \"regex\", Value: am.Name},\n\t})\n\n\tif am.Port.StrVal != \"\" {\n\t\trelabelings = append(relabelings, yaml.MapSlice{\n\t\t\t{Key: \"action\", Value: \"keep\"},\n\t\t\t{Key: \"source_labels\", Value: []string{\"__meta_kubernetes_endpoint_port_name\"}},\n\t\t\t{Key: \"regex\", Value: am.Port.String()},\n\t\t})\n\t} else if am.Port.IntVal != 0 {\n\t\trelabelings = append(relabelings, yaml.MapSlice{\n\t\t\t{Key: \"action\", Value: \"keep\"},\n\t\t\t{Key: \"source_labels\", Value: []string{\"__meta_kubernetes_container_port_number\"}},\n\t\t\t{Key: \"regex\", Value: am.Port.String()},\n\t\t})\n\t}\n\n\tif version.Major == 1 && version.Minor < 7 {\n\t\trelabelings = append(relabelings, yaml.MapSlice{\n\t\t\t{Key: \"action\", Value: \"keep\"},\n\t\t\t{Key: \"source_labels\", Value: []string{\"__meta_kubernetes_namespace\"}},\n\t\t\t{Key: \"regex\", Value: am.Namespace},\n\t\t})\n\t}\n\n\tcfg = append(cfg, yaml.MapItem{Key: \"relabel_configs\", Value: relabelings})\n\n\treturn cfg\n}\n\nfunc generateRemoteReadConfig(version semver.Version, specs []v1.RemoteReadSpec, basicAuthSecrets map[string]BasicAuthCredentials) yaml.MapItem {\n\n\tcfgs := []yaml.MapSlice{}\n\n\tfor i, spec := range specs {\n\t\t//defaults\n\t\tif spec.RemoteTimeout == \"\" {\n\t\t\tspec.RemoteTimeout = \"30s\"\n\t\t}\n\n\t\tcfg := yaml.MapSlice{\n\t\t\t{Key: \"url\", Value: spec.URL},\n\t\t\t{Key: \"remote_timeout\", Value: spec.RemoteTimeout},\n\t\t}\n\n\t\tif len(spec.RequiredMatchers) > 0 {\n\t\t\tcfg = append(cfg, yaml.MapItem{Key: \"required_matchers\", Value: stringMapToMapSlice(spec.RequiredMatchers)})\n\t\t}\n\n\t\tif spec.ReadRecent {\n\t\t\tcfg = append(cfg, yaml.MapItem{Key: \"read_recent\", Value: spec.ReadRecent})\n\t\t}\n\n\t\tif spec.BasicAuth != nil {\n\t\t\tif s, ok := basicAuthSecrets[fmt.Sprintf(\"remoteRead/%d\", i)]; ok {\n\t\t\t\tcfg = append(cfg, yaml.MapItem{\n\t\t\t\t\tKey: \"basic_auth\", Value: yaml.MapSlice{\n\t\t\t\t\t\t{Key: \"username\", Value: s.username},\n\t\t\t\t\t\t{Key: \"password\", Value: s.password},\n\t\t\t\t\t},\n\t\t\t\t})\n\t\t\t}\n\t\t}\n\n\t\tif spec.BearerTokenFile != \"\" {\n\t\t\tcfg = append(cfg, yaml.MapItem{Key: \"bearer_token_file\", Value: spec.BearerTokenFile})\n\t\t}\n\n\t\tcfg = addTLStoYaml(cfg, spec.TLSConfig)\n\n\t\tif spec.ProxyURL != \"\" {\n\t\t\tcfg = append(cfg, yaml.MapItem{Key: \"proxy_url\", Value: spec.ProxyURL})\n\t\t}\n\n\t\tcfgs = append(cfgs, cfg)\n\n\t}\n\n\treturn yaml.MapItem{\n\t\tKey:   \"remote_read\",\n\t\tValue: cfgs,\n\t}\n}\n\nfunc generateRemoteWriteConfig(version semver.Version, specs []v1.RemoteWriteSpec, basicAuthSecrets map[string]BasicAuthCredentials) yaml.MapItem {\n\n\tcfgs := []yaml.MapSlice{}\n\n\tfor i, spec := range specs {\n\t\t//defaults\n\t\tif spec.RemoteTimeout == \"\" {\n\t\t\tspec.RemoteTimeout = \"30s\"\n\t\t}\n\n\t\tcfg := yaml.MapSlice{\n\t\t\t{Key: \"url\", Value: spec.URL},\n\t\t\t{Key: \"remote_timeout\", Value: spec.RemoteTimeout},\n\t\t}\n\n\t\tif spec.WriteRelabelConfigs != nil {\n\t\t\trelabelings := []yaml.MapSlice{}\n\t\t\tfor _, c := range spec.WriteRelabelConfigs {\n\t\t\t\trelabeling := yaml.MapSlice{\n\t\t\t\t\t{Key: \"source_labels\", Value: c.SourceLabels},\n\t\t\t\t}\n\n\t\t\t\tif c.Separator != \"\" {\n\t\t\t\t\trelabeling = append(relabeling, yaml.MapItem{Key: \"separator\", Value: c.Separator})\n\t\t\t\t}\n\n\t\t\t\tif c.TargetLabel != \"\" {\n\t\t\t\t\trelabeling = append(relabeling, yaml.MapItem{Key: \"target_label\", Value: c.TargetLabel})\n\t\t\t\t}\n\n\t\t\t\tif c.Regex != \"\" {\n\t\t\t\t\trelabeling = append(relabeling, yaml.MapItem{Key: \"regex\", Value: c.Regex})\n\t\t\t\t}\n\n\t\t\t\tif c.Modulus != uint64(0) {\n\t\t\t\t\trelabeling = append(relabeling, yaml.MapItem{Key: \"modulus\", Value: c.Modulus})\n\t\t\t\t}\n\n\t\t\t\tif c.Replacement != \"\" {\n\t\t\t\t\trelabeling = append(relabeling, yaml.MapItem{Key: \"replacement\", Value: c.Replacement})\n\t\t\t\t}\n\n\t\t\t\tif c.Action != \"\" {\n\t\t\t\t\trelabeling = append(relabeling, yaml.MapItem{Key: \"action\", Value: c.Action})\n\t\t\t\t}\n\t\t\t\trelabelings = append(relabelings, relabeling)\n\t\t\t}\n\n\t\t\tcfg = append(cfg, yaml.MapItem{Key: \"write_relabel_configs\", Value: relabelings})\n\n\t\t}\n\n\t\tif spec.BasicAuth != nil {\n\t\t\tif s, ok := basicAuthSecrets[fmt.Sprintf(\"remoteWrite/%d\", i)]; ok {\n\t\t\t\tcfg = append(cfg, yaml.MapItem{\n\t\t\t\t\tKey: \"basic_auth\", Value: yaml.MapSlice{\n\t\t\t\t\t\t{Key: \"username\", Value: s.username},\n\t\t\t\t\t\t{Key: \"password\", Value: s.password},\n\t\t\t\t\t},\n\t\t\t\t})\n\t\t\t}\n\t\t}\n\n\t\tif spec.BearerToken != \"\" {\n\t\t\tcfg = append(cfg, yaml.MapItem{Key: \"bearer_token\", Value: spec.BearerToken})\n\t\t}\n\n\t\tif spec.BearerTokenFile != \"\" {\n\t\t\tcfg = append(cfg, yaml.MapItem{Key: \"bearer_token_file\", Value: spec.BearerTokenFile})\n\t\t}\n\n\t\tcfg = addTLStoYaml(cfg, spec.TLSConfig)\n\n\t\tif spec.ProxyURL != \"\" {\n\t\t\tcfg = append(cfg, yaml.MapItem{Key: \"proxy_url\", Value: spec.ProxyURL})\n\t\t}\n\n\t\tcfgs = append(cfgs, cfg)\n\t}\n\n\treturn yaml.MapItem{\n\t\tKey:   \"remote_write\",\n\t\tValue: cfgs,\n\t}\n}\n", "idx": 1, "id": 9896, "msg": "is this configuration key already exist in prometheus ?", "proj": "prometheus-operator-prometheus-operator", "lang": "go"}
{"patch": "@@ -107,7 +107,7 @@ namespace Nethermind.Merge.Plugin.Handlers.V1\n             \n             if (headUpdated && shouldUpdateHead)\n             {\n-                _poSSwitcher.ForkchoiceUpdated(newHeadBlock!.Header);\n+                _poSSwitcher.ForkchoiceUpdated(newHeadBlock!.Header, finalizedHeader);\n                 _stateProvider.ResetStateTo(newHeadBlock.StateRoot!);\n                 if (_logger.IsInfo) _logger.Info($\"Block {forkchoiceState.HeadBlockHash} was set as head\");\n             }", "y": 1, "oldf": "\ufeff//  Copyright (c) 2021 Demerzel Solutions Limited\n//  This file is part of the Nethermind library.\n// \n//  The Nethermind library is free software: you can redistribute it and/or modify\n//  it under the terms of the GNU Lesser General Public License as published by\n//  the Free Software Foundation, either version 3 of the License, or\n//  (at your option) any later version.\n// \n//  The Nethermind library is distributed in the hope that it will be useful,\n//  but WITHOUT ANY WARRANTY; without even the implied warranty of\n//  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n//  GNU Lesser General Public License for more details.\n// \n//  You should have received a copy of the GNU Lesser General Public License\n//  along with the Nethermind. If not, see <http://www.gnu.org/licenses/>.\n// \n\nusing System;\nusing System.Collections.Generic;\nusing Nethermind.Blockchain;\nusing Nethermind.Blockchain.Find;\nusing Nethermind.Consensus;\nusing Nethermind.Consensus.Producers;\nusing Nethermind.Core;\nusing Nethermind.Core.Crypto;\nusing Nethermind.Core.Extensions;\nusing Nethermind.Facade.Eth;\nusing Nethermind.JsonRpc;\nusing Nethermind.Logging;\nusing Nethermind.Merge.Plugin.Data;\nusing Nethermind.Merge.Plugin.Data.V1;\nusing Nethermind.State;\n\nnamespace Nethermind.Merge.Plugin.Handlers.V1\n{\n    /// <summary>\n    /// https://github.com/ethereum/execution-apis/blob/main/src/engine/specification.md\n    /// Propagates the change in the fork choice to the execution client\n    /// </summary>\n    public class ForkchoiceUpdatedV1Handler : IForkchoiceUpdatedV1Handler\n    {\n        private readonly IBlockTree _blockTree;\n        private readonly IStateProvider _stateProvider;\n        private readonly IManualBlockFinalizationManager _manualBlockFinalizationManager;\n        private readonly IPoSSwitcher _poSSwitcher;\n        private readonly IEthSyncingInfo _ethSyncingInfo;\n        private readonly IBlockConfirmationManager _blockConfirmationManager;\n        private readonly IPayloadService _payloadService;\n        private readonly ILogger _logger;\n\n        public ForkchoiceUpdatedV1Handler(\n            IBlockTree blockTree,\n            IStateProvider stateProvider,\n            IManualBlockFinalizationManager manualBlockFinalizationManager, \n            IPoSSwitcher poSSwitcher,\n            IEthSyncingInfo ethSyncingInfo,\n            IBlockConfirmationManager blockConfirmationManager,\n            IPayloadService payloadService,\n            ILogManager logManager)\n        {\n            _blockTree = blockTree ?? throw new ArgumentNullException(nameof(blockTree));\n            _stateProvider = stateProvider ?? throw new ArgumentNullException(nameof(stateProvider));\n            _manualBlockFinalizationManager = manualBlockFinalizationManager ?? throw new ArgumentNullException(nameof(manualBlockFinalizationManager));\n            _poSSwitcher = poSSwitcher ?? throw new ArgumentNullException(nameof(poSSwitcher));\n            _ethSyncingInfo = ethSyncingInfo ?? throw new ArgumentNullException(nameof(ethSyncingInfo));\n            _blockConfirmationManager = blockConfirmationManager ?? throw new ArgumentNullException(nameof(blockConfirmationManager));\n            _payloadService = payloadService;\n            _logger = logManager.GetClassLogger();\n        }\n\n        public ResultWrapper<ForkchoiceUpdatedV1Result> Handle(ForkchoiceStateV1 forkchoiceState, PayloadAttributes? payloadAttributes)\n        {\n            // ToDo wait for final PostMerge sync\n            // if (_ethSyncingInfo.IsSyncing())\n            // {\n            //     return ResultWrapper<ForkchoiceUpdatedV1Result>.Success(new ForkchoiceUpdatedV1Result() { Status = EngineStatus.Syncing});\n            // }\n            \n            (BlockHeader? finalizedHeader, string? finalizationErrorMsg) = EnsureHeaderForFinalization(forkchoiceState.FinalizedBlockHash);\n            if (finalizationErrorMsg != null)\n                return ResultWrapper<ForkchoiceUpdatedV1Result>.Success(new ForkchoiceUpdatedV1Result() { Status = EngineStatus.Syncing}); // ToDo wait for final PostMerge sync\n            \n            (BlockHeader? confirmedHeader, string? confirmationErrorMsg) = EnsureHeaderForConfirmation(forkchoiceState.SafeBlockHash);\n            if (confirmationErrorMsg != null)\n                return ResultWrapper<ForkchoiceUpdatedV1Result>.Success(new ForkchoiceUpdatedV1Result() { Status = EngineStatus.Syncing}); // ToDo wait for final PostMerge sync\n            \n            (Block? newHeadBlock, Block[]? blocks, string? setHeadErrorMsg) = EnsureBlocksForSetHead(forkchoiceState.HeadBlockHash);\n            if (setHeadErrorMsg != null)\n                return ResultWrapper<ForkchoiceUpdatedV1Result>.Success(new ForkchoiceUpdatedV1Result() { Status = EngineStatus.Syncing}); // ToDo wait for final PostMerge sync\n \n            if (ShouldFinalize(forkchoiceState.FinalizedBlockHash))\n                _manualBlockFinalizationManager.MarkFinalized(newHeadBlock!.Header, finalizedHeader!);\n            else if (_manualBlockFinalizationManager.LastFinalizedHash != Keccak.Zero)\n                if (_logger.IsWarn) _logger.Warn($\"Cannot finalize block. The current finalized block is: {_manualBlockFinalizationManager.LastFinalizedHash}, the requested hash: {forkchoiceState.FinalizedBlockHash}\");\n            \n            // In future safeBlockHash will be added to JSON-RPC\n             _blockConfirmationManager.Confirm(confirmedHeader!.Hash!);\n            byte[]? payloadId = null;\n\n            bool headUpdated = false;\n            bool shouldUpdateHead = blocks != null && _blockTree.Head != newHeadBlock;\n            if (shouldUpdateHead)\n            {\n                _blockTree.UpdateMainChain(blocks!, true, true);\n                headUpdated = _blockTree.Head == newHeadBlock;\n            }\n            \n            if (headUpdated && shouldUpdateHead)\n            {\n                _poSSwitcher.ForkchoiceUpdated(newHeadBlock!.Header);\n                _stateProvider.ResetStateTo(newHeadBlock.StateRoot!);\n                if (_logger.IsInfo) _logger.Info($\"Block {forkchoiceState.HeadBlockHash} was set as head\");\n            }\n            else if (headUpdated == false && shouldUpdateHead)\n            {\n                // ToDo we should never have this case. Consult it with LR\n                if (_logger.IsWarn) _logger.Warn($\"Block {forkchoiceState.FinalizedBlockHash} was not set as head.\");\n            }\n            \n            bool shouldStartPreparingPayload = payloadAttributes != null;\n            if (shouldStartPreparingPayload)\n            {\n                payloadId = _payloadService.StartPreparingPayload(newHeadBlock!.Header, payloadAttributes);\n            }\n\n\n            return ResultWrapper<ForkchoiceUpdatedV1Result>.Success(new ForkchoiceUpdatedV1Result() { PayloadId = payloadId?.ToHexString(true), Status = EngineStatus.Success});\n        }\n\n        private (BlockHeader? BlockHeader, string? ErrorMsg) EnsureHeaderForConfirmation(Keccak confirmedBlockHash)\n        {\n            string? errorMsg = null;\n            BlockHeader? blockHeader = _blockTree.FindHeader(confirmedBlockHash, BlockTreeLookupOptions.None);\n            if (blockHeader is null)\n            {\n                errorMsg = $\"Block {confirmedBlockHash} not found for confirmation.\";\n                if (_logger.IsWarn) _logger.Warn(errorMsg);\n            }\n\n            return (blockHeader, errorMsg);\n        }\n\n        private (Block? NewHeadBlock, Block[]? Blocks, string? ErrorMsg) EnsureBlocksForSetHead(Keccak headBlockHash)\n        {\n            string? errorMsg = null;\n            Block? headBlock = _blockTree.FindBlock(headBlockHash, BlockTreeLookupOptions.None);\n            if (headBlock == null)\n            {\n                errorMsg = $\"Block {headBlockHash} cannot be found and it will not be set as head.\";\n                if (_logger.IsWarn) _logger.Warn(errorMsg);\n                return (headBlock, null, errorMsg);\n            }\n\n            if (_blockTree.Head!.Hash == headBlockHash)\n            {\n                return (headBlock, null, errorMsg);\n            }\n\n            if (!TryGetBranch(headBlock, out Block[] branchOfBlocks))\n            {\n                errorMsg = $\"Block's {headBlockHash} main chain predecessor cannot be found and it will not be set as head.\";\n                if (_logger.IsWarn) _logger.Warn(errorMsg);\n            }\n\n            return (headBlock, branchOfBlocks, errorMsg);\n        }\n\n        private (BlockHeader? BlockHeader, string? ErrorMsg) EnsureHeaderForFinalization(Keccak finalizedBlockHash)\n        {\n            string? errorMsg = null;\n            BlockHeader? blockHeader = _blockTree.FindHeader(finalizedBlockHash, BlockTreeLookupOptions.None);\n\n            if (ShouldFinalize(finalizedBlockHash))\n            {\n                blockHeader = _blockTree.FindHeader(finalizedBlockHash, BlockTreeLookupOptions.None);\n                if (blockHeader is null)\n                {\n                    errorMsg = $\"Block {finalizedBlockHash} not found for finalization.\";\n                    if (_logger.IsWarn) _logger.Warn(errorMsg);\n                }\n            }\n\n            return (blockHeader, errorMsg);\n        }\n\n        private bool ShouldFinalize(Keccak finalizedBlockHash) => finalizedBlockHash != Keccak.Zero;\n\n        private bool TryGetBranch(Block block, out Block[] blocks)\n        {\n            List<Block> blocksList = new() {block};\n            Block? predecessor = block;\n            \n            while (!_blockTree.IsMainChain(predecessor.Header))\n            {\n                predecessor = _blockTree.FindParent(predecessor, BlockTreeLookupOptions.None);\n                if (predecessor == null)\n                {\n                    blocks = Array.Empty<Block>();\n                    return false;\n                }\n                blocksList.Add(predecessor);\n                \n            };\n            \n            blocksList.Reverse();\n            blocks = blocksList.ToArray();\n            return true;\n        }\n    }\n}\n", "idx": 1, "id": 26429, "msg": "finalizedHeader should be saved in FinalizationManager when we have FinalizationBlockHash != Keccak.Zero", "proj": "NethermindEth-nethermind", "lang": ".cs"}
{"patch": "@@ -0,0 +1,11 @@\n+\"\"\"Tests for the use of typing.final whenever the py-version is set < 3.8\"\"\"\n+# pylint: disable=missing-class-docstring, too-few-public-methods, missing-function-docstring, no-name-in-module\n+\n+from typing import final\n+\n+\n+@final # [using-final-in-unsupported-version]\n+class MyClass:\n+    @final # [using-final-in-unsupported-version]\n+    def my_method(self):\n+        pass", "y": 1, "oldf": "", "idx": 1, "id": 16656, "msg": "What happens if someone import `typing` and thus uses `@typing.final` instead?", "proj": "PyCQA-pylint", "lang": "py"}
{"patch": "@@ -60,7 +60,7 @@ func RootCommand() (*cobra.Command, *Flags) {\n \trootCmd.PersistentFlags().IntVar(&cfg.HttpPort, \"http.port\", node.DefaultHTTPPort, \"HTTP-RPC server listening port\")\n \trootCmd.PersistentFlags().StringSliceVar(&cfg.HttpCORSDomain, \"http.corsdomain\", []string{}, \"Comma separated list of domains from which to accept cross origin requests (browser enforced)\")\n \trootCmd.PersistentFlags().StringSliceVar(&cfg.HttpVirtualHost, \"http.vhosts\", node.DefaultConfig.HTTPVirtualHosts, \"Comma separated list of virtual hostnames from which to accept requests (server enforced). Accepts '*' wildcard.\")\n-\trootCmd.PersistentFlags().StringSliceVar(&cfg.API, \"http.api\", []string{\"eth\"}, \"API's offered over the HTTP-RPC interface\")\n+\trootCmd.PersistentFlags().StringSliceVar(&cfg.API, \"http.api\", []string{\"eth\", \"tg\"}, \"API's offered over the HTTP-RPC interface\")\n \trootCmd.PersistentFlags().Uint64Var(&cfg.Gascap, \"rpc.gascap\", 0, \"Sets a cap on gas that can be used in eth_call/estimateGas\")\n \trootCmd.PersistentFlags().Uint64Var(&cfg.MaxTraces, \"trace.maxtraces\", 200, \"Sets a limit on traces that can be returned in trace_filter\")\n \trootCmd.PersistentFlags().StringVar(&cfg.TraceType, \"trace.type\", \"parity\", \"Specify the type of tracing [geth|parity*] (experimental)\")", "y": 1, "oldf": "package cli\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"net/http\"\n\t\"time\"\n\n\t\"github.com/ledgerwatch/turbo-geth/cmd/utils\"\n\t\"github.com/ledgerwatch/turbo-geth/ethdb\"\n\t\"github.com/ledgerwatch/turbo-geth/internal/debug\"\n\t\"github.com/ledgerwatch/turbo-geth/log\"\n\t\"github.com/ledgerwatch/turbo-geth/node\"\n\t\"github.com/ledgerwatch/turbo-geth/rpc\"\n\t\"github.com/spf13/cobra\"\n)\n\ntype Flags struct {\n\tPrivateApiAddr    string\n\tChaindata         string\n\tHttpListenAddress string\n\tTLSCertfile       string\n\tTLSCACert         string\n\tTLSKeyFile        string\n\tHttpPort          int\n\tHttpCORSDomain    []string\n\tHttpVirtualHost   []string\n\tAPI               []string\n\tGascap            uint64\n\tMaxTraces         uint64\n\tTraceType         string\n\tWebsocketEnabled  bool\n}\n\nvar rootCmd = &cobra.Command{\n\tUse:   \"rpcdaemon\",\n\tShort: \"rpcdaemon is JSON RPC server that connects to turbo-geth node for remote DB access\",\n\tPersistentPreRunE: func(cmd *cobra.Command, args []string) error {\n\t\tif err := utils.SetupCobra(cmd); err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn nil\n\t},\n\tPersistentPostRunE: func(cmd *cobra.Command, args []string) error {\n\t\tutils.StopDebug()\n\t\treturn nil\n\t},\n}\n\nfunc RootCommand() (*cobra.Command, *Flags) {\n\tutils.CobraFlags(rootCmd, append(debug.Flags, utils.MetricFlags...))\n\n\tcfg := &Flags{}\n\trootCmd.PersistentFlags().StringVar(&cfg.PrivateApiAddr, \"private.api.addr\", \"127.0.0.1:9090\", \"private api network address, for example: 127.0.0.1:9090, empty string means not to start the listener. do not expose to public network. serves remote database interface\")\n\trootCmd.PersistentFlags().StringVar(&cfg.Chaindata, \"chaindata\", \"\", \"path to the database\")\n\trootCmd.PersistentFlags().StringVar(&cfg.HttpListenAddress, \"http.addr\", node.DefaultHTTPHost, \"HTTP-RPC server listening interface\")\n\trootCmd.PersistentFlags().StringVar(&cfg.TLSCertfile, \"tls.cert\", \"\", \"certificate for client side TLS handshake\")\n\trootCmd.PersistentFlags().StringVar(&cfg.TLSKeyFile, \"tls.key\", \"\", \"key file for client side TLS handshake\")\n\trootCmd.PersistentFlags().StringVar(&cfg.TLSCACert, \"tls.cacert\", \"\", \"CA certificate for client side TLS handshake\")\n\trootCmd.PersistentFlags().IntVar(&cfg.HttpPort, \"http.port\", node.DefaultHTTPPort, \"HTTP-RPC server listening port\")\n\trootCmd.PersistentFlags().StringSliceVar(&cfg.HttpCORSDomain, \"http.corsdomain\", []string{}, \"Comma separated list of domains from which to accept cross origin requests (browser enforced)\")\n\trootCmd.PersistentFlags().StringSliceVar(&cfg.HttpVirtualHost, \"http.vhosts\", node.DefaultConfig.HTTPVirtualHosts, \"Comma separated list of virtual hostnames from which to accept requests (server enforced). Accepts '*' wildcard.\")\n\trootCmd.PersistentFlags().StringSliceVar(&cfg.API, \"http.api\", []string{\"eth\"}, \"API's offered over the HTTP-RPC interface\")\n\trootCmd.PersistentFlags().Uint64Var(&cfg.Gascap, \"rpc.gascap\", 0, \"Sets a cap on gas that can be used in eth_call/estimateGas\")\n\trootCmd.PersistentFlags().Uint64Var(&cfg.MaxTraces, \"trace.maxtraces\", 200, \"Sets a limit on traces that can be returned in trace_filter\")\n\trootCmd.PersistentFlags().StringVar(&cfg.TraceType, \"trace.type\", \"parity\", \"Specify the type of tracing [geth|parity*] (experimental)\")\n\trootCmd.PersistentFlags().BoolVar(&cfg.WebsocketEnabled, \"ws\", false, \"Enable Websockets\")\n\n\treturn rootCmd, cfg\n}\n\nfunc OpenDB(cfg Flags) (ethdb.KV, ethdb.Backend, error) {\n\tvar db ethdb.KV\n\tvar txPool ethdb.Backend\n\tvar err error\n\t// Do not change the order of these checks. Chaindata needs to be checked first, because PrivateApiAddr has default value which is not \"\"\n\t// If PrivateApiAddr is checked first, the Chaindata option will never work\n\tif cfg.Chaindata != \"\" {\n\t\tif database, errOpen := ethdb.Open(cfg.Chaindata); errOpen == nil {\n\t\t\tdb = database.KV()\n\t\t} else {\n\t\t\terr = errOpen\n\t\t}\n\t} else if cfg.PrivateApiAddr != \"\" {\n\t\tdb, txPool, err = ethdb.NewRemote2().Path(cfg.PrivateApiAddr).Open(cfg.TLSCertfile, cfg.TLSKeyFile, cfg.TLSCACert)\n\t\tif err != nil {\n\t\t\treturn nil, nil, fmt.Errorf(\"could not connect to remoteDb: %w\", err)\n\t\t}\n\t} else {\n\t\treturn nil, nil, fmt.Errorf(\"either remote db or lmdb must be specified\")\n\t}\n\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"could not connect to remoteDb: %w\", err)\n\t}\n\n\treturn db, txPool, err\n}\n\nfunc StartRpcServer(ctx context.Context, cfg Flags, rpcAPI []rpc.API) error {\n\t// register apis and create handler stack\n\thttpEndpoint := fmt.Sprintf(\"%s:%d\", cfg.HttpListenAddress, cfg.HttpPort)\n\n\tsrv := rpc.NewServer()\n\tif err := node.RegisterApisFromWhitelist(rpcAPI, cfg.API, srv, false); err != nil {\n\t\treturn fmt.Errorf(\"could not start register RPC apis: %w\", err)\n\t}\n\n\tvar err error\n\n\thttpHandler := node.NewHTTPHandlerStack(srv, cfg.HttpCORSDomain, cfg.HttpVirtualHost)\n\tvar wsHandler http.Handler\n\tif cfg.WebsocketEnabled {\n\t\twsHandler = srv.WebsocketHandler([]string{\"*\"})\n\t}\n\n\tvar handler http.Handler = http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif cfg.WebsocketEnabled && r.Method == \"GET\" {\n\t\t\twsHandler.ServeHTTP(w, r)\n\t\t}\n\t\thttpHandler.ServeHTTP(w, r)\n\t})\n\n\tlistener, _, err := node.StartHTTPEndpoint(httpEndpoint, rpc.DefaultHTTPTimeouts, handler)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"could not start RPC api: %w\", err)\n\t}\n\n\tif cfg.TraceType != \"parity\" {\n\t\tlog.Info(\"Tracing output type: \", cfg.TraceType)\n\t}\n\tlog.Info(\"HTTP endpoint opened\", \"url\", httpEndpoint, \"ws\", cfg.WebsocketEnabled)\n\n\tdefer func() {\n\t\tsrv.Stop()\n\t\tshutdownCtx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n\t\tdefer cancel()\n\t\t_ = listener.Shutdown(shutdownCtx)\n\t\tlog.Info(\"HTTP endpoint closed\", \"url\", httpEndpoint)\n\t}()\n\t<-ctx.Done()\n\tlog.Info(\"Exiting...\")\n\treturn nil\n}\n", "idx": 1, "id": 21860, "msg": "Do we want to make this part of the default? Probably not. In fact, the default should probably be eth, web3 and net (which are the standard namespaces on other nodes).", "proj": "ledgerwatch-erigon", "lang": "go"}
{"patch": "@@ -280,6 +280,7 @@ ifneq ($(MAKECMDGOALS),clean)\n   ifeq ($(llvm_version),3.9.1)\n   else ifeq ($(llvm_version),5.0.2)\n   else ifeq ($(llvm_version),6.0.1)\n+  else ifeq ($(llvm_version),7.0.0) # this is what is shipped with ubuntu bionic llvm-7 package right now\n   else ifeq ($(llvm_version),7.0.1)\n   else\n     $(warning WARNING: Unsupported LLVM version: $(llvm_version))", "y": 1, "oldf": "# Determine the operating system\nOSTYPE ?=\n\nifeq ($(OS),Windows_NT)\n  OSTYPE = windows\nelse\n  UNAME_S := $(shell uname -s)\n\n  ifeq ($(UNAME_S),Linux)\n    OSTYPE = linux\n\n    ifndef AR\n      ifneq (,$(shell which gcc-ar 2> /dev/null))\n        AR = gcc-ar\n      endif\n    endif\n\n    ALPINE=$(wildcard /etc/alpine-release)\n  endif\n\n  ifeq ($(UNAME_S),Darwin)\n    OSTYPE = osx\n  endif\n\n  ifeq ($(UNAME_S),FreeBSD)\n    OSTYPE = bsd\n    CXX = c++\n  endif\n\n  ifeq ($(UNAME_S),DragonFly)\n    OSTYPE = bsd\n    CXX = c++\n  endif\n\n  ifeq ($(UNAME_S),OpenBSD)\n    OSTYPE = bsd\n    CXX = c++\n  endif\nendif\n\nifdef LTO_PLUGIN\n  lto := yes\nendif\n\n# Default settings (silent release build).\nconfig ?= release\narch ?= native\ntune ?= generic\ncpu ?= $(arch)\nfpu ?=\nbits ?= $(shell getconf LONG_BIT)\n\nifndef verbose\n  SILENT = @\nelse\n  SILENT =\nendif\n\nifneq ($(wildcard .git),)\n  tag := $(shell cat VERSION)-$(shell git rev-parse --short HEAD)\nelse\n  tag := $(shell cat VERSION)\nendif\n\nversion_str = \"$(tag) [$(config)]\\ncompiled with: llvm $(llvm_version) \\\n  -- \"$(compiler_version)\n\n# package_name, _version, and _iteration can be overridden by Travis or AppVeyor\npackage_base_version ?= $(tag)\npackage_iteration ?= \"1\"\npackage_name ?= \"ponyc\"\npackage_version = $(package_base_version)-$(package_iteration)\narchive = $(package_name)-$(package_version).tar\npackage = build/$(package_name)-$(package_version)\n\nprefix ?= /usr/local\nbindir ?= $(prefix)/bin\nincludedir ?= $(prefix)/include\nlibdir ?= $(prefix)/lib\n\n# destdir is for backward compatibility only, use ponydir instead.\nifdef destdir\n  $(warning Please use ponydir instead of destdir.)\n  ponydir ?= $(destdir)\nendif\nponydir ?= $(libdir)/pony/$(tag)\n\nsymlink := yes\n\nifdef ponydir\n  ifndef prefix\n    symlink := no\n  endif\nendif\n\nifneq (,$(filter $(OSTYPE), osx bsd))\n  symlink.flags = -sf\nelse\n  symlink.flags = -srf\nendif\n\nifneq (,$(filter $(OSTYPE), osx bsd))\n  SED_INPLACE = sed -i -e\nelse\n  SED_INPLACE = sed -i\nendif\n\nLIB_EXT ?= a\nBUILD_FLAGS = -march=$(arch) -mtune=$(tune) -Werror -Wconversion \\\n  -Wno-sign-conversion -Wextra -Wall\nLINKER_FLAGS = -march=$(arch) -mtune=$(tune) $(LDFLAGS)\nAR_FLAGS ?= rcs\nALL_CFLAGS = -std=gnu11 -fexceptions \\\n  -DPONY_VERSION=\\\"$(tag)\\\" -DLLVM_VERSION=\\\"$(llvm_version)\\\" \\\n  -DPONY_COMPILER=\\\"$(CC)\\\" -DPONY_ARCH=\\\"$(arch)\\\" \\\n  -DBUILD_COMPILER=\\\"$(compiler_version)\\\" \\\n  -DPONY_BUILD_CONFIG=\\\"$(config)\\\" \\\n  -DPONY_VERSION_STR=\\\"$(version_str)\\\" \\\n  -D_FILE_OFFSET_BITS=64\nALL_CXXFLAGS = -std=gnu++11 -fno-rtti\nLL_FLAGS = -mcpu=$(cpu)\n\n# Determine pointer size in bits.\nBITS := $(bits)\nUNAME_M := $(shell uname -m)\n\nifeq ($(BITS),64)\n  ifeq ($(UNAME_M),x86_64)\n    ifeq (,$(filter $(arch), armv8-a))\n      BUILD_FLAGS += -mcx16\n      LINKER_FLAGS += -mcx16\n    endif\n  endif\nendif\n\nifneq ($(fpu),)\n  BUILD_FLAGS += -mfpu=$(fpu)\n  LINKER_FLAGS += -mfpu=$(fpu)\nendif\n\nPONY_BUILD_DIR   ?= build/$(config)\nPONY_SOURCE_DIR  ?= src\nPONY_TEST_DIR ?= test\nPONY_BENCHMARK_DIR ?= benchmark\n\nifdef use\n  ifneq (,$(filter $(use), valgrind))\n    ALL_CFLAGS += -DUSE_VALGRIND\n    PONY_BUILD_DIR := $(PONY_BUILD_DIR)-valgrind\n  endif\n\n  ifneq (,$(filter $(use), coverage))\n    ifneq (,$(shell $(CC) -v 2>&1 | grep clang))\n      # clang\n      COVERAGE_FLAGS = -O0 -fprofile-instr-generate -fcoverage-mapping\n      LINKER_FLAGS += -fprofile-instr-generate -fcoverage-mapping\n    else\n      ifneq (,$(shell $(CC) -v 2>&1 | grep \"gcc version\"))\n        # gcc\n        COVERAGE_FLAGS = -O0 -fprofile-arcs -ftest-coverage\n        LINKER_FLAGS += -fprofile-arcs\n      else\n        $(error coverage not supported for this compiler/platform)\n      endif\n      ALL_CFLAGS += $(COVERAGE_FLAGS)\n      ALL_CXXFLAGS += $(COVERAGE_FLAGS)\n    endif\n    PONY_BUILD_DIR := $(PONY_BUILD_DIR)-coverage\n  endif\n\n  ifneq (,$(filter $(use), pooltrack))\n    ALL_CFLAGS += -DUSE_POOLTRACK\n    PONY_BUILD_DIR := $(PONY_BUILD_DIR)-pooltrack\n  endif\n\n  ifneq (,$(filter $(use), dtrace))\n    DTRACE ?= $(shell which dtrace)\n    ifeq (, $(DTRACE))\n      $(error No dtrace compatible user application static probe generation tool found)\n    endif\n\n    ALL_CFLAGS += -DUSE_DYNAMIC_TRACE\n    PONY_BUILD_DIR := $(PONY_BUILD_DIR)-dtrace\n  endif\n\n  ifneq (,$(filter $(use), actor_continuations))\n    ALL_CFLAGS += -DUSE_ACTOR_CONTINUATIONS\n    PONY_BUILD_DIR := $(PONY_BUILD_DIR)-actor_continuations\n  endif\n\n  ifneq (,$(filter $(use), scheduler_scaling_pthreads))\n    ALL_CFLAGS += -DUSE_SCHEDULER_SCALING_PTHREADS\n    PONY_BUILD_DIR := $(PONY_BUILD_DIR)-scheduler_scaling_pthreads\n  endif\nendif\n\nifdef config\n  ifeq (,$(filter $(config),debug release))\n    $(error Unknown configuration \"$(config)\")\n  endif\nendif\n\nifeq ($(config),release)\n  BUILD_FLAGS += -O3 -DNDEBUG\n  LL_FLAGS += -O3\n\n  ifeq ($(lto),yes)\n    BUILD_FLAGS += -flto -DPONY_USE_LTO\n    LINKER_FLAGS += -flto\n\n    ifdef LTO_PLUGIN\n      AR_FLAGS += --plugin $(LTO_PLUGIN)\n    endif\n\n    ifneq (,$(filter $(OSTYPE),linux bsd))\n      LINKER_FLAGS += -fuse-linker-plugin -fuse-ld=gold\n    endif\n  endif\nelse\n  BUILD_FLAGS += -g -DDEBUG\nendif\n\nifeq ($(OSTYPE),osx)\n  ALL_CFLAGS += -mmacosx-version-min=10.12 -DUSE_SCHEDULER_SCALING_PTHREADS\n  ALL_CXXFLAGS += -stdlib=libc++ -mmacosx-version-min=10.12\nendif\n\n# If we are not cleaning we need LLVM_CONFIG\nifneq ($(MAKECMDGOALS),clean)\n  ifndef LLVM_CONFIG\n    ifneq (,$(shell which llvm-config 2> /dev/null))\n      LLVM_CONFIG = llvm-config\n    else\n      $(error No LLVM installation found! Set LLVM_CONFIG environment variable \\\n        to the `llvm-config` binary for your installation)\n    endif\n  else ifeq (,$(shell which $(LLVM_CONFIG) 2> /dev/null))\n    $(error LLVM config $(LLVM_CONFIG) not found! Set LLVM_CONFIG environment \\\n        variable to a valid LLVM installation.)\n  endif\n\n  LLVM_BINDIR := $(shell $(LLVM_CONFIG) --bindir 2> /dev/null)\n\n  LLVM_LINK := $(LLVM_BINDIR)/llvm-link\n  LLVM_OPT := $(LLVM_BINDIR)/opt\n  LLVM_LLC := $(LLVM_BINDIR)/llc\n  LLVM_AS := $(LLVM_BINDIR)/llvm-as\n  llvm_build_mode := $(shell $(LLVM_CONFIG) --build-mode)\n  ifeq (Release,$(llvm_build_mode))\n    LLVM_BUILD_MODE=LLVM_BUILD_MODE_Release\n  else ifeq (RelWithDebInfo,$(llvm_build_mode))\n    LLVM_BUILD_MODE=LLVM_BUILD_MODE_RelWithDebInfo\n  else ifeq (MinSizeRel,$(llvm_build_mode))\n    LLVM_BUILD_MODE=LLVM_BUILD_MODE_MinSizeRel\n  else ifeq (Debug,$(llvm_build_mode))\n    LLVM_BUILD_MODE=LLVM_BUILD_MODE_Debug\n  else\n    $(error \"Unknown llvm build-mode of $(llvm_build_mode)\", aborting)\n  endif\n\n  llvm_version := $(shell $(LLVM_CONFIG) --version)\n\n  ifeq (,$(LLVM_LINK_STATIC))\n    ifneq (,$(filter $(use), llvm_link_static))\n      LLVM_LINK_STATIC=--link-static\n      $(warning \"linking llvm statically\")\n    endif\n  endif\n\n  ifeq ($(OSTYPE),osx)\n    ifneq (,$(shell which $(LLVM_BINDIR)/llvm-ar 2> /dev/null))\n      AR = $(LLVM_BINDIR)/llvm-ar\n      AR_FLAGS := rcs\n    else\n      AR = /usr/bin/ar\n      AR_FLAGS := -rcs\n    endif\n  endif\n\n  ifeq ($(llvm_version),3.9.1)\n  else ifeq ($(llvm_version),5.0.2)\n  else ifeq ($(llvm_version),6.0.1)\n  else ifeq ($(llvm_version),7.0.1)\n  else\n    $(warning WARNING: Unsupported LLVM version: $(llvm_version))\n    $(warning Please use LLVM 3.9.1, 5.0.2, 6.0.1, 7.0.1)\n  endif\n\n  # Third party, but prebuilt. Prebuilt libraries are defined as\n  # (1) a name (stored in prebuilt)\n  # (2) the linker flags necessary to link against the prebuilt libraries\n  # (3) a list of include directories for a set of libraries\n  # (4) a list of the libraries to link against\n  llvm.ldflags := -L$(CROSS_SYSROOT)$(subst -L,,$(shell $(LLVM_CONFIG) --ldflags $(LLVM_LINK_STATIC)))\n\n  # Get cflags using llvm-config\n  llvm.get_cflags := $(LLVM_CONFIG) --cflags $(LLVM_LINK_STATIC)\n  #$(warning llvm.get_cflags=\"$(llvm.get_cflags)\")\n  llvm.cflags := $(shell sh -c \"$(llvm.get_cflags)\")\n  #$(warning llvm.cflags=\"$(llvm.cflags)\")\n\n  # Get include dirs using grep & sed to extract \"-I<dir>\" and \"-isystem<dir>\" entries\n  # that can occur anywhere in the string and <dir> may have a leading spaces, but the\n  # regex assumes a directory does NOT contain spaces.\n  # Note: [:space:] is used for greater portability.\n  llvm.get_include_dirs := echo '$(llvm.cflags)' | grep -oE -- '(^-I[[:space:]]*| -I[[:space:]]*|^-isystem[[:space:]]*| -isystem[[:space:]]*)[^[:space:]]+' | sed -E 's/^[[:space:]]*(-I[[:space:]]*|-isystem[[:space:]]*)//'\n  #$(warning llvm.get_include_dirs=\"$(llvm.get_include_dirs)\")\n  llvm.include_dirs := $(shell sh -c \"$(llvm.get_include_dirs)\")\n  #$(warning llvm.include_dirs=\"$(llvm.include_dirs)\")\n\n  # Get the compiler output of verbose \"-v\" and preprocess, \"-E\" parameters which\n  # contains the search paths.\n  verbose_preprocess_string := $(shell echo | $(CC) -v -E - 2>&1)\n  #$(warning verbose_preprocess_string=\"$(verbose_preprocess_string)\")\n\n  # We must escape any double quotes, \", and any hash, #, characters.\n  quoteDblQuote := $(subst \",\\\",$(verbose_preprocess_string))\n  #$(warning quoteDblQuote=\"$(quoteDblQuote)\")\n  quoted_verbose_preprocess_string := $(subst \\#,\\\\\\#,$(quoteDblQuote))\n  #$(warning quoted_verbose_preprocess_string=\"$(quoted_verbose_preprocess_string)\")\n\n  # Now use a sed command line to extract the search paths from the\n  # quoted verbose preprocess string\n  get_search_paths := sed 's/\\(.*\\)search starts here:\\(.*\\)End of search list.\\(.*\\)/\\2/'\n  #$(warning get_search_paths=\"$(get_search_paths)\")\n  search_paths := $(shell echo \"$(quoted_verbose_preprocess_string)\" | $(get_search_paths))\n  #$(warning search_paths=\"$(search_paths)\")\n\n  # Note: $(search_paths) is padded with a space on front and back so\n  # that when we iterate the ${inc_dir} variable is guaranteed to have\n  # a space at the beginning and end making finding a match easy. If\n  # there is no match we output the ${inc_dir}.\n  loopit :=\t\t\t\t\t\t\t\t\t\\\n\tfor inc_dir in $(llvm.include_dirs); do\t\t\t\t\t\\\n\t\tif ! echo \" $(search_paths) \" | grep -q \" $${inc_dir} \"; then\t\\\n\t\t\techo \"-isystem $(CROSS_SYSROOT)$${inc_dir}\";\t\t\\\n\t\tfi\t\t\t\t\t\t\t\t\\\n\tdone\n\n  #$(warning loopit=\"$(loopit)\")\n  llvm.include = $(shell $(loopit))\n  #$(warning llvm.include=\"$(llvm.include)\")\n\n  llvm.libs    := $(shell $(LLVM_CONFIG) --libs $(LLVM_LINK_STATIC)) -lz -lncurses\nendif\n\ncompiler_version := \"$(shell $(CC) --version | sed -n 1p)\"\n\nifeq ($(runtime-bitcode),yes)\n  ifeq (,$(shell $(CC) -v 2>&1 | grep clang))\n    $(error Compiling the runtime as a bitcode file requires clang)\n  endif\nendif\n\n# Set default ssl version\nifdef default_ssl\n  ifeq (\"openssl_0.9.0\",\"$(default_ssl)\")\n    default_ssl_valid:=ok\n  endif\n  ifeq (\"openssl_1.1.0\",\"$(default_ssl)\")\n    default_ssl_valid:=ok\n  endif\n  ifeq (ok,$(default_ssl_valid))\n    $(warning default_ssl is $(default_ssl))\n  else\n    $(error default_ssl=$(default_ssl) is invalid, expecting one of openssl_0.9.0 or openssl_1.1.0)\n  endif\n  BUILD_FLAGS += -DPONY_DEFAULT_SSL=\\\"$(default_ssl)\\\"\nendif\n\nmakefile_abs_path := $(realpath $(lastword $(MAKEFILE_LIST)))\npackages_abs_src := $(shell dirname $(makefile_abs_path))/packages\n\n$(shell mkdir -p $(PONY_BUILD_DIR))\n\nlib   := $(PONY_BUILD_DIR)/lib/$(arch)\nbin   := $(PONY_BUILD_DIR)\ntests := $(PONY_BUILD_DIR)\nbenchmarks := $(PONY_BUILD_DIR)\nobj   := $(PONY_BUILD_DIR)/obj-$(arch)\n\n# Libraries. Defined as\n# (1) a name and output directory\nlibponyc  := $(lib)\nlibponycc := $(lib)\nlibponyrt := $(lib)\n\nifeq ($(OSTYPE),linux)\n  libponyrt-pic := $(lib)\nendif\n\n# Define special case rules for a targets source files. By default\n# this makefile assumes that a targets source files can be found\n# relative to a parent directory of the same name in $(PONY_SOURCE_DIR).\n# Note that it is possible to collect files and exceptions with\n# arbitrarily complex shell commands, as long as ':=' is used\n# for definition, instead of '='.\nifneq ($(OSTYPE),windows)\n  libponyc.except += src/libponyc/platform/signed.cc\n  libponyc.except += src/libponyc/platform/unsigned.cc\n  libponyc.except += src/libponyc/platform/vcvars.c\nendif\n\n# Handle platform specific code to avoid \"no symbols\" warnings.\nlibponyrt.except =\n\nifneq ($(OSTYPE),windows)\n  libponyrt.except += src/libponyrt/asio/iocp.c\n  libponyrt.except += src/libponyrt/lang/win_except.c\nendif\n\nifneq ($(OSTYPE),linux)\n  libponyrt.except += src/libponyrt/asio/epoll.c\nendif\n\nifneq ($(OSTYPE),osx)\n  ifneq ($(OSTYPE),bsd)\n    libponyrt.except += src/libponyrt/asio/kqueue.c\n  endif\nendif\n\nlibponyrt.except += src/libponyrt/asio/sock.c\nlibponyrt.except += src/libponyrt/dist/dist.c\nlibponyrt.except += src/libponyrt/dist/proto.c\n\nifeq ($(OSTYPE),linux)\n  libponyrt-pic.dir := src/libponyrt\n  libponyrt-pic.except := $(libponyrt.except)\nendif\n\n# Third party, but requires compilation. Defined as\n# (1) a name and output directory.\n# (2) a list of the source files to be compiled.\nlibgtest := $(lib)\nlibgtest.dir := lib/gtest\nlibgtest.files := $(libgtest.dir)/gtest-all.cc\nlibgbenchmark := $(lib)\nlibgbenchmark.dir := lib/gbenchmark\nlibgbenchmark.srcdir := $(libgbenchmark.dir)/src\n\nlibblake2 := $(lib)\nlibblake2.dir := lib/blake2\nlibblake2.files := $(libblake2.dir)/blake2b-ref.c\n\n# We don't add libponyrt here. It's a special case because it can be compiled\n# to LLVM bitcode.\nifeq ($(OSTYPE), linux)\n  libraries := libponyc libponyrt-pic libgtest libgbenchmark libblake2\nelse\n  libraries := libponyc libgtest libgbenchmark libblake2\nendif\n\nifeq ($(OSTYPE), bsd)\n  extra.bsd.libs = -lpthread -lexecinfo\n  llvm.libs += $(extra.bsd.libs)\nendif\n\nprebuilt := llvm\n\n# Binaries. Defined as\n# (1) a name and output directory.\nponyc := $(bin)\n\nbinaries := ponyc\n\n# Tests suites are directly attached to the libraries they test.\nlibponyc.tests  := $(tests)\nlibponyrt.tests := $(tests)\n\ntests := libponyc.tests libponyrt.tests\n\n# Benchmark suites are directly attached to the libraries they test.\nlibponyc.benchmarks  := $(benchmarks)\nlibponyc.benchmarks.dir := benchmark/libponyc\nlibponyc.benchmarks.srcdir := $(libponyc.benchmarks.dir)\nlibponyrt.benchmarks := $(benchmarks)\nlibponyrt.benchmarks.dir := benchmark/libponyrt\nlibponyrt.benchmarks.srcdir := $(libponyrt.benchmarks.dir)\n\nbenchmarks := libponyc.benchmarks libponyrt.benchmarks\n\n# Define include paths for targets if necessary. Note that these include paths\n# will automatically apply to the test suite of a target as well.\nlibponyc.include := -I src/common/ -I src/libponyrt/ $(llvm.include) \\\n  -isystem lib/blake2\nlibponycc.include := -I src/common/ $(llvm.include)\nlibponyrt.include := -I src/common/ -I src/libponyrt/\nlibponyrt-pic.include := $(libponyrt.include)\n\nlibponyc.tests.include := -I src/common/ -I src/libponyc/ -I src/libponyrt \\\n  $(llvm.include) -isystem lib/gtest/\nlibponyrt.tests.include := -I src/common/ -I src/libponyrt/ -isystem lib/gtest/\n\nlibponyc.benchmarks.include := -I src/common/ -I src/libponyc/ \\\n  $(llvm.include) -isystem lib/gbenchmark/include/\nlibponyrt.benchmarks.include := -I src/common/ -I src/libponyrt/ -isystem \\\n  lib/gbenchmark/include/\n\nponyc.include := -I src/common/ -I src/libponyrt/ $(llvm.include)\nlibgtest.include := -isystem lib/gtest/\nlibgbenchmark.include := -isystem lib/gbenchmark/include/\nlibblake2.include := -isystem lib/blake2/\n\nifneq (,$(filter $(OSTYPE), osx bsd))\n  libponyrt.include += -I $(CROSS_SYSROOT)/usr/local/include\nendif\n\n# target specific build options\nlibponyrt.tests.linkoptions += -rdynamic\n\nifneq ($(ALPINE),)\n  libponyrt.tests.linkoptions += -lexecinfo\nendif\n\nlibponyc.buildoptions = -D__STDC_CONSTANT_MACROS\nlibponyc.buildoptions += -D__STDC_FORMAT_MACROS\nlibponyc.buildoptions += -D__STDC_LIMIT_MACROS\nlibponyc.buildoptions += -DPONY_ALWAYS_ASSERT\nlibponyc.buildoptions += -DLLVM_BUILD_MODE=$(LLVM_BUILD_MODE)\n\nlibponyc.tests.buildoptions = -D__STDC_CONSTANT_MACROS\nlibponyc.tests.buildoptions += -D__STDC_FORMAT_MACROS\nlibponyc.tests.buildoptions += -D__STDC_LIMIT_MACROS\nlibponyc.tests.buildoptions += -DPONY_ALWAYS_ASSERT\nlibponyc.tests.buildoptions += -DPONY_PACKAGES_DIR=\\\"$(packages_abs_src)\\\"\nlibponyc.tests.buildoptions += -DLLVM_BUILD_MODE=$(LLVM_BUILD_MODE)\n\nlibponyc.tests.linkoptions += -rdynamic\n\nifneq ($(ALPINE),)\n  libponyc.tests.linkoptions += -lexecinfo\nendif\n\nlibponyc.benchmarks.buildoptions = -D__STDC_CONSTANT_MACROS\nlibponyc.benchmarks.buildoptions += -D__STDC_FORMAT_MACROS\nlibponyc.benchmarks.buildoptions += -D__STDC_LIMIT_MACROS\nlibponyc.benchmarks.buildoptions += -DLLVM_BUILD_MODE=$(LLVM_BUILD_MODE)\n\nlibgbenchmark.buildoptions := \\\n  -Wshadow -pedantic -pedantic-errors \\\n  -Wfloat-equal -fstrict-aliasing -Wstrict-aliasing -Wno-invalid-offsetof \\\n  -DHAVE_POSIX_REGEX -DHAVE_STD_REGEX -DHAVE_STEADY_CLOCK\n\nifneq ($(ALPINE),)\n  libponyc.benchmarks.linkoptions += -lexecinfo\n  libponyrt.benchmarks.linkoptions += -lexecinfo\nendif\n\nponyc.buildoptions = $(libponyc.buildoptions)\n\nponyc.linkoptions += -rdynamic\n\nifneq ($(ALPINE),)\n  ponyc.linkoptions += -lexecinfo\n  BUILD_FLAGS += -DALPINE_LINUX\nendif\n\nifeq ($(OSTYPE), linux)\n  libponyrt-pic.buildoptions += -fpic\n  libponyrt-pic.buildoptions-ll += -relocation-model=pic\nendif\n\n# Set default PIC for compiling if requested\nifdef default_pic\n  ifeq (true,$(default_pic))\n    libponyrt.buildoptions += -fpic\n    libponyrt.buildoptions-ll += -relocation-model=pic\n    BUILD_FLAGS += -DPONY_DEFAULT_PIC=true\n  else\n    ifneq (false,$(default_pic))\n      $(error default_pic must be true or false)\n    endif\n  endif\nendif\n\n# target specific disabling of build options\nlibgtest.disable = -Wconversion -Wno-sign-conversion -Wextra\nlibgbenchmark.disable = -Wconversion -Wno-sign-conversion\nlibblake2.disable = -Wconversion -Wno-sign-conversion -Wextra\n\n# Link relationships.\nponyc.links = libponyc libponyrt llvm libblake2\nlibponyc.tests.links = libgtest libponyc llvm libblake2\nlibponyc.tests.links.whole = libponyrt\nlibponyrt.tests.links = libgtest libponyrt\nlibponyc.benchmarks.links = libblake2 libgbenchmark libponyc libponyrt llvm\nlibponyrt.benchmarks.links = libgbenchmark libponyrt\n\nifeq ($(OSTYPE),linux)\n  ponyc.links += libpthread libdl libatomic\n  libponyc.tests.links += libpthread libdl libatomic\n  libponyrt.tests.links += libpthread libdl libatomic\n  libponyc.benchmarks.links += libpthread libdl libatomic\n  libponyrt.benchmarks.links += libpthread libdl libatomic\nendif\n\nifeq ($(OSTYPE),bsd)\n  libponyc.tests.links += libpthread\n  libponyrt.tests.links += $(extra.bsd.libs)\n  libponyc.benchmarks.links += libpthread\n  libponyrt.benchmarks.links += $(extra.bsd.libs)\nendif\n\nifneq (, $(DTRACE))\n  $(shell $(DTRACE) -h -s $(PONY_SOURCE_DIR)/common/dtrace_probes.d -o $(PONY_SOURCE_DIR)/common/dtrace_probes.h)\nendif\n\n# Overwrite the default linker for a target.\nponyc.linker = $(CXX) #compile as C but link as CPP (llvm)\nlibponyc.benchmarks.linker = $(CXX)\nlibponyrt.benchmarks.linker = $(CXX)\n\n# make targets\ntargets := $(libraries) libponyrt $(binaries) $(tests) $(benchmarks)\n\n.PHONY: all $(targets) install uninstall clean stats deploy prerelease check-version test-core test-stdlib-debug test-stdlib test-examples validate-grammar test-ci test-cross-ci benchmark stdlib stdlib-debug\nall: $(targets)\n\t@:\n\n# Dependencies\nlibponyc.depends := libponyrt libblake2\nlibponyc.tests.depends := libponyc libgtest\nlibponyrt.tests.depends := libponyrt libgtest\nlibponyc.benchmarks.depends := libponyc libgbenchmark\nlibponyrt.benchmarks.depends := libponyrt libgbenchmark\nponyc.depends := libponyc libponyrt\n\n# Generic make section, edit with care.\n##########################################################################\n#                                                                        #\n# DIRECTORY: Determines the source dir of a specific target              #\n#                                                                        #\n# ENUMERATE: Enumerates input and output files for a specific target     #\n#                                                                        #\n# CONFIGURE_COMPILER: Chooses a C or C++ compiler depending on the       #\n#                     target file.                                       #\n#                                                                        #\n# CONFIGURE_LIBS: Builds a string of libraries to link for a targets     #\n#                 link dependency.                                       #\n#                                                                        #\n# CONFIGURE_LINKER: Assembles the linker flags required for a target.    #\n#                                                                        #\n# EXPAND_COMMAND: Macro that expands to a proper make command for each   #\n#                 target.                                                #\n#                                                                        #\n##########################################################################\ndefine DIRECTORY\n  $(eval sourcedir := )\n  $(eval outdir := $(obj)/$(1))\n\n  ifdef $(1).srcdir\n    sourcedir := $($(1).srcdir)\n  else ifdef $(1).dir\n    sourcedir := $($(1).dir)\n  else ifneq ($$(filter $(1),$(tests)),)\n    sourcedir := $(PONY_TEST_DIR)/$(subst .tests,,$(1))\n    outdir := $(obj)/tests/$(subst .tests,,$(1))\n  else ifneq ($$(filter $(1),$(benchmarks)),)\n    sourcedir := $(PONY_BENCHMARK_DIR)/$(subst .benchmarks,,$(1))\n    outdir := $(obj)/benchmarks/$(subst .benchmarks,,$(1))\n  else\n    sourcedir := $(PONY_SOURCE_DIR)/$(1)\n  endif\nendef\n\ndefine ENUMERATE\n  $(eval sourcefiles := )\n\n  ifdef $(1).files\n    sourcefiles := $$($(1).files)\n  else\n    sourcefiles := $$(shell find $$(sourcedir) -type f -name \"*.c\" -or -name\\\n      \"*.cc\" -or -name \"*.ll\" | grep -v '.*/\\.')\n  endif\n\n  ifdef $(1).except\n    sourcefiles := $$(filter-out $($(1).except),$$(sourcefiles))\n  endif\nendef\n\ndefine CONFIGURE_COMPILER\n  ifeq ($(suffix $(1)),.cc)\n    compiler := $(CXX)\n    flags := $(ALL_CXXFLAGS) $(CXXFLAGS)\n  endif\n\n  ifeq ($(suffix $(1)),.c)\n    compiler := $(CC)\n    flags := $(ALL_CFLAGS) $(CFLAGS)\n  endif\n\n  ifeq ($(suffix $(1)),.bc)\n    compiler := $(CC)\n    flags := $(ALL_CFLAGS) $(CFLAGS)\n  endif\n\n  ifeq ($(suffix $(1)),.ll)\n    compiler := $(CC)\n    flags := $(ALL_CFLAGS) $(CFLAGS) -Wno-override-module\n  endif\nendef\n\ndefine CONFIGURE_LIBS\n  ifneq (,$$(filter $(1),$(prebuilt)))\n    linkcmd += $($(1).ldflags)\n    libs += $($(1).libs)\n  else\n    libs += $(subst lib,-l,$(1))\n  endif\nendef\n\ndefine CONFIGURE_LIBS_WHOLE\n  ifeq ($(OSTYPE),osx)\n    wholelibs += -Wl,-force_load,$(lib)/$(1).a\n  else\n    wholelibs += $(subst lib,-l,$(1))\n  endif\nendef\n\ndefine CONFIGURE_LINKER_WHOLE\n  $(eval wholelibs :=)\n\n  ifneq ($($(1).links.whole),)\n    $(foreach lk,$($(1).links.whole),$(eval $(call CONFIGURE_LIBS_WHOLE,$(lk))))\n    ifeq ($(OSTYPE),osx)\n      libs += $(wholelibs)\n    else\n      libs += -Wl,--whole-archive $(wholelibs) -Wl,--no-whole-archive\n    endif\n  endif\nendef\n\ndefine CONFIGURE_LINKER\n  $(eval linkcmd := $(LINKER_FLAGS) -L $(lib))\n  $(eval linker := $(CC))\n  $(eval libs :=)\n\n  ifdef $(1).linker\n    linker := $($(1).linker)\n  else ifneq (,$$(filter .cc,$(suffix $(sourcefiles))))\n    linker := $(CXX)\n  endif\n\n  $(eval $(call CONFIGURE_LINKER_WHOLE,$(1)))\n  $(foreach lk,$($(1).links),$(eval $(call CONFIGURE_LIBS,$(lk))))\n  linkcmd += $(libs) -L $(CROSS_SYSROOT)/usr/local/lib $($(1).linkoptions)\nendef\n\ndefine PREPARE\n  $(eval $(call DIRECTORY,$(1)))\n  $(eval $(call ENUMERATE,$(1)))\n  $(eval $(call CONFIGURE_LINKER,$(1)))\n  $(eval objectfiles  := $(subst $(sourcedir)/,$(outdir)/,$(addsuffix .o,\\\n    $(sourcefiles))))\n  $(eval bitcodefiles := $(subst .o,.bc,$(objectfiles)))\n  $(eval dependencies := $(subst .c,,$(subst .cc,,$(subst .ll,,$(subst .o,.d,\\\n    $(objectfiles))))))\nendef\n\ndefine EXPAND_OBJCMD\n$(eval file := $(subst .o,,$(1)))\n$(eval $(call CONFIGURE_COMPILER,$(file)))\n\nifeq ($(3),libponyrtyes)\n  ifneq ($(suffix $(file)),.bc)\n$(subst .c,,$(subst .cc,,$(subst .ll,,$(1)))): $(subst .c,.bc,$(subst .cc,.bc,$(subst .ll,.bc,$(file))))\n\t@echo '$$(notdir $$<)'\n\t@mkdir -p $$(dir $$@)\n\t$(SILENT)$(compiler) $(flags) -c -o $$@ $$<\n  else ifeq ($(suffix $(subst .bc,,$(file))),.ll)\n$(subst .ll,,$(1)): $(subst $(outdir)/,$(sourcedir)/,$(subst .bc,,$(file)))\n\t@echo '$$(notdir $$<)'\n\t@mkdir -p $$(dir $$@)\n\t$(SILENT)$(LLVM_AS) -o $$@ $$<\n  else\n$(subst .c,,$(subst .cc,,$(1))): $(subst $(outdir)/,$(sourcedir)/,$(subst .bc,,$(file)))\n\t@echo '$$(notdir $$<)'\n\t@mkdir -p $$(dir $$@)\n\t$(SILENT)$(compiler) -MMD -MP $(filter-out $($(2).disable),$(BUILD_FLAGS)) \\\n    $(flags) $($(2).buildoptions) -emit-llvm -c -o $$@ $$<  $($(2).include)\n  endif\nelse ifeq ($(suffix $(file)),.ll)\n$(subst .ll,,$(1)): $(subst $(outdir)/,$(sourcedir)/,$(file))\n\t@echo '$$(notdir $$<)'\n\t@mkdir -p $$(dir $$@)\n\t$(SILENT)$(LLVM_LLC) $(LL_FLAGS) $($(2).buildoptions-ll) -filetype=obj -o $$@ $$<\nelse\n$(subst .c,,$(subst .cc,,$(1))): $(subst $(outdir)/,$(sourcedir)/,$(file))\n\t@echo '$$(notdir $$<)'\n\t@mkdir -p $$(dir $$@)\n\t$(SILENT)$(compiler) -MMD -MP $(filter-out $($(2).disable),$(BUILD_FLAGS)) \\\n    $(flags) $($(2).buildoptions) -c -o $$@ $$<  $($(2).include)\nendif\nendef\n\ndefine EXPAND_COMMAND\n$(eval $(call PREPARE,$(1)))\n$(eval ofiles := $(subst .c,,$(subst .cc,,$(subst .ll,,$(objectfiles)))))\n$(eval bcfiles := $(subst .c,,$(subst .cc,,$(subst .ll,,$(bitcodefiles)))))\n$(eval depends := )\n$(foreach d,$($(1).depends),$(eval depends += $($(d))/$(d).$(LIB_EXT)))\n\nifeq ($(1),libponyrt)\n$($(1))/libponyrt.$(LIB_EXT): $(depends) $(ofiles)\n\t@mkdir -p $$(dir $$@)\n\t@echo 'Linking libponyrt'\n    ifneq (,$(DTRACE))\n    ifeq ($(OSTYPE), linux)\n\t@echo 'Generating dtrace object file (linux)'\n\t$(SILENT)$(DTRACE) -G -s $(PONY_SOURCE_DIR)/common/dtrace_probes.d -o $(PONY_BUILD_DIR)/dtrace_probes.o\n\t$(SILENT)$(AR) $(AR_FLAGS) $$@ $(ofiles) $(PONY_BUILD_DIR)/dtrace_probes.o\n    else ifeq ($(OSTYPE), bsd)\n\t@echo 'Generating dtrace object file (bsd)'\n\t$(SILENT)rm -f $(PONY_BUILD_DIR)/dtrace_probes.o\n\t$(SILENT)$(DTRACE) -G -s $(PONY_SOURCE_DIR)/common/dtrace_probes.d -o $(PONY_BUILD_DIR)/dtrace_probes.o $(ofiles)\n\t$(SILENT)$(AR) $(AR_FLAGS) $$@ $(ofiles) $(PONY_BUILD_DIR)/dtrace_probes.o\n\t$(SILENT)$(AR) $(AR_FLAGS) $(lib)/libdtrace_probes.a $(PONY_BUILD_DIR)/dtrace_probes.o\n    else\n\t$(SILENT)$(AR) $(AR_FLAGS) $$@ $(ofiles)\n    endif\n    else\n\t$(SILENT)$(AR) $(AR_FLAGS) $$@ $(ofiles)\n    endif\n  ifeq ($(runtime-bitcode),yes)\n$($(1))/libponyrt.bc: $(depends) $(bcfiles)\n\t@mkdir -p $$(dir $$@)\n\t@echo 'Generating bitcode for libponyrt'\n\t$(SILENT)$(LLVM_LINK) -o $$@ $(bcfiles)\n    ifeq ($(config),release)\n\t$(SILENT)$(LLVM_OPT) -O3 -o $$@ $$@\n    endif\nlibponyrt: $($(1))/libponyrt.bc $($(1))/libponyrt.$(LIB_EXT)\n  else\nlibponyrt: $($(1))/libponyrt.$(LIB_EXT)\n  endif\nelse ifneq ($(filter $(1),$(libraries)),)\n$($(1))/$(1).$(LIB_EXT): $(depends) $(ofiles)\n\t@mkdir -p $$(dir $$@)\n\t@echo 'Linking $(1)'\n\t$(SILENT)$(AR) $(AR_FLAGS) $$@ $(ofiles)\n$(1): $($(1))/$(1).$(LIB_EXT)\nelse\n$($(1))/$(1): $(depends) $(ofiles)\n\t@mkdir -p $$(dir $$@)\n\t@echo 'Linking $(1)'\n\t$(SILENT)$(linker) -o $$@ $(ofiles) $(linkcmd)\n$(1): $($(1))/$(1)\nendif\n\n$(foreach bcfile,$(bitcodefiles),$(eval $(call EXPAND_OBJCMD,$(bcfile),$(1),$(addsuffix $(runtime-bitcode),$(1)))))\n$(foreach ofile,$(objectfiles),$(eval $(call EXPAND_OBJCMD,$(ofile),$(1),$(addsuffix $(runtime-bitcode),$(1)))))\n-include $(dependencies)\nendef\n\n$(foreach target,$(targets),$(eval $(call EXPAND_COMMAND,$(target))))\n\n\ndefine EXPAND_INSTALL\nifeq ($(OSTYPE),linux)\ninstall-libponyrt-pic: libponyrt-pic\n\t@mkdir -p $(destdir)/lib/$(arch)\n\t$(SILENT)cp $(lib)/libponyrt-pic.a $(DESTDIR)$(ponydir)/lib/$(arch)\nendif\ninstall-libponyrt: libponyrt\n\t@mkdir -p $(destdir)/lib/$(arch)\n\t$(SILENT)cp $(lib)/libponyrt.a $(DESTDIR)$(ponydir)/lib/$(arch)\nifeq ($(OSTYPE),linux)\ninstall: libponyc libponyrt libponyrt-pic ponyc\nelse\ninstall: libponyc libponyrt ponyc\nendif\n\t@mkdir -p $(DESTDIR)$(ponydir)/bin\n\t@mkdir -p $(DESTDIR)$(ponydir)/lib/$(arch)\n\t@mkdir -p $(DESTDIR)$(ponydir)/include/pony/detail\n\t$(SILENT)cp $(lib)/libponyrt.a $(DESTDIR)$(ponydir)/lib/$(arch)\nifeq ($(OSTYPE),linux)\n\t$(SILENT)cp $(lib)/libponyrt-pic.a $(DESTDIR)$(ponydir)/lib/$(arch)\nendif\nifneq ($(wildcard $(PONY_BUILD_DIR)/lib/$(arch)/libponyrt.bc),)\n\t$(SILENT)cp $(PONY_BUILD_DIR)/lib/$(arch)/libponyrt.bc $(DESTDIR)$(ponydir)/lib/$(arch)\nendif\nifneq ($(wildcard $(lib)/libdtrace_probes.a),)\n\t$(SILENT)cp $(lib)/libdtrace_probes.a $(DESTDIR)$(ponydir)/lib/$(arch)\nendif\n\t$(SILENT)cp $(lib)/libponyc.a $(DESTDIR)$(ponydir)/lib/$(arch)\n\t$(SILENT)cp $(bin)/ponyc $(DESTDIR)$(ponydir)/bin\n\t$(SILENT)cp src/libponyrt/pony.h $(DESTDIR)$(ponydir)/include\n\t$(SILENT)cp src/common/pony/detail/atomics.h $(DESTDIR)$(ponydir)/include/pony/detail\n\t$(SILENT)cp -r packages $(DESTDIR)$(ponydir)/\nifeq ($$(symlink),yes)\n\t@mkdir -p $(DESTDIR)$(bindir)\n\t@mkdir -p $(DESTDIR)$(libdir)\n\t@mkdir -p $(DESTDIR)$(includedir)/pony/detail\n\t$(SILENT)ln $(symlink.flags) $(ponydir)/bin/ponyc $(DESTDIR)$(bindir)/ponyc\n\t$(SILENT)ln $(symlink.flags) $(ponydir)/lib/$(arch)/libponyrt.a $(DESTDIR)$(libdir)/libponyrt.a\nifeq ($(OSTYPE),linux)\n\t$(SILENT)ln $(symlink.flags) $(ponydir)/lib/$(arch)/libponyrt-pic.a $(DESTDIR)$(libdir)/libponyrt-pic.a\nendif\nifneq ($(wildcard $(DESTDIR)$(ponydir)/lib/libponyrt.bc),)\n\t$(SILENT)ln $(symlink.flags) $(ponydir)/lib/libponyrt.bc $(DESTDIR)$(libdir)/libponyrt.bc\nendif\nifneq ($(wildcard $(PONY_BUILD_DIR)/libdtrace_probes.a),)\n\t$(SILENT)ln $(symlink.flags) $(ponydir)/lib/$(arch)/libdtrace_probes.a $(DESTDIR)$(libdir)/libdtrace_probes.a\nendif\n\t$(SILENT)ln $(symlink.flags) $(ponydir)/lib/$(arch)/libponyc.a $(DESTDIR)$(libdir)/libponyc.a\n\t$(SILENT)ln $(symlink.flags) $(ponydir)/include/pony.h $(DESTDIR)$(includedir)/pony.h\n\t$(SILENT)ln $(symlink.flags) $(ponydir)/include/pony/detail/atomics.h $(DESTDIR)$(includedir)/pony/detail/atomics.h\nendif\nendef\n\n$(eval $(call EXPAND_INSTALL))\n\ndefine EXPAND_UNINSTALL\nuninstall:\n\t-$(SILENT)rm -rf $(ponydir) 2>/dev/null ||:\n\t-$(SILENT)rm $(bindir)/ponyc 2>/dev/null ||:\n\t-$(SILENT)rm $(libdir)/libponyrt.a 2>/dev/null ||:\nifeq ($(OSTYPE),linux)\n\t-$(SILENT)rm $(libdir)/libponyrt-pic.a 2>/dev/null ||:\nendif\nifneq ($(wildcard $(libdir)/libponyrt.bc),)\n\t-$(SILENT)rm $(libdir)/libponyrt.bc 2>/dev/null ||:\nendif\nifneq ($(wildcard $(libdir)/libdtrace_probes.a),)\n\t-$(SILENT)rm $(libdir)/libdtrace_probes.a 2>/dev/null ||:\nendif\n\t-$(SILENT)rm $(libdir)/libponyc.a 2>/dev/null ||:\n\t-$(SILENT)rm $(includedir)/pony.h 2>/dev/null ||:\n\t-$(SILENT)rm -r $(includedir)/pony/ 2>/dev/null ||:\nendef\n\n$(eval $(call EXPAND_UNINSTALL))\n\nifdef verbose\n  bench_verbose = -DCMAKE_VERBOSE_MAKEFILE=true\nendif\n\nifeq ($(lto),yes)\n  bench_lto = -DBENCHMARK_ENABLE_LTO=true\nendif\n\nbenchmark: all\n\t$(SILENT)echo \"Running libponyc benchmarks...\"\n\t$(SILENT)$(PONY_BUILD_DIR)/libponyc.benchmarks\n\t$(SILENT)echo \"Running libponyrt benchmarks...\"\n\t$(SILENT)(PONY_BUILD_DIR)/libponyrt.benchmarks\n\nstdlib-debug: all\n\t$(SILENT)PONYPATH=.:$(PONYPATH) $(PONY_BUILD_DIR)/ponyc $(cross_args) -d -s --checktree --verify packages/stdlib\n\nstdlib: all\n\t$(SILENT)PONYPATH=.:$(PONYPATH) $(PONY_BUILD_DIR)/ponyc $(cross_args) --checktree --verify packages/stdlib\n\ntest-stdlib-debug: stdlib-debug\n\t$(SILENT)$(cross_runner) ./stdlib --sequential\n\t$(SILENT)rm stdlib\n\ntest-stdlib: stdlib\n\t$(SILENT)$(cross_runner) ./stdlib --sequential\n\t$(SILENT)rm stdlib\n\ntest-core: all\n\t$(SILENT)$(PONY_BUILD_DIR)/libponyc.tests\n\t$(SILENT)$(PONY_BUILD_DIR)/libponyrt.tests\n\ntest: test-core test-stdlib test-examples\n\ntest-examples: all\n\t$(SILENT)PONYPATH=.:$(PONYPATH) find examples/*/* -name '*.pony' -print | xargs -n 1 dirname  | sort -u | grep -v ffi- | xargs -n 1 -I {} $(PONY_BUILD_DIR)/ponyc $(cross_args) -d -s --checktree -o {} {}\n\ncheck-version: all\n\t$(SILENT)$(PONY_BUILD_DIR)/ponyc --version\n\nvalidate-grammar: all\n\t$(SILENT)$(PONY_BUILD_DIR)/ponyc --antlr > pony.g.new\n\t$(SILENT)diff pony.g pony.g.new\n\t$(SILENT)rm pony.g.new\n\ntest-ci: all check-version test-core test-stdlib-debug test-stdlib test-examples validate-grammar\n\ntest-cross-ci: cross_args=--triple=$(cross_triple) --cpu=$(cross_cpu) --link-arch=$(cross_arch) --linker='$(cross_linker)'\ntest-cross-ci: cross_runner=$(QEMU_RUNNER)\ntest-cross-ci: test-ci\n\ndocs: all\n\t$(SILENT)$(PONY_BUILD_DIR)/ponyc packages/stdlib --docs --pass expr\n\ndocs-online: docs\n\t$(SILENT)$(SED_INPLACE) 's/site_name:\\ stdlib/site_name:\\ Pony Standard Library/' stdlib-docs/mkdocs.yml\n\n# Note: linux only\ndefine EXPAND_DEPLOY\ndeploy: test docs\n\t$(SILENT)bash .bintray.bash debian \"$(package_base_version)\" \"$(package_name)\"\n\t$(SILENT)bash .bintray.bash rpm    \"$(package_base_version)\" \"$(package_name)\"\n\t$(SILENT)bash .bintray.bash source \"$(package_base_version)\" \"$(package_name)\"\n\t$(SILENT)rm -rf build/bin\n\t@mkdir -p build/bin\n\t@mkdir -p $(package)/usr/bin\n\t@mkdir -p $(package)/usr/include/pony/detail\n\t@mkdir -p $(package)/usr/lib\n\t@mkdir -p $(package)/usr/lib/pony/$(package_version)/bin\n\t@mkdir -p $(package)/usr/lib/pony/$(package_version)/include/pony/detail\n\t@mkdir -p $(package)/usr/lib/pony/$(package_version)/lib\n\t$(SILENT)cp $(PONY_BUILD_DIR)/lib/$(arch)/libponyc.a $(package)/usr/lib/pony/$(package_version)/lib\n\t$(SILENT)cp $(PONY_BUILD_DIR)/lib/$(arch)/libponyrt.a $(package)/usr/lib/pony/$(package_version)/lib\nifeq ($(OSTYPE),linux)\n\t$(SILENT)cp $(PONY_BUILD_DIR)/lib/$(arch)/libponyrt-pic.a $(package)/usr/lib/pony/$(package_version)/lib\nendif\nifneq ($(wildcard $(PONY_BUILD_DIR)/libponyrt.bc),)\n\t$(SILENT)cp $(PONY_BUILD_DIR)/libponyrt.bc $(package)/usr/lib/pony/$(package_version)/lib\nendif\nifneq ($(wildcard $(PONY_BUILD_DIR)/libdtrace_probes.a),)\n\t$(SILENT)cp $(PONY_BUILD_DIR)/lib/$(arch)/libdtrace_probes.a $(package)/usr/lib/pony/$(package_version)/lib\nendif\n\t$(SILENT)cp $(PONY_BUILD_DIR)/ponyc $(package)/usr/lib/pony/$(package_version)/bin\n\t$(SILENT)cp src/libponyrt/pony.h $(package)/usr/lib/pony/$(package_version)/include\n\t$(SILENT)cp src/common/pony/detail/atomics.h $(package)/usr/lib/pony/$(package_version)/include/pony/detail\n\t$(SILENT)ln -f -s /usr/lib/pony/$(package_version)/lib/libponyrt.a $(package)/usr/lib/libponyrt.a\nifeq ($(OSTYPE),linux)\n\t$(SILENT)ln -f -s /usr/lib/pony/$(package_version)/lib/libponyrt-pic.a $(package)/usr/lib/libponyrt-pic.a\nendif\nifneq ($(wildcard /usr/lib/pony/$(package_version)/lib/libponyrt.bc),)\n\t$(SILENT)ln -f -s /usr/lib/pony/$(package_version)/lib/libponyrt.bc $(package)/usr/lib/libponyrt.bc\nendif\nifneq ($(wildcard /usr/lib/pony/$(package_version)/lib/libdtrace_probes.a),)\n\t$(SILENT)ln -f -s /usr/lib/pony/$(package_version)/lib/libdtrace_probes.a $(package)/usr/lib/libdtrace_probes.a\nendif\n\t$(SILENT)ln -f -s /usr/lib/pony/$(package_version)/lib/libponyc.a $(package)/usr/lib/libponyc.a\n\t$(SILENT)ln -f -s /usr/lib/pony/$(package_version)/bin/ponyc $(package)/usr/bin/ponyc\n\t$(SILENT)ln -f -s /usr/lib/pony/$(package_version)/include/pony.h $(package)/usr/include/pony.h\n\t$(SILENT)ln -f -s /usr/lib/pony/$(package_version)/include/pony/detail/atomics.h $(package)/usr/include/pony/detail/atomics.h\n\t$(SILENT)cp -r packages $(package)/usr/lib/pony/$(package_version)/\n\t$(SILENT)fpm -s dir -t deb -C $(package) -p build/bin --name $(package_name) --conflicts \"ponyc-master\" --conflicts \"ponyc-release\" --version $(package_base_version) --description \"The Pony Compiler\" --provides \"ponyc\" --provides \"ponyc-release\"\n\t$(SILENT)fpm -s dir -t rpm -C $(package) -p build/bin --name $(package_name) --conflicts \"ponyc-master\" --conflicts \"ponyc-release\" --version $(package_base_version) --description \"The Pony Compiler\" --provides \"ponyc\" --provides \"ponyc-release\" --depends \"ponydep-ncurses\"\n\t$(SILENT)git archive HEAD > build/bin/$(archive)\n\t$(SILENT)tar rvf build/bin/$(archive) stdlib-docs\n\t$(SILENT)bzip2 build/bin/$(archive)\n\t$(SILENT)rm -rf $(package) build/bin/$(archive)\nendef\n\n$(eval $(call EXPAND_DEPLOY))\n\nstats:\n\t@echo\n\t@echo '------------------------------'\n\t@echo 'Compiler and standard library '\n\t@echo '------------------------------'\n\t@echo\n\t@cloc --read-lang-def=pony.cloc src packages\n\t@echo\n\t@echo '------------------------------'\n\t@echo 'Test suite:'\n\t@echo '------------------------------'\n\t@echo\n\t@cloc --read-lang-def=pony.cloc test\n\nclean:\n\t@rm -rf $(PONY_BUILD_DIR)\n\t@rm -rf $(package)\n\t@rm -rf build/bin\n\t@rm -rf stdlib-docs\n\t@rm -f src/common/dtrace_probes.h\n\t-@rmdir build 2>/dev/null ||:\n\t@echo 'Repository cleaned ($(PONY_BUILD_DIR)).'\n\nhelp:\n\t@echo 'Usage: make [config=name] [arch=name] [use=opt,...] [target]'\n\t@echo\n\t@echo 'CONFIGURATIONS:'\n\t@echo '  debug'\n\t@echo '  release (default)'\n\t@echo\n\t@echo 'ARCHITECTURE:'\n\t@echo '  native (default)'\n\t@echo '  [any compiler supported architecture]'\n\t@echo\n\t@echo 'Compile time default options:'\n\t@echo '  default_pic=true     Make --pic the default'\n\t@echo '  default_ssl=Name     Make Name the default ssl version'\n\t@echo '                       where Name is one of:'\n\t@echo '                         openssl_0.9.0'\n\t@echo '                         openssl_1.1.0'\n\t@echo\n\t@echo 'USE OPTIONS:'\n\t@echo '   valgrind'\n\t@echo '   pooltrack'\n\t@echo '   dtrace'\n\t@echo '   actor_continuations'\n\t@echo '   coverage'\n\t@echo '   llvm_link_static'\n\t@echo '   scheduler_scaling_pthreads'\n\t@echo\n\t@echo 'TARGETS:'\n\t@echo '  libponyc               Pony compiler library'\n\t@echo '  libponyrt              Pony runtime'\n\t@echo '  libponyrt-pic          Pony runtime -fpic'\n\t@echo '  libponyc.tests         Test suite for libponyc'\n\t@echo '  libponyrt.tests        Test suite for libponyrt'\n\t@echo '  libponyc.benchmarks    Benchmark suite for libponyc'\n\t@echo '  libponyrt.benchmarks   Benchmark suite for libponyrt'\n\t@echo '  ponyc                  Pony compiler executable'\n\t@echo\n\t@echo '  all                    Build all of the above (default)'\n\t@echo '  test                   Run test suite'\n\t@echo '  benchmark              Build and run benchmark suite'\n\t@echo '  install                Install ponyc'\n\t@echo '  install-libponyrt      Install libponyrt only (for cross'\n\t@echo '                         linking)'\n\t@echo '  install-libponyrt-pic  Install libponyrt-pic only (for cross'\n\t@echo '                         linking)'\n\t@echo '  uninstall              Remove all versions of ponyc'\n\t@echo '  stats                  Print Pony cloc statistics'\n\t@echo '  clean                  Delete all build files'\n\t@echo\n", "idx": 1, "id": 13194, "msg": "This shouldn't be added. It's not supported. It's not event the default. If we are going to support this, we need to have CI for it.", "proj": "ponylang-ponyc", "lang": "c"}
{"patch": "@@ -30,6 +30,9 @@ func newSyncCache(state *core.BuildState, remoteOnly bool) core.Cache {\n \tif state.Config.Cache.HTTPURL != \"\" {\n \t\tmplex.caches = append(mplex.caches, newHTTPCache(state.Config))\n \t}\n+\tif state.Config.Cache.RetrieveCommand != \"\" {\n+\t\tmplex.caches = append(mplex.caches, newCmdCache(state.Config))\n+\t}\n \tif len(mplex.caches) == 0 {\n \t\treturn &noopCache{}\n \t} else if len(mplex.caches) == 1 {", "y": 1, "oldf": "// Caching support for Please.\n\npackage cache\n\nimport (\n\t\"sync\"\n\n\t\"gopkg.in/op/go-logging.v1\"\n\n\t\"github.com/thought-machine/please/src/core\"\n)\n\nvar log = logging.MustGetLogger(\"cache\")\n\n// NewCache is the factory function for creating a cache setup from the given config.\nfunc NewCache(state *core.BuildState) core.Cache {\n\tc := newSyncCache(state, false)\n\tif state.Config.Cache.Workers > 0 {\n\t\treturn newAsyncCache(c, state.Config)\n\t}\n\treturn c\n}\n\n// newSyncCache creates a new cache, possibly multiplexing many underneath.\nfunc newSyncCache(state *core.BuildState, remoteOnly bool) core.Cache {\n\tmplex := &cacheMultiplexer{}\n\tif state.Config.Cache.Dir != \"\" && !remoteOnly {\n\t\tmplex.caches = append(mplex.caches, newDirCache(state.Config))\n\t}\n\tif state.Config.Cache.HTTPURL != \"\" {\n\t\tmplex.caches = append(mplex.caches, newHTTPCache(state.Config))\n\t}\n\tif len(mplex.caches) == 0 {\n\t\treturn &noopCache{}\n\t} else if len(mplex.caches) == 1 {\n\t\treturn mplex.caches[0] // Skip the extra layer of indirection\n\t}\n\treturn mplex\n}\n\n// A cacheMultiplexer multiplexes several caches into one.\n// Used when we have several active (eg. http, dir).\ntype cacheMultiplexer struct {\n\tcaches []core.Cache\n}\n\nfunc (mplex cacheMultiplexer) Store(target *core.BuildTarget, key []byte, files []string) {\n\tmplex.storeUntil(target, key, files, len(mplex.caches))\n}\n\n// storeUntil stores artifacts into higher priority caches than the given one.\n// Used after artifact retrieval to ensure we have them in eg. the directory cache after\n// downloading from the RPC cache.\n// This is a little inefficient since we could write the file to plz-out then copy it to the dir cache,\n// but it's hard to fix that without breaking the cache abstraction.\nfunc (mplex cacheMultiplexer) storeUntil(target *core.BuildTarget, key []byte, files []string, stopAt int) {\n\t// Attempt to store on all caches simultaneously.\n\tvar wg sync.WaitGroup\n\tfor i, cache := range mplex.caches {\n\t\tif i == stopAt {\n\t\t\tbreak\n\t\t}\n\t\twg.Add(1)\n\t\tgo func(cache core.Cache) {\n\t\t\tcache.Store(target, key, files)\n\t\t\twg.Done()\n\t\t}(cache)\n\t}\n\twg.Wait()\n}\n\nfunc (mplex cacheMultiplexer) Retrieve(target *core.BuildTarget, key []byte, files []string) bool {\n\t// Retrieve from caches sequentially; if we did them simultaneously we could\n\t// easily write the same file from two goroutines at once.\n\tfor i, cache := range mplex.caches {\n\t\tif ok := cache.Retrieve(target, key, files); ok {\n\t\t\t// Store this into other caches\n\t\t\tmplex.storeUntil(target, key, files, i)\n\t\t\treturn ok\n\t\t}\n\t}\n\treturn false\n}\n\nfunc (mplex cacheMultiplexer) Clean(target *core.BuildTarget) {\n\tfor _, cache := range mplex.caches {\n\t\tcache.Clean(target)\n\t}\n}\n\nfunc (mplex cacheMultiplexer) CleanAll() {\n\tfor _, cache := range mplex.caches {\n\t\tcache.CleanAll()\n\t}\n}\n\nfunc (mplex cacheMultiplexer) Shutdown() {\n\tfor _, cache := range mplex.caches {\n\t\tcache.Shutdown()\n\t}\n}\n", "idx": 1, "id": 10379, "msg": "At this point we probably want to ensure there's a store command set.", "proj": "thought-machine-please", "lang": "go"}
{"patch": "@@ -117,4 +117,9 @@ interface ProductQueryInterface\n      * @return AttributeId[]\n      */\n     public function findAttributeIdsByProductId(ProductId $productId): array;\n+\n+    /**\n+     * @return array\n+     */\n+    public function findProductIdsWithBoundAttributeByAttributeId(AggregateId $id): array;\n }", "y": 1, "oldf": "<?php\n\n/**\n * Copyright \u00a9 Bold Brand Commerce Sp. z o.o. All rights reserved.\n * See LICENSE.txt for license details.\n */\n\ndeclare(strict_types=1);\n\nnamespace Ergonode\\Product\\Domain\\Query;\n\nuse Ergonode\\Product\\Domain\\ValueObject\\Sku;\nuse Ergonode\\SharedKernel\\Domain\\Aggregate\\AttributeId;\nuse Ergonode\\SharedKernel\\Domain\\Aggregate\\CategoryId;\nuse Ergonode\\SharedKernel\\Domain\\Aggregate\\ProductId;\nuse Ergonode\\SharedKernel\\Domain\\AggregateId;\nuse Ramsey\\Uuid\\Uuid;\nuse Ergonode\\SharedKernel\\Domain\\Aggregate\\MultimediaId;\nuse Ergonode\\SharedKernel\\Domain\\Aggregate\\TemplateId;\n\ninterface ProductQueryInterface\n{\n    public function findProductIdBySku(Sku $sku): ?ProductId;\n\n    public function findSkuByProductId(ProductId $id): ?Sku;\n\n    /**\n     * @return array\n     */\n    public function getAllIds(): array;\n\n    /**\n     * @return array\n     */\n    public function getAllEditedIds(?\\DateTime $dateTime = null): array;\n\n    /**\n     * @return array\n     */\n    public function getAllSkus(): array;\n\n    /**\n     * @return array\n     */\n    public function getDictionary(): array;\n\n    /**\n     * @param ProductId[] $productIds\n     *\n     * @return string[]\n     */\n    public function getOthersIds(array $productIds): array;\n\n    /**\n     * @return array\n     */\n    public function findProductIdByAttributeId(AttributeId $attributeId, ?Uuid $valueId = null): array;\n\n    /**\n     * @param string[] $skus\n     *\n     * @return ProductId[]\n     */\n    public function findProductIdsBySkus(array $skus): array;\n\n    /**\n     * @param array $segmentIds\n     *\n     * @return array\n     */\n    public function findProductIdsBySegments(array $segmentIds): array;\n\n    /**\n     * @return ProductId[]\n     */\n    public function findProductIdsByTemplate(TemplateId $templateId): array;\n\n    /**\n     * @return mixed\n     */\n    public function findProductIdByOptionId(AggregateId $id);\n\n    /**\n     * @return array\n     */\n    public function getMultimediaRelation(MultimediaId $id): array;\n\n    /**\n     * @return array\n     */\n    public function findProductIdByType(string $type): array;\n\n    public function getCount(): int;\n\n    /**\n     *\n     * @return ProductId[]\n     */\n    public function findProductIdByCategoryId(CategoryId $categoryId): array;\n\n    /**\n     * @return array\n     */\n    public function autocomplete(\n        string $search = null,\n        int $limit = null,\n        string $field = null,\n        ?string $order = 'ASC'\n    ): array;\n\n    /**\n     * @return AttributeId[]\n     */\n    public function findAttributeIdsBySku(Sku $sku): array;\n\n    /**\n     * @return AttributeId[]\n     */\n    public function findAttributeIdsByProductId(ProductId $productId): array;\n}\n", "idx": 1, "id": 9678, "msg": "If an external module decorates this interface, such a change will cause it to generate an error", "proj": "ergonode-backend", "lang": "php"}
{"patch": "@@ -228,6 +228,7 @@ setup(\n \t\t(\"libArm64/%s\"%version, glob(\"libArm64/*.dll\") + glob(\"libArm64/*.exe\")),\n \t\t(\"waves\", glob(\"waves/*.wav\")),\n \t\t(\"images\", glob(\"images/*.ico\")),\n+\t\t(\"fonts\", glob(\"fonts/*.ttf\")),\n \t\t(\"louis/tables\",glob(\"louis/tables/*\")),\n \t\t(\"COMRegistrationFixes\", glob(\"COMRegistrationFixes/*.reg\")),\n \t\t(\".\", glob(\"../miscDeps/python/*.dll\")),", "y": 1, "oldf": "# -*- coding: UTF-8 -*-\r\n#setup.py\r\n#A part of NonVisual Desktop Access (NVDA)\r\n#Copyright (C) 2006-2018 NV Access Limited, Peter V\u00e1gner, Joseph Lee\r\n#This file is covered by the GNU General Public License.\r\n#See the file COPYING for more details.\r\n\r\nimport os\r\nimport copy\r\nimport gettext\r\ngettext.install(\"nvda\")\r\nfrom setuptools import setup\r\nimport py2exe as py2exeModule\r\nfrom glob import glob\r\nimport fnmatch\r\nfrom versionInfo import *\r\nfrom py2exe import distutils_buildexe\r\nfrom py2exe.dllfinder import DllFinder\r\nimport wx\r\nimport importlib.machinery\r\n\r\nRT_MANIFEST = 24\r\nmanifest_template = \"\"\"\\\r\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\r\n<assembly xmlns=\"urn:schemas-microsoft-com:asm.v1\" manifestVersion=\"1.0\">\r\n\t<trustInfo xmlns=\"urn:schemas-microsoft-com:asm.v3\">\r\n\t\t<security>\r\n\t\t\t<requestedPrivileges>\r\n\t\t\t\t<requestedExecutionLevel\r\n\t\t\t\t\tlevel=\"asInvoker\"\r\n\t\t\t\t\tuiAccess=\"%(uiAccess)s\"\r\n\t\t\t\t/>\r\n\t\t\t</requestedPrivileges>\r\n\t\t</security>\r\n\t</trustInfo>\r\n\t<compatibility xmlns=\"urn:schemas-microsoft-com:compatibility.v1\">\r\n\t\t<application>\r\n\t\t\t<!-- Windows 7 -->\r\n\t\t\t<supportedOS\r\n\t\t\t\tId=\"{35138b9a-5d96-4fbd-8e2d-a2440225f93a}\"\r\n\t\t\t/>\r\n\t\t\t<!-- Windows 8 -->\r\n\t\t\t<supportedOS\r\n\t\t\t\tId=\"{4a2f28e3-53b9-4441-ba9c-d69d4a4a6e38}\"\r\n\t\t\t/>\r\n\t\t\t<!-- Windows 8.1 -->\r\n\t\t\t<supportedOS\r\n\t\t\t\tId=\"{1f676c76-80e1-4239-95bb-83d0f6d0da78}\"\r\n\t\t\t/>\r\n\t\t\t<!-- Windows 10 -->\r\n\t\t\t<supportedOS\r\n\t\t\t\tId=\"{8e0f7a12-bfb3-4fe8-b9a5-48fd50a15a9a}\"\r\n\t\t\t/>\r\n\t\t</application> \r\n\t</compatibility>\r\n</assembly>\r\n\"\"\"\r\n\r\n# py2exe's idea of whether a dll is a system dll appears to be wrong sometimes, so monkey patch it.\r\norig_determine_dll_type = DllFinder.determine_dll_type\r\ndef determine_dll_type(self, imagename):\r\n\tdll = os.path.basename(imagename).lower()\r\n\tif dll.startswith(\"api-ms-win-\") or dll in (\"powrprof.dll\", \"mpr.dll\", \"crypt32.dll\"):\r\n\t\t# These are definitely system dlls available on all systems and must be excluded.\r\n\t\t# Including them can cause serious problems when a binary build is run on a different version of Windows.\r\n\t\treturn None\r\n\treturn orig_determine_dll_type(self, imagename)\r\nDllFinder.determine_dll_type = determine_dll_type\r\n\r\nclass py2exe(distutils_buildexe.py2exe):\r\n\t\"\"\"Overridden py2exe command to:\r\n\t\t* Add a command line option --enable-uiAccess to enable uiAccess for the main executable and EOA proxy\r\n\t\t* Add a manifest to the executables\r\n\t\"\"\"\r\n\r\n\tuser_options = distutils_buildexe.py2exe.user_options + [\r\n\t\t(\"enable-uiAccess\", \"u\", \"enable uiAccess for the main executable\"),\r\n\t]\r\n\r\n\tdef initialize_options(self):\r\n\t\tsuper(py2exe, self).initialize_options()\r\n\t\tself.enable_uiAccess = False\r\n\r\n\tdef run(self):\r\n\t\tdist = self.distribution\r\n\t\tif self.enable_uiAccess:\r\n\t\t\t# Add a target for nvda_uiAccess, using nvda_noUIAccess as a base.\r\n\t\t\ttarget = copy.deepcopy(dist.windows[0])\r\n\t\t\ttarget[\"dest_base\"] = \"nvda_uiAccess\"\r\n\t\t\ttarget['uiAccess'] = True\r\n\t\t\tdist.windows.insert(1, target)\r\n\t\t\t# nvda_eoaProxy should have uiAccess.\r\n\t\t\ttarget = dist.windows[3]\r\n\t\t\ttarget['uiAccess'] = True\r\n\t\t# Add a manifest resource to every target at runtime.\r\n\t\tfor target in dist.windows:\r\n\t\t\ttarget[\"other_resources\"] = [\r\n\t\t\t\t(\r\n\t\t\t\t\tRT_MANIFEST,\r\n\t\t\t\t\t1,\r\n\t\t\t\t\t(manifest_template % dict(uiAccess=target['uiAccess'])).encode(\"utf-8\")\r\n\t\t\t\t),\r\n\t\t\t]\r\n\t\tsuper(py2exe, self).run()\r\n\r\ndef getLocaleDataFiles():\r\n\twxDir=wx.__path__[0]\r\n\tlocaleMoFiles=set()\r\n\tfor f in glob(\"locale/*/LC_MESSAGES\"):\r\n\t\tlocaleMoFiles.add((f, (os.path.join(f,\"nvda.mo\"),)))\r\n\t\twxMoFile=os.path.join(wxDir,f,\"wxstd.mo\")\r\n\t\tif os.path.isfile(wxMoFile):\r\n\t\t\tlocaleMoFiles.add((f,(wxMoFile,))) \r\n\t\tlang=os.path.split(os.path.split(f)[0])[1]\r\n\t\tif '_' in lang:\r\n\t\t\t\tlang=lang.split('_')[0]\r\n\t\t\t\tf=os.path.join('locale',lang,'lc_messages')\r\n\t\t\t\twxMoFile=os.path.join(wxDir,f,\"wxstd.mo\")\r\n\t\t\t\tif os.path.isfile(wxMoFile):\r\n\t\t\t\t\tlocaleMoFiles.add((f,(wxMoFile,))) \r\n\tlocaleDicFiles=[(os.path.dirname(f), (f,)) for f in glob(\"locale/*/*.dic\")]\r\n\tNVDALocaleGestureMaps=[(os.path.dirname(f), (f,)) for f in glob(\"locale/*/gestures.ini\")]\r\n\treturn list(localeMoFiles)+localeDicFiles+NVDALocaleGestureMaps\r\n\r\ndef getRecursiveDataFiles(dest,source,excludes=()):\r\n\trulesList=[]\r\n\trulesList.append((dest,\r\n\t\t[f for f in glob(\"%s/*\"%source) if not any(fnmatch.fnmatch(f,exclude) for exclude in excludes) and os.path.isfile(f)]))\r\n\t[rulesList.extend(getRecursiveDataFiles(os.path.join(dest,dirName),os.path.join(source,dirName),excludes=excludes)) for dirName in os.listdir(source) if os.path.isdir(os.path.join(source,dirName)) and not dirName.startswith('.')]\r\n\treturn rulesList\r\n\r\nsetup(\r\n\tname = name,\r\n\tversion=version,\r\n\tdescription=description,\r\n\turl=url,\r\n\tclassifiers=[\r\n'Development Status :: 3 - Alpha',\r\n'Environment :: Win32 (MS Windows)',\r\n'Topic :: Adaptive Technologies'\r\n'Intended Audience :: Developers',\r\n'Intended Audience :: End Users/Desktop',\r\n'License :: OSI Approved :: GNU General Public License (GPL)',\r\n'Natural Language :: English',\r\n'Programming Language :: Python',\r\n'Operating System :: Microsoft :: Windows',\r\n],\r\n\tcmdclass={\"py2exe\": py2exe},\r\n\twindows=[\r\n\t\t{\r\n\t\t\t\"script\":\"nvda.pyw\",\r\n\t\t\t\"dest_base\":\"nvda_noUIAccess\",\r\n\t\t\t\"uiAccess\": False,\r\n\t\t\t\"icon_resources\":[(1,\"images/nvda.ico\")],\r\n\t\t\t\"other_resources\": [], # Populated at run time\r\n\t\t\t\"version\":formatBuildVersionString(),\r\n\t\t\t\"description\":\"NVDA application\",\r\n\t\t\t\"product_name\":name,\r\n\t\t\t\"product_version\":version,\r\n\t\t\t\"copyright\":copyright,\r\n\t\t\t\"company_name\":publisher,\r\n\t\t},\r\n\t\t# The nvda_uiAccess target will be added at runtime if required.\r\n\t\t{\r\n\t\t\t\"script\": \"nvda_slave.pyw\",\r\n\t\t\t\"uiAccess\": False,\r\n\t\t\t\"icon_resources\": [(1,\"images/nvda.ico\")],\r\n\t\t\t\"other_resources\": [], # Populated at run time\r\n\t\t\t\"version\":formatBuildVersionString(),\r\n\t\t\t\"description\": name,\r\n\t\t\t\"product_name\":name,\r\n\t\t\t\"product_version\": version,\r\n\t\t\t\"copyright\": copyright,\r\n\t\t\t\"company_name\": publisher,\r\n\t\t},\r\n\t\t{\r\n\t\t\t\"script\": \"nvda_eoaProxy.pyw\",\r\n\t\t\t# uiAccess will be enabled at runtime if appropriate.\r\n\t\t\t\"uiAccess\": False,\r\n\t\t\t\"icon_resources\": [(1,\"images/nvda.ico\")],\r\n\t\t\t\"other_resources\": [], # Populated at run time\r\n\t\t\t\"version\":formatBuildVersionString(),\r\n\t\t\t\"description\": \"NVDA Ease of Access proxy\",\r\n\t\t\t\"product_name\":name,\r\n\t\t\t\"product_version\": version,\r\n\t\t\t\"copyright\": copyright,\r\n\t\t\t\"company_name\": publisher,\r\n\t\t},\r\n\t],\r\n\toptions = {\"py2exe\": {\r\n\t\t\"bundle_files\": 3,\r\n\t\t\"excludes\": [\"tkinter\",\r\n\t\t\t\"serial.loopback_connection\", \r\n\t\t\t\"serial.rfc2217\", \r\n\t\t\t\"serial.serialcli\", \r\n\t\t\t\"serial.serialjava\", \r\n\t\t\t\"serial.serialposix\", \r\n\t\t\t\"serial.socket_connection\",\r\n\t\t\t# netbios (from pywin32) is optionally used by Python3's uuid module.\r\n\t\t\t# This is not needed.\r\n\t\t\t# We also need to exclude win32wnet explicitly.\r\n\t\t\t\"netbios\",\r\n\t\t\t\"win32wnet\",\r\n\t\t\t# winxptheme is optionally used by wx.lib.agw.aui.\r\n\t\t\t# We don't need this.\r\n\t\t\t\"winxptheme\",\r\n\t\t],\r\n\t\t\"packages\": [\r\n\t\t\t\"NVDAObjects\",\r\n\t\t\t\"virtualBuffers\",\r\n\t\t\t\"appModules\",\r\n\t\t\t\"comInterfaces\",\r\n\t\t\t\"brailleDisplayDrivers\",\r\n\t\t\t\"synthDrivers\",\r\n\t\t\t\"visionEnhancementProviders\",\r\n\t\t],\r\n\t\t\"includes\": [\r\n\t\t\t\"nvdaBuiltin\",\r\n\t\t\t# #3368: bisect was implicitly included with Python 2.7.3, but isn't with 2.7.5.\r\n\t\t\t\"bisect\",\r\n\t\t],\r\n\t}},\r\n\tdata_files=[\r\n\t\t(\".\",glob(\"*.dll\")+glob(\"*.manifest\")+[\"builtin.dic\"]),\r\n\t\t(\"documentation\", ['../copying.txt', '../contributors.txt']),\r\n\t\t(\"lib/%s\"%version, glob(\"lib/*.dll\")),\r\n\t\t(\"lib64/%s\"%version, glob(\"lib64/*.dll\") + glob(\"lib64/*.exe\")),\r\n\t\t(\"libArm64/%s\"%version, glob(\"libArm64/*.dll\") + glob(\"libArm64/*.exe\")),\r\n\t\t(\"waves\", glob(\"waves/*.wav\")),\r\n\t\t(\"images\", glob(\"images/*.ico\")),\r\n\t\t(\"louis/tables\",glob(\"louis/tables/*\")),\r\n\t\t(\"COMRegistrationFixes\", glob(\"COMRegistrationFixes/*.reg\")),\r\n\t\t(\".\", glob(\"../miscDeps/python/*.dll\")),\r\n\t\t(\".\", ['message.html' ])\r\n\t] + (\r\n\t\tgetLocaleDataFiles()\r\n\t\t+ getRecursiveDataFiles(\"synthDrivers\", \"synthDrivers\",\r\n\t\t\texcludes=tuple(\r\n\t\t\t\t\"*%s\" % ext\r\n\t\t\t\tfor ext in importlib.machinery.SOURCE_SUFFIXES + importlib.machinery.BYTECODE_SUFFIXES\r\n\t\t\t) + (\r\n\t\t\t\t\"*.exp\",\r\n\t\t\t\t\"*.lib\",\r\n\t\t\t\t\"*.pdb\",\r\n\t\t\t\t\"__pycache__\"\r\n\t\t))\r\n\t\t+ getRecursiveDataFiles(\"brailleDisplayDrivers\", \"brailleDisplayDrivers\",\r\n\t\t\texcludes=tuple(\r\n\t\t\t\t\"*%s\" % ext\r\n\t\t\t\tfor ext in importlib.machinery.SOURCE_SUFFIXES + importlib.machinery.BYTECODE_SUFFIXES\r\n\t\t\t) + (\r\n\t\t\t\t\"__pycache__\",\r\n\t\t))\r\n\t\t+ getRecursiveDataFiles('documentation', '../user_docs', excludes=('*.t2t', '*.t2tconf', '*/developerGuide.*'))\r\n\t),\r\n)\r\n", "idx": 1, "id": 28270, "msg": "Should we include the files with otf extension here, too? If not, I wonder why we do allow them in the source but we don't include them as per the setup", "proj": "nvaccess-nvda", "lang": "py"}
{"patch": "@@ -67,10 +67,8 @@ public class VerbsManager {\n                 output -> {\n                     final Value verbClass = (Value) output;\n \n-                    final Verb verb = verbClass.newInstance().as(Verb.class);\n-\n                     try {\n-                        verb.install(container);\n+                        verbClass.invokeMember(\"install\", container);\n                     } catch (ScriptException se) {\n                         errorCallback.accept(se);\n                     }", "y": 1, "oldf": "/*\n * Copyright (C) 2015-2017 P\u00c2RIS Quentin\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License along\n * with this program; if not, write to the Free Software Foundation, Inc.,\n * 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.\n */\n\npackage org.phoenicis.engines;\n\nimport org.graalvm.polyglot.Value;\nimport org.phoenicis.repository.dto.ApplicationDTO;\nimport org.phoenicis.repository.dto.CategoryDTO;\nimport org.phoenicis.repository.dto.RepositoryDTO;\nimport org.phoenicis.repository.dto.TypeDTO;\nimport org.phoenicis.scripts.exceptions.ScriptException;\nimport org.phoenicis.scripts.interpreter.ScriptInterpreter;\nimport org.phoenicis.scripts.session.InteractiveScriptSession;\n\nimport java.util.ArrayList;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.function.Consumer;\n\n/**\n * manages the Verbs\n */\npublic class VerbsManager {\n    private final ScriptInterpreter scriptInterpreter;\n\n    /**\n     * Constructor\n     *\n     * @param scriptInterpreter The underlying script interpreter\n     */\n    public VerbsManager(ScriptInterpreter scriptInterpreter) {\n        this.scriptInterpreter = scriptInterpreter;\n    }\n\n    /**\n     * Installs a Verb in a given container\n     *\n     * @param engineId ID of the engine which provides the Verb (e.g. \"Wine\")\n     * @param container name of the container\n     * @param verbId ID of the Verb\n     * @param doneCallback callback executed after the script ran\n     * @param errorCallback callback executed in case of an error\n     */\n    public void installVerb(String engineId, String container, String verbId, Runnable doneCallback,\n            Consumer<Exception> errorCallback) {\n        final InteractiveScriptSession interactiveScriptSession = scriptInterpreter.createInteractiveSession();\n\n        final String script = String.format(\"include(\\\"%s\\\");\", verbId);\n\n        interactiveScriptSession.eval(script,\n                output -> {\n                    final Value verbClass = (Value) output;\n\n                    final Verb verb = verbClass.newInstance().as(Verb.class);\n\n                    try {\n                        verb.install(container);\n                    } catch (ScriptException se) {\n                        errorCallback.accept(se);\n                    }\n\n                    doneCallback.run();\n                },\n                errorCallback);\n    }\n\n    /**\n     * Installs a list of Verbs in a given container\n     *\n     * @param engineId ID of the engine which provides the Verbs (e.g. \"Wine\")\n     * @param container name of the container\n     * @param verbIds A list of verb ids\n     * @param doneCallback callback executed after the scripts ran\n     * @param errorCallback callback executed in case of an error\n     */\n    public void installVerbs(String engineId, String container, List<String> verbIds, Runnable doneCallback,\n            Consumer<Exception> errorCallback) {\n        if (verbIds.isEmpty()) {\n            doneCallback.run();\n        } else {\n            final String verbId = verbIds.get(0);\n\n            final List<String> remainingVerbIds = verbIds.subList(1, verbIds.size());\n\n            installVerb(engineId, container, verbId,\n                    // recursively install the remaining verbs in the list\n                    () -> installVerbs(engineId, container, remainingVerbIds, doneCallback, errorCallback),\n                    errorCallback);\n        }\n    }\n\n    /**\n     * Fetches the available Verbs\n     *\n     * @param repositoryDTO\n     * @param callback\n     */\n    public void fetchAvailableVerbs(RepositoryDTO repositoryDTO, Consumer<Map<String, ApplicationDTO>> callback) {\n        Map<String, ApplicationDTO> verbs = new HashMap<>();\n        // get engine CategoryDTOs\n        List<CategoryDTO> categoryDTOS = new ArrayList<>();\n        for (TypeDTO typeDTO : repositoryDTO.getTypes()) {\n            if (typeDTO.getId().equals(\"engines\")) {\n                categoryDTOS = typeDTO.getCategories();\n            }\n        }\n        for (CategoryDTO engine : categoryDTOS) {\n            for (ApplicationDTO applicationDTO : engine.getApplications()) {\n                if (applicationDTO.getId().equals(engine.getId() + \".verbs\")) {\n                    verbs.put(engine.getId().replaceAll(\"^.*\\\\.\", \"\"), applicationDTO);\n                }\n            }\n        }\n        callback.accept(verbs);\n    }\n}\n", "idx": 1, "id": 14123, "msg": "It seems like this is the only way to access javascript `static` methods from Java.", "proj": "PhoenicisOrg-phoenicis", "lang": "java"}
{"patch": "@@ -544,6 +544,13 @@ func (c *client) initClient() {\n \t// Snapshots to avoid mutex access in fast paths.\n \tc.out.wdl = opts.WriteDeadline\n \tc.out.mp = opts.MaxPending\n+\t// Snapshot max control line since currently can not be changed on reload and we\n+\t// were checking it on each call to parse. If this changes and we allow MaxControlLine\n+\t// to be reloaded without restart, this code will need to change.\n+\tc.mcl = int32(opts.MaxControlLine)\n+\tif c.mcl == 0 {\n+\t\tc.mcl = MAX_CONTROL_LINE_SIZE\n+\t}\n \n \tc.subs = make(map[string]*subscription)\n \tc.echo = true", "y": 1, "oldf": "// Copyright 2012-2021 The NATS Authors\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n// http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage server\n\nimport (\n\t\"bytes\"\n\t\"crypto/tls\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"math/rand\"\n\t\"net\"\n\t\"net/http\"\n\t\"regexp\"\n\t\"runtime\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\t\"github.com/nats-io/jwt/v2\"\n)\n\n// Type of client connection.\nconst (\n\t// CLIENT is an end user.\n\tCLIENT = iota\n\t// ROUTER represents another server in the cluster.\n\tROUTER\n\t// GATEWAY is a link between 2 clusters.\n\tGATEWAY\n\t// SYSTEM is an internal system client.\n\tSYSTEM\n\t// LEAF is for leaf node connections.\n\tLEAF\n\t// JETSTREAM is an internal jetstream client.\n\tJETSTREAM\n\t// ACCOUNT is for the internal client for accounts.\n\tACCOUNT\n)\n\n// Extended type of a CLIENT connection. This is returned by c.clientType()\n// and indicate what type of client connection we are dealing with.\n// If invoked on a non CLIENT connection, NON_CLIENT type is returned.\nconst (\n\t// If the connection is not a CLIENT connection.\n\tNON_CLIENT = iota\n\t// Regular NATS client.\n\tNATS\n\t// MQTT client.\n\tMQTT\n\t// Websocket client.\n\tWS\n)\n\nconst (\n\t// ClientProtoZero is the original Client protocol from 2009.\n\t// http://nats.io/documentation/internals/nats-protocol/\n\tClientProtoZero = iota\n\t// ClientProtoInfo signals a client can receive more then the original INFO block.\n\t// This can be used to update clients on other cluster members, etc.\n\tClientProtoInfo\n)\n\nconst (\n\tpingProto = \"PING\" + _CRLF_\n\tpongProto = \"PONG\" + _CRLF_\n\terrProto  = \"-ERR '%s'\" + _CRLF_\n\tokProto   = \"+OK\" + _CRLF_\n)\n\nfunc init() {\n\trand.Seed(time.Now().UnixNano())\n}\n\nconst (\n\t// Scratch buffer size for the processMsg() calls.\n\tmsgScratchSize  = 1024\n\tmsgHeadProto    = \"RMSG \"\n\tmsgHeadProtoLen = len(msgHeadProto)\n\n\t// For controlling dynamic buffer sizes.\n\tstartBufSize    = 512   // For INFO/CONNECT block\n\tminBufSize      = 64    // Smallest to shrink to for PING/PONG\n\tmaxBufSize      = 65536 // 64k\n\tshortsToShrink  = 2     // Trigger to shrink dynamic buffers\n\tmaxFlushPending = 10    // Max fsps to have in order to wait for writeLoop\n\treadLoopReport  = 2 * time.Second\n\n\t// Server should not send a PING (for RTT) before the first PONG has\n\t// been sent to the client. However, in case some client libs don't\n\t// send CONNECT+PING, cap the maximum time before server can send\n\t// the RTT PING.\n\tmaxNoRTTPingBeforeFirstPong = 2 * time.Second\n\n\t// For stalling fast producers\n\tstallClientMinDuration = 100 * time.Millisecond\n\tstallClientMaxDuration = time.Second\n)\n\nvar readLoopReportThreshold = readLoopReport\n\n// Represent client booleans with a bitmask\ntype clientFlag uint16\n\n// Some client state represented as flags\nconst (\n\tconnectReceived   clientFlag = 1 << iota // The CONNECT proto has been received\n\tinfoReceived                             // The INFO protocol has been received\n\tfirstPongSent                            // The first PONG has been sent\n\thandshakeComplete                        // For TLS clients, indicate that the handshake is complete\n\tflushOutbound                            // Marks client as having a flushOutbound call in progress.\n\tnoReconnect                              // Indicate that on close, this connection should not attempt a reconnect\n\tcloseConnection                          // Marks that closeConnection has already been called.\n\tconnMarkedClosed                         // Marks that markConnAsClosed has already been called.\n\twriteLoopStarted                         // Marks that the writeLoop has been started.\n\tskipFlushOnClose                         // Marks that flushOutbound() should not be called on connection close.\n\texpectConnect                            // Marks if this connection is expected to send a CONNECT\n)\n\n// set the flag (would be equivalent to set the boolean to true)\nfunc (cf *clientFlag) set(c clientFlag) {\n\t*cf |= c\n}\n\n// clear the flag (would be equivalent to set the boolean to false)\nfunc (cf *clientFlag) clear(c clientFlag) {\n\t*cf &= ^c\n}\n\n// isSet returns true if the flag is set, false otherwise\nfunc (cf clientFlag) isSet(c clientFlag) bool {\n\treturn cf&c != 0\n}\n\n// setIfNotSet will set the flag `c` only if that flag was not already\n// set and return true to indicate that the flag has been set. Returns\n// false otherwise.\nfunc (cf *clientFlag) setIfNotSet(c clientFlag) bool {\n\tif *cf&c == 0 {\n\t\t*cf |= c\n\t\treturn true\n\t}\n\treturn false\n}\n\n// ClosedState is the reason client was closed. This will\n// be passed into calls to clearConnection, but will only\n// be stored in ConnInfo for monitoring.\ntype ClosedState int\n\nconst (\n\tClientClosed = ClosedState(iota + 1)\n\tAuthenticationTimeout\n\tAuthenticationViolation\n\tTLSHandshakeError\n\tSlowConsumerPendingBytes\n\tSlowConsumerWriteDeadline\n\tWriteError\n\tReadError\n\tParseError\n\tStaleConnection\n\tProtocolViolation\n\tBadClientProtocolVersion\n\tWrongPort\n\tMaxAccountConnectionsExceeded\n\tMaxConnectionsExceeded\n\tMaxPayloadExceeded\n\tMaxControlLineExceeded\n\tMaxSubscriptionsExceeded\n\tDuplicateRoute\n\tRouteRemoved\n\tServerShutdown\n\tAuthenticationExpired\n\tWrongGateway\n\tMissingAccount\n\tRevocation\n\tInternalClient\n\tMsgHeaderViolation\n\tNoRespondersRequiresHeaders\n\tClusterNameConflict\n\tDuplicateRemoteLeafnodeConnection\n\tDuplicateClientID\n)\n\n// Some flags passed to processMsgResults\nconst pmrNoFlag int = 0\nconst (\n\tpmrCollectQueueNames int = 1 << iota\n\tpmrIgnoreEmptyQueueFilter\n\tpmrAllowSendFromRouteToRoute\n\tpmrMsgImportedFromService\n)\n\ntype client struct {\n\t// Here first because of use of atomics, and memory alignment.\n\tstats\n\t// Indicate if we should check gwrm or not. Since checking gwrm is done\n\t// when processing inbound messages and requires the lock we want to\n\t// check only when needed. This is set/get using atomic, so needs to\n\t// be memory aligned.\n\tcgwrt int32\n\tkind  int\n\tsrv   *Server\n\tacc   *Account\n\tperms *permissions\n\tin    readCache\n\tparseState\n\topts       clientOpts\n\trrTracking *rrTracking\n\tmpay       int32\n\tmsubs      int32\n\tmcl        int32\n\tmu         sync.Mutex\n\tcid        uint64\n\tstart      time.Time\n\tnonce      []byte\n\tpubKey     string\n\tnc         net.Conn\n\tncs        atomic.Value\n\tout        outbound\n\tuser       *NkeyUser\n\thost       string\n\tport       uint16\n\tsubs       map[string]*subscription\n\treplies    map[string]*resp\n\tmperms     *msgDeny\n\tdarray     []string\n\tpcd        map[*client]struct{}\n\tatmr       *time.Timer\n\tping       pinfo\n\tmsgb       [msgScratchSize]byte\n\tlast       time.Time\n\theaders    bool\n\n\trtt      time.Duration\n\trttStart time.Time\n\n\troute *route\n\tgw    *gateway\n\tleaf  *leaf\n\tws    *websocket\n\tmqtt  *mqtt\n\n\t// To keep track of gateway replies mapping\n\tgwrm map[string]*gwReplyMap\n\n\tflags clientFlag // Compact booleans into a single field. Size will be increased when needed.\n\n\trref byte\n\n\ttrace bool\n\techo  bool\n\n\ttags    jwt.TagList\n\tnameTag string\n}\n\ntype rrTracking struct {\n\trmap map[string]*remoteLatency\n\tptmr *time.Timer\n\tlrt  time.Duration\n}\n\n// Struct for PING initiation from the server.\ntype pinfo struct {\n\ttmr  *time.Timer\n\tlast time.Time\n\tout  int\n}\n\n// outbound holds pending data for a socket.\ntype outbound struct {\n\tp   []byte        // Primary write buffer\n\ts   []byte        // Secondary for use post flush\n\tnb  net.Buffers   // net.Buffers for writev IO\n\tsz  int32         // limit size per []byte, uses variable BufSize constants, start, min, max.\n\tsws int32         // Number of short writes, used for dynamic resizing.\n\tpb  int64         // Total pending/queued bytes.\n\tpm  int32         // Total pending/queued messages.\n\tfsp int32         // Flush signals that are pending per producer from readLoop's pcd.\n\tsg  *sync.Cond    // To signal writeLoop that there is data to flush.\n\twdl time.Duration // Snapshot of write deadline.\n\tmp  int64         // Snapshot of max pending for client.\n\tlft time.Duration // Last flush time for Write.\n\tstc chan struct{} // Stall chan we create to slow down producers on overrun, e.g. fan-in.\n}\n\ntype perm struct {\n\tallow *Sublist\n\tdeny  *Sublist\n}\n\ntype permissions struct {\n\tsub    perm\n\tpub    perm\n\tresp   *ResponsePermission\n\tpcache map[string]bool\n}\n\n// This is used to dynamically track responses and reply subjects\n// for dynamic permissioning.\ntype resp struct {\n\tt time.Time\n\tn int\n}\n\n// msgDeny is used when a user permission for subscriptions has a deny\n// clause but a subscription could be made that is of broader scope.\n// e.g. deny = \"foo\", but user subscribes to \"*\". That subscription should\n// succeed but no message sent on foo should be delivered.\ntype msgDeny struct {\n\tdeny   *Sublist\n\tdcache map[string]bool\n}\n\n// routeTarget collects information regarding routes and queue groups for\n// sending information to a remote.\ntype routeTarget struct {\n\tsub *subscription\n\tqs  []byte\n\t_qs [32]byte\n}\n\nconst (\n\tmaxResultCacheSize   = 512\n\tmaxDenyPermCacheSize = 256\n\tmaxPermCacheSize     = 128\n\tpruneSize            = 32\n\trouteTargetInit      = 8\n\treplyPermLimit       = 4096\n)\n\n// Represent read cache booleans with a bitmask\ntype readCacheFlag uint16\n\nconst (\n\thasMappings readCacheFlag = 1 << iota // For account subject mappings.\n)\n\n// Used in readloop to cache hot subject lookups and group statistics.\ntype readCache struct {\n\t// These are for clients who are bound to a single account.\n\tgenid   uint64\n\tresults map[string]*SublistResult\n\n\t// This is for routes and gateways to have their own L1 as well that is account aware.\n\tpacache map[string]*perAccountCache\n\n\t// This is for when we deliver messages across a route. We use this structure\n\t// to make sure to only send one message and properly scope to queues as needed.\n\trts []routeTarget\n\n\tprand *rand.Rand\n\n\t// These are all temporary totals for an invocation of a read in readloop.\n\tmsgs  int32\n\tbytes int32\n\tsubs  int32\n\n\trsz int32 // Read buffer size\n\tsrs int32 // Short reads, used for dynamic buffer resizing.\n\n\t// These are for readcache flags to avoind locks.\n\tflags readCacheFlag\n}\n\n// set the flag (would be equivalent to set the boolean to true)\nfunc (rcf *readCacheFlag) set(c readCacheFlag) {\n\t*rcf |= c\n}\n\n// clear the flag (would be equivalent to set the boolean to false)\nfunc (rcf *readCacheFlag) clear(c readCacheFlag) {\n\t*rcf &= ^c\n}\n\n// isSet returns true if the flag is set, false otherwise\nfunc (rcf readCacheFlag) isSet(c readCacheFlag) bool {\n\treturn rcf&c != 0\n}\n\nconst (\n\tdefaultMaxPerAccountCacheSize   = 4096\n\tdefaultPrunePerAccountCacheSize = 256\n\tdefaultClosedSubsCheckInterval  = 5 * time.Minute\n)\n\nvar (\n\tmaxPerAccountCacheSize   = defaultMaxPerAccountCacheSize\n\tprunePerAccountCacheSize = defaultPrunePerAccountCacheSize\n\tclosedSubsCheckInterval  = defaultClosedSubsCheckInterval\n)\n\n// perAccountCache is for L1 semantics for inbound messages from a route or gateway to mimic the performance of clients.\ntype perAccountCache struct {\n\tacc     *Account\n\tresults *SublistResult\n\tgenid   uint64\n}\n\nfunc (c *client) String() (id string) {\n\tloaded := c.ncs.Load()\n\tif loaded != nil {\n\t\treturn loaded.(string)\n\t}\n\n\treturn \"\"\n}\n\n// GetName returns the application supplied name for the connection.\nfunc (c *client) GetName() string {\n\tc.mu.Lock()\n\tname := c.opts.Name\n\tc.mu.Unlock()\n\treturn name\n}\n\n// GetOpts returns the client options provided by the application.\nfunc (c *client) GetOpts() *clientOpts {\n\treturn &c.opts\n}\n\n// GetTLSConnectionState returns the TLS ConnectionState if TLS is enabled, nil\n// otherwise. Implements the ClientAuth interface.\nfunc (c *client) GetTLSConnectionState() *tls.ConnectionState {\n\ttc, ok := c.nc.(*tls.Conn)\n\tif !ok {\n\t\treturn nil\n\t}\n\tstate := tc.ConnectionState()\n\treturn &state\n}\n\n// For CLIENT connections, this function returns the client type, that is,\n// NATS (for regular clients), MQTT or WS for websocket.\n// If this is invoked for a non CLIENT connection, NON_CLIENT is returned.\n//\n// This function does not lock the client and accesses fields that are supposed\n// to be immutable and therefore it can be invoked outside of the client's lock.\nfunc (c *client) clientType() int {\n\tswitch c.kind {\n\tcase CLIENT:\n\t\tif c.isMqtt() {\n\t\t\treturn MQTT\n\t\t} else if c.isWebsocket() {\n\t\t\treturn WS\n\t\t}\n\t\treturn NATS\n\tdefault:\n\t\treturn NON_CLIENT\n\t}\n}\n\n// This is the main subscription struct that indicates\n// interest in published messages.\n// FIXME(dlc) - This is getting bloated for normal subs, need\n// to optionally have an opts section for non-normal stuff.\ntype subscription struct {\n\tclient  *client\n\tim      *streamImport   // This is for import stream support.\n\tshadow  []*subscription // This is to track shadowed accounts.\n\ticb     msgHandler\n\tsubject []byte\n\tqueue   []byte\n\tsid     []byte\n\torigin  []byte\n\tnm      int64\n\tmax     int64\n\tqw      int32\n\tclosed  int32\n\tmqtt    *mqttSub\n}\n\n// Indicate that this subscription is closed.\n// This is used in pruning of route and gateway cache items.\nfunc (s *subscription) close() {\n\tatomic.StoreInt32(&s.closed, 1)\n}\n\n// Return true if this subscription was unsubscribed\n// or its connection has been closed.\nfunc (s *subscription) isClosed() bool {\n\treturn atomic.LoadInt32(&s.closed) == 1\n}\n\ntype clientOpts struct {\n\tEcho         bool   `json:\"echo\"`\n\tVerbose      bool   `json:\"verbose\"`\n\tPedantic     bool   `json:\"pedantic\"`\n\tTLSRequired  bool   `json:\"tls_required\"`\n\tNkey         string `json:\"nkey,omitempty\"`\n\tJWT          string `json:\"jwt,omitempty\"`\n\tSig          string `json:\"sig,omitempty\"`\n\tToken        string `json:\"auth_token,omitempty\"`\n\tUsername     string `json:\"user,omitempty\"`\n\tPassword     string `json:\"pass,omitempty\"`\n\tName         string `json:\"name\"`\n\tLang         string `json:\"lang\"`\n\tVersion      string `json:\"version\"`\n\tProtocol     int    `json:\"protocol\"`\n\tAccount      string `json:\"account,omitempty\"`\n\tAccountNew   bool   `json:\"new_account,omitempty\"`\n\tHeaders      bool   `json:\"headers,omitempty\"`\n\tNoResponders bool   `json:\"no_responders,omitempty\"`\n\n\t// Routes and Leafnodes only\n\tImport *SubjectPermission `json:\"import,omitempty\"`\n\tExport *SubjectPermission `json:\"export,omitempty\"`\n}\n\nvar defaultOpts = clientOpts{Verbose: true, Pedantic: true, Echo: true}\nvar internalOpts = clientOpts{Verbose: false, Pedantic: false, Echo: false}\n\nfunc (c *client) setTraceLevel() {\n\tif c.kind == SYSTEM && !(atomic.LoadInt32(&c.srv.logging.traceSysAcc) != 0) {\n\t\tc.trace = false\n\t} else {\n\t\tc.trace = (atomic.LoadInt32(&c.srv.logging.trace) != 0)\n\t}\n}\n\n// Lock should be held\nfunc (c *client) initClient() {\n\ts := c.srv\n\tc.cid = atomic.AddUint64(&s.gcid, 1)\n\n\t// Outbound data structure setup\n\tc.out.sz = startBufSize\n\tc.out.sg = sync.NewCond(&(c.mu))\n\topts := s.getOpts()\n\t// Snapshots to avoid mutex access in fast paths.\n\tc.out.wdl = opts.WriteDeadline\n\tc.out.mp = opts.MaxPending\n\n\tc.subs = make(map[string]*subscription)\n\tc.echo = true\n\n\tc.setTraceLevel()\n\n\t// This is a scratch buffer used for processMsg()\n\t// The msg header starts with \"RMSG \", which can be used\n\t// for both local and routes.\n\t// in bytes that is [82 77 83 71 32].\n\tc.msgb = [msgScratchSize]byte{82, 77, 83, 71, 32}\n\n\t// This is to track pending clients that have data to be flushed\n\t// after we process inbound msgs from our own connection.\n\tc.pcd = make(map[*client]struct{})\n\n\t// snapshot the string version of the connection\n\tvar conn string\n\tif c.nc != nil {\n\t\tif addr := c.nc.RemoteAddr(); addr != nil {\n\t\t\tif conn = addr.String(); conn != _EMPTY_ {\n\t\t\t\thost, port, _ := net.SplitHostPort(conn)\n\t\t\t\tiPort, _ := strconv.Atoi(port)\n\t\t\t\tc.host, c.port = host, uint16(iPort)\n\t\t\t\t// Now that we have extracted host and port, escape\n\t\t\t\t// the string because it is going to be used in Sprintf\n\t\t\t\tconn = strings.ReplaceAll(conn, \"%\", \"%%\")\n\t\t\t}\n\t\t}\n\t}\n\n\tswitch c.kind {\n\tcase CLIENT:\n\t\tswitch c.clientType() {\n\t\tcase NATS:\n\t\t\tc.ncs.Store(fmt.Sprintf(\"%s - cid:%d\", conn, c.cid))\n\t\tcase WS:\n\t\t\tc.ncs.Store(fmt.Sprintf(\"%s - wid:%d\", conn, c.cid))\n\t\tcase MQTT:\n\t\t\tc.ncs.Store(fmt.Sprintf(\"%s - mid:%d\", conn, c.cid))\n\t\t}\n\tcase ROUTER:\n\t\tc.ncs.Store(fmt.Sprintf(\"%s - rid:%d\", conn, c.cid))\n\tcase GATEWAY:\n\t\tc.ncs.Store(fmt.Sprintf(\"%s - gid:%d\", conn, c.cid))\n\tcase LEAF:\n\t\tc.ncs.Store(fmt.Sprintf(\"%s - lid:%d\", conn, c.cid))\n\tcase SYSTEM:\n\t\tc.ncs.Store(\"SYSTEM\")\n\tcase JETSTREAM:\n\t\tc.ncs.Store(\"JETSTREAM\")\n\tcase ACCOUNT:\n\t\tc.ncs.Store(\"ACCOUNT\")\n\t}\n}\n\n// RemoteAddress expose the Address of the client connection,\n// nil when not connected or unknown\nfunc (c *client) RemoteAddress() net.Addr {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\n\tif c.nc == nil {\n\t\treturn nil\n\t}\n\n\treturn c.nc.RemoteAddr()\n}\n\n// Helper function to report errors.\nfunc (c *client) reportErrRegisterAccount(acc *Account, err error) {\n\tif err == ErrTooManyAccountConnections {\n\t\tc.maxAccountConnExceeded()\n\t\treturn\n\t}\n\tc.Errorf(\"Problem registering with account [%s]\", acc.Name)\n\tc.sendErr(\"Failed Account Registration\")\n}\n\n// registerWithAccount will register the given user with a specific\n// account. This will change the subject namespace.\nfunc (c *client) registerWithAccount(acc *Account) error {\n\tif acc == nil || acc.sl == nil {\n\t\treturn ErrBadAccount\n\t}\n\t// If we were previously registered, usually to $G, do accounting here to remove.\n\tif c.acc != nil {\n\t\tif prev := c.acc.removeClient(c); prev == 1 && c.srv != nil {\n\t\t\tc.srv.decActiveAccounts()\n\t\t}\n\t}\n\n\tc.mu.Lock()\n\tkind := c.kind\n\tsrv := c.srv\n\tc.acc = acc\n\tc.applyAccountLimits()\n\tc.mu.Unlock()\n\n\t// Check if we have a max connections violation\n\tif kind == CLIENT && acc.MaxTotalConnectionsReached() {\n\t\treturn ErrTooManyAccountConnections\n\t} else if kind == LEAF && acc.MaxTotalLeafNodesReached() {\n\t\treturn ErrTooManyAccountConnections\n\t}\n\n\t// Add in new one.\n\tif prev := acc.addClient(c); prev == 0 && srv != nil {\n\t\tsrv.incActiveAccounts()\n\t}\n\n\treturn nil\n}\n\n// Helper to determine if we have met or exceeded max subs.\nfunc (c *client) subsAtLimit() bool {\n\treturn c.msubs != jwt.NoLimit && len(c.subs) >= int(c.msubs)\n}\n\nfunc minLimit(value *int32, limit int32) bool {\n\tif *value != jwt.NoLimit {\n\t\tif limit != jwt.NoLimit {\n\t\t\tif limit < *value {\n\t\t\t\t*value = limit\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t} else if limit != jwt.NoLimit {\n\t\t*value = limit\n\t\treturn true\n\t}\n\treturn false\n}\n\n// Apply account limits\n// Lock is held on entry.\n// FIXME(dlc) - Should server be able to override here?\nfunc (c *client) applyAccountLimits() {\n\tif c.acc == nil || (c.kind != CLIENT && c.kind != LEAF) {\n\t\treturn\n\t}\n\tc.mpay = jwt.NoLimit\n\tc.msubs = jwt.NoLimit\n\tif c.opts.JWT != \"\" { // user jwt implies account\n\t\tif uc, _ := jwt.DecodeUserClaims(c.opts.JWT); uc != nil {\n\t\t\tc.mpay = int32(uc.Limits.Payload)\n\t\t\tc.msubs = int32(uc.Limits.Subs)\n\t\t\tif uc.IssuerAccount != _EMPTY_ && uc.IssuerAccount != uc.Issuer {\n\t\t\t\tif scope, ok := c.acc.signingKeys[uc.Issuer]; ok {\n\t\t\t\t\tif userScope, ok := scope.(*jwt.UserScope); ok {\n\t\t\t\t\t\t// if signing key disappeared or changed and we don't get here, the client will be disconnected\n\t\t\t\t\t\tc.mpay = int32(userScope.Template.Limits.Payload)\n\t\t\t\t\t\tc.msubs = int32(userScope.Template.Limits.Subs)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tminLimit(&c.mpay, c.acc.mpay)\n\tminLimit(&c.msubs, c.acc.msubs)\n\ts := c.srv\n\topts := s.getOpts()\n\tmPay := opts.MaxPayload\n\t// options encode unlimited differently\n\tif mPay == 0 {\n\t\tmPay = jwt.NoLimit\n\t}\n\tmSubs := int32(opts.MaxSubs)\n\tif mSubs == 0 {\n\t\tmSubs = jwt.NoLimit\n\t}\n\twasUnlimited := c.mpay == jwt.NoLimit\n\tif minLimit(&c.mpay, mPay) && !wasUnlimited {\n\t\tc.Errorf(\"Max Payload set to %d from server overrides account or user config\", opts.MaxPayload)\n\t}\n\twasUnlimited = c.msubs == jwt.NoLimit\n\tif minLimit(&c.msubs, mSubs) && !wasUnlimited {\n\t\tc.Errorf(\"Max Subscriptions set to %d from server overrides account or user config\", opts.MaxSubs)\n\t}\n\tif c.subsAtLimit() {\n\t\tgo func() {\n\t\t\tc.maxSubsExceeded()\n\t\t\ttime.Sleep(20 * time.Millisecond)\n\t\t\tc.closeConnection(MaxSubscriptionsExceeded)\n\t\t}()\n\t}\n}\n\n// RegisterUser allows auth to call back into a new client\n// with the authenticated user. This is used to map\n// any permissions into the client and setup accounts.\nfunc (c *client) RegisterUser(user *User) {\n\t// Register with proper account and sublist.\n\tif user.Account != nil {\n\t\tif err := c.registerWithAccount(user.Account); err != nil {\n\t\t\tc.reportErrRegisterAccount(user.Account, err)\n\t\t\treturn\n\t\t}\n\t}\n\n\tc.mu.Lock()\n\n\t// Assign permissions.\n\tif user.Permissions == nil {\n\t\t// Reset perms to nil in case client previously had them.\n\t\tc.perms = nil\n\t\tc.mperms = nil\n\t} else {\n\t\tc.setPermissions(user.Permissions)\n\t}\n\tc.mu.Unlock()\n}\n\n// RegisterNkey allows auth to call back into a new nkey\n// client with the authenticated user. This is used to map\n// any permissions into the client and setup accounts.\nfunc (c *client) RegisterNkeyUser(user *NkeyUser) error {\n\t// Register with proper account and sublist.\n\tif user.Account != nil {\n\t\tif err := c.registerWithAccount(user.Account); err != nil {\n\t\t\tc.reportErrRegisterAccount(user.Account, err)\n\t\t\treturn err\n\t\t}\n\t}\n\n\tc.mu.Lock()\n\tc.user = user\n\t// Assign permissions.\n\tif user.Permissions == nil {\n\t\t// Reset perms to nil in case client previously had them.\n\t\tc.perms = nil\n\t\tc.mperms = nil\n\t} else {\n\t\tc.setPermissions(user.Permissions)\n\t}\n\tc.mu.Unlock()\n\treturn nil\n}\n\nfunc splitSubjectQueue(sq string) ([]byte, []byte, error) {\n\tvals := strings.Fields(strings.TrimSpace(sq))\n\ts := []byte(vals[0])\n\tvar q []byte\n\tif len(vals) == 2 {\n\t\tq = []byte(vals[1])\n\t} else if len(vals) > 2 {\n\t\treturn nil, nil, fmt.Errorf(\"invalid subject-queue %q\", sq)\n\t}\n\treturn s, q, nil\n}\n\n// Initializes client.perms structure.\n// Lock is held on entry.\nfunc (c *client) setPermissions(perms *Permissions) {\n\tif perms == nil {\n\t\treturn\n\t}\n\tc.perms = &permissions{}\n\tc.perms.pcache = make(map[string]bool)\n\n\t// Loop over publish permissions\n\tif perms.Publish != nil {\n\t\tif perms.Publish.Allow != nil {\n\t\t\tc.perms.pub.allow = NewSublistWithCache()\n\t\t}\n\t\tfor _, pubSubject := range perms.Publish.Allow {\n\t\t\tsub := &subscription{subject: []byte(pubSubject)}\n\t\t\tc.perms.pub.allow.Insert(sub)\n\t\t}\n\t\tif len(perms.Publish.Deny) > 0 {\n\t\t\tc.perms.pub.deny = NewSublistWithCache()\n\t\t}\n\t\tfor _, pubSubject := range perms.Publish.Deny {\n\t\t\tsub := &subscription{subject: []byte(pubSubject)}\n\t\t\tc.perms.pub.deny.Insert(sub)\n\t\t}\n\t}\n\n\t// Check if we are allowed to send responses.\n\tif perms.Response != nil {\n\t\trp := *perms.Response\n\t\tc.perms.resp = &rp\n\t\tc.replies = make(map[string]*resp)\n\t}\n\n\t// Loop over subscribe permissions\n\tif perms.Subscribe != nil {\n\t\tvar err error\n\t\tif len(perms.Subscribe.Allow) > 0 {\n\t\t\tc.perms.sub.allow = NewSublistWithCache()\n\t\t}\n\t\tfor _, subSubject := range perms.Subscribe.Allow {\n\t\t\tsub := &subscription{}\n\t\t\tsub.subject, sub.queue, err = splitSubjectQueue(subSubject)\n\t\t\tif err != nil {\n\t\t\t\tc.Errorf(\"%s\", err.Error())\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tc.perms.sub.allow.Insert(sub)\n\t\t}\n\t\tif len(perms.Subscribe.Deny) > 0 {\n\t\t\tc.perms.sub.deny = NewSublistWithCache()\n\t\t\t// Also hold onto this array for later.\n\t\t\tc.darray = perms.Subscribe.Deny\n\t\t}\n\t\tfor _, subSubject := range perms.Subscribe.Deny {\n\t\t\tsub := &subscription{}\n\t\t\tsub.subject, sub.queue, err = splitSubjectQueue(subSubject)\n\t\t\tif err != nil {\n\t\t\t\tc.Errorf(\"%s\", err.Error())\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tc.perms.sub.deny.Insert(sub)\n\t\t}\n\t}\n\n\t// If we are a leafnode and we are the hub copy the extracted perms\n\t// to resend back to soliciting server. These are reversed from the\n\t// way routes interpret them since this is how the soliciting server\n\t// will receive these back in an update INFO.\n\tif c.isHubLeafNode() {\n\t\tc.opts.Import = perms.Subscribe\n\t\tc.opts.Export = perms.Publish\n\t}\n}\n\n// Check to see if we have an expiration for the user JWT via base claims.\n// FIXME(dlc) - Clear on connect with new JWT.\nfunc (c *client) setExpiration(claims *jwt.ClaimsData, validFor time.Duration) {\n\tif claims.Expires == 0 {\n\t\tif validFor != 0 {\n\t\t\tc.setExpirationTimer(validFor)\n\t\t}\n\t\treturn\n\t}\n\texpiresAt := time.Duration(0)\n\ttn := time.Now().Unix()\n\tif claims.Expires > tn {\n\t\texpiresAt = time.Duration(claims.Expires-tn) * time.Second\n\t}\n\tif validFor != 0 && validFor < expiresAt {\n\t\tc.setExpirationTimer(validFor)\n\t} else {\n\t\tc.setExpirationTimer(expiresAt)\n\t}\n}\n\n// This will load up the deny structure used for filtering delivered\n// messages based on a deny clause for subscriptions.\n// Lock should be held.\nfunc (c *client) loadMsgDenyFilter() {\n\tc.mperms = &msgDeny{NewSublistWithCache(), make(map[string]bool)}\n\tfor _, sub := range c.darray {\n\t\tc.mperms.deny.Insert(&subscription{subject: []byte(sub)})\n\t}\n}\n\n// writeLoop is the main socket write functionality.\n// Runs in its own Go routine.\nfunc (c *client) writeLoop() {\n\tdefer c.srv.grWG.Done()\n\tc.mu.Lock()\n\tif c.isClosed() {\n\t\tc.mu.Unlock()\n\t\treturn\n\t}\n\tc.flags.set(writeLoopStarted)\n\tc.mu.Unlock()\n\n\t// Used to check that we did flush from last wake up.\n\twaitOk := true\n\tvar close bool\n\n\t// Main loop. Will wait to be signaled and then will use\n\t// buffered outbound structure for efficient writev to the underlying socket.\n\tfor {\n\t\tc.mu.Lock()\n\t\tif close = c.isClosed(); !close {\n\t\t\towtf := c.out.fsp > 0 && c.out.pb < maxBufSize && c.out.fsp < maxFlushPending\n\t\t\tif waitOk && (c.out.pb == 0 || owtf) {\n\t\t\t\tc.out.sg.Wait()\n\t\t\t\t// Check that connection has not been closed while lock was released\n\t\t\t\t// in the conditional wait.\n\t\t\t\tclose = c.isClosed()\n\t\t\t}\n\t\t}\n\t\tif close {\n\t\t\tc.flushAndClose(false)\n\t\t\tc.mu.Unlock()\n\n\t\t\t// We should always call closeConnection() to ensure that state is\n\t\t\t// properly cleaned-up. It will be a no-op if already done.\n\t\t\tc.closeConnection(WriteError)\n\n\t\t\t// Now explicitly call reconnect(). Thanks to ref counting, we know\n\t\t\t// that the reconnect will execute only after connection has been\n\t\t\t// removed from the server state.\n\t\t\tc.reconnect()\n\t\t\treturn\n\t\t}\n\t\t// Flush data\n\t\twaitOk = c.flushOutbound()\n\t\tc.mu.Unlock()\n\t}\n}\n\n// flushClients will make sure to flush any clients we may have\n// sent to during processing. We pass in a budget as a time.Duration\n// for how much time to spend in place flushing for this client. This\n// will normally be called in the readLoop of the client who sent the\n// message that now is being delivered.\nfunc (c *client) flushClients(budget time.Duration) time.Time {\n\tlast := time.Now()\n\n\t// Check pending clients for flush.\n\tfor cp := range c.pcd {\n\t\t// TODO(dlc) - Wonder if it makes more sense to create a new map?\n\t\tdelete(c.pcd, cp)\n\n\t\t// Queue up a flush for those in the set\n\t\tcp.mu.Lock()\n\t\t// Update last activity for message delivery\n\t\tcp.last = last\n\t\t// Remove ourselves from the pending list.\n\t\tcp.out.fsp--\n\n\t\t// Just ignore if this was closed.\n\t\tif cp.isClosed() {\n\t\t\tcp.mu.Unlock()\n\t\t\tcontinue\n\t\t}\n\n\t\tif budget > 0 && cp.out.lft < 2*budget && cp.flushOutbound() {\n\t\t\tbudget -= cp.out.lft\n\t\t} else {\n\t\t\tcp.flushSignal()\n\t\t}\n\n\t\tcp.mu.Unlock()\n\t}\n\treturn last\n}\n\n// readLoop is the main socket read functionality.\n// Runs in its own Go routine.\nfunc (c *client) readLoop(pre []byte) {\n\t// Grab the connection off the client, it will be cleared on a close.\n\t// We check for that after the loop, but want to avoid a nil dereference\n\tc.mu.Lock()\n\ts := c.srv\n\tdefer s.grWG.Done()\n\tif c.isClosed() {\n\t\tc.mu.Unlock()\n\t\treturn\n\t}\n\tnc := c.nc\n\tws := c.isWebsocket()\n\tif c.isMqtt() {\n\t\tc.mqtt.r = &mqttReader{reader: nc}\n\t}\n\tc.in.rsz = startBufSize\n\t// Snapshot max control line since currently can not be changed on reload and we\n\t// were checking it on each call to parse. If this changes and we allow MaxControlLine\n\t// to be reloaded without restart, this code will need to change.\n\tc.mcl = MAX_CONTROL_LINE_SIZE\n\tif s != nil {\n\t\tif opts := s.getOpts(); opts != nil {\n\t\t\tc.mcl = int32(opts.MaxControlLine)\n\t\t}\n\t}\n\n\t// Check the per-account-cache for closed subscriptions\n\tcpacc := c.kind == ROUTER || c.kind == GATEWAY\n\t// Last per-account-cache check for closed subscriptions\n\tlpacc := time.Now()\n\tacc := c.acc\n\tc.mu.Unlock()\n\n\tdefer func() {\n\t\tif c.isMqtt() {\n\t\t\ts.mqttHandleWill(c)\n\t\t}\n\t\t// These are used only in the readloop, so we can set them to nil\n\t\t// on exit of the readLoop.\n\t\tc.in.results, c.in.pacache = nil, nil\n\t}()\n\n\t// Start read buffer.\n\tb := make([]byte, c.in.rsz)\n\n\t// Websocket clients will return several slices if there are multiple\n\t// websocket frames in the blind read. For non WS clients though, we\n\t// will always have 1 slice per loop iteration. So we define this here\n\t// so non WS clients will use bufs[0] = b[:n].\n\tvar _bufs [1][]byte\n\tbufs := _bufs[:1]\n\n\tvar wsr *wsReadInfo\n\tif ws {\n\t\twsr = &wsReadInfo{}\n\t\twsr.init()\n\t}\n\n\t// If we have a pre buffer parse that first.\n\tif len(pre) > 0 {\n\t\tc.parse(pre)\n\t}\n\n\tfor {\n\t\tn, err := nc.Read(b)\n\t\t// If we have any data we will try to parse and exit at the end.\n\t\tif n == 0 && err != nil {\n\t\t\tc.closeConnection(closedStateForErr(err))\n\t\t\treturn\n\t\t}\n\t\tif ws {\n\t\t\tbufs, err = c.wsRead(wsr, nc, b[:n])\n\t\t\tif bufs == nil && err != nil {\n\t\t\t\tif err != io.EOF {\n\t\t\t\t\tc.Errorf(\"read error: %v\", err)\n\t\t\t\t}\n\t\t\t\tc.closeConnection(closedStateForErr(err))\n\t\t\t} else if bufs == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t} else {\n\t\t\tbufs[0] = b[:n]\n\t\t}\n\t\tstart := time.Now()\n\n\t\t// Check if the account has mappings and if so set the local readcache flag.\n\t\t// We check here to make sure any changes such as config reload are reflected here.\n\t\tif c.kind == CLIENT {\n\t\t\tif acc.hasMappings() {\n\t\t\t\tc.in.flags.set(hasMappings)\n\t\t\t} else {\n\t\t\t\tc.in.flags.clear(hasMappings)\n\t\t\t}\n\t\t}\n\n\t\t// Clear inbound stats cache\n\t\tc.in.msgs = 0\n\t\tc.in.bytes = 0\n\t\tc.in.subs = 0\n\n\t\t// Main call into parser for inbound data. This will generate callouts\n\t\t// to process messages, etc.\n\t\tfor i := 0; i < len(bufs); i++ {\n\t\t\tif err := c.parse(bufs[i]); err != nil {\n\t\t\t\tif dur := time.Since(start); dur >= readLoopReportThreshold {\n\t\t\t\t\tc.Warnf(\"Readloop processing time: %v\", dur)\n\t\t\t\t}\n\t\t\t\t// Need to call flushClients because some of the clients have been\n\t\t\t\t// assigned messages and their \"fsp\" incremented, and need now to be\n\t\t\t\t// decremented and their writeLoop signaled.\n\t\t\t\tc.flushClients(0)\n\t\t\t\t// handled inline\n\t\t\t\tif err != ErrMaxPayload && err != ErrAuthentication {\n\t\t\t\t\tc.Error(err)\n\t\t\t\t\tc.closeConnection(ProtocolViolation)\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\t// Updates stats for client and server that were collected\n\t\t// from parsing through the buffer.\n\t\tif c.in.msgs > 0 {\n\t\t\tatomic.AddInt64(&c.inMsgs, int64(c.in.msgs))\n\t\t\tatomic.AddInt64(&c.inBytes, int64(c.in.bytes))\n\t\t\tatomic.AddInt64(&s.inMsgs, int64(c.in.msgs))\n\t\t\tatomic.AddInt64(&s.inBytes, int64(c.in.bytes))\n\t\t}\n\n\t\t// Budget to spend in place flushing outbound data.\n\t\t// Client will be checked on several fronts to see\n\t\t// if applicable. Routes and Gateways will never\n\t\t// spend time flushing outbound in place.\n\t\tvar budget time.Duration\n\t\tif c.kind == CLIENT {\n\t\t\tbudget = time.Millisecond\n\t\t}\n\n\t\t// Flush, or signal to writeLoop to flush to socket.\n\t\tlast := c.flushClients(budget)\n\n\t\t// Update activity, check read buffer size.\n\t\tc.mu.Lock()\n\n\t\t// Activity based on interest changes or data/msgs.\n\t\tif c.in.msgs > 0 || c.in.subs > 0 {\n\t\t\tc.last = last\n\t\t}\n\n\t\tif n >= cap(b) {\n\t\t\tc.in.srs = 0\n\t\t} else if n < cap(b)/2 { // divide by 2 b/c we want less than what we would shrink to.\n\t\t\tc.in.srs++\n\t\t}\n\n\t\t// Update read buffer size as/if needed.\n\t\tif n >= cap(b) && cap(b) < maxBufSize {\n\t\t\t// Grow\n\t\t\tc.in.rsz = int32(cap(b) * 2)\n\t\t\tb = make([]byte, c.in.rsz)\n\t\t} else if n < cap(b) && cap(b) > minBufSize && c.in.srs > shortsToShrink {\n\t\t\t// Shrink, for now don't accelerate, ping/pong will eventually sort it out.\n\t\t\tc.in.rsz = int32(cap(b) / 2)\n\t\t\tb = make([]byte, c.in.rsz)\n\t\t}\n\t\t// re-snapshot the account since it can change during reload, etc.\n\t\tacc = c.acc\n\t\tc.mu.Unlock()\n\n\t\tif dur := time.Since(start); dur >= readLoopReportThreshold {\n\t\t\tc.Warnf(\"Readloop processing time: %v\", dur)\n\t\t}\n\n\t\t// We could have had a read error from above but still read some data.\n\t\t// If so do the close here unconditionally.\n\t\tif err != nil {\n\t\t\tc.closeConnection(closedStateForErr(err))\n\t\t\treturn\n\t\t}\n\n\t\tif cpacc && (start.Sub(lpacc)) >= closedSubsCheckInterval {\n\t\t\tc.pruneClosedSubFromPerAccountCache()\n\t\t\tlpacc = time.Now()\n\t\t}\n\t}\n}\n\n// Returns the appropriate closed state for a given read error.\nfunc closedStateForErr(err error) ClosedState {\n\tif err == io.EOF {\n\t\treturn ClientClosed\n\t}\n\treturn ReadError\n}\n\n// collapsePtoNB will place primary onto nb buffer as needed in prep for WriteTo.\n// This will return a copy on purpose.\nfunc (c *client) collapsePtoNB() (net.Buffers, int64) {\n\tif c.isWebsocket() {\n\t\treturn c.wsCollapsePtoNB()\n\t}\n\tif c.out.p != nil {\n\t\tp := c.out.p\n\t\tc.out.p = nil\n\t\treturn append(c.out.nb, p), c.out.pb\n\t}\n\treturn c.out.nb, c.out.pb\n}\n\n// This will handle the fixup needed on a partial write.\n// Assume pending has been already calculated correctly.\nfunc (c *client) handlePartialWrite(pnb net.Buffers) {\n\tif c.isWebsocket() {\n\t\tc.ws.frames = append(pnb, c.ws.frames...)\n\t\treturn\n\t}\n\tnb, _ := c.collapsePtoNB()\n\t// The partial needs to be first, so append nb to pnb\n\tc.out.nb = append(pnb, nb...)\n}\n\n// flushOutbound will flush outbound buffer to a client.\n// Will return true if data was attempted to be written.\n// Lock must be held\nfunc (c *client) flushOutbound() bool {\n\tif c.flags.isSet(flushOutbound) {\n\t\t// For CLIENT connections, it is possible that the readLoop calls\n\t\t// flushOutbound(). If writeLoop and readLoop compete and we are\n\t\t// here we should release the lock to reduce the risk of spinning.\n\t\tc.mu.Unlock()\n\t\truntime.Gosched()\n\t\tc.mu.Lock()\n\t\treturn false\n\t}\n\tc.flags.set(flushOutbound)\n\tdefer c.flags.clear(flushOutbound)\n\n\t// Check for nothing to do.\n\tif c.nc == nil || c.srv == nil || c.out.pb == 0 {\n\t\treturn true // true because no need to queue a signal.\n\t}\n\n\t// Place primary on nb, assign primary to secondary, nil out nb and secondary.\n\tnb, attempted := c.collapsePtoNB()\n\tc.out.p, c.out.nb, c.out.s = c.out.s, nil, nil\n\tif nb == nil {\n\t\treturn true\n\t}\n\n\t// For selecting primary replacement.\n\tcnb := nb\n\tvar lfs int\n\tif len(cnb) > 0 {\n\t\tlfs = len(cnb[0])\n\t}\n\n\t// In case it goes away after releasing the lock.\n\tnc := c.nc\n\tapm := c.out.pm\n\n\t// Capture this (we change the value in some tests)\n\twdl := c.out.wdl\n\t// Do NOT hold lock during actual IO.\n\tc.mu.Unlock()\n\n\t// flush here\n\tstart := time.Now()\n\n\t// FIXME(dlc) - writev will do multiple IOs past 1024 on\n\t// most platforms, need to account for that with deadline?\n\tnc.SetWriteDeadline(start.Add(wdl))\n\n\t// Actual write to the socket.\n\tn, err := nb.WriteTo(nc)\n\tnc.SetWriteDeadline(time.Time{})\n\n\tlft := time.Since(start)\n\n\t// Re-acquire client lock.\n\tc.mu.Lock()\n\n\t// Ignore ErrShortWrite errors, they will be handled as partials.\n\tif err != nil && err != io.ErrShortWrite {\n\t\t// Handle timeout error (slow consumer) differently\n\t\tif ne, ok := err.(net.Error); ok && ne.Timeout() {\n\t\t\tif closed := c.handleWriteTimeout(n, attempted, len(cnb)); closed {\n\t\t\t\treturn true\n\t\t\t}\n\t\t} else {\n\t\t\t// Other errors will cause connection to be closed.\n\t\t\t// For clients, report as debug but for others report as error.\n\t\t\treport := c.Debugf\n\t\t\tif c.kind != CLIENT {\n\t\t\t\treport = c.Errorf\n\t\t\t}\n\t\t\treport(\"Error flushing: %v\", err)\n\t\t\tc.markConnAsClosed(WriteError)\n\t\t\treturn true\n\t\t}\n\t}\n\n\t// Update flush time statistics.\n\tc.out.lft = lft\n\n\t// Subtract from pending bytes and messages.\n\tc.out.pb -= n\n\tif c.isWebsocket() {\n\t\tc.ws.fs -= n\n\t}\n\tc.out.pm -= apm // FIXME(dlc) - this will not be totally accurate on partials.\n\n\t// Check for partial writes\n\t// TODO(dlc) - zero write with no error will cause lost message and the writeloop to spin.\n\tif n != attempted && n > 0 {\n\t\tc.handlePartialWrite(nb)\n\t} else if int32(n) >= c.out.sz {\n\t\tc.out.sws = 0\n\t}\n\n\t// Adjust based on what we wrote plus any pending.\n\tpt := n + c.out.pb\n\n\t// Adjust sz as needed downward, keeping power of 2.\n\t// We do this at a slower rate.\n\tif pt < int64(c.out.sz) && c.out.sz > minBufSize {\n\t\tc.out.sws++\n\t\tif c.out.sws > shortsToShrink {\n\t\t\tc.out.sz >>= 1\n\t\t}\n\t}\n\t// Adjust sz as needed upward, keeping power of 2.\n\tif pt > int64(c.out.sz) && c.out.sz < maxBufSize {\n\t\tc.out.sz <<= 1\n\t}\n\n\t// Check to see if we can reuse buffers.\n\tif lfs != 0 && n >= int64(lfs) {\n\t\toldp := cnb[0][:0]\n\t\tif cap(oldp) >= int(c.out.sz) {\n\t\t\t// Replace primary or secondary if they are nil, reusing same buffer.\n\t\t\tif c.out.p == nil {\n\t\t\t\tc.out.p = oldp\n\t\t\t} else if c.out.s == nil || cap(c.out.s) < int(c.out.sz) {\n\t\t\t\tc.out.s = oldp\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check that if there is still data to send and writeLoop is in wait,\n\t// then we need to signal.\n\tif c.out.pb > 0 {\n\t\tc.flushSignal()\n\t}\n\n\t// Check if we have a stalled gate and if so and we are recovering release\n\t// any stalled producers. Only kind==CLIENT will stall.\n\tif c.out.stc != nil && (n == attempted || c.out.pb < c.out.mp/2) {\n\t\tclose(c.out.stc)\n\t\tc.out.stc = nil\n\t}\n\n\treturn true\n}\n\n// This is invoked from flushOutbound() for io/timeout error (slow consumer).\n// Returns a boolean to indicate if the connection has been closed or not.\n// Lock is held on entry.\nfunc (c *client) handleWriteTimeout(written, attempted int64, numChunks int) bool {\n\tif tlsConn, ok := c.nc.(*tls.Conn); ok {\n\t\tif !tlsConn.ConnectionState().HandshakeComplete {\n\t\t\t// Likely a TLSTimeout error instead...\n\t\t\tc.markConnAsClosed(TLSHandshakeError)\n\t\t\t// Would need to coordinate with tlstimeout()\n\t\t\t// to avoid double logging, so skip logging\n\t\t\t// here, and don't report a slow consumer error.\n\t\t\treturn true\n\t\t}\n\t} else if c.flags.isSet(expectConnect) && !c.flags.isSet(connectReceived) {\n\t\t// Under some conditions, a connection may hit a slow consumer write deadline\n\t\t// before the authorization timeout. If that is the case, then we handle\n\t\t// as slow consumer though we do not increase the counter as that can be\n\t\t// misleading.\n\t\tc.markConnAsClosed(SlowConsumerWriteDeadline)\n\t\treturn true\n\t}\n\n\t// Slow consumer here..\n\tatomic.AddInt64(&c.srv.slowConsumers, 1)\n\tc.Noticef(\"Slow Consumer Detected: WriteDeadline of %v exceeded with %d chunks of %d total bytes.\",\n\t\tc.out.wdl, numChunks, attempted)\n\n\t// We always close CLIENT connections, or when nothing was written at all...\n\tif c.kind == CLIENT || written == 0 {\n\t\tc.markConnAsClosed(SlowConsumerWriteDeadline)\n\t\treturn true\n\t}\n\treturn false\n}\n\n// Marks this connection has closed with the given reason.\n// Sets the connMarkedClosed flag and skipFlushOnClose depending on the reason.\n// Depending on the kind of connection, the connection will be saved.\n// If a writeLoop has been started, the final flush will be done there, otherwise\n// flush and close of TCP connection is done here in place.\n// Returns true if closed in place, flase otherwise.\n// Lock is held on entry.\nfunc (c *client) markConnAsClosed(reason ClosedState) {\n\t// Possibly set skipFlushOnClose flag even if connection has already been\n\t// mark as closed. The rationale is that a connection may be closed with\n\t// a reason that justifies a flush (say after sending an -ERR), but then\n\t// the flushOutbound() gets a write error. If that happens, connection\n\t// being lost, there is no reason to attempt to flush again during the\n\t// teardown when the writeLoop exits.\n\tvar skipFlush bool\n\tswitch reason {\n\tcase ReadError, WriteError, SlowConsumerPendingBytes, SlowConsumerWriteDeadline, TLSHandshakeError:\n\t\tc.flags.set(skipFlushOnClose)\n\t\tskipFlush = true\n\t}\n\tif c.flags.isSet(connMarkedClosed) {\n\t\treturn\n\t}\n\tc.flags.set(connMarkedClosed)\n\t// For a websocket client, unless we are told not to flush, enqueue\n\t// a websocket CloseMessage based on the reason.\n\tif !skipFlush && c.isWebsocket() && !c.ws.closeSent {\n\t\tc.wsEnqueueCloseMessage(reason)\n\t}\n\t// Be consistent with the creation: for routes and gateways,\n\t// we use Noticef on create, so use that too for delete.\n\tif c.srv != nil {\n\t\tif c.kind == ROUTER || c.kind == GATEWAY {\n\t\t\tc.Noticef(\"%s connection closed: %s\", c.typeString(), reason)\n\t\t} else { // Client, System, Jetstream, Account and Leafnode connections.\n\t\t\tc.Debugf(\"%s connection closed: %s\", c.typeString(), reason)\n\t\t}\n\t}\n\n\t// Save off the connection if its a client or leafnode.\n\tif c.kind == CLIENT || c.kind == LEAF {\n\t\tif nc := c.nc; nc != nil && c.srv != nil {\n\t\t\t// TODO: May want to send events to single go routine instead\n\t\t\t// of creating a new go routine for each save.\n\t\t\tgo c.srv.saveClosedClient(c, nc, reason)\n\t\t}\n\t}\n\t// If writeLoop exists, let it do the final flush, close and teardown.\n\tif c.flags.isSet(writeLoopStarted) {\n\t\t// Since we want the writeLoop to do the final flush and tcp close,\n\t\t// we want the reconnect to be done there too. However, it should'nt\n\t\t// happen before the connection has been removed from the server\n\t\t// state (end of closeConnection()). This ref count allows us to\n\t\t// guarantee that.\n\t\tc.rref++\n\t\tc.flushSignal()\n\t\treturn\n\t}\n\t// Flush (if skipFlushOnClose is not set) and close in place. If flushing,\n\t// use a small WriteDeadline.\n\tc.flushAndClose(true)\n}\n\n// flushSignal will use server to queue the flush IO operation to a pool of flushers.\n// Lock must be held.\nfunc (c *client) flushSignal() {\n\tc.out.sg.Signal()\n}\n\n// Traces a message.\n// Will NOT check if tracing is enabled, does NOT need the client lock.\nfunc (c *client) traceMsg(msg []byte) {\n\tmaxTrace := c.srv.getOpts().MaxTracedMsgLen\n\tif maxTrace > 0 && (len(msg)-LEN_CR_LF) > maxTrace {\n\t\tc.Tracef(\"<<- MSG_PAYLOAD: [\\\"%s...\\\"]\", msg[:maxTrace])\n\t} else {\n\t\tc.Tracef(\"<<- MSG_PAYLOAD: [%q]\", msg[:len(msg)-LEN_CR_LF])\n\t}\n}\n\n// Traces an incoming operation.\n// Will NOT check if tracing is enabled, does NOT need the client lock.\nfunc (c *client) traceInOp(op string, arg []byte) {\n\tc.traceOp(\"<<- %s\", op, arg)\n}\n\n// Traces an outgoing operation.\n// Will NOT check if tracing is enabled, does NOT need the client lock.\nfunc (c *client) traceOutOp(op string, arg []byte) {\n\tc.traceOp(\"->> %s\", op, arg)\n}\n\nfunc (c *client) traceOp(format, op string, arg []byte) {\n\topa := []interface{}{}\n\tif op != \"\" {\n\t\topa = append(opa, op)\n\t}\n\tif arg != nil {\n\t\topa = append(opa, string(arg))\n\t}\n\tc.Tracef(format, opa)\n}\n\n// Process the information messages from Clients and other Routes.\nfunc (c *client) processInfo(arg []byte) error {\n\tinfo := Info{}\n\tif err := json.Unmarshal(arg, &info); err != nil {\n\t\treturn err\n\t}\n\tswitch c.kind {\n\tcase ROUTER:\n\t\tc.processRouteInfo(&info)\n\tcase GATEWAY:\n\t\tc.processGatewayInfo(&info)\n\tcase LEAF:\n\t\treturn c.processLeafnodeInfo(&info)\n\t}\n\treturn nil\n}\n\nfunc (c *client) processErr(errStr string) {\n\tclose := true\n\tswitch c.kind {\n\tcase CLIENT:\n\t\tc.Errorf(\"Client Error %s\", errStr)\n\tcase ROUTER:\n\t\tc.Errorf(\"Route Error %s\", errStr)\n\tcase GATEWAY:\n\t\tc.Errorf(\"Gateway Error %s\", errStr)\n\tcase LEAF:\n\t\tc.Errorf(\"Leafnode Error %s\", errStr)\n\t\tc.leafProcessErr(errStr)\n\t\tclose = false\n\tcase JETSTREAM:\n\t\tc.Errorf(\"JetStream Error %s\", errStr)\n\t}\n\tif close {\n\t\tc.closeConnection(ParseError)\n\t}\n}\n\n// Password pattern matcher.\nvar passPat = regexp.MustCompile(`\"?\\s*pass\\S*?\"?\\s*[:=]\\s*\"?(([^\",\\r\\n}])*)`)\n\n// removePassFromTrace removes any notion of passwords from trace\n// messages for logging.\nfunc removePassFromTrace(arg []byte) []byte {\n\tif !bytes.Contains(arg, []byte(`pass`)) {\n\t\treturn arg\n\t}\n\t// Take a copy of the connect proto just for the trace message.\n\tvar _arg [4096]byte\n\tbuf := append(_arg[:0], arg...)\n\n\tm := passPat.FindAllSubmatchIndex(buf, -1)\n\tif len(m) == 0 {\n\t\treturn arg\n\t}\n\n\tredactedPass := []byte(\"[REDACTED]\")\n\tfor _, i := range m {\n\t\tif len(i) < 4 {\n\t\t\tcontinue\n\t\t}\n\t\tstart := i[2]\n\t\tend := i[3]\n\n\t\t// Replace password substring.\n\t\tbuf = append(buf[:start], append(redactedPass, buf[end:]...)...)\n\t\tbreak\n\t}\n\treturn buf\n}\n\n// Returns the RTT by computing the elapsed time since now and `start`.\n// On Windows VM where I (IK) run tests, time.Since() will return 0\n// (I suspect some time granularity issues). So return at minimum 1ns.\nfunc computeRTT(start time.Time) time.Duration {\n\trtt := time.Since(start)\n\tif rtt <= 0 {\n\t\trtt = time.Nanosecond\n\t}\n\treturn rtt\n}\n\n// processConnect will process a client connect op.\nfunc (c *client) processConnect(arg []byte) error {\n\tsupportsHeaders := c.srv.supportsHeaders()\n\tc.mu.Lock()\n\t// If we can't stop the timer because the callback is in progress...\n\tif !c.clearAuthTimer() {\n\t\t// wait for it to finish and handle sending the failure back to\n\t\t// the client.\n\t\tfor !c.isClosed() {\n\t\t\tc.mu.Unlock()\n\t\t\ttime.Sleep(25 * time.Millisecond)\n\t\t\tc.mu.Lock()\n\t\t}\n\t\tc.mu.Unlock()\n\t\treturn nil\n\t}\n\tc.last = time.Now()\n\t// Estimate RTT to start.\n\tif c.kind == CLIENT {\n\t\tc.rtt = computeRTT(c.start)\n\t\tif c.srv != nil {\n\t\t\tc.clearPingTimer()\n\t\t\tc.srv.setFirstPingTimer(c)\n\t\t}\n\t}\n\tkind := c.kind\n\tsrv := c.srv\n\n\t// Moved unmarshalling of clients' Options under the lock.\n\t// The client has already been added to the server map, so it is possible\n\t// that other routines lookup the client, and access its options under\n\t// the client's lock, so unmarshalling the options outside of the lock\n\t// would cause data RACEs.\n\tif err := json.Unmarshal(arg, &c.opts); err != nil {\n\t\tc.mu.Unlock()\n\t\treturn err\n\t}\n\t// Indicate that the CONNECT protocol has been received, and that the\n\t// server now knows which protocol this client supports.\n\tc.flags.set(connectReceived)\n\t// Capture these under lock\n\tc.echo = c.opts.Echo\n\tproto := c.opts.Protocol\n\tverbose := c.opts.Verbose\n\tlang := c.opts.Lang\n\taccount := c.opts.Account\n\taccountNew := c.opts.AccountNew\n\n\tif c.kind == CLIENT {\n\t\tvar ncs string\n\t\tif c.opts.Version != \"\" {\n\t\t\tncs = fmt.Sprintf(\"v%s\", c.opts.Version)\n\t\t}\n\t\tif c.opts.Lang != \"\" {\n\t\t\tif c.opts.Version == _EMPTY_ {\n\t\t\t\tncs = c.opts.Lang\n\t\t\t} else {\n\t\t\t\tncs = fmt.Sprintf(\"%s:%s\", ncs, c.opts.Lang)\n\t\t\t}\n\t\t}\n\t\tif c.opts.Name != \"\" {\n\t\t\tif c.opts.Version == _EMPTY_ && c.opts.Lang == _EMPTY_ {\n\t\t\t\tncs = c.opts.Name\n\t\t\t} else {\n\t\t\t\tncs = fmt.Sprintf(\"%s:%s\", ncs, c.opts.Name)\n\t\t\t}\n\t\t}\n\t\tif ncs != _EMPTY_ {\n\t\t\tc.ncs.Store(fmt.Sprintf(\"%s - %q\", c.String(), ncs))\n\t\t}\n\t}\n\n\t// If websocket client and JWT not in the CONNECT, use the cookie JWT (possibly empty).\n\tif ws := c.ws; ws != nil && c.opts.JWT == \"\" {\n\t\tc.opts.JWT = ws.cookieJwt\n\t}\n\t// when not in operator mode, discard the jwt\n\tif srv != nil && srv.trustedKeys == nil {\n\t\tc.opts.JWT = \"\"\n\t}\n\tujwt := c.opts.JWT\n\n\t// For headers both client and server need to support.\n\tc.headers = supportsHeaders && c.opts.Headers\n\tc.mu.Unlock()\n\n\tif srv != nil {\n\t\t// Applicable to clients only:\n\t\t// As soon as c.opts is unmarshalled and if the proto is at\n\t\t// least ClientProtoInfo, we need to increment the following counter.\n\t\t// This is decremented when client is removed from the server's\n\t\t// clients map.\n\t\tif kind == CLIENT && proto >= ClientProtoInfo {\n\t\t\tsrv.mu.Lock()\n\t\t\tsrv.cproto++\n\t\t\tsrv.mu.Unlock()\n\t\t}\n\n\t\t// Check for Auth\n\t\tif ok := srv.checkAuthentication(c); !ok {\n\t\t\t// We may fail here because we reached max limits on an account.\n\t\t\tif ujwt != \"\" {\n\t\t\t\tc.mu.Lock()\n\t\t\t\tacc := c.acc\n\t\t\t\tc.mu.Unlock()\n\t\t\t\tsrv.mu.Lock()\n\t\t\t\ttooManyAccCons := acc != nil && acc != srv.gacc\n\t\t\t\tsrv.mu.Unlock()\n\t\t\t\tif tooManyAccCons {\n\t\t\t\t\treturn ErrTooManyAccountConnections\n\t\t\t\t}\n\t\t\t}\n\t\t\tc.authViolation()\n\t\t\treturn ErrAuthentication\n\t\t}\n\n\t\t// Check for Account designation, this section should be only used when there is not a jwt.\n\t\tif account != \"\" {\n\t\t\tvar acc *Account\n\t\t\tvar wasNew bool\n\t\t\tvar err error\n\t\t\tif !srv.NewAccountsAllowed() {\n\t\t\t\tacc, err = srv.LookupAccount(account)\n\t\t\t\tif err != nil {\n\t\t\t\t\tc.Errorf(err.Error())\n\t\t\t\t\tc.sendErr(ErrMissingAccount.Error())\n\t\t\t\t\treturn err\n\t\t\t\t} else if accountNew && acc != nil {\n\t\t\t\t\tc.sendErrAndErr(ErrAccountExists.Error())\n\t\t\t\t\treturn ErrAccountExists\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t// We can create this one on the fly.\n\t\t\t\tacc, wasNew = srv.LookupOrRegisterAccount(account)\n\t\t\t\tif accountNew && !wasNew {\n\t\t\t\t\tc.sendErrAndErr(ErrAccountExists.Error())\n\t\t\t\t\treturn ErrAccountExists\n\t\t\t\t}\n\t\t\t}\n\t\t\t// If we are here we can register ourselves with the new account.\n\t\t\tif err := c.registerWithAccount(acc); err != nil {\n\t\t\t\tc.reportErrRegisterAccount(acc, err)\n\t\t\t\treturn ErrBadAccount\n\t\t\t}\n\t\t} else if c.acc == nil {\n\t\t\t// By default register with the global account.\n\t\t\tc.registerWithAccount(srv.globalAccount())\n\t\t}\n\t}\n\n\tswitch kind {\n\tcase CLIENT:\n\t\t// Check client protocol request if it exists.\n\t\tif proto < ClientProtoZero || proto > ClientProtoInfo {\n\t\t\tc.sendErr(ErrBadClientProtocol.Error())\n\t\t\tc.closeConnection(BadClientProtocolVersion)\n\t\t\treturn ErrBadClientProtocol\n\t\t}\n\t\t// Check to see that if no_responders is requested\n\t\t// they have header support on as well.\n\t\tc.mu.Lock()\n\t\tmisMatch := c.opts.NoResponders && !c.headers\n\t\tc.mu.Unlock()\n\t\tif misMatch {\n\t\t\tc.sendErr(ErrNoRespondersRequiresHeaders.Error())\n\t\t\tc.closeConnection(NoRespondersRequiresHeaders)\n\t\t\treturn ErrNoRespondersRequiresHeaders\n\t\t}\n\t\tif verbose {\n\t\t\tc.sendOK()\n\t\t}\n\tcase ROUTER:\n\t\t// Delegate the rest of processing to the route\n\t\treturn c.processRouteConnect(srv, arg, lang)\n\tcase GATEWAY:\n\t\t// Delegate the rest of processing to the gateway\n\t\treturn c.processGatewayConnect(arg)\n\tcase LEAF:\n\t\t// Delegate the rest of processing to the leaf node\n\t\treturn c.processLeafNodeConnect(srv, arg, lang)\n\t}\n\treturn nil\n}\n\nfunc (c *client) sendErrAndErr(err string) {\n\tc.sendErr(err)\n\tc.Errorf(err)\n}\n\nfunc (c *client) sendErrAndDebug(err string) {\n\tc.sendErr(err)\n\tc.Debugf(err)\n}\n\nfunc (c *client) authTimeout() {\n\tc.sendErrAndDebug(\"Authentication Timeout\")\n\tc.closeConnection(AuthenticationTimeout)\n}\n\nfunc (c *client) authExpired() {\n\tc.sendErrAndDebug(\"User Authentication Expired\")\n\tc.closeConnection(AuthenticationExpired)\n}\n\nfunc (c *client) accountAuthExpired() {\n\tc.sendErrAndDebug(\"Account Authentication Expired\")\n\tc.closeConnection(AuthenticationExpired)\n}\n\nfunc (c *client) authViolation() {\n\tvar s *Server\n\tvar hasTrustedNkeys, hasNkeys, hasUsers bool\n\tif s = c.srv; s != nil {\n\t\ts.mu.Lock()\n\t\thasTrustedNkeys = len(s.trustedKeys) > 0\n\t\thasNkeys = s.nkeys != nil\n\t\thasUsers = s.users != nil\n\t\ts.mu.Unlock()\n\t\tdefer s.sendAuthErrorEvent(c)\n\n\t}\n\tif hasTrustedNkeys {\n\t\tc.Errorf(\"%v\", ErrAuthentication)\n\t} else if hasNkeys {\n\t\tc.Errorf(\"%s - Nkey %q\",\n\t\t\tErrAuthentication.Error(),\n\t\t\tc.opts.Nkey)\n\t} else if hasUsers {\n\t\tc.Errorf(\"%s - User %q\",\n\t\t\tErrAuthentication.Error(),\n\t\t\tc.opts.Username)\n\t} else {\n\t\tc.Errorf(ErrAuthentication.Error())\n\t}\n\tc.sendErr(\"Authorization Violation\")\n\tc.closeConnection(AuthenticationViolation)\n}\n\nfunc (c *client) maxAccountConnExceeded() {\n\tc.sendErrAndErr(ErrTooManyAccountConnections.Error())\n\tc.closeConnection(MaxAccountConnectionsExceeded)\n}\n\nfunc (c *client) maxConnExceeded() {\n\tc.sendErrAndErr(ErrTooManyConnections.Error())\n\tc.closeConnection(MaxConnectionsExceeded)\n}\n\nfunc (c *client) maxSubsExceeded() {\n\tc.sendErrAndErr(ErrTooManySubs.Error())\n}\n\nfunc (c *client) maxPayloadViolation(sz int, max int32) {\n\tc.Errorf(\"%s: %d vs %d\", ErrMaxPayload.Error(), sz, max)\n\tc.sendErr(\"Maximum Payload Violation\")\n\tc.closeConnection(MaxPayloadExceeded)\n}\n\n// queueOutbound queues data for a clientconnection.\n// Returns if the data is referenced or not. If referenced, the caller\n// should not reuse the `data` array.\n// Lock should be held.\nfunc (c *client) queueOutbound(data []byte) bool {\n\t// Do not keep going if closed\n\tif c.isClosed() {\n\t\treturn false\n\t}\n\n\t// Assume data will not be referenced\n\treferenced := false\n\t// Add to pending bytes total.\n\tc.out.pb += int64(len(data))\n\n\t// Check for slow consumer via pending bytes limit.\n\t// ok to return here, client is going away.\n\tif c.kind == CLIENT && c.out.pb > c.out.mp {\n\t\t// Perf wise, it looks like it is faster to optimistically add than\n\t\t// checking current pb+len(data) and then add to pb.\n\t\tc.out.pb -= int64(len(data))\n\t\tatomic.AddInt64(&c.srv.slowConsumers, 1)\n\t\tc.Noticef(\"Slow Consumer Detected: MaxPending of %d Exceeded\", c.out.mp)\n\t\tc.markConnAsClosed(SlowConsumerPendingBytes)\n\t\treturn referenced\n\t}\n\n\tif c.out.p == nil && len(data) < maxBufSize {\n\t\tif c.out.sz == 0 {\n\t\t\tc.out.sz = startBufSize\n\t\t}\n\t\tif c.out.s != nil && cap(c.out.s) >= int(c.out.sz) {\n\t\t\tc.out.p = c.out.s\n\t\t\tc.out.s = nil\n\t\t} else {\n\t\t\t// FIXME(dlc) - make power of 2 if less than maxBufSize?\n\t\t\tc.out.p = make([]byte, 0, c.out.sz)\n\t\t}\n\t}\n\t// Determine if we copy or reference\n\tavailable := cap(c.out.p) - len(c.out.p)\n\tif len(data) > available {\n\t\t// We can't fit everything into existing primary, but message will\n\t\t// fit in next one we allocate or utilize from the secondary.\n\t\t// So copy what we can.\n\t\tif available > 0 && len(data) < int(c.out.sz) {\n\t\t\tc.out.p = append(c.out.p, data[:available]...)\n\t\t\tdata = data[available:]\n\t\t}\n\t\t// Put the primary on the nb if it has a payload\n\t\tif len(c.out.p) > 0 {\n\t\t\tc.out.nb = append(c.out.nb, c.out.p)\n\t\t\tc.out.p = nil\n\t\t}\n\t\t// Check for a big message, and if found place directly on nb\n\t\t// FIXME(dlc) - do we need signaling of ownership here if we want len(data) < maxBufSize\n\t\tif len(data) > maxBufSize {\n\t\t\tc.out.nb = append(c.out.nb, data)\n\t\t\treferenced = true\n\t\t} else {\n\t\t\t// We will copy to primary.\n\t\t\tif c.out.p == nil {\n\t\t\t\t// Grow here\n\t\t\t\tif (c.out.sz << 1) <= maxBufSize {\n\t\t\t\t\tc.out.sz <<= 1\n\t\t\t\t}\n\t\t\t\tif len(data) > int(c.out.sz) {\n\t\t\t\t\tc.out.p = make([]byte, 0, len(data))\n\t\t\t\t} else {\n\t\t\t\t\tif c.out.s != nil && cap(c.out.s) >= int(c.out.sz) { // TODO(dlc) - Size mismatch?\n\t\t\t\t\t\tc.out.p = c.out.s\n\t\t\t\t\t\tc.out.s = nil\n\t\t\t\t\t} else {\n\t\t\t\t\t\tc.out.p = make([]byte, 0, c.out.sz)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tc.out.p = append(c.out.p, data...)\n\t\t}\n\t} else {\n\t\tc.out.p = append(c.out.p, data...)\n\t}\n\n\t// Check here if we should create a stall channel if we are falling behind.\n\t// We do this here since if we wait for consumer's writeLoop it could be\n\t// too late with large number of fan in producers.\n\tif c.out.pb > c.out.mp/2 && c.out.stc == nil {\n\t\tc.out.stc = make(chan struct{})\n\t}\n\n\treturn referenced\n}\n\n// Assume the lock is held upon entry.\nfunc (c *client) enqueueProtoAndFlush(proto []byte, doFlush bool) {\n\tif c.isClosed() {\n\t\treturn\n\t}\n\tc.queueOutbound(proto)\n\tif !(doFlush && c.flushOutbound()) {\n\t\tc.flushSignal()\n\t}\n}\n\n// Queues and then flushes the connection. This should only be called when\n// the writeLoop cannot be started yet. Use enqueueProto() otherwise.\n// Lock is held on entry.\nfunc (c *client) sendProtoNow(proto []byte) {\n\tc.enqueueProtoAndFlush(proto, true)\n}\n\n// Enqueues the given protocol and signal the writeLoop if necessary.\n// Lock is held on entry.\nfunc (c *client) enqueueProto(proto []byte) {\n\tc.enqueueProtoAndFlush(proto, false)\n}\n\n// Assume the lock is held upon entry.\nfunc (c *client) sendPong() {\n\tif c.trace {\n\t\tc.traceOutOp(\"PONG\", nil)\n\t}\n\tc.enqueueProto([]byte(pongProto))\n}\n\n// Used to kick off a RTT measurement for latency tracking.\nfunc (c *client) sendRTTPing() bool {\n\tc.mu.Lock()\n\tsent := c.sendRTTPingLocked()\n\tc.mu.Unlock()\n\treturn sent\n}\n\n// Used to kick off a RTT measurement for latency tracking.\n// This is normally called only when the caller has checked that\n// the c.rtt is 0 and wants to force an update by sending a PING.\n// Client lock held on entry.\nfunc (c *client) sendRTTPingLocked() bool {\n\tif c.isMqtt() {\n\t\treturn false\n\t}\n\t// Most client libs send a CONNECT+PING and wait for a PONG from the\n\t// server. So if firstPongSent flag is set, it is ok for server to\n\t// send the PING. But in case we have client libs that don't do that,\n\t// allow the send of the PING if more than 2 secs have elapsed since\n\t// the client TCP connection was accepted.\n\tif !c.isClosed() &&\n\t\t(c.flags.isSet(firstPongSent) || time.Since(c.start) > maxNoRTTPingBeforeFirstPong) {\n\t\tc.sendPing()\n\t\treturn true\n\t}\n\treturn false\n}\n\n// Assume the lock is held upon entry.\nfunc (c *client) sendPing() {\n\tc.rttStart = time.Now()\n\tc.ping.out++\n\tif c.trace {\n\t\tc.traceOutOp(\"PING\", nil)\n\t}\n\tc.enqueueProto([]byte(pingProto))\n}\n\n// Generates the INFO to be sent to the client with the client ID included.\n// info arg will be copied since passed by value.\n// Assume lock is held.\nfunc (c *client) generateClientInfoJSON(info Info) []byte {\n\tinfo.CID = c.cid\n\tinfo.ClientIP = c.host\n\tinfo.MaxPayload = c.mpay\n\tif c.isWebsocket() {\n\t\tinfo.ClientConnectURLs = info.WSConnectURLs\n\t}\n\tinfo.WSConnectURLs = nil\n\t// Generate the info json\n\tb, _ := json.Marshal(info)\n\tpcs := [][]byte{[]byte(\"INFO\"), b, []byte(CR_LF)}\n\treturn bytes.Join(pcs, []byte(\" \"))\n}\n\nfunc (c *client) sendErr(err string) {\n\tc.mu.Lock()\n\tif c.trace {\n\t\tc.traceOutOp(\"-ERR\", []byte(err))\n\t}\n\tif !c.isMqtt() {\n\t\tc.enqueueProto([]byte(fmt.Sprintf(errProto, err)))\n\t}\n\tc.mu.Unlock()\n}\n\nfunc (c *client) sendOK() {\n\tc.mu.Lock()\n\tif c.trace {\n\t\tc.traceOutOp(\"OK\", nil)\n\t}\n\tc.enqueueProto([]byte(okProto))\n\tc.mu.Unlock()\n}\n\nfunc (c *client) processPing() {\n\tc.mu.Lock()\n\n\tif c.isClosed() {\n\t\tc.mu.Unlock()\n\t\treturn\n\t}\n\n\tc.sendPong()\n\n\t// Record this to suppress us sending one if this\n\t// is within a given time interval for activity.\n\tc.ping.last = time.Now()\n\n\t// If not a CLIENT, we are done. Also the CONNECT should\n\t// have been received, but make sure it is so before proceeding\n\tif c.kind != CLIENT || !c.flags.isSet(connectReceived) {\n\t\tc.mu.Unlock()\n\t\treturn\n\t}\n\n\t// If we are here, the CONNECT has been received so we know\n\t// if this client supports async INFO or not.\n\tvar (\n\t\tcheckInfoChange bool\n\t\tsrv             = c.srv\n\t)\n\t// For older clients, just flip the firstPongSent flag if not already\n\t// set and we are done.\n\tif c.opts.Protocol < ClientProtoInfo || srv == nil {\n\t\tc.flags.setIfNotSet(firstPongSent)\n\t} else {\n\t\t// This is a client that supports async INFO protocols.\n\t\t// If this is the first PING (so firstPongSent is not set yet),\n\t\t// we will need to check if there was a change in cluster topology\n\t\t// or we have a different max payload. We will send this first before\n\t\t// pong since most clients do flush after connect call.\n\t\tcheckInfoChange = !c.flags.isSet(firstPongSent)\n\t}\n\tc.mu.Unlock()\n\n\tif checkInfoChange {\n\t\topts := srv.getOpts()\n\t\tsrv.mu.Lock()\n\t\tc.mu.Lock()\n\t\t// Now that we are under both locks, we can flip the flag.\n\t\t// This prevents sendAsyncInfoToClients() and code here to\n\t\t// send a double INFO protocol.\n\t\tc.flags.set(firstPongSent)\n\t\t// If there was a cluster update since this client was created,\n\t\t// send an updated INFO protocol now.\n\t\tif srv.lastCURLsUpdate >= c.start.UnixNano() || c.mpay != int32(opts.MaxPayload) {\n\t\t\tc.enqueueProto(c.generateClientInfoJSON(srv.copyInfo()))\n\t\t}\n\t\tc.mu.Unlock()\n\t\tsrv.mu.Unlock()\n\t}\n}\n\nfunc (c *client) processPong() {\n\tc.mu.Lock()\n\tc.ping.out = 0\n\tc.rtt = computeRTT(c.rttStart)\n\tsrv := c.srv\n\treorderGWs := c.kind == GATEWAY && c.gw.outbound\n\tc.mu.Unlock()\n\tif reorderGWs {\n\t\tsrv.gateway.orderOutboundConnections()\n\t}\n}\n\n// Will return the parts from the raw wire msg.\nfunc (c *client) msgParts(data []byte) (hdr []byte, msg []byte) {\n\tif c != nil && c.pa.hdr > 0 {\n\t\treturn data[:c.pa.hdr], data[c.pa.hdr:]\n\t}\n\treturn nil, data\n}\n\n// Header pubs take form HPUB <subject> [reply] <hdr_len> <total_len>\\r\\n\nfunc (c *client) processHeaderPub(arg []byte) error {\n\tif !c.headers {\n\t\treturn ErrMsgHeadersNotSupported\n\t}\n\n\t// Unroll splitArgs to avoid runtime/heap issues\n\ta := [MAX_HPUB_ARGS][]byte{}\n\targs := a[:0]\n\tstart := -1\n\tfor i, b := range arg {\n\t\tswitch b {\n\t\tcase ' ', '\\t':\n\t\t\tif start >= 0 {\n\t\t\t\targs = append(args, arg[start:i])\n\t\t\t\tstart = -1\n\t\t\t}\n\t\tdefault:\n\t\t\tif start < 0 {\n\t\t\t\tstart = i\n\t\t\t}\n\t\t}\n\t}\n\tif start >= 0 {\n\t\targs = append(args, arg[start:])\n\t}\n\n\tc.pa.arg = arg\n\tswitch len(args) {\n\tcase 3:\n\t\tc.pa.subject = args[0]\n\t\tc.pa.reply = nil\n\t\tc.pa.hdr = parseSize(args[1])\n\t\tc.pa.size = parseSize(args[2])\n\t\tc.pa.hdb = args[1]\n\t\tc.pa.szb = args[2]\n\tcase 4:\n\t\tc.pa.subject = args[0]\n\t\tc.pa.reply = args[1]\n\t\tc.pa.hdr = parseSize(args[2])\n\t\tc.pa.size = parseSize(args[3])\n\t\tc.pa.hdb = args[2]\n\t\tc.pa.szb = args[3]\n\tdefault:\n\t\treturn fmt.Errorf(\"processHeaderPub Parse Error: '%s'\", arg)\n\t}\n\tif c.pa.hdr < 0 {\n\t\treturn fmt.Errorf(\"processHeaderPub Bad or Missing Header Size: '%s'\", arg)\n\t}\n\t// If number overruns an int64, parseSize() will have returned a negative value\n\tif c.pa.size < 0 {\n\t\treturn fmt.Errorf(\"processHeaderPub Bad or Missing Total Size: '%s'\", arg)\n\t}\n\tif c.pa.hdr > c.pa.size {\n\t\treturn fmt.Errorf(\"processHeaderPub Header Size larger then TotalSize: '%s'\", arg)\n\t}\n\tmaxPayload := atomic.LoadInt32(&c.mpay)\n\t// Use int64() to avoid int32 overrun...\n\tif maxPayload != jwt.NoLimit && int64(c.pa.size) > int64(maxPayload) {\n\t\tc.maxPayloadViolation(c.pa.size, maxPayload)\n\t\treturn ErrMaxPayload\n\t}\n\tif c.opts.Pedantic && !IsValidLiteralSubject(string(c.pa.subject)) {\n\t\tc.sendErr(\"Invalid Publish Subject\")\n\t}\n\treturn nil\n}\n\nfunc (c *client) processPub(arg []byte) error {\n\t// Unroll splitArgs to avoid runtime/heap issues\n\ta := [MAX_PUB_ARGS][]byte{}\n\targs := a[:0]\n\tstart := -1\n\tfor i, b := range arg {\n\t\tswitch b {\n\t\tcase ' ', '\\t':\n\t\t\tif start >= 0 {\n\t\t\t\targs = append(args, arg[start:i])\n\t\t\t\tstart = -1\n\t\t\t}\n\t\tdefault:\n\t\t\tif start < 0 {\n\t\t\t\tstart = i\n\t\t\t}\n\t\t}\n\t}\n\tif start >= 0 {\n\t\targs = append(args, arg[start:])\n\t}\n\n\tc.pa.arg = arg\n\tswitch len(args) {\n\tcase 2:\n\t\tc.pa.subject = args[0]\n\t\tc.pa.reply = nil\n\t\tc.pa.size = parseSize(args[1])\n\t\tc.pa.szb = args[1]\n\tcase 3:\n\t\tc.pa.subject = args[0]\n\t\tc.pa.reply = args[1]\n\t\tc.pa.size = parseSize(args[2])\n\t\tc.pa.szb = args[2]\n\tdefault:\n\t\treturn fmt.Errorf(\"processPub Parse Error: '%s'\", arg)\n\t}\n\t// If number overruns an int64, parseSize() will have returned a negative value\n\tif c.pa.size < 0 {\n\t\treturn fmt.Errorf(\"processPub Bad or Missing Size: '%s'\", arg)\n\t}\n\tmaxPayload := atomic.LoadInt32(&c.mpay)\n\t// Use int64() to avoid int32 overrun...\n\tif maxPayload != jwt.NoLimit && int64(c.pa.size) > int64(maxPayload) {\n\t\tc.maxPayloadViolation(c.pa.size, maxPayload)\n\t\treturn ErrMaxPayload\n\t}\n\tif c.opts.Pedantic && !IsValidLiteralSubject(string(c.pa.subject)) {\n\t\tc.sendErr(\"Invalid Publish Subject\")\n\t}\n\treturn nil\n}\n\nfunc splitArg(arg []byte) [][]byte {\n\ta := [MAX_MSG_ARGS][]byte{}\n\targs := a[:0]\n\tstart := -1\n\tfor i, b := range arg {\n\t\tswitch b {\n\t\tcase ' ', '\\t', '\\r', '\\n':\n\t\t\tif start >= 0 {\n\t\t\t\targs = append(args, arg[start:i])\n\t\t\t\tstart = -1\n\t\t\t}\n\t\tdefault:\n\t\t\tif start < 0 {\n\t\t\t\tstart = i\n\t\t\t}\n\t\t}\n\t}\n\tif start >= 0 {\n\t\targs = append(args, arg[start:])\n\t}\n\treturn args\n}\n\nfunc (c *client) parseSub(argo []byte, noForward bool) error {\n\t// Copy so we do not reference a potentially large buffer\n\t// FIXME(dlc) - make more efficient.\n\targ := make([]byte, len(argo))\n\tcopy(arg, argo)\n\targs := splitArg(arg)\n\tvar (\n\t\tsubject []byte\n\t\tqueue   []byte\n\t\tsid     []byte\n\t)\n\tswitch len(args) {\n\tcase 2:\n\t\tsubject = args[0]\n\t\tqueue = nil\n\t\tsid = args[1]\n\tcase 3:\n\t\tsubject = args[0]\n\t\tqueue = args[1]\n\t\tsid = args[2]\n\tdefault:\n\t\treturn fmt.Errorf(\"processSub Parse Error: '%s'\", arg)\n\t}\n\t// If there was an error, it has been sent to the client. We don't return an\n\t// error here to not close the connection as a parsing error.\n\tc.processSub(subject, queue, sid, nil, noForward)\n\treturn nil\n}\n\nfunc (c *client) processSub(subject, queue, bsid []byte, cb msgHandler, noForward bool) (*subscription, error) {\n\t// Create the subscription\n\tsub := &subscription{client: c, subject: subject, queue: queue, sid: bsid, icb: cb}\n\n\tc.mu.Lock()\n\n\t// Indicate activity.\n\tc.in.subs++\n\n\t// Grab connection type, account and server info.\n\tkind := c.kind\n\tacc := c.acc\n\tsrv := c.srv\n\n\tsid := string(sub.sid)\n\n\t// This check does not apply to SYSTEM or JETSTREAM or ACCOUNT clients (because they don't have a `nc`...)\n\tif c.isClosed() && (kind != SYSTEM && kind != JETSTREAM && kind != ACCOUNT) {\n\t\tc.mu.Unlock()\n\t\treturn nil, ErrConnectionClosed\n\t}\n\n\t// Check permissions if applicable.\n\tif kind == CLIENT {\n\t\t// First do a pass whether queue subscription is valid. This does not necessarily\n\t\t// mean that it will not be able to plain subscribe.\n\t\t//\n\t\t// allow = [\"foo\"]            -> can subscribe or queue subscribe to foo using any queue\n\t\t// allow = [\"foo v1\"]         -> can only queue subscribe to 'foo v1', no plain subs allowed.\n\t\t// allow = [\"foo\", \"foo v1\"]  -> can subscribe to 'foo' but can only queue subscribe to 'foo v1'\n\t\t//\n\t\tif sub.queue != nil {\n\t\t\tif !c.canQueueSubscribe(string(sub.subject), string(sub.queue)) {\n\t\t\t\tc.mu.Unlock()\n\t\t\t\tc.subPermissionViolation(sub)\n\t\t\t\treturn nil, ErrSubscribePermissionViolation\n\t\t\t}\n\t\t} else if !c.canSubscribe(string(sub.subject)) {\n\t\t\tc.mu.Unlock()\n\t\t\tc.subPermissionViolation(sub)\n\t\t\treturn nil, ErrSubscribePermissionViolation\n\t\t}\n\t}\n\n\t// Check if we have a maximum on the number of subscriptions.\n\tif c.subsAtLimit() {\n\t\tc.mu.Unlock()\n\t\tc.maxSubsExceeded()\n\t\treturn nil, ErrTooManySubs\n\t}\n\n\tvar updateGWs bool\n\tvar err error\n\n\t// Subscribe here.\n\tes := c.subs[sid]\n\tif es == nil {\n\t\tc.subs[sid] = sub\n\t\tif acc != nil && acc.sl != nil {\n\t\t\terr = acc.sl.Insert(sub)\n\t\t\tif err != nil {\n\t\t\t\tdelete(c.subs, sid)\n\t\t\t} else {\n\t\t\t\tupdateGWs = c.srv.gateway.enabled\n\t\t\t}\n\t\t}\n\t}\n\t// Unlocked from here onward\n\tc.mu.Unlock()\n\n\tif err != nil {\n\t\tc.sendErr(\"Invalid Subject\")\n\t\treturn nil, ErrMalformedSubject\n\t} else if c.opts.Verbose && kind != SYSTEM {\n\t\tc.sendOK()\n\t}\n\n\t// If it was already registered, return it.\n\tif es != nil {\n\t\treturn es, nil\n\t}\n\n\t// No account just return.\n\tif acc == nil {\n\t\treturn sub, nil\n\t}\n\n\tif err := c.addShadowSubscriptions(acc, sub); err != nil {\n\t\tc.Errorf(err.Error())\n\t}\n\n\tif noForward {\n\t\treturn sub, nil\n\t}\n\n\t// If we are routing and this is a local sub, add to the route map for the associated account.\n\tif kind == CLIENT || kind == SYSTEM || kind == JETSTREAM || kind == ACCOUNT {\n\t\tsrv.updateRouteSubscriptionMap(acc, sub, 1)\n\t\tif updateGWs {\n\t\t\tsrv.gatewayUpdateSubInterest(acc.Name, sub, 1)\n\t\t}\n\t}\n\t// Now check on leafnode updates.\n\tsrv.updateLeafNodes(acc, sub, 1)\n\treturn sub, nil\n}\n\n// Used to pass stream import matches to addShadowSub\ntype ime struct {\n\tim  *streamImport\n\tdyn bool\n}\n\n// If the client's account has stream imports and there are matches for\n// this subscription's subject, then add shadow subscriptions in the\n// other accounts that export this subject.\nfunc (c *client) addShadowSubscriptions(acc *Account, sub *subscription) error {\n\tif acc == nil {\n\t\treturn ErrMissingAccount\n\t}\n\n\tvar (\n\t\t_ims   [16]ime\n\t\tims    = _ims[:0]\n\t\ttokens []string\n\t\ttsa    [32]string\n\t\thasWC  bool\n\t)\n\n\tacc.mu.RLock()\n\t// Loop over the import subjects. We have 3 scenarios. If we have an\n\t// exact match or a superset match we should use the from field from\n\t// the import. If we are a subset, we have to dynamically calculate\n\t// the subject.\n\tfor _, im := range acc.imports.streams {\n\t\tif im.invalid {\n\t\t\tcontinue\n\t\t}\n\t\tsubj := string(sub.subject)\n\t\tif subj == im.to {\n\t\t\tims = append(ims, ime{im, false})\n\t\t\tcontinue\n\t\t}\n\t\tif tokens == nil {\n\t\t\ttokens = tsa[:0]\n\t\t\tstart := 0\n\t\t\tfor i := 0; i < len(subj); i++ {\n\t\t\t\t// This is not perfect, but the test below will\n\t\t\t\t// be more exact, this is just to trigger the\n\t\t\t\t// additional test.\n\t\t\t\tif subj[i] == pwc || subj[i] == fwc {\n\t\t\t\t\thasWC = true\n\t\t\t\t} else if subj[i] == btsep {\n\t\t\t\t\ttokens = append(tokens, subj[start:i])\n\t\t\t\t\tstart = i + 1\n\t\t\t\t}\n\t\t\t}\n\t\t\ttokens = append(tokens, subj[start:])\n\t\t}\n\t\tif isSubsetMatch(tokens, im.to) {\n\t\t\tims = append(ims, ime{im, true})\n\t\t} else if hasWC && subjectIsSubsetMatch(im.to, subj) {\n\t\t\tims = append(ims, ime{im, false})\n\t\t}\n\t}\n\tacc.mu.RUnlock()\n\n\tvar shadow []*subscription\n\n\tif len(ims) > 0 {\n\t\tshadow = make([]*subscription, 0, len(ims))\n\t}\n\n\t// Now walk through collected stream imports that matched.\n\tfor i := 0; i < len(ims); i++ {\n\t\time := &ims[i]\n\t\t// We will create a shadow subscription.\n\t\tnsub, err := c.addShadowSub(sub, ime)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tshadow = append(shadow, nsub)\n\t}\n\n\tif shadow != nil {\n\t\tc.mu.Lock()\n\t\tsub.shadow = shadow\n\t\tc.mu.Unlock()\n\t}\n\n\treturn nil\n}\n\n// Add in the shadow subscription.\nfunc (c *client) addShadowSub(sub *subscription, ime *ime) (*subscription, error) {\n\tim := ime.im\n\tnsub := *sub // copy\n\tnsub.im = im\n\n\t// Check if we need to change shadow subscription's subject.\n\tif !im.usePub {\n\t\tif ime.dyn {\n\t\t\tif im.rtr == nil {\n\t\t\t\tim.rtr = im.tr.reverse()\n\t\t\t}\n\t\t\tsubj, err := im.rtr.transformSubject(string(nsub.subject))\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tnsub.subject = []byte(subj)\n\t\t} else {\n\t\t\tnsub.subject = []byte(im.from)\n\t\t}\n\t}\n\tc.Debugf(\"Creating import subscription on %q from account %q\", nsub.subject, im.acc.Name)\n\n\tif err := im.acc.sl.Insert(&nsub); err != nil {\n\t\terrs := fmt.Sprintf(\"Could not add shadow import subscription for account %q\", im.acc.Name)\n\t\tc.Debugf(errs)\n\t\treturn nil, fmt.Errorf(errs)\n\t}\n\n\t// Update our route map here.\n\tc.srv.updateRouteSubscriptionMap(im.acc, &nsub, 1)\n\tif c.srv.gateway.enabled {\n\t\tc.srv.gatewayUpdateSubInterest(im.acc.Name, &nsub, 1)\n\t}\n\tc.srv.updateLeafNodes(im.acc, &nsub, 1)\n\n\treturn &nsub, nil\n}\n\n// canSubscribe determines if the client is authorized to subscribe to the\n// given subject. Assumes caller is holding lock.\nfunc (c *client) canSubscribe(subject string) bool {\n\tif c.perms == nil {\n\t\treturn true\n\t}\n\n\tallowed := true\n\n\t// Check allow list. If no allow list that means all are allowed. Deny can overrule.\n\tif c.perms.sub.allow != nil {\n\t\tr := c.perms.sub.allow.Match(subject)\n\t\tallowed = len(r.psubs) != 0\n\t}\n\t// If we have a deny list and we think we are allowed, check that as well.\n\tif allowed && c.perms.sub.deny != nil {\n\t\tr := c.perms.sub.deny.Match(subject)\n\t\tallowed = len(r.psubs) == 0\n\n\t\t// We use the actual subscription to signal us to spin up the deny mperms\n\t\t// and cache. We check if the subject is a wildcard that contains any of\n\t\t// the deny clauses.\n\t\t// FIXME(dlc) - We could be smarter and track when these go away and remove.\n\t\tif allowed && c.mperms == nil && subjectHasWildcard(subject) {\n\t\t\t// Whip through the deny array and check if this wildcard subject is within scope.\n\t\t\tfor _, sub := range c.darray {\n\t\t\t\ttokens := strings.Split(sub, tsep)\n\t\t\t\tif isSubsetMatch(tokens, sub) {\n\t\t\t\t\tc.loadMsgDenyFilter()\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn allowed\n}\n\nfunc queueMatches(queue string, qsubs [][]*subscription) bool {\n\tif len(qsubs) == 0 {\n\t\treturn true\n\t}\n\tfor _, qsub := range qsubs {\n\t\tqs := qsub[0]\n\t\tqname := string(qs.queue)\n\n\t\t// NOTE: '*' and '>' tokens can also be valid\n\t\t// queue names so we first check against the\n\t\t// literal name.  e.g. v1.* == v1.*\n\t\tif queue == qname || (subjectHasWildcard(qname) && subjectIsSubsetMatch(queue, qname)) {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\nfunc (c *client) canQueueSubscribe(subject, queue string) bool {\n\tif c.perms == nil {\n\t\treturn true\n\t}\n\n\tallowed := true\n\n\tif c.perms.sub.allow != nil {\n\t\tr := c.perms.sub.allow.Match(subject)\n\n\t\t// If perms DO NOT have queue name, then psubs will be greater than\n\t\t// zero. If perms DO have queue name, then qsubs will be greater than\n\t\t// zero.\n\t\tallowed = len(r.psubs) > 0\n\t\tif len(r.qsubs) > 0 {\n\t\t\t// If the queue appears in the allow list, then DO allow.\n\t\t\tallowed = queueMatches(queue, r.qsubs)\n\t\t}\n\t}\n\n\tif allowed && c.perms.sub.deny != nil {\n\t\tr := c.perms.sub.deny.Match(subject)\n\n\t\t// If perms DO NOT have queue name, then psubs will be greater than\n\t\t// zero. If perms DO have queue name, then qsubs will be greater than\n\t\t// zero.\n\t\tallowed = len(r.psubs) == 0\n\t\tif len(r.qsubs) > 0 {\n\t\t\t// If the queue appears in the deny list, then DO NOT allow.\n\t\t\tallowed = !queueMatches(queue, r.qsubs)\n\t\t}\n\t}\n\n\treturn allowed\n}\n\n// Low level unsubscribe for a given client.\nfunc (c *client) unsubscribe(acc *Account, sub *subscription, force, remove bool) {\n\tc.mu.Lock()\n\tif !force && sub.max > 0 && sub.nm < sub.max {\n\t\tc.Debugf(\n\t\t\t\"Deferring actual UNSUB(%s): %d max, %d received\",\n\t\t\tstring(sub.subject), sub.max, sub.nm)\n\t\tc.mu.Unlock()\n\t\treturn\n\t}\n\n\tif c.trace {\n\t\tc.traceOp(\"<-> %s\", \"DELSUB\", sub.sid)\n\t}\n\n\tif c.kind != CLIENT && c.kind != SYSTEM {\n\t\tc.removeReplySubTimeout(sub)\n\t}\n\n\t// Remove accounting if requested. This will be false when we close a connection\n\t// with open subscriptions.\n\tif remove {\n\t\tdelete(c.subs, string(sub.sid))\n\t\tif acc != nil {\n\t\t\tacc.sl.Remove(sub)\n\t\t}\n\t}\n\n\t// Check to see if we have shadow subscriptions.\n\tvar updateRoute bool\n\tvar updateGWs bool\n\tshadowSubs := sub.shadow\n\tsub.shadow = nil\n\tif len(shadowSubs) > 0 {\n\t\tupdateRoute = (c.kind == CLIENT || c.kind == SYSTEM || c.kind == LEAF) && c.srv != nil\n\t\tif updateRoute {\n\t\t\tupdateGWs = c.srv.gateway.enabled\n\t\t}\n\t}\n\tsub.close()\n\tc.mu.Unlock()\n\n\t// Process shadow subs if we have them.\n\tfor _, nsub := range shadowSubs {\n\t\tif err := nsub.im.acc.sl.Remove(nsub); err != nil {\n\t\t\tc.Debugf(\"Could not remove shadow import subscription for account %q\", nsub.im.acc.Name)\n\t\t} else {\n\t\t\tif updateRoute {\n\t\t\t\tc.srv.updateRouteSubscriptionMap(nsub.im.acc, nsub, -1)\n\t\t\t}\n\t\t\tif updateGWs {\n\t\t\t\tc.srv.gatewayUpdateSubInterest(nsub.im.acc.Name, nsub, -1)\n\t\t\t}\n\t\t}\n\t\t// Now check on leafnode updates.\n\t\tc.srv.updateLeafNodes(nsub.im.acc, nsub, -1)\n\t}\n\n\t// Now check to see if this was part of a respMap entry for service imports.\n\tif acc != nil {\n\t\tacc.checkForReverseEntry(string(sub.subject), nil, true)\n\t}\n}\n\nfunc (c *client) processUnsub(arg []byte) error {\n\targs := splitArg(arg)\n\tvar sid []byte\n\tmax := -1\n\n\tswitch len(args) {\n\tcase 1:\n\t\tsid = args[0]\n\tcase 2:\n\t\tsid = args[0]\n\t\tmax = parseSize(args[1])\n\tdefault:\n\t\treturn fmt.Errorf(\"processUnsub Parse Error: '%s'\", arg)\n\t}\n\n\tvar sub *subscription\n\tvar ok, unsub bool\n\n\tc.mu.Lock()\n\n\t// Indicate activity.\n\tc.in.subs++\n\n\t// Grab connection type.\n\tkind := c.kind\n\tsrv := c.srv\n\tvar acc *Account\n\n\tupdateGWs := false\n\tif sub, ok = c.subs[string(sid)]; ok {\n\t\tacc = c.acc\n\t\tif max > 0 {\n\t\t\tsub.max = int64(max)\n\t\t} else {\n\t\t\t// Clear it here to override\n\t\t\tsub.max = 0\n\t\t\tunsub = true\n\t\t}\n\t\tupdateGWs = srv.gateway.enabled\n\t}\n\tc.mu.Unlock()\n\n\tif c.opts.Verbose {\n\t\tc.sendOK()\n\t}\n\n\tif unsub {\n\t\tc.unsubscribe(acc, sub, false, true)\n\t\tif acc != nil && kind == CLIENT || kind == SYSTEM || kind == ACCOUNT {\n\t\t\tsrv.updateRouteSubscriptionMap(acc, sub, -1)\n\t\t\tif updateGWs {\n\t\t\t\tsrv.gatewayUpdateSubInterest(acc.Name, sub, -1)\n\t\t\t}\n\t\t}\n\t\t// Now check on leafnode updates.\n\t\tsrv.updateLeafNodes(acc, sub, -1)\n\t}\n\n\treturn nil\n}\n\n// checkDenySub will check if we are allowed to deliver this message in the\n// presence of deny clauses for subscriptions. Deny clauses will not prevent\n// larger scoped wildcard subscriptions, so we need to check at delivery time.\n// Lock should be held.\nfunc (c *client) checkDenySub(subject string) bool {\n\tif denied, ok := c.mperms.dcache[subject]; ok {\n\t\treturn denied\n\t} else if r := c.mperms.deny.Match(subject); len(r.psubs) != 0 {\n\t\tc.mperms.dcache[subject] = true\n\t\treturn true\n\t} else {\n\t\tc.mperms.dcache[subject] = false\n\t}\n\tif len(c.mperms.dcache) > maxDenyPermCacheSize {\n\t\tc.pruneDenyCache()\n\t}\n\treturn false\n}\n\n// Create a message header for routes or leafnodes. Header and origin cluster aware.\nfunc (c *client) msgHeaderForRouteOrLeaf(subj, reply []byte, rt *routeTarget, acc *Account) []byte {\n\thasHeader := c.pa.hdr > 0\n\tcanReceiveHeader := rt.sub.client.headers\n\n\tmh := c.msgb[:msgHeadProtoLen]\n\tkind := rt.sub.client.kind\n\tvar lnoc bool\n\n\tif kind == ROUTER {\n\t\t// If we are coming from a leaf with an origin cluster we need to handle differently\n\t\t// if we can. We will send a route based LMSG which has origin cluster and headers\n\t\t// by default.\n\t\tif c.kind == LEAF && c.remoteCluster() != _EMPTY_ && rt.sub.client.route.lnoc {\n\t\t\tmh[0] = 'L'\n\t\t\tmh = append(mh, c.remoteCluster()...)\n\t\t\tmh = append(mh, ' ')\n\t\t\tlnoc = true\n\t\t} else {\n\t\t\t// Router (and Gateway) nodes are RMSG. Set here since leafnodes may rewrite.\n\t\t\tmh[0] = 'R'\n\t\t}\n\t\tmh = append(mh, acc.Name...)\n\t\tmh = append(mh, ' ')\n\t} else {\n\t\t// Leaf nodes are LMSG\n\t\tmh[0] = 'L'\n\t\t// Remap subject if its a shadow subscription, treat like a normal client.\n\t\tif rt.sub.im != nil {\n\t\t\tif rt.sub.im.tr != nil {\n\t\t\t\tto, _ := rt.sub.im.tr.transformSubject(string(subj))\n\t\t\t\tsubj = []byte(to)\n\t\t\t} else {\n\t\t\t\tsubj = []byte(rt.sub.im.to)\n\t\t\t}\n\t\t}\n\t}\n\tmh = append(mh, subj...)\n\tmh = append(mh, ' ')\n\n\tif len(rt.qs) > 0 {\n\t\tif reply != nil {\n\t\t\tmh = append(mh, \"+ \"...) // Signal that there is a reply.\n\t\t\tmh = append(mh, reply...)\n\t\t\tmh = append(mh, ' ')\n\t\t} else {\n\t\t\tmh = append(mh, \"| \"...) // Only queues\n\t\t}\n\t\tmh = append(mh, rt.qs...)\n\t} else if reply != nil {\n\t\tmh = append(mh, reply...)\n\t\tmh = append(mh, ' ')\n\t}\n\n\tif lnoc {\n\t\t// leafnode origin LMSG always have a header entry even if zero.\n\t\tif c.pa.hdr <= 0 {\n\t\t\tmh = append(mh, '0')\n\t\t} else {\n\t\t\tmh = append(mh, c.pa.hdb...)\n\t\t}\n\t\tmh = append(mh, ' ')\n\t\tmh = append(mh, c.pa.szb...)\n\t} else if hasHeader {\n\t\tif canReceiveHeader {\n\t\t\tmh[0] = 'H'\n\t\t\tmh = append(mh, c.pa.hdb...)\n\t\t\tmh = append(mh, ' ')\n\t\t\tmh = append(mh, c.pa.szb...)\n\t\t} else {\n\t\t\t// If we are here we need to truncate the payload size\n\t\t\tnsz := strconv.Itoa(c.pa.size - c.pa.hdr)\n\t\t\tmh = append(mh, nsz...)\n\t\t}\n\t} else {\n\t\tmh = append(mh, c.pa.szb...)\n\t}\n\treturn append(mh, _CRLF_...)\n}\n\n// Create a message header for clients. Header aware.\nfunc (c *client) msgHeader(subj, reply []byte, sub *subscription) []byte {\n\t// See if we should do headers. We have to have a headers msg and\n\t// the client we are going to deliver to needs to support headers as well.\n\thasHeader := c.pa.hdr > 0\n\tcanReceiveHeader := sub.client != nil && sub.client.headers\n\n\tvar mh []byte\n\tif hasHeader && canReceiveHeader {\n\t\tmh = c.msgb[:msgHeadProtoLen]\n\t\tmh[0] = 'H'\n\t} else {\n\t\tmh = c.msgb[1:msgHeadProtoLen]\n\t}\n\tmh = append(mh, subj...)\n\tmh = append(mh, ' ')\n\n\tif len(sub.sid) > 0 {\n\t\tmh = append(mh, sub.sid...)\n\t\tmh = append(mh, ' ')\n\t}\n\tif reply != nil {\n\t\tmh = append(mh, reply...)\n\t\tmh = append(mh, ' ')\n\t}\n\tif hasHeader {\n\t\tif canReceiveHeader {\n\t\t\tmh = append(mh, c.pa.hdb...)\n\t\t\tmh = append(mh, ' ')\n\t\t\tmh = append(mh, c.pa.szb...)\n\t\t} else {\n\t\t\t// If we are here we need to truncate the payload size\n\t\t\tnsz := strconv.Itoa(c.pa.size - c.pa.hdr)\n\t\t\tmh = append(mh, nsz...)\n\t\t}\n\t} else {\n\t\tmh = append(mh, c.pa.szb...)\n\t}\n\tmh = append(mh, _CRLF_...)\n\treturn mh\n}\n\nfunc (c *client) stalledWait(producer *client) {\n\tstall := c.out.stc\n\tttl := stallDuration(c.out.pb, c.out.mp)\n\tc.mu.Unlock()\n\tdefer c.mu.Lock()\n\n\tselect {\n\tcase <-stall:\n\tcase <-time.After(ttl):\n\t\tproducer.Debugf(\"Timed out of fast producer stall (%v)\", ttl)\n\t}\n}\n\nfunc stallDuration(pb, mp int64) time.Duration {\n\tttl := stallClientMinDuration\n\tif pb >= mp {\n\t\tttl = stallClientMaxDuration\n\t} else if hmp := mp / 2; pb > hmp {\n\t\tbsz := hmp / 10\n\t\tadditional := int64(ttl) * ((pb - hmp) / bsz)\n\t\tttl += time.Duration(additional)\n\t}\n\treturn ttl\n}\n\n// Used to treat maps as efficient set\nvar needFlush = struct{}{}\n\n// deliverMsg will deliver a message to a matching subscription and its underlying client.\n// We process all connection/client types. mh is the part that will be protocol/client specific.\nfunc (c *client) deliverMsg(sub *subscription, subject, reply, mh, msg []byte, gwrply bool) bool {\n\tif sub.client == nil {\n\t\treturn false\n\t}\n\tclient := sub.client\n\tclient.mu.Lock()\n\n\t// Check echo\n\tif c == client && !client.echo {\n\t\tclient.mu.Unlock()\n\t\treturn false\n\t}\n\n\t// Check if we have a subscribe deny clause. This will trigger us to check the subject\n\t// for a match against the denied subjects.\n\tif client.mperms != nil && client.checkDenySub(string(subject)) {\n\t\tclient.mu.Unlock()\n\t\treturn false\n\t}\n\n\t// New race detector forces this now.\n\tif sub.isClosed() {\n\t\tclient.mu.Unlock()\n\t\treturn false\n\t}\n\n\t// Check if we are a leafnode and have perms to check.\n\tif client.kind == LEAF && client.perms != nil {\n\t\tif !client.pubAllowed(string(subject)) {\n\t\t\tclient.mu.Unlock()\n\t\t\treturn false\n\t\t}\n\t}\n\n\tsrv := client.srv\n\n\tsub.nm++\n\t// Check if we should auto-unsubscribe.\n\tif sub.max > 0 {\n\t\tif client.kind == ROUTER && sub.nm >= sub.max {\n\t\t\t// The only router based messages that we will see here are remoteReplies.\n\t\t\t// We handle these slightly differently.\n\t\t\tdefer client.removeReplySub(sub)\n\t\t} else {\n\t\t\t// For routing..\n\t\t\tshouldForward := client.kind == CLIENT || client.kind == SYSTEM && client.srv != nil\n\t\t\t// If we are at the exact number, unsubscribe but\n\t\t\t// still process the message in hand, otherwise\n\t\t\t// unsubscribe and drop message on the floor.\n\t\t\tif sub.nm == sub.max {\n\t\t\t\tclient.Debugf(\"Auto-unsubscribe limit of %d reached for sid '%s'\", sub.max, string(sub.sid))\n\t\t\t\t// Due to defer, reverse the code order so that execution\n\t\t\t\t// is consistent with other cases where we unsubscribe.\n\t\t\t\tif shouldForward {\n\t\t\t\t\tif srv.gateway.enabled {\n\t\t\t\t\t\tdefer srv.gatewayUpdateSubInterest(client.acc.Name, sub, -1)\n\t\t\t\t\t}\n\t\t\t\t\tdefer srv.updateRouteSubscriptionMap(client.acc, sub, -1)\n\t\t\t\t}\n\t\t\t\tdefer client.unsubscribe(client.acc, sub, true, true)\n\t\t\t} else if sub.nm > sub.max {\n\t\t\t\tclient.Debugf(\"Auto-unsubscribe limit [%d] exceeded\", sub.max)\n\t\t\t\tclient.mu.Unlock()\n\t\t\t\tclient.unsubscribe(client.acc, sub, true, true)\n\t\t\t\tif shouldForward {\n\t\t\t\t\tsrv.updateRouteSubscriptionMap(client.acc, sub, -1)\n\t\t\t\t\tif srv.gateway.enabled {\n\t\t\t\t\t\tsrv.gatewayUpdateSubInterest(client.acc.Name, sub, -1)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check here if we have a header with our message. If this client can not\n\t// support we need to strip the headers from the payload.\n\t// The actual header would have been processed correctly for us, so just\n\t// need to update payload.\n\tif c.pa.hdr > 0 && !sub.client.headers {\n\t\tmsg = msg[c.pa.hdr:]\n\t}\n\n\t// Update statistics\n\n\t// The msg includes the CR_LF, so pull back out for accounting.\n\tmsgSize := int64(len(msg))\n\tprodIsMQTT := c.isMqtt()\n\t// MQTT producers send messages without CR_LF, so don't remove it for them.\n\tif !prodIsMQTT {\n\t\tmsgSize -= int64(LEN_CR_LF)\n\t}\n\n\t// No atomic needed since accessed under client lock.\n\t// Monitor is reading those also under client's lock.\n\tclient.outMsgs++\n\tclient.outBytes += msgSize\n\n\t// Check for internal subscriptions.\n\tif sub.icb != nil {\n\t\tif gwrply {\n\t\t\t// Note that we keep track of the GW routed reply in the destination\n\t\t\t// connection (`client`). The routed reply subject is in `c.pa.reply`,\n\t\t\t// should that change, we would have to pass the GW routed reply as\n\t\t\t// a parameter of deliverMsg().\n\t\t\tsrv.trackGWReply(client, c.pa.reply)\n\t\t}\n\t\tclient.mu.Unlock()\n\t\t// Internal account clients are for service imports and need the '\\r\\n'.\n\t\tif client.kind == ACCOUNT {\n\t\t\tsub.icb(sub, c, string(subject), string(reply), msg)\n\t\t} else {\n\t\t\tsub.icb(sub, c, string(subject), string(reply), msg[:msgSize])\n\t\t}\n\t\treturn true\n\t}\n\n\t// We don't count internal deliveries so we update server statistics here.\n\tatomic.AddInt64(&srv.outMsgs, 1)\n\tatomic.AddInt64(&srv.outBytes, msgSize)\n\n\t// If we are a client and we detect that the consumer we are\n\t// sending to is in a stalled state, go ahead and wait here\n\t// with a limit.\n\tif c.kind == CLIENT && client.out.stc != nil {\n\t\tclient.stalledWait(c)\n\t}\n\n\t// Check for closed connection\n\tif client.isClosed() {\n\t\tclient.mu.Unlock()\n\t\treturn false\n\t}\n\n\t// Do a fast check here to see if we should be tracking this from a latency\n\t// perspective. This will be for a request being received for an exported service.\n\t// This needs to be from a non-client (otherwise tracking happens at requestor).\n\t//\n\t// Also this check captures if the original reply (c.pa.reply) is a GW routed\n\t// reply (since it is known to be > minReplyLen). If that is the case, we need to\n\t// track the binding between the routed reply and the reply set in the message\n\t// header (which is c.pa.reply without the GNR routing prefix).\n\tif client.kind == CLIENT && len(c.pa.reply) > minReplyLen {\n\t\tif gwrply {\n\t\t\t// Note that we keep track of the GW routed reply in the destination\n\t\t\t// connection (`client`). The routed reply subject is in `c.pa.reply`,\n\t\t\t// should that change, we would have to pass the GW routed reply as\n\t\t\t// a parameter of deliverMsg().\n\t\t\tsrv.trackGWReply(client, c.pa.reply)\n\t\t}\n\n\t\t// If we do not have a registered RTT queue that up now.\n\t\tif client.rtt == 0 {\n\t\t\tclient.sendRTTPingLocked()\n\t\t}\n\t\t// FIXME(dlc) - We may need to optimize this.\n\t\t// We will have tagged this with a suffix ('.T') if we are tracking. This is\n\t\t// needed from sampling. Not all will be tracked.\n\t\tif c.kind != CLIENT && isTrackedReply(c.pa.reply) {\n\t\t\tclient.trackRemoteReply(string(subject), string(c.pa.reply))\n\t\t}\n\t}\n\n\t// Queue to outbound buffer\n\tclient.queueOutbound(mh)\n\tclient.queueOutbound(msg)\n\tif prodIsMQTT {\n\t\t// Need to add CR_LF since MQTT producers don't send CR_LF\n\t\tclient.queueOutbound([]byte(CR_LF))\n\t}\n\n\tclient.out.pm++\n\n\t// If we are tracking dynamic publish permissions that track reply subjects,\n\t// do that accounting here. We only look at client.replies which will be non-nil.\n\tif client.replies != nil && len(reply) > 0 {\n\t\tclient.replies[string(reply)] = &resp{time.Now(), 0}\n\t\tif len(client.replies) > replyPermLimit {\n\t\t\tclient.pruneReplyPerms()\n\t\t}\n\t}\n\n\t// Check outbound threshold and queue IO flush if needed.\n\t// This is specifically looking at situations where we are getting behind and may want\n\t// to intervene before this producer goes back to top of readloop. We are in the producer's\n\t// readloop go routine at this point.\n\t// FIXME(dlc) - We may call this alot, maybe suppress after first call?\n\tif client.out.pm > 1 && client.out.pb > maxBufSize*2 {\n\t\tclient.flushSignal()\n\t}\n\n\t// Add the data size we are responsible for here. This will be processed when we\n\t// return to the top of the readLoop.\n\tc.addToPCD(client)\n\n\tif client.trace {\n\t\tclient.traceOutOp(string(mh[:len(mh)-LEN_CR_LF]), nil)\n\t}\n\n\tclient.mu.Unlock()\n\n\treturn true\n}\n\n// Add the given sub's client to the list of clients that need flushing.\n// This must be invoked from `c`'s readLoop. No lock for c is required,\n// however, `client` lock must be held on entry. This holds true even\n// if `client` is same than `c`.\nfunc (c *client) addToPCD(client *client) {\n\tif _, ok := c.pcd[client]; !ok {\n\t\tclient.out.fsp++\n\t\tc.pcd[client] = needFlush\n\t}\n}\n\n// This will track a remote reply for an exported service that has requested\n// latency tracking.\n// Lock assumed to be held.\nfunc (c *client) trackRemoteReply(subject, reply string) {\n\ta := c.acc\n\tif a == nil {\n\t\treturn\n\t}\n\n\tvar lrt time.Duration\n\tvar respThresh time.Duration\n\n\ta.mu.RLock()\n\tse := a.getServiceExport(subject)\n\tif se != nil {\n\t\tlrt = a.lowestServiceExportResponseTime()\n\t\trespThresh = se.respThresh\n\t}\n\ta.mu.RUnlock()\n\n\tif se == nil {\n\t\treturn\n\t}\n\n\tif c.rrTracking == nil {\n\t\tc.rrTracking = &rrTracking{\n\t\t\trmap: make(map[string]*remoteLatency),\n\t\t\tptmr: time.AfterFunc(lrt, c.pruneRemoteTracking),\n\t\t\tlrt:  lrt,\n\t\t}\n\t}\n\trl := remoteLatency{\n\t\tAccount:    a.Name,\n\t\tReqId:      reply,\n\t\trespThresh: respThresh,\n\t}\n\trl.M2.RequestStart = time.Now().UTC()\n\tc.rrTracking.rmap[reply] = &rl\n}\n\n// pruneRemoteTracking will prune any remote tracking objects\n// that are too old. These are orphaned when a service is not\n// sending reponses etc.\n// Lock should be held upon entry.\nfunc (c *client) pruneRemoteTracking() {\n\tc.mu.Lock()\n\tif c.rrTracking == nil {\n\t\tc.mu.Unlock()\n\t\treturn\n\t}\n\tnow := time.Now()\n\tfor subject, rl := range c.rrTracking.rmap {\n\t\tif now.After(rl.M2.RequestStart.Add(rl.respThresh)) {\n\t\t\tdelete(c.rrTracking.rmap, subject)\n\t\t}\n\t}\n\tif len(c.rrTracking.rmap) > 0 {\n\t\tt := c.rrTracking.ptmr\n\t\tt.Stop()\n\t\tt.Reset(c.rrTracking.lrt)\n\t} else {\n\t\tc.rrTracking.ptmr.Stop()\n\t\tc.rrTracking = nil\n\t}\n\tc.mu.Unlock()\n}\n\n// pruneReplyPerms will remove any stale or expired entries\n// in our reply cache. We make sure to not check too often.\nfunc (c *client) pruneReplyPerms() {\n\t// Make sure we do not check too often.\n\tif c.perms.resp == nil {\n\t\treturn\n\t}\n\n\tmm := c.perms.resp.MaxMsgs\n\tttl := c.perms.resp.Expires\n\tnow := time.Now()\n\n\tfor k, resp := range c.replies {\n\t\tif mm > 0 && resp.n >= mm {\n\t\t\tdelete(c.replies, k)\n\t\t} else if ttl > 0 && now.Sub(resp.t) > ttl {\n\t\t\tdelete(c.replies, k)\n\t\t}\n\t}\n}\n\n// pruneDenyCache will prune the deny cache via randomly\n// deleting items. Doing so pruneSize items at a time.\n// Lock must be held for this one since it is shared under\n// deliverMsg.\nfunc (c *client) pruneDenyCache() {\n\tr := 0\n\tfor subject := range c.mperms.dcache {\n\t\tdelete(c.mperms.dcache, subject)\n\t\tif r++; r > pruneSize {\n\t\t\tbreak\n\t\t}\n\t}\n}\n\n// prunePubPermsCache will prune the cache via randomly\n// deleting items. Doing so pruneSize items at a time.\nfunc (c *client) prunePubPermsCache() {\n\tr := 0\n\tfor subject := range c.perms.pcache {\n\t\tdelete(c.perms.pcache, subject)\n\t\tif r++; r > pruneSize {\n\t\t\tbreak\n\t\t}\n\t}\n}\n\n// pubAllowed checks on publish permissioning.\n// Lock should not be held.\nfunc (c *client) pubAllowed(subject string) bool {\n\treturn c.pubAllowedFullCheck(subject, true)\n}\n\n// pubAllowedFullCheck checks on all publish permissioning depending\n// on the flag for dynamic reply permissions.\nfunc (c *client) pubAllowedFullCheck(subject string, fullCheck bool) bool {\n\tif c.perms == nil || (c.perms.pub.allow == nil && c.perms.pub.deny == nil) {\n\t\treturn true\n\t}\n\t// Check if published subject is allowed if we have permissions in place.\n\tallowed, ok := c.perms.pcache[subject]\n\tif ok {\n\t\treturn allowed\n\t}\n\t// Cache miss, check allow then deny as needed.\n\tif c.perms.pub.allow != nil {\n\t\tr := c.perms.pub.allow.Match(subject)\n\t\tallowed = len(r.psubs) != 0\n\t} else {\n\t\t// No entries means all are allowed. Deny will overrule as needed.\n\t\tallowed = true\n\t}\n\t// If we have a deny list and are currently allowed, check that as well.\n\tif allowed && c.perms.pub.deny != nil {\n\t\tr := c.perms.pub.deny.Match(subject)\n\t\tallowed = len(r.psubs) == 0\n\t}\n\n\t// If we are currently not allowed but we are tracking reply subjects\n\t// dynamically, check to see if we are allowed here but avoid pcache.\n\t// We need to acquire the lock though.\n\tif !allowed && fullCheck && c.perms.resp != nil {\n\t\tc.mu.Lock()\n\t\tif resp := c.replies[subject]; resp != nil {\n\t\t\tresp.n++\n\t\t\t// Check if we have sent too many responses.\n\t\t\tif c.perms.resp.MaxMsgs > 0 && resp.n > c.perms.resp.MaxMsgs {\n\t\t\t\tdelete(c.replies, subject)\n\t\t\t} else if c.perms.resp.Expires > 0 && time.Since(resp.t) > c.perms.resp.Expires {\n\t\t\t\tdelete(c.replies, subject)\n\t\t\t} else {\n\t\t\t\tallowed = true\n\t\t\t}\n\t\t}\n\t\tc.mu.Unlock()\n\t} else {\n\t\t// Update our cache here.\n\t\tc.perms.pcache[string(subject)] = allowed\n\t\t// Prune if needed.\n\t\tif len(c.perms.pcache) > maxPermCacheSize {\n\t\t\tc.prunePubPermsCache()\n\t\t}\n\t}\n\treturn allowed\n}\n\n// Test whether a reply subject is a service import reply.\nfunc isServiceReply(reply []byte) bool {\n\t// This function is inlined and checking this way is actually faster\n\t// than byte-by-byte comparison.\n\treturn len(reply) > 3 && string(reply[:4]) == replyPrefix\n}\n\n// Test whether a reply subject is a service import or a gateway routed reply.\nfunc isReservedReply(reply []byte) bool {\n\tif isServiceReply(reply) {\n\t\treturn true\n\t}\n\t// Faster to check with string([:]) than byte-by-byte\n\tif len(reply) > gwReplyPrefixLen && string(reply[:gwReplyPrefixLen]) == gwReplyPrefix {\n\t\treturn true\n\t}\n\treturn false\n}\n\n// This will decide to call the client code or router code.\nfunc (c *client) processInboundMsg(msg []byte) {\n\tswitch c.kind {\n\tcase CLIENT:\n\t\tc.processInboundClientMsg(msg)\n\tcase ROUTER:\n\t\tc.processInboundRoutedMsg(msg)\n\tcase GATEWAY:\n\t\tc.processInboundGatewayMsg(msg)\n\tcase LEAF:\n\t\tc.processInboundLeafMsg(msg)\n\t}\n}\n\n// selectMappedSubject will chose the mapped subject based on the client's inbound subject.\nfunc (c *client) selectMappedSubject() bool {\n\tnsubj, changed := c.acc.selectMappedSubject(string(c.pa.subject))\n\tif changed {\n\t\tc.pa.subject = []byte(nsubj)\n\t}\n\treturn changed\n}\n\n// processInboundClientMsg is called to process an inbound msg from a client.\nfunc (c *client) processInboundClientMsg(msg []byte) bool {\n\t// Update statistics\n\t// The msg includes the CR_LF, so pull back out for accounting.\n\tc.in.msgs++\n\tc.in.bytes += int32(len(msg) - LEN_CR_LF)\n\n\t// Check that client (could be here with SYSTEM) is not publishing on reserved \"$GNR\" prefix.\n\tif c.kind == CLIENT && hasGWRoutedReplyPrefix(c.pa.subject) {\n\t\tc.pubPermissionViolation(c.pa.subject)\n\t\treturn false\n\t}\n\n\t// Mostly under testing scenarios.\n\tif c.srv == nil || c.acc == nil {\n\t\treturn false\n\t}\n\n\t// Check pub permissions\n\tif c.perms != nil && (c.perms.pub.allow != nil || c.perms.pub.deny != nil) && !c.pubAllowed(string(c.pa.subject)) {\n\t\tc.pubPermissionViolation(c.pa.subject)\n\t\treturn false\n\t}\n\n\t// Now check for reserved replies. These are used for service imports.\n\tif len(c.pa.reply) > 0 && isReservedReply(c.pa.reply) {\n\t\tc.replySubjectViolation(c.pa.reply)\n\t\treturn false\n\t}\n\n\tif c.opts.Verbose {\n\t\tc.sendOK()\n\t}\n\n\t// If MQTT client, check for retain flag now that we have passed permissions check\n\tif c.isMqtt() {\n\t\tc.mqttHandlePubRetain()\n\t}\n\n\t// Check if this client's gateway replies map is not empty\n\tif atomic.LoadInt32(&c.cgwrt) > 0 && c.handleGWReplyMap(msg) {\n\t\treturn true\n\t}\n\n\t// If we have an exported service and we are doing remote tracking, check this subject\n\t// to see if we need to report the latency.\n\tif c.rrTracking != nil {\n\t\tc.mu.Lock()\n\t\trl := c.rrTracking.rmap[string(c.pa.subject)]\n\t\tif rl != nil {\n\t\t\tdelete(c.rrTracking.rmap, string(c.pa.subject))\n\t\t}\n\t\tc.mu.Unlock()\n\n\t\tif rl != nil {\n\t\t\tsl := &rl.M2\n\t\t\t// Fill this in and send it off to the other side.\n\t\t\tsl.Status = 200\n\t\t\tsl.Responder = c.getClientInfo(true)\n\t\t\tsl.ServiceLatency = time.Since(sl.RequestStart) - sl.Responder.RTT\n\t\t\tsl.TotalLatency = sl.ServiceLatency + sl.Responder.RTT\n\t\t\tsanitizeLatencyMetric(sl)\n\t\t\tlsub := remoteLatencySubjectForResponse(c.pa.subject)\n\t\t\tc.srv.sendInternalAccountMsg(nil, lsub, rl) // Send to SYS account\n\t\t}\n\t}\n\n\t// Match the subscriptions. We will use our own L1 map if\n\t// it's still valid, avoiding contention on the shared sublist.\n\tvar r *SublistResult\n\tvar ok bool\n\n\tgenid := atomic.LoadUint64(&c.acc.sl.genid)\n\tif genid == c.in.genid && c.in.results != nil {\n\t\tr, ok = c.in.results[string(c.pa.subject)]\n\t} else {\n\t\t// Reset our L1 completely.\n\t\tc.in.results = make(map[string]*SublistResult)\n\t\tc.in.genid = genid\n\t}\n\n\t// Go back to the sublist data structure.\n\tif !ok {\n\t\tr = c.acc.sl.Match(string(c.pa.subject))\n\t\tc.in.results[string(c.pa.subject)] = r\n\t\t// Prune the results cache. Keeps us from unbounded growth. Random delete.\n\t\tif len(c.in.results) > maxResultCacheSize {\n\t\t\tn := 0\n\t\t\tfor subject := range c.in.results {\n\t\t\t\tdelete(c.in.results, subject)\n\t\t\t\tif n++; n > pruneSize {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Indication if we attempted to deliver the message to anyone.\n\tvar didDeliver bool\n\tvar qnames [][]byte\n\n\t// Check for no interest, short circuit if so.\n\t// This is the fanout scale.\n\tif len(r.psubs)+len(r.qsubs) > 0 {\n\t\tflag := pmrNoFlag\n\t\t// If there are matching queue subs and we are in gateway mode,\n\t\t// we need to keep track of the queue names the messages are\n\t\t// delivered to. When sending to the GWs, the RMSG will include\n\t\t// those names so that the remote clusters do not deliver messages\n\t\t// to their queue subs of the same names.\n\t\tif len(r.qsubs) > 0 && c.srv.gateway.enabled &&\n\t\t\tatomic.LoadInt64(&c.srv.gateway.totalQSubs) > 0 {\n\t\t\tflag |= pmrCollectQueueNames\n\t\t}\n\n\t\tdidDeliver, qnames = c.processMsgResults(c.acc, r, msg, c.pa.deliver, c.pa.subject, c.pa.reply, flag)\n\t}\n\n\t// Now deal with gateways\n\tif c.srv.gateway.enabled {\n\t\tdidDeliver = c.sendMsgToGateways(c.acc, msg, c.pa.subject, c.pa.reply, qnames) || didDeliver\n\t}\n\n\t// Check to see if we did not deliver to anyone and the client has a reply subject set\n\t// and wants notification of no_responders.\n\tif !didDeliver && len(c.pa.reply) > 0 {\n\t\tc.mu.Lock()\n\t\tif c.opts.NoResponders {\n\t\t\tif sub := c.subForReply(c.pa.reply); sub != nil {\n\t\t\t\tproto := fmt.Sprintf(\"HMSG %s %s 16 16\\r\\nNATS/1.0 503\\r\\n\\r\\n\\r\\n\", c.pa.reply, sub.sid)\n\t\t\t\tc.queueOutbound([]byte(proto))\n\t\t\t\tc.addToPCD(c)\n\t\t\t}\n\t\t}\n\t\tc.mu.Unlock()\n\t}\n\n\treturn didDeliver\n}\n\n// Return the subscription for this reply subject. Only look at normal subs for this client.\nfunc (c *client) subForReply(reply []byte) *subscription {\n\tr := c.acc.sl.Match(string(reply))\n\tfor _, sub := range r.psubs {\n\t\tif sub.client == c {\n\t\t\treturn sub\n\t\t}\n\t}\n\treturn nil\n}\n\n// This is invoked knowing that this client has some GW replies\n// in its map. It will check if one is find for the c.pa.subject\n// and if so will process it directly (send to GWs and LEAFs) and\n// return true to notify the caller that the message was handled.\n// If there is no mapping for the subject, false is returned.\nfunc (c *client) handleGWReplyMap(msg []byte) bool {\n\tc.mu.Lock()\n\trm, ok := c.gwrm[string(c.pa.subject)]\n\tif !ok {\n\t\tc.mu.Unlock()\n\t\treturn false\n\t}\n\t// Set subject to the mapped reply subject\n\tc.pa.subject = []byte(rm.ms)\n\n\tvar rl *remoteLatency\n\n\tif c.rrTracking != nil {\n\t\trl = c.rrTracking.rmap[string(c.pa.subject)]\n\t\tif rl != nil {\n\t\t\tdelete(c.rrTracking.rmap, string(c.pa.subject))\n\t\t}\n\t}\n\tc.mu.Unlock()\n\n\tif rl != nil {\n\t\tsl := &rl.M2\n\t\t// Fill this in and send it off to the other side.\n\t\tsl.Status = 200\n\t\tsl.Responder = c.getClientInfo(true)\n\t\tsl.ServiceLatency = time.Since(sl.RequestStart) - sl.Responder.RTT\n\t\tsl.TotalLatency = sl.ServiceLatency + sl.Responder.RTT\n\t\tsanitizeLatencyMetric(sl)\n\t\tlsub := remoteLatencySubjectForResponse(c.pa.subject)\n\t\tc.srv.sendInternalAccountMsg(nil, lsub, rl) // Send to SYS account\n\t}\n\n\t// Check for leaf nodes\n\tif c.srv.gwLeafSubs.Count() > 0 {\n\t\tif r := c.srv.gwLeafSubs.Match(string(c.pa.subject)); len(r.psubs) > 0 {\n\t\t\tc.processMsgResults(c.acc, r, msg, nil, c.pa.subject, c.pa.reply, pmrNoFlag)\n\t\t}\n\t}\n\tif c.srv.gateway.enabled {\n\t\tc.sendMsgToGateways(c.acc, msg, c.pa.subject, c.pa.reply, nil)\n\t}\n\n\treturn true\n}\n\n// Used to setup the response map for a service import request that has a reply subject.\nfunc (c *client) setupResponseServiceImport(acc *Account, si *serviceImport, tracking bool, header http.Header) *serviceImport {\n\trsi := si.acc.addRespServiceImport(acc, string(c.pa.reply), si, tracking, header)\n\tif si.latency != nil {\n\t\tif c.rtt == 0 {\n\t\t\t// We have a service import that we are tracking but have not established RTT.\n\t\t\tc.sendRTTPing()\n\t\t}\n\t\tsi.acc.mu.Lock()\n\t\trsi.rc = c\n\t\tsi.acc.mu.Unlock()\n\t}\n\treturn rsi\n}\n\n// This will set a header for the message.\n// Lock does not need to be held but this should only be called\n// from the inbound go routine. We will update the pubArgs.\nfunc (c *client) setHeader(key, value string, msg []byte) []byte {\n\tconst hdrLine = \"NATS/1.0\\r\\n\"\n\tvar bb bytes.Buffer\n\tvar omi int\n\t// Write original header if present.\n\tif c.pa.hdr > LEN_CR_LF {\n\t\tomi = c.pa.hdr\n\t\tbb.Write(msg[:c.pa.hdr-LEN_CR_LF])\n\t} else {\n\t\tbb.WriteString(hdrLine)\n\t}\n\thttp.Header{key: []string{value}}.Write(&bb)\n\tbb.WriteString(CR_LF)\n\tnhdr := bb.Len()\n\t// Put the original message back.\n\tbb.Write(msg[omi:])\n\tnsize := bb.Len() - LEN_CR_LF\n\t// Update pubArgs\n\t// If others will use this later we need to save and restore original.\n\tc.pa.hdr = nhdr\n\tc.pa.size = nsize\n\tc.pa.hdb = []byte(strconv.Itoa(nhdr))\n\tc.pa.szb = []byte(strconv.Itoa(nsize))\n\treturn bb.Bytes()\n}\n\n// processServiceImport is an internal callback when a subscription matches an imported service\n// from another account. This includes response mappings as well.\nfunc (c *client) processServiceImport(si *serviceImport, acc *Account, msg []byte) {\n\t// If we are a GW and this is not a direct serviceImport ignore.\n\tisResponse := si.isRespServiceImport()\n\tif c.kind == GATEWAY && !isResponse {\n\t\treturn\n\t}\n\t// If we are here and we are a serviceImport response make sure we are not matching back\n\t// to the import/export pair that started the request. If so ignore.\n\tif isResponse && c.pa.psi != nil && c.pa.psi.se == si.se {\n\t\treturn\n\t}\n\n\tacc.mu.RLock()\n\tshouldReturn := si.invalid || acc.sl == nil\n\tacc.mu.RUnlock()\n\n\tif shouldReturn {\n\t\treturn\n\t}\n\n\tvar nrr []byte\n\tvar rsi *serviceImport\n\n\t// Check if there is a reply present and set up a response.\n\t// TODO(dlc) - restrict to configured service imports and not responses?\n\ttracking, headers := shouldSample(si.latency, c)\n\tif len(c.pa.reply) > 0 {\n\t\tif rsi = c.setupResponseServiceImport(acc, si, tracking, headers); rsi != nil {\n\t\t\tnrr = []byte(rsi.from)\n\t\t}\n\t} else {\n\t\t// Check to see if this was a bad request with no reply and we were supposed to be tracking.\n\t\tif !si.response && si.latency != nil && tracking {\n\t\t\tsi.acc.sendBadRequestTrackingLatency(si, c, headers)\n\t\t}\n\t}\n\n\t// Send tracking info here if we are tracking this response.\n\t// This is always a response.\n\tvar didSendTL bool\n\tif si.tracking {\n\t\t// Stamp that we attempted delivery.\n\t\tsi.didDeliver = true\n\t\tdidSendTL = acc.sendTrackingLatency(si, c)\n\t}\n\n\t// Pick correct to subject. If we matched on a wildcard use the literal publish subject.\n\tto := si.to\n\tif si.tr != nil {\n\t\t// FIXME(dlc) - This could be slow, may want to look at adding cache to bare transforms?\n\t\tto, _ = si.tr.transformSubject(string(c.pa.subject))\n\t} else if si.usePub {\n\t\tto = string(c.pa.subject)\n\t}\n\t// Now check to see if this account has mappings that could affect the service import.\n\t// Can't use non-locked trick like in processInboundClientMsg, so just call into selectMappedSubject\n\t// so we only lock once.\n\tto, _ = si.acc.selectMappedSubject(to)\n\n\t// Copy our pubArg and account\n\tpacopy := c.pa\n\toacc := c.acc\n\t// Change this so that we detect recursion\n\tc.pa.psi = si\n\n\t// Place our client info for the request in the message.\n\t// This will survive going across routes, etc.\n\tif c.pa.proxy == nil && !si.response {\n\t\tif ci := c.getClientInfo(si.share); ci != nil {\n\t\t\tif b, _ := json.Marshal(ci); b != nil {\n\t\t\t\tmsg = c.setHeader(ClientInfoHdr, string(b), msg)\n\t\t\t}\n\t\t}\n\t}\n\n\t// Set our reply.\n\tc.pa.reply = nrr\n\t// For processing properly across routes, etc.\n\tif c.kind == CLIENT || c.kind == LEAF {\n\t\tc.pa.proxy = c.acc\n\t}\n\tc.mu.Lock()\n\tc.acc = si.acc\n\tc.mu.Unlock()\n\n\t// FIXME(dlc) - Do L1 cache trick like normal client?\n\trr := si.acc.sl.Match(to)\n\n\t// If we are a route or gateway or leafnode and this message is flipped to a queue subscriber we\n\t// need to handle that since the processMsgResults will want a queue filter.\n\tflags := pmrMsgImportedFromService\n\tif c.kind == GATEWAY || c.kind == ROUTER || c.kind == LEAF {\n\t\tflags |= pmrIgnoreEmptyQueueFilter\n\t}\n\n\t// We will be calling back into processMsgResults since we are now being called as a normal sub.\n\t// We need to take care of the c.in.rts, so save off what is there and use a local version. We\n\t// will put back what was there after.\n\n\torts := c.in.rts\n\n\tvar lrts [routeTargetInit]routeTarget\n\tc.in.rts = lrts[:0]\n\n\tvar didDeliver bool\n\n\t// If this is not a gateway connection but gateway is enabled,\n\t// try to send this converted message to all gateways.\n\tif c.srv.gateway.enabled {\n\t\tflags |= pmrCollectQueueNames\n\t\tvar queues [][]byte\n\t\tdidDeliver, queues = c.processMsgResults(si.acc, rr, msg, nil, []byte(to), nrr, flags)\n\t\tdidDeliver = c.sendMsgToGateways(si.acc, msg, []byte(to), nrr, queues) || didDeliver\n\t} else {\n\t\tdidDeliver, _ = c.processMsgResults(si.acc, rr, msg, nil, []byte(to), nrr, flags)\n\t}\n\n\t// Put what was there back now.\n\tc.in.rts = orts\n\tc.pa = pacopy\n\tc.mu.Lock()\n\tc.acc = oacc\n\tc.mu.Unlock()\n\n\t// Determine if we should remove this service import. This is for response service imports.\n\t// We will remove if we did not deliver, or if we are a response service import and we are\n\t// a singleton, or we have an EOF message.\n\tshouldRemove := !didDeliver || (si.response && (si.rt == Singleton || len(msg) == LEN_CR_LF))\n\t// If we are tracking and we did not actually send the latency info we need to suppress the removal.\n\tif si.tracking && !didSendTL {\n\t\tshouldRemove = false\n\t}\n\t// If we are streamed or chunked we need to update our timestamp to avoid cleanup.\n\tif si.rt != Singleton && didDeliver {\n\t\tacc.mu.Lock()\n\t\tsi.ts = time.Now().UnixNano()\n\t\tacc.mu.Unlock()\n\t}\n\n\t// Cleanup of a response service import\n\tif shouldRemove {\n\t\treason := rsiOk\n\t\tif !didDeliver {\n\t\t\treason = rsiNoDelivery\n\t\t}\n\t\tif si.isRespServiceImport() {\n\t\t\tacc.removeRespServiceImport(si, reason)\n\t\t} else {\n\t\t\t// This is a main import and since we could not even deliver to the exporting account\n\t\t\t// go ahead and remove the respServiceImport we created above.\n\t\t\tsi.acc.removeRespServiceImport(rsi, reason)\n\t\t}\n\t}\n}\n\nfunc (c *client) addSubToRouteTargets(sub *subscription) {\n\tif c.in.rts == nil {\n\t\tc.in.rts = make([]routeTarget, 0, routeTargetInit)\n\t}\n\n\tfor i := range c.in.rts {\n\t\trt := &c.in.rts[i]\n\t\tif rt.sub.client == sub.client {\n\t\t\tif sub.queue != nil {\n\t\t\t\trt.qs = append(rt.qs, sub.queue...)\n\t\t\t\trt.qs = append(rt.qs, ' ')\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t}\n\n\tvar rt *routeTarget\n\tlrts := len(c.in.rts)\n\n\t// If we are here we do not have the sub yet in our list\n\t// If we have to grow do so here.\n\tif lrts == cap(c.in.rts) {\n\t\tc.in.rts = append(c.in.rts, routeTarget{})\n\t}\n\n\tc.in.rts = c.in.rts[:lrts+1]\n\trt = &c.in.rts[lrts]\n\trt.sub = sub\n\trt.qs = rt._qs[:0]\n\tif sub.queue != nil {\n\t\trt.qs = append(rt.qs, sub.queue...)\n\t\trt.qs = append(rt.qs, ' ')\n\t}\n}\n\n// This processes the sublist results for a given message.\n// Returns if the message was delivered to at least target and queue filters.\nfunc (c *client) processMsgResults(acc *Account, r *SublistResult, msg, deliver, subject, reply []byte, flags int) (bool, [][]byte) {\n\t// For sending messages across routes and leafnodes.\n\t// Reset if we have one since we reuse this data structure.\n\tif c.in.rts != nil {\n\t\tc.in.rts = c.in.rts[:0]\n\t}\n\n\tvar rplyHasGWPrefix bool\n\tvar creply = reply\n\n\t// If the reply subject is a GW routed reply, we will perform some\n\t// tracking in deliverMsg(). We also want to send to the user the\n\t// reply without the prefix. `creply` will be set to that and be\n\t// used to create the message header for client connections.\n\tif rplyHasGWPrefix = isGWRoutedReply(reply); rplyHasGWPrefix {\n\t\tcreply = reply[gwSubjectOffset:]\n\t}\n\n\t// With JetStream we now have times where we want to match a subscription\n\t// on one subject, but deliver it with another. e.g. JetStream deliverables.\n\t// This only works for last mile, meaning to a client. For other types we need\n\t// to use the original subject.\n\tsubj := subject\n\tif len(deliver) > 0 {\n\t\tsubj = deliver\n\t}\n\n\t// Check for JetStream encoded reply subjects.\n\t// For now these will only be on $JS.ACK prefixed reply subjects.\n\tif len(creply) > 0 &&\n\t\tc.kind != CLIENT && c.kind != SYSTEM && c.kind != JETSTREAM && c.kind != ACCOUNT &&\n\t\tbytes.HasPrefix(creply, []byte(jsAckPre)) {\n\t\t// We need to rewrite the subject and the reply.\n\t\tif li := bytes.LastIndex(creply, []byte(\"@\")); li != 0 && li < len(creply)-1 {\n\t\t\tsubj, creply = creply[li+1:], creply[:li]\n\t\t}\n\t}\n\n\tvar didDeliver bool\n\n\t// delivery subject for clients\n\tvar dsubj []byte\n\t// Used as scratch if mapping\n\tvar _dsubj [64]byte\n\n\t// Loop over all normal subscriptions that match.\n\tfor _, sub := range r.psubs {\n\t\t// Check if this is a send to a ROUTER. We now process\n\t\t// these after everything else.\n\t\tswitch sub.client.kind {\n\t\tcase ROUTER:\n\t\t\tif (c.kind != ROUTER && !c.isSpokeLeafNode()) || (flags&pmrAllowSendFromRouteToRoute != 0) {\n\t\t\t\tc.addSubToRouteTargets(sub)\n\t\t\t}\n\t\t\tcontinue\n\t\tcase GATEWAY:\n\t\t\t// Never send to gateway from here.\n\t\t\tcontinue\n\t\tcase LEAF:\n\t\t\t// We handle similarly to routes and use the same data structures.\n\t\t\t// Leaf node delivery audience is different however.\n\t\t\t// Also leaf nodes are always no echo, so we make sure we are not\n\t\t\t// going to send back to ourselves here.\n\t\t\tif c != sub.client && (c.kind != ROUTER || sub.client.isHubLeafNode()) {\n\t\t\t\tc.addSubToRouteTargets(sub)\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\t// Assume delivery subject is the normal subject to this point.\n\t\tdsubj = subj\n\n\t\t// Check for stream import mapped subs (shadow subs). These apply to local subs only.\n\t\tif sub.im != nil {\n\t\t\t// If this message was a service import do not re-export to an exported stream.\n\t\t\tif flags&pmrMsgImportedFromService != 0 {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif sub.im.tr != nil {\n\t\t\t\tto, _ := sub.im.tr.transformSubject(string(dsubj))\n\t\t\t\tdsubj = append(_dsubj[:0], to...)\n\t\t\t} else if sub.im.usePub {\n\t\t\t\tdsubj = append(_dsubj[:0], subj...)\n\t\t\t} else {\n\t\t\t\tdsubj = append(_dsubj[:0], sub.im.to...)\n\t\t\t}\n\t\t\t// If we are mapping for a deliver subject we will reverse roles.\n\t\t\t// The original subj we set from above is correct for the msg header,\n\t\t\t// but we need to transform the deliver subject to properly route.\n\t\t\tif len(deliver) > 0 {\n\t\t\t\tdsubj, subj = subj, dsubj\n\t\t\t}\n\t\t}\n\n\t\t// Remap to the original subject if internal.\n\t\tif sub.icb != nil {\n\t\t\tsubj = subject\n\t\t}\n\n\t\t// Normal delivery\n\t\tmh := c.msgHeader(dsubj, creply, sub)\n\t\tdidDeliver = c.deliverMsg(sub, subj, creply, mh, msg, rplyHasGWPrefix) || didDeliver\n\t}\n\n\t// Set these up to optionally filter based on the queue lists.\n\t// This is for messages received from routes which will have directed\n\t// guidance on which queue groups we should deliver to.\n\tqf := c.pa.queues\n\n\t// Declared here because of goto.\n\tvar queues [][]byte\n\n\t// For all routes/leaf/gateway connections, we may still want to send messages to\n\t// leaf nodes or routes even if there are no queue filters since we collect\n\t// them above and do not process inline like normal clients.\n\t// However, do select queue subs if asked to ignore empty queue filter.\n\tif (c.kind == LEAF || c.kind == ROUTER || c.kind == GATEWAY) && qf == nil && flags&pmrIgnoreEmptyQueueFilter == 0 {\n\t\tgoto sendToRoutesOrLeafs\n\t}\n\n\t// Check to see if we have our own rand yet. Global rand\n\t// has contention with lots of clients, etc.\n\tif c.in.prand == nil {\n\t\tc.in.prand = rand.New(rand.NewSource(time.Now().UnixNano()))\n\t}\n\n\t// Process queue subs\n\tfor i := 0; i < len(r.qsubs); i++ {\n\t\tqsubs := r.qsubs[i]\n\t\t// If we have a filter check that here. We could make this a map or someting more\n\t\t// complex but linear search since we expect queues to be small. Should be faster\n\t\t// and more cache friendly.\n\t\tif qf != nil && len(qsubs) > 0 {\n\t\t\ttqn := qsubs[0].queue\n\t\t\tfor _, qn := range qf {\n\t\t\t\tif bytes.Equal(qn, tqn) {\n\t\t\t\t\tgoto selectQSub\n\t\t\t\t}\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\tselectQSub:\n\t\t// We will hold onto remote or lead qsubs when we are coming from\n\t\t// a route or a leaf node just in case we can no longer do local delivery.\n\t\tvar rsub, sub *subscription\n\t\tvar _ql [32]*subscription\n\n\t\tsrc := c.kind\n\t\t// If we just came from a route we want to prefer local subs.\n\t\t// So only select from local subs but remember the first rsub\n\t\t// in case all else fails.\n\t\tif src == ROUTER {\n\t\t\tql := _ql[:0]\n\t\t\tfor i := 0; i < len(qsubs); i++ {\n\t\t\t\tsub = qsubs[i]\n\t\t\t\tif sub.client.kind == LEAF || sub.client.kind == ROUTER {\n\t\t\t\t\tif rsub == nil {\n\t\t\t\t\t\trsub = sub\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tql = append(ql, sub)\n\t\t\t\t}\n\t\t\t}\n\t\t\tqsubs = ql\n\t\t}\n\n\t\tsindex := 0\n\t\tlqs := len(qsubs)\n\t\tif lqs > 1 {\n\t\t\tsindex = c.in.prand.Int() % lqs\n\t\t}\n\n\t\t// Find a subscription that is able to deliver this message starting at a random index.\n\t\tfor i := 0; i < lqs; i++ {\n\t\t\tif sindex+i < lqs {\n\t\t\t\tsub = qsubs[sindex+i]\n\t\t\t} else {\n\t\t\t\tsub = qsubs[(sindex+i)%lqs]\n\t\t\t}\n\t\t\tif sub == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// We have taken care of preferring local subs for a message from a route above.\n\t\t\t// Here we just care about a client or leaf and skipping a leaf and preferring locals.\n\t\t\tif dst := sub.client.kind; dst == ROUTER || dst == LEAF {\n\t\t\t\tif (src == LEAF || src == CLIENT) && dst == LEAF {\n\t\t\t\t\tif rsub == nil {\n\t\t\t\t\t\trsub = sub\n\t\t\t\t\t}\n\t\t\t\t\tcontinue\n\t\t\t\t} else {\n\t\t\t\t\tc.addSubToRouteTargets(sub)\n\t\t\t\t\t// Clear rsub since we added a sub.\n\t\t\t\t\trsub = nil\n\t\t\t\t\tif flags&pmrCollectQueueNames != 0 {\n\t\t\t\t\t\tqueues = append(queues, sub.queue)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\t// Assume delivery subject is normal subject to this point.\n\t\t\tdsubj = subj\n\t\t\t// Check for stream import mapped subs. These apply to local subs only.\n\t\t\tif sub.im != nil {\n\t\t\t\t// If this message was a service import do not re-export to an exported stream.\n\t\t\t\tif flags&pmrMsgImportedFromService != 0 {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif sub.im.tr != nil {\n\t\t\t\t\tto, _ := sub.im.tr.transformSubject(string(subj))\n\t\t\t\t\tdsubj = append(_dsubj[:0], to...)\n\t\t\t\t} else if sub.im.usePub {\n\t\t\t\t\tdsubj = append(_dsubj[:0], subj...)\n\t\t\t\t} else {\n\t\t\t\t\tdsubj = append(_dsubj[:0], sub.im.to...)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tvar rreply = reply\n\t\t\tif rplyHasGWPrefix && sub.client.kind == CLIENT {\n\t\t\t\trreply = creply\n\t\t\t}\n\t\t\t// \"rreply\" will be stripped of the $GNR prefix (if present)\n\t\t\t// for client connections only.\n\t\t\tmh := c.msgHeader(dsubj, rreply, sub)\n\t\t\tif c.deliverMsg(sub, subject, rreply, mh, msg, rplyHasGWPrefix) {\n\t\t\t\tdidDeliver = true\n\t\t\t\t// Clear rsub\n\t\t\t\trsub = nil\n\t\t\t\tif flags&pmrCollectQueueNames != 0 {\n\t\t\t\t\tqueues = append(queues, sub.queue)\n\t\t\t\t}\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif rsub != nil {\n\t\t\t// If we are here we tried to deliver to a local qsub\n\t\t\t// but failed. So we will send it to a remote or leaf node.\n\t\t\tc.addSubToRouteTargets(rsub)\n\t\t\tif flags&pmrCollectQueueNames != 0 {\n\t\t\t\tqueues = append(queues, rsub.queue)\n\t\t\t}\n\t\t}\n\t}\n\nsendToRoutesOrLeafs:\n\n\t// If no messages for routes or leafnodes return here.\n\tif len(c.in.rts) == 0 {\n\t\treturn didDeliver, queues\n\t}\n\n\t// If we do have a deliver subject we need to do something with it.\n\t// Again this is when JetStream (but possibly others) wants the system\n\t// to rewrite the delivered subject. The way we will do that is place it\n\t// at the end of the reply subject if it exists.\n\tif len(deliver) > 0 && len(reply) > 0 {\n\t\treply = append(reply, '@')\n\t\treply = append(reply, deliver...)\n\t}\n\n\t// We address by index to avoid struct copy.\n\t// We have inline structs for memory layout and cache coherency.\n\tfor i := range c.in.rts {\n\t\trt := &c.in.rts[i]\n\t\t// Check if we have an origin cluster set from a leafnode message.\n\t\t// If so make sure we do not send it back to the same cluster for a different\n\t\t// leafnode. Cluster wide no echo.\n\t\tif rt.sub.client.kind == LEAF {\n\t\t\t// Check two scenarios. One is inbound from a route (c.pa.origin)\n\t\t\tif c.kind == ROUTER && len(c.pa.origin) > 0 {\n\t\t\t\tif string(c.pa.origin) == rt.sub.client.remoteCluster() {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\t\t\t// The other is leaf to leaf.\n\t\t\tif c.kind == LEAF {\n\t\t\t\tsrc, dest := c.remoteCluster(), rt.sub.client.remoteCluster()\n\t\t\t\tif src != _EMPTY_ && src == dest {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tmh := c.msgHeaderForRouteOrLeaf(subject, reply, rt, acc)\n\t\tdidDeliver = c.deliverMsg(rt.sub, subject, reply, mh, msg, false) || didDeliver\n\t}\n\treturn didDeliver, queues\n}\n\nfunc (c *client) pubPermissionViolation(subject []byte) {\n\tc.sendErr(fmt.Sprintf(\"Permissions Violation for Publish to %q\", subject))\n\tc.Errorf(\"Publish Violation - %s, Subject %q\", c.getAuthUser(), subject)\n}\n\nfunc (c *client) subPermissionViolation(sub *subscription) {\n\terrTxt := fmt.Sprintf(\"Permissions Violation for Subscription to %q\", sub.subject)\n\tlogTxt := fmt.Sprintf(\"Subscription Violation - %s, Subject %q, SID %s\",\n\t\tc.getAuthUser(), sub.subject, sub.sid)\n\n\tif sub.queue != nil {\n\t\terrTxt = fmt.Sprintf(\"Permissions Violation for Subscription to %q using queue %q\", sub.subject, sub.queue)\n\t\tlogTxt = fmt.Sprintf(\"Subscription Violation - %s, Subject %q, Queue: %q, SID %s\",\n\t\t\tc.getAuthUser(), sub.subject, sub.queue, sub.sid)\n\t}\n\n\tc.sendErr(errTxt)\n\tc.Errorf(logTxt)\n}\n\nfunc (c *client) replySubjectViolation(reply []byte) {\n\tc.sendErr(fmt.Sprintf(\"Permissions Violation for Publish with Reply of %q\", reply))\n\tc.Errorf(\"Publish Violation - %s, Reply %q\", c.getAuthUser(), reply)\n}\n\nfunc (c *client) processPingTimer() {\n\tc.mu.Lock()\n\tc.ping.tmr = nil\n\t// Check if connection is still opened\n\tif c.isClosed() {\n\t\tc.mu.Unlock()\n\t\treturn\n\t}\n\n\tc.Debugf(\"%s Ping Timer\", c.typeString())\n\n\tvar sendPing bool\n\n\t// If we have had activity within the PingInterval then\n\t// there is no need to send a ping. This can be client data\n\t// or if we received a ping from the other side.\n\tpingInterval := c.srv.getOpts().PingInterval\n\tif c.kind == GATEWAY {\n\t\tpingInterval = adjustPingIntervalForGateway(pingInterval)\n\t\tsendPing = true\n\t}\n\tnow := time.Now()\n\tneedRTT := c.rtt == 0 || now.Sub(c.rttStart) > DEFAULT_RTT_MEASUREMENT_INTERVAL\n\n\t// Do not delay PINGs for GATEWAY connections.\n\tif c.kind != GATEWAY {\n\t\tif delta := now.Sub(c.last); delta < pingInterval && !needRTT {\n\t\t\tc.Debugf(\"Delaying PING due to client activity %v ago\", delta.Round(time.Second))\n\t\t} else if delta := now.Sub(c.ping.last); delta < pingInterval && !needRTT {\n\t\t\tc.Debugf(\"Delaying PING due to remote ping %v ago\", delta.Round(time.Second))\n\t\t} else {\n\t\t\tsendPing = true\n\t\t}\n\t}\n\tif sendPing {\n\t\t// Check for violation\n\t\tif c.ping.out+1 > c.srv.getOpts().MaxPingsOut {\n\t\t\tc.Debugf(\"Stale Client Connection - Closing\")\n\t\t\tc.enqueueProto([]byte(fmt.Sprintf(errProto, \"Stale Connection\")))\n\t\t\tc.mu.Unlock()\n\t\t\tc.closeConnection(StaleConnection)\n\t\t\treturn\n\t\t}\n\t\t// Send PING\n\t\tc.sendPing()\n\t}\n\n\t// Reset to fire again.\n\tc.setPingTimer()\n\tc.mu.Unlock()\n}\n\n// Returns the smallest value between the given `d` and `gatewayMaxPingInterval` durations.\n// Invoked for connections known to be of GATEWAY type.\nfunc adjustPingIntervalForGateway(d time.Duration) time.Duration {\n\tif d > gatewayMaxPingInterval {\n\t\treturn gatewayMaxPingInterval\n\t}\n\treturn d\n}\n\n// Lock should be held\nfunc (c *client) setPingTimer() {\n\tif c.srv == nil {\n\t\treturn\n\t}\n\td := c.srv.getOpts().PingInterval\n\tif c.kind == GATEWAY {\n\t\td = adjustPingIntervalForGateway(d)\n\t}\n\tc.ping.tmr = time.AfterFunc(d, c.processPingTimer)\n}\n\n// Lock should be held\nfunc (c *client) clearPingTimer() {\n\tif c.ping.tmr == nil {\n\t\treturn\n\t}\n\tc.ping.tmr.Stop()\n\tc.ping.tmr = nil\n}\n\n// Lock should be held\nfunc (c *client) setAuthTimer(d time.Duration) {\n\tc.atmr = time.AfterFunc(d, c.authTimeout)\n}\n\n// Lock should be held\nfunc (c *client) clearAuthTimer() bool {\n\tif c.atmr == nil {\n\t\treturn true\n\t}\n\tstopped := c.atmr.Stop()\n\tc.atmr = nil\n\treturn stopped\n}\n\n// We may reuse atmr for expiring user jwts,\n// so check connectReceived.\n// Lock assume held on entry.\nfunc (c *client) awaitingAuth() bool {\n\treturn !c.flags.isSet(connectReceived) && c.atmr != nil\n}\n\n// This will set the atmr for the JWT expiration time.\n// We will lock on entry.\nfunc (c *client) setExpirationTimer(d time.Duration) {\n\tc.mu.Lock()\n\tc.atmr = time.AfterFunc(d, c.authExpired)\n\tc.mu.Unlock()\n}\n\n// Possibly flush the connection and then close the low level connection.\n// The boolean `minimalFlush` indicates if the flush operation should have a\n// minimal write deadline.\n// Lock is held on entry.\nfunc (c *client) flushAndClose(minimalFlush bool) {\n\tif !c.flags.isSet(skipFlushOnClose) && c.out.pb > 0 {\n\t\tif minimalFlush {\n\t\t\tconst lowWriteDeadline = 100 * time.Millisecond\n\n\t\t\t// Reduce the write deadline if needed.\n\t\t\tif c.out.wdl > lowWriteDeadline {\n\t\t\t\tc.out.wdl = lowWriteDeadline\n\t\t\t}\n\t\t}\n\t\tc.flushOutbound()\n\t}\n\tc.out.p, c.out.s = nil, nil\n\n\t// Close the low level connection. WriteDeadline need to be set\n\t// in case this is a TLS connection.\n\tif c.nc != nil {\n\t\tc.nc.SetWriteDeadline(time.Now().Add(100 * time.Millisecond))\n\t\tc.nc.Close()\n\t\tc.nc = nil\n\t}\n}\n\nfunc (c *client) typeString() string {\n\tswitch c.kind {\n\tcase CLIENT:\n\t\treturn \"Client\"\n\tcase ROUTER:\n\t\treturn \"Router\"\n\tcase GATEWAY:\n\t\treturn \"Gateway\"\n\tcase LEAF:\n\t\treturn \"Leafnode\"\n\tcase JETSTREAM:\n\t\treturn \"JetStream\"\n\tcase ACCOUNT:\n\t\treturn \"Account\"\n\tcase SYSTEM:\n\t\treturn \"System\"\n\t}\n\treturn \"Unknown Type\"\n}\n\n// swapAccountAfterReload will check to make sure the bound account for this client\n// is current. Under certain circumstances after a reload we could be pointing to\n// an older one.\nfunc (c *client) swapAccountAfterReload() {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tif c.srv == nil {\n\t\treturn\n\t}\n\tacc, _ := c.srv.LookupAccount(c.acc.Name)\n\tc.acc = acc\n}\n\n// processSubsOnConfigReload removes any subscriptions the client has that are no\n// longer authorized, and checks for imports (accounts) due to a config reload.\nfunc (c *client) processSubsOnConfigReload(awcsti map[string]struct{}) {\n\tc.mu.Lock()\n\tvar (\n\t\tcheckPerms = c.perms != nil\n\t\tcheckAcc   = c.acc != nil\n\t\tacc        = c.acc\n\t)\n\tif !checkPerms && !checkAcc {\n\t\tc.mu.Unlock()\n\t\treturn\n\t}\n\tvar (\n\t\t_subs    [32]*subscription\n\t\tsubs     = _subs[:0]\n\t\t_removed [32]*subscription\n\t\tremoved  = _removed[:0]\n\t\tsrv      = c.srv\n\t)\n\tif checkAcc {\n\t\t// We actually only want to check if stream imports have changed.\n\t\tif _, ok := awcsti[acc.Name]; !ok {\n\t\t\tcheckAcc = false\n\t\t}\n\t}\n\t// We will clear any mperms we have here. It will rebuild on the fly with canSubscribe,\n\t// so we do that here as we collect them. We will check result down below.\n\tc.mperms = nil\n\t// Collect client's subs under the lock\n\tfor _, sub := range c.subs {\n\t\t// Just checking to rebuild mperms under the lock, will collect removed though here.\n\t\t// Only collect under subs array of canSubscribe and checkAcc true.\n\t\tcanSub := c.canSubscribe(string(sub.subject))\n\t\tcanQSub := sub.queue != nil && c.canQueueSubscribe(string(sub.subject), string(sub.queue))\n\n\t\tif !canSub && !canQSub {\n\t\t\tremoved = append(removed, sub)\n\t\t} else if checkAcc {\n\t\t\tsubs = append(subs, sub)\n\t\t}\n\t}\n\tc.mu.Unlock()\n\n\t// This list is all subs who are allowed and we need to check accounts.\n\tfor _, sub := range subs {\n\t\tc.mu.Lock()\n\t\toldShadows := sub.shadow\n\t\tsub.shadow = nil\n\t\tc.mu.Unlock()\n\t\tc.addShadowSubscriptions(acc, sub)\n\t\tfor _, nsub := range oldShadows {\n\t\t\tnsub.im.acc.sl.Remove(nsub)\n\t\t}\n\t}\n\n\t// Unsubscribe all that need to be removed and report back to client and logs.\n\tfor _, sub := range removed {\n\t\tc.unsubscribe(acc, sub, true, true)\n\t\tc.sendErr(fmt.Sprintf(\"Permissions Violation for Subscription to %q (sid %q)\",\n\t\t\tsub.subject, sub.sid))\n\t\tsrv.Noticef(\"Removed sub %q (sid %q) for %s - not authorized\",\n\t\t\tsub.subject, sub.sid, c.getAuthUser())\n\t}\n}\n\n// Allows us to count up all the queue subscribers during close.\ntype qsub struct {\n\tsub *subscription\n\tn   int32\n}\n\nfunc (c *client) closeConnection(reason ClosedState) {\n\tc.mu.Lock()\n\tif c.flags.isSet(closeConnection) {\n\t\tc.mu.Unlock()\n\t\treturn\n\t}\n\t// Note that we may have markConnAsClosed() invoked before closeConnection(),\n\t// so don't set this to 1, instead bump the count.\n\tc.rref++\n\tc.flags.set(closeConnection)\n\tc.clearAuthTimer()\n\tc.clearPingTimer()\n\tc.markConnAsClosed(reason)\n\n\t// Unblock anyone who is potentially stalled waiting on us.\n\tif c.out.stc != nil {\n\t\tclose(c.out.stc)\n\t\tc.out.stc = nil\n\t}\n\n\tvar (\n\t\tconnectURLs   []string\n\t\twsConnectURLs []string\n\t\tkind          = c.kind\n\t\tsrv           = c.srv\n\t\tnoReconnect   = c.flags.isSet(noReconnect)\n\t\tacc           = c.acc\n\t)\n\n\t// Snapshot for use if we are a client connection.\n\t// FIXME(dlc) - we can just stub in a new one for client\n\t// and reference existing one.\n\tvar subs []*subscription\n\tif kind == CLIENT || kind == LEAF || kind == JETSTREAM {\n\t\tvar _subs [32]*subscription\n\t\tsubs = _subs[:0]\n\t\tfor _, sub := range c.subs {\n\t\t\t// Auto-unsubscribe subscriptions must be unsubscribed forcibly.\n\t\t\tsub.max = 0\n\t\t\tsub.close()\n\t\t\tsubs = append(subs, sub)\n\t\t}\n\t}\n\n\tif c.route != nil {\n\t\tconnectURLs = c.route.connectURLs\n\t\twsConnectURLs = c.route.wsConnURLs\n\t}\n\n\t// If we have remote latency tracking running shut that down.\n\tif c.rrTracking != nil {\n\t\tc.rrTracking.ptmr.Stop()\n\t\tc.rrTracking = nil\n\t}\n\n\tc.mu.Unlock()\n\n\t// Remove client's or leaf node or jetstream subscriptions.\n\tif acc != nil && (kind == CLIENT || kind == LEAF || kind == JETSTREAM) {\n\t\tacc.sl.RemoveBatch(subs)\n\t} else if kind == ROUTER {\n\t\tgo c.removeRemoteSubs()\n\t}\n\n\tif srv != nil {\n\t\t// If this is a route that disconnected, possibly send an INFO with\n\t\t// the updated list of connect URLs to clients that know how to\n\t\t// handle async INFOs.\n\t\tif (len(connectURLs) > 0 || len(wsConnectURLs) > 0) && !srv.getOpts().Cluster.NoAdvertise {\n\t\t\tsrv.removeConnectURLsAndSendINFOToClients(connectURLs, wsConnectURLs)\n\t\t}\n\n\t\t// Unregister\n\t\tsrv.removeClient(c)\n\n\t\t// Update remote subscriptions.\n\t\tif acc != nil && (kind == CLIENT || kind == LEAF) {\n\t\t\tqsubs := map[string]*qsub{}\n\t\t\tfor _, sub := range subs {\n\t\t\t\t// Call unsubscribe here to cleanup shadow subscriptions and such.\n\t\t\t\tc.unsubscribe(acc, sub, true, false)\n\t\t\t\t// Update route as normal for a normal subscriber.\n\t\t\t\tif sub.queue == nil {\n\t\t\t\t\tsrv.updateRouteSubscriptionMap(acc, sub, -1)\n\t\t\t\t\tsrv.updateLeafNodes(acc, sub, -1)\n\t\t\t\t} else {\n\t\t\t\t\t// We handle queue subscribers special in case we\n\t\t\t\t\t// have a bunch we can just send one update to the\n\t\t\t\t\t// connected routes.\n\t\t\t\t\tkey := string(sub.subject) + \" \" + string(sub.queue)\n\t\t\t\t\tif esub, ok := qsubs[key]; ok {\n\t\t\t\t\t\tesub.n++\n\t\t\t\t\t} else {\n\t\t\t\t\t\tqsubs[key] = &qsub{sub, 1}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif srv.gateway.enabled {\n\t\t\t\t\tsrv.gatewayUpdateSubInterest(acc.Name, sub, -1)\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Process any qsubs here.\n\t\t\tfor _, esub := range qsubs {\n\t\t\t\tsrv.updateRouteSubscriptionMap(acc, esub.sub, -(esub.n))\n\t\t\t\tsrv.updateLeafNodes(acc, esub.sub, -(esub.n))\n\t\t\t}\n\t\t\tif prev := acc.removeClient(c); prev == 1 && srv != nil {\n\t\t\t\tsrv.decActiveAccounts()\n\t\t\t}\n\t\t}\n\t}\n\n\t// Don't reconnect connections that have been marked with\n\t// the no reconnect flag.\n\tif noReconnect {\n\t\treturn\n\t}\n\n\tc.reconnect()\n}\n\n// Depending on the kind of connections, this may attempt to recreate a connection.\n// The actual reconnect attempt will be started in a go routine.\nfunc (c *client) reconnect() {\n\tvar (\n\t\tretryImplicit bool\n\t\tgwName        string\n\t\tgwIsOutbound  bool\n\t\tgwCfg         *gatewayCfg\n\t)\n\n\tc.mu.Lock()\n\t// Decrease the ref count and perform the reconnect only if == 0.\n\tc.rref--\n\tif c.flags.isSet(noReconnect) || c.rref > 0 {\n\t\tc.mu.Unlock()\n\t\treturn\n\t}\n\tif c.route != nil {\n\t\tretryImplicit = c.route.retry\n\t}\n\tkind := c.kind\n\tif kind == GATEWAY {\n\t\tgwName = c.gw.name\n\t\tgwIsOutbound = c.gw.outbound\n\t\tgwCfg = c.gw.cfg\n\t}\n\tsrv := c.srv\n\tc.mu.Unlock()\n\n\t// Check for a solicited route. If it was, start up a reconnect unless\n\t// we are already connected to the other end.\n\tif c.isSolicitedRoute() || retryImplicit {\n\t\t// Capture these under lock\n\t\tc.mu.Lock()\n\t\trid := c.route.remoteID\n\t\trtype := c.route.routeType\n\t\trurl := c.route.url\n\t\tc.mu.Unlock()\n\n\t\tsrv.mu.Lock()\n\t\tdefer srv.mu.Unlock()\n\n\t\t// It is possible that the server is being shutdown.\n\t\t// If so, don't try to reconnect\n\t\tif !srv.running {\n\t\t\treturn\n\t\t}\n\n\t\tif rid != \"\" && srv.remotes[rid] != nil {\n\t\t\tsrv.Debugf(\"Not attempting reconnect for solicited route, already connected to \\\"%s\\\"\", rid)\n\t\t\treturn\n\t\t} else if rid == srv.info.ID {\n\t\t\tsrv.Debugf(\"Detected route to self, ignoring %q\", rurl)\n\t\t\treturn\n\t\t} else if rtype != Implicit || retryImplicit {\n\t\t\tsrv.Debugf(\"Attempting reconnect for solicited route \\\"%s\\\"\", rurl)\n\t\t\t// Keep track of this go-routine so we can wait for it on\n\t\t\t// server shutdown.\n\t\t\tsrv.startGoRoutine(func() { srv.reConnectToRoute(rurl, rtype) })\n\t\t}\n\t} else if srv != nil && kind == GATEWAY && gwIsOutbound {\n\t\tif gwCfg != nil {\n\t\t\tsrv.Debugf(\"Attempting reconnect for gateway %q\", gwName)\n\t\t\t// Run this as a go routine since we may be called within\n\t\t\t// the solicitGateway itself if there was an error during\n\t\t\t// the creation of the gateway connection.\n\t\t\tsrv.startGoRoutine(func() { srv.reconnectGateway(gwCfg) })\n\t\t} else {\n\t\t\tsrv.Debugf(\"Gateway %q not in configuration, not attempting reconnect\", gwName)\n\t\t}\n\t} else if c.isSolicitedLeafNode() {\n\t\t// Check if this is a solicited leaf node. Start up a reconnect.\n\t\tsrv.startGoRoutine(func() { srv.reConnectToRemoteLeafNode(c.leaf.remote) })\n\t}\n}\n\n// Set the noReconnect flag. This is used before a call to closeConnection()\n// to prevent the connection to reconnect (routes, gateways).\nfunc (c *client) setNoReconnect() {\n\tc.mu.Lock()\n\tc.flags.set(noReconnect)\n\tc.mu.Unlock()\n}\n\n// Returns the client's RTT value with the protection of the client's lock.\nfunc (c *client) getRTTValue() time.Duration {\n\tc.mu.Lock()\n\trtt := c.rtt\n\tc.mu.Unlock()\n\treturn rtt\n}\n\n// This function is used by ROUTER and GATEWAY connections to\n// look for a subject on a given account (since these type of\n// connections are not bound to a specific account).\n// If the c.pa.subject is found in the cache, the cached result\n// is returned, otherwse, we match the account's sublist and update\n// the cache. The cache is pruned if reaching a certain size.\nfunc (c *client) getAccAndResultFromCache() (*Account, *SublistResult) {\n\tvar (\n\t\tacc *Account\n\t\tpac *perAccountCache\n\t\tr   *SublistResult\n\t\tok  bool\n\t)\n\t// Check our cache.\n\tif pac, ok = c.in.pacache[string(c.pa.pacache)]; ok {\n\t\t// Check the genid to see if it's still valid.\n\t\tif genid := atomic.LoadUint64(&pac.acc.sl.genid); genid != pac.genid {\n\t\t\tok = false\n\t\t\tdelete(c.in.pacache, string(c.pa.pacache))\n\t\t} else {\n\t\t\tacc = pac.acc\n\t\t\tr = pac.results\n\t\t}\n\t}\n\n\tif !ok {\n\t\t// Match correct account and sublist.\n\t\tif acc, _ = c.srv.LookupAccount(string(c.pa.account)); acc == nil {\n\t\t\treturn nil, nil\n\t\t}\n\n\t\t// Match against the account sublist.\n\t\tr = acc.sl.Match(string(c.pa.subject))\n\n\t\t// Store in our cache\n\t\tc.in.pacache[string(c.pa.pacache)] = &perAccountCache{acc, r, atomic.LoadUint64(&acc.sl.genid)}\n\n\t\t// Check if we need to prune.\n\t\tif len(c.in.pacache) > maxPerAccountCacheSize {\n\t\t\tc.prunePerAccountCache()\n\t\t}\n\t}\n\treturn acc, r\n}\n\n// Account will return the associated account for this client.\nfunc (c *client) Account() *Account {\n\tif c == nil {\n\t\treturn nil\n\t}\n\tc.mu.Lock()\n\tacc := c.acc\n\tc.mu.Unlock()\n\treturn acc\n}\n\n// prunePerAccountCache will prune off a random number of cache entries.\nfunc (c *client) prunePerAccountCache() {\n\tn := 0\n\tfor cacheKey := range c.in.pacache {\n\t\tdelete(c.in.pacache, cacheKey)\n\t\tif n++; n > prunePerAccountCacheSize {\n\t\t\tbreak\n\t\t}\n\t}\n}\n\n// pruneClosedSubFromPerAccountCache remove entries that contain subscriptions\n// that have been closed.\nfunc (c *client) pruneClosedSubFromPerAccountCache() {\n\tfor cacheKey, pac := range c.in.pacache {\n\t\tfor _, sub := range pac.results.psubs {\n\t\t\tif sub.isClosed() {\n\t\t\t\tgoto REMOVE\n\t\t\t}\n\t\t}\n\t\tfor _, qsub := range pac.results.qsubs {\n\t\t\tfor _, sub := range qsub {\n\t\t\t\tif sub.isClosed() {\n\t\t\t\t\tgoto REMOVE\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tcontinue\n\tREMOVE:\n\t\tdelete(c.in.pacache, cacheKey)\n\t}\n}\n\n// Grabs the information for this client.\nfunc (c *client) getClientInfo(detailed bool) *ClientInfo {\n\tif c == nil || (c.kind != CLIENT && c.kind != LEAF) {\n\t\treturn nil\n\t}\n\t// Server name. Defaults to server ID if not set explicitly.\n\tvar sn string\n\tif detailed && c.kind != LEAF {\n\t\tsn = c.srv.Name()\n\t}\n\n\tc.mu.Lock()\n\tvar ci ClientInfo\n\t// RTT and Account are always added.\n\tci.Account = accForClient(c)\n\tci.RTT = c.rtt\n\t// Detailed signals additional opt in.\n\tif detailed {\n\t\tif c.kind == LEAF {\n\t\t\tsn = c.leaf.remoteServer\n\t\t}\n\t\tci.Start = &c.start\n\t\tci.Host = c.host\n\t\tci.ID = c.cid\n\t\tci.Name = c.opts.Name\n\t\tci.User = c.getRawAuthUser()\n\t\tci.Lang = c.opts.Lang\n\t\tci.Version = c.opts.Version\n\t\tci.Server = sn\n\t\tci.Jwt = c.opts.JWT\n\t\tci.IssuerKey = issuerForClient(c)\n\t\tci.NameTag = c.nameTag\n\t\tci.Tags = c.tags\n\t}\n\tc.mu.Unlock()\n\treturn &ci\n}\n\n// getRAwAuthUser returns the raw auth user for the client.\n// Lock should be held.\nfunc (c *client) getRawAuthUser() string {\n\tswitch {\n\tcase c.opts.Nkey != \"\":\n\t\treturn c.opts.Nkey\n\tcase c.opts.Username != \"\":\n\t\treturn c.opts.Username\n\tcase c.opts.JWT != \"\":\n\t\treturn c.pubKey\n\tcase c.opts.Token != \"\":\n\t\treturn c.opts.Token\n\tdefault:\n\t\treturn \"\"\n\t}\n}\n\n// getAuthUser returns the auth user for the client.\n// Lock should be held.\nfunc (c *client) getAuthUser() string {\n\tswitch {\n\tcase c.opts.Nkey != \"\":\n\t\treturn fmt.Sprintf(\"Nkey %q\", c.opts.Nkey)\n\tcase c.opts.Username != \"\":\n\t\treturn fmt.Sprintf(\"User %q\", c.opts.Username)\n\tcase c.opts.JWT != \"\":\n\t\treturn fmt.Sprintf(\"JWT User %q\", c.pubKey)\n\tdefault:\n\t\treturn `User \"N/A\"`\n\t}\n}\n\n// Given an array of strings, this function converts it to a map as long\n// as all the content (converted to upper-case) matches some constants.\n\n// Converts the given array of strings to a map of string.\n// The strings are converted to upper-case and added to the map only\n// if the server recognize them as valid connection types.\n// If there are unknown connection types, the map of valid ones is returned\n// along with an error that contains the name of the unknown.\nfunc convertAllowedConnectionTypes(cts []string) (map[string]struct{}, error) {\n\tvar unknown []string\n\tm := make(map[string]struct{}, len(cts))\n\tfor _, i := range cts {\n\t\ti = strings.ToUpper(i)\n\t\tswitch i {\n\t\tcase jwt.ConnectionTypeStandard, jwt.ConnectionTypeWebsocket, jwt.ConnectionTypeLeafnode, jwt.ConnectionTypeMqtt:\n\t\t\tm[i] = struct{}{}\n\t\tdefault:\n\t\t\tunknown = append(unknown, i)\n\t\t}\n\t}\n\tvar err error\n\t// We will still return the map of valid ones.\n\tif len(unknown) != 0 {\n\t\terr = fmt.Errorf(\"invalid connection types %q\", unknown)\n\t}\n\treturn m, err\n}\n\n// This will return true if the connection is of a type present in the given `acts` map.\n// Note that so far this is used only for CLIENT or LEAF connections.\n// But a CLIENT can be standard or websocket (and other types in the future).\nfunc (c *client) connectionTypeAllowed(acts map[string]struct{}) bool {\n\t// Empty means all type of clients are allowed\n\tif len(acts) == 0 {\n\t\treturn true\n\t}\n\tvar want string\n\tswitch c.kind {\n\tcase CLIENT:\n\t\tswitch c.clientType() {\n\t\tcase NATS:\n\t\t\twant = jwt.ConnectionTypeStandard\n\t\tcase WS:\n\t\t\twant = jwt.ConnectionTypeWebsocket\n\t\tcase MQTT:\n\t\t\twant = jwt.ConnectionTypeMqtt\n\t\t}\n\tcase LEAF:\n\t\twant = jwt.ConnectionTypeLeafnode\n\t}\n\t_, ok := acts[want]\n\treturn ok\n}\n\n// isClosed returns true if either closeConnection or connMarkedClosed\n// flag have been set, or if `nc` is nil, which may happen in tests.\nfunc (c *client) isClosed() bool {\n\treturn c.flags.isSet(closeConnection) || c.flags.isSet(connMarkedClosed) || c.nc == nil\n}\n\n// Logging functionality scoped to a client or route.\nfunc (c *client) Error(err error) {\n\tc.srv.Errors(c, err)\n}\n\nfunc (c *client) Errorf(format string, v ...interface{}) {\n\tformat = fmt.Sprintf(\"%s - %s\", c, format)\n\tc.srv.Errorf(format, v...)\n}\n\nfunc (c *client) Debugf(format string, v ...interface{}) {\n\tformat = fmt.Sprintf(\"%s - %s\", c, format)\n\tc.srv.Debugf(format, v...)\n}\n\nfunc (c *client) Noticef(format string, v ...interface{}) {\n\tformat = fmt.Sprintf(\"%s - %s\", c, format)\n\tc.srv.Noticef(format, v...)\n}\n\nfunc (c *client) Tracef(format string, v ...interface{}) {\n\tformat = fmt.Sprintf(\"%s - %s\", c, format)\n\tc.srv.Tracef(format, v...)\n}\n\nfunc (c *client) Warnf(format string, v ...interface{}) {\n\tformat = fmt.Sprintf(\"%s - %s\", c, format)\n\tc.srv.Warnf(format, v...)\n}\n", "idx": 1, "id": 12374, "msg": "This is consistent for all clients that we will check yes? Seems like we should just use the singleton, maybe pass it to the parse function or since clients have a server pointer set it at server start and just access that way without locks?", "proj": "nats-io-nats-server", "lang": "go"}
{"patch": "@@ -19,6 +19,7 @@\n # along with qutebrowser.  If not, see <http://www.gnu.org/licenses/>.\n \n \"\"\"Generate the html documentation based on the asciidoc files.\"\"\"\n+from typing import List, Tuple\n \n import re\n import os", "y": 1, "oldf": "#!/usr/bin/env python3\n# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:\n\n# Copyright 2014-2020 Florian Bruhin (The Compiler) <mail@qutebrowser.org>\n\n# This file is part of qutebrowser.\n#\n# qutebrowser is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# qutebrowser is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with qutebrowser.  If not, see <http://www.gnu.org/licenses/>.\n\n\"\"\"Generate the html documentation based on the asciidoc files.\"\"\"\n\nimport re\nimport os\nimport os.path\nimport sys\nimport subprocess\nimport glob\nimport shutil\nimport tempfile\nimport argparse\nimport io\n\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), os.pardir))\n\nfrom scripts import utils\n\n\nclass AsciiDoc:\n\n    \"\"\"Abstraction of an asciidoc subprocess.\"\"\"\n\n    FILES = ['faq', 'changelog', 'contributing', 'quickstart', 'userscripts']\n\n    def __init__(self, asciidoc, website):\n        self._cmd = None\n        self._asciidoc = asciidoc\n        self._website = website\n        self._homedir = None\n        self._themedir = None\n        self._tempdir = None\n        self._failed = False\n\n    def prepare(self):\n        \"\"\"Get the asciidoc command and create the homedir to use.\"\"\"\n        self._cmd = self._get_asciidoc_cmd()\n        self._homedir = tempfile.mkdtemp()\n        self._themedir = os.path.join(\n            self._homedir, '.asciidoc', 'themes', 'qute')\n        self._tempdir = os.path.join(self._homedir, 'tmp')\n        os.makedirs(self._tempdir)\n        os.makedirs(self._themedir)\n\n    def cleanup(self):\n        \"\"\"Clean up the temporary home directory for asciidoc.\"\"\"\n        if self._homedir is not None and not self._failed:\n            shutil.rmtree(self._homedir)\n\n    def build(self):\n        \"\"\"Build either the website or the docs.\"\"\"\n        if self._website:\n            self._build_website()\n        else:\n            self._build_docs()\n            self._copy_images()\n\n    def _build_docs(self):\n        \"\"\"Render .asciidoc files to .html sites.\"\"\"\n        files = [('doc/{}.asciidoc'.format(f),\n                  'qutebrowser/html/doc/{}.html'.format(f))\n                 for f in self.FILES]\n        for src in glob.glob('doc/help/*.asciidoc'):\n            name, _ext = os.path.splitext(os.path.basename(src))\n            dst = 'qutebrowser/html/doc/{}.html'.format(name)\n            files.append((src, dst))\n\n        # patch image links to use local copy\n        replacements = [\n            (\"https://raw.githubusercontent.com/qutebrowser/qutebrowser/master/doc/img/cheatsheet-big.png\",\n             \"qute://help/img/cheatsheet-big.png\"),\n            (\"https://raw.githubusercontent.com/qutebrowser/qutebrowser/master/doc/img/cheatsheet-small.png\",\n             \"qute://help/img/cheatsheet-small.png\")\n        ]\n        asciidoc_args = ['-a', 'source-highlighter=pygments']\n\n        for src, dst in files:\n            src_basename = os.path.basename(src)\n            modified_src = os.path.join(self._tempdir, src_basename)\n            with open(modified_src, 'w', encoding='utf-8') as modified_f, \\\n                    open(src, 'r', encoding='utf-8') as f:\n                for line in f:\n                    for orig, repl in replacements:\n                        line = line.replace(orig, repl)\n                    modified_f.write(line)\n            self.call(modified_src, dst, *asciidoc_args)\n\n    def _copy_images(self):\n        \"\"\"Copy image files to qutebrowser/html/doc.\"\"\"\n        print(\"Copying files...\")\n        dst_path = os.path.join('qutebrowser', 'html', 'doc', 'img')\n        try:\n            os.mkdir(dst_path)\n        except FileExistsError:\n            pass\n        for filename in ['cheatsheet-big.png', 'cheatsheet-small.png']:\n            src = os.path.join('doc', 'img', filename)\n            dst = os.path.join(dst_path, filename)\n            shutil.copy(src, dst)\n\n    def _build_website_file(self, root, filename):\n        \"\"\"Build a single website file.\"\"\"\n        src = os.path.join(root, filename)\n        src_basename = os.path.basename(src)\n        parts = [self._website[0]]\n        dirname = os.path.dirname(src)\n        if dirname:\n            parts.append(os.path.relpath(os.path.dirname(src)))\n        parts.append(\n            os.extsep.join((os.path.splitext(src_basename)[0],\n                            'html')))\n        dst = os.path.join(*parts)\n        os.makedirs(os.path.dirname(dst), exist_ok=True)\n\n        modified_src = os.path.join(self._tempdir, src_basename)\n        shutil.copy('www/header.asciidoc', modified_src)\n\n        outfp = io.StringIO()\n\n        with open(modified_src, 'r', encoding='utf-8') as header_file:\n            header = header_file.read()\n            header += \"\\n\\n\"\n\n        with open(src, 'r', encoding='utf-8') as infp:\n            outfp.write(\"\\n\\n\")\n            hidden = False\n            found_title = False\n            title = \"\"\n            last_line = \"\"\n\n            for line in infp:\n                line = line.rstrip()\n                if line == '// QUTE_WEB_HIDE':\n                    assert not hidden\n                    hidden = True\n                elif line == '// QUTE_WEB_HIDE_END':\n                    assert hidden\n                    hidden = False\n                elif line == \"The Compiler <mail@qutebrowser.org>\":\n                    continue\n                elif re.fullmatch(r':\\w+:.*', line):\n                    # asciidoc field\n                    continue\n\n                if not found_title:\n                    if re.fullmatch(r'=+', line):\n                        line = line.replace('=', '-')\n                        found_title = True\n                        title = last_line + \" | qutebrowser\\n\"\n                        title += \"=\" * (len(title) - 1)\n                    elif re.fullmatch(r'= .+', line):\n                        line = '==' + line[1:]\n                        found_title = True\n                        title = last_line + \" | qutebrowser\\n\"\n                        title += \"=\" * (len(title) - 1)\n\n                if not hidden:\n                    outfp.write(line.replace(\".asciidoc[\", \".html[\") + '\\n')\n                    last_line = line\n\n        current_lines = outfp.getvalue()\n        outfp.close()\n\n        with open(modified_src, 'w+', encoding='utf-8') as final_version:\n            final_version.write(title + \"\\n\\n\" + header + current_lines)\n\n        asciidoc_args = ['--theme=qute', '-a toc', '-a toc-placement=manual',\n                         '-a', 'source-highlighter=pygments']\n        self.call(modified_src, dst, *asciidoc_args)\n\n    def _build_website(self):\n        \"\"\"Prepare and build the website.\"\"\"\n        theme_file = os.path.abspath(os.path.join('www', 'qute.css'))\n        shutil.copy(theme_file, self._themedir)\n\n        outdir = self._website[0]\n\n        for root, _dirs, files in os.walk(os.getcwd()):\n            for filename in files:\n                basename, ext = os.path.splitext(filename)\n                if (ext != '.asciidoc' or\n                        basename in ['header', 'OpenSans-License']):\n                    continue\n                self._build_website_file(root, filename)\n\n        copy = {'icons': 'icons', 'doc/img': 'doc/img', 'www/media': 'media/'}\n\n        for src, dest in copy.items():\n            full_dest = os.path.join(outdir, dest)\n            try:\n                shutil.rmtree(full_dest)\n            except FileNotFoundError:\n                pass\n            shutil.copytree(src, full_dest)\n\n        for dst, link_name in [\n                ('README.html', 'index.html'),\n                (os.path.join('doc', 'quickstart.html'), 'quickstart.html')]:\n            try:\n                os.symlink(dst, os.path.join(outdir, link_name))\n            except FileExistsError:\n                pass\n\n    def _get_asciidoc_cmd(self):\n        \"\"\"Try to find out what commandline to use to invoke asciidoc.\"\"\"\n        if self._asciidoc is not None:\n            return self._asciidoc\n\n        try:\n            subprocess.run(['asciidoc'], stdout=subprocess.DEVNULL,\n                           stderr=subprocess.DEVNULL, check=True)\n        except OSError:\n            pass\n        else:\n            return ['asciidoc']\n\n        try:\n            subprocess.run(['asciidoc.py'], stdout=subprocess.DEVNULL,\n                           stderr=subprocess.DEVNULL, check=True)\n        except OSError:\n            pass\n        else:\n            return ['asciidoc.py']\n\n        raise FileNotFoundError\n\n    def call(self, src, dst, *args):\n        \"\"\"Call asciidoc for the given files.\n\n        Args:\n            src: The source .asciidoc file.\n            dst: The destination .html file, or None to auto-guess.\n            *args: Additional arguments passed to asciidoc.\n        \"\"\"\n        print(\"Calling asciidoc for {}...\".format(os.path.basename(src)))\n        cmdline = self._cmd[:]\n        if dst is not None:\n            cmdline += ['--out-file', dst]\n        cmdline += args\n        cmdline.append(src)\n        try:\n            env = os.environ.copy()\n            env['HOME'] = self._homedir\n            subprocess.run(cmdline, check=True, env=env)\n        except (subprocess.CalledProcessError, OSError) as e:\n            self._failed = True\n            utils.print_col(str(e), 'red')\n            print(\"Keeping modified sources in {}.\".format(self._homedir))\n            sys.exit(1)\n\n\ndef parse_args():\n    \"\"\"Parse command-line arguments.\"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--website', help=\"Build website into a given \"\n                        \"directory.\", nargs=1)\n    parser.add_argument('--asciidoc', help=\"Full path to python and \"\n                        \"asciidoc.py. If not given, it's searched in PATH.\",\n                        nargs=2, required=False,\n                        metavar=('PYTHON', 'ASCIIDOC'))\n    return parser.parse_args()\n\n\ndef run(**kwargs):\n    \"\"\"Regenerate documentation.\"\"\"\n    try:\n        os.mkdir('qutebrowser/html/doc')\n    except FileExistsError:\n        pass\n\n    asciidoc = AsciiDoc(**kwargs)\n    try:\n        asciidoc.prepare()\n    except FileNotFoundError:\n        utils.print_col(\"Could not find asciidoc! Please install it, or use \"\n                        \"the --asciidoc argument to point this script to the \"\n                        \"correct python/asciidoc.py location!\", 'red')\n        sys.exit(1)\n\n    try:\n        asciidoc.build()\n    finally:\n        asciidoc.cleanup()\n\n\ndef main(colors=False):\n    \"\"\"Generate html files for the online documentation.\"\"\"\n    utils.change_cwd()\n    utils.use_color = colors\n    args = parse_args()\n    run(asciidoc=args.asciidoc, website=args.website)\n\n\nif __name__ == '__main__':\n    main(colors=True)\n", "idx": 1, "id": 24308, "msg": "nitpick: Please move this down to the other imports, as it's a Python stdlib import.", "proj": "qutebrowser-qutebrowser", "lang": "py"}
{"patch": "@@ -106,7 +106,11 @@ class User < ActiveRecord::Base\n \n   def self.from_oauth_hash(auth_hash)\n     user_data = auth_hash.extra.raw_info.to_hash\n-    self.find_or_create_by(email_address: user_data['email'])\n+    user = self.for_email(user_data['email'])\n+    if user_data['first_name'].present? && user_data['last_name'].present?\n+      user.update_attributes(first_name: user_data['first_name'], last_name: user_data['last_name'])\n+    end\n+    user\n   end\n \n   def role_on(proposal)", "y": 1, "oldf": "class User < ActiveRecord::Base\n  has_paper_trail class_name: 'C2Version'\n\n  validates :client_slug, inclusion: {\n    in: ->(_) { Proposal.client_slugs },\n    message: \"'%{value}' is not in Proposal.client_slugs #{Proposal.client_slugs.inspect}\",\n    allow_blank: true\n  }\n  validates :email_address, presence: true, uniqueness: true\n  validates_email_format_of :email_address\n\n  has_many :steps, dependent: :destroy\n  has_many :comments, dependent: :destroy\n  has_many :observations, dependent: :destroy\n\n  has_many :user_roles, dependent: :destroy\n  has_many :roles, through: :user_roles\n  has_many :proposals, foreign_key: \"requester_id\", dependent: :destroy\n\n  has_many :outgoing_delegations, class_name: 'ApprovalDelegate', foreign_key: 'assigner_id'\n\n  def self.active\n    where(active: true)\n  end\n\n  # this is for user_roles specifically, not proposals or any other objects for which\n  # this user might have roles.\n  # rubocop:disable Style/PredicateName\n  def has_role?(name_or_role)\n    if name_or_role.is_a?(Role)\n      self.roles.include?(name_or_role)\n    else\n      self.roles.exists?(name: name_or_role)\n    end\n  end\n  # rubocop:enable Style/PredicateName\n\n  def add_role(name_or_role)\n    if name_or_role.is_a?(Role)\n      role = name_or_role\n    else\n      role = Role.find_or_create_by!(name: name_or_role)\n    end\n    self.user_roles.find_or_create_by!(role: role)\n  end\n\n  def self.with_role(name_or_role)\n    if name_or_role.is_a?(Role)\n      name_or_role.users\n    else\n      User.joins(:roles).where(roles: { name: name_or_role })\n    end\n  end\n\n  def self.sql_for_role_slug(role, slug)\n    self.with_role(role).select(:id).where(client_slug: slug).to_sql\n  end\n\n  def full_name\n    if first_name.present? && last_name.present?\n      \"#{first_name} #{last_name}\"\n    else\n      email_address\n    end\n  end\n\n  def requested_proposals\n    Proposal.where(requester_id: self.id)\n  end\n\n  def last_requested_proposal\n    self.requested_proposals.order('created_at DESC').first\n  end\n\n  def add_delegate(other)\n    self.outgoing_delegations.create!(assignee: other)\n  end\n\n  def delegates_to?(other)\n    self.outgoing_delegations.exists?(assignee_id: other.id)\n  end\n\n  def client_admin?\n    self.has_role?('client_admin')\n  end\n\n  def admin?\n    has_role?('admin')\n  end\n\n  def not_admin?\n    !admin?\n  end\n\n  def self.for_email(email)\n    User.find_or_create_by(email_address: email.strip.downcase)\n  end\n\n  def self.for_email_with_slug(email, client_slug)\n    u = self.for_email(email)\n    unless u.client_slug\n      u.client_slug = client_slug\n    end\n    u\n  end\n\n  def self.from_oauth_hash(auth_hash)\n    user_data = auth_hash.extra.raw_info.to_hash\n    self.find_or_create_by(email_address: user_data['email'])\n  end\n\n  def role_on(proposal)\n    RolePicker.new(self, proposal)\n  end\nend\n", "idx": 1, "id": 15372, "msg": "I'm surprised rubocop isn't picking up singe quotes?", "proj": "18F-C2", "lang": "rb"}
{"patch": "@@ -153,13 +153,12 @@ public abstract class VectorWriter implements Closeable {\n     private final DocIDMerger<VectorValuesSub> docIdMerger;\n     private final int[] ordBase;\n     private final int cost;\n-    private final int size;\n+    private int size;\n \n     private int docId;\n     private VectorValuesSub current;\n-    // For each doc with a vector, record its ord in the segments being merged. This enables random\n-    // access into the\n-    // unmerged segments using the ords from the merged segment.\n+    /* For each doc with a vector, record its ord in the segments being merged. This enables random access into the unmerged segments using the ords from the merged segment.\n+     */\n     private int[] ordMap;\n     private int ord;\n ", "y": 1, "oldf": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage org.apache.lucene.codecs;\n\nimport static org.apache.lucene.search.DocIdSetIterator.NO_MORE_DOCS;\n\nimport java.io.Closeable;\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.List;\nimport org.apache.lucene.index.DocIDMerger;\nimport org.apache.lucene.index.FieldInfo;\nimport org.apache.lucene.index.MergeState;\nimport org.apache.lucene.index.RandomAccessVectorValues;\nimport org.apache.lucene.index.RandomAccessVectorValuesProducer;\nimport org.apache.lucene.index.VectorValues;\nimport org.apache.lucene.search.TopDocs;\nimport org.apache.lucene.util.BytesRef;\n\n/** Writes vectors to an index. */\npublic abstract class VectorWriter implements Closeable {\n\n  /** Sole constructor */\n  protected VectorWriter() {}\n\n  /** Write all values contained in the provided reader */\n  public abstract void writeField(FieldInfo fieldInfo, VectorValues values) throws IOException;\n\n  /** Called once at the end before close */\n  public abstract void finish() throws IOException;\n\n  /** Merge the vector values from multiple segments, for all fields */\n  public void merge(MergeState mergeState) throws IOException {\n    for (int i = 0; i < mergeState.fieldInfos.length; i++) {\n      VectorReader reader = mergeState.vectorReaders[i];\n      assert reader != null || mergeState.fieldInfos[i].hasVectorValues() == false;\n      if (reader != null) {\n        reader.checkIntegrity();\n      }\n    }\n    for (FieldInfo fieldInfo : mergeState.mergeFieldInfos) {\n      if (fieldInfo.hasVectorValues()) {\n        mergeVectors(fieldInfo, mergeState);\n      }\n    }\n    finish();\n  }\n\n  private void mergeVectors(FieldInfo mergeFieldInfo, final MergeState mergeState)\n      throws IOException {\n    if (mergeState.infoStream.isEnabled(\"VV\")) {\n      mergeState.infoStream.message(\"VV\", \"merging \" + mergeState.segmentInfo);\n    }\n    List<VectorValuesSub> subs = new ArrayList<>();\n    int dimension = -1;\n    VectorValues.SearchStrategy searchStrategy = null;\n    int nonEmptySegmentIndex = 0;\n    for (int i = 0; i < mergeState.vectorReaders.length; i++) {\n      VectorReader vectorReader = mergeState.vectorReaders[i];\n      if (vectorReader != null) {\n        if (mergeFieldInfo != null && mergeFieldInfo.hasVectorValues()) {\n          int segmentDimension = mergeFieldInfo.getVectorDimension();\n          VectorValues.SearchStrategy segmentSearchStrategy =\n              mergeFieldInfo.getVectorSearchStrategy();\n          if (dimension == -1) {\n            dimension = segmentDimension;\n            searchStrategy = mergeFieldInfo.getVectorSearchStrategy();\n          } else if (dimension != segmentDimension) {\n            throw new IllegalStateException(\n                \"Varying dimensions for vector-valued field \"\n                    + mergeFieldInfo.name\n                    + \": \"\n                    + dimension\n                    + \"!=\"\n                    + segmentDimension);\n          } else if (searchStrategy != segmentSearchStrategy) {\n            throw new IllegalStateException(\n                \"Varying search strategys for vector-valued field \"\n                    + mergeFieldInfo.name\n                    + \": \"\n                    + searchStrategy\n                    + \"!=\"\n                    + segmentSearchStrategy);\n          }\n          VectorValues values = vectorReader.getVectorValues(mergeFieldInfo.name);\n          if (values != null) {\n            subs.add(new VectorValuesSub(nonEmptySegmentIndex++, mergeState.docMaps[i], values));\n          }\n        }\n      }\n    }\n    // Create a new VectorValues by iterating over the sub vectors, mapping the resulting\n    // docids using docMaps in the mergeState.\n    if (subs.size() > 0) {\n      writeField(mergeFieldInfo, new VectorValuesMerger(subs, mergeState));\n    }\n    if (mergeState.infoStream.isEnabled(\"VV\")) {\n      mergeState.infoStream.message(\"VV\", \"merge done \" + mergeState.segmentInfo);\n    }\n  }\n\n  /** Tracks state of one sub-reader that we are merging */\n  private static class VectorValuesSub extends DocIDMerger.Sub {\n\n    final MergeState.DocMap docMap;\n    final VectorValues values;\n    final int segmentIndex;\n    int count;\n\n    VectorValuesSub(int segmentIndex, MergeState.DocMap docMap, VectorValues values) {\n      super(docMap);\n      this.values = values;\n      this.segmentIndex = segmentIndex;\n      this.docMap = docMap;\n      assert values.docID() == -1;\n    }\n\n    @Override\n    public int nextDoc() throws IOException {\n      int docId = values.nextDoc();\n      if (docId != NO_MORE_DOCS) {\n        // Note: this does count deleted docs since they are present in the to-be-merged segment\n        ++count;\n      }\n      return docId;\n    }\n  }\n\n  /**\n   * View over multiple VectorValues supporting iterator-style access via DocIdMerger. Maintains a\n   * reverse ordinal mapping for documents having values in order to support random access by dense\n   * ordinal.\n   */\n  private static class VectorValuesMerger extends VectorValues\n      implements RandomAccessVectorValuesProducer {\n    private final List<VectorValuesSub> subs;\n    private final DocIDMerger<VectorValuesSub> docIdMerger;\n    private final int[] ordBase;\n    private final int cost;\n    private final int size;\n\n    private int docId;\n    private VectorValuesSub current;\n    // For each doc with a vector, record its ord in the segments being merged. This enables random\n    // access into the\n    // unmerged segments using the ords from the merged segment.\n    private int[] ordMap;\n    private int ord;\n\n    VectorValuesMerger(List<VectorValuesSub> subs, MergeState mergeState) throws IOException {\n      this.subs = subs;\n      docIdMerger = DocIDMerger.of(subs, mergeState.needsIndexSort);\n      int totalCost = 0, totalSize = 0;\n      for (VectorValuesSub sub : subs) {\n        totalCost += sub.values.cost();\n        totalSize += sub.values.size();\n      }\n      cost = totalCost;\n      size = totalSize;\n      ordMap = new int[size];\n      ordBase = new int[subs.size()];\n      int lastBase = 0;\n      for (int k = 0; k < subs.size(); k++) {\n        int size = subs.get(k).values.size();\n        ordBase[k] = lastBase;\n        lastBase += size;\n      }\n      docId = -1;\n    }\n\n    @Override\n    public int docID() {\n      return docId;\n    }\n\n    @Override\n    public int nextDoc() throws IOException {\n      current = docIdMerger.next();\n      if (current == null) {\n        docId = NO_MORE_DOCS;\n      } else {\n        docId = current.mappedDocID;\n        ordMap[ord++] = ordBase[current.segmentIndex] + current.count - 1;\n      }\n      return docId;\n    }\n\n    @Override\n    public float[] vectorValue() throws IOException {\n      return current.values.vectorValue();\n    }\n\n    @Override\n    public BytesRef binaryValue() throws IOException {\n      return current.values.binaryValue();\n    }\n\n    @Override\n    public RandomAccessVectorValues randomAccess() {\n      return new MergerRandomAccess();\n    }\n\n    @Override\n    public int advance(int target) {\n      throw new UnsupportedOperationException();\n    }\n\n    @Override\n    public int size() {\n      return size;\n    }\n\n    @Override\n    public long cost() {\n      return cost;\n    }\n\n    @Override\n    public int dimension() {\n      return subs.get(0).values.dimension();\n    }\n\n    @Override\n    public SearchStrategy searchStrategy() {\n      return subs.get(0).values.searchStrategy();\n    }\n\n    @Override\n    public TopDocs search(float[] target, int k, int fanout) throws IOException {\n      throw new UnsupportedOperationException();\n    }\n\n    class MergerRandomAccess implements RandomAccessVectorValues {\n\n      private final List<RandomAccessVectorValues> raSubs;\n\n      MergerRandomAccess() {\n        raSubs = new ArrayList<>(subs.size());\n        for (VectorValuesSub sub : subs) {\n          if (sub.values instanceof RandomAccessVectorValuesProducer) {\n            raSubs.add(((RandomAccessVectorValuesProducer) sub.values).randomAccess());\n          } else {\n            throw new IllegalStateException(\n                \"Cannot merge VectorValues without support for random access\");\n          }\n        }\n      }\n\n      @Override\n      public int size() {\n        return size;\n      }\n\n      @Override\n      public int dimension() {\n        return VectorValuesMerger.this.dimension();\n      }\n\n      @Override\n      public SearchStrategy searchStrategy() {\n        return VectorValuesMerger.this.searchStrategy();\n      }\n\n      @Override\n      public float[] vectorValue(int target) throws IOException {\n        int unmappedOrd = ordMap[target];\n        int segmentOrd = Arrays.binarySearch(ordBase, unmappedOrd);\n        if (segmentOrd < 0) {\n          // get the index of the greatest lower bound\n          segmentOrd = -2 - segmentOrd;\n        }\n        while (segmentOrd < ordBase.length - 1 && ordBase[segmentOrd + 1] == ordBase[segmentOrd]) {\n          // forward over empty segments which will share the same ordBase\n          segmentOrd++;\n        }\n        return raSubs.get(segmentOrd).vectorValue(unmappedOrd - ordBase[segmentOrd]);\n      }\n\n      @Override\n      public BytesRef binaryValue(int targetOrd) throws IOException {\n        throw new UnsupportedOperationException();\n      }\n    }\n  }\n}\n", "idx": 1, "id": 39677, "msg": "Hmmm I thought spotless would wrap this line, but it doesn't seem to complain about it", "proj": "apache-lucene-solr", "lang": "java"}
{"patch": "@@ -7,7 +7,7 @@\n  * \"License\"); you may not use this file except in compliance\n  * with the License. You may obtain a copy of the License at\n  *\n- *   http://www.apache.org/licenses/LICENSE-2.0\n+ * http://www.apache.org/licenses/LICENSE-2.0\n  *\n  * Unless required by applicable law or agreed to in writing,\n  * software distributed under the License is distributed on an", "y": 1, "oldf": "/**\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements. See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership. The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License. You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied. See the License for the\n * specific language governing permissions and limitations\n * under the License.\n *\n * Contains some contributions under the Thrift Software License.\n * Please see doc/old-thrift-license.txt in the Thrift distribution for\n * details.\n */\n\nusing System;\nusing System.Text;\nusing Thrift.Transport;\nusing System.Collections;\nusing System.IO;\nusing System.Collections.Generic;\n\nnamespace Thrift.Protocol\n{\n    public class TCompactProtocol : TProtocol\n    {\n        private static TStruct ANONYMOUS_STRUCT = new TStruct(\"\");\n        private static TField TSTOP = new TField(\"\", TType.Stop, (short)0);\n\n        private static byte[] ttypeToCompactType = new byte[16];\n\n        private const byte PROTOCOL_ID = 0x82;\n        private const byte VERSION = 1;\n        private const byte VERSION_MASK = 0x1f; // 0001 1111\n        private const byte TYPE_MASK = 0xE0; // 1110 0000\n        private const byte TYPE_BITS = 0x07; // 0000 0111\n        private const int TYPE_SHIFT_AMOUNT = 5;\n\n        /**\n         * All of the on-wire type codes.\n         */\n        private static class Types\n        {\n            public const byte STOP = 0x00;\n            public const byte BOOLEAN_TRUE = 0x01;\n            public const byte BOOLEAN_FALSE = 0x02;\n            public const byte BYTE = 0x03;\n            public const byte I16 = 0x04;\n            public const byte I32 = 0x05;\n            public const byte I64 = 0x06;\n            public const byte DOUBLE = 0x07;\n            public const byte BINARY = 0x08;\n            public const byte LIST = 0x09;\n            public const byte SET = 0x0A;\n            public const byte MAP = 0x0B;\n            public const byte STRUCT = 0x0C;\n        }\n\n        /**\n         * Used to keep track of the last field for the current and previous structs,\n         * so we can do the delta stuff.\n         */\n        private Stack<short> lastField_ = new Stack<short>(15);\n\n        private short lastFieldId_ = 0;\n\n        /**\n         * If we encounter a boolean field begin, save the TField here so it can\n         * have the value incorporated.\n         */\n        private Nullable<TField> booleanField_;\n\n        /**\n         * If we Read a field header, and it's a boolean field, save the boolean\n         * value here so that ReadBool can use it.\n         */\n        private  Nullable<Boolean> boolValue_;\n\n\n        #region CompactProtocol Factory\n\n        /**\n          * Factory\n          */\n        public class Factory : TProtocolFactory\n        {\n            public Factory() { }\n\n            public TProtocol GetProtocol(TTransport trans)\n            {\n                return new TCompactProtocol(trans);\n            }\n        }\n\n        #endregion\n\n        public TCompactProtocol(TTransport trans)\n            : base(trans)\n        {\n            ttypeToCompactType[(int)TType.Stop] = Types.STOP;\n            ttypeToCompactType[(int)TType.Bool] = Types.BOOLEAN_TRUE;\n            ttypeToCompactType[(int)TType.Byte] = Types.BYTE;\n            ttypeToCompactType[(int)TType.I16] = Types.I16;\n            ttypeToCompactType[(int)TType.I32] = Types.I32;\n            ttypeToCompactType[(int)TType.I64] = Types.I64;\n            ttypeToCompactType[(int)TType.Double] = Types.DOUBLE;\n            ttypeToCompactType[(int)TType.String] = Types.BINARY;\n            ttypeToCompactType[(int)TType.List] = Types.LIST;\n            ttypeToCompactType[(int)TType.Set] = Types.SET;\n            ttypeToCompactType[(int)TType.Map] = Types.MAP;\n            ttypeToCompactType[(int)TType.Struct] = Types.STRUCT;\n        }\n\n        public void reset()\n        {\n            lastField_.Clear();\n            lastFieldId_ = 0;\n        }\n\n        #region Write Methods\n\n\n        /**\n         * Writes a byte without any possibility of all that field header nonsense.\n         * Used internally by other writing methods that know they need to Write a byte.\n         */\n        private byte[] byteDirectBuffer = new byte[1];\n        private void WriteByteDirect(byte b)\n        {\n            byteDirectBuffer[0] = b;\n            trans.Write(byteDirectBuffer);\n        }\n\n        /**\n         * Writes a byte without any possibility of all that field header nonsense.\n         */\n        private void WriteByteDirect(int n)\n        {\n            WriteByteDirect((byte)n);\n        }\n\n        /**\n         * Write an i32 as a varint. Results in 1-5 bytes on the wire.\n         * TODO: make a permanent buffer like WriteVarint64?\n         */\n        byte[] i32buf = new byte[5];\n        private void WriteVarint32(uint n)\n        {\n            int idx = 0;\n            while (true)\n            {\n                if ((n & ~0x7F) == 0)\n                {\n                    i32buf[idx++] = (byte)n;\n                    // WriteByteDirect((byte)n);\n                    break;\n                    // return;\n                }\n                else\n                {\n                    i32buf[idx++] = (byte)((n & 0x7F) | 0x80);\n                    // WriteByteDirect((byte)((n & 0x7F) | 0x80));\n                    n >>= 7;\n                }\n            }\n            trans.Write(i32buf, 0, idx);\n        }\n\n        /**\n        * Write a message header to the wire. Compact Protocol messages contain the\n        * protocol version so we can migrate forwards in the future if need be.\n        */\n        public override void WriteMessageBegin(TMessage message)\n        {\n            WriteByteDirect(PROTOCOL_ID);\n            WriteByteDirect((byte)((VERSION & VERSION_MASK) | ((((uint)message.Type) << TYPE_SHIFT_AMOUNT) & TYPE_MASK)));\n            WriteVarint32((uint)message.SeqID);\n            WriteString(message.Name);\n        }\n\n        /**\n         * Write a struct begin. This doesn't actually put anything on the wire. We\n         * use it as an opportunity to put special placeholder markers on the field\n         * stack so we can get the field id deltas correct.\n         */\n        public override void WriteStructBegin(TStruct strct)\n        {\n            lastField_.Push(lastFieldId_);\n            lastFieldId_ = 0;\n        }\n\n        /**\n         * Write a struct end. This doesn't actually put anything on the wire. We use\n         * this as an opportunity to pop the last field from the current struct off\n         * of the field stack.\n         */\n        public override void WriteStructEnd()\n        {\n            lastFieldId_ = lastField_.Pop();\n        }\n\n        /**\n         * Write a field header containing the field id and field type. If the\n         * difference between the current field id and the last one is small (< 15),\n         * then the field id will be encoded in the 4 MSB as a delta. Otherwise, the\n         * field id will follow the type header as a zigzag varint.\n         */\n        public override void WriteFieldBegin(TField field)\n        {\n            if (field.Type == TType.Bool)\n            {\n                // we want to possibly include the value, so we'll wait.\n                booleanField_ = field;\n            }\n            else\n            {\n                WriteFieldBeginInternal(field, 0xFF);\n            }\n        }\n\n        /**\n         * The workhorse of WriteFieldBegin. It has the option of doing a\n         * 'type override' of the type header. This is used specifically in the\n         * boolean field case.\n         */\n        private void WriteFieldBeginInternal(TField field, byte typeOverride)\n        {\n            // short lastField = lastField_.Pop();\n\n            // if there's a type override, use that.\n            byte typeToWrite = typeOverride == 0xFF ? getCompactType(field.Type) : typeOverride;\n\n            // check if we can use delta encoding for the field id\n            if (field.ID > lastFieldId_ && field.ID - lastFieldId_ <= 15)\n            {\n                // Write them together\n                WriteByteDirect((field.ID - lastFieldId_) << 4 | typeToWrite);\n            }\n            else\n            {\n                // Write them separate\n                WriteByteDirect(typeToWrite);\n                WriteI16(field.ID);\n            }\n\n            lastFieldId_ = field.ID;\n            // lastField_.push(field.id);\n        }\n\n        /**\n         * Write the STOP symbol so we know there are no more fields in this struct.\n         */\n        public override void WriteFieldStop()\n        {\n            WriteByteDirect(Types.STOP);\n        }\n\n        /**\n         * Write a map header. If the map is empty, omit the key and value type\n         * headers, as we don't need any additional information to skip it.\n         */\n        public override void WriteMapBegin(TMap map)\n        {\n            if (map.Count == 0)\n            {\n                WriteByteDirect(0);\n            }\n            else\n            {\n                WriteVarint32((uint)map.Count);\n                WriteByteDirect(getCompactType(map.KeyType) << 4 | getCompactType(map.ValueType));\n            }\n        }\n\n        /**\n         * Write a list header.\n         */\n        public override void WriteListBegin(TList list)\n        {\n            WriteCollectionBegin(list.ElementType, list.Count);\n        }\n\n        /**\n         * Write a set header.\n         */\n        public override void WriteSetBegin(TSet set)\n        {\n            WriteCollectionBegin(set.ElementType, set.Count);\n        }\n\n        /**\n         * Write a boolean value. Potentially, this could be a boolean field, in\n         * which case the field header info isn't written yet. If so, decide what the\n         * right type header is for the value and then Write the field header.\n         * Otherwise, Write a single byte.\n         */\n        public override void WriteBool(Boolean b)\n        {\n            if (booleanField_ != null)\n            {\n                // we haven't written the field header yet\n                WriteFieldBeginInternal(booleanField_.Value, b ? Types.BOOLEAN_TRUE : Types.BOOLEAN_FALSE);\n                booleanField_ = null;\n            }\n            else\n            {\n                // we're not part of a field, so just Write the value.\n                WriteByteDirect(b ? Types.BOOLEAN_TRUE : Types.BOOLEAN_FALSE);\n            }\n        }\n\n        /**\n         * Write a byte. Nothing to see here!\n         */\n        public override void WriteByte(sbyte b)\n        {\n            WriteByteDirect((byte)b);\n        }\n\n        /**\n         * Write an I16 as a zigzag varint.\n         */\n        public override void WriteI16(short i16)\n        {\n            WriteVarint32(intToZigZag(i16));\n        }\n\n        /**\n         * Write an i32 as a zigzag varint.\n         */\n        public override void WriteI32(int i32)\n        {\n            WriteVarint32(intToZigZag(i32));\n        }\n\n        /**\n         * Write an i64 as a zigzag varint.\n         */\n        public override void WriteI64(long i64)\n        {\n            WriteVarint64(longToZigzag(i64));\n        }\n\n        /**\n         * Write a double to the wire as 8 bytes.\n         */\n        public override void WriteDouble(double dub)\n        {\n            byte[] data = new byte[] { 0, 0, 0, 0, 0, 0, 0, 0 };\n            fixedLongToBytes(BitConverter.DoubleToInt64Bits(dub), data, 0);\n            trans.Write(data);\n        }\n\n        /**\n         * Write a string to the wire with a varint size preceding.\n         */\n        public override void WriteString(String str)\n        {\n            byte[] bytes = UTF8Encoding.UTF8.GetBytes(str);\n            WriteBinary(bytes, 0, bytes.Length);\n        }\n\n        /**\n         * Write a byte array, using a varint for the size.\n         */\n        public override void WriteBinary(byte[] bin)\n        {\n            WriteBinary(bin, 0, bin.Length);\n        }\n\n        private void WriteBinary(byte[] buf, int offset, int length)\n        {\n            WriteVarint32((uint)length);\n            trans.Write(buf, offset, length);\n        }\n\n        //\n        // These methods are called by structs, but don't actually have any wire\n        // output or purpose.\n        //\n\n        public override void WriteMessageEnd() { }\n        public override void WriteMapEnd() { }\n        public override void WriteListEnd() { }\n        public override void WriteSetEnd() { }\n        public override void WriteFieldEnd() { }\n\n        //\n        // Internal writing methods\n        //\n\n        /**\n         * Abstract method for writing the start of lists and sets. List and sets on\n         * the wire differ only by the type indicator.\n         */\n        protected void WriteCollectionBegin(TType elemType, int size)\n        {\n            if (size <= 14)\n            {\n                WriteByteDirect(size << 4 | getCompactType(elemType));\n            }\n            else\n            {\n                WriteByteDirect(0xf0 | getCompactType(elemType));\n                WriteVarint32((uint)size);\n            }\n        }\n\n        /**\n         * Write an i64 as a varint. Results in 1-10 bytes on the wire.\n         */\n        byte[] varint64out = new byte[10];\n        private void WriteVarint64(ulong n)\n        {\n            int idx = 0;\n            while (true)\n            {\n                if ((n & ~(ulong)0x7FL) == 0)\n                {\n                    varint64out[idx++] = (byte)n;\n                    break;\n                }\n                else\n                {\n                    varint64out[idx++] = ((byte)((n & 0x7F) | 0x80));\n                    n >>= 7;\n                }\n            }\n            trans.Write(varint64out, 0, idx);\n        }\n\n        /**\n         * Convert l into a zigzag long. This allows negative numbers to be\n         * represented compactly as a varint.\n         */\n        private ulong longToZigzag(long n)\n        {\n            return (ulong)(n << 1) ^ (ulong)(n >> 63);\n        }\n\n        /**\n         * Convert n into a zigzag int. This allows negative numbers to be\n         * represented compactly as a varint.\n         */\n        private uint intToZigZag(int n)\n        {\n            return (uint)(n << 1) ^ (uint)(n >> 31);\n        }\n\n        /**\n         * Convert a long into little-endian bytes in buf starting at off and going\n         * until off+7.\n         */\n        private void fixedLongToBytes(long n, byte[] buf, int off)\n        {\n            buf[off + 0] = (byte)(n & 0xff);\n            buf[off + 1] = (byte)((n >> 8) & 0xff);\n            buf[off + 2] = (byte)((n >> 16) & 0xff);\n            buf[off + 3] = (byte)((n >> 24) & 0xff);\n            buf[off + 4] = (byte)((n >> 32) & 0xff);\n            buf[off + 5] = (byte)((n >> 40) & 0xff);\n            buf[off + 6] = (byte)((n >> 48) & 0xff);\n            buf[off + 7] = (byte)((n >> 56) & 0xff);\n        }\n\n        #endregion\n\n        #region ReadMethods\n\n        /**\n   * Read a message header.\n   */\n        public override TMessage ReadMessageBegin()\n        {\n            byte protocolId = (byte)ReadByte();\n            if (protocolId != PROTOCOL_ID)\n            {\n                throw new TProtocolException(\"Expected protocol id \" + PROTOCOL_ID.ToString(\"X\") + \" but got \" + protocolId.ToString(\"X\"));\n            }\n            byte versionAndType = (byte)ReadByte();\n            byte version = (byte)(versionAndType & VERSION_MASK);\n            if (version != VERSION)\n            {\n                throw new TProtocolException(\"Expected version \" + VERSION + \" but got \" + version);\n            }\n            byte type = (byte)((versionAndType >> TYPE_SHIFT_AMOUNT) & TYPE_BITS);\n            int seqid = (int)ReadVarint32();\n            String messageName = ReadString();\n            return new TMessage(messageName, (TMessageType)type, seqid);\n        }\n\n        /**\n         * Read a struct begin. There's nothing on the wire for this, but it is our\n         * opportunity to push a new struct begin marker onto the field stack.\n         */\n        public override TStruct ReadStructBegin()\n        {\n            lastField_.Push(lastFieldId_);\n            lastFieldId_ = 0;\n            return ANONYMOUS_STRUCT;\n        }\n\n        /**\n         * Doesn't actually consume any wire data, just removes the last field for\n         * this struct from the field stack.\n         */\n        public override void ReadStructEnd()\n        {\n            // consume the last field we Read off the wire.\n            lastFieldId_ = lastField_.Pop();\n        }\n\n        /**\n         * Read a field header off the wire.\n         */\n        public override TField ReadFieldBegin()\n        {\n            byte type = (byte)ReadByte();\n\n            // if it's a stop, then we can return immediately, as the struct is over.\n            if (type == Types.STOP)\n            {\n                return TSTOP;\n            }\n\n            short fieldId;\n\n            // mask off the 4 MSB of the type header. it could contain a field id delta.\n            short modifier = (short)((type & 0xf0) >> 4);\n            if (modifier == 0)\n            {\n                // not a delta. look ahead for the zigzag varint field id.\n                fieldId = ReadI16();\n            }\n            else\n            {\n                // has a delta. add the delta to the last Read field id.\n                fieldId = (short)(lastFieldId_ + modifier);\n            }\n\n            TField field = new TField(\"\", getTType((byte)(type & 0x0f)), fieldId);\n\n            // if this happens to be a boolean field, the value is encoded in the type\n            if (isBoolType(type))\n            {\n                // save the boolean value in a special instance variable.\n                boolValue_ = (byte)(type & 0x0f) == Types.BOOLEAN_TRUE ? true : false;\n            }\n\n            // push the new field onto the field stack so we can keep the deltas going.\n            lastFieldId_ = field.ID;\n            return field;\n        }\n\n        /**\n         * Read a map header off the wire. If the size is zero, skip Reading the key\n         * and value type. This means that 0-length maps will yield TMaps without the\n         * \"correct\" types.\n         */\n        public override TMap ReadMapBegin()\n        {\n            int size = (int)ReadVarint32();\n            byte keyAndValueType = size == 0 ? (byte)0 : (byte)ReadByte();\n            return new TMap(getTType((byte)(keyAndValueType >> 4)), getTType((byte)(keyAndValueType & 0xf)), size);\n        }\n\n        /**\n         * Read a list header off the wire. If the list size is 0-14, the size will\n         * be packed into the element type header. If it's a longer list, the 4 MSB\n         * of the element type header will be 0xF, and a varint will follow with the\n         * true size.\n         */\n        public override TList ReadListBegin()\n        {\n            byte size_and_type = (byte)ReadByte();\n            int size = (size_and_type >> 4) & 0x0f;\n            if (size == 15)\n            {\n                size = (int)ReadVarint32();\n            }\n            TType type = getTType(size_and_type);\n            return new TList(type, size);\n        }\n\n        /**\n         * Read a set header off the wire. If the set size is 0-14, the size will\n         * be packed into the element type header. If it's a longer set, the 4 MSB\n         * of the element type header will be 0xF, and a varint will follow with the\n         * true size.\n         */\n        public override TSet ReadSetBegin()\n        {\n            return new TSet(ReadListBegin());\n        }\n\n        /**\n         * Read a boolean off the wire. If this is a boolean field, the value should\n         * already have been Read during ReadFieldBegin, so we'll just consume the\n         * pre-stored value. Otherwise, Read a byte.\n         */\n        public override Boolean ReadBool()\n        {\n            if (boolValue_ != null)\n            {\n                bool result = boolValue_.Value;\n                boolValue_ = null;\n                return result;\n            }\n            return ReadByte() == Types.BOOLEAN_TRUE;\n        }\n\n        byte[] byteRawBuf = new byte[1];\n        /**\n         * Read a single byte off the wire. Nothing interesting here.\n         */\n        public override sbyte ReadByte()\n        {\n            trans.ReadAll(byteRawBuf, 0, 1);\n            return (sbyte)byteRawBuf[0];\n        }\n\n        /**\n         * Read an i16 from the wire as a zigzag varint.\n         */\n        public override short ReadI16()\n        {\n            return (short)zigzagToInt(ReadVarint32());\n        }\n\n        /**\n         * Read an i32 from the wire as a zigzag varint.\n         */\n        public override int ReadI32()\n        {\n            return zigzagToInt(ReadVarint32());\n        }\n\n        /**\n         * Read an i64 from the wire as a zigzag varint.\n         */\n        public override long ReadI64()\n        {\n            return zigzagToLong(ReadVarint64());\n        }\n\n        /**\n         * No magic here - just Read a double off the wire.\n         */\n        public override double ReadDouble()\n        {\n            byte[] longBits = new byte[8];\n            trans.ReadAll(longBits, 0, 8);\n            return BitConverter.Int64BitsToDouble(bytesToLong(longBits));\n        }\n\n        /**\n         * Reads a byte[] (via ReadBinary), and then UTF-8 decodes it.\n         */\n        public override String ReadString()\n        {\n            int length = (int)ReadVarint32();\n\n            if (length == 0)\n            {\n                return \"\";\n            }\n\n            return Encoding.UTF8.GetString(ReadBinary(length));\n        }\n\n        /**\n         * Read a byte[] from the wire.\n         */\n        public override byte[] ReadBinary()\n        {\n            int length = (int)ReadVarint32();\n            if (length == 0) return new byte[0];\n\n            byte[] buf = new byte[length];\n            trans.ReadAll(buf, 0, length);\n            return buf;\n        }\n\n        /**\n         * Read a byte[] of a known length from the wire.\n         */\n        private byte[] ReadBinary(int length)\n        {\n            if (length == 0) return new byte[0];\n\n            byte[] buf = new byte[length];\n            trans.ReadAll(buf, 0, length);\n            return buf;\n        }\n\n        //\n        // These methods are here for the struct to call, but don't have any wire\n        // encoding.\n        //\n        public override void ReadMessageEnd() { }\n        public override void ReadFieldEnd() { }\n        public override void ReadMapEnd() { }\n        public override void ReadListEnd() { }\n        public override void ReadSetEnd() { }\n\n        //\n        // Internal Reading methods\n        //\n\n        /**\n         * Read an i32 from the wire as a varint. The MSB of each byte is set\n         * if there is another byte to follow. This can Read up to 5 bytes.\n         */\n        private uint ReadVarint32()\n        {\n            uint result = 0;\n            int shift = 0;\n            while (true)\n            {\n                byte b = (byte)ReadByte();\n                result |= (uint)(b & 0x7f) << shift;\n                if ((b & 0x80) != 0x80) break;\n                shift += 7;\n            }\n            return result;\n        }\n\n        /**\n         * Read an i64 from the wire as a proper varint. The MSB of each byte is set\n         * if there is another byte to follow. This can Read up to 10 bytes.\n         */\n        private ulong ReadVarint64()\n        {\n            int shift = 0;\n            ulong result = 0;\n            while (true)\n            {\n                byte b = (byte)ReadByte();\n                result |= (ulong)(b & 0x7f) << shift;\n                if ((b & 0x80) != 0x80) break;\n                shift += 7;\n            }\n\n            return result;\n        }\n\n        #endregion\n\n        //\n        // encoding helpers\n        //\n\n        /**\n         * Convert from zigzag int to int.\n         */\n        private int zigzagToInt(uint n)\n        {\n            return (int)(n >> 1) ^ (-(int)(n & 1));\n        }\n\n        /**\n         * Convert from zigzag long to long.\n         */\n        private long zigzagToLong(ulong n)\n        {\n            return (long)(n >> 1) ^ (-(long)(n & 1));\n        }\n\n        /**\n         * Note that it's important that the mask bytes are long literals,\n         * otherwise they'll default to ints, and when you shift an int left 56 bits,\n         * you just get a messed up int.\n         */\n        private long bytesToLong(byte[] bytes)\n        {\n            return\n              ((bytes[7] & 0xffL) << 56) |\n              ((bytes[6] & 0xffL) << 48) |\n              ((bytes[5] & 0xffL) << 40) |\n              ((bytes[4] & 0xffL) << 32) |\n              ((bytes[3] & 0xffL) << 24) |\n              ((bytes[2] & 0xffL) << 16) |\n              ((bytes[1] & 0xffL) << 8) |\n              ((bytes[0] & 0xffL));\n        }\n\n        //\n        // type testing and converting\n        //\n\n        private Boolean isBoolType(byte b)\n        {\n            int lowerNibble = b & 0x0f;\n            return lowerNibble == Types.BOOLEAN_TRUE || lowerNibble == Types.BOOLEAN_FALSE;\n        }\n\n        /**\n         * Given a TCompactProtocol.Types constant, convert it to its corresponding\n         * TType value.\n         */\n        private TType getTType(byte type)\n        {\n            switch ((byte)(type & 0x0f))\n            {\n                case Types.STOP:\n                    return TType.Stop;\n                case Types.BOOLEAN_FALSE:\n                case Types.BOOLEAN_TRUE:\n                    return TType.Bool;\n                case Types.BYTE:\n                    return TType.Byte;\n                case Types.I16:\n                    return TType.I16;\n                case Types.I32:\n                    return TType.I32;\n                case Types.I64:\n                    return TType.I64;\n                case Types.DOUBLE:\n                    return TType.Double;\n                case Types.BINARY:\n                    return TType.String;\n                case Types.LIST:\n                    return TType.List;\n                case Types.SET:\n                    return TType.Set;\n                case Types.MAP:\n                    return TType.Map;\n                case Types.STRUCT:\n                    return TType.Struct;\n                default:\n                    throw new TProtocolException(\"don't know what type: \" + (byte)(type & 0x0f));\n            }\n        }\n\n        /**\n         * Given a TType value, find the appropriate TCompactProtocol.Types constant.\n         */\n        private byte getCompactType(TType ttype)\n        {\n            return ttypeToCompactType[(int)ttype];\n        }\n    }\n}\n", "idx": 1, "id": 14271, "msg": "Why are we doing that change?", "proj": "apache-thrift", "lang": "c"}
{"patch": "@@ -95,6 +95,15 @@ class EasyAdminExtension extends AbstractTypeExtension\n     {\n         return LegacyFormHelper::getType('form');\n     }\n+\n+    /**\n+     * {@inheritdoc}\n+     */\n+    public static function getExtendedTypes()\n+    {\n+        // needed to avoid a deprecation when using Symfony 4.2\n+        return [LegacyFormHelper::getType('form')];\n+    }\n }\n \n class_alias('EasyCorp\\Bundle\\EasyAdminBundle\\Form\\Extension\\EasyAdminExtension', 'JavierEguiluz\\Bundle\\EasyAdminBundle\\Form\\Extension\\EasyAdminExtension', false);", "y": 1, "oldf": "<?php\n\n/*\n * This file is part of the EasyAdminBundle.\n *\n * (c) Javier Eguiluz <javier.eguiluz@gmail.com>\n *\n * For the full copyright and license information, please view the LICENSE\n * file that was distributed with this source code.\n */\n\nnamespace EasyCorp\\Bundle\\EasyAdminBundle\\Form\\Extension;\n\nuse EasyCorp\\Bundle\\EasyAdminBundle\\Form\\Util\\LegacyFormHelper;\nuse Symfony\\Component\\Form\\AbstractTypeExtension;\nuse Symfony\\Component\\Form\\FormInterface;\nuse Symfony\\Component\\Form\\FormView;\nuse Symfony\\Component\\HttpFoundation\\Request;\nuse Symfony\\Component\\HttpFoundation\\RequestStack;\n\n/**\n * Extension that injects EasyAdmin related information in the view used to\n * render the form.\n *\n * @author Maxime Steinhausser <maxime.steinhausser@gmail.com>\n */\nclass EasyAdminExtension extends AbstractTypeExtension\n{\n    /** @var Request|null */\n    private $request;\n\n    /** @var RequestStack|null */\n    private $requestStack;\n\n    /**\n     * @param RequestStack|null $requestStack\n     */\n    public function __construct(RequestStack $requestStack = null)\n    {\n        $this->requestStack = $requestStack;\n    }\n\n    /**\n     * {@inheritdoc}\n     */\n    public function finishView(FormView $view, FormInterface $form, array $options)\n    {\n        if (null !== $this->requestStack) {\n            $this->request = $this->requestStack->getCurrentRequest();\n        }\n\n        if (null === $this->request) {\n            return;\n        }\n\n        if ($this->request->attributes->has('easyadmin')) {\n            $easyadmin = $this->request->attributes->get('easyadmin');\n            $entity = $easyadmin['entity'];\n            $action = $easyadmin['view'];\n            $fields = isset($entity[$action]['fields']) ? $entity[$action]['fields'] : array();\n            $view->vars['easyadmin'] = array(\n                'entity' => $entity,\n                'view' => $action,\n                'item' => $easyadmin['item'],\n                'field' => null,\n                'form_group' => $form->getConfig()->getAttribute('easyadmin_form_group'),\n                'form_tab' => $form->getConfig()->getAttribute('easyadmin_form_tab'),\n            );\n\n            /*\n             * Checks if current form view is direct child on the topmost form\n             * (ie. this form view`s field exists in easyadmin configuration)\n             */\n            if (null !== $view->parent && null === $view->parent->parent) {\n                $view->vars['easyadmin']['field'] = isset($fields[$view->vars['name']]) ? $fields[$view->vars['name']] : null;\n            }\n        }\n    }\n\n    /**\n     * BC for SF < 2.4.\n     * To be replaced by the usage of the request stack when 2.3 support is dropped.\n     *\n     * @param Request|null $request\n     */\n    public function setRequest(Request $request = null)\n    {\n        $this->request = $request;\n    }\n\n    /**\n     * {@inheritdoc}\n     */\n    public function getExtendedType()\n    {\n        return LegacyFormHelper::getType('form');\n    }\n}\n\nclass_alias('EasyCorp\\Bundle\\EasyAdminBundle\\Form\\Extension\\EasyAdminExtension', 'JavierEguiluz\\Bundle\\EasyAdminBundle\\Form\\Extension\\EasyAdminExtension', false);\n", "idx": 1, "id": 11653, "msg": "looks like this should be `return array(LegacyFormHelper::getType('form'));`", "proj": "EasyCorp-EasyAdminBundle", "lang": "php"}
{"patch": "@@ -88,6 +88,11 @@ def convert_019_100(data):\n \n def convert_100_200(data):\n     data[\"version\"] = (2, 0, 0)\n+    data[\"client_conn\"][\"address\"] = data[\"client_conn\"][\"address\"][\"address\"]\n+    data[\"server_conn\"][\"address\"] = data[\"server_conn\"][\"address\"][\"address\"]\n+    data[\"server_conn\"][\"source_address\"] = data[\"server_conn\"][\"source_address\"][\"address\"]\n+    if data[\"server_conn\"][\"ip_address\"]:\n+        data[\"server_conn\"][\"ip_address\"] = data[\"server_conn\"][\"ip_address\"][\"address\"]\n     return data\n \n ", "y": 1, "oldf": "\"\"\"\nThis module handles the import of mitmproxy flows generated by old versions.\n\"\"\"\n\nfrom typing import Any\n\nfrom mitmproxy import version\nfrom mitmproxy.utils import strutils\n\n\ndef convert_011_012(data):\n    data[b\"version\"] = (0, 12)\n    return data\n\n\ndef convert_012_013(data):\n    data[b\"version\"] = (0, 13)\n    return data\n\n\ndef convert_013_014(data):\n    data[b\"request\"][b\"first_line_format\"] = data[b\"request\"].pop(b\"form_in\")\n    data[b\"request\"][b\"http_version\"] = b\"HTTP/\" + \".\".join(\n        str(x) for x in data[b\"request\"].pop(b\"httpversion\")).encode()\n    data[b\"response\"][b\"http_version\"] = b\"HTTP/\" + \".\".join(\n        str(x) for x in data[b\"response\"].pop(b\"httpversion\")).encode()\n    data[b\"response\"][b\"status_code\"] = data[b\"response\"].pop(b\"code\")\n    data[b\"response\"][b\"body\"] = data[b\"response\"].pop(b\"content\")\n    data[b\"server_conn\"].pop(b\"state\")\n    data[b\"server_conn\"][b\"via\"] = None\n    data[b\"version\"] = (0, 14)\n    return data\n\n\ndef convert_014_015(data):\n    data[b\"version\"] = (0, 15)\n    return data\n\n\ndef convert_015_016(data):\n    for m in (b\"request\", b\"response\"):\n        if b\"body\" in data[m]:\n            data[m][b\"content\"] = data[m].pop(b\"body\")\n    if b\"msg\" in data[b\"response\"]:\n        data[b\"response\"][b\"reason\"] = data[b\"response\"].pop(b\"msg\")\n    data[b\"request\"].pop(b\"form_out\", None)\n    data[b\"version\"] = (0, 16)\n    return data\n\n\ndef convert_016_017(data):\n    data[b\"server_conn\"][b\"peer_address\"] = None\n    data[b\"version\"] = (0, 17)\n    return data\n\n\ndef convert_017_018(data):\n    # convert_unicode needs to be called for every dual release and the first py3-only release\n    data = convert_unicode(data)\n\n    data[\"server_conn\"][\"ip_address\"] = data[\"server_conn\"].pop(\"peer_address\")\n    data[\"marked\"] = False\n    data[\"version\"] = (0, 18)\n    return data\n\n\ndef convert_018_019(data):\n    # convert_unicode needs to be called for every dual release and the first py3-only release\n    data = convert_unicode(data)\n\n    data[\"request\"].pop(\"stickyauth\", None)\n    data[\"request\"].pop(\"stickycookie\", None)\n    data[\"client_conn\"][\"sni\"] = None\n    data[\"client_conn\"][\"alpn_proto_negotiated\"] = None\n    data[\"client_conn\"][\"cipher_name\"] = None\n    data[\"client_conn\"][\"tls_version\"] = None\n    data[\"server_conn\"][\"alpn_proto_negotiated\"] = None\n    data[\"mode\"] = \"regular\"\n    data[\"metadata\"] = dict()\n    data[\"version\"] = (0, 19)\n    return data\n\n\ndef convert_019_100(data):\n    data[\"version\"] = (1, 0, 0)\n    return data\n\n\ndef convert_100_200(data):\n    data[\"version\"] = (2, 0, 0)\n    return data\n\n\ndef convert_200_300(data):\n    data[\"version\"] = (3, 0, 0)\n    data[\"client_conn\"][\"mitmcert\"] = None\n    return data\n\n\ndef _convert_dict_keys(o: Any) -> Any:\n    if isinstance(o, dict):\n        return {strutils.always_str(k): _convert_dict_keys(v) for k, v in o.items()}\n    else:\n        return o\n\n\ndef _convert_dict_vals(o: dict, values_to_convert: dict) -> dict:\n    for k, v in values_to_convert.items():\n        if not o or k not in o:\n            continue\n        if v is True:\n            o[k] = strutils.always_str(o[k])\n        else:\n            _convert_dict_vals(o[k], v)\n    return o\n\n\ndef convert_unicode(data: dict) -> dict:\n    \"\"\"\n    This method converts between Python 3 and Python 2 dumpfiles.\n    \"\"\"\n    data = _convert_dict_keys(data)\n    data = _convert_dict_vals(\n        data, {\n            \"type\": True,\n            \"id\": True,\n            \"request\": {\n                \"first_line_format\": True\n            },\n            \"error\": {\n                \"msg\": True\n            }\n        }\n    )\n    return data\n\n\nconverters = {\n    (0, 11): convert_011_012,\n    (0, 12): convert_012_013,\n    (0, 13): convert_013_014,\n    (0, 14): convert_014_015,\n    (0, 15): convert_015_016,\n    (0, 16): convert_016_017,\n    (0, 17): convert_017_018,\n    (0, 18): convert_018_019,\n    (0, 19): convert_019_100,\n    (1, 0): convert_100_200,\n    (2, 0): convert_200_300,\n}\n\n\ndef migrate_flow(flow_data):\n    while True:\n        flow_version = tuple(flow_data.get(b\"version\", flow_data.get(\"version\")))\n        if flow_version[:2] == version.IVERSION[:2]:\n            break\n        elif flow_version[:2] in converters:\n            flow_data = converters[flow_version[:2]](flow_data)\n        else:\n            v = \".\".join(str(i) for i in flow_version)\n            raise ValueError(\n                \"{} cannot read files serialized with version {}.\".format(version.MITMPROXY, v)\n            )\n    return flow_data\n", "idx": 1, "id": 12888, "msg": "This is incomplete I think (at least source_address and ip_address are missing)", "proj": "mitmproxy-mitmproxy", "lang": "py"}
{"patch": "@@ -57,8 +57,10 @@ module Selenium\n     #\n     # @return [Driver]\n     #\n-    # @see Selenium::WebDriver::Remote::Bridge\n+    # @see Selenium::WebDriver::Remote::OSSBridge\n+    # @see Selenium::WebDriver::Remote::W3CBridge\n     # @see Selenium::WebDriver::Firefox::Bridge\n+    # @see Selenium::WebDriver::Firefox::W3CBridge\n     # @see Selenium::WebDriver::IE::Bridge\n     # @see Selenium::WebDriver::Edge::Bridge\n     # @see Selenium::WebDriver::Chrome::Bridge", "y": 1, "oldf": "# encoding: utf-8\n#\n# Licensed to the Software Freedom Conservancy (SFC) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The SFC licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\nrequire 'childprocess'\nrequire 'tmpdir'\nrequire 'fileutils'\nrequire 'date'\nrequire 'json'\n\nrequire 'selenium/webdriver/common'\nrequire 'selenium/webdriver/atoms'\n\nmodule Selenium\n  module WebDriver\n    Point     = Struct.new(:x, :y)\n    Dimension = Struct.new(:width, :height)\n    Location  = Struct.new(:latitude, :longitude, :altitude)\n\n    autoload :Chrome,    'selenium/webdriver/chrome'\n    autoload :Edge,      'selenium/webdriver/edge'\n    autoload :Firefox,   'selenium/webdriver/firefox'\n    autoload :IE,        'selenium/webdriver/ie'\n    autoload :PhantomJS, 'selenium/webdriver/phantomjs'\n    autoload :Remote,    'selenium/webdriver/remote'\n    autoload :Safari,    'selenium/webdriver/safari'\n    autoload :Support,   'selenium/webdriver/support'\n\n    # @api private\n\n    def self.root\n      @root ||= File.expand_path('../..', __FILE__)\n    end\n\n    #\n    # Create a new Driver instance with the correct bridge for the given browser\n    #\n    # @param browser [:ie, :internet_explorer, :edge, :remote, :chrome, :firefox, :ff, :phantomjs, :safari]\n    #   the driver type to use\n    # @param *rest\n    #   arguments passed to Bridge.new\n    #\n    # @return [Driver]\n    #\n    # @see Selenium::WebDriver::Remote::Bridge\n    # @see Selenium::WebDriver::Firefox::Bridge\n    # @see Selenium::WebDriver::IE::Bridge\n    # @see Selenium::WebDriver::Edge::Bridge\n    # @see Selenium::WebDriver::Chrome::Bridge\n    # @see Selenium::WebDriver::PhantomJS::Bridge\n    # @see Selenium::WebDriver::Safari::Bridge\n    #\n    # @example\n    #\n    #   WebDriver.for :firefox, :profile => \"some-profile\"\n    #   WebDriver.for :firefox, :profile => Profile.new\n    #   WebDriver.for :remote,  :url => \"http://localhost:4444/wd/hub\", :desired_capabilities => caps\n    #\n    # One special argument is not passed on to the bridges, :listener.\n    # You can pass a listener for this option to get notified of WebDriver events.\n    # The passed object must respond to #call or implement the methods from AbstractEventListener.\n    #\n    # @see Selenium::WebDriver::Support::AbstractEventListener\n    #\n\n    def self.for(*args)\n      WebDriver::Driver.for(*args)\n    end\n  end # WebDriver\nend # Selenium\n", "idx": 1, "id": 14227, "msg": "Maybe call it `WireBridge`?", "proj": "SeleniumHQ-selenium", "lang": "py"}
{"patch": "@@ -490,7 +490,10 @@ EOS\n         #   end\n         def its(attribute, &block)\n           RSpec.deprecate(\"Use of rspec-core's `its` method\", :replacement => 'the rspec-its gem')\n-          describe(attribute) do\n+          description = attribute\n+          description = description.to_s if Symbol === description\n+\n+          describe(description) do\n             if Array === attribute\n               let(:__its_subject) { subject[*attribute] }\n             else", "y": 1, "oldf": "module RSpec\n  module Core\n    module MemoizedHelpers\n      # @note `subject` was contributed by Joe Ferris to support the one-liner\n      #   syntax embraced by shoulda matchers:\n      #\n      #       describe Widget do\n      #         it { is_expected.to validate_presence_of(:name) }\n      #         # or\n      #         it { should validate_presence_of(:name) }\n      #       end\n      #\n      #   While the examples below demonstrate how to use `subject`\n      #   explicitly in examples, we recommend that you define a method with\n      #   an intention revealing name instead.\n      #\n      # @example\n      #\n      #   # explicit declaration of subject\n      #   describe Person do\n      #     subject { Person.new(:birthdate => 19.years.ago) }\n      #     it \"should be eligible to vote\" do\n      #       subject.should be_eligible_to_vote\n      #       # ^ ^ explicit reference to subject not recommended\n      #     end\n      #   end\n      #\n      #   # implicit subject => { Person.new }\n      #   describe Person do\n      #     it \"should be eligible to vote\" do\n      #       subject.should be_eligible_to_vote\n      #       # ^ ^ explicit reference to subject not recommended\n      #     end\n      #   end\n      #\n      #   # one-liner syntax - expectation is set on the subject\n      #   describe Person do\n      #     it { is_expected.to be_eligible_to_vote }\n      #     # or\n      #     it { should be_eligible_to_vote }\n      #   end\n      #\n      # @note Because `subject` is designed to create state that is reset between\n      #   each example, and `before(:all)` is designed to setup state that is\n      #   shared across _all_ examples in an example group, `subject` is _not_\n      #   intended to be used in a `before(:all)` hook. RSpec 2.13.1 prints\n      #   a warning when you reference a `subject` from `before(:all)` and we plan\n      #   to have it raise an error in RSpec 3.\n      #\n      # @see #should\n      def subject\n        __memoized.fetch(:subject) do\n          __memoized[:subject] = begin\n            described = described_class || self.class.description\n            Class === described ? described.new : described\n          end\n        end\n      end\n\n      # When `should` is called with no explicit receiver, the call is\n      # delegated to the object returned by `subject`. Combined with an\n      # implicit subject this supports very concise expressions.\n      #\n      # @example\n      #\n      #   describe Person do\n      #     it { should be_eligible_to_vote }\n      #   end\n      #\n      # @see #subject\n      # @see #is_expected\n      #\n      # @note This only works if you are using rspec-expectations.\n      # @note If you are using RSpec's newer expect-based syntax you may\n      #       want to use `is_expected.to` instead of `should`.\n      def should(matcher=nil, message=nil)\n        RSpec::Expectations::PositiveExpectationHandler.handle_matcher(subject, matcher, message)\n      end\n\n      # Just like `should`, `should_not` delegates to the subject (implicit or\n      # explicit) of the example group.\n      #\n      # @example\n      #\n      #   describe Person do\n      #     it { should_not be_eligible_to_vote }\n      #   end\n      #\n      # @see #subject\n      # @see #is_expected\n      #\n      # @note This only works if you are using rspec-expectations.\n      # @note If you are using RSpec's newer expect-based syntax you may\n      #       want to use `is_expected.to_not` instead of `should_not`.\n      def should_not(matcher=nil, message=nil)\n        RSpec::Expectations::NegativeExpectationHandler.handle_matcher(subject, matcher, message)\n      end\n\n      # Wraps the `subject` in `expect` to make it the target of an expectation.\n      # Designed to read nicely for one-liners.\n      #\n      # @example\n      #\n      #   describe [1, 2, 3] do\n      #     it { is_expected.to be_an Array }\n      #     it { is_expected.not_to include 4 }\n      #   end\n      #\n      # @see #subject\n      # @see #should\n      # @see #should_not\n      #\n      # @note This only works if you are using rspec-expectations.\n      def is_expected\n        expect(subject)\n      end\n\n      private\n\n      # @private\n      def __memoized\n        @__memoized ||= {}\n      end\n\n      # Used internally to customize the behavior of the\n      # memoized hash when used in a `before(:all)` hook.\n      #\n      # @private\n      class AllHookMemoizedHash\n        def self.isolate_for_all_hook(example_group_instance)\n          hash_type = self\n\n          example_group_instance.instance_eval do\n            @__memoized = hash_type.new(example_group_instance)\n\n            begin\n              yield\n            ensure\n              @__memoized.preserve_accessed_lets\n              @__memoized = nil\n            end\n          end\n        end\n\n        def initialize(example_group_instance)\n          @example_group_instance = example_group_instance\n          @hash = {}\n        end\n\n        def fetch(key, &block)\n          description = if key == :subject\n            \"subject\"\n          else\n            \"let declaration `#{key}`\"\n          end\n\n          ::RSpec.warn_deprecation <<-EOS\nDEPRECATION: #{description} accessed in #{article} #{hook_expression} hook at:\n  #{CallerFilter.first_non_rspec_line}\n\n`let` and `subject` declarations are not intended to be called\nin #{article} #{hook_expression} hook, as they exist to define state that\nis reset between each example, while #{hook_expression} exists to\n#{hook_intention}.\n\nThis is deprecated behavior that will not be supported in RSpec 3.\nEOS\n          @hash.fetch(key, &block)\n        end\n\n        def []=(key, value)\n          @hash[key] = value\n        end\n\n        def preserve_accessed_lets\n          hash = @hash\n\n          @example_group_instance.class.class_eval do\n            hash.each do |key, value|\n              undef_method(key) if method_defined?(key)\n              define_method(key) { value }\n            end\n          end\n        end\n\n        class Before < self\n          def hook_expression\n            \"`before(:all)`\"\n          end\n\n          def article\n            \"a\"\n          end\n\n          def hook_intention\n            \"define state that is shared across examples in an example group\"\n          end\n        end\n\n        class After < self\n          def hook_expression\n            \"`after(:all)`\"\n          end\n\n          def article\n            \"an\"\n          end\n\n          def hook_intention\n            \"cleanup state that is shared across examples in an example group\"\n          end\n        end\n      end\n\n      def self.included(mod)\n        mod.extend(ClassMethods)\n      end\n\n      module ClassMethods\n        # Generates a method whose return value is memoized after the first\n        # call. Useful for reducing duplication between examples that assign\n        # values to the same local variable.\n        #\n        # @note `let` _can_ enhance readability when used sparingly (1,2, or\n        #   maybe 3 declarations) in any given example group, but that can\n        #   quickly degrade with overuse. YMMV.\n        #\n        # @note `let` uses an `||=` conditional that has the potential to\n        #   behave in surprising ways in examples that spawn separate threads,\n        #   though we have yet to see this in practice. You've been warned.\n        #\n        # @note Because `let` is designed to create state that is reset between\n        #   each example, and `before(:all)` is designed to setup state that is\n        #   shared across _all_ examples in an example group, `let` is _not_\n        #   intended to be used in a `before(:all)` hook. RSpec 2.13.1 prints\n        #   a warning when you reference a `let` from `before(:all)` and we plan\n        #   to have it raise an error in RSpec 3.\n        #\n        # @example\n        #\n        #   describe Thing do\n        #     let(:thing) { Thing.new }\n        #\n        #     it \"does something\" do\n        #       # first invocation, executes block, memoizes and returns result\n        #       thing.do_something\n        #\n        #       # second invocation, returns the memoized value\n        #       thing.should be_something\n        #     end\n        #   end\n        def let(name, &block)\n          # We have to pass the block directly to `define_method` to\n          # allow it to use method constructs like `super` and `return`.\n          raise \"#let or #subject called without a block\" if block.nil?\n          MemoizedHelpers.module_for(self).send(:define_method, name, &block)\n\n          # Apply the memoization. The method has been defined in an ancestor\n          # module so we can use `super` here to get the value.\n          if block.arity == 1\n            define_method(name) { __memoized.fetch(name) { |k| __memoized[k] = super(RSpec.current_example, &nil) } }\n          else\n            define_method(name) { __memoized.fetch(name) { |k| __memoized[k] = super(&nil) } }\n          end\n        end\n\n        # Just like `let`, except the block is invoked by an implicit `before`\n        # hook. This serves a dual purpose of setting up state and providing a\n        # memoized reference to that state.\n        #\n        # @example\n        #\n        #   class Thing\n        #     def self.count\n        #       @count ||= 0\n        #     end\n        #\n        #     def self.count=(val)\n        #       @count += val\n        #     end\n        #\n        #     def self.reset_count\n        #       @count = 0\n        #     end\n        #\n        #     def initialize\n        #       self.class.count += 1\n        #     end\n        #   end\n        #\n        #   describe Thing do\n        #     after(:each) { Thing.reset_count }\n        #\n        #     context \"using let\" do\n        #       let(:thing) { Thing.new }\n        #\n        #       it \"is not invoked implicitly\" do\n        #         Thing.count.should eq(0)\n        #       end\n        #\n        #       it \"can be invoked explicitly\" do\n        #         thing\n        #         Thing.count.should eq(1)\n        #       end\n        #     end\n        #\n        #     context \"using let!\" do\n        #       let!(:thing) { Thing.new }\n        #\n        #       it \"is invoked implicitly\" do\n        #         Thing.count.should eq(1)\n        #       end\n        #\n        #       it \"returns memoized version on first invocation\" do\n        #         thing\n        #         Thing.count.should eq(1)\n        #       end\n        #     end\n        #   end\n        def let!(name, &block)\n          let(name, &block)\n          before { __send__(name) }\n        end\n\n        # Declares a `subject` for an example group which can then be wrapped\n        # with `expect` using `is_expected` to make it the target of an expectation\n        # in a concise, one-line example.\n        #\n        # Given a `name`, defines a method with that name which returns the\n        # `subject`. This lets you declare the subject once and access it\n        # implicitly in one-liners and explicitly using an intention revealing\n        # name.\n        #\n        # @param [String,Symbol] name used to define an accessor with an\n        #   intention revealing name\n        # @param block defines the value to be returned by `subject` in examples\n        #\n        # @example\n        #\n        #   describe CheckingAccount, \"with $50\" do\n        #     subject { CheckingAccount.new(Money.new(50, :USD)) }\n        #     it { is_expected.to have_a_balance_of(Money.new(50, :USD)) }\n        #     it { is_expected.not_to be_overdrawn }\n        #   end\n        #\n        #   describe CheckingAccount, \"with a non-zero starting balance\" do\n        #     subject(:account) { CheckingAccount.new(Money.new(50, :USD)) }\n        #     it { is_expected.not_to be_overdrawn }\n        #     it \"has a balance equal to the starting balance\" do\n        #       account.balance.should eq(Money.new(50, :USD))\n        #     end\n        #   end\n        #\n        # @see MemoizedHelpers#should\n        def subject(name=nil, &block)\n          if name\n            let(name, &block)\n            alias_method :subject, name\n\n            self::NamedSubjectPreventSuper.send(:define_method, name) do\n              raise NotImplementedError, \"`super` in named subjects is not supported\"\n            end\n          else\n            let(:subject, &block)\n          end\n        end\n\n        # Just like `subject`, except the block is invoked by an implicit `before`\n        # hook. This serves a dual purpose of setting up state and providing a\n        # memoized reference to that state.\n        #\n        # @example\n        #\n        #   class Thing\n        #     def self.count\n        #       @count ||= 0\n        #     end\n        #\n        #     def self.count=(val)\n        #       @count += val\n        #     end\n        #\n        #     def self.reset_count\n        #       @count = 0\n        #     end\n        #\n        #     def initialize\n        #       self.class.count += 1\n        #     end\n        #   end\n        #\n        #   describe Thing do\n        #     after(:each) { Thing.reset_count }\n        #\n        #     context \"using subject\" do\n        #       subject { Thing.new }\n        #\n        #       it \"is not invoked implicitly\" do\n        #         Thing.count.should eq(0)\n        #       end\n        #\n        #       it \"can be invoked explicitly\" do\n        #         subject\n        #         Thing.count.should eq(1)\n        #       end\n        #     end\n        #\n        #     context \"using subject!\" do\n        #       subject!(:thing) { Thing.new }\n        #\n        #       it \"is invoked implicitly\" do\n        #         Thing.count.should eq(1)\n        #       end\n        #\n        #       it \"returns memoized version on first invocation\" do\n        #         subject\n        #         Thing.count.should eq(1)\n        #       end\n        #     end\n        #   end\n        def subject!(name=nil, &block)\n          subject(name, &block)\n          before { subject }\n        end\n\n        # Creates a nested example group named by the submitted `attribute`,\n        # and then generates an example using the submitted block.\n        #\n        # @example\n        #\n        #   # This ...\n        #   describe Array do\n        #     its(:size) { should eq(0) }\n        #   end\n        #\n        #   # ... generates the same runtime structure as this:\n        #   describe Array do\n        #     describe \"size\" do\n        #       it \"should eq(0)\" do\n        #         subject.size.should eq(0)\n        #       end\n        #     end\n        #   end\n        #\n        # The attribute can be a `Symbol` or a `String`. Given a `String`\n        # with dots, the result is as though you concatenated that `String`\n        # onto the subject in an expression.\n        #\n        # @example\n        #\n        #   describe Person do\n        #     subject do\n        #       Person.new.tap do |person|\n        #         person.phone_numbers << \"555-1212\"\n        #       end\n        #     end\n        #\n        #     its(\"phone_numbers.first\") { should eq(\"555-1212\") }\n        #   end\n        #\n        # When the subject is a `Hash`, you can refer to the Hash keys by\n        # specifying a `Symbol` or `String` in an array.\n        #\n        # @example\n        #\n        #   describe \"a configuration Hash\" do\n        #     subject do\n        #       { :max_users => 3,\n        #         'admin' => :all_permissions }\n        #     end\n        #\n        #     its([:max_users]) { should eq(3) }\n        #     its(['admin']) { should eq(:all_permissions) }\n        #\n        #     # You can still access to its regular methods this way:\n        #     its(:keys) { should include(:max_users) }\n        #     its(:count) { should eq(2) }\n        #   end\n        #\n        # Note that this method does not modify `subject` in any way, so if you\n        # refer to `subject` in `let` or `before` blocks, you're still\n        # referring to the outer subject.\n        #\n        # @example\n        #\n        #   describe Person do\n        #     subject { Person.new }\n        #     before { subject.age = 25 }\n        #     its(:age) { should eq(25) }\n        #   end\n        def its(attribute, &block)\n          RSpec.deprecate(\"Use of rspec-core's `its` method\", :replacement => 'the rspec-its gem')\n          describe(attribute) do\n            if Array === attribute\n              let(:__its_subject) { subject[*attribute] }\n            else\n              let(:__its_subject) do\n                attribute_chain = attribute.to_s.split('.')\n                attribute_chain.inject(subject) do |inner_subject, attr|\n                  inner_subject.send(attr)\n                end\n              end\n            end\n\n            def should(matcher=nil, message=nil)\n              RSpec::Expectations::PositiveExpectationHandler.handle_matcher(__its_subject, matcher, message)\n            end\n\n            def should_not(matcher=nil, message=nil)\n              RSpec::Expectations::NegativeExpectationHandler.handle_matcher(__its_subject, matcher, message)\n            end\n\n            example(&block)\n          end\n        end\n      end\n\n      # @api private\n      #\n      # Gets the LetDefinitions module. The module is mixed into\n      # the example group and is used to hold all let definitions.\n      # This is done so that the block passed to `let` can be\n      # forwarded directly on to `define_method`, so that all method\n      # constructs (including `super` and `return`) can be used in\n      # a `let` block.\n      #\n      # The memoization is provided by a method definition on the\n      # example group that supers to the LetDefinitions definition\n      # in order to get the value to memoize.\n      def self.module_for(example_group)\n        get_constant_or_yield(example_group, :LetDefinitions) do\n          mod = Module.new do\n            include Module.new {\n              example_group.const_set(:NamedSubjectPreventSuper, self)\n            }\n          end\n\n          example_group.const_set(:LetDefinitions, mod)\n          mod\n        end\n      end\n\n      # @api private\n      def self.define_helpers_on(example_group)\n        example_group.send(:include, module_for(example_group))\n      end\n\n      if Module.method(:const_defined?).arity == 1 # for 1.8\n        # @api private\n        #\n        # Gets the named constant or yields.\n        # On 1.8, const_defined? / const_get do not take into\n        # account the inheritance hierarchy.\n        def self.get_constant_or_yield(example_group, name)\n          if example_group.const_defined?(name)\n            example_group.const_get(name)\n          else\n            yield\n          end\n        end\n      else\n        # @api private\n        #\n        # Gets the named constant or yields.\n        # On 1.9, const_defined? / const_get take into account the\n        # the inheritance by default, and accept an argument to\n        # disable this behavior. It's important that we don't\n        # consider inheritance here; each example group level that\n        # uses a `let` should get its own `LetDefinitions` module.\n        def self.get_constant_or_yield(example_group, name)\n          if example_group.const_defined?(name, (check_ancestors = false))\n            example_group.const_get(name, check_ancestors)\n          else\n            yield\n          end\n        end\n      end\n    end\n  end\nend\n", "idx": 1, "id": 12189, "msg": "Is it only Symbols we're worried about converting? Is it not safe to just call `to_s` anyway?", "proj": "rspec-rspec-core", "lang": "rb"}
{"patch": "@@ -2,10 +2,8 @@\n #  Copyright (C) 2006 Greg Landrum\n #  This file is part of RDKit and covered by $RDBASE/license.txt\n #\n-\n-\n-import argparse\n import sys\n+import argparse\n \n from rdkit import Chem\n from rdkit import Geometry", "y": 1, "oldf": "#\n#  Copyright (C) 2006 Greg Landrum\n#  This file is part of RDKit and covered by $RDBASE/license.txt\n#\n\n\nimport argparse\nimport sys\n\nfrom rdkit import Chem\nfrom rdkit import Geometry\nfrom rdkit.Chem import rdDepictor\n\n\ndef AlignDepict(mol, core, corePattern=None, acceptFailure=False):\n  \"\"\"\n  Arguments:\n    - mol:          the molecule to be aligned, this will come back\n                    with a single conformer.\n    - core:         a molecule with the core atoms to align to;\n                    this should have a depiction.\n    - corePattern:  (optional) an optional molecule to be used to\n                    generate the atom mapping between the molecule\n                    and the core.\n  \"\"\"\n  if core and corePattern:\n    if not core.GetNumAtoms(onlyExplicit=True) == corePattern.GetNumAtoms(onlyExplicit=True):\n      raise ValueError(\n        'When a pattern is provided, it must have the same number of atoms as the core')\n    coreMatch = core.GetSubstructMatch(corePattern)\n    if not coreMatch:\n      raise ValueError(\"Core does not map to itself\")\n  else:\n    coreMatch = list(range(core.GetNumAtoms(onlyExplicit=True)))\n  if corePattern:\n    match = mol.GetSubstructMatch(corePattern)\n  else:\n    match = mol.GetSubstructMatch(core)\n\n  if not match:\n    if not acceptFailure:\n      raise ValueError('Substructure match with core not found.')\n    else:\n      coordMap = {}\n  else:\n    conf = core.GetConformer()\n    coordMap = {}\n    for i, idx in enumerate(match):\n      pt3 = conf.GetAtomPosition(coreMatch[i])\n      pt2 = Geometry.Point2D(pt3.x, pt3.y)\n      coordMap[idx] = pt2\n  rdDepictor.Compute2DCoords(mol, clearConfs=True, coordMap=coordMap, canonOrient=False)\n\n\ndef initParser():\n  \"\"\" Initialize the parser \"\"\"\n  parser = argparse.ArgumentParser(description='Create aligned depiction')\n  parser.add_argument('--pattern', '-p', metavar='SMARTS', default=None, dest='patt')\n  parser.add_argument('--smiles', default=False, action='store_true', dest='useSmiles',\n                      help='Set if core and input are SMILES strings')\n  parser.add_argument('-o', dest='outF', type=argparse.FileType('w'), default=sys.stdout,\n                      metavar='OUTFILE',\n                      help='Specify a file to take the output. If missing, uses stdout.')\n  parser.add_argument('core', metavar='core')\n  parser.add_argument('mol', metavar='molecule', help='')\n  return parser\n\n\ndef processArgs(args):\n  patt = args.patt\n  if patt:\n    patt = Chem.MolFromSmarts(patt)\n\n  if args.useSmiles:\n    core = Chem.MolFromSmiles(args.core)\n    mol = Chem.MolFromSmiles(args.mol)\n    rdDepictor.Compute2DCoords(core)\n  else:\n    core = Chem.MolFromMolFile(args.core)\n    mol = Chem.MolFromMolFile(args.mol)\n\n  AlignDepict(mol, core, patt)\n  print(Chem.MolToMolBlock(mol), file=args.outF)\n\n\ndef main():\n  \"\"\" Main application \"\"\"\n  parser = initParser()\n  args = parser.parse_args()\n  processArgs(args)\n\n\nif __name__ == '__main__':\n  main()\n", "idx": 1, "id": 23954, "msg": "Are you using an automated tool for sorting the imports?", "proj": "rdkit-rdkit", "lang": "cpp"}
{"patch": "@@ -303,7 +303,8 @@ public class HadoopTables implements Tables, Configurable {\n       }\n \n       Map<String, String> properties = propertiesBuilder.build();\n-      TableMetadata metadata = tableMetadata(schema, spec, sortOrder, properties, location);\n+\n+      TableMetadata metadata = TableMetadata.newTableMetadata(schema, spec, sortOrder, location, properties);\n       ops.commit(null, metadata);\n       return new BaseTable(ops, location);\n     }", "y": 1, "oldf": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\n\npackage org.apache.iceberg.hadoop;\n\nimport java.io.IOException;\nimport java.io.UncheckedIOException;\nimport java.util.Map;\nimport org.apache.hadoop.conf.Configurable;\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.iceberg.BaseTable;\nimport org.apache.iceberg.CatalogUtil;\nimport org.apache.iceberg.MetadataTableType;\nimport org.apache.iceberg.MetadataTableUtils;\nimport org.apache.iceberg.PartitionSpec;\nimport org.apache.iceberg.Schema;\nimport org.apache.iceberg.SortOrder;\nimport org.apache.iceberg.StaticTableOperations;\nimport org.apache.iceberg.Table;\nimport org.apache.iceberg.TableMetadata;\nimport org.apache.iceberg.TableOperations;\nimport org.apache.iceberg.Tables;\nimport org.apache.iceberg.Transaction;\nimport org.apache.iceberg.Transactions;\nimport org.apache.iceberg.catalog.Catalog;\nimport org.apache.iceberg.exceptions.AlreadyExistsException;\nimport org.apache.iceberg.exceptions.NoSuchTableException;\nimport org.apache.iceberg.relocated.com.google.common.annotations.VisibleForTesting;\nimport org.apache.iceberg.relocated.com.google.common.base.Preconditions;\nimport org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\nimport org.apache.iceberg.util.Pair;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\n/**\n * Implementation of Iceberg tables that uses the Hadoop FileSystem\n * to store metadata and manifests.\n */\npublic class HadoopTables implements Tables, Configurable {\n  private static final Logger LOG = LoggerFactory.getLogger(HadoopTables.class);\n  private static final String METADATA_JSON = \"metadata.json\";\n  private Configuration conf;\n\n  public HadoopTables() {\n    this(new Configuration());\n  }\n\n  public HadoopTables(Configuration conf) {\n    this.conf = conf;\n  }\n\n  /**\n   * Loads the table location from a FileSystem path location.\n   *\n   * @param location a path URI (e.g. hdfs:///warehouse/my_table/)\n   * @return table implementation\n   */\n  @Override\n  public Table load(String location) {\n    Table result;\n    Pair<String, MetadataTableType> parsedMetadataType = parseMetadataType(location);\n\n    if (parsedMetadataType != null) {\n      // Load a metadata table\n      result = loadMetadataTable(parsedMetadataType.first(), location, parsedMetadataType.second());\n    } else {\n      // Load a normal table\n      TableOperations ops = newTableOps(location);\n      if (ops.current() != null) {\n        result = new BaseTable(ops, location);\n      } else {\n        throw new NoSuchTableException(\"Table does not exist at location: %s\", location);\n      }\n    }\n\n    LOG.info(\"Table location loaded: {}\", result.location());\n    return result;\n  }\n\n  /**\n   * Try to resolve a metadata table, which we encode as URI fragments\n   * e.g. hdfs:///warehouse/my_table#snapshots\n   * @param location Path to parse\n   * @return A base table name and MetadataTableType if a type is found, null if not\n   */\n  private Pair<String, MetadataTableType> parseMetadataType(String location) {\n    int hashIndex = location.lastIndexOf('#');\n    if (hashIndex != -1 && !location.endsWith(\"#\")) {\n      String baseTable = location.substring(0, hashIndex);\n      String metaTable = location.substring(hashIndex + 1);\n      MetadataTableType type = MetadataTableType.from(metaTable);\n      return (type == null) ? null : Pair.of(baseTable, type);\n    } else {\n      return null;\n    }\n  }\n\n  private Table loadMetadataTable(String location, String metadataTableName, MetadataTableType type) {\n    TableOperations ops = newTableOps(location);\n    if (ops.current() == null) {\n      throw new NoSuchTableException(\"Table does not exist at location: %s\", location);\n    }\n\n    return MetadataTableUtils.createMetadataTableInstance(ops, location, metadataTableName, type);\n  }\n\n  /**\n   * Create a table using the FileSystem implementation resolve from\n   * location.\n   *\n   * @param schema iceberg schema used to create the table\n   * @param spec partitioning spec, if null the table will be unpartitioned\n   * @param properties a string map of table properties, initialized to empty if null\n   * @param location a path URI (e.g. hdfs:///warehouse/my_table)\n   * @return newly created table implementation\n   */\n  @Override\n  public Table create(Schema schema, PartitionSpec spec, SortOrder order,\n                      Map<String, String> properties, String location) {\n    return buildTable(location, schema).withPartitionSpec(spec)\n        .withSortOrder(order)\n        .withProperties(properties)\n        .create();\n  }\n\n  /**\n   * Drop a table and delete all data and metadata files.\n   *\n   * @param location a path URI (e.g. hdfs:///warehouse/my_table)\n   * @return true if the table was dropped, false if it did not exist\n   */\n  public boolean dropTable(String location) {\n    return dropTable(location, true);\n  }\n\n  /**\n   * Drop a table; optionally delete data and metadata files.\n   * <p>\n   * If purge is set to true the implementation should delete all data and metadata files.\n   *\n   * @param location a path URI (e.g. hdfs:///warehouse/my_table)\n   * @param purge if true, delete all data and metadata files in the table\n   * @return true if the table was dropped, false if it did not exist\n   */\n  public boolean dropTable(String location, boolean purge) {\n    TableOperations ops = newTableOps(location);\n    TableMetadata lastMetadata = null;\n    if (ops.current() != null) {\n      if (purge) {\n        lastMetadata = ops.current();\n      }\n    } else {\n      return false;\n    }\n\n    try {\n      if (purge && lastMetadata != null) {\n        // Since the data files and the metadata files may store in different locations,\n        // so it has to call dropTableData to force delete the data file.\n        CatalogUtil.dropTableData(ops.io(), lastMetadata);\n      }\n      Path tablePath = new Path(location);\n      Util.getFs(tablePath, conf).delete(tablePath, true /* recursive */);\n      return true;\n    } catch (IOException e) {\n      throw new UncheckedIOException(\"Failed to delete file: \" + location, e);\n    }\n  }\n\n  @VisibleForTesting\n  TableOperations newTableOps(String location) {\n    if (location.contains(METADATA_JSON)) {\n      return new StaticTableOperations(location, new HadoopFileIO(conf));\n    } else {\n      return new HadoopTableOperations(new Path(location), new HadoopFileIO(conf), conf);\n    }\n  }\n\n  private TableMetadata tableMetadata(Schema schema, PartitionSpec spec, SortOrder order,\n                                      Map<String, String> properties, String location) {\n    Preconditions.checkNotNull(schema, \"A table schema is required\");\n\n    Map<String, String> tableProps = properties == null ? ImmutableMap.of() : properties;\n    PartitionSpec partitionSpec = spec == null ? PartitionSpec.unpartitioned() : spec;\n    SortOrder sortOrder = order == null ? SortOrder.unsorted() : order;\n    return TableMetadata.newTableMetadata(schema, partitionSpec, sortOrder, location, tableProps);\n  }\n\n  /**\n   * Start a transaction to create a table.\n   *\n   * @param location a location for the table\n   * @param schema a schema\n   * @param spec a partition spec\n   * @param properties a string map of table properties\n   * @return a {@link Transaction} to create the table\n   * @throws AlreadyExistsException if the table already exists\n   */\n  public Transaction newCreateTableTransaction(\n      String location,\n      Schema schema,\n      PartitionSpec spec,\n      Map<String, String> properties) {\n    return buildTable(location, schema).withPartitionSpec(spec).withProperties(properties).createTransaction();\n  }\n\n  /**\n   * Start a transaction to replace a table.\n   *\n   * @param location a location for the table\n   * @param schema a schema\n   * @param spec a partition spec\n   * @param properties a string map of table properties\n   * @param orCreate whether to create the table if not exists\n   * @return a {@link Transaction} to replace the table\n   * @throws NoSuchTableException if the table doesn't exist and orCreate is false\n   */\n  public Transaction newReplaceTableTransaction(\n      String location,\n      Schema schema,\n      PartitionSpec spec,\n      Map<String, String> properties,\n      boolean orCreate) {\n\n\n    Catalog.TableBuilder builder = buildTable(location, schema).withPartitionSpec(spec).withProperties(properties);\n    return orCreate ? builder.createOrReplaceTransaction() : builder.replaceTransaction();\n  }\n\n  public Catalog.TableBuilder buildTable(String location, Schema schema) {\n    return new HadoopTableBuilder(location, schema);\n  }\n\n  private class HadoopTableBuilder implements Catalog.TableBuilder {\n    private final String location;\n    private final Schema schema;\n    private final ImmutableMap.Builder<String, String> propertiesBuilder = ImmutableMap.builder();\n    private PartitionSpec spec = PartitionSpec.unpartitioned();\n    private SortOrder sortOrder = SortOrder.unsorted();\n\n\n    HadoopTableBuilder(String location, Schema schema) {\n      this.location = location;\n      this.schema = schema;\n    }\n\n    @Override\n    public Catalog.TableBuilder withPartitionSpec(PartitionSpec newSpec) {\n      this.spec = newSpec != null ? newSpec : PartitionSpec.unpartitioned();\n      return this;\n    }\n\n    @Override\n    public Catalog.TableBuilder withSortOrder(SortOrder newSortOrder) {\n      this.sortOrder = newSortOrder != null ? newSortOrder : SortOrder.unsorted();\n      return this;\n    }\n\n    @Override\n    public Catalog.TableBuilder withLocation(String newLocation) {\n      Preconditions.checkArgument(newLocation == null || location.equals(newLocation),\n          String.format(\"Table location %s differs from the table location (%s) from the PathIdentifier\",\n              newLocation, location));\n      return this;\n    }\n\n    @Override\n    public Catalog.TableBuilder withProperties(Map<String, String> properties) {\n      if (properties != null) {\n        propertiesBuilder.putAll(properties);\n      }\n      return this;\n    }\n\n    @Override\n    public Catalog.TableBuilder withProperty(String key, String value) {\n      propertiesBuilder.put(key, value);\n      return this;\n    }\n\n    @Override\n    public Table create() {\n      TableOperations ops = newTableOps(location);\n      if (ops.current() != null) {\n        throw new AlreadyExistsException(\"Table already exists at location: %s\", location);\n      }\n\n      Map<String, String> properties = propertiesBuilder.build();\n      TableMetadata metadata = tableMetadata(schema, spec, sortOrder, properties, location);\n      ops.commit(null, metadata);\n      return new BaseTable(ops, location);\n    }\n\n    @Override\n    public Transaction createTransaction() {\n      TableOperations ops = newTableOps(location);\n      if (ops.current() != null) {\n        throw new AlreadyExistsException(\"Table already exists: %s\", location);\n      }\n\n      Map<String, String> properties = propertiesBuilder.build();\n      TableMetadata metadata = tableMetadata(schema, spec, null, properties, location);\n      return Transactions.createTableTransaction(location, ops, metadata);\n    }\n\n    @Override\n    public Transaction replaceTransaction() {\n      return newReplaceTableTransaction(false);\n    }\n\n    @Override\n    public Transaction createOrReplaceTransaction() {\n      return newReplaceTableTransaction(true);\n    }\n\n    private Transaction newReplaceTableTransaction(boolean orCreate) {\n      TableOperations ops = newTableOps(location);\n      if (!orCreate && ops.current() == null) {\n        throw new NoSuchTableException(\"No such table: %s\", location);\n      }\n\n      Map<String, String> properties = propertiesBuilder.build();\n      TableMetadata metadata;\n      if (ops.current() != null) {\n        metadata = ops.current().buildReplacement(schema, spec, sortOrder, location, properties);\n      } else {\n        metadata = tableMetadata(schema, spec, sortOrder, properties, location);\n      }\n\n      if (orCreate) {\n        return Transactions.createOrReplaceTableTransaction(location, ops, metadata);\n      } else {\n        return Transactions.replaceTableTransaction(location, ops, metadata);\n      }\n    }\n  }\n\n  @Override\n  public void setConf(Configuration conf) {\n    this.conf = conf;\n  }\n\n  @Override\n  public Configuration getConf() {\n    return conf;\n  }\n}\n", "idx": 1, "id": 31360, "msg": "Is it necessary to change this file? Doesn't `tableMetadata` call `newTableMetadata`?", "proj": "apache-iceberg", "lang": "java"}
{"patch": "@@ -142,6 +142,11 @@ public class DocsStreamer implements Iterator<SolrDocument> {\n     return docIterator.hasNext();\n   }\n \n+  // called at the end of the stream\n+  public void finish(){\n+    if (transformer != null) transformer.finish();\n+  }\n+\n   public SolrDocument next() {\n     int id = docIterator.nextDoc();\n     idx++;", "y": 1, "oldf": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.apache.solr.response;\n\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.HashSet;\nimport java.util.Iterator;\nimport java.util.List;\nimport java.util.Set;\n\nimport org.apache.lucene.document.Document;\nimport org.apache.lucene.index.IndexableField;\nimport org.apache.lucene.util.BytesRef;\nimport org.apache.solr.common.SolrDocument;\nimport org.apache.solr.common.SolrException;\nimport org.apache.solr.response.transform.DocTransformer;\nimport org.apache.solr.schema.BinaryField;\nimport org.apache.solr.schema.BoolField;\nimport org.apache.solr.schema.DatePointField;\nimport org.apache.solr.schema.DoublePointField;\nimport org.apache.solr.schema.FieldType;\nimport org.apache.solr.schema.FloatPointField;\nimport org.apache.solr.schema.IndexSchema;\nimport org.apache.solr.schema.IntPointField;\nimport org.apache.solr.schema.LongPointField;\nimport org.apache.solr.schema.SchemaField;\nimport org.apache.solr.schema.StrField;\nimport org.apache.solr.schema.TextField;\nimport org.apache.solr.schema.TrieDateField;\nimport org.apache.solr.schema.TrieDoubleField;\nimport org.apache.solr.schema.TrieField;\nimport org.apache.solr.schema.TrieFloatField;\nimport org.apache.solr.schema.TrieIntField;\nimport org.apache.solr.schema.TrieLongField;\nimport org.apache.solr.search.DocIterator;\nimport org.apache.solr.search.DocList;\nimport org.apache.solr.search.ReturnFields;\nimport org.apache.solr.search.SolrDocumentFetcher;\nimport org.apache.solr.search.SolrReturnFields;\n\n/**\n * This streams SolrDocuments from a DocList and applies transformer\n */\npublic class DocsStreamer implements Iterator<SolrDocument> {\n  public static final Set<Class> KNOWN_TYPES = new HashSet<>();\n\n  private final org.apache.solr.response.ResultContext rctx;\n  private final SolrDocumentFetcher docFetcher; // a collaborator of SolrIndexSearcher\n  private final DocList docs;\n\n  private final DocTransformer transformer;\n  private final DocIterator docIterator;\n\n  private final Set<String> fnames; // returnFields.getLuceneFieldNames(). Maybe null. Not empty.\n  private final boolean onlyPseudoFields;\n  private final Set<String> dvFieldsToReturn; // maybe null. Not empty.\n\n  private int idx = -1;\n\n  public DocsStreamer(ResultContext rctx) {\n    this.rctx = rctx;\n    this.docs = rctx.getDocList();\n    transformer = rctx.getReturnFields().getTransformer();\n    docIterator = this.docs.iterator();\n    fnames = rctx.getReturnFields().getLuceneFieldNames();\n    //TODO move onlyPseudoFields calc to ReturnFields\n    onlyPseudoFields = (fnames == null && !rctx.getReturnFields().wantsAllFields() && !rctx.getReturnFields().hasPatternMatching())\n        || (fnames != null && fnames.size() == 1 && SolrReturnFields.SCORE.equals(fnames.iterator().next()));\n\n    // add non-stored DV fields that may have been requested\n    docFetcher = rctx.getSearcher().getDocFetcher();\n    dvFieldsToReturn = calcDocValueFieldsForReturn(docFetcher, rctx.getReturnFields());\n\n    if (transformer != null) transformer.setContext(rctx);\n  }\n\n  // TODO move to ReturnFields ?  Or SolrDocumentFetcher ?\n  public static Set<String> calcDocValueFieldsForReturn(SolrDocumentFetcher docFetcher, ReturnFields returnFields) {\n    Set<String> result = null;\n    if (returnFields.wantsAllFields()) {\n      // check whether there are no additional fields\n      Set<String> fieldNames = returnFields.getLuceneFieldNames(true);\n      if (fieldNames == null) {\n        result = docFetcher.getNonStoredDVs(true);\n      } else {\n        result = new HashSet<>(docFetcher.getNonStoredDVs(true)); // copy\n        // add all requested fields that may be useDocValuesAsStored=false\n        for (String fl : fieldNames) {\n          if (docFetcher.getNonStoredDVs(false).contains(fl)) {\n            result.add(fl);\n          }\n        }\n      }\n    } else {\n      if (returnFields.hasPatternMatching()) {\n        for (String s : docFetcher.getNonStoredDVs(true)) {\n          if (returnFields.wantsField(s)) {\n            if (null == result) {\n              result = new HashSet<>();\n            }\n            result.add(s);\n          }\n        }\n      } else {\n        Set<String> fnames = returnFields.getLuceneFieldNames();\n        if (fnames == null) {\n          return null;\n        }\n        result = new HashSet<>(fnames); // copy\n        // here we get all non-stored dv fields because even if a user has set\n        // useDocValuesAsStored=false in schema, he may have requested a field\n        // explicitly using the fl parameter\n        result.retainAll(docFetcher.getNonStoredDVs(false));\n      }\n    }\n    if (result != null && result.isEmpty()) {\n      return null;\n    }\n    return result;\n  }\n\n  public int currentIndex() {\n    return idx;\n  }\n\n  public boolean hasNext() {\n    return docIterator.hasNext();\n  }\n\n  public SolrDocument next() {\n    int id = docIterator.nextDoc();\n    idx++;\n    SolrDocument sdoc = null;\n\n    if (onlyPseudoFields) {\n      // no need to get stored fields of the document, see SOLR-5968\n      sdoc = new SolrDocument();\n    } else {\n      try {\n        Document doc = docFetcher.doc(id, fnames);\n        sdoc = convertLuceneDocToSolrDoc(doc, rctx.getSearcher().getSchema()); // make sure to use the schema from the searcher and not the request (cross-core)\n\n        // decorate the document with non-stored docValues fields\n        if (dvFieldsToReturn != null) {\n          docFetcher.decorateDocValueFields(sdoc, id, dvFieldsToReturn);\n        }\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error reading document with docId \" + id, e);\n      }\n    }\n\n    if (transformer != null) {\n      boolean doScore = rctx.wantsScores();\n      try {\n        transformer.transform(sdoc, id, doScore ? docIterator.score() : 0);\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error applying transformer\", e);\n      }\n    }\n    return sdoc;\n\n  }\n\n  // TODO move to SolrDocumentFetcher ?  Refactor to also call docFetcher.decorateDocValueFields(...) ?\n  public static SolrDocument convertLuceneDocToSolrDoc(Document doc, final IndexSchema schema) {\n    SolrDocument out = new SolrDocument();\n    for (IndexableField f : doc.getFields()) {\n      // Make sure multivalued fields are represented as lists\n      Object existing = out.get(f.name());\n      if (existing == null) {\n        SchemaField sf = schema.getFieldOrNull(f.name());\n        if (sf != null && sf.multiValued()) {\n          List<Object> vals = new ArrayList<>();\n          vals.add(f);\n          out.setField(f.name(), vals);\n        } else {\n          out.setField(f.name(), f);\n        }\n      } else {\n        out.addField(f.name(), f);\n      }\n    }\n    return out;\n  }\n\n  @Override\n  public void remove() { //do nothing\n  }\n\n  public static Object getValue(SchemaField sf, IndexableField f) {\n    FieldType ft = null;\n    if (sf != null) ft = sf.getType();\n\n    if (ft == null) {  // handle fields not in the schema\n      BytesRef bytesRef = f.binaryValue();\n      if (bytesRef != null) {\n        if (bytesRef.offset == 0 && bytesRef.length == bytesRef.bytes.length) {\n          return bytesRef.bytes;\n        } else {\n          final byte[] bytes = new byte[bytesRef.length];\n          System.arraycopy(bytesRef.bytes, bytesRef.offset, bytes, 0, bytesRef.length);\n          return bytes;\n        }\n      } else return f.stringValue();\n    } else {\n      if (KNOWN_TYPES.contains(ft.getClass())) {\n        return ft.toObject(f);\n      } else {\n        return ft.toExternal(f);\n      }\n    }\n  }\n\n\n  static {\n    KNOWN_TYPES.add(BoolField.class);\n    KNOWN_TYPES.add(StrField.class);\n    KNOWN_TYPES.add(TextField.class);\n    KNOWN_TYPES.add(TrieField.class);\n    KNOWN_TYPES.add(TrieIntField.class);\n    KNOWN_TYPES.add(TrieLongField.class);\n    KNOWN_TYPES.add(TrieFloatField.class);\n    KNOWN_TYPES.add(TrieDoubleField.class);\n    KNOWN_TYPES.add(TrieDateField.class);\n    KNOWN_TYPES.add(BinaryField.class);\n    KNOWN_TYPES.add(IntPointField.class);\n    KNOWN_TYPES.add(LongPointField.class);\n    KNOWN_TYPES.add(DoublePointField.class);\n    KNOWN_TYPES.add(FloatPointField.class);\n    KNOWN_TYPES.add(DatePointField.class);\n    // We do not add UUIDField because UUID object is not a supported type in JavaBinCodec\n    // and if we write UUIDField.toObject, we wouldn't know how to handle it in the client side\n  }\n\n}\n", "idx": 1, "id": 26373, "msg": "can't we leverage Closeable here and get some sugar&warns? Also, line 89 still calls setContext() .. is it right? or I'm missing something?", "proj": "apache-lucene-solr", "lang": "java"}
{"patch": "@@ -293,6 +293,19 @@ func (r *DefaultRuleRenderer) endpointIptablesChain(\n \t\t},\n \t})\n \n+\trules = append(rules, Rule{\n+\t\tMatch: Match().ProtocolNum(ProtoUDP).\n+\t\t\tDestPorts(uint16(r.Config.VXLANPort)).\n+\t\t\tVXLANVNI(uint32(r.Config.VXLANVNI)),\n+\t\tAction:  DropAction{},\n+\t\tComment: \"Drop VXLAN encapped packets originating in pods\",\n+\t})\n+\trules = append(rules, Rule{\n+\t\tMatch:   Match().ProtocolNum(ProtoIPIP),\n+\t\tAction:  DropAction{},\n+\t\tComment: \"Drop IPinIP encapped packets originating in pods\",\n+\t})\n+\n \tif len(policyNames) > 0 {\n \t\t// Clear the \"pass\" mark.  If a policy sets that mark, we'll skip the rest of the policies and\n \t\t// continue processing the profiles, if there are any.", "y": 1, "oldf": "// Copyright (c) 2016-2018 Tigera, Inc. All rights reserved.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage rules\n\nimport (\n\tlog \"github.com/sirupsen/logrus\"\n\n\t\"github.com/projectcalico/felix/hashutils\"\n\t. \"github.com/projectcalico/felix/iptables\"\n\t\"github.com/projectcalico/felix/proto\"\n)\n\nfunc (r *DefaultRuleRenderer) WorkloadEndpointToIptablesChains(\n\tifaceName string,\n\tepMarkMapper EndpointMarkMapper,\n\tadminUp bool,\n\tingressPolicies []string,\n\tegressPolicies []string,\n\tprofileIDs []string,\n) []*Chain {\n\tresult := []*Chain{}\n\tresult = append(result,\n\t\t// Chain for traffic _to_ the endpoint.\n\t\tr.endpointIptablesChain(\n\t\t\tingressPolicies,\n\t\t\tprofileIDs,\n\t\t\tifaceName,\n\t\t\tPolicyInboundPfx,\n\t\t\tProfileInboundPfx,\n\t\t\tWorkloadToEndpointPfx,\n\t\t\t\"\", // No fail-safe chains for workloads.\n\t\t\tchainTypeNormal,\n\t\t\tadminUp,\n\t\t\tr.filterAllowAction, // Workload endpoint chains are only used in the filter table\n\t\t),\n\t\t// Chain for traffic _from_ the endpoint.\n\t\tr.endpointIptablesChain(\n\t\t\tegressPolicies,\n\t\t\tprofileIDs,\n\t\t\tifaceName,\n\t\t\tPolicyOutboundPfx,\n\t\t\tProfileOutboundPfx,\n\t\t\tWorkloadFromEndpointPfx,\n\t\t\t\"\", // No fail-safe chains for workloads.\n\t\t\tchainTypeNormal,\n\t\t\tadminUp,\n\t\t\tr.filterAllowAction, // Workload endpoint chains are only used in the filter table\n\t\t),\n\t)\n\n\tif r.KubeIPVSSupportEnabled {\n\t\t// Chain for setting endpoint mark of an endpoint.\n\t\tresult = append(result,\n\t\t\tr.endpointSetMarkChain(\n\t\t\t\tifaceName,\n\t\t\t\tepMarkMapper,\n\t\t\t\tSetEndPointMarkPfx,\n\t\t\t),\n\t\t)\n\t}\n\n\treturn result\n}\n\nfunc (r *DefaultRuleRenderer) HostEndpointToFilterChains(\n\tifaceName string,\n\tepMarkMapper EndpointMarkMapper,\n\tingressPolicyNames []string,\n\tegressPolicyNames []string,\n\tingressForwardPolicyNames []string,\n\tegressForwardPolicyNames []string,\n\tprofileIDs []string,\n) []*Chain {\n\tlog.WithField(\"ifaceName\", ifaceName).Debug(\"Rendering filter host endpoint chain.\")\n\tresult := []*Chain{}\n\tresult = append(result,\n\t\t// Chain for output traffic _to_ the endpoint.\n\t\tr.endpointIptablesChain(\n\t\t\tegressPolicyNames,\n\t\t\tprofileIDs,\n\t\t\tifaceName,\n\t\t\tPolicyOutboundPfx,\n\t\t\tProfileOutboundPfx,\n\t\t\tHostToEndpointPfx,\n\t\t\tChainFailsafeOut,\n\t\t\tchainTypeNormal,\n\t\t\ttrue, // Host endpoints are always admin up.\n\t\t\tr.filterAllowAction,\n\t\t),\n\t\t// Chain for input traffic _from_ the endpoint.\n\t\tr.endpointIptablesChain(\n\t\t\tingressPolicyNames,\n\t\t\tprofileIDs,\n\t\t\tifaceName,\n\t\t\tPolicyInboundPfx,\n\t\t\tProfileInboundPfx,\n\t\t\tHostFromEndpointPfx,\n\t\t\tChainFailsafeIn,\n\t\t\tchainTypeNormal,\n\t\t\ttrue, // Host endpoints are always admin up.\n\t\t\tr.filterAllowAction,\n\t\t),\n\t\t// Chain for forward traffic _to_ the endpoint.\n\t\tr.endpointIptablesChain(\n\t\t\tegressForwardPolicyNames,\n\t\t\tprofileIDs,\n\t\t\tifaceName,\n\t\t\tPolicyOutboundPfx,\n\t\t\tProfileOutboundPfx,\n\t\t\tHostToEndpointForwardPfx,\n\t\t\t\"\", // No fail-safe chains for forward traffic.\n\t\t\tchainTypeForward,\n\t\t\ttrue, // Host endpoints are always admin up.\n\t\t\tr.filterAllowAction,\n\t\t),\n\t\t// Chain for forward traffic _from_ the endpoint.\n\t\tr.endpointIptablesChain(\n\t\t\tingressForwardPolicyNames,\n\t\t\tprofileIDs,\n\t\t\tifaceName,\n\t\t\tPolicyInboundPfx,\n\t\t\tProfileInboundPfx,\n\t\t\tHostFromEndpointForwardPfx,\n\t\t\t\"\", // No fail-safe chains for forward traffic.\n\t\t\tchainTypeForward,\n\t\t\ttrue, // Host endpoints are always admin up.\n\t\t\tr.filterAllowAction,\n\t\t),\n\t)\n\n\tif r.KubeIPVSSupportEnabled {\n\t\t// Chain for setting endpoint mark of an endpoint.\n\t\tresult = append(result,\n\t\t\tr.endpointSetMarkChain(\n\t\t\t\tifaceName,\n\t\t\t\tepMarkMapper,\n\t\t\t\tSetEndPointMarkPfx,\n\t\t\t),\n\t\t)\n\t}\n\n\treturn result\n}\n\nfunc (r *DefaultRuleRenderer) HostEndpointToRawChains(\n\tifaceName string,\n\tingressPolicyNames []string,\n\tegressPolicyNames []string,\n) []*Chain {\n\tlog.WithField(\"ifaceName\", ifaceName).Debug(\"Rendering raw (untracked) host endpoint chain.\")\n\treturn []*Chain{\n\t\t// Chain for traffic _to_ the endpoint.\n\t\tr.endpointIptablesChain(\n\t\t\tegressPolicyNames,\n\t\t\tnil, // We don't render profiles into the raw table.\n\t\t\tifaceName,\n\t\t\tPolicyOutboundPfx,\n\t\t\tProfileOutboundPfx,\n\t\t\tHostToEndpointPfx,\n\t\t\tChainFailsafeOut,\n\t\t\tchainTypeUntracked,\n\t\t\ttrue, // Host endpoints are always admin up.\n\t\t\tAcceptAction{},\n\t\t),\n\t\t// Chain for traffic _from_ the endpoint.\n\t\tr.endpointIptablesChain(\n\t\t\tingressPolicyNames,\n\t\t\tnil, // We don't render profiles into the raw table.\n\t\t\tifaceName,\n\t\t\tPolicyInboundPfx,\n\t\t\tProfileInboundPfx,\n\t\t\tHostFromEndpointPfx,\n\t\t\tChainFailsafeIn,\n\t\t\tchainTypeUntracked,\n\t\t\ttrue, // Host endpoints are always admin up.\n\t\t\tAcceptAction{},\n\t\t),\n\t}\n}\n\nfunc (r *DefaultRuleRenderer) HostEndpointToMangleChains(\n\tifaceName string,\n\tpreDNATPolicyNames []string,\n) []*Chain {\n\tlog.WithField(\"ifaceName\", ifaceName).Debug(\"Rendering pre-DNAT host endpoint chain.\")\n\treturn []*Chain{\n\t\t// Chain for traffic _from_ the endpoint.  Pre-DNAT policy does not apply to\n\t\t// outgoing traffic through a host endpoint.\n\t\tr.endpointIptablesChain(\n\t\t\tpreDNATPolicyNames,\n\t\t\tnil, // We don't render profiles into the raw table.\n\t\t\tifaceName,\n\t\t\tPolicyInboundPfx,\n\t\t\tProfileInboundPfx,\n\t\t\tHostFromEndpointPfx,\n\t\t\tChainFailsafeIn,\n\t\t\tchainTypePreDNAT,\n\t\t\ttrue, // Host endpoints are always admin up.\n\t\t\tr.mangleAllowAction,\n\t\t),\n\t}\n}\n\ntype endpointChainType int\n\nconst (\n\tchainTypeNormal endpointChainType = iota\n\tchainTypeUntracked\n\tchainTypePreDNAT\n\tchainTypeForward\n)\n\nfunc (r *DefaultRuleRenderer) endpointSetMarkChain(\n\tname string,\n\tepMarkMapper EndpointMarkMapper,\n\tendpointPrefix string,\n) *Chain {\n\trules := []Rule{}\n\tchainName := EndpointChainName(endpointPrefix, name)\n\n\tif endPointMark, err := epMarkMapper.GetEndpointMark(name); err == nil {\n\t\t// Set endpoint mark.\n\t\trules = append(rules, Rule{\n\t\t\tAction: SetMaskedMarkAction{\n\t\t\t\tMark: endPointMark,\n\t\t\t\tMask: epMarkMapper.GetMask()},\n\t\t})\n\t}\n\treturn &Chain{\n\t\tName:  chainName,\n\t\tRules: rules,\n\t}\n}\n\nfunc (r *DefaultRuleRenderer) endpointIptablesChain(\n\tpolicyNames []string,\n\tprofileIds []string,\n\tname string,\n\tpolicyPrefix PolicyChainNamePrefix,\n\tprofilePrefix ProfileChainNamePrefix,\n\tendpointPrefix string,\n\tfailsafeChain string,\n\tchainType endpointChainType,\n\tadminUp bool,\n\tallowAction Action,\n) *Chain {\n\trules := []Rule{}\n\tchainName := EndpointChainName(endpointPrefix, name)\n\n\tif !adminUp {\n\t\t// Endpoint is admin-down, drop all traffic to/from it.\n\t\trules = append(rules, Rule{\n\t\t\tMatch:   Match(),\n\t\t\tAction:  DropAction{},\n\t\t\tComment: \"Endpoint admin disabled\",\n\t\t})\n\t\treturn &Chain{\n\t\t\tName:  chainName,\n\t\t\tRules: rules,\n\t\t}\n\t}\n\n\tif chainType != chainTypeUntracked {\n\t\t// Tracked chain: install conntrack rules, which implement our stateful connections.\n\t\t// This allows return traffic associated with a previously-permitted request.\n\t\trules = r.appendConntrackRules(rules, allowAction)\n\t}\n\n\t// First set up failsafes.\n\tif failsafeChain != \"\" {\n\t\trules = append(rules, Rule{\n\t\t\tAction: JumpAction{Target: failsafeChain},\n\t\t})\n\t}\n\n\t// Start by ensuring that the accept mark bit is clear, policies set that bit to indicate\n\t// that they accepted the packet.\n\trules = append(rules, Rule{\n\t\tAction: ClearMarkAction{\n\t\t\tMark: r.IptablesMarkAccept,\n\t\t},\n\t})\n\n\tif len(policyNames) > 0 {\n\t\t// Clear the \"pass\" mark.  If a policy sets that mark, we'll skip the rest of the policies and\n\t\t// continue processing the profiles, if there are any.\n\t\trules = append(rules, Rule{\n\t\t\tComment: \"Start of policies\",\n\t\t\tAction: ClearMarkAction{\n\t\t\t\tMark: r.IptablesMarkPass,\n\t\t\t},\n\t\t})\n\n\t\t// Then, jump to each policy in turn.\n\t\tfor _, polID := range policyNames {\n\t\t\tpolChainName := PolicyChainName(\n\t\t\t\tpolicyPrefix,\n\t\t\t\t&proto.PolicyID{Name: polID},\n\t\t\t)\n\t\t\t// If a previous policy didn't set the \"pass\" mark, jump to the policy.\n\t\t\trules = append(rules, Rule{\n\t\t\t\tMatch:  Match().MarkClear(r.IptablesMarkPass),\n\t\t\t\tAction: JumpAction{Target: polChainName},\n\t\t\t})\n\t\t\t// If policy marked packet as accepted, it returns, setting the accept\n\t\t\t// mark bit.\n\t\t\tif chainType == chainTypeUntracked {\n\t\t\t\t// For an untracked policy, map allow to \"NOTRACK and ALLOW\".\n\t\t\t\trules = append(rules, Rule{\n\t\t\t\t\tMatch:  Match().MarkSingleBitSet(r.IptablesMarkAccept),\n\t\t\t\t\tAction: NoTrackAction{},\n\t\t\t\t})\n\t\t\t}\n\t\t\t// If accept bit is set, return from this chain.  We don't immediately\n\t\t\t// accept because there may be other policy still to apply.\n\t\t\trules = append(rules, Rule{\n\t\t\t\tMatch:   Match().MarkSingleBitSet(r.IptablesMarkAccept),\n\t\t\t\tAction:  ReturnAction{},\n\t\t\t\tComment: \"Return if policy accepted\",\n\t\t\t})\n\t\t}\n\n\t\tif chainType == chainTypeNormal || chainType == chainTypeForward {\n\t\t\t// When rendering normal and forward rules, if no policy marked the packet as \"pass\", drop the\n\t\t\t// packet.\n\t\t\t//\n\t\t\t// For untracked and pre-DNAT rules, we don't do that because there may be\n\t\t\t// normal rules still to be applied to the packet in the filter table.\n\t\t\trules = append(rules, Rule{\n\t\t\t\tMatch:   Match().MarkClear(r.IptablesMarkPass),\n\t\t\t\tAction:  DropAction{},\n\t\t\t\tComment: \"Drop if no policies passed packet\",\n\t\t\t})\n\t\t}\n\n\t} else if chainType == chainTypeForward {\n\t\t// Forwarded traffic is allowed when there are no policies with\n\t\t// applyOnForward that apply to this endpoint (and in this direction).\n\t\trules = append(rules, Rule{\n\t\t\tAction:  SetMarkAction{Mark: r.IptablesMarkAccept},\n\t\t\tComment: \"Allow forwarded traffic by default\",\n\t\t})\n\t\trules = append(rules, Rule{\n\t\t\tAction:  ReturnAction{},\n\t\t\tComment: \"Return for accepted forward traffic\",\n\t\t})\n\t}\n\n\tif chainType == chainTypeNormal {\n\t\t// Then, jump to each profile in turn.\n\t\tfor _, profileID := range profileIds {\n\t\t\tprofChainName := ProfileChainName(profilePrefix, &proto.ProfileID{Name: profileID})\n\t\t\trules = append(rules,\n\t\t\t\tRule{Action: JumpAction{Target: profChainName}},\n\t\t\t\t// If policy marked packet as accepted, it returns, setting the\n\t\t\t\t// accept mark bit.  If that is set, return from this chain.\n\t\t\t\tRule{\n\t\t\t\t\tMatch:   Match().MarkSingleBitSet(r.IptablesMarkAccept),\n\t\t\t\t\tAction:  ReturnAction{},\n\t\t\t\t\tComment: \"Return if profile accepted\",\n\t\t\t\t})\n\t\t}\n\n\t\t// When rendering normal rules, if no profile marked the packet as accepted, drop\n\t\t// the packet.\n\t\t//\n\t\t// For untracked rules, we don't do that because there may be tracked rules\n\t\t// still to be applied to the packet in the filter table.\n\t\trules = append(rules, Rule{\n\t\t\tMatch:   Match(),\n\t\t\tAction:  DropAction{},\n\t\t\tComment: \"Drop if no profiles matched\",\n\t\t})\n\t}\n\n\treturn &Chain{\n\t\tName:  chainName,\n\t\tRules: rules,\n\t}\n}\n\nfunc (r *DefaultRuleRenderer) appendConntrackRules(rules []Rule, allowAction Action) []Rule {\n\t// Allow return packets for established connections.\n\tif allowAction != (AcceptAction{}) {\n\t\t// If we've been asked to return instead of accept the packet immediately,\n\t\t// make sure we flag the packet as allowed.\n\t\trules = append(rules,\n\t\t\tRule{\n\t\t\t\tMatch:  Match().ConntrackState(\"RELATED,ESTABLISHED\"),\n\t\t\t\tAction: SetMarkAction{Mark: r.IptablesMarkAccept},\n\t\t\t},\n\t\t)\n\t}\n\trules = append(rules,\n\t\tRule{\n\t\t\tMatch:  Match().ConntrackState(\"RELATED,ESTABLISHED\"),\n\t\t\tAction: allowAction,\n\t\t},\n\t)\n\tif !r.Config.DisableConntrackInvalid {\n\t\t// Drop packets that aren't either a valid handshake or part of an established\n\t\t// connection.\n\t\trules = append(rules, Rule{\n\t\t\tMatch:  Match().ConntrackState(\"INVALID\"),\n\t\t\tAction: DropAction{},\n\t\t})\n\t}\n\treturn rules\n}\n\nfunc EndpointChainName(prefix string, ifaceName string) string {\n\treturn hashutils.GetLengthLimitedID(\n\t\tprefix,\n\t\tifaceName,\n\t\tMaxChainNameLength,\n\t)\n}\n", "idx": 1, "id": 16987, "msg": "I believe these rules will be enforced both (1) on egress from a local workload, and (2) on ingress **to** a local workload. Right? I understand that we definitely want (1), but do we really want to enforce (2) as well?", "proj": "projectcalico-felix", "lang": "go"}
{"patch": "@@ -64,6 +64,7 @@ public class Spark3BinPackStrategy extends BinPackStrategy {\n       Dataset<Row> scanDF = cloneSession.read().format(\"iceberg\")\n           .option(SparkReadOptions.FILE_SCAN_TASK_SET_ID, groupID)\n           .option(SparkReadOptions.SPLIT_SIZE, splitSize(inputFileSize(filesToRewrite)))\n+          .option(SparkReadOptions.LOOKBACK, 10)\n           .option(SparkReadOptions.FILE_OPEN_COST, \"0\")\n           .load(table.name());\n ", "y": 1, "oldf": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\n\npackage org.apache.iceberg.spark.actions;\n\nimport java.util.List;\nimport java.util.Set;\nimport java.util.UUID;\nimport org.apache.iceberg.DataFile;\nimport org.apache.iceberg.FileScanTask;\nimport org.apache.iceberg.Table;\nimport org.apache.iceberg.actions.BinPackStrategy;\nimport org.apache.iceberg.spark.FileRewriteCoordinator;\nimport org.apache.iceberg.spark.FileScanTaskSetManager;\nimport org.apache.iceberg.spark.SparkReadOptions;\nimport org.apache.iceberg.spark.SparkWriteOptions;\nimport org.apache.spark.sql.Dataset;\nimport org.apache.spark.sql.Row;\nimport org.apache.spark.sql.SparkSession;\nimport org.apache.spark.sql.internal.SQLConf;\n\npublic class Spark3BinPackStrategy extends BinPackStrategy {\n  private final Table table;\n  private final SparkSession spark;\n  private final FileScanTaskSetManager manager = FileScanTaskSetManager.get();\n  private final FileRewriteCoordinator rewriteCoordinator = FileRewriteCoordinator.get();\n\n  public Spark3BinPackStrategy(Table table, SparkSession spark) {\n    this.table = table;\n    this.spark = spark;\n  }\n\n  @Override\n  public Table table() {\n    return table;\n  }\n\n  @Override\n  public Set<DataFile> rewriteFiles(List<FileScanTask> filesToRewrite) {\n    String groupID = UUID.randomUUID().toString();\n    try {\n      manager.stageTasks(table, groupID, filesToRewrite);\n\n      // Disable Adaptive Query Execution as this may change the output partitioning of our write\n      SparkSession cloneSession = spark.cloneSession();\n      cloneSession.conf().set(SQLConf.ADAPTIVE_EXECUTION_ENABLED().key(), false);\n\n      Dataset<Row> scanDF = cloneSession.read().format(\"iceberg\")\n          .option(SparkReadOptions.FILE_SCAN_TASK_SET_ID, groupID)\n          .option(SparkReadOptions.SPLIT_SIZE, splitSize(inputFileSize(filesToRewrite)))\n          .option(SparkReadOptions.FILE_OPEN_COST, \"0\")\n          .load(table.name());\n\n      // write the packed data into new files where each split becomes a new file\n      scanDF.write()\n          .format(\"iceberg\")\n          .option(SparkWriteOptions.REWRITTEN_FILE_SCAN_TASK_SET_ID, groupID)\n          .option(SparkWriteOptions.TARGET_FILE_SIZE_BYTES, writeMaxFileSize())\n          .option(SparkWriteOptions.DISTRIBUTION_MODE, \"none\")\n          .mode(\"append\")\n          .save(table.name());\n\n      return rewriteCoordinator.fetchNewDataFiles(table, groupID);\n    } finally {\n      manager.removeTasks(table, groupID);\n      rewriteCoordinator.clearRewrite(table, groupID);\n    }\n  }\n}\n", "idx": 1, "id": 43717, "msg": "is this needed? 10 is already the default", "proj": "apache-iceberg", "lang": "java"}
{"patch": "@@ -1081,10 +1081,15 @@ public class JDBCConnection implements ObjectStoreConnection {\n             throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n         }\n         int curTagCount = getDomainTagsCount(domainId);\n-        int remainingTagsToInsert = domainTagsLimit - curTagCount;\n+        int newTagCount = calculateTagCount(tags);\n+        if (curTagCount + newTagCount > domainTagsLimit) {\n+            throw ZMSUtils.quotaLimitError(\"domain tag quota exceeded - limit: \"\n+                + domainTagsLimit + \", current tags count: \" + curTagCount + \", new tags count: \" + newTagCount, caller);\n+        }\n+\n         boolean res = true;\n         for (Map.Entry<String, StringList> e : tags.entrySet()) {\n-            for (int i = 0; i < e.getValue().getList().size() && remainingTagsToInsert-- > 0; i++) {\n+            for (int i = 0; i < e.getValue().getList().size(); i++) {\n                 String tagValue = e.getValue().getList().get(i);\n                 try (PreparedStatement ps = con.prepareStatement(SQL_INSERT_DOMAIN_TAG)) {\n                     ps.setInt(1, domainId);", "y": 1, "oldf": "/*\n * Copyright 2016 Yahoo Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.yahoo.athenz.zms.store.impl.jdbc;\n\nimport java.sql.*;\nimport java.util.*;\n\nimport com.yahoo.athenz.auth.AuthorityConsts;\nimport com.yahoo.athenz.common.server.util.ResourceUtils;\nimport com.yahoo.athenz.zms.*;\nimport org.eclipse.jetty.util.StringUtil;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport com.yahoo.athenz.zms.store.AthenzDomain;\nimport com.yahoo.athenz.zms.store.ObjectStoreConnection;\nimport com.yahoo.athenz.zms.utils.ZMSUtils;\nimport com.yahoo.athenz.zms.ZMSConsts;\nimport com.yahoo.rdl.JSON;\nimport com.yahoo.rdl.Struct;\nimport com.yahoo.rdl.Timestamp;\nimport com.yahoo.rdl.UUID;\n\npublic class JDBCConnection implements ObjectStoreConnection {\n\n    private static final Logger LOG = LoggerFactory.getLogger(JDBCConnection.class);\n\n    private static final int MYSQL_ER_OPTION_PREVENTS_STATEMENT = 1290;\n    private static final int MYSQL_ER_OPTION_DUPLICATE_ENTRY = 1062;\n\n    private static final String SQL_DELETE_DOMAIN = \"DELETE FROM domain WHERE name=?;\";\n    private static final String SQL_GET_DOMAIN = \"SELECT * FROM domain WHERE name=?;\";\n    private static final String SQL_GET_DOMAIN_ID = \"SELECT domain_id FROM domain WHERE name=?;\";\n    private static final String SQL_GET_ACTIVE_DOMAIN_ID = \"SELECT domain_id FROM domain WHERE name=? AND enabled=true;\";\n    private static final String SQL_GET_DOMAINS_WITH_NAME = \"SELECT name FROM domain WHERE name LIKE ?;\";\n    private static final String SQL_GET_DOMAIN_WITH_ACCOUNT = \"SELECT name FROM domain WHERE account=?;\";\n    private static final String SQL_GET_DOMAIN_WITH_SUBSCRIPTION = \"SELECT name FROM domain WHERE azure_subscription=?;\";\n    private static final String SQL_GET_DOMAIN_WITH_PRODUCT_ID = \"SELECT name FROM domain WHERE ypm_id=?;\";\n    private static final String SQL_LIST_DOMAIN_WITH_BUSINESS_SERVICE = \"SELECT name FROM domain WHERE business_service=?;\";\n    private static final String SQL_INSERT_DOMAIN = \"INSERT INTO domain \"\n            + \"(name, description, org, uuid, enabled, audit_enabled, account, ypm_id, application_id, cert_dns_domain,\"\n            + \" member_expiry_days, token_expiry_mins, service_cert_expiry_mins, role_cert_expiry_mins, sign_algorithm,\"\n            + \" service_expiry_days, user_authority_filter, group_expiry_days, azure_subscription, business_service)\"\n            + \" VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?);\";\n    private static final String SQL_UPDATE_DOMAIN = \"UPDATE domain \"\n            + \"SET description=?, org=?, uuid=?, enabled=?, audit_enabled=?, account=?, ypm_id=?, application_id=?,\"\n            + \" cert_dns_domain=?, member_expiry_days=?, token_expiry_mins=?, service_cert_expiry_mins=?,\"\n            + \" role_cert_expiry_mins=?, sign_algorithm=?, service_expiry_days=?, user_authority_filter=?,\"\n            + \" group_expiry_days=?, azure_subscription=?, business_service=? WHERE name=?;\";\n    private static final String SQL_UPDATE_DOMAIN_MOD_TIMESTAMP = \"UPDATE domain \"\n            + \"SET modified=CURRENT_TIMESTAMP(3) WHERE name=?;\";\n    private static final String SQL_GET_DOMAIN_MOD_TIMESTAMP = \"SELECT modified FROM domain WHERE name=?;\";\n    private static final String SQL_LIST_DOMAIN = \"SELECT * FROM domain;\";\n    private static final String SQL_LIST_DOMAIN_PREFIX = \"SELECT name, modified FROM domain WHERE name>=? AND name<?;\";\n    private static final String SQL_LIST_DOMAIN_MODIFIED = \"SELECT * FROM domain WHERE modified>?;\";\n    private static final String SQL_LIST_DOMAIN_PREFIX_MODIFIED = \"SELECT name, modified FROM domain \"\n            + \"WHERE name>=? AND name<? AND modified>?;\";\n    private static final String SQL_LIST_DOMAIN_ROLE_NAME_MEMBER = \"SELECT domain.name FROM domain \"\n            + \"JOIN role ON role.domain_id=domain.domain_id \"\n            + \"JOIN role_member ON role_member.role_id=role.role_id \"\n            + \"JOIN principal ON principal.principal_id=role_member.principal_id \"\n            + \"WHERE principal.name=? AND role.name=?;\";\n    private static final String SQL_LIST_DOMAIN_ROLE_MEMBER = \"SELECT domain.name FROM domain \"\n            + \"JOIN role ON role.domain_id=domain.domain_id \"\n            + \"JOIN role_member ON role_member.role_id=role.role_id \"\n            + \"JOIN principal ON principal.principal_id=role_member.principal_id \"\n            + \"WHERE principal.name=?;\";\n    private static final String SQL_LIST_DOMAIN_ROLE_NAME = \"SELECT domain.name FROM domain \"\n            + \"JOIN role ON role.domain_id=domain.domain_id WHERE role.name=?;\";\n    private static final String SQL_LIST_DOMAIN_AWS = \"SELECT name, account FROM domain WHERE account!='';\";\n    private static final String SQL_GET_ROLE = \"SELECT * FROM role \"\n            + \"JOIN domain ON domain.domain_id=role.domain_id \"\n            + \"WHERE domain.name=? AND role.name=?;\";\n    private static final String SQL_GET_ROLE_ID = \"SELECT role_id FROM role WHERE domain_id=? AND name=?;\";\n    private static final String SQL_INSERT_ROLE = \"INSERT INTO role (name, domain_id, trust, audit_enabled, self_serve,\"\n            + \" member_expiry_days, token_expiry_mins, cert_expiry_mins, sign_algorithm, service_expiry_days,\"\n            + \" member_review_days, service_review_days, review_enabled, notify_roles, user_authority_filter, \"\n            + \" user_authority_expiration, group_expiry_days) \"\n            + \"VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?);\";\n    private static final String SQL_UPDATE_ROLE = \"UPDATE role SET trust=?, audit_enabled=?, self_serve=?, \"\n            + \"member_expiry_days=?, token_expiry_mins=?, cert_expiry_mins=?, sign_algorithm=?, \"\n            + \"service_expiry_days=?, member_review_days=?, service_review_days=?, review_enabled=?, notify_roles=?, \"\n            + \"user_authority_filter=?, user_authority_expiration=?, group_expiry_days=? WHERE role_id=?;\";\n    private static final String SQL_DELETE_ROLE = \"DELETE FROM role WHERE domain_id=? AND name=?;\";\n    private static final String SQL_UPDATE_ROLE_MOD_TIMESTAMP = \"UPDATE role \"\n            + \"SET modified=CURRENT_TIMESTAMP(3) WHERE role_id=?;\";\n    private static final String SQL_LIST_ROLE = \"SELECT name FROM role WHERE domain_id=?;\";\n    private static final String SQL_COUNT_ROLE = \"SELECT COUNT(*) FROM role WHERE domain_id=?;\";\n    private static final String SQL_GET_ROLE_MEMBER = \"SELECT principal.principal_id, role_member.expiration, \"\n            + \"role_member.review_reminder, role_member.req_principal, role_member.system_disabled FROM principal \"\n            + \"JOIN role_member ON role_member.principal_id=principal.principal_id \"\n            + \"JOIN role ON role.role_id=role_member.role_id \"\n            + \"WHERE role.role_id=? AND principal.name=?;\";\n    private static final String SQL_GET_TEMP_ROLE_MEMBER = \"SELECT principal.principal_id, role_member.expiration, \"\n            + \"role_member.review_reminder, role_member.req_principal, role_member.system_disabled FROM principal \"\n            + \"JOIN role_member ON role_member.principal_id=principal.principal_id \"\n            + \"JOIN role ON role.role_id=role_member.role_id \"\n            + \"WHERE role.role_id=? AND principal.name=? AND role_member.expiration=?;\";\n    private static final String SQL_GET_PENDING_ROLE_MEMBER = \"SELECT principal.principal_id, pending_role_member.expiration, pending_role_member.review_reminder, pending_role_member.req_principal FROM principal \"\n            + \"JOIN pending_role_member ON pending_role_member.principal_id=principal.principal_id \"\n            + \"JOIN role ON role.role_id=pending_role_member.role_id \"\n            + \"WHERE role.role_id=? AND principal.name=?;\";\n    private static final String SQL_GET_TEMP_PENDING_ROLE_MEMBER = \"SELECT principal.principal_id, pending_role_member.expiration, pending_role_member.review_reminder, pending_role_member.req_principal FROM principal \"\n            + \"JOIN pending_role_member ON pending_role_member.principal_id=principal.principal_id \"\n            + \"JOIN role ON role.role_id=pending_role_member.role_id \"\n            + \"WHERE role.role_id=? AND principal.name=? AND pending_role_member.expiration=?;\";\n    private static final String SQL_STD_ROLE_MEMBER_EXISTS = \"SELECT principal_id FROM role_member WHERE role_id=? AND principal_id=?;\";\n    private static final String SQL_PENDING_ROLE_MEMBER_EXISTS = \"SELECT principal_id FROM pending_role_member WHERE role_id=? AND principal_id=?;\";\n    private static final String SQL_LIST_ROLE_MEMBERS = \"SELECT principal.name, role_member.expiration, \"\n            + \"role_member.review_reminder, role_member.active, role_member.audit_ref, role_member.system_disabled FROM principal \"\n            + \"JOIN role_member ON role_member.principal_id=principal.principal_id \"\n            + \"JOIN role ON role.role_id=role_member.role_id WHERE role.role_id=?;\";\n    private static final String SQL_LIST_PENDING_ROLE_MEMBERS = \"SELECT principal.name, pending_role_member.expiration, pending_role_member.review_reminder, pending_role_member.req_time, pending_role_member.audit_ref FROM principal \"\n            + \"JOIN pending_role_member ON pending_role_member.principal_id=principal.principal_id \"\n            + \"JOIN role ON role.role_id=pending_role_member.role_id WHERE role.role_id=?;\";\n    private static final String SQL_COUNT_ROLE_MEMBERS = \"SELECT COUNT(*) FROM role_member WHERE role_id=?;\";\n    private static final String SQL_GET_PRINCIPAL_ID = \"SELECT principal_id FROM principal WHERE name=?;\";\n    private static final String SQL_INSERT_PRINCIPAL = \"INSERT INTO principal (name) VALUES (?);\";\n    private static final String SQL_DELETE_PRINCIPAL = \"DELETE FROM principal WHERE name=?;\";\n    private static final String SQL_DELETE_SUB_PRINCIPALS = \"DELETE FROM principal WHERE name LIKE ?;\";\n    private static final String SQL_LIST_PRINCIPAL = \"SELECT * FROM principal;\";\n    private static final String SQL_LIST_PRINCIPAL_DOMAIN = \"SELECT * FROM principal WHERE name LIKE ?;\";\n    private static final String SQL_LAST_INSERT_ID = \"SELECT LAST_INSERT_ID();\";\n    private static final String SQL_INSERT_ROLE_MEMBER = \"INSERT INTO role_member \"\n            + \"(role_id, principal_id, expiration, review_reminder, active, audit_ref, req_principal) VALUES (?,?,?,?,?,?,?);\";\n    private static final String SQL_INSERT_PENDING_ROLE_MEMBER = \"INSERT INTO pending_role_member \"\n            + \"(role_id, principal_id, expiration, review_reminder, audit_ref, req_principal) VALUES (?,?,?,?,?,?);\";\n    private static final String SQL_DELETE_ROLE_MEMBER = \"DELETE FROM role_member WHERE role_id=? AND principal_id=?;\";\n    private static final String SQL_DELETE_PENDING_ROLE_MEMBER = \"DELETE FROM pending_role_member WHERE role_id=? AND principal_id=?;\";\n    private static final String SQL_UPDATE_ROLE_MEMBER = \"UPDATE role_member \"\n            + \"SET expiration=?, review_reminder=?, active=?, audit_ref=?, req_principal=? WHERE role_id=? AND principal_id=?;\";\n    private static final String SQL_UPDATE_ROLE_MEMBER_DISABLED_STATE = \"UPDATE role_member \"\n            + \"SET system_disabled=?, audit_ref=?, req_principal=? WHERE role_id=? AND principal_id=?;\";\n    private static final String SQL_UPDATE_PENDING_ROLE_MEMBER = \"UPDATE pending_role_member \"\n            + \"SET expiration=?, review_reminder=?, audit_ref=?, req_time=CURRENT_TIMESTAMP(3), req_principal=? WHERE role_id=? AND principal_id=?;\";\n    private static final String SQL_INSERT_ROLE_AUDIT_LOG = \"INSERT INTO role_audit_log \"\n            + \"(role_id, admin, member, action, audit_ref) VALUES (?,?,?,?,?);\";\n    private static final String SQL_LIST_ROLE_AUDIT_LOGS = \"SELECT * FROM role_audit_log WHERE role_id=?;\";\n    private static final String SQL_GET_POLICY = \"SELECT * FROM policy \"\n            + \"JOIN domain ON domain.domain_id=policy.domain_id WHERE domain.name=? AND policy.name=?;\";\n    private static final String SQL_INSERT_POLICY = \"INSERT INTO policy (name, domain_id) VALUES (?,?);\";\n    private static final String SQL_UPDATE_POLICY = \"UPDATE policy SET name=? WHERE policy_id=?;\";\n    private static final String SQL_UPDATE_POLICY_MOD_TIMESTAMP = \"UPDATE policy \"\n            + \"SET modified=CURRENT_TIMESTAMP(3) WHERE policy_id=?;\";\n    private static final String SQL_GET_POLICY_ID = \"SELECT policy_id FROM policy WHERE domain_id=? AND name=?;\";\n    private static final String SQL_DELETE_POLICY = \"DELETE FROM policy WHERE domain_id=? AND name=?;\";\n    private static final String SQL_LIST_POLICY = \"SELECT name FROM policy WHERE domain_id=?\";\n    private static final String SQL_COUNT_POLICY = \"SELECT COUNT(*) FROM policy WHERE domain_id=?\";\n    private static final String SQL_LIST_ASSERTION = \"SELECT * FROM assertion WHERE policy_id=?\";\n    private static final String SQL_COUNT_ASSERTION = \"SELECT COUNT(*) FROM assertion WHERE policy_id=?\";\n    private static final String SQL_GET_ASSERTION = \"SELECT * FROM assertion \"\n            + \"JOIN policy ON assertion.policy_id=policy.policy_id \"\n            + \"JOIN domain ON policy.domain_id=domain.domain_id \"\n            + \"WHERE assertion.assertion_id=? AND domain.name=? AND policy.name=?;\";\n    private static final String SQL_CHECK_ASSERTION = \"SELECT assertion_id FROM assertion \"\n            + \"WHERE policy_id=? AND role=? AND resource=? AND action=? AND effect=?;\";\n    private static final String SQL_INSERT_ASSERTION = \"INSERT INTO assertion \"\n            + \"(policy_id, role, resource, action, effect) VALUES (?,?,?,?,?);\";\n    private static final String SQL_DELETE_ASSERTION = \"DELETE FROM assertion \"\n            + \"WHERE policy_id=? AND assertion_id=?;\";\n    private static final String SQL_GET_SERVICE = \"SELECT * FROM service \"\n            + \"JOIN domain ON domain.domain_id=service.domain_id WHERE domain.name=? AND service.name=?;\";\n    private static final String SQL_INSERT_SERVICE = \"INSERT INTO service \"\n            + \"(name, description, provider_endpoint, executable, svc_user, svc_group, domain_id) VALUES (?,?,?,?,?,?,?);\";\n    private static final String SQL_UPDATE_SERVICE = \"UPDATE service SET \"\n            + \"description=?, provider_endpoint=?, executable=?, svc_user=?, svc_group=?  WHERE service_id=?;\";\n    private static final String SQL_UPDATE_SERVICE_MOD_TIMESTAMP = \"UPDATE service \"\n            + \"SET modified=CURRENT_TIMESTAMP(3) WHERE service_id=?;\";\n    private static final String SQL_DELETE_SERVICE = \"DELETE FROM service WHERE domain_id=? AND name=?;\";\n    private static final String SQL_GET_SERVICE_ID = \"SELECT service_id FROM service WHERE domain_id=? AND name=?;\";\n    private static final String SQL_LIST_SERVICE = \"SELECT name FROM service WHERE domain_id=?;\";\n    private static final String SQL_COUNT_SERVICE = \"SELECT COUNT(*) FROM service WHERE domain_id=?;\";\n    private static final String SQL_LIST_PUBLIC_KEY = \"SELECT * FROM public_key WHERE service_id=?;\";\n    private static final String SQL_COUNT_PUBLIC_KEY = \"SELECT COUNT(*) FROM public_key WHERE service_id=?;\";\n    private static final String SQL_GET_PUBLIC_KEY = \"SELECT key_value FROM public_key WHERE service_id=? AND key_id=?;\";\n    private static final String SQL_INSERT_PUBLIC_KEY = \"INSERT INTO public_key \"\n            + \"(service_id, key_id, key_value) VALUES (?,?,?);\";\n    private static final String SQL_UPDATE_PUBLIC_KEY = \"UPDATE public_key SET key_value=? WHERE service_id=? AND key_id=?;\";\n    private static final String SQL_DELETE_PUBLIC_KEY = \"DELETE FROM public_key WHERE service_id=? AND key_id=?;\";\n    private static final String SQL_LIST_SERVICE_HOST = \"SELECT host.name FROM host \"\n            + \"JOIN service_host ON service_host.host_id=host.host_id \"\n            + \"WHERE service_host.service_id=?;\";\n    private static final String SQL_INSERT_SERVICE_HOST = \"INSERT INTO service_host (service_id, host_id) VALUES (?,?);\";\n    private static final String SQL_DELETE_SERVICE_HOST = \"DELETE FROM service_host WHERE service_id=? AND host_id=?;\";\n    private static final String SQL_GET_HOST_ID = \"SELECT host_id FROM host WHERE name=?;\";\n    private static final String SQL_INSERT_HOST = \"INSERT INTO host (name) VALUES (?);\";\n    private static final String SQL_INSERT_ENTITY = \"INSERT INTO entity (domain_id, name, value) VALUES (?,?,?);\";\n    private static final String SQL_UPDATE_ENTITY = \"UPDATE entity SET value=? WHERE domain_id=? AND name=?;\";\n    private static final String SQL_DELETE_ENTITY = \"DELETE FROM entity WHERE domain_id=? AND name=?;\";\n    private static final String SQL_GET_ENTITY = \"SELECT value FROM entity WHERE domain_id=? AND name=?;\";\n    private static final String SQL_LIST_ENTITY = \"SELECT name FROM entity WHERE domain_id=?;\";\n    private static final String SQL_COUNT_ENTITY = \"SELECT COUNT(*) FROM entity WHERE domain_id=?;\";\n    private static final String SQL_INSERT_DOMAIN_TEMPLATE = \"INSERT INTO domain_template (domain_id, template) VALUES (?,?);\";\n    private static final String SQL_UPDATE_DOMAIN_TEMPLATE = \"UPDATE domain_template SET current_version=? WHERE domain_id=? and template=?;\";\n    private static final String SQL_DELETE_DOMAIN_TEMPLATE = \"DELETE FROM domain_template WHERE domain_id=? AND template=?;\";\n    private static final String SQL_LIST_DOMAIN_TEMPLATES = \"SELECT * FROM domain_template WHERE domain_id=?;\";\n    private static final String SQL_LIST_DOMAIN_TEMPLATE = \"SELECT template FROM domain_template \"\n            + \"JOIN domain ON domain_template.domain_id=domain.domain_id \"\n            + \"WHERE domain.name=?;\";\n    private static final String SQL_GET_DOMAIN_ENTITIES = \"SELECT * FROM entity WHERE domain_id=?;\";\n    private static final String SQL_GET_DOMAIN_ROLES = \"SELECT * FROM role WHERE domain_id=?;\";\n    private static final String SQL_GET_DOMAIN_ROLE_MEMBERS = \"SELECT role.name, principal.name, role_member.expiration, \"\n            + \"role_member.review_reminder, role_member.system_disabled FROM principal \"\n            + \"JOIN role_member ON role_member.principal_id=principal.principal_id \"\n            + \"JOIN role ON role.role_id=role_member.role_id \"\n            + \"WHERE role.domain_id=?;\";\n\n    private static final String SQL_GET_PRINCIPAL_ROLES = \"SELECT role.name, domain.name, role_member.expiration, \"\n            + \"role_member.review_reminder, role_member.system_disabled FROM role_member \"\n            + \"JOIN role ON role.role_id=role_member.role_id \"\n            + \"JOIN domain ON domain.domain_id=role.domain_id \"\n            + \"WHERE role_member.principal_id=?;\";\n\n    private static final String SQL_GET_PRINCIPAL_ROLES_DOMAIN = \"SELECT role.name, domain.name, role_member.expiration, \"\n            + \"role_member.review_reminder, role_member.system_disabled FROM role_member \"\n            + \"JOIN role ON role.role_id=role_member.role_id \"\n            + \"JOIN domain ON domain.domain_id=role.domain_id \"\n            + \"WHERE role_member.principal_id=? AND domain.domain_id=?;\";\n\n    private static final String SQL_GET_REVIEW_OVERDUE_DOMAIN_ROLE_MEMBERS = \"SELECT role.name, principal.name, role_member.expiration, \"\n            + \"role_member.review_reminder, role_member.system_disabled FROM principal \"\n            + \"JOIN role_member ON role_member.principal_id=principal.principal_id \"\n            + \"JOIN role ON role.role_id=role_member.role_id \"\n            + \"WHERE role.domain_id=? AND role_member.review_reminder < CURRENT_TIME;\";\n    private static final String SQL_GET_DOMAIN_POLICIES = \"SELECT * FROM policy WHERE domain_id=?;\";\n    private static final String SQL_GET_DOMAIN_POLICY_ASSERTIONS = \"SELECT policy.name, \"\n            + \"assertion.effect, assertion.action, assertion.role, assertion.resource, \"\n            + \"assertion.assertion_id FROM assertion \"\n            + \"JOIN policy ON policy.policy_id=assertion.policy_id \"\n            + \"WHERE policy.domain_id=?;\";\n    private static final String SQL_GET_DOMAIN_SERVICES = \"SELECT * FROM service WHERE domain_id=?;\";\n    private static final String SQL_GET_DOMAIN_SERVICES_HOSTS = \"SELECT service.name, host.name FROM host \"\n            + \"JOIN service_host ON host.host_id=service_host.host_id \"\n            + \"JOIN service ON service.service_id=service_host.service_id \"\n            + \"WHERE service.domain_id=?;\";\n    private static final String SQL_GET_DOMAIN_SERVICES_PUBLIC_KEYS = \"SELECT service.name, \"\n            + \"public_key.key_id, public_key.key_value FROM public_key \"\n            + \"JOIN service ON service.service_id=public_key.service_id \"\n            + \"WHERE service.domain_id=?;\";\n    private static final String SQL_LIST_POLICY_REFERENCING_ROLE = \"SELECT name FROM policy \"\n            + \"JOIN assertion ON policy.policy_id=assertion.policy_id \"\n            + \"WHERE policy.domain_id=? AND assertion.role=?;\";\n    private static final String SQL_LIST_ROLE_ASSERTIONS = \"SELECT assertion.role, assertion.resource, \"\n            + \"assertion.action, assertion.effect, assertion.assertion_id, policy.domain_id, domain.name FROM assertion \"\n            + \"JOIN policy ON assertion.policy_id=policy.policy_id \"\n            + \"JOIN domain ON policy.domain_id=domain.domain_id\";\n    private static final String SQL_LIST_ROLE_ASSERTION_QUERY_ACTION = \" WHERE assertion.action=?;\";\n    private static final String SQL_LIST_ROLE_ASSERTION_NO_ACTION = \" WHERE assertion.action!='assume_role';\";\n    private static final String SQL_LIST_ROLE_PRINCIPALS = \"SELECT role.domain_id, role.name AS role_name FROM principal \"\n            + \"JOIN role_member ON principal.principal_id=role_member.principal_id \"\n            + \"JOIN role ON role_member.role_id=role.role_id WHERE principal.name=? \"\n            + \"AND principal.system_suspended=0 AND role_member.system_disabled=0 \"\n            + \"AND (role_member.expiration IS NULL OR role_member.expiration > CURRENT_TIME);\";\n    private static final String SQL_LIST_ROLE_GROUP_PRINCIPALS = \"SELECT principal.name, role.domain_id, \"\n            + \"role.name AS role_name FROM principal \"\n            + \"JOIN role_member ON principal.principal_id=role_member.principal_id \"\n            + \"JOIN role ON role_member.role_id=role.role_id WHERE principal.name LIKE '%:group.%' \"\n            + \"AND principal.system_suspended=0 AND role_member.system_disabled=0 \"\n            + \"AND (role_member.expiration IS NULL OR role_member.expiration > CURRENT_TIME);\";\n    private static final String SQL_LIST_GROUP_FOR_PRINCIPAL = \"SELECT principal_group.name, domain.name AS domain_name \"\n            + \"FROM principal_group_member  JOIN principal_group ON principal_group.group_id=principal_group_member.group_id \"\n            + \"JOIN domain ON domain.domain_id=principal_group.domain_id JOIN principal ON principal.principal_id=principal_group_member.principal_id \"\n            + \"WHERE principal.name=? AND principal.system_suspended=0 AND principal_group_member.system_disabled=0 \"\n            + \"AND (principal_group_member.expiration IS NULL OR principal_group_member.expiration > CURRENT_TIME);\";\n    private static final String SQL_LIST_TRUSTED_STANDARD_ROLES = \"SELECT role.domain_id, role.name, \"\n            + \"policy.domain_id AS assert_domain_id, assertion.role FROM role \"\n            + \"JOIN domain ON domain.domain_id=role.domain_id \"\n            + \"JOIN assertion ON assertion.resource=CONCAT(domain.name, \\\":role.\\\", role.name) \"\n            + \"JOIN policy ON policy.policy_id=assertion.policy_id \"\n            + \"WHERE assertion.action='assume_role';\";\n    private static final String SQL_LIST_TRUSTED_WILDCARD_ROLES = \"SELECT role.domain_id, role.name, \"\n            + \"policy.domain_id AS assert_domain_id, assertion.role FROM role \"\n            + \"JOIN domain ON domain.domain_id=role.domain_id \"\n            + \"JOIN assertion ON assertion.resource=CONCAT(\\\"*:role.\\\", role.name) \"\n            + \"JOIN policy ON policy.policy_id=assertion.policy_id \"\n            + \"WHERE assertion.action='assume_role';\";\n    private static final String SQL_LIST_PRINCIPAL_ROLES = \"SELECT domain.name, \"\n            + \"role.name AS role_name FROM role_member \"\n            + \"JOIN role ON role_member.role_id=role.role_id \"\n            + \"JOIN domain ON domain.domain_id=role.domain_id \"\n            + \"WHERE role_member.principal_id=?;\";\n    private static final String SQL_LIST_PRINCIPAL_DOMAIN_ROLES = \"SELECT role.name AS role_name FROM role_member \"\n            + \"JOIN role ON role_member.role_id=role.role_id \"\n            + \"JOIN domain ON domain.domain_id=role.domain_id \"\n            + \"WHERE role_member.principal_id=? AND domain.domain_id=?;\";\n    private static final String SQL_GET_QUOTA = \"SELECT * FROM quota WHERE domain_id=?;\";\n    private static final String SQL_INSERT_QUOTA = \"INSERT INTO quota (domain_id, role, role_member, \"\n            + \"policy, assertion, service, service_host, public_key, entity, subdomain, principal_group, principal_group_member) \"\n            + \"VALUES (?,?,?,?,?,?,?,?,?,?,?,?);\";\n    private static final String SQL_UPDATE_QUOTA = \"UPDATE quota SET role=?, role_member=?, \"\n            + \"policy=?, assertion=?, service=?, service_host=?, public_key=?, entity=?, \"\n            + \"subdomain=?, principal_group=?, principal_group_member=?  WHERE domain_id=?;\";\n    private static final String SQL_DELETE_QUOTA = \"DELETE FROM quota WHERE domain_id=?;\";\n\n    private static final String SQL_PENDING_ORG_AUDIT_ROLE_MEMBER_LIST = \"SELECT do.name AS domain, ro.name AS role, \"\n            + \"principal.name AS member, rmo.expiration, rmo.review_reminder, rmo.audit_ref, rmo.req_time, rmo.req_principal \"\n            + \"FROM principal JOIN pending_role_member rmo \"\n            + \"ON rmo.principal_id=principal.principal_id JOIN role ro ON ro.role_id=rmo.role_id JOIN domain do ON ro.domain_id=do.domain_id \"\n            + \"WHERE ro.audit_enabled=true AND ro.domain_id IN ( select domain_id FROM domain WHERE org IN ( \"\n            + \"SELECT DISTINCT role.name AS org FROM role_member JOIN role ON role.role_id=role_member.role_id \"\n            + \"WHERE role_member.principal_id=? AND role.domain_id=?) ) order by do.name, ro.name, principal.name;\";\n    private static final String SQL_PENDING_DOMAIN_AUDIT_ROLE_MEMBER_LIST = \"SELECT do.name AS domain, ro.name AS role, \"\n            + \"principal.name AS member, rmo.expiration, rmo.review_reminder, rmo.audit_ref, rmo.req_time, rmo.req_principal \"\n            + \"FROM principal JOIN pending_role_member rmo \"\n            + \"ON rmo.principal_id=principal.principal_id JOIN role ro ON ro.role_id=rmo.role_id JOIN domain do ON ro.domain_id=do.domain_id \"\n            + \"WHERE ro.audit_enabled=true AND ro.domain_id IN ( select domain_id FROM domain WHERE name IN ( \"\n            + \"SELECT DISTINCT role.name AS domain_name FROM role_member JOIN role ON role.role_id=role_member.role_id \"\n            + \"WHERE role_member.principal_id=? AND role.domain_id=?) ) order by do.name, ro.name, principal.name;\";\n    private static final String SQL_PENDING_DOMAIN_ADMIN_ROLE_MEMBER_LIST = \"SELECT do.name AS domain, ro.name AS role, \"\n            + \"principal.name AS member, rmo.expiration, rmo.review_reminder, rmo.audit_ref, rmo.req_time, rmo.req_principal \"\n            + \"FROM principal JOIN pending_role_member rmo \"\n            + \"ON rmo.principal_id=principal.principal_id JOIN role ro ON ro.role_id=rmo.role_id JOIN domain do ON ro.domain_id=do.domain_id \"\n            + \"WHERE (ro.self_serve=true OR ro.review_enabled=true) AND ro.domain_id IN ( SELECT domain.domain_id FROM domain JOIN role \"\n            + \"ON role.domain_id=domain.domain_id JOIN role_member ON role.role_id=role_member.role_id \"\n            + \"WHERE role_member.principal_id=? AND role_member.active=true AND role.name='admin' ) \"\n            + \"order by do.name, ro.name, principal.name;\";\n\n    private static final String SQL_AUDIT_ENABLED_PENDING_MEMBERSHIP_REMINDER_ENTRIES =\n            \"SELECT distinct d.org, d.name FROM pending_role_member rm \" +\n            \"JOIN role r ON r.role_id=rm.role_id JOIN domain d ON r.domain_id=d.domain_id \" +\n            \"WHERE r.audit_enabled=true AND rm.last_notified_time=? AND rm.server=?;\";\n\n    private static final String SQL_ADMIN_PENDING_MEMBERSHIP_REMINDER_DOMAINS =\n            \"SELECT distinct d.name FROM pending_role_member rm \" +\n            \"JOIN role r ON r.role_id=rm.role_id \" +\n            \"JOIN domain d ON r.domain_id=d.domain_id WHERE (r.self_serve=true OR r.review_enabled=true) AND rm.last_notified_time=? AND rm.server=?;\";\n\n    private static final String SQL_GET_EXPIRED_PENDING_ROLE_MEMBERS = \"SELECT d.name, r.name, p.name, prm.expiration, prm.review_reminder, prm.audit_ref, prm.req_time, prm.req_principal \" +\n            \"FROM principal p JOIN pending_role_member prm \" +\n            \"ON prm.principal_id=p.principal_id JOIN role r ON prm.role_id=r.role_id JOIN domain d ON d.domain_id=r.domain_id \" +\n            \"WHERE prm.req_time < (CURRENT_TIME - INTERVAL ? DAY);\";\n\n    private static final String SQL_UPDATE_PENDING_ROLE_MEMBERS_NOTIFICATION_TIMESTAMP = \"UPDATE pending_role_member SET last_notified_time=?, server=? \" +\n            \"WHERE DAYOFWEEK(req_time)=DAYOFWEEK(?) AND (last_notified_time IS NULL || last_notified_time < (CURRENT_TIME - INTERVAL ? DAY));\";\n\n    private static final String SQL_UPDATE_ROLE_MEMBERS_EXPIRY_NOTIFICATION_TIMESTAMP =\n            \"UPDATE role_member SET last_notified_time=?, server=? \" +\n            \"WHERE (\" +\n                    // Expiration is set and Review isn't (or after expiration) - start sending a month before expiration\n                    \"(expiration > CURRENT_TIME AND (review_reminder is NULL OR review_reminder >= expiration) AND DATEDIFF(expiration, CURRENT_TIME) IN (0,1,7,14,21,28)) OR\" +\n                    // Expiration and Review both set and review is before expiration - start sending from review date\n                    \"(expiration > CURRENT_TIME AND review_reminder is not NULL AND review_reminder <= CURRENT_TIME AND DATEDIFF(expiration, CURRENT_TIME) IN (0,1,7,14,21,28))\" +\n                    \") AND \" +\n                    \"(last_notified_time IS NULL || last_notified_time < (CURRENT_TIME - INTERVAL ? DAY));\";\n    private static final String SQL_LIST_NOTIFY_TEMPORARY_ROLE_MEMBERS = \"SELECT domain.name AS domain_name, role.name AS role_name, \" +\n            \"principal.name AS principal_name, role_member.expiration, role_member.review_reminder FROM role_member \" +\n            \"JOIN role ON role.role_id=role_member.role_id \" +\n            \"JOIN principal ON principal.principal_id=role_member.principal_id \" +\n            \"JOIN domain ON domain.domain_id=role.domain_id \" +\n            \"WHERE role_member.last_notified_time=? AND role_member.server=?;\";\n\n    private static final String SQL_UPDATE_ROLE_MEMBERS_REVIEW_NOTIFICATION_TIMESTAMP =\n            \"UPDATE role_member SET review_last_notified_time=?, review_server=? \" +\n            \"WHERE (\" +\n                    \"review_reminder > CURRENT_TIME AND (expiration is NULL) AND DATEDIFF(review_reminder, CURRENT_TIME) IN (0,1,7,14,21,28) AND \" +\n                    \"(review_last_notified_time IS NULL || review_last_notified_time < (CURRENT_TIME - INTERVAL ? DAY)));\";\n    private static final String SQL_LIST_NOTIFY_REVIEW_ROLE_MEMBERS = \"SELECT domain.name AS domain_name, role.name AS role_name, \" +\n            \"principal.name AS principal_name, role_member.expiration, role_member.review_reminder FROM role_member \" +\n            \"JOIN role ON role.role_id=role_member.role_id \" +\n            \"JOIN principal ON principal.principal_id=role_member.principal_id \" +\n            \"JOIN domain ON domain.domain_id=role.domain_id \" +\n            \"WHERE role_member.review_last_notified_time=? AND role_member.review_server=?;\";\n\n    private static final String SQL_UPDATE_ROLE_REVIEW_TIMESTAMP = \"UPDATE role SET last_reviewed_time=CURRENT_TIMESTAMP(3) WHERE role_id=?;\";\n    private static final String SQL_LIST_ROLES_WITH_RESTRICTIONS = \"SELECT domain.name as domain_name, \"\n            + \"role.name as role_name, domain.user_authority_filter as domain_user_authority_filter FROM role \"\n            + \"JOIN domain ON role.domain_id=domain.domain_id WHERE role.user_authority_filter!='' \"\n            + \"OR role.user_authority_expiration!='' OR domain.user_authority_filter!='';\";\n\n    private static final String SQL_GET_GROUP = \"SELECT * FROM principal_group \"\n            + \"JOIN domain ON domain.domain_id=principal_group.domain_id \"\n            + \"WHERE domain.name=? AND principal_group.name=?;\";\n    private static final String SQL_INSERT_GROUP = \"INSERT INTO principal_group (name, domain_id, audit_enabled, self_serve,\"\n            + \" review_enabled, notify_roles, user_authority_filter, user_authority_expiration, member_expiry_days, service_expiry_days) \"\n            + \"VALUES (?,?,?,?,?,?,?,?,?,?);\";\n    private static final String SQL_UPDATE_GROUP = \"UPDATE principal_group SET audit_enabled=?, self_serve=?, \"\n            + \"review_enabled=?, notify_roles=?, user_authority_filter=?, user_authority_expiration=?,\"\n            + \"member_expiry_days=?, service_expiry_days=? WHERE group_id=?;\";\n    private static final String SQL_GET_GROUP_ID = \"SELECT group_id FROM principal_group WHERE domain_id=? AND name=?;\";\n    private static final String SQL_DELETE_GROUP = \"DELETE FROM principal_group WHERE domain_id=? AND name=?;\";\n    private static final String SQL_UPDATE_GROUP_MOD_TIMESTAMP = \"UPDATE principal_group \"\n            + \"SET modified=CURRENT_TIMESTAMP(3) WHERE group_id=?;\";\n    private static final String SQL_COUNT_GROUP = \"SELECT COUNT(*) FROM principal_group WHERE domain_id=?;\";\n    private static final String SQL_GET_GROUP_MEMBER = \"SELECT principal.principal_id, principal_group_member.expiration, \"\n            + \"principal_group_member.req_principal, principal_group_member.system_disabled FROM principal \"\n            + \"JOIN principal_group_member ON principal_group_member.principal_id=principal.principal_id \"\n            + \"JOIN principal_group ON principal_group.group_id=principal_group_member.group_id \"\n            + \"WHERE principal_group.group_id=? AND principal.name=?;\";\n    private static final String SQL_GET_TEMP_GROUP_MEMBER = \"SELECT principal.principal_id, principal_group_member.expiration, \"\n            + \"principal_group_member.req_principal, principal_group_member.system_disabled FROM principal \"\n            + \"JOIN principal_group_member ON principal_group_member.principal_id=principal.principal_id \"\n            + \"JOIN principal_group ON principal_group.group_id=principal_group_member.group_id \"\n            + \"WHERE principal_group.group_id=? AND principal.name=? AND principal_group_member.expiration=?;\";\n    private static final String SQL_GET_PENDING_GROUP_MEMBER = \"SELECT principal.principal_id, \"\n            + \"pending_principal_group_member.expiration, pending_principal_group_member.req_principal FROM principal \"\n            + \"JOIN pending_principal_group_member ON pending_principal_group_member.principal_id=principal.principal_id \"\n            + \"JOIN principal_group ON principal_group.group_id=pending_principal_group_member.group_id \"\n            + \"WHERE principal_group.group_id=? AND principal.name=?;\";\n    private static final String SQL_GET_TEMP_PENDING_GROUP_MEMBER = \"SELECT principal.principal_id, \"\n            + \"pending_principal_group_member.expiration, pending_principal_group_member.req_principal FROM principal \"\n            + \"JOIN pending_principal_group_member ON pending_principal_group_member.principal_id=principal.principal_id \"\n            + \"JOIN principal_group ON principal_group.group_id=pending_principal_group_member.group_id \"\n            + \"WHERE principal_group.group_id=? AND principal.name=? AND pending_principal_group_member.expiration=?;\";\n    private static final String SQL_LIST_GROUP_AUDIT_LOGS = \"SELECT * FROM principal_group_audit_log WHERE group_id=?;\";\n    private static final String SQL_UPDATE_GROUP_REVIEW_TIMESTAMP = \"UPDATE principal_group SET last_reviewed_time=CURRENT_TIMESTAMP(3) WHERE group_id=?;\";\n    private static final String SQL_LIST_GROUPS_WITH_RESTRICTIONS = \"SELECT domain.name as domain_name, \"\n            + \"principal_group.name as group_name, domain.user_authority_filter as domain_user_authority_filter FROM principal_group \"\n            + \"JOIN domain ON principal_group.domain_id=domain.domain_id WHERE principal_group.user_authority_filter!='' \"\n            + \"OR principal_group.user_authority_expiration!='' OR domain.user_authority_filter!='';\";\n    private static final String SQL_LIST_GROUP_MEMBERS = \"SELECT principal.name, principal_group_member.expiration, \"\n            + \"principal_group_member.active, principal_group_member.audit_ref, principal_group_member.system_disabled FROM principal \"\n            + \"JOIN principal_group_member ON principal_group_member.principal_id=principal.principal_id \"\n            + \"JOIN principal_group ON principal_group.group_id=principal_group_member.group_id WHERE principal_group.group_id=?;\";\n    private static final String SQL_LIST_PENDING_GROUP_MEMBERS = \"SELECT principal.name, pending_principal_group_member.expiration, \"\n            + \"pending_principal_group_member.req_time, pending_principal_group_member.audit_ref FROM principal \"\n            + \"JOIN pending_principal_group_member ON pending_principal_group_member.principal_id=principal.principal_id \"\n            + \"JOIN principal_group ON principal_group.group_id=pending_principal_group_member.group_id WHERE principal_group.group_id=?;\";\n    private static final String SQL_COUNT_GROUP_MEMBERS = \"SELECT COUNT(*) FROM principal_group_member WHERE group_id=?;\";\n    private static final String SQL_STD_GROUP_MEMBER_EXISTS = \"SELECT principal_id FROM principal_group_member WHERE group_id=? AND principal_id=?;\";\n    private static final String SQL_PENDING_GROUP_MEMBER_EXISTS = \"SELECT principal_id FROM pending_principal_group_member WHERE group_id=? AND principal_id=?;\";\n    private static final String SQL_UPDATE_GROUP_MEMBER = \"UPDATE principal_group_member \"\n            + \"SET expiration=?, active=?, audit_ref=?, req_principal=? WHERE group_id=? AND principal_id=?;\";\n    private static final String SQL_UPDATE_GROUP_MEMBER_DISABLED_STATE = \"UPDATE principal_group_member \"\n            + \"SET system_disabled=?, audit_ref=?, req_principal=? WHERE group_id=? AND principal_id=?;\";\n    private static final String SQL_UPDATE_PENDING_GROUP_MEMBER = \"UPDATE pending_principal_group_member \"\n            + \"SET expiration=?, audit_ref=?, req_time=CURRENT_TIMESTAMP(3), req_principal=? WHERE group_id=? AND principal_id=?;\";\n    private static final String SQL_INSERT_GROUP_MEMBER = \"INSERT INTO principal_group_member \"\n            + \"(group_id, principal_id, expiration, active, audit_ref, req_principal) VALUES (?,?,?,?,?,?);\";\n    private static final String SQL_INSERT_PENDING_GROUP_MEMBER = \"INSERT INTO pending_principal_group_member \"\n            + \"(group_id, principal_id, expiration, audit_ref, req_principal) VALUES (?,?,?,?,?);\";\n    private static final String SQL_DELETE_GROUP_MEMBER = \"DELETE FROM principal_group_member WHERE group_id=? AND principal_id=?;\";\n    private static final String SQL_DELETE_PENDING_GROUP_MEMBER = \"DELETE FROM pending_principal_group_member WHERE group_id=? AND principal_id=?;\";\n    private static final String SQL_INSERT_GROUP_AUDIT_LOG = \"INSERT INTO principal_group_audit_log \"\n            + \"(group_id, admin, member, action, audit_ref) VALUES (?,?,?,?,?);\";\n    private static final String SQL_GET_PRINCIPAL_GROUPS = \"SELECT principal_group.name, domain.name, principal_group_member.expiration, \"\n            + \"principal_group_member.system_disabled FROM principal_group_member \"\n            + \"JOIN principal_group ON principal_group.group_id=principal_group_member.group_id \"\n            + \"JOIN domain ON domain.domain_id=principal_group.domain_id \"\n            + \"WHERE principal_group_member.principal_id=?;\";\n    private static final String SQL_GET_PRINCIPAL_GROUPS_DOMAIN = \"SELECT principal_group.name, domain.name, principal_group_member.expiration, \"\n            + \"principal_group_member.system_disabled FROM principal_group_member \"\n            + \"JOIN principal_group ON principal_group.group_id=principal_group_member.group_id \"\n            + \"JOIN domain ON domain.domain_id=principal_group.domain_id \"\n            + \"WHERE principal_group_member.principal_id=? AND domain.domain_id=?;\";\n    private static final String SQL_GET_DOMAIN_GROUPS = \"SELECT * FROM principal_group WHERE domain_id=?;\";\n    private static final String SQL_GET_DOMAIN_GROUP_MEMBERS = \"SELECT principal_group.name, principal.name, \"\n            + \"principal_group_member.expiration, principal_group_member.system_disabled FROM principal \"\n            + \"JOIN principal_group_member ON principal_group_member.principal_id=principal.principal_id \"\n            + \"JOIN principal_group ON principal_group.group_id=principal_group_member.group_id \"\n            + \"WHERE principal_group.domain_id=?;\";\n    private static final String SQL_PENDING_ORG_AUDIT_GROUP_MEMBER_LIST = \"SELECT do.name AS domain, grp.name AS group_name, \"\n            + \"principal.name AS member, pgm.expiration, pgm.audit_ref, pgm.req_time, pgm.req_principal \"\n            + \"FROM principal JOIN pending_principal_group_member pgm \"\n            + \"ON pgm.principal_id=principal.principal_id JOIN principal_group grp ON grp.group_id=pgm.group_id JOIN domain do ON grp.domain_id=do.domain_id \"\n            + \"WHERE grp.audit_enabled=true AND grp.domain_id IN ( select domain_id FROM domain WHERE org IN ( \"\n            + \"SELECT DISTINCT role.name AS org FROM role_member JOIN role ON role.role_id=role_member.role_id \"\n            + \"WHERE role_member.principal_id=? AND role.domain_id=?) ) order by do.name, grp.name, principal.name;\";\n    private static final String SQL_PENDING_DOMAIN_AUDIT_GROUP_MEMBER_LIST = \"SELECT do.name AS domain, grp.name AS group_name, \"\n            + \"principal.name AS member, pgm.expiration, pgm.audit_ref, pgm.req_time, pgm.req_principal \"\n            + \"FROM principal JOIN pending_principal_group_member pgm \"\n            + \"ON pgm.principal_id=principal.principal_id JOIN principal_group grp ON grp.group_id=pgm.group_id JOIN domain do ON grp.domain_id=do.domain_id \"\n            + \"WHERE grp.audit_enabled=true AND grp.domain_id IN ( select domain_id FROM domain WHERE name IN ( \"\n            + \"SELECT DISTINCT role.name AS domain_name FROM role_member JOIN role ON role.role_id=role_member.role_id \"\n            + \"WHERE role_member.principal_id=? AND role.domain_id=?) ) order by do.name, grp.name, principal.name;\";\n    private static final String SQL_PENDING_DOMAIN_ADMIN_GROUP_MEMBER_LIST = \"SELECT do.name AS domain, grp.name AS group_name, \"\n            + \"principal.name AS member, pgm.expiration, pgm.audit_ref, pgm.req_time, pgm.req_principal \"\n            + \"FROM principal JOIN pending_principal_group_member pgm \"\n            + \"ON pgm.principal_id=principal.principal_id JOIN principal_group grp ON grp.group_id=pgm.group_id JOIN domain do ON grp.domain_id=do.domain_id \"\n            + \"WHERE (grp.self_serve=true OR grp.review_enabled=true) AND grp.domain_id IN ( SELECT domain.domain_id FROM domain JOIN role \"\n            + \"ON role.domain_id=domain.domain_id JOIN role_member ON role.role_id=role_member.role_id \"\n            + \"WHERE role_member.principal_id=? AND role_member.active=true AND role.name='admin' ) \"\n            + \"order by do.name, grp.name, principal.name;\";\n    private static final String SQL_GET_EXPIRED_PENDING_GROUP_MEMBERS = \"SELECT d.name, grp.name, p.name, pgm.expiration, pgm.audit_ref, pgm.req_time, pgm.req_principal \"\n            + \"FROM principal p JOIN pending_principal_group_member pgm \"\n            + \"ON pgm.principal_id=p.principal_id JOIN principal_group grp ON pgm.group_id=grp.group_id JOIN domain d ON d.domain_id=grp.domain_id \"\n            + \"WHERE pgm.req_time < (CURRENT_TIME - INTERVAL ? DAY);\";\n    private static final String SQL_AUDIT_ENABLED_PENDING_GROUP_MEMBERSHIP_REMINDER_ENTRIES = \"SELECT distinct d.org, d.name FROM pending_principal_group_member pgm \"\n            + \"JOIN principal_group grp ON grp.group_id=pgm.group_id JOIN domain d ON grp.domain_id=d.domain_id \"\n            + \"WHERE grp.audit_enabled=true AND pgm.last_notified_time=? AND pgm.server=?;\";\n    private static final String SQL_UPDATE_PENDING_GROUP_MEMBERS_NOTIFICATION_TIMESTAMP = \"UPDATE pending_principal_group_member SET last_notified_time=?, server=? \"\n            + \"WHERE DAYOFWEEK(req_time)=DAYOFWEEK(?) AND (last_notified_time IS NULL || last_notified_time < (CURRENT_TIME - INTERVAL ? DAY));\";\n    private static final String SQL_ADMIN_PENDING_GROUP_MEMBERSHIP_REMINDER_DOMAINS = \"SELECT distinct d.name FROM pending_principal_group_member pgm \"\n            + \"JOIN principal_group grp ON grp.group_id=pgm.group_id JOIN domain d ON grp.domain_id=d.domain_id \"\n            + \"WHERE grp.self_serve=true AND pgm.last_notified_time=? AND pgm.server=?;\";\n    private static final String SQL_UPDATE_GROUP_MEMBERS_EXPIRY_NOTIFICATION_TIMESTAMP = \"UPDATE principal_group_member SET last_notified_time=?, server=? \"\n            + \"WHERE expiration > CURRENT_TIME AND DATEDIFF(expiration, CURRENT_TIME) IN (0,1,7,14,21,28) \"\n            + \"AND (last_notified_time IS NULL || last_notified_time < (CURRENT_TIME - INTERVAL ? DAY));\";\n    private static final String SQL_LIST_NOTIFY_TEMPORARY_GROUP_MEMBERS = \"SELECT domain.name AS domain_name, principal_group.name AS group_name, \"\n            + \"principal.name AS principal_name, principal_group_member.expiration FROM principal_group_member \"\n            + \"JOIN principal_group ON principal_group.group_id=principal_group_member.group_id \"\n            + \"JOIN principal ON principal.principal_id=principal_group_member.principal_id \"\n            + \"JOIN domain ON domain.domain_id=principal_group.domain_id \"\n            + \"WHERE principal_group_member.last_notified_time=? AND principal_group_member.server=?;\";\n    private static final String SQL_UPDATE_PRINCIPAL = \"UPDATE principal SET system_suspended=? WHERE name=?;\";\n    private static final String SQL_GET_PRINCIPAL = \"SELECT name FROM principal WHERE system_suspended=?;\";\n    private static final String SQL_INSERT_ROLE_TAG = \"INSERT INTO role_tags\"\n            + \"(role_id, role_tags.key, role_tags.value) VALUES (?,?,?);\";\n    private static final String SQL_ROLE_TAG_COUNT = \"SELECT COUNT(*) FROM role_tags WHERE role_id=?\";\n    private static final String SQL_DELETE_ROLE_TAG = \"DELETE FROM role_tags WHERE role_id=? AND role_tags.key=?;\";\n    private static final String SQL_GET_ROLE_TAGS = \"SELECT rt.key, rt.value FROM role_tags rt \"\n            + \"JOIN role r ON rt.role_id = r.role_id JOIN domain ON domain.domain_id=r.domain_id \"\n            + \"WHERE domain.name=? AND r.name=?\";\n    private static final String SQL_GET_DOMAIN_ROLE_TAGS = \"SELECT r.name, rt.key, rt.value FROM role_tags rt \"\n            + \"JOIN role r ON rt.role_id = r.role_id JOIN domain ON domain.domain_id=r.domain_id \"\n            + \"WHERE domain.name=?\";\n\n    private static final String SQL_INSERT_DOMAIN_TAG = \"INSERT INTO domain_tags\"\n        + \"(domain_id, domain_tags.key, domain_tags.value) VALUES (?,?,?);\";\n    private static final String SQL_DOMAIN_TAG_COUNT = \"SELECT COUNT(*) FROM domain_tags WHERE domain_id=?\";\n    private static final String SQL_DELETE_DOMAIN_TAG = \"DELETE FROM domain_tags WHERE domain_id=? AND domain_tags.key=?;\";\n    private static final String SQL_GET_DOMAIN_TAGS = \"SELECT dt.key, dt.value FROM domain_tags dt \"\n        + \"JOIN domain d ON dt.domain_id = d.domain_id WHERE d.name=?\";\n    private static final String SQL_LOOKUP_DOMAIN_BY_TAG_KEY = \"SELECT d.name FROM domain d \"\n        + \"JOIN domain_tags dt ON dt.domain_id = d.domain_id WHERE dt.key=?\";\n    private static final String SQL_LOOKUP_DOMAIN_BY_TAG_KEY_VAL = \"SELECT d.name FROM domain d \"\n        + \"JOIN domain_tags dt ON dt.domain_id = d.domain_id WHERE dt.key=? AND dt.value=?\";\n\n    private static final String CACHE_DOMAIN    = \"d:\";\n    private static final String CACHE_ROLE      = \"r:\";\n    private static final String CACHE_GROUP     = \"g:\";\n    private static final String CACHE_POLICY    = \"p:\";\n    private static final String CACHE_SERVICE   = \"s:\";\n    private static final String CACHE_PRINCIPAL = \"u:\";\n    private static final String CACHE_HOST      = \"h:\";\n    private static final String ALL_PRINCIPALS  = \"*\";\n\n    private static final String AWS_ARN_PREFIX  = \"arn:aws:iam::\";\n\n    private static final String MYSQL_SERVER_TIMEZONE = System.getProperty(ZMSConsts.ZMS_PROP_MYSQL_SERVER_TIMEZONE, \"GMT\");\n\n    private int roleTagsLimit = ZMSConsts.ZMS_DEFAULT_TAG_LIMIT;\n    private int domainTagsLimit = ZMSConsts.ZMS_DEFAULT_TAG_LIMIT;\n\n    Connection con;\n    boolean transactionCompleted;\n    int queryTimeout = 60;\n    Map<String, Integer> objectMap;\n\n    public JDBCConnection(Connection con, boolean autoCommit) throws SQLException {\n        this.con = con;\n        con.setAutoCommit(autoCommit);\n        transactionCompleted = autoCommit;\n        objectMap = new HashMap<>();\n    }\n\n    @Override\n    public void setOperationTimeout(int queryTimeout) {\n        this.queryTimeout = queryTimeout;\n    }\n\n    @Override\n    public void setTagLimit(int domainLimit, int roleLimit) {\n        this.domainTagsLimit = domainLimit;\n        this.roleTagsLimit = roleLimit;\n    }\n\n    @Override\n    public void close() {\n\n        if (con == null) {\n            return;\n        }\n\n        // the client is always responsible for properly committing\n        // all changes before closing the connection, but in case\n        // we missed it, we're going to be safe and commit all\n        // changes before closing the connection\n\n        try {\n            commitChanges();\n        } catch (Exception ex) {\n            // error is already logged but we have to continue\n            // processing so we can close our connection\n        }\n\n        try {\n            con.close();\n            con = null;\n        } catch (SQLException ex) {\n            LOG.error(\"close: state - {}, code - {}, message - {}\", ex.getSQLState(),\n                    ex.getErrorCode(), ex.getMessage());\n        }\n    }\n\n    @Override\n    public void rollbackChanges() {\n\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"rollback transaction changes...\");\n        }\n\n        if (transactionCompleted) {\n            return;\n        }\n\n        try {\n            con.rollback();\n        } catch (SQLException ex) {\n            LOG.error(\"rollbackChanges: state - {}, code - {}, message - {}\", ex.getSQLState(),\n                    ex.getErrorCode(), ex.getMessage());\n        }\n\n        transactionCompleted = true;\n        try {\n            con.setAutoCommit(true);\n        } catch (SQLException ex) {\n            LOG.error(\"rollback auto-commit after failure: state - {}, code - {}, message - {}\",\n                    ex.getSQLState(), ex.getErrorCode(), ex.getMessage());\n        }\n    }\n\n    @Override\n    public void commitChanges() {\n\n        final String caller = \"commitChanges\";\n        if (transactionCompleted) {\n            return;\n        }\n\n        try {\n            con.commit();\n            transactionCompleted = true;\n            con.setAutoCommit(true);\n        } catch (SQLException ex) {\n            LOG.error(\"commitChanges: state - {}, code - {}, message - {}\", ex.getSQLState(),\n                    ex.getErrorCode(), ex.getMessage());\n            transactionCompleted = true;\n            throw sqlError(ex, caller);\n        }\n    }\n\n    int executeUpdate(PreparedStatement ps, String caller) throws SQLException {\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"{}: {}\", caller, ps.toString());\n        }\n        ps.setQueryTimeout(queryTimeout);\n        return ps.executeUpdate();\n    }\n\n    ResultSet executeQuery(PreparedStatement ps, String caller) throws SQLException {\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"{}: {}\", caller, ps.toString());\n        }\n        ps.setQueryTimeout(queryTimeout);\n        return ps.executeQuery();\n    }\n\n    Domain saveDomainSettings(String domainName, ResultSet rs, boolean fetchTags) throws SQLException {\n        Domain domain = new Domain().setName(domainName)\n                .setAuditEnabled(rs.getBoolean(ZMSConsts.DB_COLUMN_AUDIT_ENABLED))\n                .setEnabled(rs.getBoolean(ZMSConsts.DB_COLUMN_ENABLED))\n                .setModified(Timestamp.fromMillis(rs.getTimestamp(ZMSConsts.DB_COLUMN_MODIFIED).getTime()))\n                .setDescription(saveValue(rs.getString(ZMSConsts.DB_COLUMN_DESCRIPTION)))\n                .setOrg(saveValue(rs.getString(ZMSConsts.DB_COLUMN_ORG)))\n                .setId(saveUuidValue(rs.getString(ZMSConsts.DB_COLUMN_UUID)))\n                .setAccount(saveValue(rs.getString(ZMSConsts.DB_COLUMN_ACCOUNT)))\n                .setAzureSubscription(saveValue(rs.getString(ZMSConsts.DB_COLUMN_AZURE_SUBSCRIPTION)))\n                .setYpmId(rs.getInt(ZMSConsts.DB_COLUMN_PRODUCT_ID))\n                .setCertDnsDomain(saveValue(rs.getString(ZMSConsts.DB_COLUMN_CERT_DNS_DOMAIN)))\n                .setMemberExpiryDays(nullIfDefaultValue(rs.getInt(ZMSConsts.DB_COLUMN_MEMBER_EXPIRY_DAYS), 0))\n                .setTokenExpiryMins(nullIfDefaultValue(rs.getInt(ZMSConsts.DB_COLUMN_TOKEN_EXPIRY_MINS), 0))\n                .setRoleCertExpiryMins(nullIfDefaultValue(rs.getInt(ZMSConsts.DB_COLUMN_ROLE_CERT_EXPIRY_MINS), 0))\n                .setServiceCertExpiryMins(nullIfDefaultValue(rs.getInt(ZMSConsts.DB_COLUMN_SERVICE_CERT_EXPIRY_MINS), 0))\n                .setApplicationId(saveValue(rs.getString(ZMSConsts.DB_COLUMN_APPLICATION_ID)))\n                .setSignAlgorithm(saveValue(rs.getString(ZMSConsts.DB_COLUMN_SIGN_ALGORITHM)))\n                .setServiceExpiryDays(nullIfDefaultValue(rs.getInt(ZMSConsts.DB_COLUMN_SERVICE_EXPIRY_DAYS), 0))\n                .setGroupExpiryDays(nullIfDefaultValue(rs.getInt(ZMSConsts.DB_COLUMN_GROUP_EXPIRY_DAYS), 0))\n                .setUserAuthorityFilter(saveValue(rs.getString(ZMSConsts.DB_COLUMN_USER_AUTHORITY_FILTER)))\n                .setBusinessService(saveValue(rs.getString(ZMSConsts.DB_COLUMN_BUSINESS_SERVICE)));\n        if (fetchTags) {\n            domain.setTags(getDomainTags(domainName));\n        }\n        return domain;\n    }\n\n    @Override\n    public Domain getDomain(String domainName) {\n\n        final String caller = \"getDomain\";\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_DOMAIN)) {\n            ps.setString(1, domainName);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    return saveDomainSettings(domainName, rs, true);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return null;\n    }\n\n    @Override\n    public boolean insertDomain(Domain domain) {\n\n        int affectedRows;\n        final String caller = \"insertDomain\";\n\n        // we need to verify that our account and product ids are unique\n        // in the store. we can't rely on db uniqueness check since\n        // some of the domains will not have these attributes set\n\n        verifyDomainAccountUniqueness(domain.getName(), domain.getAccount(), caller);\n        verifyDomainSubscriptionUniqueness(domain.getName(), domain.getAzureSubscription(), caller);\n        verifyDomainProductIdUniqueness(domain.getName(), domain.getYpmId(), caller);\n        verifyDomainNameDashUniqueness(domain.getName(), caller);\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_INSERT_DOMAIN)) {\n            ps.setString(1, domain.getName());\n            ps.setString(2, processInsertValue(domain.getDescription()));\n            ps.setString(3, processInsertValue(domain.getOrg()));\n            ps.setString(4, processInsertUuidValue(domain.getId()));\n            ps.setBoolean(5, processInsertValue(domain.getEnabled(), true));\n            ps.setBoolean(6, processInsertValue(domain.getAuditEnabled(), false));\n            ps.setString(7, processInsertValue(domain.getAccount()));\n            ps.setInt(8, processInsertValue(domain.getYpmId()));\n            ps.setString(9, processInsertValue(domain.getApplicationId()));\n            ps.setString(10, processInsertValue(domain.getCertDnsDomain()));\n            ps.setInt(11, processInsertValue(domain.getMemberExpiryDays()));\n            ps.setInt(12, processInsertValue(domain.getTokenExpiryMins()));\n            ps.setInt(13, processInsertValue(domain.getServiceCertExpiryMins()));\n            ps.setInt(14, processInsertValue(domain.getRoleCertExpiryMins()));\n            ps.setString(15, processInsertValue(domain.getSignAlgorithm()));\n            ps.setInt(16, processInsertValue(domain.getServiceExpiryDays()));\n            ps.setString(17, processInsertValue(domain.getUserAuthorityFilter()));\n            ps.setInt(18, processInsertValue(domain.getGroupExpiryDays()));\n            ps.setString(19, processInsertValue(domain.getAzureSubscription()));\n            ps.setString(20, processInsertValue(domain.getBusinessService()));\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    void verifyDomainNameDashUniqueness(final String name, String caller) {\n\n        // with our certificates we replace .'s with -'s\n        // so we need to make sure we don't allow creation\n        // of domains such as sports.api and sports-api since\n        // they'll have the same component value\n\n        final String domainMatch = name.replace('.', '-');\n        final String domainQuery = name.replace('.', '_').replace('-', '_');\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_DOMAINS_WITH_NAME)) {\n            ps.setString(1, domainQuery);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    final String domainName = rs.getString(1);\n                    if (domainMatch.equals(domainName.replace('.', '-'))) {\n                        throw requestError(caller, \"Domain name conflict: \" + domainName);\n                    }\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n    }\n\n    void verifyDomainProductIdUniqueness(String name, Integer productId, String caller) {\n\n        if (productId == null || productId == 0) {\n            return;\n        }\n\n        String domainName = lookupDomainById(null, null, productId);\n        if (domainName != null && !domainName.equals(name)) {\n            throw requestError(caller, \"Product Id: \" + productId +\n                    \" is already assigned to domain: \" + domainName);\n        }\n    }\n\n    void verifyDomainAccountUniqueness(final String name, final String account, final String caller) {\n\n        if (account == null || account.isEmpty()) {\n            return;\n        }\n\n        String domainName = lookupDomainById(account, null, 0);\n        if (domainName != null && !domainName.equals(name)) {\n            throw requestError(caller, \"Account Id: \" + account +\n                    \" is already assigned to domain: \" + domainName);\n        }\n    }\n\n    void verifyDomainSubscriptionUniqueness(final String name, final String subscription, final String caller) {\n\n        if (subscription == null || subscription.isEmpty()) {\n            return;\n        }\n\n        String domainName = lookupDomainById(null, subscription, 0);\n        if (domainName != null && !domainName.equals(name)) {\n            throw requestError(caller, \"Subscription Id: \" + subscription +\n                    \" is already assigned to domain: \" + domainName);\n        }\n    }\n\n    @Override\n    public boolean updateDomain(Domain domain) {\n\n        int affectedRows;\n        final String caller = \"updateDomain\";\n\n        // we need to verify that our account and product ids are unique\n        // in the store. we can't rely on db uniqueness check since\n        // some of the domains will not have these attributes set\n\n        verifyDomainAccountUniqueness(domain.getName(), domain.getAccount(), caller);\n        verifyDomainSubscriptionUniqueness(domain.getName(), domain.getAzureSubscription(), caller);\n        verifyDomainProductIdUniqueness(domain.getName(), domain.getYpmId(), caller);\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_UPDATE_DOMAIN)) {\n            ps.setString(1, processInsertValue(domain.getDescription()));\n            ps.setString(2, processInsertValue(domain.getOrg()));\n            ps.setString(3, processInsertUuidValue(domain.getId()));\n            ps.setBoolean(4, processInsertValue(domain.getEnabled(), true));\n            ps.setBoolean(5, processInsertValue(domain.getAuditEnabled(), false));\n            ps.setString(6, processInsertValue(domain.getAccount()));\n            ps.setInt(7, processInsertValue(domain.getYpmId()));\n            ps.setString(8, processInsertValue(domain.getApplicationId()));\n            ps.setString(9, processInsertValue(domain.getCertDnsDomain()));\n            ps.setInt(10, processInsertValue(domain.getMemberExpiryDays()));\n            ps.setInt(11, processInsertValue(domain.getTokenExpiryMins()));\n            ps.setInt(12, processInsertValue(domain.getServiceCertExpiryMins()));\n            ps.setInt(13, processInsertValue(domain.getRoleCertExpiryMins()));\n            ps.setString(14, processInsertValue(domain.getSignAlgorithm()));\n            ps.setInt(15, processInsertValue(domain.getServiceExpiryDays()));\n            ps.setString(16, processInsertValue(domain.getUserAuthorityFilter()));\n            ps.setInt(17, processInsertValue(domain.getGroupExpiryDays()));\n            ps.setString(18, processInsertValue(domain.getAzureSubscription()));\n            ps.setString(19, processInsertValue(domain.getBusinessService()));\n            ps.setString(20, domain.getName());\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        // invalidate the cache domain entry\n\n        objectMap.remove(CACHE_DOMAIN + domain.getName());\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public boolean updateDomainModTimestamp(String domainName) {\n\n        int affectedRows;\n        final String caller = \"updateDomainModTimestamp\";\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_UPDATE_DOMAIN_MOD_TIMESTAMP)) {\n            ps.setString(1, domainName);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public long getDomainModTimestamp(String domainName) {\n\n        long modTime = 0;\n        final String caller = \"getDomainModTimestamp\";\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_DOMAIN_MOD_TIMESTAMP)) {\n            ps.setString(1, domainName);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    modTime = rs.getTimestamp(1).getTime();\n                }\n            }\n        } catch (SQLException ex) {\n            // ignore any failures and return default value 0\n        }\n        return modTime;\n    }\n\n    @Override\n    public boolean deleteDomain(String domainName) {\n\n        int affectedRows;\n        final String caller = \"deleteDomain\";\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_DELETE_DOMAIN)) {\n            ps.setString(1, domainName);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    PreparedStatement prepareDomainScanStatement(String prefix, long modifiedSince)\n            throws SQLException {\n\n        PreparedStatement ps;\n        if (prefix != null && prefix.length() > 0) {\n            int len = prefix.length();\n            char c = (char) (prefix.charAt(len - 1) + 1);\n            String stop = prefix.substring(0, len - 1) + c;\n            if (modifiedSince != 0) {\n                ps = con.prepareStatement(SQL_LIST_DOMAIN_PREFIX_MODIFIED);\n                ps.setString(1, prefix);\n                ps.setString(2, stop);\n                Calendar cal = Calendar.getInstance(TimeZone.getTimeZone(MYSQL_SERVER_TIMEZONE));\n                ps.setTimestamp(3, new java.sql.Timestamp(modifiedSince), cal);\n            } else {\n                ps = con.prepareStatement(SQL_LIST_DOMAIN_PREFIX);\n                ps.setString(1, prefix);\n                ps.setString(2, stop);\n            }\n        } else if (modifiedSince != 0) {\n            ps = con.prepareStatement(SQL_LIST_DOMAIN_MODIFIED);\n            Calendar cal = Calendar.getInstance(TimeZone.getTimeZone(MYSQL_SERVER_TIMEZONE));\n            ps.setTimestamp(1, new java.sql.Timestamp(modifiedSince), cal);\n        } else {\n            ps = con.prepareStatement(SQL_LIST_DOMAIN);\n        }\n        return ps;\n    }\n\n\n    PreparedStatement prepareScanByRoleStatement(String roleMember, String roleName)\n            throws SQLException {\n\n        PreparedStatement ps;\n        boolean memberPresent = (roleMember != null && !roleMember.isEmpty());\n        boolean rolePresent = (roleName != null && !roleName.isEmpty());\n        if (memberPresent && rolePresent) {\n            ps = con.prepareStatement(SQL_LIST_DOMAIN_ROLE_NAME_MEMBER);\n            ps.setString(1, roleMember);\n            ps.setString(2, roleName);\n        } else if (memberPresent) {\n            ps = con.prepareStatement(SQL_LIST_DOMAIN_ROLE_MEMBER);\n            ps.setString(1, roleMember);\n        } else if (rolePresent) {\n            ps = con.prepareStatement(SQL_LIST_DOMAIN_ROLE_NAME);\n            ps.setString(1, roleName);\n        } else {\n            ps = con.prepareStatement(SQL_LIST_DOMAIN);\n        }\n        return ps;\n    }\n\n    @Override\n    public List<String> lookupDomainByRole(String roleMember, String roleName) {\n\n        final String caller = \"lookupDomainByRole\";\n\n        // it's possible that we'll get duplicate domain names returned\n        // from this result - e.g. when no role name is filtered on so\n        // we're going to automatically skip those by using a set\n\n        Set<String> uniqueDomains = new HashSet<>();\n        try (PreparedStatement ps = prepareScanByRoleStatement(roleMember, roleName)) {\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    uniqueDomains.add(rs.getString(ZMSConsts.DB_COLUMN_NAME));\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        List<String> domains = new ArrayList<>(uniqueDomains);\n        Collections.sort(domains);\n        return domains;\n    }\n\n    @Override\n    public List<String> lookupDomainByBusinessService(String businessService) {\n\n        final String caller = \"lookupDomainByBusinessService\";\n\n        List<String> domains = new ArrayList<>();\n        try (PreparedStatement ps = con.prepareStatement(SQL_LIST_DOMAIN_WITH_BUSINESS_SERVICE)) {\n            ps.setString(1, businessService.trim());\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    domains.add(rs.getString(ZMSConsts.DB_COLUMN_NAME));\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return domains;\n    }\n\n    @Override\n    public String lookupDomainById(String account, String subscription, int productId) {\n\n        final String caller = \"lookupDomain\";\n        String sqlCmd;\n        if (account != null) {\n            sqlCmd = SQL_GET_DOMAIN_WITH_ACCOUNT;\n        } else if (subscription != null) {\n            sqlCmd = SQL_GET_DOMAIN_WITH_SUBSCRIPTION;\n        } else {\n            sqlCmd = SQL_GET_DOMAIN_WITH_PRODUCT_ID;\n        }\n\n        String domainName = null;\n        try (PreparedStatement ps = con.prepareStatement(sqlCmd)) {\n\n            if (account != null) {\n                ps.setString(1, account.trim());\n            } else if (subscription != null) {\n                ps.setString(1, subscription.trim());\n            } else {\n                ps.setInt(1, productId);\n            }\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    domainName = rs.getString(1);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        return domainName;\n    }\n\n    @Override\n    public List<String> listDomains(String prefix, long modifiedSince) {\n\n        final String caller = \"listDomains\";\n\n        List<String> domains = new ArrayList<>();\n        try (PreparedStatement ps = prepareDomainScanStatement(prefix, modifiedSince)) {\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    domains.add(rs.getString(ZMSConsts.DB_COLUMN_NAME));\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        Collections.sort(domains);\n        return domains;\n    }\n\n    public boolean deleteDomainTags(String domainName, Set<String> tagsToRemove) {\n        final String caller = \"deleteDomainTags\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        boolean res = true;\n        for (String tagKey : tagsToRemove) {\n            try (PreparedStatement ps = con.prepareStatement(SQL_DELETE_DOMAIN_TAG)) {\n                ps.setInt(1, domainId);\n                ps.setString(2, processInsertValue(tagKey));\n                res &= (executeUpdate(ps, caller) > 0);\n            } catch (SQLException ex) {\n                throw sqlError(ex, caller);\n            }\n        }\n        return res;\n    }\n\n    public boolean insertDomainTags(String domainName, Map<String, StringList> tags) {\n        final String caller = \"updateDomainTags\";\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int curTagCount = getDomainTagsCount(domainId);\n        int remainingTagsToInsert = domainTagsLimit - curTagCount;\n        boolean res = true;\n        for (Map.Entry<String, StringList> e : tags.entrySet()) {\n            for (int i = 0; i < e.getValue().getList().size() && remainingTagsToInsert-- > 0; i++) {\n                String tagValue = e.getValue().getList().get(i);\n                try (PreparedStatement ps = con.prepareStatement(SQL_INSERT_DOMAIN_TAG)) {\n                    ps.setInt(1, domainId);\n                    ps.setString(2, processInsertValue(e.getKey()));\n                    ps.setString(3, processInsertValue(tagValue));\n                    res &= (executeUpdate(ps, caller) > 0);\n                } catch (SQLException ex) {\n                    throw sqlError(ex, caller);\n                }\n            }\n        }\n        if (remainingTagsToInsert < 0) {\n            LOG.info(\"Domain tags limit for domain: [{}] has reached\", domainName);\n        }\n        return res;\n    }\n\n    private int getDomainTagsCount(int domainId) {\n        final String caller = \"getDomainTagsCount\";\n        int count = 0;\n        try (PreparedStatement ps = con.prepareStatement(SQL_DOMAIN_TAG_COUNT)) {\n            ps.setInt(1, domainId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    count = rs.getInt(1);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return count;\n    }\n\n    public Map<String, StringList> getDomainTags(String domainName) {\n        final String caller = \"getDomainTags\";\n        Map<String, StringList> domainTag = null;\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_DOMAIN_TAGS)) {\n            ps.setString(1, domainName);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    String tagKey = rs.getString(1);\n                    String tagValue = rs.getString(2);\n                    if (domainTag == null) {\n                        domainTag = new HashMap<>();\n                    }\n                    StringList tagValues = domainTag.computeIfAbsent(tagKey, k -> new StringList().setList(new ArrayList<>()));\n                    tagValues.getList().add(tagValue);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return domainTag;\n    }\n\n    public List<String> lookupDomainByTags(String tagKey, String tagValue) {\n        final String caller = \"lookupDomainByTags\";\n\n        // since domain tag might include multiple values - duplicates\n        // are possible. use Set to avoid duplicates\n\n        Set<String> uniqueDomains = new HashSet<>();\n\n        try (PreparedStatement ps = prepareScanByTags(tagKey, tagValue)) {\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    uniqueDomains.add(rs.getString(ZMSConsts.DB_COLUMN_NAME));\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        List<String> domains = new ArrayList<>(uniqueDomains);\n        Collections.sort(domains);\n        return domains;\n    }\n\n    PreparedStatement prepareScanByTags(String tagKey, String tagValue) throws SQLException {\n        PreparedStatement ps;\n        if (!StringUtil.isEmpty(tagValue)) {\n            ps = con.prepareStatement(SQL_LOOKUP_DOMAIN_BY_TAG_KEY_VAL);\n            ps.setString(1, tagKey);\n            ps.setString(2, tagValue);\n        } else {\n            ps = con.prepareStatement(SQL_LOOKUP_DOMAIN_BY_TAG_KEY);\n            ps.setString(1, tagKey);\n        }\n        return ps;\n    }\n\n    @Override\n    public boolean insertDomainTemplate(String domainName, String templateName, String params) {\n\n        final String caller = \"insertDomainTemplate\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int affectedRows;\n        try (PreparedStatement ps = con.prepareStatement(SQL_INSERT_DOMAIN_TEMPLATE)) {\n            ps.setInt(1, domainId);\n            ps.setString(2, templateName);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public boolean updateDomainTemplate(String domainName, String templateName, TemplateMetaData templateMetaData) {\n\n        final String caller = \"updateDomainTemplate\";\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int affectedRows;\n        try (PreparedStatement ps = con.prepareStatement(SQL_UPDATE_DOMAIN_TEMPLATE)) {\n            ps.setInt(1, templateMetaData.getLatestVersion());\n            ps.setInt(2, domainId);\n            ps.setString(3, templateName);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n\n    @Override\n    public boolean deleteDomainTemplate(String domainName, String templateName, String params) {\n\n        final String caller = \"deleteDomainTemplate\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int affectedRows;\n        try (PreparedStatement ps = con.prepareStatement(SQL_DELETE_DOMAIN_TEMPLATE)) {\n            ps.setInt(1, domainId);\n            ps.setString(2, templateName);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public List<String> listDomainTemplates(String domainName) {\n\n        final String caller = \"listDomainTemplates\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        List<String> templates = new ArrayList<>();\n        try (PreparedStatement ps = con.prepareStatement(SQL_LIST_DOMAIN_TEMPLATE)) {\n            ps.setString(1, domainName);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    templates.add(rs.getString(1));\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        Collections.sort(templates);\n        return templates;\n    }\n\n    @Override\n    public Map<String, List<String>> getDomainFromTemplateName(Map<String, Integer> templateNameAndLatestVersion) {\n        final String caller = \"getDomainsFromTemplate\";\n        Map<String, List<String>> domainNameTemplateListMap = new HashMap<>();\n\n        try (PreparedStatement ps = con.prepareStatement(generateDomainTemplateVersionQuery(templateNameAndLatestVersion))) {\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    String domainName = rs.getString(ZMSConsts.DB_COLUMN_NAME);\n                    String templateName = rs.getString(ZMSConsts.DB_COLUMN_TEMPLATE_NAME);\n                    if (domainNameTemplateListMap.get(domainName) != null) {\n                        List<String> tempTemplateList = domainNameTemplateListMap.get(domainName);\n                        tempTemplateList.add(templateName);\n                    } else {\n                        List<String> templateList = new ArrayList<>();\n                        templateList.add(templateName);\n                        domainNameTemplateListMap.put(domainName, templateList);\n                    }\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        return domainNameTemplateListMap;\n    }\n\n    int getDomainId(String domainName) {\n        return getDomainId(domainName, false);\n    }\n\n    int getDomainId(String domainName, boolean domainStateCheck) {\n\n        final String caller = \"getDomainId\";\n\n        // first check to see if our cache contains this value\n        // otherwise we'll contact the MySQL Server\n\n        final String cacheKey = CACHE_DOMAIN + domainName;\n        Integer value = objectMap.get(cacheKey);\n        if (value != null) {\n            return value;\n        }\n\n        int domainId = 0;\n        final String sqlCommand = domainStateCheck ? SQL_GET_ACTIVE_DOMAIN_ID : SQL_GET_DOMAIN_ID;\n        try (PreparedStatement ps = con.prepareStatement(sqlCommand)) {\n            ps.setString(1, domainName);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    domainId = rs.getInt(1);\n                }\n            }\n        } catch (SQLException ex) {\n            LOG.error(\"unable to get domain id for name: {} error code: {} msg: {}\",\n                    domainName, ex.getErrorCode(), ex.getMessage());\n        }\n\n        // before returning the value update our cache\n\n        if (domainId != 0) {\n            objectMap.put(cacheKey, domainId);\n        }\n\n        return domainId;\n    }\n\n    int getPolicyId(int domainId, String policyName) {\n\n        final String caller = \"getPolicyId\";\n\n        // first check to see if our cache contains this value\n        // otherwise we'll contact the MySQL Server\n\n        final String cacheKey = CACHE_POLICY + domainId + '.' + policyName;\n\n        Integer value = objectMap.get(cacheKey);\n        if (value != null) {\n            return value;\n        }\n\n        int policyId = 0;\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_POLICY_ID)) {\n            ps.setInt(1, domainId);\n            ps.setString(2, policyName);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    policyId = rs.getInt(1);\n                }\n            }\n        } catch (SQLException ex) {\n            LOG.error(\"unable to get policy id for name: {} error code: {} msg: {}\",\n                    policyName, ex.getErrorCode(), ex.getMessage());\n        }\n\n        // before returning the value update our cache\n\n        if (policyId != 0) {\n            objectMap.put(cacheKey, policyId);\n        }\n\n        return policyId;\n    }\n\n    int getRoleId(int domainId, String roleName) {\n\n        final String caller = \"getRoleId\";\n\n        // first check to see if our cache contains this value\n        // otherwise we'll contact the MySQL Server\n\n        final String cacheKey = CACHE_ROLE + domainId + '.' + roleName;\n\n        Integer value = objectMap.get(cacheKey);\n        if (value != null) {\n            return value;\n        }\n\n        int roleId = 0;\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_ROLE_ID)) {\n            ps.setInt(1, domainId);\n            ps.setString(2, roleName);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    roleId = rs.getInt(1);\n                }\n            }\n        } catch (SQLException ex) {\n            LOG.error(\"unable to get role id for name: {} error code: {} msg: {}\",\n                    roleName, ex.getErrorCode(), ex.getMessage());\n        }\n\n        // before returning the value update our cache\n\n        if (roleId != 0) {\n            objectMap.put(cacheKey, roleId);\n        }\n\n        return roleId;\n    }\n\n    int getGroupId(int domainId, final String groupName) {\n\n        final String caller = \"getGroupId\";\n\n        // first check to see if our cache contains this value\n        // otherwise we'll contact the MySQL Server\n\n        final String cacheKey = CACHE_GROUP + domainId + '.' + groupName;\n\n        Integer value = objectMap.get(cacheKey);\n        if (value != null) {\n            return value;\n        }\n\n        int groupId = 0;\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_GROUP_ID)) {\n            ps.setInt(1, domainId);\n            ps.setString(2, groupName);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    groupId = rs.getInt(1);\n                }\n            }\n        } catch (SQLException ex) {\n            LOG.error(\"unable to get group id for name: {} error code: {} msg: {}\",\n                    groupName, ex.getErrorCode(), ex.getMessage());\n        }\n\n        // before returning the value update our cache\n\n        if (groupId != 0) {\n            objectMap.put(cacheKey, groupId);\n        }\n\n        return groupId;\n    }\n\n    int getServiceId(int domainId, String serviceName) {\n\n        final String caller = \"getServiceId\";\n\n        // first check to see if our cache contains this value\n        // otherwise we'll contact the MySQL Server\n\n        final String cacheKey = CACHE_SERVICE + domainId + '.' + serviceName;\n\n        Integer value = objectMap.get(cacheKey);\n        if (value != null) {\n            return value;\n        }\n\n        int serviceId = 0;\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_SERVICE_ID)) {\n            ps.setInt(1, domainId);\n            ps.setString(2, serviceName);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    serviceId = rs.getInt(1);\n                }\n            }\n        } catch (SQLException ex) {\n            LOG.error(\"unable to get service id for name: {} error code: {} msg: {}\",\n                    serviceName, ex.getErrorCode(), ex.getMessage());\n        }\n\n        // before returning the value update our cache\n\n        if (serviceId != 0) {\n            objectMap.put(cacheKey, serviceId);\n        }\n\n        return serviceId;\n    }\n\n    int getPrincipalId(String principal) {\n\n        final String caller = \"getPrincipalId\";\n\n        // first check to see if our cache contains this value\n        // otherwise we'll contact the MySQL Server\n\n        final String cacheKey = CACHE_PRINCIPAL + principal;\n        Integer value = objectMap.get(cacheKey);\n        if (value != null) {\n            return value;\n        }\n\n        int principalId = 0;\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_PRINCIPAL_ID)) {\n            ps.setString(1, principal);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    principalId = rs.getInt(1);\n                }\n            }\n        } catch (SQLException ex) {\n            LOG.error(\"unable to get principal id for name: {} error code: {} msg: {}\",\n                    principal, ex.getErrorCode(), ex.getMessage());\n        }\n\n        // before returning the value update our cache\n\n        if (principalId != 0) {\n            objectMap.put(cacheKey, principalId);\n        }\n\n        return principalId;\n    }\n\n    int getHostId(String hostName) {\n\n        final String caller = \"getHostId\";\n\n        // first check to see if our cache contains this value\n        // otherwise we'll contact the MySQL Server\n\n        final String cacheKey = CACHE_HOST + hostName;\n        Integer value = objectMap.get(cacheKey);\n        if (value != null) {\n            return value;\n        }\n\n        int hostId = 0;\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_HOST_ID)) {\n            ps.setString(1, hostName);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    hostId = rs.getInt(1);\n                }\n            }\n        } catch (SQLException ex) {\n            LOG.error(\"unable to get host id for name: {} error code: {} msg: {}\",\n                    hostName, ex.getErrorCode(), ex.getMessage());\n        }\n\n        // before returning the value update our cache\n\n        if (hostId != 0) {\n            objectMap.put(cacheKey, hostId);\n        }\n\n        return hostId;\n    }\n\n    int getLastInsertId() {\n\n        int lastInsertId = 0;\n        final String caller = \"getLastInsertId\";\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_LAST_INSERT_ID)) {\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    lastInsertId = rs.getInt(1);\n                }\n            }\n        } catch (SQLException ex) {\n            LOG.error(\"unable to get last insert id - error code: {} msg: {}\",\n                    ex.getErrorCode(), ex.getMessage());\n        }\n        return lastInsertId;\n    }\n\n    PreparedStatement preparePrincipalScanStatement(String domainName)\n            throws SQLException {\n\n        PreparedStatement ps;\n        if (domainName != null && domainName.length() > 0) {\n            final String principalPattern = domainName + \".%\";\n            ps = con.prepareStatement(SQL_LIST_PRINCIPAL_DOMAIN);\n            ps.setString(1, principalPattern);\n        } else {\n            ps = con.prepareStatement(SQL_LIST_PRINCIPAL);\n        }\n        return ps;\n    }\n\n    @Override\n    public List<String> listPrincipals(String domainName) {\n\n        final String caller = \"listPrincipals\";\n\n        List<String> principals = new ArrayList<>();\n        try (PreparedStatement ps = preparePrincipalScanStatement(domainName)) {\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    principals.add(rs.getString(ZMSConsts.DB_COLUMN_NAME));\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return principals;\n    }\n\n    @Override\n    public boolean deletePrincipal(String principalName, boolean subDomains) {\n\n        final String caller = \"deletePrincipal\";\n\n        // first we're going to delete the principal from the principal table\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_DELETE_PRINCIPAL)) {\n            ps.setString(1, principalName);\n            executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        // next delete any principal that was created in the principal's\n        // sub-domains. These will be in the format \"principal.%\"\n\n        if (subDomains) {\n            final String domainPattern = principalName + \".%\";\n            try (PreparedStatement ps = con.prepareStatement(SQL_DELETE_SUB_PRINCIPALS)) {\n                ps.setString(1, domainPattern);\n                executeUpdate(ps, caller);\n            } catch (SQLException ex) {\n                throw sqlError(ex, caller);\n            }\n        }\n\n        return true;\n    }\n\n    @Override\n    public Role getRole(String domainName, String roleName) {\n\n        final String caller = \"getRole\";\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_ROLE)) {\n            ps.setString(1, domainName);\n            ps.setString(2, roleName);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    return retrieveRole(rs, domainName, roleName);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return null;\n    }\n\n    @Override\n    public boolean insertRole(String domainName, Role role) {\n\n        int affectedRows;\n        final String caller = \"insertRole\";\n\n        String roleName = ZMSUtils.extractRoleName(domainName, role.getName());\n        if (roleName == null) {\n            throw requestError(caller, \"domain name mismatch: \" + domainName +\n                    \" insert role name: \" + role.getName());\n        }\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        try (PreparedStatement ps = con.prepareStatement(SQL_INSERT_ROLE)) {\n            ps.setString(1, roleName);\n            ps.setInt(2, domainId);\n            ps.setString(3, processInsertValue(role.getTrust()));\n            ps.setBoolean(4, processInsertValue(role.getAuditEnabled(), false));\n            ps.setBoolean(5, processInsertValue(role.getSelfServe(), false));\n            ps.setInt(6, processInsertValue(role.getMemberExpiryDays()));\n            ps.setInt(7, processInsertValue(role.getTokenExpiryMins()));\n            ps.setInt(8, processInsertValue(role.getCertExpiryMins()));\n            ps.setString(9, processInsertValue(role.getSignAlgorithm()));\n            ps.setInt(10, processInsertValue(role.getServiceExpiryDays()));\n            ps.setInt(11, processInsertValue(role.getMemberReviewDays()));\n            ps.setInt(12, processInsertValue(role.getServiceReviewDays()));\n            ps.setBoolean(13, processInsertValue(role.getReviewEnabled(), false));\n            ps.setString(14, processInsertValue(role.getNotifyRoles()));\n            ps.setString(15, processInsertValue(role.getUserAuthorityFilter()));\n            ps.setString(16, processInsertValue(role.getUserAuthorityExpiration()));\n            ps.setInt(17, processInsertValue(role.getGroupExpiryDays()));\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public boolean updateRole(String domainName, Role role) {\n\n        int affectedRows;\n        final String caller = \"updateRole\";\n\n        String roleName = ZMSUtils.extractRoleName(domainName, role.getName());\n        if (roleName == null) {\n            throw requestError(caller, \"domain name mismatch: \" + domainName +\n                    \" update role name: \" + role.getName());\n        }\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int roleId = getRoleId(domainId, roleName);\n        if (roleId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_ROLE, ResourceUtils.roleResourceName(domainName, roleName));\n        }\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_UPDATE_ROLE)) {\n            ps.setString(1, processInsertValue(role.getTrust()));\n            ps.setBoolean(2, processInsertValue(role.getAuditEnabled(), false));\n            ps.setBoolean(3, processInsertValue(role.getSelfServe(), false));\n            ps.setInt(4, processInsertValue(role.getMemberExpiryDays()));\n            ps.setInt(5, processInsertValue(role.getTokenExpiryMins()));\n            ps.setInt(6, processInsertValue(role.getCertExpiryMins()));\n            ps.setString(7, processInsertValue(role.getSignAlgorithm()));\n            ps.setInt(8, processInsertValue(role.getServiceExpiryDays()));\n            ps.setInt(9, processInsertValue(role.getMemberReviewDays()));\n            ps.setInt(10, processInsertValue(role.getServiceReviewDays()));\n            ps.setBoolean(11, processInsertValue(role.getReviewEnabled(), false));\n            ps.setString(12, processInsertValue(role.getNotifyRoles()));\n            ps.setString(13, processInsertValue(role.getUserAuthorityFilter()));\n            ps.setString(14, processInsertValue(role.getUserAuthorityExpiration()));\n            ps.setInt(15, processInsertValue(role.getGroupExpiryDays()));\n            ps.setInt(16, roleId);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public boolean updateRoleModTimestamp(String domainName, String roleName) {\n\n        int affectedRows;\n        final String caller = \"updateRoleModTimestamp\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int roleId = getRoleId(domainId, roleName);\n        if (roleId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_ROLE, ResourceUtils.roleResourceName(domainName, roleName));\n        }\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_UPDATE_ROLE_MOD_TIMESTAMP)) {\n            ps.setInt(1, roleId);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public boolean updateRoleReviewTimestamp(String domainName, String roleName) {\n\n        int affectedRows;\n        final String caller = \"updateRoleReviewTimestamp\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int roleId = getRoleId(domainId, roleName);\n        if (roleId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_ROLE, ResourceUtils.roleResourceName(domainName, roleName));\n        }\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_UPDATE_ROLE_REVIEW_TIMESTAMP)) {\n            ps.setInt(1, roleId);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public boolean updateServiceIdentityModTimestamp(String domainName, String serviceName) {\n\n        int affectedRows;\n        final String caller = \"updateServiceIdentityModTimestamp\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int serviceId = getServiceId(domainId, serviceName);\n        if (serviceId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_SERVICE, ResourceUtils.serviceResourceName(domainName, serviceName));\n        }\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_UPDATE_SERVICE_MOD_TIMESTAMP)) {\n            ps.setInt(1, serviceId);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public boolean deleteRole(String domainName, String roleName) {\n\n        final String caller = \"deleteRole\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int affectedRows;\n        try (PreparedStatement ps = con.prepareStatement(SQL_DELETE_ROLE)) {\n            ps.setInt(1, domainId);\n            ps.setString(2, roleName);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public List<String> listRoles(String domainName) {\n\n        final String caller = \"listRoles\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        List<String> roles = new ArrayList<>();\n        try (PreparedStatement ps = con.prepareStatement(SQL_LIST_ROLE)) {\n            ps.setInt(1, domainId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    roles.add(rs.getString(1));\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        Collections.sort(roles);\n        return roles;\n    }\n\n    @Override\n    public int countRoles(String domainName) {\n\n        final String caller = \"countRoles\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int count = 0;\n        try (PreparedStatement ps = con.prepareStatement(SQL_COUNT_ROLE)) {\n            ps.setInt(1, domainId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    count = rs.getInt(1);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return count;\n    }\n\n    public static Comparator<RoleMember> RoleMemberComparator = (roleMember1, roleMember2) -> {\n        String roleMember1Name = roleMember1.getMemberName().toLowerCase();\n        String roleMember2Name = roleMember2.getMemberName().toLowerCase();\n        return roleMember1Name.compareTo(roleMember2Name);\n    };\n\n    public static Comparator<GroupMember> GroupMemberComparator = (groupMember1, groupMember2) -> {\n        String groupMember1Name = groupMember1.getMemberName().toLowerCase();\n        String groupMember2Name = groupMember2.getMemberName().toLowerCase();\n        return groupMember1Name.compareTo(groupMember2Name);\n    };\n\n    void getStdRoleMembers(int roleId, List<RoleMember> members, final String caller) {\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_LIST_ROLE_MEMBERS)) {\n            ps.setInt(1, roleId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    RoleMember roleMember = new RoleMember();\n                    roleMember.setMemberName(rs.getString(1));\n                    java.sql.Timestamp expiration = rs.getTimestamp(2);\n                    if (expiration != null) {\n                        roleMember.setExpiration(Timestamp.fromMillis(expiration.getTime()));\n                    }\n                    java.sql.Timestamp reviewReminder = rs.getTimestamp(3);\n                    if (reviewReminder != null) {\n                        roleMember.setReviewReminder(Timestamp.fromMillis(reviewReminder.getTime()));\n                    }\n                    roleMember.setActive(nullIfDefaultValue(rs.getBoolean(4), true));\n                    roleMember.setAuditRef(rs.getString(5));\n                    roleMember.setSystemDisabled(nullIfDefaultValue(rs.getInt(6), 0));\n                    roleMember.setApproved(true);\n                    members.add(roleMember);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n    }\n\n    void getPendingRoleMembers(int roleId, List<RoleMember> members, final String caller) {\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_LIST_PENDING_ROLE_MEMBERS)) {\n            ps.setInt(1, roleId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    RoleMember roleMember = new RoleMember();\n                    roleMember.setMemberName(rs.getString(1));\n                    java.sql.Timestamp timestamp = rs.getTimestamp(2);\n                    if (timestamp != null) {\n                        roleMember.setExpiration(Timestamp.fromMillis(timestamp.getTime()));\n                    }\n                    timestamp = rs.getTimestamp(3);\n                    if (timestamp != null) {\n                        roleMember.setReviewReminder(Timestamp.fromMillis(timestamp.getTime()));\n                    }\n                    timestamp = rs.getTimestamp(4);\n                    if (timestamp != null) {\n                        roleMember.setRequestTime(Timestamp.fromMillis(timestamp.getTime()));\n                    }\n                    roleMember.setAuditRef(rs.getString(5));\n                    roleMember.setActive(false);\n                    roleMember.setApproved(false);\n                    members.add(roleMember);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n    }\n\n    @Override\n    public List<RoleMember> listRoleMembers(String domainName, String roleName, Boolean pending) {\n\n        final String caller = \"listRoleMembers\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int roleId = getRoleId(domainId, roleName);\n        if (roleId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_ROLE, ResourceUtils.roleResourceName(domainName, roleName));\n        }\n\n        // first get our standard role members\n\n        List<RoleMember> members = new ArrayList<>();\n        getStdRoleMembers(roleId, members, caller);\n\n        // if requested, include pending members as well\n\n        if (pending == Boolean.TRUE) {\n            getPendingRoleMembers(roleId, members, caller);\n        }\n\n        members.sort(RoleMemberComparator);\n        return members;\n    }\n\n    @Override\n    public int countRoleMembers(String domainName, String roleName) {\n\n        final String caller = \"countRoleMembers\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int roleId = getRoleId(domainId, roleName);\n        if (roleId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_ROLE, ResourceUtils.roleResourceName(domainName, roleName));\n        }\n        int count = 0;\n        try (PreparedStatement ps = con.prepareStatement(SQL_COUNT_ROLE_MEMBERS)) {\n            ps.setInt(1, roleId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    count = rs.getInt(1);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return count;\n    }\n\n    @Override\n    public List<PrincipalRole> listPrincipalRoles(String domainName, String principalName) {\n\n        final String caller = \"listPrincipalRoles\";\n        if (domainName == null) {\n            return listPrincipalRolesForAllDomains(principalName, caller);\n        } else {\n            return listPrincipalRolesForOneDomain(domainName, principalName, caller);\n        }\n    }\n\n    List<PrincipalRole> listPrincipalRolesForAllDomains(String principalName, String caller) {\n\n        int principalId = getPrincipalId(principalName);\n        if (principalId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_PRINCIPAL, principalName);\n        }\n        List<PrincipalRole> roles = new ArrayList<>();\n        try (PreparedStatement ps = con.prepareStatement(SQL_LIST_PRINCIPAL_ROLES)) {\n            ps.setInt(1, principalId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    PrincipalRole role = new PrincipalRole();\n                    role.setDomainName(rs.getString(ZMSConsts.DB_COLUMN_NAME));\n                    role.setRoleName(rs.getString(ZMSConsts.DB_COLUMN_ROLE_NAME));\n                    roles.add(role);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return roles;\n    }\n\n    List<PrincipalRole> listPrincipalRolesForOneDomain(String domainName, String principalName, String caller) {\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int principalId = getPrincipalId(principalName);\n        if (principalId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_PRINCIPAL, principalName);\n        }\n        List<PrincipalRole> roles = new ArrayList<>();\n        try (PreparedStatement ps = con.prepareStatement(SQL_LIST_PRINCIPAL_DOMAIN_ROLES)) {\n            ps.setInt(1, principalId);\n            ps.setInt(2, domainId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    PrincipalRole role = new PrincipalRole();\n                    role.setRoleName(rs.getString(ZMSConsts.DB_COLUMN_ROLE_NAME));\n                    roles.add(role);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return roles;\n    }\n\n    @Override\n    public List<RoleAuditLog> listRoleAuditLogs(String domainName, String roleName) {\n\n        final String caller = \"listRoleAuditLogs\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int roleId = getRoleId(domainId, roleName);\n        if (roleId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_ROLE, ResourceUtils.roleResourceName(domainName, roleName));\n        }\n        List<RoleAuditLog> logs = new ArrayList<>();\n        try (PreparedStatement ps = con.prepareStatement(SQL_LIST_ROLE_AUDIT_LOGS)) {\n            ps.setInt(1, roleId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    RoleAuditLog log = new RoleAuditLog();\n                    log.setAction(rs.getString(ZMSConsts.DB_COLUMN_ACTION));\n                    log.setMember(rs.getString(ZMSConsts.DB_COLUMN_MEMBER));\n                    log.setAdmin(rs.getString(ZMSConsts.DB_COLUMN_ADMIN));\n                    log.setAuditRef(saveValue(rs.getString(ZMSConsts.DB_COLUMN_AUDIT_REF)));\n                    log.setCreated(Timestamp.fromMillis(rs.getTimestamp(ZMSConsts.DB_COLUMN_CREATED).getTime()));\n                    logs.add(log);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return logs;\n    }\n\n    boolean parsePrincipal(String principal, StringBuilder domain, StringBuilder name) {\n        int idx = principal.lastIndexOf('.');\n        if (idx == -1 || idx == 0 || idx == principal.length() - 1) {\n            return false;\n        }\n        domain.append(principal, 0, idx);\n        name.append(principal.substring(idx + 1));\n        return true;\n    }\n\n    boolean getRoleMembership(final String query, int roleId, final String member, long expiration,\n            Membership membership, boolean disabledFlagCheck, final String caller) {\n\n        try (PreparedStatement ps = con.prepareStatement(query)) {\n            ps.setInt(1, roleId);\n            ps.setString(2, member);\n            if (expiration != 0) {\n                ps.setTimestamp(3, new java.sql.Timestamp(expiration));\n            }\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    membership.setIsMember(true);\n                    java.sql.Timestamp expiry = rs.getTimestamp(ZMSConsts.DB_COLUMN_EXPIRATION);\n                    if (expiry != null) {\n                        membership.setExpiration(Timestamp.fromMillis(expiry.getTime()));\n                    }\n                    java.sql.Timestamp reviewReminder = rs.getTimestamp(ZMSConsts.DB_COLUMN_REVIEW_REMINDER);\n                    if (reviewReminder != null) {\n                        membership.setReviewReminder(Timestamp.fromMillis(reviewReminder.getTime()));\n                    }\n                    membership.setRequestPrincipal(rs.getString(ZMSConsts.DB_COLUMN_REQ_PRINCIPAL));\n                    if (disabledFlagCheck) {\n                        membership.setSystemDisabled(nullIfDefaultValue(rs.getInt(ZMSConsts.DB_COLUMN_SYSTEM_DISABLED), 0));\n                    }\n                    return true;\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return false;\n    }\n\n    @Override\n    public Membership getRoleMember(String domainName, String roleName, String member,\n            long expiration, boolean pending) {\n\n        final String caller = \"getRoleMember\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int roleId = getRoleId(domainId, roleName);\n        if (roleId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_ROLE, ResourceUtils.roleResourceName(domainName, roleName));\n        }\n\n        Membership membership = new Membership()\n                .setMemberName(member)\n                .setRoleName(ResourceUtils.roleResourceName(domainName, roleName))\n                .setIsMember(false);\n\n        // first we're going to check if we have a standard user with the given\n        // details before checking for pending unless we're specifically asking\n        // for pending member only in which case we'll skip the first check\n\n        if (!pending) {\n            String query = expiration == 0 ? SQL_GET_ROLE_MEMBER : SQL_GET_TEMP_ROLE_MEMBER;\n            if (getRoleMembership(query, roleId, member, expiration, membership, true, caller)) {\n                membership.setApproved(true);\n            }\n        }\n\n        if (!membership.getIsMember()) {\n            String query = expiration == 0 ? SQL_GET_PENDING_ROLE_MEMBER : SQL_GET_TEMP_PENDING_ROLE_MEMBER;\n            if (getRoleMembership(query, roleId, member, expiration, membership, false, caller)) {\n                membership.setApproved(false);\n            }\n        }\n\n        return membership;\n    }\n\n    int insertPrincipal(String principal) {\n\n        int affectedRows;\n        final String caller = \"insertPrincipal\";\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_INSERT_PRINCIPAL)) {\n            ps.setString(1, principal);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n\n            // it's possible that 2 threads try to add the same principal\n            // into different roles. so we're going to have a special\n            // handling here - if we get back entry already exists exception\n            // we're just going to lookup the principal id and return\n            // that instead of returning an exception\n\n            if (ex.getErrorCode() == MYSQL_ER_OPTION_DUPLICATE_ENTRY) {\n                return getPrincipalId(principal);\n            }\n\n            throw sqlError(ex, caller);\n        }\n\n        int principalId = 0;\n        if (affectedRows == 1) {\n            principalId = getLastInsertId();\n        }\n        return principalId;\n    }\n\n    int insertHost(String hostName) {\n\n        int affectedRows;\n        final String caller = \"insertHost\";\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_INSERT_HOST)) {\n            ps.setString(1, hostName);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        int hostId = 0;\n        if (affectedRows == 1) {\n            hostId = getLastInsertId();\n        }\n        return hostId;\n    }\n\n    boolean roleMemberExists(int roleId, int principalId, boolean pending, final String caller) {\n\n        String statement = pending ? SQL_PENDING_ROLE_MEMBER_EXISTS : SQL_STD_ROLE_MEMBER_EXISTS;\n        try (PreparedStatement ps = con.prepareStatement(statement)) {\n            ps.setInt(1, roleId);\n            ps.setInt(2, principalId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    return true;\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return false;\n    }\n\n    @Override\n    public boolean insertRoleMember(String domainName, String roleName, RoleMember roleMember,\n            String admin, String auditRef) {\n\n        final String caller = \"insertRoleMember\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int roleId = getRoleId(domainId, roleName);\n        if (roleId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_ROLE, ResourceUtils.roleResourceName(domainName, roleName));\n        }\n        String principal = roleMember.getMemberName();\n        if (!validatePrincipalDomain(principal)) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, principal);\n        }\n        int principalId = getPrincipalId(principal);\n        if (principalId == 0) {\n            principalId = insertPrincipal(principal);\n            if (principalId == 0) {\n                throw internalServerError(caller, \"Unable to insert principal: \" + principal);\n            }\n        }\n\n        // need to check if entry already exists\n\n        boolean pendingRequest = (roleMember.getApproved() == Boolean.FALSE);\n        boolean roleMemberExists = roleMemberExists(roleId, principalId, pendingRequest, caller);\n\n        // process the request based on the type of the request\n        // either pending request or standard insert\n\n        boolean result;\n        if (pendingRequest) {\n            result = insertPendingRoleMember(roleId, principalId, roleMember, admin,\n                    auditRef, roleMemberExists, caller);\n        } else {\n            result = insertStandardRoleMember(roleId, principalId, roleMember, admin,\n                    principal, auditRef, roleMemberExists, false, caller);\n        }\n        return result;\n    }\n\n    boolean insertPendingRoleMember(int roleId, int principalId, RoleMember roleMember,\n            final String admin, final String auditRef, boolean roleMemberExists, final String caller) {\n\n        java.sql.Timestamp expiration = null;\n        if (roleMember.getExpiration() != null) {\n            expiration = new java.sql.Timestamp(roleMember.getExpiration().toDate().getTime());\n        }\n        java.sql.Timestamp reviewReminder = null;\n        if (roleMember.getReviewReminder() != null) {\n            reviewReminder = new java.sql.Timestamp(roleMember.getReviewReminder().toDate().getTime());\n        }\n\n        int affectedRows;\n        if (roleMemberExists) {\n\n            try (PreparedStatement ps = con.prepareStatement(SQL_UPDATE_PENDING_ROLE_MEMBER)) {\n                ps.setTimestamp(1, expiration);\n                ps.setTimestamp(2, reviewReminder);\n                ps.setString(3, processInsertValue(auditRef));\n                ps.setString(4, processInsertValue(admin));\n                ps.setInt(5, roleId);\n                ps.setInt(6, principalId);\n                affectedRows = executeUpdate(ps, caller);\n            } catch (SQLException ex) {\n                throw sqlError(ex, caller);\n            }\n\n        } else {\n\n            try (PreparedStatement ps = con.prepareStatement(SQL_INSERT_PENDING_ROLE_MEMBER)) {\n                ps.setInt(1, roleId);\n                ps.setInt(2, principalId);\n                ps.setTimestamp(3, expiration);\n                ps.setTimestamp(4, reviewReminder);\n                ps.setString(5, processInsertValue(auditRef));\n                ps.setString(6, processInsertValue(admin));\n                affectedRows = executeUpdate(ps, caller);\n            } catch (SQLException ex) {\n                throw sqlError(ex, caller);\n            }\n        }\n\n        return (affectedRows > 0);\n    }\n\n    boolean insertStandardRoleMember(int roleId, int principalId, RoleMember roleMember,\n            final String admin, final String principal, final String auditRef,\n            boolean roleMemberExists, boolean approveRequest, final String caller) {\n\n        java.sql.Timestamp expiration = null;\n        if (roleMember.getExpiration() != null) {\n            expiration = new java.sql.Timestamp(roleMember.getExpiration().toDate().getTime());\n        }\n        java.sql.Timestamp reviewReminder = null;\n        if (roleMember.getReviewReminder() != null) {\n            reviewReminder = new java.sql.Timestamp(roleMember.getReviewReminder().toDate().getTime());\n        }\n\n        boolean result;\n        String auditOperation;\n\n        if (roleMemberExists) {\n\n            try (PreparedStatement ps = con.prepareStatement(SQL_UPDATE_ROLE_MEMBER)) {\n                ps.setTimestamp(1, expiration);\n                ps.setTimestamp(2, reviewReminder);\n                ps.setBoolean(3, processInsertValue(roleMember.getActive(), true));\n                ps.setString(4, processInsertValue(auditRef));\n                ps.setString(5, processInsertValue(admin));\n                ps.setInt(6, roleId);\n                ps.setInt(7, principalId);\n                executeUpdate(ps, caller);\n            } catch (SQLException ex) {\n                throw sqlError(ex, caller);\n            }\n            auditOperation = approveRequest ? \"APPROVE\" : \"UPDATE\";\n            result = true;\n\n        } else {\n\n            int affectedRows;\n            try (PreparedStatement ps = con.prepareStatement(SQL_INSERT_ROLE_MEMBER)) {\n                ps.setInt(1, roleId);\n                ps.setInt(2, principalId);\n                ps.setTimestamp(3, expiration);\n                ps.setTimestamp(4, reviewReminder);\n                ps.setBoolean(5, processInsertValue(roleMember.getActive(), true));\n                ps.setString(6, processInsertValue(auditRef));\n                ps.setString(7, processInsertValue(admin));\n                affectedRows = executeUpdate(ps, caller);\n            } catch (SQLException ex) {\n                throw sqlError(ex, caller);\n            }\n\n            auditOperation = approveRequest ? \"APPROVE\" : \"ADD\";\n            result = (affectedRows > 0);\n        }\n\n        // add audit log entry for this change if the operation was successful\n        // add return the result of the audit log insert operation\n\n        if (result) {\n            result = insertRoleAuditLog(roleId, admin, principal, auditOperation, auditRef);\n        }\n        return result;\n    }\n\n    @Override\n    public boolean updateRoleMemberDisabledState(String domainName, String roleName, String principal,\n            String admin, int disabledState, String auditRef) {\n\n        final String caller = \"updateRoleMemberDisabledState\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int roleId = getRoleId(domainId, roleName);\n        if (roleId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_ROLE, ResourceUtils.roleResourceName(domainName, roleName));\n        }\n        int principalId = getPrincipalId(principal);\n        if (principalId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_PRINCIPAL, principal);\n        }\n\n        int affectedRows;\n        try (PreparedStatement ps = con.prepareStatement(SQL_UPDATE_ROLE_MEMBER_DISABLED_STATE)) {\n            ps.setInt(1, disabledState);\n            ps.setString(2, processInsertValue(auditRef));\n            ps.setString(3, processInsertValue(admin));\n            ps.setInt(4, roleId);\n            ps.setInt(5, principalId);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        boolean result = (affectedRows > 0);\n\n        // add audit log entry for this change if the disable was successful\n        // add return the result of the audit log insert operation\n\n        if (result) {\n            final String operation = disabledState == 0 ? \"ENABLE\" : \"DISABLE\";\n            result = insertRoleAuditLog(roleId, admin, principal, operation, auditRef);\n        }\n\n        return result;\n    }\n\n    @Override\n    public boolean deleteRoleMember(String domainName, String roleName, String principal,\n            String admin, String auditRef) {\n\n        final String caller = \"deleteRoleMember\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int roleId = getRoleId(domainId, roleName);\n        if (roleId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_ROLE, ResourceUtils.roleResourceName(domainName, roleName));\n        }\n        int principalId = getPrincipalId(principal);\n        if (principalId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_PRINCIPAL, principal);\n        }\n        int affectedRows;\n        try (PreparedStatement ps = con.prepareStatement(SQL_DELETE_ROLE_MEMBER)) {\n            ps.setInt(1, roleId);\n            ps.setInt(2, principalId);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        boolean result = (affectedRows > 0);\n\n        // add audit log entry for this change if the delete was successful\n        // add return the result of the audit log insert operation\n\n        if (result) {\n            result = insertRoleAuditLog(roleId, admin, principal, \"DELETE\", auditRef);\n        }\n\n        return result;\n    }\n\n    boolean insertRoleAuditLog(int roleId, String admin, String member,\n            String action, String auditRef) {\n\n        int affectedRows;\n        final String caller = \"insertRoleAuditEntry\";\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_INSERT_ROLE_AUDIT_LOG)) {\n            ps.setInt(1, roleId);\n            ps.setString(2, processInsertValue(admin));\n            ps.setString(3, member);\n            ps.setString(4, action);\n            ps.setString(5, processInsertValue(auditRef));\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public Assertion getAssertion(String domainName, String policyName, Long assertionId) {\n\n        final String caller = \"getAssertion\";\n\n        Assertion assertion = null;\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_ASSERTION)) {\n            ps.setInt(1, assertionId.intValue());\n            ps.setString(2, domainName);\n            ps.setString(3, policyName);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    assertion = new Assertion();\n                    assertion.setRole(ResourceUtils.roleResourceName(domainName, rs.getString(ZMSConsts.DB_COLUMN_ROLE)));\n                    assertion.setResource(rs.getString(ZMSConsts.DB_COLUMN_RESOURCE));\n                    assertion.setAction(rs.getString(ZMSConsts.DB_COLUMN_ACTION));\n                    assertion.setEffect(AssertionEffect.valueOf(rs.getString(ZMSConsts.DB_COLUMN_EFFECT)));\n                    assertion.setId((long) rs.getInt(ZMSConsts.DB_COLUMN_ASSERT_ID));\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return assertion;\n    }\n\n    @Override\n    public Policy getPolicy(String domainName, String policyName) {\n\n        final String caller = \"getPolicy\";\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_POLICY)) {\n            ps.setString(1, domainName);\n            ps.setString(2, policyName);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    return new Policy().setName(ResourceUtils.policyResourceName(domainName, policyName))\n                            .setModified(Timestamp.fromMillis(rs.getTimestamp(ZMSConsts.DB_COLUMN_MODIFIED).getTime()));\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return null;\n    }\n\n    @Override\n    public boolean insertPolicy(String domainName, Policy policy) {\n\n        int affectedRows;\n        final String caller = \"insertPolicy\";\n\n        String policyName = ZMSUtils.extractPolicyName(domainName, policy.getName());\n        if (policyName == null) {\n            throw requestError(caller, \"domain name mismatch: \" + domainName +\n                    \" insert policy name: \" + policy.getName());\n        }\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        try (PreparedStatement ps = con.prepareStatement(SQL_INSERT_POLICY)) {\n            ps.setString(1, policyName);\n            ps.setInt(2, domainId);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public boolean updatePolicy(String domainName, Policy policy) {\n\n        int affectedRows;\n        final String caller = \"updatePolicy\";\n\n        String policyName = ZMSUtils.extractPolicyName(domainName, policy.getName());\n        if (policyName == null) {\n            throw requestError(caller, \"domain name mismatch: \" + domainName +\n                    \" update policy name: \" + policy.getName());\n        }\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int policyId = getPolicyId(domainId, policyName);\n        if (policyId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_POLICY, ResourceUtils.policyResourceName(domainName, policyName));\n        }\n        try (PreparedStatement ps = con.prepareStatement(SQL_UPDATE_POLICY)) {\n            ps.setString(1, policyName);\n            ps.setInt(2, policyId);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public boolean updatePolicyModTimestamp(String domainName, String policyName) {\n\n        int affectedRows;\n        final String caller = \"updatePolicyModTimestamp\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int policyId = getPolicyId(domainId, policyName);\n        if (policyId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_POLICY, ResourceUtils.policyResourceName(domainName, policyName));\n        }\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_UPDATE_POLICY_MOD_TIMESTAMP)) {\n            ps.setInt(1, policyId);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public boolean deletePolicy(String domainName, String policyName) {\n\n        final String caller = \"deletePolicy\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int affectedRows;\n        try (PreparedStatement ps = con.prepareStatement(SQL_DELETE_POLICY)) {\n            ps.setInt(1, domainId);\n            ps.setString(2, policyName);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public List<String> listPolicies(String domainName, String assertionRoleName) {\n\n        final String caller = \"listPolicies\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        List<String> policies = new ArrayList<>();\n        final String sqlStatement = (assertionRoleName == null) ? SQL_LIST_POLICY : SQL_LIST_POLICY_REFERENCING_ROLE;\n        try (PreparedStatement ps = con.prepareStatement(sqlStatement)) {\n            ps.setInt(1, domainId);\n            if (assertionRoleName != null) {\n                ps.setString(2, assertionRoleName);\n            }\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    policies.add(rs.getString(1));\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        Collections.sort(policies);\n        return policies;\n    }\n\n    @Override\n    public int countPolicies(String domainName) {\n\n        final String caller = \"countPolicies\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int count = 0;\n        try (PreparedStatement ps = con.prepareStatement(SQL_COUNT_POLICY)) {\n            ps.setInt(1, domainId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    count = rs.getInt(1);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return count;\n    }\n\n    @Override\n    public boolean insertAssertion(String domainName, String policyName, Assertion assertion) {\n\n        final String caller = \"insertAssertion\";\n\n        String roleName = ZMSUtils.extractRoleName(domainName, assertion.getRole());\n        if (roleName == null) {\n            throw requestError(caller, \"domain name mismatch: \" + domainName +\n                    \" assertion role name: \" + assertion.getRole());\n        }\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int policyId = getPolicyId(domainId, policyName);\n        if (policyId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_POLICY, ResourceUtils.policyResourceName(domainName, policyName));\n        }\n\n        // special handling for assertions since we don't want to have duplicates\n        // and we don't want to setup a unique key across all values in the row\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_CHECK_ASSERTION)) {\n            ps.setInt(1, policyId);\n            ps.setString(2, roleName);\n            ps.setString(3, assertion.getResource());\n            ps.setString(4, assertion.getAction());\n            ps.setString(5, processInsertValue(assertion.getEffect()));\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    return true;\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        // at this point we know we don't have another assertion with the same\n        // values so we'll go ahead and add one\n\n        int affectedRows;\n        try (PreparedStatement ps = con.prepareStatement(SQL_INSERT_ASSERTION)) {\n            ps.setInt(1, policyId);\n            ps.setString(2, roleName);\n            ps.setString(3, assertion.getResource());\n            ps.setString(4, assertion.getAction());\n            ps.setString(5, processInsertValue(assertion.getEffect()));\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        boolean result = (affectedRows > 0);\n\n        if (result) {\n            assertion.setId((long) getLastInsertId());\n        }\n        return result;\n    }\n\n    @Override\n    public boolean deleteAssertion(String domainName, String policyName, Long assertionId) {\n\n        final String caller = \"deleteAssertion\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int policyId = getPolicyId(domainId, policyName);\n        if (policyId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_POLICY, ResourceUtils.policyResourceName(domainName, policyName));\n        }\n\n        int affectedRows;\n        try (PreparedStatement ps = con.prepareStatement(SQL_DELETE_ASSERTION)) {\n            ps.setInt(1, policyId);\n            ps.setInt(2, assertionId.intValue());\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public List<Assertion> listAssertions(String domainName, String policyName) {\n\n        final String caller = \"listAssertions\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int policyId = getPolicyId(domainId, policyName);\n        if (policyId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_POLICY, ResourceUtils.policyResourceName(domainName, policyName));\n        }\n        List<Assertion> assertions = new ArrayList<>();\n        try (PreparedStatement ps = con.prepareStatement(SQL_LIST_ASSERTION)) {\n            ps.setInt(1, policyId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    Assertion assertion = new Assertion();\n                    assertion.setRole(ResourceUtils.roleResourceName(domainName, rs.getString(ZMSConsts.DB_COLUMN_ROLE)));\n                    assertion.setResource(rs.getString(ZMSConsts.DB_COLUMN_RESOURCE));\n                    assertion.setAction(rs.getString(ZMSConsts.DB_COLUMN_ACTION));\n                    assertion.setEffect(AssertionEffect.valueOf(rs.getString(ZMSConsts.DB_COLUMN_EFFECT)));\n                    assertion.setId((long) rs.getInt(ZMSConsts.DB_COLUMN_ASSERT_ID));\n                    assertions.add(assertion);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return assertions;\n    }\n\n    @Override\n    public int countAssertions(String domainName, String policyName) {\n\n        final String caller = \"countAssertions\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int policyId = getPolicyId(domainId, policyName);\n        if (policyId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_POLICY, ResourceUtils.policyResourceName(domainName, policyName));\n        }\n        int count = 0;\n        try (PreparedStatement ps = con.prepareStatement(SQL_COUNT_ASSERTION)) {\n            ps.setInt(1, policyId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    count = rs.getInt(1);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return count;\n    }\n\n    String saveValue(String value) {\n        return (value.isEmpty()) ? null : value;\n    }\n\n    UUID saveUuidValue(String value) {\n        return (value.isEmpty()) ? null : UUID.fromString(value);\n    }\n\n    @Override\n    public ServiceIdentity getServiceIdentity(String domainName, String serviceName) {\n\n        final String caller = \"getServiceIdentity\";\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_SERVICE)) {\n            ps.setString(1, domainName);\n            ps.setString(2, serviceName);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n\n                    return new ServiceIdentity()\n                            .setName(ResourceUtils.serviceResourceName(domainName, serviceName))\n                            .setDescription(saveValue(rs.getString(ZMSConsts.DB_COLUMN_DESCRIPTION)))\n                            .setModified(Timestamp.fromMillis(rs.getTimestamp(ZMSConsts.DB_COLUMN_MODIFIED).getTime()))\n                            .setProviderEndpoint(saveValue(rs.getString(ZMSConsts.DB_COLUMN_PROVIDER_ENDPOINT)))\n                            .setExecutable(saveValue(rs.getString(ZMSConsts.DB_COLUMN_EXECUTABLE)))\n                            .setUser(saveValue(rs.getString(ZMSConsts.DB_COLUMN_SVC_USER)))\n                            .setGroup(saveValue(rs.getString(ZMSConsts.DB_COLUMN_SVC_GROUP)));\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return null;\n    }\n\n    int processInsertValue(Integer value) {\n        return (value == null) ? 0 : value;\n    }\n\n    String processInsertValue(String value) {\n        return (value == null) ? \"\" : value.trim();\n    }\n\n    boolean processInsertValue(Boolean value, boolean defaultValue) {\n        return (value == null) ? defaultValue : value;\n    }\n\n    String processInsertValue(AssertionEffect value) {\n        return (value == null) ? ZMSConsts.ASSERTION_EFFECT_ALLOW : value.toString();\n    }\n\n    String processInsertUuidValue(UUID value) {\n        return (value == null) ? \"\" : value.toString();\n    }\n\n    @Override\n    public boolean insertServiceIdentity(String domainName, ServiceIdentity service) {\n\n        int affectedRows;\n        final String caller = \"insertServiceIdentity\";\n\n        String serviceName = ZMSUtils.extractServiceName(domainName, service.getName());\n        if (serviceName == null) {\n            throw requestError(caller, \"domain name mismatch: \" + domainName +\n                    \" insert service name: \" + service.getName());\n        }\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        try (PreparedStatement ps = con.prepareStatement(SQL_INSERT_SERVICE)) {\n            ps.setString(1, serviceName);\n            ps.setString(2, processInsertValue(service.getDescription()));\n            ps.setString(3, processInsertValue(service.getProviderEndpoint()));\n            ps.setString(4, processInsertValue(service.getExecutable()));\n            ps.setString(5, processInsertValue(service.getUser()));\n            ps.setString(6, processInsertValue(service.getGroup()));\n            ps.setInt(7, domainId);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public boolean updateServiceIdentity(String domainName, ServiceIdentity service) {\n\n        int affectedRows;\n        final String caller = \"updateServiceIdentity\";\n\n        String serviceName = ZMSUtils.extractServiceName(domainName, service.getName());\n        if (serviceName == null) {\n            throw requestError(caller, \"domain name mismatch: \" + domainName +\n                    \" update service name: \" + service.getName());\n        }\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int serviceId = getServiceId(domainId, serviceName);\n        if (serviceId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_SERVICE, ResourceUtils.serviceResourceName(domainName, serviceName));\n        }\n        try (PreparedStatement ps = con.prepareStatement(SQL_UPDATE_SERVICE)) {\n            ps.setString(1, processInsertValue(service.getDescription()));\n            ps.setString(2, processInsertValue(service.getProviderEndpoint()));\n            ps.setString(3, processInsertValue(service.getExecutable()));\n            ps.setString(4, processInsertValue(service.getUser()));\n            ps.setString(5, processInsertValue(service.getGroup()));\n            ps.setInt(6, serviceId);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public boolean deleteServiceIdentity(String domainName, String serviceName) {\n\n        final String caller = \"deleteServiceIdentity\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int affectedRows;\n        try (PreparedStatement ps = con.prepareStatement(SQL_DELETE_SERVICE)) {\n            ps.setInt(1, domainId);\n            ps.setString(2, serviceName);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public List<String> listServiceIdentities(String domainName) {\n\n        final String caller = \"listServiceIdentities\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        List<String> services = new ArrayList<>();\n        try (PreparedStatement ps = con.prepareStatement(SQL_LIST_SERVICE)) {\n            ps.setInt(1, domainId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    services.add(rs.getString(1));\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        Collections.sort(services);\n        return services;\n    }\n\n    @Override\n    public int countServiceIdentities(String domainName) {\n\n        final String caller = \"countServiceIdentities\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int count = 0;\n        try (PreparedStatement ps = con.prepareStatement(SQL_COUNT_SERVICE)) {\n            ps.setInt(1, domainId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    count = rs.getInt(1);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return count;\n    }\n\n    @Override\n    public List<PublicKeyEntry> listPublicKeys(String domainName, String serviceName) {\n\n        final String caller = \"listPublicKeys\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int serviceId = getServiceId(domainId, serviceName);\n        if (serviceId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_SERVICE, ResourceUtils.serviceResourceName(domainName, serviceName));\n        }\n        List<PublicKeyEntry> publicKeys = new ArrayList<>();\n        try (PreparedStatement ps = con.prepareStatement(SQL_LIST_PUBLIC_KEY)) {\n            ps.setInt(1, serviceId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    PublicKeyEntry publicKey = new PublicKeyEntry()\n                            .setId(rs.getString(ZMSConsts.DB_COLUMN_KEY_ID))\n                            .setKey(rs.getString(ZMSConsts.DB_COLUMN_KEY_VALUE));\n                    publicKeys.add(publicKey);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return publicKeys;\n    }\n\n    @Override\n    public int countPublicKeys(String domainName, String serviceName) {\n\n        final String caller = \"countPublicKeys\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int serviceId = getServiceId(domainId, serviceName);\n        if (serviceId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_SERVICE, ResourceUtils.serviceResourceName(domainName, serviceName));\n        }\n        int count = 0;\n        try (PreparedStatement ps = con.prepareStatement(SQL_COUNT_PUBLIC_KEY)) {\n            ps.setInt(1, serviceId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    count = rs.getInt(1);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return count;\n    }\n\n    @Override\n    public PublicKeyEntry getPublicKeyEntry(String domainName, String serviceName,\n            String keyId, boolean domainStateCheck) {\n\n        final String caller = \"getPublicKeyEntry\";\n\n        int domainId = getDomainId(domainName, domainStateCheck);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int serviceId = getServiceId(domainId, serviceName);\n        if (serviceId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_SERVICE, ResourceUtils.serviceResourceName(domainName, serviceName));\n        }\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_PUBLIC_KEY)) {\n            ps.setInt(1, serviceId);\n            ps.setString(2, keyId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    return new PublicKeyEntry().setId(keyId)\n                            .setKey(rs.getString(ZMSConsts.DB_COLUMN_KEY_VALUE));\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return null;\n    }\n\n    @Override\n    public boolean insertPublicKeyEntry(String domainName, String serviceName, PublicKeyEntry publicKey) {\n\n        final String caller = \"insertPublicKeyEntry\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int serviceId = getServiceId(domainId, serviceName);\n        if (serviceId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_SERVICE, ResourceUtils.serviceResourceName(domainName, serviceName));\n        }\n        int affectedRows;\n        try (PreparedStatement ps = con.prepareStatement(SQL_INSERT_PUBLIC_KEY)) {\n            ps.setInt(1, serviceId);\n            ps.setString(2, publicKey.getId());\n            ps.setString(3, publicKey.getKey());\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public boolean updatePublicKeyEntry(String domainName, String serviceName, PublicKeyEntry publicKey) {\n\n        final String caller = \"updatePublicKeyEntry\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int serviceId = getServiceId(domainId, serviceName);\n        if (serviceId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_SERVICE, ResourceUtils.serviceResourceName(domainName, serviceName));\n        }\n        int affectedRows;\n        try (PreparedStatement ps = con.prepareStatement(SQL_UPDATE_PUBLIC_KEY)) {\n            ps.setString(1, publicKey.getKey());\n            ps.setInt(2, serviceId);\n            ps.setString(3, publicKey.getId());\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public boolean deletePublicKeyEntry(String domainName, String serviceName, String keyId) {\n\n        final String caller = \"deletePublicKeyEntry\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int serviceId = getServiceId(domainId, serviceName);\n        if (serviceId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_SERVICE, ResourceUtils.serviceResourceName(domainName, serviceName));\n        }\n        int affectedRows;\n        try (PreparedStatement ps = con.prepareStatement(SQL_DELETE_PUBLIC_KEY)) {\n            ps.setInt(1, serviceId);\n            ps.setString(2, keyId);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public List<String> listServiceHosts(String domainName, String serviceName) {\n\n        final String caller = \"listServiceHosts\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int serviceId = getServiceId(domainId, serviceName);\n        if (serviceId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_SERVICE, ResourceUtils.serviceResourceName(domainName, serviceName));\n        }\n        List<String> hosts = new ArrayList<>();\n        try (PreparedStatement ps = con.prepareStatement(SQL_LIST_SERVICE_HOST)) {\n            ps.setInt(1, serviceId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    hosts.add(rs.getString(ZMSConsts.DB_COLUMN_NAME));\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return hosts;\n    }\n\n    @Override\n    public boolean insertServiceHost(String domainName, String serviceName, String hostName) {\n\n        final String caller = \"insertServiceHost\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int serviceId = getServiceId(domainId, serviceName);\n        if (serviceId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_SERVICE, ResourceUtils.serviceResourceName(domainName, serviceName));\n        }\n        int hostId = getHostId(hostName);\n        if (hostId == 0) {\n            hostId = insertHost(hostName);\n            if (hostId == 0) {\n                throw internalServerError(caller, \"Unable to insert host: \" + hostName);\n            }\n        }\n        int affectedRows;\n        try (PreparedStatement ps = con.prepareStatement(SQL_INSERT_SERVICE_HOST)) {\n            ps.setInt(1, serviceId);\n            ps.setInt(2, hostId);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public boolean deleteServiceHost(String domainName, String serviceName, String hostName) {\n\n        final String caller = \"deleteServiceHost\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int serviceId = getServiceId(domainId, serviceName);\n        if (serviceId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_SERVICE, ResourceUtils.serviceResourceName(domainName, serviceName));\n        }\n        int hostId = getHostId(hostName);\n        if (hostId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_HOST, hostName);\n        }\n        int affectedRows;\n        try (PreparedStatement ps = con.prepareStatement(SQL_DELETE_SERVICE_HOST)) {\n            ps.setInt(1, serviceId);\n            ps.setInt(2, hostId);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public boolean insertEntity(String domainName, Entity entity) {\n\n        final String caller = \"insertEntity\";\n\n        String entityName = ZMSUtils.extractEntityName(domainName, entity.getName());\n        if (entityName == null) {\n            throw requestError(caller, \"domain name mismatch: \" + domainName +\n                    \" insert entity name: \" + entity.getName());\n        }\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int affectedRows;\n        try (PreparedStatement ps = con.prepareStatement(SQL_INSERT_ENTITY)) {\n            ps.setInt(1, domainId);\n            ps.setString(2, entityName);\n            ps.setString(3, JSON.string(entity.getValue()));\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public boolean updateEntity(String domainName, Entity entity) {\n\n        final String caller = \"updateEntity\";\n\n        String entityName = ZMSUtils.extractEntityName(domainName, entity.getName());\n        if (entityName == null) {\n            throw requestError(caller, \"domain name mismatch: \" + domainName +\n                    \" insert entity name: \" + entity.getName());\n        }\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int affectedRows;\n        try (PreparedStatement ps = con.prepareStatement(SQL_UPDATE_ENTITY)) {\n            ps.setString(1, JSON.string(entity.getValue()));\n            ps.setInt(2, domainId);\n            ps.setString(3, entityName);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public boolean deleteEntity(String domainName, String entityName) {\n\n        final String caller = \"deleteEntity\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int affectedRows;\n        try (PreparedStatement ps = con.prepareStatement(SQL_DELETE_ENTITY)) {\n            ps.setInt(1, domainId);\n            ps.setString(2, entityName);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public Entity getEntity(String domainName, String entityName) {\n\n        final String caller = \"getEntity\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_ENTITY)) {\n            ps.setInt(1, domainId);\n            ps.setString(2, entityName);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    return new Entity().setName(ResourceUtils.entityResourceName(domainName, entityName))\n                            .setValue(JSON.fromString(rs.getString(ZMSConsts.DB_COLUMN_VALUE), Struct.class));\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return null;\n    }\n\n    @Override\n    public List<String> listEntities(String domainName) {\n\n        final String caller = \"listEntities\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        List<String> entities = new ArrayList<>();\n        try (PreparedStatement ps = con.prepareStatement(SQL_LIST_ENTITY)) {\n            ps.setInt(1, domainId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    entities.add(rs.getString(1));\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        Collections.sort(entities);\n        return entities;\n    }\n\n    @Override\n    public int countEntities(String domainName) {\n\n        final String caller = \"countEntities\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int count = 0;\n        try (PreparedStatement ps = con.prepareStatement(SQL_COUNT_ENTITY)) {\n            ps.setInt(1, domainId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    count = rs.getInt(1);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return count;\n    }\n\n    Role retrieveRole(ResultSet rs, final String domainName, final String roleName) throws SQLException {\n        Role role = new Role().setName(ResourceUtils.roleResourceName(domainName, roleName))\n                .setModified(Timestamp.fromMillis(rs.getTimestamp(ZMSConsts.DB_COLUMN_MODIFIED).getTime()))\n                .setTrust(saveValue(rs.getString(ZMSConsts.DB_COLUMN_TRUST)))\n                .setAuditEnabled(nullIfDefaultValue(rs.getBoolean(ZMSConsts.DB_COLUMN_AUDIT_ENABLED), false))\n                .setSelfServe(nullIfDefaultValue(rs.getBoolean(ZMSConsts.DB_COLUMN_SELF_SERVE), false))\n                .setMemberExpiryDays(nullIfDefaultValue(rs.getInt(ZMSConsts.DB_COLUMN_MEMBER_EXPIRY_DAYS), 0))\n                .setTokenExpiryMins(nullIfDefaultValue(rs.getInt(ZMSConsts.DB_COLUMN_TOKEN_EXPIRY_MINS), 0))\n                .setCertExpiryMins(nullIfDefaultValue(rs.getInt(ZMSConsts.DB_COLUMN_CERT_EXPIRY_MINS), 0))\n                .setSignAlgorithm(saveValue(rs.getString(ZMSConsts.DB_COLUMN_SIGN_ALGORITHM)))\n                .setServiceExpiryDays(nullIfDefaultValue(rs.getInt(ZMSConsts.DB_COLUMN_SERVICE_EXPIRY_DAYS), 0))\n                .setGroupExpiryDays(nullIfDefaultValue(rs.getInt(ZMSConsts.DB_COLUMN_GROUP_EXPIRY_DAYS), 0))\n                .setReviewEnabled(nullIfDefaultValue(rs.getBoolean(ZMSConsts.DB_COLUMN_REVIEW_ENABLED), false))\n                .setMemberReviewDays(nullIfDefaultValue(rs.getInt(ZMSConsts.DB_COLUMN_MEMBER_REVIEW_DAYS), 0))\n                .setServiceReviewDays(nullIfDefaultValue(rs.getInt(ZMSConsts.DB_COLUMN_SERVICE_REVIEW_DAYS), 0))\n                .setNotifyRoles(saveValue(rs.getString(ZMSConsts.DB_COLUMN_NOTIFY_ROLES)))\n                .setUserAuthorityFilter(saveValue(rs.getString(ZMSConsts.DB_COLUMN_USER_AUTHORITY_FILTER)))\n                .setUserAuthorityExpiration(saveValue(rs.getString(ZMSConsts.DB_COLUMN_USER_AUTHORITY_EXPIRATION)));\n        java.sql.Timestamp lastReviewedTime = rs.getTimestamp(ZMSConsts.DB_COLUMN_LAST_REVIEWED_TIME);\n        if (lastReviewedTime != null) {\n            role.setLastReviewedDate(Timestamp.fromMillis(lastReviewedTime.getTime()));\n        }\n        return role;\n    }\n\n    void getAthenzDomainRoles(String domainName, int domainId, AthenzDomain athenzDomain) {\n\n        final String caller = \"getAthenzDomain\";\n        Map<String, Role> roleMap = new HashMap<>();\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_DOMAIN_ROLES)) {\n            ps.setInt(1, domainId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    final String roleName = rs.getString(ZMSConsts.DB_COLUMN_NAME);\n                    Role role = retrieveRole(rs, domainName, roleName);\n                    roleMap.put(roleName, role);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_DOMAIN_ROLE_MEMBERS)) {\n            ps.setInt(1, domainId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    String roleName = rs.getString(1);\n                    Role role = roleMap.get(roleName);\n                    if (role == null) {\n                        continue;\n                    }\n                    List<RoleMember> members = role.getRoleMembers();\n                    if (members == null) {\n                        members = new ArrayList<>();\n                        role.setRoleMembers(members);\n                    }\n                    RoleMember roleMember = new RoleMember();\n                    roleMember.setMemberName(rs.getString(2));\n                    java.sql.Timestamp expiration = rs.getTimestamp(3);\n                    if (expiration != null) {\n                        roleMember.setExpiration(Timestamp.fromMillis(expiration.getTime()));\n                    }\n                    java.sql.Timestamp reviewReminder = rs.getTimestamp(4);\n                    if (reviewReminder != null) {\n                        roleMember.setReviewReminder(Timestamp.fromMillis(reviewReminder.getTime()));\n                    }\n                    roleMember.setSystemDisabled(nullIfDefaultValue(rs.getInt(5), 0));\n                    members.add(roleMember);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        // add role tags\n        addTagsToRoles(roleMap, athenzDomain.getName());\n\n        athenzDomain.getRoles().addAll(roleMap.values());\n    }\n\n    void getAthenzDomainGroups(String domainName, int domainId, AthenzDomain athenzDomain) {\n\n        final String caller = \"getAthenzDomain\";\n        Map<String, Group> groupMap = new HashMap<>();\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_DOMAIN_GROUPS)) {\n            ps.setInt(1, domainId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    final String groupName = rs.getString(ZMSConsts.DB_COLUMN_NAME);\n                    Group group = retrieveGroup(rs, domainName, groupName);\n                    groupMap.put(groupName, group);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_DOMAIN_GROUP_MEMBERS)) {\n            ps.setInt(1, domainId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    final String groupName = rs.getString(1);\n                    Group group = groupMap.get(groupName);\n                    if (group == null) {\n                        continue;\n                    }\n                    List<GroupMember> members = group.getGroupMembers();\n                    if (members == null) {\n                        members = new ArrayList<>();\n                        group.setGroupMembers(members);\n                    }\n                    GroupMember groupMember = new GroupMember();\n                    groupMember.setMemberName(rs.getString(2));\n                    groupMember.setGroupName(group.getName());\n                    java.sql.Timestamp expiration = rs.getTimestamp(3);\n                    if (expiration != null) {\n                        groupMember.setExpiration(Timestamp.fromMillis(expiration.getTime()));\n                    }\n                    groupMember.setSystemDisabled(nullIfDefaultValue(rs.getInt(4), 0));\n                    members.add(groupMember);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        athenzDomain.getGroups().addAll(groupMap.values());\n    }\n\n    void getAthenzDomainPolicies(String domainName, int domainId, AthenzDomain athenzDomain) {\n\n        final String caller = \"getAthenzDomain\";\n        Map<String, Policy> policyMap = new HashMap<>();\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_DOMAIN_POLICIES)) {\n            ps.setInt(1, domainId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    String policyName = rs.getString(ZMSConsts.DB_COLUMN_NAME);\n                    Policy policy = new Policy().setName(ResourceUtils.policyResourceName(domainName, policyName))\n                            .setModified(Timestamp.fromMillis(rs.getTimestamp(ZMSConsts.DB_COLUMN_MODIFIED).getTime()));\n                    policyMap.put(policyName, policy);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_DOMAIN_POLICY_ASSERTIONS)) {\n            ps.setInt(1, domainId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    String policyName = rs.getString(1);\n                    Policy policy = policyMap.get(policyName);\n                    if (policy == null) {\n                        continue;\n                    }\n                    List<Assertion> assertions = policy.getAssertions();\n                    if (assertions == null) {\n                        assertions = new ArrayList<>();\n                        policy.setAssertions(assertions);\n                    }\n                    Assertion assertion = new Assertion();\n                    assertion.setRole(ResourceUtils.roleResourceName(domainName, rs.getString(ZMSConsts.DB_COLUMN_ROLE)));\n                    assertion.setResource(rs.getString(ZMSConsts.DB_COLUMN_RESOURCE));\n                    assertion.setAction(rs.getString(ZMSConsts.DB_COLUMN_ACTION));\n                    assertion.setEffect(AssertionEffect.valueOf(rs.getString(ZMSConsts.DB_COLUMN_EFFECT)));\n                    assertion.setId((long) rs.getInt(ZMSConsts.DB_COLUMN_ASSERT_ID));\n                    assertions.add(assertion);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        athenzDomain.getPolicies().addAll(policyMap.values());\n    }\n\n    void getAthenzDomainServices(String domainName, int domainId, AthenzDomain athenzDomain) {\n\n        final String caller = \"getAthenzDomain\";\n        Map<String, ServiceIdentity> serviceMap = new HashMap<>();\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_DOMAIN_SERVICES)) {\n            ps.setInt(1, domainId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    String serviceName = rs.getString(ZMSConsts.DB_COLUMN_NAME);\n                    ServiceIdentity service = new ServiceIdentity()\n                            .setName(ResourceUtils.serviceResourceName(domainName, serviceName))\n                            .setProviderEndpoint(saveValue(rs.getString(ZMSConsts.DB_COLUMN_PROVIDER_ENDPOINT)))\n                            .setExecutable(saveValue(rs.getString(ZMSConsts.DB_COLUMN_EXECUTABLE)))\n                            .setUser(saveValue(rs.getString(ZMSConsts.DB_COLUMN_SVC_USER)))\n                            .setGroup(saveValue(rs.getString(ZMSConsts.DB_COLUMN_SVC_GROUP)))\n                            .setModified(Timestamp.fromMillis(rs.getTimestamp(ZMSConsts.DB_COLUMN_MODIFIED).getTime()));\n                    List<PublicKeyEntry> publicKeys = new ArrayList<>();\n                    service.setPublicKeys(publicKeys);\n                    serviceMap.put(serviceName, service);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_DOMAIN_SERVICES_HOSTS)) {\n            ps.setInt(1, domainId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    String serviceName = rs.getString(1);\n                    ServiceIdentity service = serviceMap.get(serviceName);\n                    if (service == null) {\n                        continue;\n                    }\n                    List<String> hosts = service.getHosts();\n                    if (hosts == null) {\n                        hosts = new ArrayList<>();\n                        service.setHosts(hosts);\n                    }\n                    hosts.add(rs.getString(2));\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_DOMAIN_SERVICES_PUBLIC_KEYS)) {\n            ps.setInt(1, domainId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    String serviceName = rs.getString(1);\n                    ServiceIdentity service = serviceMap.get(serviceName);\n                    if (service == null) {\n                        continue;\n                    }\n                    PublicKeyEntry publicKey = new PublicKeyEntry()\n                            .setId(rs.getString(ZMSConsts.DB_COLUMN_KEY_ID))\n                            .setKey(rs.getString(ZMSConsts.DB_COLUMN_KEY_VALUE));\n                    service.getPublicKeys().add(publicKey);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        athenzDomain.getServices().addAll(serviceMap.values());\n    }\n\n    void getAthenzDomainEntities(String domainName, int domainId, AthenzDomain athenzDomain) {\n\n        final String caller = \"getAthenzDomain\";\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_DOMAIN_ENTITIES)) {\n            ps.setInt(1, domainId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    athenzDomain.getEntities().add(new Entity()\n                            .setName(ResourceUtils.entityResourceName(domainName, rs.getString(ZMSConsts.DB_COLUMN_NAME)))\n                            .setValue(JSON.fromString(rs.getString(ZMSConsts.DB_COLUMN_VALUE), Struct.class)));\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n    }\n\n    @Override\n    public AthenzDomain getAthenzDomain(String domainName) {\n\n        final String caller = \"getAthenzDomain\";\n\n        int domainId = 0;\n        AthenzDomain athenzDomain = new AthenzDomain(domainName);\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_DOMAIN)) {\n            ps.setString(1, domainName);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    athenzDomain.setDomain(saveDomainSettings(domainName, rs, true));\n                    domainId = rs.getInt(ZMSConsts.DB_COLUMN_DOMAIN_ID);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n\n        getAthenzDomainRoles(domainName, domainId, athenzDomain);\n        getAthenzDomainGroups(domainName, domainId, athenzDomain);\n        getAthenzDomainPolicies(domainName, domainId, athenzDomain);\n        getAthenzDomainServices(domainName, domainId, athenzDomain);\n        getAthenzDomainEntities(domainName, domainId, athenzDomain);\n\n        return athenzDomain;\n    }\n\n    @Override\n    public DomainMetaList listModifiedDomains(long modifiedSince) {\n\n        final String caller = \"listModifiedDomains\";\n\n        DomainMetaList domainModifiedList = new DomainMetaList();\n        List<Domain> nameMods = new ArrayList<>();\n\n        try (PreparedStatement ps = prepareDomainScanStatement(null, modifiedSince)) {\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    final String domainName = rs.getString(ZMSConsts.DB_COLUMN_NAME);\n                    nameMods.add(saveDomainSettings(domainName, rs, false));\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        domainModifiedList.setDomains(nameMods);\n        return domainModifiedList;\n    }\n\n    boolean validatePrincipalDomain(String principal) {\n        // special case for all principals\n        if (ALL_PRINCIPALS.equals(principal)) {\n            return true;\n        }\n        int idx = principal.indexOf(AuthorityConsts.GROUP_SEP);\n        if (idx == -1) {\n            idx = principal.lastIndexOf('.');\n            if (idx == -1 || idx == 0 || idx == principal.length() - 1) {\n                return false;\n            }\n        }\n        return getDomainId(principal.substring(0, idx)) != 0;\n    }\n\n    String roleIndex(String domainId, String roleName) {\n        return domainId + ':' + roleName;\n    }\n\n    PreparedStatement prepareRoleAssertionsStatement(String action)\n            throws SQLException {\n\n        PreparedStatement ps;\n        if (action != null && action.length() > 0) {\n            ps = con.prepareStatement(SQL_LIST_ROLE_ASSERTIONS + SQL_LIST_ROLE_ASSERTION_QUERY_ACTION);\n            ps.setString(1, action);\n        } else {\n            ps = con.prepareStatement(SQL_LIST_ROLE_ASSERTIONS + SQL_LIST_ROLE_ASSERTION_NO_ACTION);\n        }\n        return ps;\n    }\n\n    Map<String, List<Assertion>> getRoleAssertions(String action, String caller) {\n\n        Map<String, List<Assertion>> roleAssertions = new HashMap<>();\n        try (PreparedStatement ps = prepareRoleAssertionsStatement(action)) {\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    Assertion assertion = new Assertion();\n                    String domainName = rs.getString(ZMSConsts.DB_COLUMN_NAME);\n                    String roleName = rs.getString(ZMSConsts.DB_COLUMN_ROLE);\n                    assertion.setRole(ResourceUtils.roleResourceName(domainName, roleName));\n                    assertion.setResource(rs.getString(ZMSConsts.DB_COLUMN_RESOURCE));\n                    assertion.setAction(rs.getString(ZMSConsts.DB_COLUMN_ACTION));\n                    assertion.setEffect(AssertionEffect.valueOf(rs.getString(ZMSConsts.DB_COLUMN_EFFECT)));\n                    assertion.setId((long) rs.getInt(ZMSConsts.DB_COLUMN_ASSERT_ID));\n\n                    String index = roleIndex(rs.getString(ZMSConsts.DB_COLUMN_DOMAIN_ID), roleName);\n                    List<Assertion> assertions = roleAssertions.computeIfAbsent(index, k -> new ArrayList<>());\n\n                    if (LOG.isDebugEnabled()) {\n                        LOG.debug(\"{}: adding assertion {} for {}\", caller, assertion, index);\n                    }\n\n                    assertions.add(assertion);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        return roleAssertions;\n    }\n\n    Set<String> getRolePrincipals(final String principalName, final String caller) {\n\n        // first let's find out all the roles that given principal is member of\n\n        Set<String> rolePrincipals = getRolesForPrincipal(principalName, caller);\n\n        // next let's extract all groups that the given principal is member of\n        // if the group list is not empty then we need to extract all the roles\n        // where groups are member of and include those roles that match our\n        // extracted groups in the role principals map\n\n        Set<String> groups = getGroupsForPrincipal(principalName, caller);\n        if (!groups.isEmpty()) {\n            updatePrincipalRoleGroupMembership(rolePrincipals, groups, principalName, caller);\n        }\n        return rolePrincipals;\n    }\n\n    void updatePrincipalRoleGroupMembership(Set<String> rolePrincipals, final Set<String> groups,\n            final String principalName, final String caller) {\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_LIST_ROLE_GROUP_PRINCIPALS)) {\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n\n                    final String groupName = rs.getString(ZMSConsts.DB_COLUMN_NAME);\n                    if (!groups.contains(groupName)) {\n                        continue;\n                    }\n\n                    final String roleName = rs.getString(ZMSConsts.DB_COLUMN_ROLE_NAME);\n                    final String index = roleIndex(rs.getString(ZMSConsts.DB_COLUMN_DOMAIN_ID), roleName);\n\n                    if (LOG.isDebugEnabled()) {\n                        LOG.debug(\"{}: adding principal {} for {}\", caller, principalName, index);\n                    }\n\n                    rolePrincipals.add(index);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n    }\n\n    Set<String> getGroupsForPrincipal(final String principalName, final String caller) {\n\n        Set<String> groups = new HashSet<>();\n        try (PreparedStatement ps = con.prepareStatement(SQL_LIST_GROUP_FOR_PRINCIPAL)) {\n            ps.setString(1, principalName);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    final String groupName = rs.getString(ZMSConsts.DB_COLUMN_NAME);\n                    final String domainName = rs.getString(ZMSConsts.DB_COLUMN_DOMAIN_NAME);\n                    groups.add(ResourceUtils.groupResourceName(domainName, groupName));\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        return groups;\n    }\n\n    Set<String> getRolesForPrincipal(final String principalName, final String caller) {\n\n        Set<String> rolePrincipals = new HashSet<>();\n        try (PreparedStatement ps = con.prepareStatement(SQL_LIST_ROLE_PRINCIPALS)) {\n            ps.setString(1, principalName);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n\n                    final String roleName = rs.getString(ZMSConsts.DB_COLUMN_ROLE_NAME);\n                    final String index = roleIndex(rs.getString(ZMSConsts.DB_COLUMN_DOMAIN_ID), roleName);\n\n                    if (LOG.isDebugEnabled()) {\n                        LOG.debug(\"{}: adding principal {} for {}\", caller, principalName, index);\n                    }\n\n                    rolePrincipals.add(index);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        return rolePrincipals;\n    }\n\n    void getTrustedSubTypeRoles(String sqlCommand, Map<String, List<String>> trustedRoles,\n            String caller) {\n\n        try (PreparedStatement ps = con.prepareStatement(sqlCommand)) {\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    String trustDomainId = rs.getString(ZMSConsts.DB_COLUMN_DOMAIN_ID);\n                    String trustRoleName = rs.getString(ZMSConsts.DB_COLUMN_NAME);\n                    String assertDomainId = rs.getString(ZMSConsts.DB_COLUMN_ASSERT_DOMAIN_ID);\n                    String assertRoleName = rs.getString(ZMSConsts.DB_COLUMN_ROLE);\n\n                    String index = roleIndex(assertDomainId, assertRoleName);\n                    List<String> roles = trustedRoles.computeIfAbsent(index, k -> new ArrayList<>());\n                    String tRoleName = roleIndex(trustDomainId, trustRoleName);\n                    roles.add(tRoleName);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n    }\n\n    Map<String, List<String>> getTrustedRoles(String caller) {\n\n        Map<String, List<String>> trustedRoles = new HashMap<>();\n        getTrustedSubTypeRoles(SQL_LIST_TRUSTED_STANDARD_ROLES, trustedRoles, caller);\n        getTrustedSubTypeRoles(SQL_LIST_TRUSTED_WILDCARD_ROLES, trustedRoles, caller);\n        return trustedRoles;\n    }\n\n    Map<String, String> getAwsDomains(String caller) {\n\n        Map<String, String> awsDomains = new HashMap<>();\n        try (PreparedStatement ps = con.prepareStatement(SQL_LIST_DOMAIN_AWS)) {\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    awsDomains.put(rs.getString(ZMSConsts.DB_COLUMN_NAME), rs.getString(ZMSConsts.DB_COLUMN_ACCOUNT));\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        return awsDomains;\n    }\n\n    void addRoleAssertions(List<Assertion> principalAssertions, List<Assertion> roleAssertions,\n            Map<String, String> awsDomains) {\n\n        // if the role assertions is empty then we have nothing to do\n\n        if (roleAssertions == null || roleAssertions.isEmpty()) {\n\n            if (LOG.isDebugEnabled()) {\n                LOG.debug(\"addRoleAssertions: role assertion list is empty\");\n            }\n\n            return;\n        }\n\n        // if this is not an aws request or the awsDomain list is empty,\n        // then we're just going to add the role assertions to the\n        // principal's assertion list as is\n\n        if (awsDomains == null || awsDomains.isEmpty()) {\n            principalAssertions.addAll(roleAssertions);\n            return;\n        }\n\n        // we're going to update each assertion and generate the\n        // resource in the expected aws role format. however, we\n        // going to skip any assertions where we do not have a\n        // valid syntax or no aws domain\n\n        for (Assertion assertion : roleAssertions) {\n\n            final String resource = assertion.getResource();\n\n            if (LOG.isDebugEnabled()) {\n                LOG.debug(\"addRoleAssertions: processing assertion: {}\", resource);\n            }\n\n            // first we need to check if the assertion has already\n            // been processed and as such the resource has been\n            // rewritten to have aws format\n\n            if (resource.startsWith(AWS_ARN_PREFIX)) {\n                principalAssertions.add(assertion);\n                continue;\n            }\n\n            // otherwise we're going to look for the domain component\n\n            int idx = resource.indexOf(':');\n            if (idx == -1) {\n                if (LOG.isDebugEnabled()) {\n                    LOG.debug(\"addRoleAssertions: resource without domain component: {}\", resource);\n                }\n                continue;\n            }\n\n            final String resourceDomain = resource.substring(0, idx);\n            String awsDomain = awsDomains.get(resourceDomain);\n            if (awsDomain == null) {\n                if (LOG.isDebugEnabled()) {\n                    LOG.debug(\"addRoleAssertions: resource without aws domain: {}\", resourceDomain);\n                }\n                continue;\n            }\n\n            assertion.setResource(AWS_ARN_PREFIX + awsDomain + \":role/\" + resource.substring(idx + 1));\n            principalAssertions.add(assertion);\n        }\n    }\n\n    ResourceAccess getResourceAccessObject(String principal, List<Assertion> assertions) {\n        ResourceAccess rsrcAccess = new ResourceAccess();\n        rsrcAccess.setPrincipal(principal);\n        rsrcAccess.setAssertions(assertions != null ? assertions : new ArrayList<>());\n        return rsrcAccess;\n    }\n\n    @Override\n    public ResourceAccessList listResourceAccess(String principal, String action, String userDomain) {\n\n        final String caller = \"listResourceAccess\";\n\n        ResourceAccessList rsrcAccessList = new ResourceAccessList();\n        List<ResourceAccess> resources = new ArrayList<>();\n        rsrcAccessList.setResources(resources);\n\n        // check to see if this an aws request based on\n        // the action query\n\n        boolean awsQuery = (action != null && action.equals(ZMSConsts.ACTION_ASSUME_AWS_ROLE));\n\n        // first let's get the principal list that we're asked to check for\n        // since if we have no matches then we have nothing to do\n\n        Set<String> rolePrincipals = getRolePrincipals(principal, caller);\n        if (rolePrincipals.isEmpty()) {\n\n            // so the given principal is not available as a role member\n            // so before returning an empty response let's make sure\n            // that it has been registered in Athenz otherwise we'll\n            // just return 404 - not found exception\n\n            if (getPrincipalId(principal) == 0) {\n                throw notFoundError(caller, ZMSConsts.OBJECT_PRINCIPAL, principal);\n            }\n\n            resources.add(getResourceAccessObject(principal, null));\n            return rsrcAccessList;\n        }\n\n        // now let's get the list of role assertions. if we have\n        // no matches, then we have nothing to do\n\n        Map<String, List<Assertion>> roleAssertions = getRoleAssertions(action, caller);\n        if (roleAssertions.isEmpty()) {\n            resources.add(getResourceAccessObject(principal, null));\n            return rsrcAccessList;\n        }\n\n        // finally we need to get all the trusted role maps\n\n        Map<String, List<String>> trustedRoles = getTrustedRoles(caller);\n\n        // if we're asked for action assume_aws_role then we're looking\n        // for role access in AWS. So we're going to retrieve\n        // the domains that have aws account configured only and update\n        // the resource to generate aws role resources.\n\n        Map<String, String> awsDomains = null;\n        if (awsQuery) {\n            awsDomains = getAwsDomains(caller);\n        }\n\n        // now let's go ahead and combine all of our data together\n        // we're going to go through each principal, lookup\n        // the assertions for the role and add them to the return object\n        // if the role has no corresponding assertions, then we're going\n        // to look at the trust role map in case it's a trusted role\n\n        Map<String, List<Assertion>> principalAssertions = new HashMap<>();\n        for (String roleIndex : rolePrincipals) {\n\n            if (LOG.isDebugEnabled()) {\n                LOG.debug(\"{}: processing role: {}\", caller, roleIndex);\n            }\n\n            List<Assertion> assertions = principalAssertions.computeIfAbsent(principal, k -> new ArrayList<>());\n\n            // retrieve the assertions for this role\n\n            addRoleAssertions(assertions, roleAssertions.get(roleIndex), awsDomains);\n\n            // check to see if this is a trusted role. There might be multiple\n            // roles all being mapped as trusted, so we need to process them all\n\n            List<String> mappedTrustedRoles = trustedRoles.get(roleIndex);\n            if (mappedTrustedRoles != null) {\n                for (String mappedTrustedRole : mappedTrustedRoles) {\n\n                    if (LOG.isDebugEnabled()) {\n                        LOG.debug(\"{}: processing trusted role: {}\", caller, mappedTrustedRole);\n                    }\n\n                    addRoleAssertions(assertions, roleAssertions.get(mappedTrustedRole), awsDomains);\n                }\n            }\n        }\n\n        // finally we need to create resource access list objects and return\n\n        for (Map.Entry<String, List<Assertion>> entry : principalAssertions.entrySet()) {\n            resources.add(getResourceAccessObject(entry.getKey(), entry.getValue()));\n        }\n\n        return rsrcAccessList;\n    }\n\n    @Override\n    public Quota getQuota(String domainName) {\n\n        final String caller = \"getQuota\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        Quota quota = null;\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_QUOTA)) {\n            ps.setInt(1, domainId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    quota = new Quota().setName(domainName);\n                    quota.setAssertion(rs.getInt(ZMSConsts.DB_COLUMN_ASSERTION));\n                    quota.setRole(rs.getInt(ZMSConsts.DB_COLUMN_ROLE));\n                    quota.setRoleMember(rs.getInt(ZMSConsts.DB_COLUMN_ROLE_MEMBER));\n                    quota.setPolicy(rs.getInt(ZMSConsts.DB_COLUMN_POLICY));\n                    quota.setService(rs.getInt(ZMSConsts.DB_COLUMN_SERVICE));\n                    quota.setServiceHost(rs.getInt(ZMSConsts.DB_COLUMN_SERVICE_HOST));\n                    quota.setPublicKey(rs.getInt(ZMSConsts.DB_COLUMN_PUBLIC_KEY));\n                    quota.setEntity(rs.getInt(ZMSConsts.DB_COLUMN_ENTITY));\n                    quota.setSubdomain(rs.getInt(ZMSConsts.DB_COLUMN_SUBDOMAIN));\n                    quota.setGroup(rs.getInt(ZMSConsts.DB_COLUMN_PRINCIPAL_GROUP));\n                    quota.setGroupMember(rs.getInt(ZMSConsts.DB_COLUMN_PRINCIPAL_GROUP_MEMBER));\n                    quota.setModified(Timestamp.fromMillis(rs.getTimestamp(ZMSConsts.DB_COLUMN_MODIFIED).getTime()));\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return quota;\n    }\n\n    @Override\n    public boolean insertQuota(String domainName, Quota quota) {\n\n        final String caller = \"insertQuota\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int affectedRows;\n        try (PreparedStatement ps = con.prepareStatement(SQL_INSERT_QUOTA)) {\n            ps.setInt(1, domainId);\n            ps.setInt(2, quota.getRole());\n            ps.setInt(3, quota.getRoleMember());\n            ps.setInt(4, quota.getPolicy());\n            ps.setInt(5, quota.getAssertion());\n            ps.setInt(6, quota.getService());\n            ps.setInt(7, quota.getServiceHost());\n            ps.setInt(8, quota.getPublicKey());\n            ps.setInt(9, quota.getEntity());\n            ps.setInt(10, quota.getSubdomain());\n            ps.setInt(11, quota.getGroup());\n            ps.setInt(12, quota.getGroupMember());\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public boolean updateQuota(String domainName, Quota quota) {\n\n        final String caller = \"updateQuota\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int affectedRows;\n        try (PreparedStatement ps = con.prepareStatement(SQL_UPDATE_QUOTA)) {\n            ps.setInt(1, quota.getRole());\n            ps.setInt(2, quota.getRoleMember());\n            ps.setInt(3, quota.getPolicy());\n            ps.setInt(4, quota.getAssertion());\n            ps.setInt(5, quota.getService());\n            ps.setInt(6, quota.getServiceHost());\n            ps.setInt(7, quota.getPublicKey());\n            ps.setInt(8, quota.getEntity());\n            ps.setInt(9, quota.getSubdomain());\n            ps.setInt(10, quota.getGroup());\n            ps.setInt(11, quota.getGroupMember());\n            ps.setInt(12, domainId);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public boolean deleteQuota(String domainName) {\n\n        final String caller = \"deleteQuota\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int affectedRows;\n        try (PreparedStatement ps = con.prepareStatement(SQL_DELETE_QUOTA)) {\n            ps.setInt(1, domainId);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public DomainRoleMembers listDomainRoleMembers(String domainName) {\n        return listDomainRoleMembersWithQuery(domainName, SQL_GET_DOMAIN_ROLE_MEMBERS, \"listDomainRoleMembers\");\n    }\n\n    @Override\n    public DomainRoleMember getPrincipalRoles(String principal, String domainName) {\n        final String caller = \"getPrincipalRoles\";\n\n        int principalId = getPrincipalId(principal);\n        if (principalId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_PRINCIPAL, principal);\n        }\n\n        DomainRoleMember roleMember = new DomainRoleMember();\n        roleMember.setMemberRoles(new ArrayList<>());\n        roleMember.setMemberName(principal);\n        if (StringUtil.isEmpty(domainName)) {\n            try (PreparedStatement ps = con.prepareStatement(SQL_GET_PRINCIPAL_ROLES)) {\n                ps.setInt(1, principalId);\n                return getRolesForPrincipal(caller, roleMember, ps);\n            } catch (SQLException ex) {\n                throw sqlError(ex, caller);\n            }\n        } else {\n            int domainId = getDomainId(domainName);\n            if (domainId == 0) {\n                throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n            }\n\n            try (PreparedStatement ps = con.prepareStatement(SQL_GET_PRINCIPAL_ROLES_DOMAIN)) {\n                ps.setInt(1, principalId);\n                ps.setInt(2, domainId);\n                return getRolesForPrincipal(caller, roleMember, ps);\n            } catch (SQLException ex) {\n                throw sqlError(ex, caller);\n            }\n        }\n    }\n\n    private DomainRoleMember getRolesForPrincipal(String caller, DomainRoleMember roleMember, PreparedStatement ps) throws SQLException {\n        try (ResultSet rs = executeQuery(ps, caller)) {\n            while (rs.next()) {\n                final String roleName = rs.getString(1);\n                final String domain = rs.getString(2);\n\n                MemberRole memberRole = new MemberRole();\n                memberRole.setRoleName(roleName);\n                memberRole.setDomainName(domain);\n\n                java.sql.Timestamp expiration = rs.getTimestamp(3);\n                if (expiration != null) {\n                    memberRole.setExpiration(Timestamp.fromMillis(expiration.getTime()));\n                }\n                java.sql.Timestamp reviewReminder = rs.getTimestamp(4);\n                if (reviewReminder != null) {\n                    memberRole.setReviewReminder(Timestamp.fromMillis(reviewReminder.getTime()));\n                }\n                memberRole.setSystemDisabled(nullIfDefaultValue(rs.getInt(5), 0));\n\n                roleMember.getMemberRoles().add(memberRole);\n            }\n\n            return roleMember;\n        }\n    }\n\n    @Override\n    public DomainRoleMembers listOverdueReviewRoleMembers(String domainName) {\n        return listDomainRoleMembersWithQuery(domainName, SQL_GET_REVIEW_OVERDUE_DOMAIN_ROLE_MEMBERS, \"listDomainRoleMembersWithQuery\");\n    }\n\n    @Override\n    public Map<String, List<DomainGroupMember>> getPendingDomainGroupMembers(String principal) {\n\n        final String caller = \"getPendingDomainGroupMembersList\";\n        int principalId = getPrincipalId(principal);\n        if (principalId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_PRINCIPAL, principal);\n        }\n\n        Map<String, List<DomainGroupMember>> domainGroupMembersMap = new LinkedHashMap<>();\n\n        // first we're going to retrieve all the members that are waiting\n        // for approval based on their domain org values\n\n        processPendingGroupMembers(ZMSConsts.SYS_AUTH_AUDIT_BY_ORG, SQL_PENDING_ORG_AUDIT_GROUP_MEMBER_LIST,\n                principalId, domainGroupMembersMap, caller);\n\n        // then we're going to retrieve all the members that are waiting\n        // for approval based on their domain name values\n\n        processPendingGroupMembers(ZMSConsts.SYS_AUTH_AUDIT_BY_DOMAIN, SQL_PENDING_DOMAIN_AUDIT_GROUP_MEMBER_LIST,\n                principalId, domainGroupMembersMap, caller);\n\n        // finally retrieve the self serve groups\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_PENDING_DOMAIN_ADMIN_GROUP_MEMBER_LIST)) {\n            ps.setInt(1, principalId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    populateDomainGroupMembersMapFromResultSet(domainGroupMembersMap, rs);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        return domainGroupMembersMap;\n    }\n\n    @Override\n    public Map<String, List<DomainGroupMember>> getExpiredPendingDomainGroupMembers(int pendingGroupMemberLifespan) {\n\n        final String caller = \"getExpiredPendingDomainGroupMembers\";\n\n        //update audit log with details before deleting\n\n        Map<String, List<DomainGroupMember>> domainGroupMembersMap = new LinkedHashMap<>();\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_EXPIRED_PENDING_GROUP_MEMBERS)) {\n            ps.setInt(1, pendingGroupMemberLifespan);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    populateDomainGroupMembersMapFromResultSet(domainGroupMembersMap, rs);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return domainGroupMembersMap;\n    }\n\n    @Override\n    public Set<String> getPendingGroupMembershipApproverRoles(String server, long timestamp) {\n\n        final String caller = \"getPendingGroupMembershipApproverGroups\";\n\n        Set<String> targetRoles = new HashSet<>();\n        int orgDomainId = getDomainId(ZMSConsts.SYS_AUTH_AUDIT_BY_ORG);\n        int domDomainId = getDomainId(ZMSConsts.SYS_AUTH_AUDIT_BY_DOMAIN);\n\n        java.sql.Timestamp ts = new java.sql.Timestamp(timestamp);\n\n        //Get orgs and domains for audit enabled groups with pending membership\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_AUDIT_ENABLED_PENDING_GROUP_MEMBERSHIP_REMINDER_ENTRIES)) {\n            ps.setTimestamp(1, ts);\n            ps.setString(2, server);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n\n                    // first process the org value\n\n                    final String org = rs.getString(1);\n                    if (org != null && !org.isEmpty()) {\n                        int roleId = getRoleId(orgDomainId, org);\n                        if (roleId != 0) {\n                            targetRoles.add(ResourceUtils.roleResourceName(ZMSConsts.SYS_AUTH_AUDIT_BY_ORG, org));\n                        }\n                    }\n\n                    // then process the domain value\n\n                    final String domain = rs.getString(2);\n                    int roleId = getRoleId(domDomainId, domain);\n                    if (roleId != 0) {\n                        targetRoles.add(ResourceUtils.roleResourceName(ZMSConsts.SYS_AUTH_AUDIT_BY_DOMAIN, domain));\n                    }\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        // get admin groups of pending self-serve and review-enabled requests\n\n        getRecipientRoleForAdminGroupMembershipApproval(caller, targetRoles, ts, server);\n\n        return targetRoles;\n    }\n\n    @Override\n    public boolean updatePendingGroupMembersNotificationTimestamp(String server, long timestamp, int delayDays) {\n\n        final String caller = \"updatePendingGroupMembersNotificationTimestamp\";\n        int affectedRows;\n        java.sql.Timestamp ts = new java.sql.Timestamp(timestamp);\n        try (PreparedStatement ps = con.prepareStatement(SQL_UPDATE_PENDING_GROUP_MEMBERS_NOTIFICATION_TIMESTAMP)) {\n            ps.setTimestamp(1, ts);\n            ps.setString(2, server);\n            ps.setTimestamp(3, ts);\n            ps.setInt(4, delayDays);\n\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    private DomainRoleMembers listDomainRoleMembersWithQuery(String domainName, String query, String caller) {\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        DomainRoleMembers domainRoleMembers = new DomainRoleMembers();\n        domainRoleMembers.setDomainName(domainName);\n\n        Map<String, DomainRoleMember> memberMap = new HashMap<>();\n        try (PreparedStatement ps = con.prepareStatement(query)) {\n            ps.setInt(1, domainId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    final String roleName = rs.getString(1);\n                    final String memberName = rs.getString(2);\n\n                    DomainRoleMember domainRoleMember = memberMap.get(memberName);\n                    if (domainRoleMember == null) {\n                        domainRoleMember = new DomainRoleMember();\n                        domainRoleMember.setMemberName(memberName);\n                        memberMap.put(memberName, domainRoleMember);\n                    }\n                    List<MemberRole> memberRoles = domainRoleMember.getMemberRoles();\n                    if (memberRoles == null) {\n                        memberRoles = new ArrayList<>();\n                        domainRoleMember.setMemberRoles(memberRoles);\n                    }\n                    MemberRole memberRole = new MemberRole();\n                    memberRole.setRoleName(roleName);\n\n                    java.sql.Timestamp expiration = rs.getTimestamp(3);\n                    if (expiration != null) {\n                        memberRole.setExpiration(Timestamp.fromMillis(expiration.getTime()));\n                    }\n                    java.sql.Timestamp reviewReminder = rs.getTimestamp(4);\n                    if (reviewReminder != null) {\n                        memberRole.setReviewReminder(Timestamp.fromMillis(reviewReminder.getTime()));\n                    }\n                    memberRole.setSystemDisabled(nullIfDefaultValue(rs.getInt(5), 0));\n                    memberRoles.add(memberRole);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        if (!memberMap.isEmpty()) {\n            domainRoleMembers.setMembers(new ArrayList<>(memberMap.values()));\n        }\n        return domainRoleMembers;\n    }\n\n    @Override\n    public boolean deletePendingRoleMember(String domainName, String roleName, String principal,\n            String admin, String auditRef) {\n\n        final String caller = \"deletePendingRoleMember\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int roleId = getRoleId(domainId, roleName);\n        if (roleId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_ROLE, ResourceUtils.roleResourceName(domainName, roleName));\n        }\n        int principalId = getPrincipalId(principal);\n        if (principalId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_PRINCIPAL, principal);\n        }\n        return executeDeletePendingRoleMember(roleId, principalId, admin, principal, auditRef, true, caller);\n    }\n\n    public boolean executeDeletePendingRoleMember(int roleId, int principalId, final String admin,\n            final String principal, final String auditRef, boolean auditLog, final String caller) {\n\n        int affectedRows;\n        try (PreparedStatement ps = con.prepareStatement(SQL_DELETE_PENDING_ROLE_MEMBER)) {\n            ps.setInt(1, roleId);\n            ps.setInt(2, principalId);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        boolean result = (affectedRows > 0);\n        if (result && auditLog) {\n            result = insertRoleAuditLog(roleId, admin, principal, \"REJECT\", auditRef);\n        }\n        return result;\n    }\n\n    @Override\n    public boolean confirmRoleMember(String domainName, String roleName, RoleMember roleMember,\n            String admin, String auditRef) {\n\n        final String caller = \"confirmRoleMember\";\n\n        String principal = roleMember.getMemberName();\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int roleId = getRoleId(domainId, roleName);\n        if (roleId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_ROLE, ResourceUtils.roleResourceName(domainName, roleName));\n        }\n        int principalId = getPrincipalId(principal);\n        if (principalId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_PRINCIPAL, principal);\n        }\n\n        // need to check if the pending entry already exists\n        // before doing any work\n\n        boolean roleMemberExists = roleMemberExists(roleId, principalId, true, caller);\n        if (!roleMemberExists) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_PRINCIPAL, principal);\n        }\n\n        boolean result;\n        if (roleMember.getApproved() == Boolean.TRUE) {\n            roleMemberExists = roleMemberExists(roleId, principalId, false, caller);\n            result = insertStandardRoleMember(roleId, principalId, roleMember, admin,\n                    principal, auditRef, roleMemberExists, true, caller);\n\n            if (result) {\n                executeDeletePendingRoleMember(roleId, principalId, admin, principal,\n                        auditRef, false, caller);\n            }\n        } else {\n            result = executeDeletePendingRoleMember(roleId, principalId, admin,\n                principal, auditRef, true, caller);\n        }\n\n        return result;\n    }\n\n    void processPendingMembers(final String domainName, final String query, int principalId,\n            Map<String, List<DomainRoleMember>> domainRoleMembersMap, final String caller) {\n\n        int auditDomId = getDomainId(domainName);\n        try (PreparedStatement ps = con.prepareStatement(query)) {\n            ps.setInt(1, principalId);\n            ps.setInt(2, auditDomId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    populateDomainRoleMembersMapFromResultSet(domainRoleMembersMap, rs);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n    }\n\n    void processPendingGroupMembers(final String domainName, final String query, int principalId,\n                                    Map<String, List<DomainGroupMember>> domainGroupMembersMap, final String caller) {\n\n        int auditDomId = getDomainId(domainName);\n        try (PreparedStatement ps = con.prepareStatement(query)) {\n            ps.setInt(1, principalId);\n            ps.setInt(2, auditDomId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    populateDomainGroupMembersMapFromResultSet(domainGroupMembersMap, rs);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n    }\n\n    @Override\n    public Map<String, List<DomainRoleMember>> getPendingDomainRoleMembers(String principal) {\n\n        final String caller = \"getPendingDomainRoleMembersList\";\n        int principalId = getPrincipalId(principal);\n        if (principalId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_PRINCIPAL, principal);\n        }\n\n        Map<String, List<DomainRoleMember>> domainRoleMembersMap = new LinkedHashMap<>();\n\n        // first we're going to retrieve all the members that are waiting\n        // for approval based on their domain org values\n\n        processPendingMembers(ZMSConsts.SYS_AUTH_AUDIT_BY_ORG, SQL_PENDING_ORG_AUDIT_ROLE_MEMBER_LIST,\n            principalId, domainRoleMembersMap, caller);\n\n        // then we're going to retrieve all the members that are waiting\n        // for approval based on their domain name values\n        processPendingMembers(ZMSConsts.SYS_AUTH_AUDIT_BY_DOMAIN, SQL_PENDING_DOMAIN_AUDIT_ROLE_MEMBER_LIST,\n            principalId, domainRoleMembersMap, caller);\n\n        // finally retrieve the self serve roles\n        try (PreparedStatement ps = con.prepareStatement(SQL_PENDING_DOMAIN_ADMIN_ROLE_MEMBER_LIST)) {\n            ps.setInt(1, principalId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    populateDomainRoleMembersMapFromResultSet(domainRoleMembersMap, rs);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        return domainRoleMembersMap;\n    }\n\n    private void populateDomainRoleMembersMapFromResultSet(Map<String, List<DomainRoleMember>> domainRoleMembersMap, ResultSet rs) throws SQLException {\n\n        List<DomainRoleMember> domainRoleMembers;\n        final String domain = rs.getString(1);\n        if (!domainRoleMembersMap.containsKey(domain)) {\n            domainRoleMembers = new ArrayList<>();\n            domainRoleMembersMap.put(domain, domainRoleMembers);\n        }\n        domainRoleMembers = domainRoleMembersMap.get(domain);\n\n        DomainRoleMember domainRoleMember = new DomainRoleMember();\n        domainRoleMember.setMemberName(rs.getString(3));\n        List<MemberRole> memberRoles = new ArrayList<>();\n\n        MemberRole memberRole = new MemberRole();\n        memberRole.setRoleName(rs.getString(2));\n        java.sql.Timestamp expiration = rs.getTimestamp(4);\n        if (expiration != null) {\n            memberRole.setExpiration(Timestamp.fromMillis(expiration.getTime()));\n        }\n        java.sql.Timestamp reviewReminder = rs.getTimestamp(5);\n        if (reviewReminder != null) {\n            memberRole.setReviewReminder(Timestamp.fromMillis(reviewReminder.getTime()));\n        }\n        memberRole.setActive(false);\n        memberRole.setAuditRef(rs.getString(6));\n\n        expiration = rs.getTimestamp(7);\n        if (expiration != null) {\n            memberRole.setRequestTime(Timestamp.fromMillis(expiration.getTime()));\n        }\n        memberRole.setRequestPrincipal(rs.getString(8));\n        memberRoles.add(memberRole);\n\n        domainRoleMember.setMemberRoles(memberRoles);\n        if (!domainRoleMembers.contains(domainRoleMember)) {\n            domainRoleMembers.add(domainRoleMember);\n        }\n    }\n\n    private void populateDomainGroupMembersMapFromResultSet(Map<String, List<DomainGroupMember>> domainGroupMembersMap, ResultSet rs) throws SQLException {\n\n        List<DomainGroupMember> domainGroupMembers;\n        final String domain = rs.getString(1);\n        if (!domainGroupMembersMap.containsKey(domain)) {\n            domainGroupMembers = new ArrayList<>();\n            domainGroupMembersMap.put(domain, domainGroupMembers);\n        }\n        domainGroupMembers = domainGroupMembersMap.get(domain);\n\n        DomainGroupMember domainGroupMember = new DomainGroupMember();\n        domainGroupMember.setMemberName(rs.getString(3));\n        List<GroupMember> memberGroups = new ArrayList<>();\n\n        GroupMember memberGroup = new GroupMember();\n        memberGroup.setGroupName(rs.getString(2));\n        java.sql.Timestamp expiration = rs.getTimestamp(4);\n        if (expiration != null) {\n            memberGroup.setExpiration(Timestamp.fromMillis(expiration.getTime()));\n        }\n        memberGroup.setActive(false);\n        memberGroup.setAuditRef(rs.getString(5));\n\n        expiration = rs.getTimestamp(6);\n        if (expiration != null) {\n            memberGroup.setRequestTime(Timestamp.fromMillis(expiration.getTime()));\n        }\n        memberGroup.setRequestPrincipal(rs.getString(7));\n        memberGroups.add(memberGroup);\n\n        domainGroupMember.setMemberGroups(memberGroups);\n        if (!domainGroupMembers.contains(domainGroupMember)) {\n            domainGroupMembers.add(domainGroupMember);\n        }\n    }\n\n    @Override\n    public Set<String> getPendingMembershipApproverRoles(String server, long timestamp) {\n\n        final String caller = \"getPendingMembershipApproverRoles\";\n\n        Set<String> targetRoles = new HashSet<>();\n        int orgDomainId = getDomainId(ZMSConsts.SYS_AUTH_AUDIT_BY_ORG);\n        int domDomainId = getDomainId(ZMSConsts.SYS_AUTH_AUDIT_BY_DOMAIN);\n\n        java.sql.Timestamp ts = new java.sql.Timestamp(timestamp);\n\n        //Get orgs and domains for audit enabled roles with pending membership\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_AUDIT_ENABLED_PENDING_MEMBERSHIP_REMINDER_ENTRIES)) {\n            ps.setTimestamp(1, ts);\n            ps.setString(2, server);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n\n                    // first process the org value\n\n                    final String org = rs.getString(1);\n                    if (org != null && !org.isEmpty()) {\n                        int roleId = getRoleId(orgDomainId, org);\n                        if (roleId != 0) {\n                            targetRoles.add(ResourceUtils.roleResourceName(ZMSConsts.SYS_AUTH_AUDIT_BY_ORG, org));\n                        }\n                    }\n\n                    // then process the domain value\n\n                    final String domain = rs.getString(2);\n                    int roleId = getRoleId(domDomainId, domain);\n                    if (roleId != 0) {\n                        targetRoles.add(ResourceUtils.roleResourceName(ZMSConsts.SYS_AUTH_AUDIT_BY_DOMAIN, domain));\n                    }\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        // get admin roles of pending self-serve and review-enabled requests\n\n        getRecipientRoleForAdminMembershipApproval(caller, targetRoles, ts, server);\n\n        return targetRoles;\n    }\n\n    @Override\n    public Map<String, List<DomainRoleMember>> getExpiredPendingDomainRoleMembers(int pendingRoleMemberLifespan) {\n\n        final String caller = \"getExpiredPendingMembers\";\n        //update audit log with details before deleting\n\n        Map<String, List<DomainRoleMember>> domainRoleMembersMap = new LinkedHashMap<>();\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_EXPIRED_PENDING_ROLE_MEMBERS)) {\n            ps.setInt(1, pendingRoleMemberLifespan);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    populateDomainRoleMembersMapFromResultSet(domainRoleMembersMap, rs);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return domainRoleMembersMap;\n    }\n\n    @Override\n    public boolean updatePendingRoleMembersNotificationTimestamp(String server, long timestamp, int delayDays) {\n        final String caller = \"updatePendingRoleMembersNotificationTimestamp\";\n        int affectedRows;\n        java.sql.Timestamp ts = new java.sql.Timestamp(timestamp);\n        try (PreparedStatement ps = con.prepareStatement(SQL_UPDATE_PENDING_ROLE_MEMBERS_NOTIFICATION_TIMESTAMP)) {\n            ps.setTimestamp(1, ts);\n            ps.setString(2, server);\n            ps.setTimestamp(3, ts);\n            ps.setInt(4, delayDays);\n\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    private void getRecipientRoleForAdminMembershipApproval(String caller, Set<String> targetRoles,\n                java.sql.Timestamp timestamp, String server) {\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_ADMIN_PENDING_MEMBERSHIP_REMINDER_DOMAINS)) {\n            ps.setTimestamp(1, timestamp);\n            ps.setString(2, server);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    targetRoles.add(ResourceUtils.roleResourceName(rs.getString(1), ZMSConsts.ADMIN_ROLE_NAME));\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n    }\n\n    private void getRecipientRoleForAdminGroupMembershipApproval(String caller, Set<String> targetRoles,\n                                                            java.sql.Timestamp timestamp, String server) {\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_ADMIN_PENDING_GROUP_MEMBERSHIP_REMINDER_DOMAINS)) {\n            ps.setTimestamp(1, timestamp);\n            ps.setString(2, server);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    targetRoles.add(ResourceUtils.roleResourceName(rs.getString(1), ZMSConsts.ADMIN_ROLE_NAME));\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n    }\n\n    @Override\n    public Map<String, DomainRoleMember> getNotifyTemporaryRoleMembers(String server, long timestamp) {\n        return getNotifyRoleMembers(server, timestamp, SQL_LIST_NOTIFY_TEMPORARY_ROLE_MEMBERS, \"listNotifyTemporaryRoleMembers\");\n    }\n\n    @Override\n    public boolean updateRoleMemberExpirationNotificationTimestamp(String server, long timestamp, int delayDays) {\n        return updateMemberNotificationTimestamp(server, timestamp, delayDays,\n                SQL_UPDATE_ROLE_MEMBERS_EXPIRY_NOTIFICATION_TIMESTAMP, \"updateRoleMemberExpirationNotificationTimestamp\");\n    }\n\n    @Override\n    public Map<String, DomainGroupMember> getNotifyTemporaryGroupMembers(String server, long timestamp) {\n\n        final String caller = \"getNotifyTemporaryGroupMembers\";\n        Map<String, DomainGroupMember> memberMap = new HashMap<>();\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_LIST_NOTIFY_TEMPORARY_GROUP_MEMBERS)) {\n            ps.setTimestamp(1, new java.sql.Timestamp(timestamp));\n            ps.setString(2, server);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    final String memberName = rs.getString(ZMSConsts.DB_COLUMN_PRINCIPAL_NAME);\n                    java.sql.Timestamp expiration = rs.getTimestamp(ZMSConsts.DB_COLUMN_EXPIRATION);\n\n                    DomainGroupMember domainGroupMember = memberMap.get(memberName);\n                    if (domainGroupMember == null) {\n                        domainGroupMember = new DomainGroupMember();\n                        domainGroupMember.setMemberName(memberName);\n                        memberMap.put(memberName, domainGroupMember);\n                    }\n                    List<GroupMember> memberGroups = domainGroupMember.getMemberGroups();\n                    if (memberGroups == null) {\n                        memberGroups = new ArrayList<>();\n                        domainGroupMember.setMemberGroups(memberGroups);\n                    }\n                    GroupMember memberGroup = new GroupMember();\n                    memberGroup.setMemberName(memberName);\n                    memberGroup.setGroupName(rs.getString(ZMSConsts.DB_COLUMN_AS_GROUP_NAME));\n                    memberGroup.setDomainName(rs.getString(ZMSConsts.DB_COLUMN_DOMAIN_NAME));\n                    if (expiration != null) {\n                        memberGroup.setExpiration(Timestamp.fromMillis(expiration.getTime()));\n                    }\n                    memberGroups.add(memberGroup);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        return memberMap;\n    }\n\n    @Override\n    public boolean updateGroupMemberExpirationNotificationTimestamp(String server, long timestamp, int delayDays) {\n        return updateMemberNotificationTimestamp(server, timestamp, delayDays,\n                SQL_UPDATE_GROUP_MEMBERS_EXPIRY_NOTIFICATION_TIMESTAMP, \"updateGroupMemberExpirationNotificationTimestamp\");\n    }\n\n    @Override\n    public Map<String, DomainRoleMember> getNotifyReviewRoleMembers(String server, long timestamp) {\n        return getNotifyRoleMembers(server, timestamp, SQL_LIST_NOTIFY_REVIEW_ROLE_MEMBERS, \"listNotifyReviewRoleMembers\");\n    }\n\n    @Override\n    public boolean updateRoleMemberReviewNotificationTimestamp(String server, long timestamp, int delayDays) {\n        return updateMemberNotificationTimestamp(server, timestamp, delayDays,\n                SQL_UPDATE_ROLE_MEMBERS_REVIEW_NOTIFICATION_TIMESTAMP, \"updateRoleMemberReviewNotificationTimestamp\");\n    }\n\n    private boolean updateMemberNotificationTimestamp(final String server, long timestamp, int delayDays,\n                                                      final String query, final String caller) {\n        int affectedRows;\n        try (PreparedStatement ps = con.prepareStatement(query)) {\n            ps.setTimestamp(1, new java.sql.Timestamp(timestamp));\n            ps.setString(2, server);\n            ps.setInt(3, delayDays);\n\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    private Map<String, DomainRoleMember> getNotifyRoleMembers(final String server, long timestamp, final String query,\n                                                               final String caller) {\n\n        Map<String, DomainRoleMember> memberMap = new HashMap<>();\n\n        try (PreparedStatement ps = con.prepareStatement(query)) {\n            ps.setTimestamp(1, new java.sql.Timestamp(timestamp));\n            ps.setString(2, server);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    final String memberName = rs.getString(ZMSConsts.DB_COLUMN_PRINCIPAL_NAME);\n                    java.sql.Timestamp expiration = rs.getTimestamp(ZMSConsts.DB_COLUMN_EXPIRATION);\n                    java.sql.Timestamp reviewReminder = rs.getTimestamp(ZMSConsts.DB_COLUMN_REVIEW_REMINDER);\n\n                    DomainRoleMember domainRoleMember = memberMap.get(memberName);\n                    if (domainRoleMember == null) {\n                        domainRoleMember = new DomainRoleMember();\n                        domainRoleMember.setMemberName(memberName);\n                        memberMap.put(memberName, domainRoleMember);\n                    }\n                    List<MemberRole> memberRoles = domainRoleMember.getMemberRoles();\n                    if (memberRoles == null) {\n                        memberRoles = new ArrayList<>();\n                        domainRoleMember.setMemberRoles(memberRoles);\n                    }\n                    MemberRole memberRole = new MemberRole();\n                    memberRole.setMemberName(memberName);\n                    memberRole.setRoleName(rs.getString(ZMSConsts.DB_COLUMN_ROLE_NAME));\n                    memberRole.setDomainName(rs.getString(ZMSConsts.DB_COLUMN_DOMAIN_NAME));\n                    if (expiration != null) {\n                        memberRole.setExpiration(Timestamp.fromMillis(expiration.getTime()));\n                    }\n                    if (reviewReminder != null) {\n                        memberRole.setReviewReminder(Timestamp.fromMillis(reviewReminder.getTime()));\n                    }\n                    memberRoles.add(memberRole);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        return memberMap;\n    }\n\n    @Override\n    public List<TemplateMetaData> getDomainTemplates(String domainName) {\n        TemplateMetaData templateDomainMapping;\n        List<TemplateMetaData> templateDomainMappingList = new ArrayList<>();\n        final String caller = \"getDomainTemplates\";\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_LIST_DOMAIN_TEMPLATES)) {\n            ps.setInt(1, domainId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    templateDomainMapping = new TemplateMetaData();\n                    templateDomainMapping.setTemplateName(rs.getString(ZMSConsts.DB_COLUMN_TEMPLATE_NAME));\n                    templateDomainMapping.setCurrentVersion(rs.getInt(ZMSConsts.DB_COLUMN_TEMPLATE_VERSION));\n                    templateDomainMappingList.add(templateDomainMapping);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return templateDomainMappingList;\n    }\n\n    @Override\n    public List<PrincipalRole> listRolesWithUserAuthorityRestrictions() {\n\n        final String caller = \"listRolesWithUserAuthorityRestrictions\";\n        List<PrincipalRole> roles = new ArrayList<>();\n        try (PreparedStatement ps = con.prepareStatement(SQL_LIST_ROLES_WITH_RESTRICTIONS)) {\n\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    PrincipalRole prRole = new PrincipalRole();\n                    prRole.setDomainName(rs.getString(ZMSConsts.DB_COLUMN_AS_DOMAIN_NAME));\n                    prRole.setRoleName(rs.getString(ZMSConsts.DB_COLUMN_AS_ROLE_NAME));\n                    prRole.setDomainUserAuthorityFilter(rs.getString(ZMSConsts.DB_COLUMN_AS_DOMAIN_USER_AUTHORITY_FILTER));\n                    roles.add(prRole);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        return roles;\n    }\n\n    Group retrieveGroup(ResultSet rs, final String domainName, final String groupName) throws SQLException {\n        Group group = new Group().setName(ResourceUtils.groupResourceName(domainName, groupName))\n                .setModified(Timestamp.fromMillis(rs.getTimestamp(ZMSConsts.DB_COLUMN_MODIFIED).getTime()))\n                .setAuditEnabled(nullIfDefaultValue(rs.getBoolean(ZMSConsts.DB_COLUMN_AUDIT_ENABLED), false))\n                .setSelfServe(nullIfDefaultValue(rs.getBoolean(ZMSConsts.DB_COLUMN_SELF_SERVE), false))\n                .setReviewEnabled(nullIfDefaultValue(rs.getBoolean(ZMSConsts.DB_COLUMN_REVIEW_ENABLED), false))\n                .setNotifyRoles(saveValue(rs.getString(ZMSConsts.DB_COLUMN_NOTIFY_ROLES)))\n                .setUserAuthorityFilter(saveValue(rs.getString(ZMSConsts.DB_COLUMN_USER_AUTHORITY_FILTER)))\n                .setUserAuthorityExpiration(saveValue(rs.getString(ZMSConsts.DB_COLUMN_USER_AUTHORITY_EXPIRATION)))\n                .setMemberExpiryDays(nullIfDefaultValue(rs.getInt(ZMSConsts.DB_COLUMN_MEMBER_EXPIRY_DAYS), 0))\n                .setServiceExpiryDays(nullIfDefaultValue(rs.getInt(ZMSConsts.DB_COLUMN_SERVICE_EXPIRY_DAYS), 0));\n\n        java.sql.Timestamp lastReviewedTime = rs.getTimestamp(ZMSConsts.DB_COLUMN_LAST_REVIEWED_TIME);\n        if (lastReviewedTime != null) {\n            group.setLastReviewedDate(Timestamp.fromMillis(lastReviewedTime.getTime()));\n        }\n        return group;\n    }\n\n    @Override\n    public Group getGroup(String domainName, String groupName) {\n        final String caller = \"getGroup\";\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_GROUP)) {\n            ps.setString(1, domainName);\n            ps.setString(2, groupName);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    return retrieveGroup(rs, domainName, groupName);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return null;\n    }\n\n    @Override\n    public boolean insertGroup(String domainName, Group group) {\n        int affectedRows;\n        final String caller = \"insertGroup\";\n\n        String groupName = ZMSUtils.extractGroupName(domainName, group.getName());\n        if (groupName == null) {\n            throw requestError(caller, \"domain name mismatch: \" + domainName +\n                    \" insert group name: \" + group.getName());\n        }\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        try (PreparedStatement ps = con.prepareStatement(SQL_INSERT_GROUP)) {\n            ps.setString(1, groupName);\n            ps.setInt(2, domainId);\n            ps.setBoolean(3, processInsertValue(group.getAuditEnabled(), false));\n            ps.setBoolean(4, processInsertValue(group.getSelfServe(), false));\n            ps.setBoolean(5, processInsertValue(group.getReviewEnabled(), false));\n            ps.setString(6, processInsertValue(group.getNotifyRoles()));\n            ps.setString(7, processInsertValue(group.getUserAuthorityFilter()));\n            ps.setString(8, processInsertValue(group.getUserAuthorityExpiration()));\n            ps.setInt(9, processInsertValue(group.getMemberExpiryDays()));\n            ps.setInt(10, processInsertValue(group.getServiceExpiryDays()));\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public boolean updateGroup(String domainName, Group group) {\n        int affectedRows;\n        final String caller = \"updateGroup\";\n\n        String groupName = ZMSUtils.extractGroupName(domainName, group.getName());\n        if (groupName == null) {\n            throw requestError(caller, \"domain name mismatch: \" + domainName +\n                    \" update group name: \" + group.getName());\n        }\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int groupId = getGroupId(domainId, groupName);\n        if (groupId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_GROUP, ResourceUtils.groupResourceName(domainName, groupName));\n        }\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_UPDATE_GROUP)) {\n            ps.setBoolean(1, processInsertValue(group.getAuditEnabled(), false));\n            ps.setBoolean(2, processInsertValue(group.getSelfServe(), false));\n            ps.setBoolean(3, processInsertValue(group.getReviewEnabled(), false));\n            ps.setString(4, processInsertValue(group.getNotifyRoles()));\n            ps.setString(5, processInsertValue(group.getUserAuthorityFilter()));\n            ps.setString(6, processInsertValue(group.getUserAuthorityExpiration()));\n            ps.setInt(7, processInsertValue(group.getMemberExpiryDays()));\n            ps.setInt(8, processInsertValue(group.getServiceExpiryDays()));\n            ps.setInt(9, groupId);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public boolean deleteGroup(String domainName, String groupName) {\n\n        final String caller = \"deleteGroup\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int affectedRows;\n        try (PreparedStatement ps = con.prepareStatement(SQL_DELETE_GROUP)) {\n            ps.setInt(1, domainId);\n            ps.setString(2, groupName);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public boolean updateGroupModTimestamp(String domainName, String groupName) {\n        int affectedRows;\n        final String caller = \"updateGroupModTimestamp\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int groupId = getGroupId(domainId, groupName);\n        if (groupId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_GROUP, ResourceUtils.groupResourceName(domainName, groupName));\n        }\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_UPDATE_GROUP_MOD_TIMESTAMP)) {\n            ps.setInt(1, groupId);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public int countGroups(String domainName) {\n        final String caller = \"countGroups\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int count = 0;\n        try (PreparedStatement ps = con.prepareStatement(SQL_COUNT_GROUP)) {\n            ps.setInt(1, domainId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    count = rs.getInt(1);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return count;\n    }\n\n    @Override\n    public List<GroupAuditLog> listGroupAuditLogs(String domainName, String groupName) {\n\n        final String caller = \"listGroupAuditLogs\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int groupId = getGroupId(domainId, groupName);\n        if (groupId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_GROUP, ResourceUtils.groupResourceName(domainName, groupName));\n        }\n        List<GroupAuditLog> logs = new ArrayList<>();\n        try (PreparedStatement ps = con.prepareStatement(SQL_LIST_GROUP_AUDIT_LOGS)) {\n            ps.setInt(1, groupId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    GroupAuditLog log = new GroupAuditLog();\n                    log.setAction(rs.getString(ZMSConsts.DB_COLUMN_ACTION));\n                    log.setMember(rs.getString(ZMSConsts.DB_COLUMN_MEMBER));\n                    log.setAdmin(rs.getString(ZMSConsts.DB_COLUMN_ADMIN));\n                    log.setAuditRef(saveValue(rs.getString(ZMSConsts.DB_COLUMN_AUDIT_REF)));\n                    log.setCreated(Timestamp.fromMillis(rs.getTimestamp(ZMSConsts.DB_COLUMN_CREATED).getTime()));\n                    logs.add(log);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return logs;\n    }\n\n    @Override\n    public boolean updateGroupReviewTimestamp(String domainName, String groupName) {\n        int affectedRows;\n        final String caller = \"updateGroupReviewTimestamp\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int groupId = getGroupId(domainId, groupName);\n        if (groupId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_GROUP, ResourceUtils.groupResourceName(domainName, groupName));\n        }\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_UPDATE_GROUP_REVIEW_TIMESTAMP)) {\n            ps.setInt(1, groupId);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    void getStdGroupMembers(int groupId, List<GroupMember> members, final String caller) {\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_LIST_GROUP_MEMBERS)) {\n            ps.setInt(1, groupId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    GroupMember groupMember = new GroupMember();\n                    groupMember.setMemberName(rs.getString(1));\n                    java.sql.Timestamp expiration = rs.getTimestamp(2);\n                    if (expiration != null) {\n                        groupMember.setExpiration(Timestamp.fromMillis(expiration.getTime()));\n                    }\n                    groupMember.setActive(nullIfDefaultValue(rs.getBoolean(3), true));\n                    groupMember.setAuditRef(rs.getString(4));\n                    groupMember.setSystemDisabled(nullIfDefaultValue(rs.getInt(5), 0));\n                    groupMember.setApproved(true);\n                    members.add(groupMember);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n    }\n\n    void getPendingGroupMembers(int groupId, List<GroupMember> members, final String caller) {\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_LIST_PENDING_GROUP_MEMBERS)) {\n            ps.setInt(1, groupId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    GroupMember groupMember = new GroupMember();\n                    groupMember.setMemberName(rs.getString(1));\n                    java.sql.Timestamp timestamp = rs.getTimestamp(2);\n                    if (timestamp != null) {\n                        groupMember.setExpiration(Timestamp.fromMillis(timestamp.getTime()));\n                    }\n                    timestamp = rs.getTimestamp(3);\n                    if (timestamp != null) {\n                        groupMember.setRequestTime(Timestamp.fromMillis(timestamp.getTime()));\n                    }\n                    groupMember.setAuditRef(rs.getString(4));\n                    groupMember.setActive(false);\n                    groupMember.setApproved(false);\n                    members.add(groupMember);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n    }\n\n    @Override\n    public List<GroupMember> listGroupMembers(String domainName, String groupName, Boolean pending) {\n        final String caller = \"listGroupMembers\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int groupId = getGroupId(domainId, groupName);\n        if (groupId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_GROUP, ResourceUtils.groupResourceName(domainName, groupName));\n        }\n\n        // first get our standard group members\n\n        List<GroupMember> members = new ArrayList<>();\n        getStdGroupMembers(groupId, members, caller);\n\n        // if requested, include pending members as well\n\n        if (pending == Boolean.TRUE) {\n            getPendingGroupMembers(groupId, members, caller);\n        }\n\n        members.sort(GroupMemberComparator);\n        return members;\n    }\n\n    @Override\n    public int countGroupMembers(String domainName, String groupName) {\n        final String caller = \"countGroupMembers\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int groupId = getGroupId(domainId, groupName);\n        if (groupId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_GROUP, ResourceUtils.groupResourceName(domainName, groupName));\n        }\n        int count = 0;\n        try (PreparedStatement ps = con.prepareStatement(SQL_COUNT_GROUP_MEMBERS)) {\n            ps.setInt(1, groupId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    count = rs.getInt(1);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return count;\n    }\n\n    boolean getGroupMembership(final String query, int groupId, final String member, long expiration,\n                               GroupMembership membership, boolean disabledFlagCheck, final String caller) {\n\n        try (PreparedStatement ps = con.prepareStatement(query)) {\n            ps.setInt(1, groupId);\n            ps.setString(2, member);\n            if (expiration != 0) {\n                ps.setTimestamp(3, new java.sql.Timestamp(expiration));\n            }\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    membership.setIsMember(true);\n                    java.sql.Timestamp expiry = rs.getTimestamp(ZMSConsts.DB_COLUMN_EXPIRATION);\n                    if (expiry != null) {\n                        membership.setExpiration(Timestamp.fromMillis(expiry.getTime()));\n                    }\n                    membership.setRequestPrincipal(rs.getString(ZMSConsts.DB_COLUMN_REQ_PRINCIPAL));\n                    if (disabledFlagCheck) {\n                        membership.setSystemDisabled(nullIfDefaultValue(rs.getInt(ZMSConsts.DB_COLUMN_SYSTEM_DISABLED), 0));\n                    }\n                    return true;\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return false;\n    }\n\n    @Override\n    public GroupMembership getGroupMember(String domainName, String groupName, String member, long expiration, boolean pending) {\n\n        final String caller = \"getGroupMember\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int groupId = getGroupId(domainId, groupName);\n        if (groupId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_GROUP, ResourceUtils.groupResourceName(domainName, groupName));\n        }\n\n        GroupMembership membership = new GroupMembership()\n                .setMemberName(member)\n                .setGroupName(ResourceUtils.groupResourceName(domainName, groupName))\n                .setIsMember(false);\n\n        // first we're going to check if we have a standard user with the given\n        // details before checking for pending unless we're specifically asking\n        // for pending member only in which case we'll skip the first check\n\n        if (!pending) {\n            String query = expiration == 0 ? SQL_GET_GROUP_MEMBER : SQL_GET_TEMP_GROUP_MEMBER;\n            if (getGroupMembership(query, groupId, member, expiration, membership, true, caller)) {\n                membership.setApproved(true);\n            }\n        }\n\n        if (!membership.getIsMember()) {\n            String query = expiration == 0 ? SQL_GET_PENDING_GROUP_MEMBER : SQL_GET_TEMP_PENDING_GROUP_MEMBER;\n            if (getGroupMembership(query, groupId, member, expiration, membership, false, caller)) {\n                membership.setApproved(false);\n            }\n        }\n\n        return membership;\n    }\n\n    boolean groupMemberExists(int groupId, int principalId, boolean pending, final String caller) {\n\n        String statement = pending ? SQL_PENDING_GROUP_MEMBER_EXISTS : SQL_STD_GROUP_MEMBER_EXISTS;\n        try (PreparedStatement ps = con.prepareStatement(statement)) {\n            ps.setInt(1, groupId);\n            ps.setInt(2, principalId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    return true;\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return false;\n    }\n\n    boolean insertGroupAuditLog(int groupId, String admin, String member,\n                               String action, String auditRef) {\n\n        int affectedRows;\n        final String caller = \"insertGroupAuditEntry\";\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_INSERT_GROUP_AUDIT_LOG)) {\n            ps.setInt(1, groupId);\n            ps.setString(2, processInsertValue(admin));\n            ps.setString(3, member);\n            ps.setString(4, action);\n            ps.setString(5, processInsertValue(auditRef));\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    boolean insertPendingGroupMember(int groupId, int principalId, GroupMember groupMember,\n                                    final String admin, final String auditRef, boolean groupMemberExists, final String caller) {\n\n        java.sql.Timestamp expiration = null;\n        if (groupMember.getExpiration() != null) {\n            expiration = new java.sql.Timestamp(groupMember.getExpiration().toDate().getTime());\n        }\n\n        int affectedRows;\n        if (groupMemberExists) {\n\n            try (PreparedStatement ps = con.prepareStatement(SQL_UPDATE_PENDING_GROUP_MEMBER)) {\n                ps.setTimestamp(1, expiration);\n                ps.setString(2, processInsertValue(auditRef));\n                ps.setString(3, processInsertValue(admin));\n                ps.setInt(4, groupId);\n                ps.setInt(5, principalId);\n                affectedRows = executeUpdate(ps, caller);\n            } catch (SQLException ex) {\n                throw sqlError(ex, caller);\n            }\n\n        } else {\n\n            try (PreparedStatement ps = con.prepareStatement(SQL_INSERT_PENDING_GROUP_MEMBER)) {\n                ps.setInt(1, groupId);\n                ps.setInt(2, principalId);\n                ps.setTimestamp(3, expiration);\n                ps.setString(4, processInsertValue(auditRef));\n                ps.setString(5, processInsertValue(admin));\n                affectedRows = executeUpdate(ps, caller);\n            } catch (SQLException ex) {\n                throw sqlError(ex, caller);\n            }\n        }\n\n        return (affectedRows > 0);\n    }\n\n    boolean insertStandardGroupMember(int groupId, int principalId, GroupMember groupMember,\n                                     final String admin, final String principal, final String auditRef,\n                                     boolean groupMemberExists, boolean approveRequest, final String caller) {\n\n        java.sql.Timestamp expiration = null;\n        if (groupMember.getExpiration() != null) {\n            expiration = new java.sql.Timestamp(groupMember.getExpiration().toDate().getTime());\n        }\n\n        boolean result;\n        String auditOperation;\n\n        if (groupMemberExists) {\n\n            try (PreparedStatement ps = con.prepareStatement(SQL_UPDATE_GROUP_MEMBER)) {\n                ps.setTimestamp(1, expiration);\n                ps.setBoolean(2, processInsertValue(groupMember.getActive(), true));\n                ps.setString(3, processInsertValue(auditRef));\n                ps.setString(4, processInsertValue(admin));\n                ps.setInt(5, groupId);\n                ps.setInt(6, principalId);\n                executeUpdate(ps, caller);\n            } catch (SQLException ex) {\n                throw sqlError(ex, caller);\n            }\n            auditOperation = approveRequest ? \"APPROVE\" : \"UPDATE\";\n            result = true;\n\n        } else {\n\n            int affectedRows;\n            try (PreparedStatement ps = con.prepareStatement(SQL_INSERT_GROUP_MEMBER)) {\n                ps.setInt(1, groupId);\n                ps.setInt(2, principalId);\n                ps.setTimestamp(3, expiration);\n                ps.setBoolean(4, processInsertValue(groupMember.getActive(), true));\n                ps.setString(5, processInsertValue(auditRef));\n                ps.setString(6, processInsertValue(admin));\n                affectedRows = executeUpdate(ps, caller);\n            } catch (SQLException ex) {\n                throw sqlError(ex, caller);\n            }\n\n            auditOperation = approveRequest ? \"APPROVE\" : \"ADD\";\n            result = (affectedRows > 0);\n        }\n\n        // add audit log entry for this change if the operation was successful\n        // add return the result of the audit log insert operation\n\n        if (result) {\n            result = insertGroupAuditLog(groupId, admin, principal, auditOperation, auditRef);\n        }\n        return result;\n    }\n\n    @Override\n    public boolean insertGroupMember(String domainName, String groupName, GroupMember groupMember,\n                                     String admin, String auditRef) {\n\n        final String caller = \"insertGroupMember\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int groupId = getGroupId(domainId, groupName);\n        if (groupId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_GROUP, ResourceUtils.groupResourceName(domainName, groupName));\n        }\n        String principal = groupMember.getMemberName();\n        if (!validatePrincipalDomain(principal)) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, principal);\n        }\n        int principalId = getPrincipalId(principal);\n        if (principalId == 0) {\n            principalId = insertPrincipal(principal);\n            if (principalId == 0) {\n                throw internalServerError(caller, \"Unable to insert principal: \" + principal);\n            }\n        }\n\n        // need to check if entry already exists\n\n        boolean pendingRequest = (groupMember.getApproved() == Boolean.FALSE);\n        boolean groupMemberExists = groupMemberExists(groupId, principalId, pendingRequest, caller);\n\n        // process the request based on the type of the request\n        // either pending request or standard insert\n\n        boolean result;\n        if (pendingRequest) {\n            result = insertPendingGroupMember(groupId, principalId, groupMember, admin,\n                    auditRef, groupMemberExists, caller);\n        } else {\n            result = insertStandardGroupMember(groupId, principalId, groupMember, admin,\n                    principal, auditRef, groupMemberExists, false, caller);\n        }\n        return result;\n    }\n\n    @Override\n    public boolean deleteGroupMember(String domainName, String groupName, String principal, String admin, String auditRef) {\n\n        final String caller = \"deleteGroupMember\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int groupId = getGroupId(domainId, groupName);\n        if (groupId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_GROUP, ResourceUtils.groupResourceName(domainName, groupName));\n        }\n        int principalId = getPrincipalId(principal);\n        if (principalId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_PRINCIPAL, principal);\n        }\n        int affectedRows;\n        try (PreparedStatement ps = con.prepareStatement(SQL_DELETE_GROUP_MEMBER)) {\n            ps.setInt(1, groupId);\n            ps.setInt(2, principalId);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        boolean result = (affectedRows > 0);\n\n        // add audit log entry for this change if the delete was successful\n        // add return the result of the audit log insert operation\n\n        if (result) {\n            result = insertGroupAuditLog(groupId, admin, principal, \"DELETE\", auditRef);\n        }\n\n        return result;\n    }\n\n    @Override\n    public boolean updateGroupMemberDisabledState(String domainName, String groupName, String principal, String admin,\n                                                  int disabledState, String auditRef) {\n\n        final String caller = \"updateGroupMemberDisabledState\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int groupId = getGroupId(domainId, groupName);\n        if (groupId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_GROUP, ResourceUtils.groupResourceName(domainName, groupName));\n        }\n        int principalId = getPrincipalId(principal);\n        if (principalId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_PRINCIPAL, principal);\n        }\n\n        int affectedRows;\n        try (PreparedStatement ps = con.prepareStatement(SQL_UPDATE_GROUP_MEMBER_DISABLED_STATE)) {\n            ps.setInt(1, disabledState);\n            ps.setString(2, processInsertValue(auditRef));\n            ps.setString(3, processInsertValue(admin));\n            ps.setInt(4, groupId);\n            ps.setInt(5, principalId);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        boolean result = (affectedRows > 0);\n\n        // add audit log entry for this change if the disable was successful\n        // add return the result of the audit log insert operation\n\n        if (result) {\n            final String operation = disabledState == 0 ? \"ENABLE\" : \"DISABLE\";\n            result = insertGroupAuditLog(groupId, admin, principal, operation, auditRef);\n        }\n\n        return result;\n    }\n\n    @Override\n    public boolean deletePendingGroupMember(String domainName, String groupName, String principal,\n                                           String admin, String auditRef) {\n\n        final String caller = \"deletePendingGroupMember\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int groupId = getGroupId(domainId, groupName);\n        if (groupId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_GROUP, ResourceUtils.groupResourceName(domainName, groupName));\n        }\n        int principalId = getPrincipalId(principal);\n        if (principalId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_PRINCIPAL, principal);\n        }\n        return executeDeletePendingGroupMember(groupId, principalId, admin, principal, auditRef, true, caller);\n    }\n\n    public boolean executeDeletePendingGroupMember(int groupId, int principalId, final String admin,\n                                                  final String principal, final String auditRef, boolean auditLog, final String caller) {\n\n        int affectedRows;\n        try (PreparedStatement ps = con.prepareStatement(SQL_DELETE_PENDING_GROUP_MEMBER)) {\n            ps.setInt(1, groupId);\n            ps.setInt(2, principalId);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        boolean result = (affectedRows > 0);\n        if (result && auditLog) {\n            result = insertGroupAuditLog(groupId, admin, principal, \"REJECT\", auditRef);\n        }\n        return result;\n    }\n\n    @Override\n    public boolean confirmGroupMember(String domainName, String groupName, GroupMember groupMember,\n                                      String admin, String auditRef) {\n\n        final String caller = \"confirmGroupMember\";\n\n        String principal = groupMember.getMemberName();\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int groupId = getGroupId(domainId, groupName);\n        if (groupId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_GROUP, ResourceUtils.groupResourceName(domainName, groupName));\n        }\n        int principalId = getPrincipalId(principal);\n        if (principalId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_PRINCIPAL, principal);\n        }\n\n        // need to check if the pending entry already exists\n        // before doing any work\n\n        boolean groupMemberExists = groupMemberExists(groupId, principalId, true, caller);\n        if (!groupMemberExists) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_PRINCIPAL, principal);\n        }\n\n        boolean result;\n        if (groupMember.getApproved() == Boolean.TRUE) {\n            groupMemberExists = groupMemberExists(groupId, principalId, false, caller);\n            result = insertStandardGroupMember(groupId, principalId, groupMember, admin,\n                    principal, auditRef, groupMemberExists, true, caller);\n\n            if (result) {\n                executeDeletePendingGroupMember(groupId, principalId, admin, principal,\n                        auditRef, false, caller);\n            }\n        } else {\n            result = executeDeletePendingGroupMember(groupId, principalId, admin,\n                    principal, auditRef, true, caller);\n        }\n\n        return result;\n    }\n\n    private DomainGroupMember getGroupsForPrincipal(String caller, DomainGroupMember domainGroupMember, PreparedStatement ps) throws SQLException {\n\n        try (ResultSet rs = executeQuery(ps, caller)) {\n            while (rs.next()) {\n                final String groupName = rs.getString(1);\n                final String domain = rs.getString(2);\n\n                GroupMember groupMember = new GroupMember();\n                groupMember.setGroupName(groupName);\n                groupMember.setDomainName(domain);\n\n                java.sql.Timestamp expiration = rs.getTimestamp(3);\n                if (expiration != null) {\n                    groupMember.setExpiration(Timestamp.fromMillis(expiration.getTime()));\n                }\n                groupMember.setSystemDisabled(nullIfDefaultValue(rs.getInt(4), 0));\n\n                domainGroupMember.getMemberGroups().add(groupMember);\n            }\n\n            return domainGroupMember;\n        }\n    }\n\n    @Override\n    public DomainGroupMember getPrincipalGroups(String principal, String domainName) {\n\n        final String caller = \"getPrincipalGroups\";\n\n        int principalId = getPrincipalId(principal);\n        if (principalId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_PRINCIPAL, principal);\n        }\n\n        DomainGroupMember domainGroupMember = new DomainGroupMember();\n        domainGroupMember.setMemberGroups(new ArrayList<>());\n        domainGroupMember.setMemberName(principal);\n        if (StringUtil.isEmpty(domainName)) {\n            try (PreparedStatement ps = con.prepareStatement(SQL_GET_PRINCIPAL_GROUPS)) {\n                ps.setInt(1, principalId);\n                return getGroupsForPrincipal(caller, domainGroupMember, ps);\n            } catch (SQLException ex) {\n                throw sqlError(ex, caller);\n            }\n        } else {\n            int domainId = getDomainId(domainName);\n            if (domainId == 0) {\n                throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n            }\n            try (PreparedStatement ps = con.prepareStatement(SQL_GET_PRINCIPAL_GROUPS_DOMAIN)) {\n                ps.setInt(1, principalId);\n                ps.setInt(2, domainId);\n                return getGroupsForPrincipal(caller, domainGroupMember, ps);\n            } catch (SQLException ex) {\n                throw sqlError(ex, caller);\n            }\n        }\n    }\n\n    @Override\n    public List<PrincipalGroup> listGroupsWithUserAuthorityRestrictions() {\n\n        final String caller = \"listGroupsWithUserAuthorityRestrictions\";\n        List<PrincipalGroup> groups = new ArrayList<>();\n        try (PreparedStatement ps = con.prepareStatement(SQL_LIST_GROUPS_WITH_RESTRICTIONS)) {\n\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    PrincipalGroup group = new PrincipalGroup();\n                    group.setDomainName(rs.getString(ZMSConsts.DB_COLUMN_AS_DOMAIN_NAME));\n                    group.setGroupName(rs.getString(ZMSConsts.DB_COLUMN_AS_GROUP_NAME));\n                    group.setDomainUserAuthorityFilter(rs.getString(ZMSConsts.DB_COLUMN_AS_DOMAIN_USER_AUTHORITY_FILTER));\n                    groups.add(group);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n\n        return groups;\n    }\n\n\n    @Override\n    public boolean updatePrincipal(String principal, int newState) {\n        final String caller = \"updatePrincipal\";\n\n        int affectedRows;\n        try (PreparedStatement ps = con.prepareStatement(SQL_UPDATE_PRINCIPAL)) {\n            ps.setInt(1, newState);\n            ps.setString(2, principal);\n            affectedRows = executeUpdate(ps, caller);\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return (affectedRows > 0);\n    }\n\n    @Override\n    public List<String> getPrincipals(int queriedState) {\n        final String caller = \"getPrincipals\";\n        List<String> principals = new ArrayList<>();\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_PRINCIPAL)) {\n            ps.setInt(1, queriedState);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    principals.add(rs.getString(ZMSConsts.DB_COLUMN_NAME));\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return principals;\n    }\n\n    // To avoid firing multiple queries against DB, this function will generate 1 consolidated query for all domains->templates combination\n    public String generateDomainTemplateVersionQuery(Map<String, Integer> templateNameAndLatestVersion) {\n        StringBuilder query = new StringBuilder();\n        query.append(\"SELECT domain.name, domain_template.template FROM domain_template \" +\n                \"JOIN domain ON domain_template.domain_id=domain.domain_id WHERE \");\n        for (String templateName : templateNameAndLatestVersion.keySet()) {\n            query.append(\"(domain_template.template = '\").append(templateName).append(\"' and current_version < \")\n                    .append(templateNameAndLatestVersion.get(templateName)).append(\") OR \");\n        }\n        //To remove the last occurrence of \"OR\" from the generated query\n        query.delete(query.lastIndexOf(\") OR\"), query.lastIndexOf(\"OR\") + 3).append(\");\");\n        return query.toString();\n    }\n\n    RuntimeException notFoundError(String caller, String objectType, String objectName) {\n        rollbackChanges();\n        String message = \"unknown \" + objectType + \" - \" + objectName;\n        return ZMSUtils.notFoundError(message, caller);\n    }\n\n    RuntimeException requestError(String caller, String message) {\n        rollbackChanges();\n        return ZMSUtils.requestError(message, caller);\n    }\n\n    RuntimeException internalServerError(String caller, String message) {\n        rollbackChanges();\n        return ZMSUtils.internalServerError(message, caller);\n    }\n\n    RuntimeException sqlError(SQLException ex, String caller) {\n\n        // check to see if this is a conflict error in which case\n        // we're going to let the server to retry the caller\n        // The two SQL states that are 'retry-able' are 08S01\n        // for a communications error, and 40001 for deadlock.\n        // also check for the error code where the mysql server is\n        // in read-mode which could happen if we had a failover\n        // and the connections are still going to the old master\n\n        String sqlState = ex.getSQLState();\n        int code = ResourceException.INTERNAL_SERVER_ERROR;\n        String msg;\n        if (\"08S01\".equals(sqlState) || \"40001\".equals(sqlState)) {\n            code = ResourceException.CONFLICT;\n            msg = \"Concurrent update conflict, please retry your operation later.\";\n        } else if (ex.getErrorCode() == MYSQL_ER_OPTION_PREVENTS_STATEMENT) {\n            code = ResourceException.GONE;\n            msg = \"MySQL Database running in read-only mode\";\n        } else if (ex.getErrorCode() == MYSQL_ER_OPTION_DUPLICATE_ENTRY) {\n            code = ResourceException.BAD_REQUEST;\n            msg = \"Entry already exists\";\n        } else if (ex instanceof SQLTimeoutException) {\n            code = ResourceException.SERVICE_UNAVAILABLE;\n            msg = \"Statement cancelled due to timeout\";\n        } else {\n            msg = ex.getMessage() + \", state: \" + sqlState + \", code: \" + ex.getErrorCode();\n        }\n        rollbackChanges();\n        return ZMSUtils.error(code, msg, caller);\n    }\n\n    Boolean nullIfDefaultValue(boolean flag, boolean defaultValue) {\n        return flag == defaultValue ? null : flag;\n    }\n\n    Integer nullIfDefaultValue(int value, int defaultValue) {\n        return value == defaultValue ? null : value;\n    }\n\n    private void addTagsToRoles(Map<String, Role> roleMap, String domainName) {\n\n        Map<String, Map<String, StringList>> domainRoleTags = getDomainRoleTags(domainName);\n        if (domainRoleTags != null) {\n            for (Map.Entry<String, Role> roleEntry : roleMap.entrySet()) {\n                Map<String, StringList> roleTag = domainRoleTags.get(roleEntry.getKey());\n                if (roleTag != null) {\n                    roleEntry.getValue().setTags(roleTag);\n                }\n            }\n        }\n    }\n\n    Map<String, Map<String, StringList>> getDomainRoleTags(String domainName) {\n        final String caller = \"getDomainRoleTags\";\n        Map<String, Map<String, StringList>> domainRoleTags = null;\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_DOMAIN_ROLE_TAGS)) {\n            ps.setString(1, domainName);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    String roleName = rs.getString(1);\n                    String tagKey = rs.getString(2);\n                    String tagValue = rs.getString(3);\n                    if (domainRoleTags == null) {\n                        domainRoleTags = new HashMap<>();\n                    }\n                    Map<String, StringList> roleTag = domainRoleTags.computeIfAbsent(roleName, tags -> new HashMap<>());\n                    StringList tagValues = roleTag.computeIfAbsent(tagKey, k -> new StringList().setList(new ArrayList<>()));\n                    tagValues.getList().add(tagValue);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return domainRoleTags;\n    }\n\n    @Override\n    public Map<String, StringList> getRoleTags(String domainName, String roleName) {\n        final String caller = \"getRoleTags\";\n        Map<String, StringList> roleTag = null;\n\n        try (PreparedStatement ps = con.prepareStatement(SQL_GET_ROLE_TAGS)) {\n            ps.setString(1, domainName);\n            ps.setString(2, roleName);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                while (rs.next()) {\n                    String tagKey = rs.getString(1);\n                    String tagValue = rs.getString(2);\n                    if (roleTag == null) {\n                        roleTag = new HashMap<>();\n                    }\n                    StringList tagValues = roleTag.computeIfAbsent(tagKey, k -> new StringList().setList(new ArrayList<>()));\n                    tagValues.getList().add(tagValue);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return roleTag;\n    }\n\n    @Override\n    public boolean insertRoleTags(String roleName, String domainName, Map<String, StringList> roleTags) {\n        final String caller = \"insertRoleTags\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int roleId = getRoleId(domainId, roleName);\n        if (roleId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_ROLE, ResourceUtils.roleResourceName(domainName, roleName));\n        }\n        int curTagCount = getRoleTagsCount(roleId);\n\n        int remainingTagsToInsert = roleTagsLimit - curTagCount;\n        boolean res = true;\n        for (Map.Entry<String, StringList> e : roleTags.entrySet()) {\n            for (int i = 0; i < e.getValue().getList().size() && remainingTagsToInsert-- > 0; i++) {\n                String tagValue = e.getValue().getList().get(i);\n                try (PreparedStatement ps = con.prepareStatement(SQL_INSERT_ROLE_TAG)) {\n                    ps.setInt(1, roleId);\n                    ps.setString(2, processInsertValue(e.getKey()));\n                    ps.setString(3, processInsertValue(tagValue));\n                    res &= (executeUpdate(ps, caller) > 0);\n                } catch (SQLException ex) {\n                    throw sqlError(ex, caller);\n                }\n            }\n        }\n        if (remainingTagsToInsert < 0) {\n            LOG.info(\"Role tags limit for role: [{}], domain: [{}] has reached\", roleName, domainName);\n        }\n        return res;\n    }\n    \n    private int getRoleTagsCount(int roleId) {\n        final String caller = \"getRoleTagsCount\";\n        int count = 0;\n        try (PreparedStatement ps = con.prepareStatement(SQL_ROLE_TAG_COUNT)) {\n            ps.setInt(1, roleId);\n            try (ResultSet rs = executeQuery(ps, caller)) {\n                if (rs.next()) {\n                    count = rs.getInt(1);\n                }\n            }\n        } catch (SQLException ex) {\n            throw sqlError(ex, caller);\n        }\n        return count;\n    }\n\n    @Override\n    public boolean deleteRoleTags(String roleName, String domainName, Set<String> tagKeys) {\n        final String caller = \"deleteRoleTags\";\n\n        int domainId = getDomainId(domainName);\n        if (domainId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_DOMAIN, domainName);\n        }\n        int roleId = getRoleId(domainId, roleName);\n        if (roleId == 0) {\n            throw notFoundError(caller, ZMSConsts.OBJECT_ROLE, ResourceUtils.roleResourceName(domainName, roleName));\n        }\n        boolean res = true;\n        for (String tagKey : tagKeys) {\n            try (PreparedStatement ps = con.prepareStatement(SQL_DELETE_ROLE_TAG)) {\n                ps.setInt(1, roleId);\n                ps.setString(2, processInsertValue(tagKey));\n                res &= (executeUpdate(ps, caller) > 0);\n            } catch (SQLException ex) {\n                throw sqlError(ex, caller);\n            }\n        }\n        return res;\n    }\n}\n", "idx": 1, "id": 5644, "msg": "why are we adding the current tag count to new tag count ?", "proj": "AthenZ-athenz", "lang": "java"}
{"patch": "@@ -41,6 +41,13 @@ public interface Table {\n \n   /**\n    * Refresh the current table metadata.\n+   *\n+   * <p>If this table is associated with a TransactionalCatalog, this refresh will be bounded by\n+   * the visibility that the {@code IsolationLevel} of that transaction exposes. For example, if\n+   * we are in a context of {@code READ_COMMITTED}, this refresh will update to the latest state\n+   * of the table. However, in the case of {@code SERIALIZABLE} where this table hasn't mutated\n+   * within this transaction, calling refresh will have no impact as the isolation level\n+   * constrains all observations to within the transactional snapshot.\n    */\n   void refresh();\n ", "y": 1, "oldf": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\n\npackage org.apache.iceberg;\n\nimport java.util.List;\nimport java.util.Map;\nimport org.apache.iceberg.encryption.EncryptionManager;\nimport org.apache.iceberg.io.FileIO;\nimport org.apache.iceberg.io.LocationProvider;\n\n/**\n * Represents a table.\n */\npublic interface Table {\n\n  /**\n   * Return the full name for this table.\n   *\n   * @return this table's name\n   */\n  default String name() {\n    return toString();\n  }\n\n  /**\n   * Refresh the current table metadata.\n   */\n  void refresh();\n\n  /**\n   * Create a new {@link TableScan scan} for this table.\n   * <p>\n   * Once a table scan is created, it can be refined to project columns and filter data.\n   *\n   * @return a table scan for this table\n   */\n  TableScan newScan();\n\n  /**\n   * Return the {@link Schema schema} for this table.\n   *\n   * @return this table's schema\n   */\n  Schema schema();\n\n  /**\n   * Return the {@link PartitionSpec partition spec} for this table.\n   *\n   * @return this table's partition spec\n   */\n  PartitionSpec spec();\n\n  /**\n   * Return a map of {@link PartitionSpec partition specs} for this table.\n   *\n   * @return this table's partition specs map\n   */\n  Map<Integer, PartitionSpec> specs();\n\n  /**\n   * Return the {@link SortOrder sort order} for this table.\n   *\n   * @return this table's sort order\n   */\n  SortOrder sortOrder();\n\n  /**\n   * Return a map of sort order IDs to {@link SortOrder sort orders} for this table.\n   *\n   * @return this table's sort orders map\n   */\n  Map<Integer, SortOrder> sortOrders();\n\n  /**\n   * Return a map of string properties for this table.\n   *\n   * @return this table's properties map\n   */\n  Map<String, String> properties();\n\n  /**\n   * Return the table's base location.\n   *\n   * @return this table's location\n   */\n  String location();\n\n  /**\n   * Get the current {@link Snapshot snapshot} for this table, or null if there are no snapshots.\n   *\n   * @return the current table Snapshot.\n   */\n  Snapshot currentSnapshot();\n\n  /**\n   * Get the {@link Snapshot snapshot} of this table with the given id, or null if there is no\n   * matching snapshot.\n   *\n   * @return the {@link Snapshot} with the given id.\n   */\n  Snapshot snapshot(long snapshotId);\n\n  /**\n   * Get the {@link Snapshot snapshots} of this table.\n   *\n   * @return an Iterable of snapshots of this table.\n   */\n  Iterable<Snapshot> snapshots();\n\n  /**\n   * Get the snapshot history of this table.\n   *\n   * @return a list of {@link HistoryEntry history entries}\n   */\n  List<HistoryEntry> history();\n\n  /**\n   * Create a new {@link UpdateSchema} to alter the columns of this table and commit the change.\n   *\n   * @return a new {@link UpdateSchema}\n   */\n  UpdateSchema updateSchema();\n\n  /**\n   * Create a new {@link UpdateProperties} to update table properties and commit the changes.\n   *\n   * @return a new {@link UpdateProperties}\n   */\n  UpdateProperties updateProperties();\n\n  /**\n   * Create a new {@link UpdateLocation} to update table location and commit the changes.\n   *\n   * @return a new {@link UpdateLocation}\n   */\n  UpdateLocation updateLocation();\n\n  /**\n   * Create a new {@link AppendFiles append API} to add files to this table and commit.\n   *\n   * @return a new {@link AppendFiles}\n   */\n  AppendFiles newAppend();\n\n  /**\n   * Create a new {@link AppendFiles append API} to add files to this table and commit.\n   * <p>\n   * Using this method signals to the underlying implementation that the append should not perform\n   * extra work in order to commit quickly. Fast appends are not recommended for normal writes\n   * because the fast commit may cause split planning to slow down over time.\n   * <p>\n   * Implementations may not support fast appends, in which case this will return the same appender\n   * as {@link #newAppend()}.\n   *\n   * @return a new {@link AppendFiles}\n   */\n  default AppendFiles newFastAppend() {\n    return newAppend();\n  }\n\n  /**\n   * Create a new {@link RewriteFiles rewrite API} to replace files in this table and commit.\n   *\n   * @return a new {@link RewriteFiles}\n   */\n  RewriteFiles newRewrite();\n\n  /**\n   * Create a new {@link RewriteManifests rewrite manifests API} to replace manifests for this\n   * table and commit.\n   *\n   * @return a new {@link RewriteManifests}\n   */\n  RewriteManifests rewriteManifests();\n\n  /**\n   * Create a new {@link OverwriteFiles overwrite API} to overwrite files by a filter expression.\n   *\n   * @return a new {@link OverwriteFiles}\n   */\n  OverwriteFiles newOverwrite();\n\n  /**\n   * Create a new {@link RowDelta row-level delta API} to remove or replace rows in existing data files.\n   *\n   * @return a new {@link RowDelta}\n   */\n  RowDelta newRowDelta();\n\n  /**\n   * Not recommended: Create a new {@link ReplacePartitions replace partitions API} to dynamically\n   * overwrite partitions in the table with new data.\n   * <p>\n   * This is provided to implement SQL compatible with Hive table operations but is not recommended.\n   * Instead, use the {@link OverwriteFiles overwrite API} to explicitly overwrite data.\n   *\n   * @return a new {@link ReplacePartitions}\n   */\n  ReplacePartitions newReplacePartitions();\n\n  /**\n   * Create a new {@link DeleteFiles delete API} to replace files in this table and commit.\n   *\n   * @return a new {@link DeleteFiles}\n   */\n  DeleteFiles newDelete();\n\n  /**\n   * Create a new {@link ExpireSnapshots expire API} to manage snapshots in this table and commit.\n   *\n   * @return a new {@link ExpireSnapshots}\n   */\n  ExpireSnapshots expireSnapshots();\n\n  /**\n   * Create a new {@link Rollback rollback API} to roll back to a previous snapshot and commit.\n   *\n   * @return a new {@link Rollback}\n   * @deprecated Replaced by {@link #manageSnapshots()}\n   */\n  @Deprecated\n  Rollback rollback();\n\n  /**\n   * Create a new {@link ManageSnapshots manage snapshots API} to manage snapshots in this table and commit.\n   * @return a new {@link ManageSnapshots}\n   */\n  ManageSnapshots manageSnapshots();\n\n  /**\n   * Create a new {@link Transaction transaction API} to commit multiple table operations at once.\n   *\n   * @return a new {@link Transaction}\n   */\n  Transaction newTransaction();\n\n  /**\n   * Returns a {@link FileIO} to read and write table data and metadata files.\n   */\n  FileIO io();\n\n  /**\n   * Returns an {@link org.apache.iceberg.encryption.EncryptionManager} to encrypt and decrypt data files.\n   */\n  EncryptionManager encryption();\n\n  /**\n   * Returns a {@link LocationProvider} to provide locations for new data files.\n   */\n  LocationProvider locationProvider();\n}\n", "idx": 1, "id": 29003, "msg": "\"this table hasn't mutated within this transaction\" may sound like implying that if this transaction contains table mutation changes, `refresh` may have impact, which I think is not true? I guess what you were saying was if other transactions committed to this table successfully when this transaction is half way through, refresh in this transaction will still return the same state as when this transaction begins.", "proj": "apache-iceberg", "lang": "java"}
{"patch": "@@ -47,11 +47,11 @@ func initProvider() func() {\n \t// `localhost:30080` address. Otherwise, replace `localhost` with the\n \t// address of your cluster. If you run the app inside k8s, then you can\n \t// probably connect directly to the service through dns\n-\texp, err := otlp.NewExporter(\n-\t\totlp.WithInsecure(),\n+\tconfig := otlp.NewConnectionConfig(otlp.WithInsecure(),\n \t\totlp.WithAddress(\"localhost:30080\"),\n \t\totlp.WithGRPCDialOption(grpc.WithBlock()), // useful for testing\n \t)\n+\texp, err := otlp.NewExporter(config, config)\n \thandleErr(err, \"failed to create exporter\")\n \n \tbsp := sdktrace.NewBatchSpanProcessor(exp)", "y": 1, "oldf": "// Copyright The OpenTelemetry Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n// Example using the OTLP exporter + collector + third-party backends. For\n// information about using the exporter, see:\n// https://pkg.go.dev/go.opentelemetry.io/otel/exporters/otlp?tab=doc#example-package-Insecure\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"log\"\n\t\"time\"\n\n\t\"google.golang.org/grpc\"\n\n\t\"go.opentelemetry.io/otel/api/global\"\n\t\"go.opentelemetry.io/otel/api/metric\"\n\tapitrace \"go.opentelemetry.io/otel/api/trace\"\n\t\"go.opentelemetry.io/otel/exporters/otlp\"\n\t\"go.opentelemetry.io/otel/label\"\n\t\"go.opentelemetry.io/otel/sdk/metric/controller/push\"\n\t\"go.opentelemetry.io/otel/sdk/metric/processor/basic\"\n\t\"go.opentelemetry.io/otel/sdk/metric/selector/simple\"\n\t\"go.opentelemetry.io/otel/sdk/resource\"\n\tsdktrace \"go.opentelemetry.io/otel/sdk/trace\"\n\t\"go.opentelemetry.io/otel/semconv\"\n)\n\n// Initializes an OTLP exporter, and configures the corresponding trace and\n// metric providers.\nfunc initProvider() func() {\n\n\t// If the OpenTelemetry Collector is running on a local cluster (minikube or\n\t// microk8s), it should be accessible through the NodePort service at the\n\t// `localhost:30080` address. Otherwise, replace `localhost` with the\n\t// address of your cluster. If you run the app inside k8s, then you can\n\t// probably connect directly to the service through dns\n\texp, err := otlp.NewExporter(\n\t\totlp.WithInsecure(),\n\t\totlp.WithAddress(\"localhost:30080\"),\n\t\totlp.WithGRPCDialOption(grpc.WithBlock()), // useful for testing\n\t)\n\thandleErr(err, \"failed to create exporter\")\n\n\tbsp := sdktrace.NewBatchSpanProcessor(exp)\n\ttracerProvider := sdktrace.NewProvider(\n\t\tsdktrace.WithConfig(sdktrace.Config{DefaultSampler: sdktrace.AlwaysSample()}),\n\t\tsdktrace.WithResource(resource.New(\n\t\t\t// the service name used to display traces in backends\n\t\t\tsemconv.ServiceNameKey.String(\"test-service\"),\n\t\t)),\n\t\tsdktrace.WithSpanProcessor(bsp),\n\t)\n\n\tpusher := push.New(\n\t\tbasic.New(\n\t\t\tsimple.NewWithExactDistribution(),\n\t\t\texp,\n\t\t),\n\t\texp,\n\t\tpush.WithPeriod(2*time.Second),\n\t)\n\n\tglobal.SetTracerProvider(tracerProvider)\n\tglobal.SetMeterProvider(pusher.Provider())\n\tpusher.Start()\n\n\treturn func() {\n\t\tbsp.Shutdown() // shutdown the processor\n\t\thandleErr(exp.Shutdown(context.Background()), \"failed to stop exporter\")\n\t\tpusher.Stop() // pushes any last exports to the receiver\n\t}\n}\n\nfunc main() {\n\tlog.Printf(\"Waiting for connection...\")\n\n\tshutdown := initProvider()\n\tdefer shutdown()\n\n\ttracer := global.Tracer(\"test-tracer\")\n\tmeter := global.Meter(\"test-meter\")\n\n\t// labels represent additional key-value descriptors that can be bound to a\n\t// metric observer or recorder.\n\tcommonLabels := []label.KeyValue{\n\t\tlabel.String(\"labelA\", \"chocolate\"),\n\t\tlabel.String(\"labelB\", \"raspberry\"),\n\t\tlabel.String(\"labelC\", \"vanilla\"),\n\t}\n\n\t// Recorder metric example\n\tvaluerecorder := metric.Must(meter).\n\t\tNewFloat64Counter(\n\t\t\t\"an_important_metric\",\n\t\t\tmetric.WithDescription(\"Measures the cumulative epicness of the app\"),\n\t\t).Bind(commonLabels...)\n\tdefer valuerecorder.Unbind()\n\n\t// work begins\n\tctx, span := tracer.Start(\n\t\tcontext.Background(),\n\t\t\"CollectorExporter-Example\",\n\t\tapitrace.WithAttributes(commonLabels...))\n\tdefer span.End()\n\tfor i := 0; i < 10; i++ {\n\t\t_, iSpan := tracer.Start(ctx, fmt.Sprintf(\"Sample-%d\", i))\n\t\tlog.Printf(\"Doing really hard work (%d / 10)\\n\", i+1)\n\t\tvaluerecorder.Add(ctx, 1.0)\n\n\t\t<-time.After(time.Second)\n\t\tiSpan.End()\n\t}\n\n\tlog.Printf(\"Done!\")\n}\n\nfunc handleErr(err error, message string) {\n\tif err != nil {\n\t\tlog.Fatalf(\"%s: %v\", message, err)\n\t}\n}\n", "idx": 1, "id": 13368, "msg": "NewExporter takes in two arguments: a configuration for the metrics connection and one for the traces", "proj": "open-telemetry-opentelemetry-go", "lang": "go"}
{"patch": "@@ -26,7 +26,10 @@ exports = module.exports = function(grunt, options) {\n \t\t\t\t\t'http://' + host + ':<%= connect.test.options.port %>/test/commons/',\n \t\t\t\t\t'http://' +\n \t\t\t\t\t\thost +\n-\t\t\t\t\t\t':<%= connect.test.options.port %>/test/integration/rules/'\n+\t\t\t\t\t\t':<%= connect.test.options.port %>/test/integration/rules/',\n+\t\t\t\t\t'http://' +\n+\t\t\t\t\t\thost +\n+\t\t\t\t\t\t':<%= connect.test.options.port %>/test/integration/api/external/'\n \t\t\t\t],\n \t\t\t\trun: true,\n \t\t\t\tgrowlOnSuccess: false,", "y": 1, "oldf": "exports = module.exports = function(grunt, options) {\n\tvar host = 'localhost';\n\n\tif (process.env.REMOTE_TESTSERVER_HOST) {\n\t\thost = process.env.REMOTE_TESTSERVER_HOST;\n\t}\n\n\tfunction mapToUrl(files, port) {\n\t\treturn grunt.file.expand(files).map(function(file) {\n\t\t\treturn 'http://' + host + ':' + port + '/' + file;\n\t\t});\n\t}\n\n\treturn {\n\t\toptions: options,\n\t\tunit: {\n\t\t\toptions: {\n\t\t\t\tlogErrors: true,\n\t\t\t\tlog: true,\n\t\t\t\turls: [\n\t\t\t\t\t'http://' + host + ':<%= connect.test.options.port %>/test/core/',\n\t\t\t\t\t'http://' + host + ':<%= connect.test.options.port %>/test/checks/',\n\t\t\t\t\t'http://' +\n\t\t\t\t\t\thost +\n\t\t\t\t\t\t':<%= connect.test.options.port %>/test/rule-matches/',\n\t\t\t\t\t'http://' + host + ':<%= connect.test.options.port %>/test/commons/',\n\t\t\t\t\t'http://' +\n\t\t\t\t\t\thost +\n\t\t\t\t\t\t':<%= connect.test.options.port %>/test/integration/rules/'\n\t\t\t\t],\n\t\t\t\trun: true,\n\t\t\t\tgrowlOnSuccess: false,\n\t\t\t\tmocha: {\n\t\t\t\t\tgrep: grunt.option('grep')\n\t\t\t\t}\n\t\t\t}\n\t\t},\n\t\tintegration: {\n\t\t\toptions: {\n\t\t\t\tlog: true,\n\t\t\t\turls: mapToUrl(\n\t\t\t\t\t[\n\t\t\t\t\t\t'test/integration/full/**/*.html',\n\t\t\t\t\t\t'!test/integration/full/**/frames/**/*.html'\n\t\t\t\t\t].concat([\n\t\t\t\t\t\t// These tests can be flaky on AppVeyor in Chrome and frequently fail\n\t\t\t\t\t\tprocess.env.APPVEYOR\n\t\t\t\t\t\t\t? ['!test/integration/full/preload-cssom/preload-cssom.html']\n\t\t\t\t\t\t\t: []\n\t\t\t\t\t]),\n\t\t\t\t\t'<%= connect.test.options.port %>'\n\t\t\t\t),\n\t\t\t\trun: true,\n\t\t\t\tgrowlOnSuccess: false,\n\t\t\t\tmocha: {\n\t\t\t\t\tgrep: grunt.option('grep')\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t};\n};\n", "idx": 1, "id": 15000, "msg": "I like the new directory `/api`, what is the thinking behind `/external`?", "proj": "dequelabs-axe-core", "lang": "js"}
{"patch": "@@ -41,6 +41,11 @@ class TabDeletedError(Exception):\n     \"\"\"Exception raised when _tab_index is called for a deleted tab.\"\"\"\n \n \n+class MarkNotSetError(Exception):\n+\n+    \"\"\"Exception raised when _tab_index is called for a deleted tab.\"\"\"\n+\n+\n class TabbedBrowser(tabwidget.TabWidget):\n \n     \"\"\"A TabWidget with QWebViews inside.", "y": 1, "oldf": "# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:\n\n# Copyright 2014-2016 Florian Bruhin (The Compiler) <mail@qutebrowser.org>\n#\n# This file is part of qutebrowser.\n#\n# qutebrowser is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# qutebrowser is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with qutebrowser.  If not, see <http://www.gnu.org/licenses/>.\n\n\"\"\"The main tabbed browser widget.\"\"\"\n\nimport functools\nimport collections\n\nfrom PyQt5.QtWidgets import QSizePolicy\nfrom PyQt5.QtCore import pyqtSignal, pyqtSlot, QTimer, QUrl\nfrom PyQt5.QtGui import QIcon\n\nfrom qutebrowser.config import config\nfrom qutebrowser.keyinput import modeman\nfrom qutebrowser.mainwindow import tabwidget\nfrom qutebrowser.browser import signalfilter, webview\nfrom qutebrowser.utils import log, usertypes, utils, qtutils, objreg, urlutils\n\n\nUndoEntry = collections.namedtuple('UndoEntry', ['url', 'history'])\n\n\nclass TabDeletedError(Exception):\n\n    \"\"\"Exception raised when _tab_index is called for a deleted tab.\"\"\"\n\n\nclass TabbedBrowser(tabwidget.TabWidget):\n\n    \"\"\"A TabWidget with QWebViews inside.\n\n    Provides methods to manage tabs, convenience methods to interact with the\n    current tab (cur_*) and filters signals to re-emit them when they occurred\n    in the currently visible tab.\n\n    For all tab-specific signals (cur_*) emitted by a tab, this happens:\n       - the signal gets filtered with _filter_signals and self.cur_* gets\n         emitted if the signal occurred in the current tab.\n\n    Attributes:\n        search_text/search_flags: Search parameters which are shared between\n                                  all tabs.\n        _win_id: The window ID this tabbedbrowser is associated with.\n        _filter: A SignalFilter instance.\n        _now_focused: The tab which is focused now.\n        _tab_insert_idx_left: Where to insert a new tab with\n                         tabbar -> new-tab-position set to 'left'.\n        _tab_insert_idx_right: Same as above, for 'right'.\n        _undo_stack: List of UndoEntry namedtuples of closed tabs.\n        shutting_down: Whether we're currently shutting down.\n\n    Signals:\n        cur_progress: Progress of the current tab changed (loadProgress).\n        cur_load_started: Current tab started loading (loadStarted)\n        cur_load_finished: Current tab finished loading (loadFinished)\n        cur_statusbar_message: Current tab got a statusbar message\n                               (statusBarMessage)\n        cur_url_text_changed: Current URL text changed.\n        cur_link_hovered: Link hovered in current tab (linkHovered)\n        cur_scroll_perc_changed: Scroll percentage of current tab changed.\n                                 arg 1: x-position in %.\n                                 arg 2: y-position in %.\n        cur_load_status_changed: Loading status of current tab changed.\n        close_window: The last tab was closed, close this window.\n        resized: Emitted when the browser window has resized, so the completion\n                 widget can adjust its size to it.\n                 arg: The new size.\n        current_tab_changed: The current tab changed to the emitted WebView.\n        new_tab: Emits the new WebView and its index when a new tab is opened.\n    \"\"\"\n\n    cur_progress = pyqtSignal(int)\n    cur_load_started = pyqtSignal()\n    cur_load_finished = pyqtSignal(bool)\n    cur_statusbar_message = pyqtSignal(str)\n    cur_url_text_changed = pyqtSignal(str)\n    cur_link_hovered = pyqtSignal(str, str, str)\n    cur_scroll_perc_changed = pyqtSignal(int, int)\n    cur_load_status_changed = pyqtSignal(str)\n    close_window = pyqtSignal()\n    resized = pyqtSignal('QRect')\n    got_cmd = pyqtSignal(str)\n    current_tab_changed = pyqtSignal(webview.WebView)\n    new_tab = pyqtSignal(webview.WebView, int)\n\n    def __init__(self, win_id, parent=None):\n        super().__init__(win_id, parent)\n        self._win_id = win_id\n        self._tab_insert_idx_left = 0\n        self._tab_insert_idx_right = -1\n        self.shutting_down = False\n        self.tabCloseRequested.connect(self.on_tab_close_requested)\n        self.currentChanged.connect(self.on_current_changed)\n        self.cur_load_started.connect(self.on_cur_load_started)\n        self.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)\n        self._undo_stack = []\n        self._filter = signalfilter.SignalFilter(win_id, self)\n        self._now_focused = None\n        self.search_text = None\n        self.search_flags = 0\n        objreg.get('config').changed.connect(self.update_favicons)\n        objreg.get('config').changed.connect(self.update_window_title)\n        objreg.get('config').changed.connect(self.update_tab_titles)\n\n    def __repr__(self):\n        return utils.get_repr(self, count=self.count())\n\n    def _tab_index(self, tab):\n        \"\"\"Get the index of a given tab.\n\n        Raises TabDeletedError if the tab doesn't exist anymore.\n        \"\"\"\n        try:\n            idx = self.indexOf(tab)\n        except RuntimeError as e:\n            log.webview.debug(\"Got invalid tab ({})!\".format(e))\n            raise TabDeletedError(e)\n        if idx == -1:\n            log.webview.debug(\"Got invalid tab (index is -1)!\")\n            raise TabDeletedError(\"index is -1!\")\n        return idx\n\n    def widgets(self):\n        \"\"\"Get a list of open tab widgets.\n\n        We don't implement this as generator so we can delete tabs while\n        iterating over the list.\n        \"\"\"\n        w = []\n        for i in range(self.count()):\n            w.append(self.widget(i))\n        return w\n\n    @config.change_filter('ui', 'window-title-format')\n    def update_window_title(self):\n        \"\"\"Change the window title to match the current tab.\"\"\"\n        idx = self.currentIndex()\n        if idx == -1:\n            # (e.g. last tab removed)\n            log.webview.debug(\"Not updating window title because index is -1\")\n            return\n        tabtitle = self.page_title(idx)\n        widget = self.widget(idx)\n\n        fields = {}\n        if widget.load_status == webview.LoadStatus.loading:\n            fields['perc'] = '[{}%] '.format(widget.progress)\n        else:\n            fields['perc'] = ''\n        fields['perc_raw'] = widget.progress\n        fields['title'] = tabtitle\n        fields['title_sep'] = ' - ' if tabtitle else ''\n        fields['id'] = self._win_id\n        y = widget.scroll_pos[1]\n        if y <= 0:\n            scroll_pos = 'top'\n        elif y >= 100:\n            scroll_pos = 'bot'\n        else:\n            scroll_pos = '{:2}%'.format(y)\n\n        fields['scroll_pos'] = scroll_pos\n        fmt = config.get('ui', 'window-title-format')\n        self.window().setWindowTitle(fmt.format(**fields))\n\n    def _connect_tab_signals(self, tab):\n        \"\"\"Set up the needed signals for tab.\"\"\"\n        page = tab.page()\n        frame = page.mainFrame()\n        # filtered signals\n        tab.linkHovered.connect(\n            self._filter.create(self.cur_link_hovered, tab))\n        tab.loadProgress.connect(\n            self._filter.create(self.cur_progress, tab))\n        frame.loadFinished.connect(\n            self._filter.create(self.cur_load_finished, tab))\n        frame.loadStarted.connect(\n            self._filter.create(self.cur_load_started, tab))\n        tab.statusBarMessage.connect(\n            self._filter.create(self.cur_statusbar_message, tab))\n        tab.scroll_pos_changed.connect(\n            self._filter.create(self.cur_scroll_perc_changed, tab))\n        tab.scroll_pos_changed.connect(self.on_scroll_pos_changed)\n        tab.url_text_changed.connect(\n            self._filter.create(self.cur_url_text_changed, tab))\n        tab.load_status_changed.connect(\n            self._filter.create(self.cur_load_status_changed, tab))\n        tab.url_text_changed.connect(\n            functools.partial(self.on_url_text_changed, tab))\n        # misc\n        tab.titleChanged.connect(\n            functools.partial(self.on_title_changed, tab))\n        tab.iconChanged.connect(\n            functools.partial(self.on_icon_changed, tab))\n        tab.loadProgress.connect(\n            functools.partial(self.on_load_progress, tab))\n        frame.loadFinished.connect(\n            functools.partial(self.on_load_finished, tab))\n        frame.loadStarted.connect(\n            functools.partial(self.on_load_started, tab))\n        page.windowCloseRequested.connect(\n            functools.partial(self.on_window_close_requested, tab))\n\n    def current_url(self):\n        \"\"\"Get the URL of the current tab.\n\n        Intended to be used from command handlers.\n\n        Return:\n            The current URL as QUrl.\n        \"\"\"\n        widget = self.currentWidget()\n        if widget is None:\n            url = QUrl()\n        else:\n            url = widget.cur_url\n        # It's possible for url to be invalid, but the caller will handle that.\n        qtutils.ensure_valid(url)\n        return url\n\n    def shutdown(self):\n        \"\"\"Try to shut down all tabs cleanly.\"\"\"\n        self.shutting_down = True\n        for tab in self.widgets():\n            self._remove_tab(tab)\n\n    def close_tab(self, tab):\n        \"\"\"Close a tab.\n\n        Args:\n            tab: The QWebView to be closed.\n        \"\"\"\n        last_close = config.get('tabs', 'last-close')\n        count = self.count()\n\n        if last_close == 'ignore' and count == 1:\n            return\n\n        self._remove_tab(tab)\n\n        if count == 1:  # We just closed the last tab above.\n            if last_close == 'close':\n                self.close_window.emit()\n            elif last_close == 'blank':\n                self.openurl(QUrl('about:blank'), newtab=True)\n            elif last_close == 'startpage':\n                url = QUrl(config.get('general', 'startpage')[0])\n                self.openurl(url, newtab=True)\n            elif last_close == 'default-page':\n                url = config.get('general', 'default-page')\n                self.openurl(url, newtab=True)\n\n    def _remove_tab(self, tab):\n        \"\"\"Remove a tab from the tab list and delete it properly.\n\n        Args:\n            tab: The QWebView to be closed.\n        \"\"\"\n        idx = self.indexOf(tab)\n        if idx == -1:\n            raise TabDeletedError(\"tab {} is not contained in \"\n                                  \"TabbedWidget!\".format(tab))\n        if tab is self._now_focused:\n            self._now_focused = None\n        if tab is objreg.get('last-focused-tab', None, scope='window',\n                             window=self._win_id):\n            objreg.delete('last-focused-tab', scope='window',\n                          window=self._win_id)\n        if tab.cur_url.isValid():\n            history_data = qtutils.serialize(tab.history())\n            entry = UndoEntry(tab.cur_url, history_data)\n            self._undo_stack.append(entry)\n        elif tab.cur_url.isEmpty():\n            # There are some good reasons why an URL could be empty\n            # (target=\"_blank\" with a download, see [1]), so we silently ignore\n            # this.\n            # [1] https://github.com/The-Compiler/qutebrowser/issues/163\n            pass\n        else:\n            # We display a warnings for URLs which are not empty but invalid -\n            # but we don't return here because we want the tab to close either\n            # way.\n            urlutils.invalid_url_error(self._win_id, tab.cur_url, \"saving tab\")\n        tab.shutdown()\n        self.removeTab(idx)\n        tab.deleteLater()\n\n    def undo(self):\n        \"\"\"Undo removing of a tab.\"\"\"\n        # Remove unused tab which may be created after the last tab is closed\n        last_close = config.get('tabs', 'last-close')\n        if last_close in ['blank', 'startpage', 'default-page']:\n            only_one_tab_open = self.count() == 1\n            no_history = self.widget(0).history().count() == 1\n            urls = {\n                'blank': QUrl('about:blank'),\n                'startpage': QUrl(config.get('general', 'startpage')[0]),\n                'default-page': config.get('general', 'default-page'),\n            }\n            first_tab_url = self.widget(0).page().mainFrame().requestedUrl()\n            last_close_urlstr = urls[last_close].toString().rstrip('/')\n            first_tab_urlstr = first_tab_url.toString().rstrip('/')\n            last_close_url_used = first_tab_urlstr == last_close_urlstr\n\n            if only_one_tab_open and no_history and last_close_url_used:\n                self.removeTab(0)\n\n        url, history_data = self._undo_stack.pop()\n        newtab = self.tabopen(url, background=False)\n        qtutils.deserialize(history_data, newtab.history())\n\n    @pyqtSlot('QUrl', bool)\n    def openurl(self, url, newtab):\n        \"\"\"Open a URL, used as a slot.\n\n        Args:\n            url: The URL to open as QUrl.\n            newtab: True to open URL in a new tab, False otherwise.\n        \"\"\"\n        qtutils.ensure_valid(url)\n        if newtab or self.currentWidget() is None:\n            self.tabopen(url, background=False)\n        else:\n            self.currentWidget().openurl(url)\n\n    @pyqtSlot(int)\n    def on_tab_close_requested(self, idx):\n        \"\"\"Close a tab via an index.\"\"\"\n        tab = self.widget(idx)\n        if tab is None:\n            log.webview.debug(\"Got invalid tab {} for index {}!\".format(\n                tab, idx))\n            return\n        self.close_tab(tab)\n\n    @pyqtSlot(webview.WebView)\n    def on_window_close_requested(self, widget):\n        \"\"\"Close a tab with a widget given.\"\"\"\n        try:\n            self.close_tab(widget)\n        except TabDeletedError:\n            log.webview.debug(\"Requested to close {!r} which does not \"\n                              \"exist!\".format(widget))\n\n    @pyqtSlot('QUrl', bool)\n    def tabopen(self, url=None, background=None, explicit=False):\n        \"\"\"Open a new tab with a given URL.\n\n        Inner logic for open-tab and open-tab-bg.\n        Also connect all the signals we need to _filter_signals.\n\n        Args:\n            url: The URL to open as QUrl or None for an empty tab.\n            background: Whether to open the tab in the background.\n                        if None, the background-tabs setting decides.\n            explicit: Whether the tab was opened explicitly.\n                      If this is set, the new position might be different. With\n                      the default settings we handle it like Chromium does:\n                          - Tabs from clicked links etc. are to the right of\n                            the current.\n                          - Explicitly opened tabs are at the very right.\n\n        Return:\n            The opened WebView instance.\n        \"\"\"\n        if url is not None:\n            qtutils.ensure_valid(url)\n        log.webview.debug(\"Creating new tab with URL {}\".format(url))\n        if config.get('tabs', 'tabs-are-windows') and self.count() > 0:\n            from qutebrowser.mainwindow import mainwindow\n            window = mainwindow.MainWindow()\n            window.show()\n            tabbed_browser = objreg.get('tabbed-browser', scope='window',\n                                        window=window.win_id)\n            return tabbed_browser.tabopen(url, background, explicit)\n        tab = webview.WebView(self._win_id, self)\n        self._connect_tab_signals(tab)\n        idx = self._get_new_tab_idx(explicit)\n        self.insertTab(idx, tab, \"\")\n        if url is not None:\n            tab.openurl(url)\n        if background is None:\n            background = config.get('tabs', 'background-tabs')\n        if not background:\n            self.setCurrentWidget(tab)\n        tab.show()\n        self.new_tab.emit(tab, idx)\n        return tab\n\n    def _get_new_tab_idx(self, explicit):\n        \"\"\"Get the index of a tab to insert.\n\n        Args:\n            explicit: Whether the tab was opened explicitly.\n\n        Return:\n            The index of the new tab.\n        \"\"\"\n        if explicit:\n            pos = config.get('tabs', 'new-tab-position-explicit')\n        else:\n            pos = config.get('tabs', 'new-tab-position')\n        if pos == 'left':\n            idx = self._tab_insert_idx_left\n            # On first sight, we'd think we have to decrement\n            # self._tab_insert_idx_left here, as we want the next tab to be\n            # *before* the one we just opened. However, since we opened a tab\n            # *to the left* of the currently focused tab, indices will shift by\n            # 1 automatically.\n        elif pos == 'right':\n            idx = self._tab_insert_idx_right\n            self._tab_insert_idx_right += 1\n        elif pos == 'first':\n            idx = 0\n        elif pos == 'last':\n            idx = -1\n        else:\n            raise ValueError(\"Invalid new-tab-position '{}'.\".format(pos))\n        log.webview.debug(\"new-tab-position {} -> opening new tab at {}, \"\n                          \"next left: {} / right: {}\".format(\n                              pos, idx, self._tab_insert_idx_left,\n                              self._tab_insert_idx_right))\n        return idx\n\n    @config.change_filter('tabs', 'show-favicons')\n    def update_favicons(self):\n        \"\"\"Update favicons when config was changed.\"\"\"\n        show = config.get('tabs', 'show-favicons')\n        for i, tab in enumerate(self.widgets()):\n            if show:\n                self.setTabIcon(i, tab.icon())\n            else:\n                self.setTabIcon(i, QIcon())\n\n    @pyqtSlot()\n    def on_load_started(self, tab):\n        \"\"\"Clear icon and update title when a tab started loading.\n\n        Args:\n            tab: The tab where the signal belongs to.\n        \"\"\"\n        try:\n            idx = self._tab_index(tab)\n        except TabDeletedError:\n            # We can get signals for tabs we already deleted...\n            return\n        self.update_tab_title(idx)\n        if tab.keep_icon:\n            tab.keep_icon = False\n        else:\n            self.setTabIcon(idx, QIcon())\n        if idx == self.currentIndex():\n            self.update_window_title()\n\n    @pyqtSlot()\n    def on_cur_load_started(self):\n        \"\"\"Leave insert/hint mode when loading started.\"\"\"\n        modeman.maybe_leave(self._win_id, usertypes.KeyMode.insert,\n                            'load started')\n        modeman.maybe_leave(self._win_id, usertypes.KeyMode.hint,\n                            'load started')\n\n    @pyqtSlot(webview.WebView, str)\n    def on_title_changed(self, tab, text):\n        \"\"\"Set the title of a tab.\n\n        Slot for the titleChanged signal of any tab.\n\n        Args:\n            tab: The WebView where the title was changed.\n            text: The text to set.\n        \"\"\"\n        if not text:\n            log.webview.debug(\"Ignoring title change to '{}'.\".format(text))\n            return\n        try:\n            idx = self._tab_index(tab)\n        except TabDeletedError:\n            # We can get signals for tabs we already deleted...\n            return\n        log.webview.debug(\"Changing title for idx {} to '{}'\".format(\n            idx, text))\n        self.set_page_title(idx, text)\n        if idx == self.currentIndex():\n            self.update_window_title()\n\n    @pyqtSlot(webview.WebView, str)\n    def on_url_text_changed(self, tab, url):\n        \"\"\"Set the new URL as title if there's no title yet.\n\n        Args:\n            tab: The WebView where the title was changed.\n            url: The new URL.\n        \"\"\"\n        try:\n            idx = self._tab_index(tab)\n        except TabDeletedError:\n            # We can get signals for tabs we already deleted...\n            return\n        if not self.page_title(idx):\n            self.set_page_title(idx, url)\n\n    @pyqtSlot(webview.WebView)\n    def on_icon_changed(self, tab):\n        \"\"\"Set the icon of a tab.\n\n        Slot for the iconChanged signal of any tab.\n\n        Args:\n            tab: The WebView where the title was changed.\n        \"\"\"\n        if not config.get('tabs', 'show-favicons'):\n            return\n        try:\n            idx = self._tab_index(tab)\n        except TabDeletedError:\n            # We can get signals for tabs we already deleted...\n            return\n        self.setTabIcon(idx, tab.icon())\n\n    @pyqtSlot(usertypes.KeyMode)\n    def on_mode_left(self, mode):\n        \"\"\"Give focus to current tab if command mode was left.\"\"\"\n        if mode in (usertypes.KeyMode.command, usertypes.KeyMode.prompt,\n                    usertypes.KeyMode.yesno):\n            widget = self.currentWidget()\n            log.modes.debug(\"Left status-input mode, focusing {!r}\".format(\n                widget))\n            if widget is None:\n                return\n            widget.setFocus()\n\n    @pyqtSlot(int)\n    def on_current_changed(self, idx):\n        \"\"\"Set last-focused-tab and leave hinting mode when focus changed.\"\"\"\n        if idx == -1 or self.shutting_down:\n            # closing the last tab (before quitting) or shutting down\n            return\n        tab = self.widget(idx)\n        log.modes.debug(\"Current tab changed, focusing {!r}\".format(tab))\n        tab.setFocus()\n        for mode in (usertypes.KeyMode.hint, usertypes.KeyMode.insert,\n                     usertypes.KeyMode.caret, usertypes.KeyMode.passthrough):\n            modeman.maybe_leave(self._win_id, mode, 'tab changed')\n        if self._now_focused is not None:\n            objreg.register('last-focused-tab', self._now_focused, update=True,\n                            scope='window', window=self._win_id)\n        self._now_focused = tab\n        self.current_tab_changed.emit(tab)\n        QTimer.singleShot(0, self.update_window_title)\n        self._tab_insert_idx_left = self.currentIndex()\n        self._tab_insert_idx_right = self.currentIndex() + 1\n\n    @pyqtSlot()\n    def on_cmd_return_pressed(self):\n        \"\"\"Set focus when the commandline closes.\"\"\"\n        log.modes.debug(\"Commandline closed, focusing {!r}\".format(self))\n\n    def on_load_progress(self, tab, perc):\n        \"\"\"Adjust tab indicator on load progress.\"\"\"\n        try:\n            idx = self._tab_index(tab)\n        except TabDeletedError:\n            # We can get signals for tabs we already deleted...\n            return\n        start = config.get('colors', 'tabs.indicator.start')\n        stop = config.get('colors', 'tabs.indicator.stop')\n        system = config.get('colors', 'tabs.indicator.system')\n        color = utils.interpolate_color(start, stop, perc, system)\n        self.set_tab_indicator_color(idx, color)\n        self.update_tab_title(idx)\n        if idx == self.currentIndex():\n            self.update_window_title()\n\n    def on_load_finished(self, tab):\n        \"\"\"Adjust tab indicator when loading finished.\n\n        We don't take loadFinished's ok argument here as it always seems to be\n        true when the QWebPage has an ErrorPageExtension implemented.\n        See https://github.com/The-Compiler/qutebrowser/issues/84\n        \"\"\"\n        try:\n            idx = self._tab_index(tab)\n        except TabDeletedError:\n            # We can get signals for tabs we already deleted...\n            return\n        if tab.page().error_occurred:\n            color = config.get('colors', 'tabs.indicator.error')\n        else:\n            start = config.get('colors', 'tabs.indicator.start')\n            stop = config.get('colors', 'tabs.indicator.stop')\n            system = config.get('colors', 'tabs.indicator.system')\n            color = utils.interpolate_color(start, stop, 100, system)\n        self.set_tab_indicator_color(idx, color)\n        self.update_tab_title(idx)\n        if idx == self.currentIndex():\n            self.update_window_title()\n\n    @pyqtSlot()\n    def on_scroll_pos_changed(self):\n        \"\"\"Update tab and window title when scroll position changed.\"\"\"\n        self.update_window_title()\n        self.update_tab_title(self.currentIndex())\n\n    def resizeEvent(self, e):\n        \"\"\"Extend resizeEvent of QWidget to emit a resized signal afterwards.\n\n        Args:\n            e: The QResizeEvent\n        \"\"\"\n        super().resizeEvent(e)\n        self.resized.emit(self.geometry())\n\n    def wheelEvent(self, e):\n        \"\"\"Override wheelEvent of QWidget to forward it to the focused tab.\n\n        Args:\n            e: The QWheelEvent\n        \"\"\"\n        if self._now_focused is not None:\n            self._now_focused.wheelEvent(e)\n        else:\n            e.ignore()\n", "idx": 1, "id": 14524, "msg": "You'll need to adjust the docstring :wink:", "proj": "qutebrowser-qutebrowser", "lang": "py"}
{"patch": "@@ -23,7 +23,7 @@ func GetApps() map[string][]App {\n \tapps := make(map[string][]App)\n \tfor platformType := range PluginMap {\n \t\tlabels := map[string]string{\n-\t\t\t\"com.ddev.platform\":          platformType,\n+\t\t\t\"com.ddev.platform\":          \"ddev\",\n \t\t\t\"com.docker.compose.service\": \"web\",\n \t\t}\n \t\tsites, err := dockerutil.FindContainersByLabels(labels)", "y": 1, "oldf": "package platform\n\nimport (\n\t\"fmt\"\n\t\"path/filepath\"\n\t\"strings\"\n\n\tlog \"github.com/Sirupsen/logrus\"\n\t\"github.com/fatih/color\"\n\t\"github.com/fsouza/go-dockerclient\"\n\t\"github.com/gosuri/uitable\"\n\n\t\"errors\"\n\n\t\"github.com/drud/ddev/pkg/dockerutil\"\n\t\"github.com/drud/ddev/pkg/fileutil\"\n\t\"github.com/drud/ddev/pkg/util\"\n\thomedir \"github.com/mitchellh/go-homedir\"\n)\n\n// GetApps returns a list of ddev applictions keyed by platform.\nfunc GetApps() map[string][]App {\n\tapps := make(map[string][]App)\n\tfor platformType := range PluginMap {\n\t\tlabels := map[string]string{\n\t\t\t\"com.ddev.platform\":          platformType,\n\t\t\t\"com.docker.compose.service\": \"web\",\n\t\t}\n\t\tsites, err := dockerutil.FindContainersByLabels(labels)\n\n\t\tif err == nil {\n\t\t\tfor _, siteContainer := range sites {\n\t\t\t\tsite, err := GetPluginApp(platformType)\n\t\t\t\t// This should absolutely never happen, so just fatal on the off chance it does.\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Fatalf(\"could not get application for plugin type %s\", platformType)\n\t\t\t\t}\n\t\t\t\tapproot, ok := siteContainer.Labels[\"com.ddev.approot\"]\n\t\t\t\tif !ok {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\t_, ok = apps[platformType]\n\t\t\t\tif !ok {\n\t\t\t\t\tapps[platformType] = []App{}\n\t\t\t\t}\n\n\t\t\t\terr = site.Init(approot)\n\t\t\t\tif err == nil {\n\t\t\t\t\tapps[platformType] = append(apps[platformType], site)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn apps\n}\n\n// RenderAppTable will format a table for user display based on a list of apps.\nfunc RenderAppTable(platform string, apps []App) {\n\tif len(apps) > 0 {\n\t\tfmt.Printf(\"%v %s %v found.\\n\", len(apps), platform, util.FormatPlural(len(apps), \"site\", \"sites\"))\n\t\ttable := CreateAppTable()\n\t\tfor _, site := range apps {\n\t\t\tRenderAppRow(table, site)\n\t\t}\n\t\tfmt.Println(table)\n\t}\n\n}\n\n// CreateAppTable will create a new app table for describe and list output\nfunc CreateAppTable() *uitable.Table {\n\ttable := uitable.New()\n\ttable.MaxColWidth = 140\n\ttable.Separator = \"  \"\n\ttable.AddRow(\"NAME\", \"TYPE\", \"LOCATION\", \"URL\", \"STATUS\")\n\treturn table\n}\n\n// RenderAppRow will add an application row to an existing table for describe and list output.\nfunc RenderAppRow(table *uitable.Table, site App) {\n\t// test tilde expansion\n\tappRoot := site.AppRoot()\n\tuserDir, err := homedir.Dir()\n\tif err == nil {\n\t\tappRoot = strings.Replace(appRoot, userDir, \"~\", 1)\n\t}\n\tstatus := site.SiteStatus()\n\tif status == \"stopped\" {\n\t\tstatus = color.YellowString(status)\n\t} else {\n\t\tstatus = color.CyanString(status)\n\t}\n\ttable.AddRow(\n\t\tsite.GetName(),\n\t\tsite.GetType(),\n\t\tappRoot,\n\t\tsite.URL(),\n\t\tstatus,\n\t)\n}\n\n// Cleanup will clean up ddev apps even if the composer file has been deleted.\nfunc Cleanup(app App) error {\n\tclient := dockerutil.GetDockerClient()\n\n\t// Find all containers which match the current site name.\n\tlabels := map[string]string{\n\t\t\"com.ddev.site-name\": app.GetName(),\n\t}\n\tcontainers, err := dockerutil.FindContainersByLabels(labels)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// First, try stopping the listed containers if they are running.\n\tfor i := range containers {\n\t\tif containers[i].State == \"running\" || containers[i].State == \"restarting\" || containers[i].State == \"paused\" {\n\t\t\tcontainerName := containers[i].Names[0][1:len(containers[i].Names[0])]\n\t\t\tfmt.Printf(\"Stopping container: %s\\n\", containerName)\n\t\t\terr = client.StopContainer(containers[i].ID, 60)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"could not stop container %s: %v\", containerName, err)\n\t\t\t}\n\t\t}\n\t}\n\n\t// Try to remove the containers once they are stopped.\n\tfor i := range containers {\n\t\tcontainerName := containers[i].Names[0][1:len(containers[i].Names[0])]\n\t\tremoveOpts := docker.RemoveContainerOptions{\n\t\t\tID:            containers[i].ID,\n\t\t\tRemoveVolumes: true,\n\t\t\tForce:         true,\n\t\t}\n\t\tfmt.Printf(\"Removing container: %s\\n\", containerName)\n\t\tif err := client.RemoveContainer(removeOpts); err != nil {\n\t\t\treturn fmt.Errorf(\"could not remove container %s: %v\", containerName, err)\n\t\t}\n\t}\n\n\treturn StopRouter()\n}\n\n// CheckForConf checks for a config.yaml at the cwd or parent dirs.\nfunc CheckForConf(confPath string) (string, error) {\n\tif fileutil.FileExists(confPath + \"/.ddev/config.yaml\") {\n\t\treturn confPath, nil\n\t}\n\tpathList := strings.Split(confPath, \"/\")\n\n\tfor _ = range pathList {\n\t\tconfPath = filepath.Dir(confPath)\n\t\tif fileutil.FileExists(confPath + \"/.ddev/config.yaml\") {\n\t\t\treturn confPath, nil\n\t\t}\n\t}\n\n\treturn \"\", errors.New(\"no .ddev/config.yaml file was found in this directory or any parent\")\n}\n\n// ddevContainersRunning determines if any ddev-controlled containers are currently running.\nfunc ddevContainersRunning() (bool, error) {\n\tcontainers, err := dockerutil.GetDockerContainers(false)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\tfor _, container := range containers {\n\t\tif _, ok := container.Labels[\"com.ddev.platform\"]; ok {\n\t\t\treturn true, nil\n\t\t}\n\t}\n\treturn false, nil\n}\n", "idx": 1, "id": 11384, "msg": "Not sure why this is changing to a hard-coded string.", "proj": "drud-ddev", "lang": "php"}
{"patch": "@@ -78,7 +78,7 @@ public class ExpireSnapshotsProcedure extends BaseProcedure {\n   @Override\n   public InternalRow[] call(InternalRow args) {\n     Identifier tableIdent = toIdentifier(args.getString(0), PARAMETERS[0].name());\n-    Long olderThanMillis = args.isNullAt(1) ? null : DateTimeUtils.toMillis(args.getLong(1));\n+    Long olderThanMillis = args.isNullAt(1) ? null : DateTimeUtils.microsToMillis(args.getLong(1));\n     Integer retainLastNum = args.isNullAt(2) ? null : args.getInt(2);\n \n     return modifyIcebergTable(tableIdent, table -> {", "y": 1, "oldf": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\n\npackage org.apache.iceberg.spark.procedures;\n\nimport org.apache.iceberg.actions.Actions;\nimport org.apache.iceberg.actions.ExpireSnapshotsAction;\nimport org.apache.iceberg.actions.ExpireSnapshotsActionResult;\nimport org.apache.iceberg.spark.procedures.SparkProcedures.ProcedureBuilder;\nimport org.apache.spark.sql.catalyst.InternalRow;\nimport org.apache.spark.sql.catalyst.util.DateTimeUtils;\nimport org.apache.spark.sql.connector.catalog.Identifier;\nimport org.apache.spark.sql.connector.catalog.TableCatalog;\nimport org.apache.spark.sql.connector.iceberg.catalog.ProcedureParameter;\nimport org.apache.spark.sql.types.DataTypes;\nimport org.apache.spark.sql.types.Metadata;\nimport org.apache.spark.sql.types.StructField;\nimport org.apache.spark.sql.types.StructType;\n\n/**\n * A procedure that expires snapshots in a table.\n *\n * @see Actions#expireSnapshots()\n */\npublic class ExpireSnapshotsProcedure extends BaseProcedure {\n\n  private static final ProcedureParameter[] PARAMETERS = new ProcedureParameter[] {\n      ProcedureParameter.required(\"table\", DataTypes.StringType),\n      ProcedureParameter.optional(\"older_than\", DataTypes.TimestampType),\n      ProcedureParameter.optional(\"retain_last\", DataTypes.IntegerType)\n  };\n\n  private static final StructType OUTPUT_TYPE = new StructType(new StructField[]{\n      new StructField(\"deleted_data_files_count\", DataTypes.LongType, true, Metadata.empty()),\n      new StructField(\"deleted_manifest_files_count\", DataTypes.LongType, true, Metadata.empty()),\n      new StructField(\"deleted_manifest_lists_count\", DataTypes.LongType, true, Metadata.empty())\n  });\n\n  public static ProcedureBuilder builder() {\n    return new BaseProcedure.Builder<ExpireSnapshotsProcedure>() {\n      @Override\n      protected ExpireSnapshotsProcedure doBuild() {\n        return new ExpireSnapshotsProcedure(tableCatalog());\n      }\n    };\n  }\n\n  private ExpireSnapshotsProcedure(TableCatalog tableCatalog) {\n    super(tableCatalog);\n  }\n\n  @Override\n  public ProcedureParameter[] parameters() {\n    return PARAMETERS;\n  }\n\n  @Override\n  public StructType outputType() {\n    return OUTPUT_TYPE;\n  }\n\n  @Override\n  public InternalRow[] call(InternalRow args) {\n    Identifier tableIdent = toIdentifier(args.getString(0), PARAMETERS[0].name());\n    Long olderThanMillis = args.isNullAt(1) ? null : DateTimeUtils.toMillis(args.getLong(1));\n    Integer retainLastNum = args.isNullAt(2) ? null : args.getInt(2);\n\n    return modifyIcebergTable(tableIdent, table -> {\n      Actions actions = Actions.forTable(table);\n\n      ExpireSnapshotsAction action = actions.expireSnapshots();\n\n      if (olderThanMillis != null) {\n        action.expireOlderThan(olderThanMillis);\n      }\n\n      if (retainLastNum != null) {\n        action.retainLast(retainLastNum);\n      }\n\n      ExpireSnapshotsActionResult result = action.execute();\n\n      InternalRow outputRow = newInternalRow(\n          result.dataFilesDeleted(),\n          result.manifestFilesDeleted(),\n          result.manifestListsDeleted());\n      return new InternalRow[]{outputRow};\n    });\n  }\n\n  @Override\n  public String description() {\n    return \"ExpireSnapshotProcedure\";\n  }\n}\n", "idx": 1, "id": 36038, "msg": "This could be copied into iceberg code to avoid the spark internal dep? We could use a version check to adjust the method used if needed.", "proj": "apache-iceberg", "lang": "java"}
{"patch": "@@ -52,7 +52,7 @@ type TaskStateChange struct {\n \tReason string\n \n \t// Task is a pointer to the task involved in the state change that gives the event handler a hook into storing\n-\t// what status was sent.  This is used to ensure the same event is handled only once.\n+\t// what stats was sent.  This is used to ensure the same event is handled only once.\n \tTask *Task\n }\n ", "y": 1, "oldf": "// Copyright 2014-2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\"). You may\n// not use this file except in compliance with the License. A copy of the\n// License is located at\n//\n//\thttp://aws.amazon.com/apache2.0/\n//\n// or in the \"license\" file accompanying this file. This file is distributed\n// on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n// express or implied. See the License for the specific language governing\n// permissions and limitations under the License.\n\npackage api\n\nimport (\n\t\"fmt\"\n\t\"strconv\"\n)\n\n// ContainerStateChange represents a state change that needs to be sent to the\n// SubmitContainerStateChange API\ntype ContainerStateChange struct {\n\t// TaskArn is the unique identifier for the task\n\tTaskArn string\n\t// ContainerName is the name of the container\n\tContainerName string\n\t// Status is the status to send\n\tStatus ContainerStatus\n\n\t// Reason may contain details of why the container stopped\n\tReason string\n\t// ExitCode is the exit code of the container, if available\n\tExitCode *int\n\t// PortBindings are the details of the host ports picked for the specified\n\t// container ports\n\tPortBindings []PortBinding\n\n\t// Container is a pointer to the container involved in the state change that gives the event handler a hook into\n\t// storing what status was sent.  This is used to ensure the same event is handled only once.\n\tContainer *Container\n}\n\n// TaskStateChange represents a state change that needs to be sent to the\n// SubmitTaskStateChange API\ntype TaskStateChange struct {\n\t// TaskArn is the unique identifier for the task\n\tTaskArn string\n\t// Status is the status to send\n\tStatus TaskStatus\n\t// Reason may contain details of why the task stopped\n\tReason string\n\n\t// Task is a pointer to the task involved in the state change that gives the event handler a hook into storing\n\t// what status was sent.  This is used to ensure the same event is handled only once.\n\tTask *Task\n}\n\n// String returns a human readable string representation of this object\nfunc (c *ContainerStateChange) String() string {\n\tres := fmt.Sprintf(\"%s %s -> %s\", c.TaskArn, c.ContainerName, c.Status.String())\n\tif c.ExitCode != nil {\n\t\tres += \", Exit \" + strconv.Itoa(*c.ExitCode) + \", \"\n\t}\n\tif c.Reason != \"\" {\n\t\tres += \", Reason \" + c.Reason\n\t}\n\tif len(c.PortBindings) != 0 {\n\t\tres += fmt.Sprintf(\", Ports %v\", c.PortBindings)\n\t}\n\tif c.Container != nil {\n\t\tres += \", Known Sent: \" + c.Container.GetSentStatus().String()\n\t}\n\treturn res\n}\n\n// String returns a human readable string representation of this object\nfunc (t *TaskStateChange) String() string {\n\tres := fmt.Sprintf(\"%s -> %s\", t.TaskArn, t.Status.String())\n\tif t.Task != nil {\n\t\tres += \", Known Sent: \" + t.Task.GetSentStatus().String()\n\t}\n\treturn res\n}\n", "idx": 1, "id": 15044, "msg": "This is supposed to be `status`. Why did you change this?", "proj": "aws-amazon-ecs-agent", "lang": "go"}
{"patch": "@@ -1,4 +1,4 @@\n-// <copyright file=\"ConsoleExporterOptions.cs\" company=\"OpenTelemetry Authors\">\n+\ufeff// <copyright file=\"ConsoleExporterOptions.cs\" company=\"OpenTelemetry Authors\">\n // Copyright The OpenTelemetry Authors\n //\n // Licensed under the Apache License, Version 2.0 (the \"License\");", "y": 1, "oldf": "// <copyright file=\"ConsoleExporterOptions.cs\" company=\"OpenTelemetry Authors\">\n// Copyright The OpenTelemetry Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n// </copyright>\n\nnamespace OpenTelemetry.Exporter.Console\n{\n    public class ConsoleExporterOptions\n    {\n        public bool Pretty { get; set; }\n    }\n}\n", "idx": 1, "id": 14549, "msg": "Is there a BOM change?", "proj": "open-telemetry-opentelemetry-dotnet", "lang": ".cs"}
{"patch": "@@ -19,7 +19,7 @@ DEFINE_int32(num_accept_threads, 1, \"Number of threads to accept incoming connec\n DEFINE_bool(reuse_port, true, \"Whether to turn on the SO_REUSEPORT option\");\n DEFINE_int32(listen_backlog, 1024, \"Backlog of the listen socket\");\n DEFINE_string(listen_netdev, \"any\", \"The network device to listen on\");\n-DEFINE_string(pid_file, \"nebula-graphd.pid\", \"File to hold the process id\");\n+DEFINE_string(pid_file, \"pids/nebula-graphd.pid\", \"File to hold the process id\");\n \n DEFINE_bool(redirect_stdout, true, \"Whether to redirect stdout and stderr to separate files\");\n DEFINE_string(stdout_log_file, \"graphd-stdout.log\", \"Destination filename of stdout\");", "y": 1, "oldf": "/* Copyright (c) 2018 - present, VE Software Inc. All rights reserved\n *\n * This source code is licensed under Apache 2.0 License\n *  (found in the LICENSE.Apache file in the root directory)\n */\n\n#include \"base/Base.h\"\n#include \"graph/GraphFlags.h\"\n\nDEFINE_int32(port, 34500, \"Nebula Graph daemon's listen port\");\nDEFINE_int32(client_idle_timeout_secs, 0,\n                \"Seconds before we close the idle connections, 0 for infinite\");\nDEFINE_int32(session_idle_timeout_secs, 600,\n                \"Seconds before we expire the idle sessions, 0 for infinite\");\nDEFINE_int32(session_reclaim_interval_secs, 10, \"Period we try to reclaim expired sessions\");\nDEFINE_int32(num_netio_threads, 0,\n                \"Number of networking threads, 0 for number of physical CPU cores\");\nDEFINE_int32(num_accept_threads, 1, \"Number of threads to accept incoming connections\");\nDEFINE_bool(reuse_port, true, \"Whether to turn on the SO_REUSEPORT option\");\nDEFINE_int32(listen_backlog, 1024, \"Backlog of the listen socket\");\nDEFINE_string(listen_netdev, \"any\", \"The network device to listen on\");\nDEFINE_string(pid_file, \"nebula-graphd.pid\", \"File to hold the process id\");\n\nDEFINE_bool(redirect_stdout, true, \"Whether to redirect stdout and stderr to separate files\");\nDEFINE_string(stdout_log_file, \"graphd-stdout.log\", \"Destination filename of stdout\");\nDEFINE_string(stderr_log_file, \"graphd-stderr.log\", \"Destination filename of stderr\");\nDEFINE_bool(daemonize, true, \"Whether run as a daemon process\");\n", "idx": 1, "id": 16425, "msg": "Do we need to include the path?", "proj": "vesoft-inc-nebula", "lang": "cpp"}
{"patch": "@@ -22,7 +22,7 @@ namespace OpenTelemetry.Trace.Samplers\n     public sealed class AlwaysOffActivitySampler : ActivitySampler\n     {\n         /// <inheritdoc />\n-        public override string Description { get; } = nameof(AlwaysOffActivitySampler);\n+        public override string Description { get; } = \"AlwaysOffSampler\";\n \n         /// <inheritdoc />\n         public override SamplingResult ShouldSample(in ActivitySamplingParameters samplingParameters)", "y": 1, "oldf": "\ufeff// <copyright file=\"AlwaysOffActivitySampler.cs\" company=\"OpenTelemetry Authors\">\n// Copyright The OpenTelemetry Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n// </copyright>\n\nnamespace OpenTelemetry.Trace.Samplers\n{\n    /// <summary>\n    /// Sampler implementation which never samples any activity.\n    /// </summary>\n    public sealed class AlwaysOffActivitySampler : ActivitySampler\n    {\n        /// <inheritdoc />\n        public override string Description { get; } = nameof(AlwaysOffActivitySampler);\n\n        /// <inheritdoc />\n        public override SamplingResult ShouldSample(in ActivitySamplingParameters samplingParameters)\n        {\n            return new SamplingResult(false);\n        }\n    }\n}\n", "idx": 1, "id": 15016, "msg": "We'll be renaming ActivitySampler to Sampler anyway, so this change will be non-required. Prefer to avoid changes here to avoid merge conflict with my PR doing the rename.", "proj": "open-telemetry-opentelemetry-dotnet", "lang": ".cs"}
{"patch": "@@ -269,7 +269,9 @@ func (f *Fs) connect(ctx context.Context) (project *uplink.Project, err error) {\n \tfs.Debugf(f, \"connecting...\")\n \tdefer fs.Debugf(f, \"connected: %+v\", err)\n \n-\tcfg := uplink.Config{}\n+\tcfg := uplink.Config{\n+\t\tUserAgent: \"rclone\",\n+\t}\n \n \tproject, err = cfg.OpenProject(ctx, f.access)\n \tif err != nil {", "y": 1, "oldf": "// +build go1.13,!plan9\n\n// Package tardigrade provides an interface to Tardigrade decentralized object storage.\npackage tardigrade\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"path\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/pkg/errors\"\n\t\"github.com/rclone/rclone/fs\"\n\t\"github.com/rclone/rclone/fs/config\"\n\t\"github.com/rclone/rclone/fs/config/configmap\"\n\t\"github.com/rclone/rclone/fs/config/configstruct\"\n\t\"github.com/rclone/rclone/fs/fserrors\"\n\t\"github.com/rclone/rclone/fs/hash\"\n\t\"github.com/rclone/rclone/lib/bucket\"\n\t\"golang.org/x/text/unicode/norm\"\n\n\t\"storj.io/uplink\"\n)\n\nconst (\n\texistingProvider = \"existing\"\n\tnewProvider      = \"new\"\n)\n\nvar satMap = map[string]string{\n\t\"us-central-1.tardigrade.io\":  \"12EayRS2V1kEsWESU9QMRseFhdxYxKicsiFmxrsLZHeLUtdps3S@us-central-1.tardigrade.io:7777\",\n\t\"europe-west-1.tardigrade.io\": \"12L9ZFwhzVpuEKMUNUqkaTLGzwY9G24tbiigLiXpmZWKwmcNDDs@europe-west-1.tardigrade.io:7777\",\n\t\"asia-east-1.tardigrade.io\":   \"121RTSDpyNZVcEU84Ticf2L1ntiuUimbWgfATz21tuvgk3vzoA6@asia-east-1.tardigrade.io:7777\",\n}\n\n// Register with Fs\nfunc init() {\n\tfs.Register(&fs.RegInfo{\n\t\tName:        \"tardigrade\",\n\t\tDescription: \"Tardigrade Decentralized Cloud Storage\",\n\t\tNewFs:       NewFs,\n\t\tConfig: func(name string, configMapper configmap.Mapper) {\n\t\t\tprovider, _ := configMapper.Get(fs.ConfigProvider)\n\n\t\t\tconfig.FileDeleteKey(name, fs.ConfigProvider)\n\n\t\t\tif provider == newProvider {\n\t\t\t\tsatelliteString, _ := configMapper.Get(\"satellite_address\")\n\t\t\t\tapiKey, _ := configMapper.Get(\"api_key\")\n\t\t\t\tpassphrase, _ := configMapper.Get(\"passphrase\")\n\n\t\t\t\t// satelliteString contains always default and passphrase can be empty\n\t\t\t\tif apiKey == \"\" {\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tsatellite, found := satMap[satelliteString]\n\t\t\t\tif !found {\n\t\t\t\t\tsatellite = satelliteString\n\t\t\t\t}\n\n\t\t\t\taccess, err := uplink.RequestAccessWithPassphrase(context.TODO(), satellite, apiKey, passphrase)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Fatalf(\"Couldn't create access grant: %v\", err)\n\t\t\t\t}\n\n\t\t\t\tserialziedAccess, err := access.Serialize()\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Fatalf(\"Couldn't serialize access grant: %v\", err)\n\t\t\t\t}\n\t\t\t\tconfigMapper.Set(\"satellite_address\", satellite)\n\t\t\t\tconfigMapper.Set(\"access_grant\", serialziedAccess)\n\t\t\t} else if provider == existingProvider {\n\t\t\t\tconfig.FileDeleteKey(name, \"satellite_address\")\n\t\t\t\tconfig.FileDeleteKey(name, \"api_key\")\n\t\t\t\tconfig.FileDeleteKey(name, \"passphrase\")\n\t\t\t} else {\n\t\t\t\tlog.Fatalf(\"Invalid provider type: %s\", provider)\n\t\t\t}\n\t\t},\n\t\tOptions: []fs.Option{\n\t\t\t{\n\t\t\t\tName:     fs.ConfigProvider,\n\t\t\t\tHelp:     \"Choose an authentication method.\",\n\t\t\t\tRequired: true,\n\t\t\t\tDefault:  existingProvider,\n\t\t\t\tExamples: []fs.OptionExample{{\n\t\t\t\t\tValue: \"existing\",\n\t\t\t\t\tHelp:  \"Use an existing access grant.\",\n\t\t\t\t}, {\n\t\t\t\t\tValue: newProvider,\n\t\t\t\t\tHelp:  \"Create a new access grant from satellite address, API key, and passphrase.\",\n\t\t\t\t},\n\t\t\t\t}},\n\t\t\t{\n\t\t\t\tName:     \"access_grant\",\n\t\t\t\tHelp:     \"Access Grant.\",\n\t\t\t\tRequired: false,\n\t\t\t\tProvider: \"existing\",\n\t\t\t},\n\t\t\t{\n\t\t\t\tName:     \"satellite_address\",\n\t\t\t\tHelp:     \"Satellite Address. Custom satellite address should match the format: `<nodeid>@<address>:<port>`.\",\n\t\t\t\tRequired: false,\n\t\t\t\tProvider: newProvider,\n\t\t\t\tDefault:  \"us-central-1.tardigrade.io\",\n\t\t\t\tExamples: []fs.OptionExample{{\n\t\t\t\t\tValue: \"us-central-1.tardigrade.io\",\n\t\t\t\t\tHelp:  \"US Central 1\",\n\t\t\t\t}, {\n\t\t\t\t\tValue: \"europe-west-1.tardigrade.io\",\n\t\t\t\t\tHelp:  \"Europe West 1\",\n\t\t\t\t}, {\n\t\t\t\t\tValue: \"asia-east-1.tardigrade.io\",\n\t\t\t\t\tHelp:  \"Asia East 1\",\n\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tName:     \"api_key\",\n\t\t\t\tHelp:     \"API Key.\",\n\t\t\t\tRequired: false,\n\t\t\t\tProvider: newProvider,\n\t\t\t},\n\t\t\t{\n\t\t\t\tName:     \"passphrase\",\n\t\t\t\tHelp:     \"Encryption Passphrase. To access existing objects enter passphrase used for uploading.\",\n\t\t\t\tRequired: false,\n\t\t\t\tProvider: newProvider,\n\t\t\t},\n\t\t},\n\t})\n}\n\n// Options defines the configuration for this backend\ntype Options struct {\n\tAccess string `config:\"access_grant\"`\n\n\tSatelliteAddress string `config:\"satellite_address\"`\n\tAPIKey           string `config:\"api_key\"`\n\tPassphrase       string `config:\"passphrase\"`\n}\n\n// Fs represents a remote to Tardigrade\ntype Fs struct {\n\tname string // the name of the remote\n\troot string // root of the filesystem\n\n\topts     Options      // parsed options\n\tfeatures *fs.Features // optional features\n\n\taccess *uplink.Access // parsed scope\n\n\tproject *uplink.Project // project client\n}\n\n// Check the interfaces are satisfied.\nvar (\n\t_ fs.Fs          = &Fs{}\n\t_ fs.ListRer     = &Fs{}\n\t_ fs.PutStreamer = &Fs{}\n)\n\n// NewFs creates a filesystem backed by Tardigrade.\nfunc NewFs(name, root string, m configmap.Mapper) (_ fs.Fs, err error) {\n\tctx := context.Background()\n\n\t// Setup filesystem and connection to Tardigrade\n\troot = norm.NFC.String(root)\n\troot = strings.Trim(root, \"/\")\n\n\tf := &Fs{\n\t\tname: name,\n\t\troot: root,\n\t}\n\n\t// Parse config into Options struct\n\terr = configstruct.Set(m, &f.opts)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Parse access\n\tvar access *uplink.Access\n\n\tif f.opts.Access != \"\" {\n\t\taccess, err = uplink.ParseAccess(f.opts.Access)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"tardigrade: access\")\n\t\t}\n\t}\n\n\tif access == nil && f.opts.SatelliteAddress != \"\" && f.opts.APIKey != \"\" && f.opts.Passphrase != \"\" {\n\t\taccess, err = uplink.RequestAccessWithPassphrase(ctx, f.opts.SatelliteAddress, f.opts.APIKey, f.opts.Passphrase)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"tardigrade: access\")\n\t\t}\n\n\t\tserializedAccess, err := access.Serialize()\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"tardigrade: access\")\n\t\t}\n\n\t\terr = config.SetValueAndSave(f.name, \"access_grant\", serializedAccess)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"tardigrade: access\")\n\t\t}\n\t}\n\n\tif access == nil {\n\t\treturn nil, errors.New(\"access not found\")\n\t}\n\n\tf.access = access\n\n\tf.features = (&fs.Features{\n\t\tBucketBased:       true,\n\t\tBucketBasedRootOK: true,\n\t}).Fill(f)\n\n\tproject, err := f.connect(ctx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tf.project = project\n\n\t// Root validation needs to check the following: If a bucket path is\n\t// specified and exists, then the object must be a directory.\n\t//\n\t// NOTE: At this point this must return the filesystem object we've\n\t// created so far even if there is an error.\n\tif root != \"\" {\n\t\tbucketName, bucketPath := bucket.Split(root)\n\n\t\tif bucketName != \"\" && bucketPath != \"\" {\n\t\t\t_, err = project.StatBucket(ctx, bucketName)\n\t\t\tif err != nil {\n\t\t\t\treturn f, errors.Wrap(err, \"tardigrade: bucket\")\n\t\t\t}\n\n\t\t\tobject, err := project.StatObject(ctx, bucketName, bucketPath)\n\t\t\tif err == nil {\n\t\t\t\tif !object.IsPrefix {\n\t\t\t\t\t// If the root is actually a file we\n\t\t\t\t\t// need to return the *parent*\n\t\t\t\t\t// directory of the root instead and an\n\t\t\t\t\t// error that the original root\n\t\t\t\t\t// requested is a file.\n\t\t\t\t\tnewRoot := path.Dir(f.root)\n\t\t\t\t\tif newRoot == \".\" {\n\t\t\t\t\t\tnewRoot = \"\"\n\t\t\t\t\t}\n\t\t\t\t\tf.root = newRoot\n\n\t\t\t\t\treturn f, fs.ErrorIsFile\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn f, nil\n}\n\n// connect opens a connection to Tardigrade.\nfunc (f *Fs) connect(ctx context.Context) (project *uplink.Project, err error) {\n\tfs.Debugf(f, \"connecting...\")\n\tdefer fs.Debugf(f, \"connected: %+v\", err)\n\n\tcfg := uplink.Config{}\n\n\tproject, err = cfg.OpenProject(ctx, f.access)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"tardigrade: project\")\n\t}\n\n\treturn\n}\n\n// absolute computes the absolute bucket name and path from the filesystem root\n// and the relative path provided.\nfunc (f *Fs) absolute(relative string) (bucketName, bucketPath string) {\n\tbn, bp := bucket.Split(path.Join(f.root, relative))\n\n\t// NOTE: Technically libuplink does not care about the encoding. It is\n\t// happy to work with them as opaque byte sequences. However, rclone\n\t// has a test that requires two paths with the same normalized form\n\t// (but different un-normalized forms) to point to the same file. This\n\t// means we have to normalize before we interact with libuplink.\n\treturn norm.NFC.String(bn), norm.NFC.String(bp)\n}\n\n// Name of the remote (as passed into NewFs)\nfunc (f *Fs) Name() string {\n\treturn f.name\n}\n\n// Root of the remote (as passed into NewFs)\nfunc (f *Fs) Root() string {\n\treturn f.root\n}\n\n// String returns a description of the FS\nfunc (f *Fs) String() string {\n\treturn fmt.Sprintf(\"FS sj://%s\", f.root)\n}\n\n// Precision of the ModTimes in this Fs\nfunc (f *Fs) Precision() time.Duration {\n\treturn time.Nanosecond\n}\n\n// Hashes returns the supported hash types of the filesystem.\nfunc (f *Fs) Hashes() hash.Set {\n\treturn hash.NewHashSet()\n}\n\n// Features returns the optional features of this Fs\nfunc (f *Fs) Features() *fs.Features {\n\treturn f.features\n}\n\n// List the objects and directories in relative into entries. The entries can\n// be returned in any order but should be for a complete directory.\n//\n// relative should be \"\" to list the root, and should not have trailing\n// slashes.\n//\n// This should return fs.ErrDirNotFound if the directory isn't found.\nfunc (f *Fs) List(ctx context.Context, relative string) (entries fs.DirEntries, err error) {\n\tfs.Debugf(f, \"ls ./%s\", relative)\n\n\tbucketName, bucketPath := f.absolute(relative)\n\n\tdefer func() {\n\t\tif errors.Is(err, uplink.ErrBucketNotFound) {\n\t\t\terr = fs.ErrorDirNotFound\n\t\t}\n\t}()\n\n\tif bucketName == \"\" {\n\t\tif bucketPath != \"\" {\n\t\t\treturn nil, fs.ErrorListBucketRequired\n\t\t}\n\n\t\treturn f.listBuckets(ctx)\n\t}\n\n\treturn f.listObjects(ctx, relative, bucketName, bucketPath)\n}\n\nfunc (f *Fs) listBuckets(ctx context.Context) (entries fs.DirEntries, err error) {\n\tfs.Debugf(f, \"BKT ls\")\n\n\tbuckets := f.project.ListBuckets(ctx, nil)\n\n\tfor buckets.Next() {\n\t\tbucket := buckets.Item()\n\n\t\tentries = append(entries, fs.NewDir(bucket.Name, bucket.Created))\n\t}\n\n\treturn entries, buckets.Err()\n}\n\n// newDirEntry creates a directory entry from an uplink object.\n//\n// NOTE: Getting the exact behavior required by rclone is somewhat tricky. The\n// path manipulation here is necessary to cover all the different ways the\n// filesystem and object could be initialized and combined.\nfunc (f *Fs) newDirEntry(relative, prefix string, object *uplink.Object) fs.DirEntry {\n\tif object.IsPrefix {\n\t\t//                         . The entry must include the relative path as its prefix. Depending on\n\t\t//                         | what is being listed and how the filesystem root was initialized the\n\t\t//                         | relative path may be empty (and so we use path joining here to ensure\n\t\t//                         | we don't end up with an empty path segment).\n\t\t//                         |\n\t\t//                         |                    . Remove the prefix used during listing.\n\t\t//                         |                    |\n\t\t//                         |                    |           . Remove the trailing slash.\n\t\t//                         |                    |           |\n\t\t//                         v                    v           v\n\t\treturn fs.NewDir(path.Join(relative, object.Key[len(prefix):len(object.Key)-1]), object.System.Created)\n\t}\n\n\treturn newObjectFromUplink(f, relative, object)\n}\n\nfunc (f *Fs) listObjects(ctx context.Context, relative, bucketName, bucketPath string) (entries fs.DirEntries, err error) {\n\tfs.Debugf(f, \"OBJ ls ./%s (%q, %q)\", relative, bucketName, bucketPath)\n\n\topts := &uplink.ListObjectsOptions{\n\t\tPrefix: newPrefix(bucketPath),\n\n\t\tSystem: true,\n\t\tCustom: true,\n\t}\n\tfs.Debugf(f, \"opts %+v\", opts)\n\n\tobjects := f.project.ListObjects(ctx, bucketName, opts)\n\n\tfor objects.Next() {\n\t\tentries = append(entries, f.newDirEntry(relative, opts.Prefix, objects.Item()))\n\t}\n\n\terr = objects.Err()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn entries, nil\n}\n\n// ListR lists the objects and directories of the Fs starting from dir\n// recursively into out.\n//\n// relative should be \"\" to start from the root, and should not have trailing\n// slashes.\n//\n// This should return ErrDirNotFound if the directory isn't found.\n//\n// It should call callback for each tranche of entries read. These need not be\n// returned in any particular order. If callback returns an error then the\n// listing will stop immediately.\n//\n// Don't implement this unless you have a more efficient way of listing\n// recursively that doing a directory traversal.\nfunc (f *Fs) ListR(ctx context.Context, relative string, callback fs.ListRCallback) (err error) {\n\tfs.Debugf(f, \"ls -R ./%s\", relative)\n\n\tbucketName, bucketPath := f.absolute(relative)\n\n\tdefer func() {\n\t\tif errors.Is(err, uplink.ErrBucketNotFound) {\n\t\t\terr = fs.ErrorDirNotFound\n\t\t}\n\t}()\n\n\tif bucketName == \"\" {\n\t\tif bucketPath != \"\" {\n\t\t\treturn fs.ErrorListBucketRequired\n\t\t}\n\n\t\treturn f.listBucketsR(ctx, callback)\n\t}\n\n\treturn f.listObjectsR(ctx, relative, bucketName, bucketPath, callback)\n}\n\nfunc (f *Fs) listBucketsR(ctx context.Context, callback fs.ListRCallback) (err error) {\n\tfs.Debugf(f, \"BKT ls -R\")\n\n\tbuckets := f.project.ListBuckets(ctx, nil)\n\n\tfor buckets.Next() {\n\t\tbucket := buckets.Item()\n\n\t\terr = f.listObjectsR(ctx, bucket.Name, bucket.Name, \"\", callback)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn buckets.Err()\n}\n\nfunc (f *Fs) listObjectsR(ctx context.Context, relative, bucketName, bucketPath string, callback fs.ListRCallback) (err error) {\n\tfs.Debugf(f, \"OBJ ls -R ./%s (%q, %q)\", relative, bucketName, bucketPath)\n\n\topts := &uplink.ListObjectsOptions{\n\t\tPrefix:    newPrefix(bucketPath),\n\t\tRecursive: true,\n\n\t\tSystem: true,\n\t\tCustom: true,\n\t}\n\n\tobjects := f.project.ListObjects(ctx, bucketName, opts)\n\n\tfor objects.Next() {\n\t\tobject := objects.Item()\n\n\t\terr = callback(fs.DirEntries{f.newDirEntry(relative, opts.Prefix, object)})\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\terr = objects.Err()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\n// NewObject finds the Object at relative. If it can't be found it returns the\n// error ErrorObjectNotFound.\nfunc (f *Fs) NewObject(ctx context.Context, relative string) (_ fs.Object, err error) {\n\tfs.Debugf(f, \"stat ./%s\", relative)\n\n\tbucketName, bucketPath := f.absolute(relative)\n\n\tobject, err := f.project.StatObject(ctx, bucketName, bucketPath)\n\tif err != nil {\n\t\tfs.Debugf(f, \"err: %+v\", err)\n\n\t\tif errors.Is(err, uplink.ErrObjectNotFound) {\n\t\t\treturn nil, fs.ErrorObjectNotFound\n\t\t}\n\t\treturn nil, err\n\t}\n\n\treturn newObjectFromUplink(f, relative, object), nil\n}\n\n// Put in to the remote path with the modTime given of the given size\n//\n// When called from outside an Fs by rclone, src.Size() will always be >= 0.\n// But for unknown-sized objects (indicated by src.Size() == -1), Put should\n// either return an error or upload it properly (rather than e.g. calling\n// panic).\n//\n// May create the object even if it returns an error - if so will return the\n// object and the error, otherwise will return nil and the error\nfunc (f *Fs) Put(ctx context.Context, in io.Reader, src fs.ObjectInfo, options ...fs.OpenOption) (_ fs.Object, err error) {\n\tfs.Debugf(f, \"cp input ./%s # %+v %d\", src.Remote(), options, src.Size())\n\n\t// Reject options we don't support.\n\tfor _, option := range options {\n\t\tif option.Mandatory() {\n\t\t\tfs.Errorf(f, \"Unsupported mandatory option: %v\", option)\n\n\t\t\treturn nil, errors.New(\"unsupported mandatory option\")\n\t\t}\n\t}\n\n\tbucketName, bucketPath := f.absolute(src.Remote())\n\n\tupload, err := f.project.UploadObject(ctx, bucketName, bucketPath, nil)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer func() {\n\t\tif err != nil {\n\t\t\taerr := upload.Abort()\n\t\t\tif aerr != nil {\n\t\t\t\tfs.Errorf(f, \"cp input ./%s %+v: %+v\", src.Remote(), options, aerr)\n\t\t\t}\n\t\t}\n\t}()\n\n\terr = upload.SetCustomMetadata(ctx, uplink.CustomMetadata{\n\t\t\"rclone:mtime\": src.ModTime(ctx).Format(time.RFC3339Nano),\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t_, err = io.Copy(upload, in)\n\tif err != nil {\n\t\terr = fserrors.RetryError(err)\n\t\tfs.Errorf(f, \"cp input ./%s %+v: %+v\\n\", src.Remote(), options, err)\n\n\t\treturn nil, err\n\t}\n\n\terr = upload.Commit()\n\tif err != nil {\n\t\tif errors.Is(err, uplink.ErrBucketNotFound) {\n\t\t\t// Rclone assumes the backend will create the bucket if not existing yet.\n\t\t\t// Here we create the bucket and return a retry error for rclone to retry the upload.\n\t\t\t_, err = f.project.EnsureBucket(ctx, bucketName)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\terr = fserrors.RetryError(errors.New(\"bucket was not available, now created, the upload must be retried\"))\n\t\t}\n\t\treturn nil, err\n\t}\n\n\treturn newObjectFromUplink(f, \"\", upload.Info()), nil\n}\n\n// PutStream uploads to the remote path with the modTime given of indeterminate\n// size.\n//\n// May create the object even if it returns an error - if so will return the\n// object and the error, otherwise will return nil and the error.\nfunc (f *Fs) PutStream(ctx context.Context, in io.Reader, src fs.ObjectInfo, options ...fs.OpenOption) (_ fs.Object, err error) {\n\treturn f.Put(ctx, in, src, options...)\n}\n\n// Mkdir makes the directory (container, bucket)\n//\n// Shouldn't return an error if it already exists\nfunc (f *Fs) Mkdir(ctx context.Context, relative string) (err error) {\n\tfs.Debugf(f, \"mkdir -p ./%s\", relative)\n\n\tbucketName, _ := f.absolute(relative)\n\n\t_, err = f.project.EnsureBucket(ctx, bucketName)\n\n\treturn err\n}\n\n// Rmdir removes the directory (container, bucket)\n//\n// NOTE: Despite code documentation to the contrary, this method should not\n// return an error if the directory does not exist.\nfunc (f *Fs) Rmdir(ctx context.Context, relative string) (err error) {\n\tfs.Debugf(f, \"rmdir ./%s\", relative)\n\n\tbucketName, bucketPath := f.absolute(relative)\n\n\tif bucketPath != \"\" {\n\t\t// If we can successfully stat it, then it is an object (and not a prefix).\n\t\t_, err := f.project.StatObject(ctx, bucketName, bucketPath)\n\t\tif err != nil {\n\t\t\tif errors.Is(err, uplink.ErrObjectNotFound) {\n\t\t\t\t// At this point we know it is not an object,\n\t\t\t\t// but we don't know if it is a prefix for one.\n\t\t\t\t//\n\t\t\t\t// We check this by doing a listing and if we\n\t\t\t\t// get any results back, then we know this is a\n\t\t\t\t// valid prefix (which implies the directory is\n\t\t\t\t// not empty).\n\t\t\t\topts := &uplink.ListObjectsOptions{\n\t\t\t\t\tPrefix: newPrefix(bucketPath),\n\n\t\t\t\t\tSystem: true,\n\t\t\t\t\tCustom: true,\n\t\t\t\t}\n\n\t\t\t\tobjects := f.project.ListObjects(ctx, bucketName, opts)\n\n\t\t\t\tif objects.Next() {\n\t\t\t\t\treturn fs.ErrorDirectoryNotEmpty\n\t\t\t\t}\n\n\t\t\t\treturn objects.Err()\n\t\t\t}\n\n\t\t\treturn err\n\t\t}\n\n\t\treturn fs.ErrorIsFile\n\t}\n\n\t_, err = f.project.DeleteBucket(ctx, bucketName)\n\tif err != nil {\n\t\tif errors.Is(err, uplink.ErrBucketNotFound) {\n\t\t\treturn fs.ErrorDirNotFound\n\t\t}\n\n\t\tif errors.Is(err, uplink.ErrBucketNotEmpty) {\n\t\t\treturn fs.ErrorDirectoryNotEmpty\n\t\t}\n\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\n// newPrefix returns a new prefix for listing conforming to the libuplink\n// requirements. In particular, libuplink requires a trailing slash for\n// listings, but rclone does not always provide one. Further, depending on how\n// the path was initially path normalization may have removed it (e.g. a\n// trailing slash from the CLI is removed before it ever gets to the backend\n// code).\nfunc newPrefix(prefix string) string {\n\tif prefix == \"\" {\n\t\treturn prefix\n\t}\n\n\tif prefix[len(prefix)-1] == '/' {\n\t\treturn prefix\n\t}\n\n\treturn prefix + \"/\"\n}\n", "idx": 1, "id": 11195, "msg": "That looks fine! You could use `\"rclone/\"+fs.Version` too if you wanted. BTW does tardigrade use http under the hood? If you were using rclone's http Client then you'd get a User-Agent and you'd also get support for `-vv --dump bodies` and other nice things.", "proj": "rclone-rclone", "lang": "go"}
{"patch": "@@ -490,6 +490,16 @@ given file (report RP0402 must not be disabled)'}\n                 importedname = node.modname\n             else:\n                 importedname = node.names[0][0].split('.')[0]\n+        if isinstance(node, astroid.ImportFrom) and \\\n+                node.as_string().startswith('from .'):\n+            # We need the impotedname with first point to detect local package\n+            # Example of node:\n+            #  'from .my_package1 import MyClass1'\n+            #  the output should be '.my_package1' instead of 'my_package1'\n+            # Example of node:\n+            #  'from . import my_package2'\n+            #  the output should be '.my_package2' instead of '{pyfile}'\n+            importedname = '.' + importedname\n         self._imports_stack.append((node, importedname))\n \n     @staticmethod", "y": 1, "oldf": "# Copyright (c) 2003-2013 LOGILAB S.A. (Paris, FRANCE).\n# http://www.logilab.fr/ -- mailto:contact@logilab.fr\n#\n# This program is free software; you can redistribute it and/or modify it under\n# the terms of the GNU General Public License as published by the Free Software\n# Foundation; either version 2 of the License, or (at your option) any later\n# version.\n#\n# This program is distributed in the hope that it will be useful, but WITHOUT\n# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n# FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License along with\n# this program; if not, write to the Free Software Foundation, Inc.,\n# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.\n\"\"\"imports checkers for Python code\"\"\"\n\nimport collections\nfrom distutils import sysconfig\nimport os\nimport sys\n\nimport six\n\nimport astroid\nfrom astroid import are_exclusive\nfrom astroid.modutils import (get_module_part, is_standard_module)\nimport isort\n\nfrom pylint.interfaces import IAstroidChecker\nfrom pylint.utils import EmptyReport, get_global_option\nfrom pylint.checkers import BaseChecker\nfrom pylint.checkers.utils import check_messages, node_ignores_exception\nfrom pylint.graph import get_cycles, DotBackend\nfrom pylint.reporters.ureports.nodes import VerbatimText, Paragraph\n\n\ndef _qualified_names(modname):\n    \"\"\"Split the names of the given module into subparts\n\n    For example,\n        _qualified_names('pylint.checkers.ImportsChecker')\n    returns\n        ['pylint', 'pylint.checkers', 'pylint.checkers.ImportsChecker']\n    \"\"\"\n    names = modname.split('.')\n    return ['.'.join(names[0:i+1]) for i in range(len(names))]\n\n\ndef _get_import_name(importnode, modname):\n    \"\"\"Get a prepared module name from the given import node\n\n    In the case of relative imports, this will return the\n    absolute qualified module name, which might be useful\n    for debugging. Otherwise, the initial module name\n    is returned unchanged.\n    \"\"\"\n    if isinstance(importnode, astroid.ImportFrom):\n        if importnode.level:\n            root = importnode.root()\n            if isinstance(root, astroid.Module):\n                modname = root.relative_to_absolute_name(\n                    modname, level=importnode.level)\n    return modname\n\n\ndef _get_first_import(node, context, name, base, level, alias):\n    \"\"\"return the node where [base.]<name> is imported or None if not found\n    \"\"\"\n    fullname = '%s.%s' % (base, name) if base else name\n\n    first = None\n    found = False\n    for first in context.body:\n        if first is node:\n            continue\n        if first.scope() is node.scope() and first.fromlineno > node.fromlineno:\n            continue\n        if isinstance(first, astroid.Import):\n            if any(fullname == iname[0] for iname in first.names):\n                found = True\n                break\n        elif isinstance(first, astroid.ImportFrom):\n            if level == first.level:\n                for imported_name, imported_alias in first.names:\n                    if fullname == '%s.%s' % (first.modname, imported_name):\n                        found = True\n                        break\n                    if name != '*' and name == imported_name and not (alias or imported_alias):\n                        found = True\n                        break\n                if found:\n                    break\n    if found and not are_exclusive(first, node):\n        return first\n\n\ndef _ignore_import_failure(node, modname, ignored_modules):\n    for submodule in _qualified_names(modname):\n        if submodule in ignored_modules:\n            return True\n\n    return node_ignores_exception(node, ImportError)\n\n# utilities to represents import dependencies as tree and dot graph ###########\n\ndef _make_tree_defs(mod_files_list):\n    \"\"\"get a list of 2-uple (module, list_of_files_which_import_this_module),\n    it will return a dictionary to represent this as a tree\n    \"\"\"\n    tree_defs = {}\n    for mod, files in mod_files_list:\n        node = (tree_defs, ())\n        for prefix in mod.split('.'):\n            node = node[0].setdefault(prefix, [{}, []])\n        node[1] += files\n    return tree_defs\n\n\ndef _repr_tree_defs(data, indent_str=None):\n    \"\"\"return a string which represents imports as a tree\"\"\"\n    lines = []\n    nodes = data.items()\n    for i, (mod, (sub, files)) in enumerate(sorted(nodes, key=lambda x: x[0])):\n        if not files:\n            files = ''\n        else:\n            files = '(%s)' % ','.join(files)\n        if indent_str is None:\n            lines.append('%s %s' % (mod, files))\n            sub_indent_str = '  '\n        else:\n            lines.append(r'%s\\-%s %s' % (indent_str, mod, files))\n            if i == len(nodes)-1:\n                sub_indent_str = '%s  ' % indent_str\n            else:\n                sub_indent_str = '%s| ' % indent_str\n        if sub:\n            lines.append(_repr_tree_defs(sub, sub_indent_str))\n    return '\\n'.join(lines)\n\n\ndef _dependencies_graph(filename, dep_info):\n    \"\"\"write dependencies as a dot (graphviz) file\n    \"\"\"\n    done = {}\n    printer = DotBackend(filename[:-4], rankdir='LR')\n    printer.emit('URL=\".\" node[shape=\"box\"]')\n    for modname, dependencies in sorted(six.iteritems(dep_info)):\n        done[modname] = 1\n        printer.emit_node(modname)\n        for modname in dependencies:\n            if modname not in done:\n                done[modname] = 1\n                printer.emit_node(modname)\n    for depmodname, dependencies in sorted(six.iteritems(dep_info)):\n        for modname in dependencies:\n            printer.emit_edge(modname, depmodname)\n    printer.generate(filename)\n\n\ndef _make_graph(filename, dep_info, sect, gtype):\n    \"\"\"generate a dependencies graph and add some information about it in the\n    report's section\n    \"\"\"\n    _dependencies_graph(filename, dep_info)\n    sect.append(Paragraph('%simports graph has been written to %s'\n                          % (gtype, filename)))\n\n\n# the import checker itself ###################################################\n\nMSGS = {\n    'E0401': ('Unable to import %s',\n              'import-error',\n              'Used when pylint has been unable to import a module.',\n              {'old_names': [('F0401', 'import-error')]}),\n    'E0402': ('Attempted relative import beyond top-level package',\n              'relative-beyond-top-level',\n              'Used when a relative import tries to access too many levels '\n              'in the current package.'),\n    'R0401': ('Cyclic import (%s)',\n              'cyclic-import',\n              'Used when a cyclic import between two or more modules is \\\n              detected.'),\n\n    'W0401': ('Wildcard import %s',\n              'wildcard-import',\n              'Used when `from module import *` is detected.'),\n    'W0402': ('Uses of a deprecated module %r',\n              'deprecated-module',\n              'Used a module marked as deprecated is imported.'),\n    'W0403': ('Relative import %r, should be %r',\n              'relative-import',\n              'Used when an import relative to the package directory is '\n              'detected.',\n              {'maxversion': (3, 0)}),\n    'W0404': ('Reimport %r (imported line %s)',\n              'reimported',\n              'Used when a module is reimported multiple times.'),\n    'W0406': ('Module import itself',\n              'import-self',\n              'Used when a module is importing itself.'),\n\n    'W0410': ('__future__ import is not the first non docstring statement',\n              'misplaced-future',\n              'Python 2.5 and greater require __future__ import to be the \\\n              first non docstring statement in the module.'),\n\n    'C0410': ('Multiple imports on one line (%s)',\n              'multiple-imports',\n              'Used when import statement importing multiple modules is '\n              'detected.'),\n    'C0411': ('%s comes before %s',\n              'wrong-import-order',\n              'Used when PEP8 import order is not respected (standard imports '\n              'first, then third-party libraries, then local imports)'),\n    'C0412': ('Imports from package %s are not grouped',\n              'ungrouped-imports',\n              'Used when imports are not grouped by packages'),\n    'C0413': ('Import \"%s\" should be placed at the top of the '\n              'module',\n              'wrong-import-position',\n              'Used when code and imports are mixed'),\n    }\n\n\nDEFAULT_STANDARD_LIBRARY = ()\nDEFAULT_KNOWN_THIRD_PARTY = ('enchant',)\n\n\nclass ImportsChecker(BaseChecker):\n    \"\"\"checks for\n    * external modules dependencies\n    * relative / wildcard imports\n    * cyclic imports\n    * uses of deprecated modules\n    \"\"\"\n\n    __implements__ = IAstroidChecker\n\n    name = 'imports'\n    msgs = MSGS\n    priority = -2\n\n    if six.PY2:\n        deprecated_modules = ('regsub', 'TERMIOS', 'Bastion', 'rexec')\n    else:\n        deprecated_modules = ('optparse', )\n    options = (('deprecated-modules',\n                {'default' : deprecated_modules,\n                 'type' : 'csv',\n                 'metavar' : '<modules>',\n                 'help' : 'Deprecated modules which should not be used, \\\nseparated by a comma'}\n               ),\n               ('import-graph',\n                {'default' : '',\n                 'type' : 'string',\n                 'metavar' : '<file.dot>',\n                 'help' : 'Create a graph of every (i.e. internal and \\\nexternal) dependencies in the given file (report RP0402 must not be disabled)'}\n               ),\n               ('ext-import-graph',\n                {'default' : '',\n                 'type' : 'string',\n                 'metavar' : '<file.dot>',\n                 'help' : 'Create a graph of external dependencies in the \\\ngiven file (report RP0402 must not be disabled)'}\n               ),\n               ('int-import-graph',\n                {'default' : '',\n                 'type' : 'string',\n                 'metavar' : '<file.dot>',\n                 'help' : 'Create a graph of internal dependencies in the \\\ngiven file (report RP0402 must not be disabled)'}\n               ),\n               ('known-standard-library',\n                {'default': DEFAULT_STANDARD_LIBRARY,\n                 'type': 'csv',\n                 'metavar': '<modules>',\n                 'help': 'Force import order to recognize a module as part of' \\\n                         ' the standard compatibility libraries.'}\n               ),\n               ('known-third-party',\n                {'default': DEFAULT_KNOWN_THIRD_PARTY,\n                 'type': 'csv',\n                 'metavar': '<modules>',\n                 'help': 'Force import order to recognize a module as part of' \\\n                         ' a third party library.'}\n               ),\n\n              )\n\n    def __init__(self, linter=None):\n        BaseChecker.__init__(self, linter)\n        self.stats = None\n        self.import_graph = None\n        self._imports_stack = []\n        self._first_non_import_node = None\n        self.__int_dep_info = self.__ext_dep_info = None\n        self.reports = (('RP0401', 'External dependencies',\n                         self._report_external_dependencies),\n                        ('RP0402', 'Modules dependencies graph',\n                         self._report_dependencies_graph),\n                       )\n\n        self._site_packages = self._compute_site_packages()\n\n    @staticmethod\n    def _compute_site_packages():\n        def _normalized_path(path):\n            return os.path.normcase(os.path.abspath(path))\n\n        paths = set()\n        real_prefix = getattr(sys, 'real_prefix', None)\n        for prefix in filter(None, (real_prefix, sys.prefix)):\n            path = sysconfig.get_python_lib(prefix=prefix)\n            path = _normalized_path(path)\n            paths.add(path)\n\n        # Handle Debian's derivatives /usr/local.\n        if os.path.isfile(\"/etc/debian_version\"):\n            for prefix in filter(None, (real_prefix, sys.prefix)):\n                libpython = os.path.join(prefix, \"local\", \"lib\",\n                                         \"python\" + sysconfig.get_python_version(),\n                                         \"dist-packages\")\n                paths.add(libpython)\n        return paths\n\n    def open(self):\n        \"\"\"called before visiting project (i.e set of modules)\"\"\"\n        self.linter.add_stats(dependencies={})\n        self.linter.add_stats(cycles=[])\n        self.stats = self.linter.stats\n        self.import_graph = collections.defaultdict(set)\n        self._ignored_modules = get_global_option(\n            self, 'ignored-modules', default=[])\n\n    def close(self):\n        \"\"\"called before visiting project (i.e set of modules)\"\"\"\n        # don't try to compute cycles if the associated message is disabled\n        if self.linter.is_message_enabled('cyclic-import'):\n            vertices = list(self.import_graph)\n            for cycle in get_cycles(self.import_graph, vertices=vertices):\n                self.add_message('cyclic-import', args=' -> '.join(cycle))\n\n    @check_messages('wrong-import-position', 'multiple-imports',\n                    'relative-import', 'reimported')\n    def visit_import(self, node):\n        \"\"\"triggered when an import statement is seen\"\"\"\n        self._check_reimport(node)\n\n        modnode = node.root()\n        names = [name for name, _ in node.names]\n        if len(names) >= 2:\n            self.add_message('multiple-imports', args=', '.join(names), node=node)\n\n        for name in names:\n            self._check_deprecated_module(node, name)\n            importedmodnode = self._get_imported_module(node, name)\n            if isinstance(node.scope(), astroid.Module):\n                self._check_position(node)\n                self._record_import(node, importedmodnode)\n\n            if importedmodnode is None:\n                continue\n\n            self._check_relative_import(modnode, node, importedmodnode, name)\n            self._add_imported_module(node, importedmodnode.name)\n\n    @check_messages(*(MSGS.keys()))\n    def visit_importfrom(self, node):\n        \"\"\"triggered when a from statement is seen\"\"\"\n        basename = node.modname\n        self._check_misplaced_future(node)\n        self._check_deprecated_module(node, basename)\n        self._check_wildcard_imports(node)\n        self._check_same_line_imports(node)\n        self._check_reimport(node, basename=basename, level=node.level)\n\n        modnode = node.root()\n        importedmodnode = self._get_imported_module(node, basename)\n        if isinstance(node.scope(), astroid.Module):\n            self._check_position(node)\n            self._record_import(node, importedmodnode)\n        if importedmodnode is None:\n            return\n        self._check_relative_import(modnode, node, importedmodnode, basename)\n\n        for name, _ in node.names:\n            if name != '*':\n                self._add_imported_module(node, '%s.%s' % (importedmodnode.name, name))\n\n    @check_messages('wrong-import-order', 'ungrouped-imports',\n                    'wrong-import-position')\n    def leave_module(self, node):\n        # Check imports are grouped by category (standard, 3rd party, local)\n        std_imports, ext_imports, loc_imports = self._check_imports_order(node)\n\n        # Check imports are grouped by package within a given category\n        met = set()\n        current_package = None\n        for import_node, import_name in std_imports + ext_imports + loc_imports:\n            package, _, _ = import_name.partition('.')\n            if current_package and current_package != package and package in met:\n                self.add_message('ungrouped-imports', node=import_node,\n                                 args=package)\n            current_package = package\n            met.add(package)\n\n        self._imports_stack = []\n        self._first_non_import_node = None\n\n    def visit_if(self, node):\n        # if the node does not contain an import instruction, and if it is the\n        # first node of the module, keep a track of it (all the import positions\n        # of the module will be compared to the position of this first\n        # instruction)\n        if self._first_non_import_node:\n            return\n        if not isinstance(node.parent, astroid.Module):\n            return\n        if any(node.nodes_of_class((astroid.Import, astroid.ImportFrom))):\n            return\n        self._first_non_import_node = node\n\n    visit_tryfinally = visit_tryexcept = visit_assignattr = visit_assign \\\n            = visit_ifexp = visit_comprehension = visit_if\n\n    def visit_functiondef(self, node):\n        # If it is the first non import instruction of the module, record it.\n        if self._first_non_import_node:\n            return\n\n        # Check if the node belongs to an `If` or a `Try` block. If they\n        # contain imports, skip recording this node.\n        if not isinstance(node.parent.scope(), astroid.Module):\n            return\n\n        root = node\n        while not isinstance(root.parent, astroid.Module):\n            root = root.parent\n\n        if isinstance(root, (astroid.If, astroid.TryFinally, astroid.TryExcept)):\n            if any(root.nodes_of_class((astroid.Import, astroid.ImportFrom))):\n                return\n\n        self._first_non_import_node = node\n\n    visit_classdef = visit_for = visit_while = visit_functiondef\n\n    def _check_misplaced_future(self, node):\n        basename = node.modname\n        if basename == '__future__':\n            # check if this is the first non-docstring statement in the module\n            prev = node.previous_sibling()\n            if prev:\n                # consecutive future statements are possible\n                if not (isinstance(prev, astroid.ImportFrom)\n                        and prev.modname == '__future__'):\n                    self.add_message('misplaced-future', node=node)\n            return\n\n    def _check_same_line_imports(self, node):\n        # Detect duplicate imports on the same line.\n        names = (name for name, _ in node.names)\n        counter = collections.Counter(names)\n        for name, count in counter.items():\n            if count > 1:\n                self.add_message('reimported', node=node,\n                                 args=(name, node.fromlineno))\n\n    def _check_position(self, node):\n        \"\"\"Check `node` import or importfrom node position is correct\n\n        Send a message  if `node` comes before another instruction\n        \"\"\"\n        # if a first non-import instruction has already been encountered,\n        # it means the import comes after it and therefore is not well placed\n        if self._first_non_import_node:\n            self.add_message('wrong-import-position', node=node,\n                             args=node.as_string())\n\n    def _record_import(self, node, importedmodnode):\n        \"\"\"Record the package `node` imports from\"\"\"\n        importedname = importedmodnode.name if importedmodnode else None\n        if not importedname:\n            if isinstance(node, astroid.ImportFrom):\n                importedname = node.modname\n            else:\n                importedname = node.names[0][0].split('.')[0]\n        self._imports_stack.append((node, importedname))\n\n    @staticmethod\n    def _is_fallback_import(node, imports):\n        imports = [import_node for (import_node, _) in imports]\n        return any(astroid.are_exclusive(import_node, node)\n                   for import_node in imports)\n\n    def _check_imports_order(self, node):\n        \"\"\"Checks imports of module `node` are grouped by category\n\n        Imports must follow this order: standard, 3rd party, local\n        \"\"\"\n        extern_imports = []\n        local_imports = []\n        std_imports = []\n        isort_obj = isort.SortImports(\n            file_contents='', known_third_party=self.config.known_third_party,\n            known_standard_library=self.config.known_standard_library,\n        )\n        for node, modname in self._imports_stack:\n            package = modname.split('.')[0]\n            import_category = isort_obj.place_module(package)\n            if import_category in ('FUTURE', 'STDLIB'):\n                std_imports.append((node, package))\n                wrong_import = extern_imports or local_imports\n                if self._is_fallback_import(node, wrong_import):\n                    continue\n                if wrong_import:\n                    self.add_message('wrong-import-order', node=node,\n                                     args=('standard import \"%s\"' % node.as_string(),\n                                           '\"%s\"' % wrong_import[0][0].as_string()))\n            elif import_category in ('FIRSTPARTY', 'THIRDPARTY'):\n                extern_imports.append((node, package))\n                wrong_import = local_imports\n                if wrong_import:\n                    self.add_message('wrong-import-order', node=node,\n                                     args=('external import \"%s\"' % node.as_string(),\n                                           '\"%s\"' % wrong_import[0][0].as_string()))\n            elif import_category == 'LOCALFOLDER':\n                local_imports.append((node, package))\n        return std_imports, extern_imports, local_imports\n\n    def _get_imported_module(self, importnode, modname):\n        try:\n            return importnode.do_import_module(modname)\n        except astroid.TooManyLevelsError:\n            if _ignore_import_failure(importnode, modname, self._ignored_modules):\n                return None\n\n            self.add_message('relative-beyond-top-level', node=importnode)\n\n        except astroid.AstroidBuildingException:\n            if _ignore_import_failure(importnode, modname, self._ignored_modules):\n                return None\n\n            dotted_modname = _get_import_name(importnode, modname)\n            self.add_message('import-error', args=repr(dotted_modname),\n                             node=importnode)\n\n    def _check_relative_import(self, modnode, importnode, importedmodnode,\n                               importedasname):\n        \"\"\"check relative import. node is either an Import or From node, modname\n        the imported module name.\n        \"\"\"\n        if not self.linter.is_message_enabled('relative-import'):\n            return\n        if importedmodnode.file is None:\n            return False # built-in module\n        if modnode is importedmodnode:\n            return False # module importing itself\n        if modnode.absolute_import_activated() or getattr(importnode, 'level', None):\n            return False\n        if importedmodnode.name != importedasname:\n            # this must be a relative import...\n            self.add_message('relative-import',\n                             args=(importedasname, importedmodnode.name),\n                             node=importnode)\n\n    def _add_imported_module(self, node, importedmodname):\n        \"\"\"notify an imported module, used to analyze dependencies\"\"\"\n        module_file = node.root().file\n        context_name = node.root().name\n        base = os.path.splitext(os.path.basename(module_file))[0]\n\n        # Determine if we have a `from .something import` in a package's\n        # __init__. This means the module will never be able to import\n        # itself using this condition (the level will be bigger or\n        # if the same module is named as the package, it will be different\n        # anyway).\n        if isinstance(node, astroid.ImportFrom):\n            if node.level and node.level > 0 and base == '__init__':\n                return\n\n        try:\n            importedmodname = get_module_part(importedmodname,\n                                              module_file)\n        except ImportError:\n            pass\n\n        if context_name == importedmodname:\n            self.add_message('import-self', node=node)\n        elif not is_standard_module(importedmodname):\n            # handle dependencies\n            importedmodnames = self.stats['dependencies'].setdefault(\n                importedmodname, set())\n            if context_name not in importedmodnames:\n                importedmodnames.add(context_name)\n            # update import graph\n            mgraph = self.import_graph[context_name]\n            if importedmodname not in mgraph:\n                mgraph.add(importedmodname)\n\n    def _check_deprecated_module(self, node, mod_path):\n        \"\"\"check if the module is deprecated\"\"\"\n        for mod_name in self.config.deprecated_modules:\n            if mod_path == mod_name or mod_path.startswith(mod_name + '.'):\n                self.add_message('deprecated-module', node=node, args=mod_path)\n\n    def _check_reimport(self, node, basename=None, level=None):\n        \"\"\"check if the import is necessary (i.e. not already done)\"\"\"\n        if not self.linter.is_message_enabled('reimported'):\n            return\n\n        frame = node.frame()\n        root = node.root()\n        contexts = [(frame, level)]\n        if root is not frame:\n            contexts.append((root, None))\n\n        for context, level in contexts:\n            for name, alias in node.names:\n                first = _get_first_import(node, context, name, basename, level, alias)\n                if first is not None:\n                    self.add_message('reimported', node=node,\n                                     args=(name, first.fromlineno))\n\n    def _report_external_dependencies(self, sect, _, dummy):\n        \"\"\"return a verbatim layout for displaying dependencies\"\"\"\n        dep_info = _make_tree_defs(six.iteritems(self._external_dependencies_info()))\n        if not dep_info:\n            raise EmptyReport()\n        tree_str = _repr_tree_defs(dep_info)\n        sect.append(VerbatimText(tree_str))\n\n    def _report_dependencies_graph(self, sect, _, dummy):\n        \"\"\"write dependencies as a dot (graphviz) file\"\"\"\n        dep_info = self.stats['dependencies']\n        if not dep_info or not (self.config.import_graph\n                                or self.config.ext_import_graph\n                                or self.config.int_import_graph):\n            raise EmptyReport()\n        filename = self.config.import_graph\n        if filename:\n            _make_graph(filename, dep_info, sect, '')\n        filename = self.config.ext_import_graph\n        if filename:\n            _make_graph(filename, self._external_dependencies_info(),\n                        sect, 'external ')\n        filename = self.config.int_import_graph\n        if filename:\n            _make_graph(filename, self._internal_dependencies_info(),\n                        sect, 'internal ')\n\n    def _external_dependencies_info(self):\n        \"\"\"return cached external dependencies information or build and\n        cache them\n        \"\"\"\n        if self.__ext_dep_info is None:\n            package = self.linter.current_name\n            self.__ext_dep_info = result = {}\n            for importee, importers in six.iteritems(self.stats['dependencies']):\n                if not importee.startswith(package):\n                    result[importee] = importers\n        return self.__ext_dep_info\n\n    def _internal_dependencies_info(self):\n        \"\"\"return cached internal dependencies information or build and\n        cache them\n        \"\"\"\n        if self.__int_dep_info is None:\n            package = self.linter.current_name\n            self.__int_dep_info = result = {}\n            for importee, importers in six.iteritems(self.stats['dependencies']):\n                if importee.startswith(package):\n                    result[importee] = importers\n        return self.__int_dep_info\n\n    def _check_wildcard_imports(self, node):\n        for name, _ in node.names:\n            if name == '*':\n                self.add_message('wildcard-import', args=node.modname, node=node)\n\n\ndef register(linter):\n    \"\"\"required method to auto register this checker \"\"\"\n    linter.register_checker(ImportsChecker(linter))\n", "idx": 1, "id": 8398, "msg": "Alternatively (and better) would be to look for the .level attribute of the node. If it's bigger or equal to 1, than that is a relative import. So \"from . import x\" should have level 1, while \"from .. import z\" should have level 2 and so on. The same should happen for \"from .c import z\".", "proj": "PyCQA-pylint", "lang": "py"}
{"patch": "@@ -245,7 +245,15 @@ func (cds *contentDirectoryService) Handle(action string, argsXML []byte, r *htt\n \t\t\t\t\"UpdateID\":       cds.updateIDString(),\n \t\t\t}, nil\n \t\tcase \"BrowseMetadata\":\n-\t\t\tresult, err := xml.Marshal(obj)\n+\t\t\tnode, err := cds.vfs.Stat(obj.Path)\n+\t\t\tif err != nil {\n+\t\t\t\treturn nil, err\n+\t\t\t}\n+\t\t\tupnpObject, err := cds.cdsObjectToUpnpavObject(obj, node, host)\n+\t\t\tif err != nil {\n+\t\t\t\treturn nil, err\n+\t\t\t}\n+\t\t\tresult, err := xml.Marshal(upnpObject)\n \t\t\tif err != nil {\n \t\t\t\treturn nil, err\n \t\t\t}", "y": 1, "oldf": "package dlna\n\nimport (\n\t\"context\"\n\t\"encoding/xml\"\n\t\"fmt\"\n\t\"log\"\n\t\"mime\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"os\"\n\t\"path\"\n\t\"path/filepath\"\n\t\"regexp\"\n\t\"sort\"\n\t\"strings\"\n\n\t\"github.com/anacrolix/dms/dlna\"\n\t\"github.com/anacrolix/dms/upnp\"\n\t\"github.com/anacrolix/dms/upnpav\"\n\t\"github.com/pkg/errors\"\n\t\"github.com/rclone/rclone/fs\"\n\t\"github.com/rclone/rclone/vfs\"\n)\n\n// Add a minimal number of mime types to augment go's built in types\n// for environments which don't have access to a mime.types file (eg\n// Termux on android)\nfunc init() {\n\tfor _, t := range []struct {\n\t\tmimeType   string\n\t\textensions string\n\t}{\n\t\t{\"audio/flac\", \".flac\"},\n\t\t{\"audio/mpeg\", \".mpga,.mpega,.mp2,.mp3,.m4a\"},\n\t\t{\"audio/ogg\", \".oga,.ogg,.opus,.spx\"},\n\t\t{\"audio/x-wav\", \".wav\"},\n\t\t{\"image/tiff\", \".tiff,.tif\"},\n\t\t{\"video/dv\", \".dif,.dv\"},\n\t\t{\"video/fli\", \".fli\"},\n\t\t{\"video/mpeg\", \".mpeg,.mpg,.mpe\"},\n\t\t{\"video/MP2T\", \".ts\"},\n\t\t{\"video/mp4\", \".mp4\"},\n\t\t{\"video/quicktime\", \".qt,.mov\"},\n\t\t{\"video/ogg\", \".ogv\"},\n\t\t{\"video/webm\", \".webm\"},\n\t\t{\"video/x-msvideo\", \".avi\"},\n\t\t{\"video/x-matroska\", \".mpv,.mkv\"},\n\t} {\n\t\tfor _, ext := range strings.Split(t.extensions, \",\") {\n\t\t\terr := mime.AddExtensionType(ext, t.mimeType)\n\t\t\tif err != nil {\n\t\t\t\tpanic(err)\n\t\t\t}\n\t\t}\n\t}\n}\n\ntype contentDirectoryService struct {\n\t*server\n\tupnp.Eventing\n}\n\nfunc (cds *contentDirectoryService) updateIDString() string {\n\treturn fmt.Sprintf(\"%d\", uint32(os.Getpid()))\n}\n\nvar mediaMimeTypeRegexp = regexp.MustCompile(\"^(video|audio|image)/\")\n\n// Turns the given entry and DMS host into a UPnP object. A nil object is\n// returned if the entry is not of interest.\nfunc (cds *contentDirectoryService) cdsObjectToUpnpavObject(cdsObject object, fileInfo vfs.Node, host string) (ret interface{}, err error) {\n\tobj := upnpav.Object{\n\t\tID:         cdsObject.ID(),\n\t\tRestricted: 1,\n\t\tParentID:   cdsObject.ParentID(),\n\t}\n\n\tif fileInfo.IsDir() {\n\t\tobj.Class = \"object.container.storageFolder\"\n\t\tobj.Title = fileInfo.Name()\n\t\tret = upnpav.Container{Object: obj}\n\t\treturn\n\t}\n\n\tif !fileInfo.Mode().IsRegular() {\n\t\treturn\n\t}\n\n\t// Read the mime type from the fs.Object if possible,\n\t// otherwise fall back to working out what it is from the file path.\n\tvar mimeType string\n\tif o, ok := fileInfo.DirEntry().(fs.Object); ok {\n\t\tmimeType = fs.MimeType(context.TODO(), o)\n\t} else {\n\t\tmimeType = fs.MimeTypeFromName(fileInfo.Name())\n\t}\n\n\tmediaType := mediaMimeTypeRegexp.FindStringSubmatch(mimeType)\n\tif mediaType == nil {\n\t\treturn\n\t}\n\n\tobj.Class = \"object.item.\" + mediaType[1] + \"Item\"\n\tobj.Title = fileInfo.Name()\n\n\titem := upnpav.Item{\n\t\tObject: obj,\n\t\tRes:    make([]upnpav.Resource, 0, 1),\n\t}\n\n\titem.Res = append(item.Res, upnpav.Resource{\n\t\tURL: (&url.URL{\n\t\t\tScheme: \"http\",\n\t\t\tHost:   host,\n\t\t\tPath:   resPath,\n\t\t\tRawQuery: url.Values{\n\t\t\t\t\"path\": {cdsObject.Path},\n\t\t\t}.Encode(),\n\t\t}).String(),\n\t\tProtocolInfo: fmt.Sprintf(\"http-get:*:%s:%s\", mimeType, dlna.ContentFeatures{\n\t\t\tSupportRange: true,\n\t\t}.String()),\n\t\tBitrate:    0,\n\t\tDuration:   \"\",\n\t\tSize:       uint64(fileInfo.Size()),\n\t\tResolution: \"\",\n\t})\n\n\tret = item\n\treturn\n}\n\n// Returns all the upnpav objects in a directory.\nfunc (cds *contentDirectoryService) readContainer(o object, host string) (ret []interface{}, err error) {\n\tnode, err := cds.vfs.Stat(o.Path)\n\tif err != nil {\n\t\treturn\n\t}\n\n\tif !node.IsDir() {\n\t\terr = errors.New(\"not a directory\")\n\t\treturn\n\t}\n\n\tdir := node.(*vfs.Dir)\n\tdirEntries, err := dir.ReadDirAll()\n\tif err != nil {\n\t\terr = errors.New(\"failed to list directory\")\n\t\treturn\n\t}\n\n\tsort.Sort(dirEntries)\n\n\tfor _, de := range dirEntries {\n\t\tchild := object{\n\t\t\tpath.Join(o.Path, de.Name()),\n\t\t}\n\t\tobj, err := cds.cdsObjectToUpnpavObject(child, de, host)\n\t\tif err != nil {\n\t\t\tfs.Errorf(cds, \"error with %s: %s\", child.FilePath(), err)\n\t\t\tcontinue\n\t\t}\n\t\tif obj == nil {\n\t\t\tfs.Debugf(cds, \"unrecognized file type: %s\", de)\n\t\t\tcontinue\n\t\t}\n\t\tret = append(ret, obj)\n\t}\n\n\treturn\n}\n\ntype browse struct {\n\tObjectID       string\n\tBrowseFlag     string\n\tFilter         string\n\tStartingIndex  int\n\tRequestedCount int\n}\n\n// ContentDirectory object from ObjectID.\nfunc (cds *contentDirectoryService) objectFromID(id string) (o object, err error) {\n\to.Path, err = url.QueryUnescape(id)\n\tif err != nil {\n\t\treturn\n\t}\n\tif o.Path == \"0\" {\n\t\to.Path = \"/\"\n\t}\n\to.Path = path.Clean(o.Path)\n\tif !path.IsAbs(o.Path) {\n\t\terr = fmt.Errorf(\"bad ObjectID %v\", o.Path)\n\t\treturn\n\t}\n\treturn\n}\n\nfunc (cds *contentDirectoryService) Handle(action string, argsXML []byte, r *http.Request) (map[string]string, error) {\n\thost := r.Host\n\n\tswitch action {\n\tcase \"GetSystemUpdateID\":\n\t\treturn map[string]string{\n\t\t\t\"Id\": cds.updateIDString(),\n\t\t}, nil\n\tcase \"GetSortCapabilities\":\n\t\treturn map[string]string{\n\t\t\t\"SortCaps\": \"dc:title\",\n\t\t}, nil\n\tcase \"Browse\":\n\t\tvar browse browse\n\t\tif err := xml.Unmarshal(argsXML, &browse); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tobj, err := cds.objectFromID(browse.ObjectID)\n\t\tif err != nil {\n\t\t\treturn nil, upnp.Errorf(upnpav.NoSuchObjectErrorCode, err.Error())\n\t\t}\n\t\tswitch browse.BrowseFlag {\n\t\tcase \"BrowseDirectChildren\":\n\t\t\tobjs, err := cds.readContainer(obj, host)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, upnp.Errorf(upnpav.NoSuchObjectErrorCode, err.Error())\n\t\t\t}\n\t\t\ttotalMatches := len(objs)\n\t\t\tobjs = objs[func() (low int) {\n\t\t\t\tlow = browse.StartingIndex\n\t\t\t\tif low > len(objs) {\n\t\t\t\t\tlow = len(objs)\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}():]\n\t\t\tif browse.RequestedCount != 0 && browse.RequestedCount < len(objs) {\n\t\t\t\tobjs = objs[:browse.RequestedCount]\n\t\t\t}\n\t\t\tresult, err := xml.Marshal(objs)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\treturn map[string]string{\n\t\t\t\t\"TotalMatches\":   fmt.Sprint(totalMatches),\n\t\t\t\t\"NumberReturned\": fmt.Sprint(len(objs)),\n\t\t\t\t\"Result\":         didlLite(string(result)),\n\t\t\t\t\"UpdateID\":       cds.updateIDString(),\n\t\t\t}, nil\n\t\tcase \"BrowseMetadata\":\n\t\t\tresult, err := xml.Marshal(obj)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\treturn map[string]string{\n\t\t\t\t\"Result\": didlLite(string(result)),\n\t\t\t}, nil\n\t\tdefault:\n\t\t\treturn nil, upnp.Errorf(upnp.ArgumentValueInvalidErrorCode, \"unhandled browse flag: %v\", browse.BrowseFlag)\n\t\t}\n\tcase \"GetSearchCapabilities\":\n\t\treturn map[string]string{\n\t\t\t\"SearchCaps\": \"\",\n\t\t}, nil\n\t// Samsung Extensions\n\tcase \"X_GetFeatureList\":\n\t\treturn map[string]string{\n\t\t\t\"FeatureList\": `<Features xmlns=\"urn:schemas-upnp-org:av:avs\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"urn:schemas-upnp-org:av:avs http://www.upnp.org/schemas/av/avs.xsd\">\n\t<Feature name=\"samsung.com_BASICVIEW\" version=\"1\">\n\t\t<container id=\"/\" type=\"object.item.imageItem\"/>\n\t\t<container id=\"/\" type=\"object.item.audioItem\"/>\n\t\t<container id=\"/\" type=\"object.item.videoItem\"/>\n\t</Feature>\n</Features>`}, nil\n\tcase \"X_SetBookmark\":\n\t\t// just ignore\n\t\treturn map[string]string{}, nil\n\tdefault:\n\t\treturn nil, upnp.InvalidActionError\n\t}\n}\n\n// Represents a ContentDirectory object.\ntype object struct {\n\tPath string // The cleaned, absolute path for the object relative to the server.\n}\n\n// Returns the actual local filesystem path for the object.\nfunc (o *object) FilePath() string {\n\treturn filepath.FromSlash(o.Path)\n}\n\n// Returns the ObjectID for the object. This is used in various ContentDirectory actions.\nfunc (o object) ID() string {\n\tif !path.IsAbs(o.Path) {\n\t\tlog.Panicf(\"Relative object path: %s\", o.Path)\n\t}\n\tif len(o.Path) == 1 {\n\t\treturn \"0\"\n\t}\n\treturn url.QueryEscape(o.Path)\n}\n\nfunc (o *object) IsRoot() bool {\n\treturn o.Path == \"/\"\n}\n\n// Returns the object's parent ObjectID. Fortunately it can be deduced from the\n// ObjectID (for now).\nfunc (o object) ParentID() string {\n\tif o.IsRoot() {\n\t\treturn \"-1\"\n\t}\n\to.Path = path.Dir(o.Path)\n\treturn o.ID()\n}\n", "idx": 1, "id": 9421, "msg": "ineffectual assignment to `err` (from `ineffassign`)", "proj": "rclone-rclone", "lang": "go"}
{"patch": "@@ -125,10 +125,16 @@ func (a *ClusterIdentityAllocator) Run(stopCh <-chan struct{}) {\n \t}\n }\n \n+type ClusterIdentity struct {\n+\tUUID uuid.UUID\n+}\n+\n // ClusterIdentityProvider is an interface used to retrieve the cluster identity information (UUID),\n-// as provided by the user or generated by the Antrea Controller.\n+// as provided by the user or generated by the Antrea Controller. It also returns the time at which\n+// the antrea-cluster-identity was created, which can typically be considered as the time at which\n+// Antrea was deployed to the cluster.\n type ClusterIdentityProvider interface {\n-\tGet() (uuid.UUID, error)\n+\tGet() (ClusterIdentity, time.Time, error)\n }\n \n type clusterIdentityProvider struct {", "y": 1, "oldf": "// Copyright 2021 Antrea Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage clusteridentity\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"time\"\n\n\t\"github.com/google/uuid\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/apimachinery/pkg/util/wait\"\n\tclientset \"k8s.io/client-go/kubernetes\"\n\t\"k8s.io/klog\"\n)\n\nconst (\n\tDefaultClusterIdentityConfigMapName = \"antrea-cluster-identity\"\n\tuuidConfigMapKey                    = \"uuid\"\n)\n\n// ClusterIdentityAllocator ensures that the antrea-cluster-identity ConfigMap is populated\n// correctly, with a valid UUID. It is meant to be used by the Antrea Controller.\ntype ClusterIdentityAllocator struct {\n\tclusterIdentityConfigMapNamespace string\n\tclusterIdentityConfigMapName      string\n\tk8sClient                         clientset.Interface\n}\n\n// NewClusterIdentityAllocator creates a ClusterIdentityAllocator object\nfunc NewClusterIdentityAllocator(\n\tclusterIdentityConfigMapNamespace string,\n\tclusterIdentityConfigMapName string,\n\tk8sClient clientset.Interface,\n) *ClusterIdentityAllocator {\n\treturn &ClusterIdentityAllocator{\n\t\tclusterIdentityConfigMapNamespace: clusterIdentityConfigMapNamespace,\n\t\tclusterIdentityConfigMapName:      clusterIdentityConfigMapName,\n\t\tk8sClient:                         k8sClient,\n\t}\n}\n\nfunc (a *ClusterIdentityAllocator) updateConfigMapIfNeeded() error {\n\tconfigMap, err := a.k8sClient.CoreV1().ConfigMaps(a.clusterIdentityConfigMapNamespace).Get(context.TODO(), a.clusterIdentityConfigMapName, metav1.GetOptions{})\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error when getting '%s/%s' ConfigMap: %v\", a.clusterIdentityConfigMapNamespace, a.clusterIdentityConfigMapName, err)\n\t}\n\n\t// returns a triplet consisting of the cluster UUID, a boolean indicating if the UUID needs\n\t// to be written to the ConfigMap, and an error if applicable\n\tinspectUUID := func() (uuid.UUID, bool, error) {\n\t\tclusterUUIDStr, ok := configMap.Data[uuidConfigMapKey]\n\t\tif ok && clusterUUIDStr != \"\" {\n\t\t\tclusterUUID, err := uuid.Parse(clusterUUIDStr)\n\t\t\tif err != nil {\n\t\t\t\treturn uuid.Nil, false, fmt.Errorf(\"cluster already has UUID '%s' but it is not valid: %v\", clusterUUIDStr, err)\n\t\t\t}\n\t\t\treturn clusterUUID, false, nil\n\t\t}\n\n\t\t// generate a new random UUID\n\t\tclusterUUID := uuid.New()\n\n\t\treturn clusterUUID, true, nil\n\t}\n\n\tclusterUUID, clusterUUIDNeedsUpdate, err := inspectUUID()\n\tif err != nil {\n\t\treturn err\n\t}\n\tif !clusterUUIDNeedsUpdate {\n\t\tklog.Infof(\"Existing cluster UUID: %v\", clusterUUID)\n\t\treturn nil\n\t}\n\n\tconfigMap.Data = map[string]string{\n\t\tuuidConfigMapKey: clusterUUID.String(),\n\t}\n\tif _, err := a.k8sClient.CoreV1().ConfigMaps(a.clusterIdentityConfigMapNamespace).Update(context.TODO(), configMap, metav1.UpdateOptions{}); err != nil {\n\t\treturn fmt.Errorf(\"error when updating '%s/%s' ConfigMap with new cluster identity: %v\", a.clusterIdentityConfigMapNamespace, a.clusterIdentityConfigMapName, err)\n\t}\n\tklog.Infof(\"New cluster UUID: %v\", clusterUUID)\n\treturn nil\n}\n\n// Run will ensure that the antrea-cluster-identity ConfigMap is up-to-date. It is meant to be\n// called asynchronously in its own goroutine, and will keep retrying in case of error, using an\n// exponential backoff mechanism.\nfunc (a *ClusterIdentityAllocator) Run(stopCh <-chan struct{}) {\n\t// Exponential backoff, starting at 100ms with a factor of 2. A \"steps\" value of 8 means we\n\t// will increase the backoff duration at most 8 times, so the max duration is (100ms * //\n\t// 2^8), which is about 25s.\n\tretry := wait.Backoff{\n\t\tSteps:    8,\n\t\tDuration: 100 * time.Millisecond,\n\t\tFactor:   2.0,\n\t\tJitter:   0.0,\n\t}\n\n\tfor {\n\t\terr := a.updateConfigMapIfNeeded()\n\t\tif err == nil {\n\t\t\treturn\n\t\t}\n\t\tsleepDuration := retry.Step()\n\t\tklog.Errorf(\"Cannot validate or update cluster UUID because of the following error, will retry in %v: %v\", sleepDuration, err)\n\t\tselect {\n\t\tcase <-stopCh:\n\t\t\treturn\n\t\tcase <-time.After(sleepDuration):\n\t\t\tcontinue\n\t\t}\n\t}\n}\n\n// ClusterIdentityProvider is an interface used to retrieve the cluster identity information (UUID),\n// as provided by the user or generated by the Antrea Controller.\ntype ClusterIdentityProvider interface {\n\tGet() (uuid.UUID, error)\n}\n\ntype clusterIdentityProvider struct {\n\tclusterIdentityConfigMapNamespace string\n\tclusterIdentityConfigMapName      string\n\tk8sClient                         clientset.Interface\n}\n\n// NewClusterIdentityProvider returns a new object implementing the ClusterIdentityProvider\n// interface.\nfunc NewClusterIdentityProvider(\n\tclusterIdentityConfigMapNamespace string,\n\tclusterIdentityConfigMapName string,\n\tk8sClient clientset.Interface,\n) *clusterIdentityProvider {\n\treturn &clusterIdentityProvider{\n\t\tclusterIdentityConfigMapNamespace: clusterIdentityConfigMapNamespace,\n\t\tclusterIdentityConfigMapName:      clusterIdentityConfigMapName,\n\t\tk8sClient:                         k8sClient,\n\t}\n}\n\n// Get will retrieve the cluster identity (UUID) stored in the antrea-cluster-identity ConfigMap. In\n// case of error, clients are invited to retry as the information may not be available yet.\nfunc (p *clusterIdentityProvider) Get() (uuid.UUID, error) {\n\tconfigMap, err := p.k8sClient.CoreV1().ConfigMaps(p.clusterIdentityConfigMapNamespace).Get(context.TODO(), p.clusterIdentityConfigMapName, metav1.GetOptions{})\n\tif err != nil {\n\t\treturn uuid.Nil, fmt.Errorf(\"error when getting '%s/%s' ConfigMap: %v\", p.clusterIdentityConfigMapNamespace, p.clusterIdentityConfigMapName, err)\n\t}\n\n\tgetUUID := func() (uuid.UUID, error) {\n\t\tclusterUUIDStr, ok := configMap.Data[uuidConfigMapKey]\n\t\tif !ok || clusterUUIDStr == \"\" {\n\t\t\treturn uuid.Nil, fmt.Errorf(\"cluster UUID has not been set yet\")\n\t\t}\n\t\tclusterUUID, err := uuid.Parse(clusterUUIDStr)\n\t\tif err != nil {\n\t\t\treturn uuid.Nil, fmt.Errorf(\"cluster UUID cannot be parsed\")\n\t\t}\n\t\treturn clusterUUID, nil\n\t}\n\n\treturn getUUID()\n}\n", "idx": 1, "id": 34102, "msg": "out of curiosity, why creating another struct to wrap it?", "proj": "antrea-io-antrea", "lang": "go"}
{"patch": "@@ -162,8 +162,10 @@ namespace pwiz.Skyline.Model.Lib\n                 var thatPeptideKey = thatItem.LibraryKey as PeptideLibraryKey;\n                 if (thatPeptideKey == null)\n                 {\n-                    result.Add(thatItem.LibraryKey);\n-                    nonPeptideKeySet.Add(thatItem.LibraryKey);\n+                    if (nonPeptideKeySet.Add(thatItem.LibraryKey))\n+                    {\n+                        result.Add(thatItem.LibraryKey); // First time we've seen it, add to list\n+                    }\n                     continue;\n                 }\n                 PeptideLibraryKey[] thisKeysWithUnmodSeq;", "y": 1, "oldf": "\ufeff/*\r\n * Original author: Nicholas Shulman <nicksh .at. u.washington.edu>,\r\n *                  MacCoss Lab, Department of Genome Sciences, UW\r\n *\r\n * Copyright 2017 University of Washington - Seattle, WA\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *     http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n\r\nusing System.Collections;\r\nusing System.Collections.Generic;\r\nusing System.Linq;\r\nusing System.Text;\r\nusing JetBrains.Annotations;\r\nusing pwiz.Common.Collections;\r\nusing pwiz.Skyline.Util;\r\n\r\nnamespace pwiz.Skyline.Model.Lib\r\n{\r\n    public class LibKeyIndex : AbstractReadOnlyCollection<LibKeyIndex.IndexItem>\r\n    {\r\n        private readonly ImmutableList<ISubIndex> _subIndexes;\r\n\r\n        public LibKeyIndex(IEnumerable<IndexItem> items)\r\n        {\r\n            var allItems = items.ToArray();\r\n            _subIndexes = ImmutableList.ValueOf(new ISubIndex[]\r\n            {\r\n                new PeptideSubIndex(allItems),\r\n                new MoleculeSubIndex(allItems),\r\n                new PrecursorSubIndex(allItems)\r\n            });\r\n            Count = _subIndexes.Sum(index => index.Count);\r\n        }\r\n\r\n        public LibKeyIndex(IEnumerable<LibraryKey> keys) \r\n            : this(keys.Select((key, index) => new IndexItem(key, index)))\r\n        {\r\n        }\r\n\r\n        public override IEnumerator<IndexItem> GetEnumerator()\r\n        {\r\n            return _subIndexes.SelectMany(index => index).GetEnumerator();\r\n        }\r\n\r\n        public override int Count { get; }\r\n\r\n        public IndexItem? Find(LibraryKey libraryKey)\r\n        {\r\n            return _subIndexes.SelectMany(index => index.ItemsEqualTo(libraryKey)).FirstOrDefault();\r\n        }\r\n\r\n        public IEnumerable<IndexItem> ItemsMatching(LibraryKey libraryKey, bool matchAdductAlso)\r\n        {\r\n            return _subIndexes.SelectMany(index => index.ItemsMatching(libraryKey, matchAdductAlso));\r\n        }\r\n\r\n        public IEnumerable<IndexItem> ItemsWithUnmodifiedSequence(LibraryKey libraryKey)\r\n        {\r\n            return _subIndexes.SelectMany(index => index.ItemsMatchingWithoutModifications(libraryKey));\r\n        }\r\n\r\n        public struct IndexItem\r\n        {\r\n            public static IEnumerable<IndexItem> NONE =\r\n                ImmutableList<IndexItem>.EMPTY;\r\n\r\n            public IndexItem(LibraryKey libraryKey, int originalIndex) : this()\r\n            {\r\n                LibraryKey = libraryKey;\r\n                OriginalIndex = originalIndex;\r\n            }\r\n\r\n            public LibraryKey LibraryKey { get; private set; }\r\n            public int OriginalIndex { get; private set; }\r\n        }\r\n\r\n\r\n        public static bool ModificationsMatch(string strMod1, string strMod2)\r\n        {\r\n            if (strMod1 == strMod2)\r\n            {\r\n                return true;\r\n            }\r\n            var massMod1 = MassModification.Parse(strMod1);\r\n            var massMod2 = MassModification.Parse(strMod2);\r\n            if (massMod1 == null || massMod2 == null)\r\n            {\r\n                return false;\r\n            }\r\n            return massMod1.Matches(massMod2);\r\n        }\r\n\r\n        public static bool KeysMatch(LibraryKey key1, LibraryKey key2)\r\n        {\r\n            if (Equals(key1, key2))\r\n            {\r\n                return true;\r\n            }\r\n            if (!Equals(key1.Adduct, key2.Adduct))\r\n            {\r\n                return false;\r\n            }\r\n            var peptideKey1 = key1 as PeptideLibraryKey;\r\n            var peptideKey2 = key2 as PeptideLibraryKey;\r\n            if (peptideKey1 == null || peptideKey2 == null)\r\n            {\r\n                return false;\r\n            }\r\n            if (!Equals(peptideKey1.UnmodifiedSequence, peptideKey2.UnmodifiedSequence))\r\n            {\r\n                return false;\r\n            }\r\n            var mods1 = peptideKey1.GetModifications();\r\n            var mods2 = peptideKey2.GetModifications();\r\n            if (mods1.Count != mods2.Count)\r\n            {\r\n                return false;\r\n            }\r\n            if (!mods1.Select(mod => mod.Key).SequenceEqual(mods2.Select(mod => mod.Key)))\r\n            {\r\n                return false;\r\n            }\r\n\r\n            for (int i = 0; i < mods1.Count; i++)\r\n            {\r\n                if (!ModificationsMatch(mods1[i].Value, mods2[i].Value))\r\n                {\r\n                    return false;\r\n                }\r\n            }\r\n            return true;\r\n        }\r\n\r\n\r\n\r\n        /// <summary>\r\n        /// Return a set of library keys that are the most general of the ones found in this and that,\r\n        /// and which covers all of the keys.\r\n        /// <see cref=\"MostGeneralPeptideKey\" />\r\n        /// </summary>\r\n        public IList<LibraryKey> MergeKeys(LibKeyIndex that)\r\n        {\r\n            var keysByUnmodifiedSequence = this.Select(item => item.LibraryKey)\r\n                .OfType<PeptideLibraryKey>()\r\n                .ToLookup(key => key.UnmodifiedSequence)\r\n                .ToDictionary(grouping => grouping.Key, grouping => grouping.ToArray());\r\n            var result = new List<LibraryKey>();\r\n            var nonPeptideKeySet = new HashSet<LibraryKey>();\r\n            foreach (var thatItem in that)\r\n            {\r\n                var thatPeptideKey = thatItem.LibraryKey as PeptideLibraryKey;\r\n                if (thatPeptideKey == null)\r\n                {\r\n                    result.Add(thatItem.LibraryKey);\r\n                    nonPeptideKeySet.Add(thatItem.LibraryKey);\r\n                    continue;\r\n                }\r\n                PeptideLibraryKey[] thisKeysWithUnmodSeq;\r\n                if (!keysByUnmodifiedSequence.TryGetValue(thatPeptideKey.UnmodifiedSequence, out thisKeysWithUnmodSeq))\r\n                {\r\n                    result.Add(thatPeptideKey);\r\n                    continue;\r\n                }\r\n                keysByUnmodifiedSequence[thatPeptideKey.UnmodifiedSequence] =\r\n                    MergePeptideLibraryKey(thisKeysWithUnmodSeq, thatPeptideKey).ToArray();\r\n            }\r\n            result.AddRange(this.Select(item => item.LibraryKey)\r\n                .Where(key => !(key is PeptideLibraryKey) && !nonPeptideKeySet.Contains(key)));\r\n            result.AddRange(keysByUnmodifiedSequence.SelectMany(entry => entry.Value));\r\n            return result;\r\n        }\r\n\r\n        private IEnumerable<PeptideLibraryKey> MergePeptideLibraryKey(ICollection<PeptideLibraryKey> thisKeys,\r\n            PeptideLibraryKey thatKey)\r\n        {\r\n            while (true)\r\n            {\r\n                PeptideLibraryKey mostGeneralKey = thatKey;\r\n                foreach (var thisKey in thisKeys)\r\n                {\r\n                    if (KeysMatch(thisKey, mostGeneralKey))\r\n                    {\r\n                        mostGeneralKey = MostGeneralPeptideKey(thisKey, mostGeneralKey);\r\n                    }\r\n                }\r\n                if (Equals(mostGeneralKey, thatKey))\r\n                {\r\n                    break;\r\n                }\r\n                thatKey = mostGeneralKey;\r\n            }\r\n            return new[] {thatKey}.Concat(thisKeys.Where(key => !KeysMatch(thatKey, key)));\r\n        }\r\n\r\n        /// <summary>\r\n        /// Given two keys that match each other (i.e. the modification masses are within the other's margin of error)\r\n        /// return a key which has the lower precision of the two.\r\n        /// For instance, if one key is C[+57.021464]PEPTIDER[+10] and the is C[+57.02]PEPTIDEK[10.0083],\r\n        /// the result be C[+57.02]PEPTIDER[+10].\r\n        /// </summary>\r\n        private PeptideLibraryKey MostGeneralPeptideKey(PeptideLibraryKey key1, PeptideLibraryKey key2)\r\n        {\r\n            Assume.AreEqual(key1.UnmodifiedSequence, key2.UnmodifiedSequence);\r\n            var mods1 = key1.GetModifications();\r\n            var mods2 = key2.GetModifications();\r\n            Assume.AreEqual(mods1.Count, mods2.Count);\r\n            var newMods = new List<KeyValuePair<int, string>>(mods1.Count);\r\n            for (int i = 0; i < mods1.Count; i++)\r\n            {\r\n                var mod1 = mods1[i];\r\n                var mod2 = mods2[i];\r\n                Assume.AreEqual(mod1.Key, mod2.Key);\r\n                if (mod1.Value == mod2.Value)\r\n                {\r\n                    newMods.Add(mod1);\r\n                    continue;\r\n                }\r\n                MassModification massMod1 = MassModification.Parse(mod1.Value);\r\n                MassModification massMod2 = MassModification.Parse(mod2.Value);\r\n                if (massMod1.Precision <= massMod2.Precision)\r\n                {\r\n                    newMods.Add(mod1);\r\n                }\r\n                else\r\n                {\r\n                    newMods.Add(mod2);\r\n                }\r\n            }\r\n            return new PeptideLibraryKey(MakeModifiedSequence(key1.UnmodifiedSequence, newMods), key1.Charge);\r\n        }\r\n\r\n        private string MakeModifiedSequence(string unmodifiedSequence,\r\n            IEnumerable<KeyValuePair<int, string>> modifications)\r\n        {\r\n            StringBuilder modifiedSequence = new StringBuilder();\r\n            int ichUnmodified = 0;\r\n            foreach (var modification in modifications)\r\n            {\r\n                Assume.IsTrue(modification.Key >= ichUnmodified);\r\n                modifiedSequence.Append(unmodifiedSequence.Substring(ichUnmodified,\r\n                    modification.Key - ichUnmodified + 1));\r\n                ichUnmodified = modification.Key + 1;\r\n                modifiedSequence.Append(ModifiedSequence.Bracket(modification.Value));\r\n            }\r\n            modifiedSequence.Append(unmodifiedSequence.Substring(ichUnmodified));\r\n            return modifiedSequence.ToString();\r\n        }\r\n\r\n        private interface ISubIndex : IEnumerable<IndexItem>\r\n        {\r\n            int Count { get; }\r\n            /// <summary>\r\n            /// Returns the set of items whose LibraryKey is exactly equal to the requested key.\r\n            /// </summary>\r\n            IEnumerable<IndexItem> ItemsEqualTo(LibraryKey libraryKey);\r\n            /// <summary>\r\n            /// Returns the set of items whose LibraryKey matches, using the fuzzy logic specific to\r\n            /// the type of library key.\r\n            /// </summary>\r\n            IEnumerable<IndexItem> ItemsMatching(LibraryKey libraryKey, bool matchAdductAlso);\r\n            /// <summary>\r\n            /// For peptides, returns the set of items whose UnmodifiedSequence match, otherwise\r\n            /// returns the same as ItemsMatching(libraryKey, false).\r\n            /// </summary>\r\n            IEnumerable<IndexItem> ItemsMatchingWithoutModifications(LibraryKey libraryKey);\r\n        }\r\n\r\n        private abstract class SubIndex<TKey> : ISubIndex where TKey : LibraryKey\r\n        {\r\n            public int Count { get; protected set; }\r\n            IEnumerator IEnumerable.GetEnumerator()\r\n            {\r\n                return GetEnumerator();\r\n            }\r\n\r\n            public abstract IEnumerator<IndexItem> GetEnumerator();\r\n            public IEnumerable<IndexItem> ItemsEqualTo(LibraryKey libraryKey)\r\n            {\r\n                var key = libraryKey as TKey;\r\n                if (key == null)\r\n                {\r\n                    return IndexItem.NONE;\r\n                }\r\n                return ExactMatches(key);\r\n            }\r\n\r\n            protected virtual IEnumerable<IndexItem> ExactMatches(TKey key)\r\n            {\r\n                return ItemsMatching(key, false).Where(indexItem => Equals(key, indexItem.LibraryKey));\r\n\r\n            }\r\n\r\n            public IEnumerable<IndexItem> ItemsMatching(LibraryKey libraryKey, bool matchAdductAlso)\r\n            {\r\n                var key = libraryKey as TKey;\r\n                if (key == null)\r\n                {\r\n                    return IndexItem.NONE;\r\n                }\r\n                var matches = ItemsMatching(key);\r\n                return matchAdductAlso ? matches.Where(item => Equals(item.LibraryKey.Adduct, libraryKey.Adduct)) : matches;\r\n            }\r\n\r\n            protected abstract IEnumerable<IndexItem> ItemsMatching(TKey key);\r\n            public IEnumerable<IndexItem> ItemsMatchingWithoutModifications(LibraryKey libraryKey)\r\n            {\r\n                var key = libraryKey as TKey;\r\n                if (key == null)\r\n                {\r\n                    return IndexItem.NONE;\r\n                }\r\n                return ItemsMatchingWithoutModifications(key);\r\n            }\r\n\r\n            protected virtual IEnumerable<IndexItem> ItemsMatchingWithoutModifications(TKey key)\r\n            {\r\n                return ItemsMatching(key);\r\n            }\r\n        }\r\n\r\n        /// <summary>\r\n        /// Holds the set of peptides in the LibKeyIndex. This maintains a Dictionary from\r\n        /// unmodified sequence to the keys.\r\n        /// For any particular unmodified sequence, the keys are sorted by the modification indexes \r\n        /// (the amino acid locations that are modified). The fuzzy modification comparison only\r\n        /// has to compare pepties that have modifications in the same locations.\r\n        /// </summary>\r\n        private class PeptideSubIndex : SubIndex<PeptideLibraryKey>\r\n        {\r\n            private readonly IDictionary<string, ImmutableList<PeptideEntry>> _entries;\r\n            public PeptideSubIndex(IEnumerable<IndexItem> items)\r\n            {\r\n                _entries = new Dictionary<string, ImmutableList<PeptideEntry>>();\r\n                var singletonIndexes = new Dictionary<int, ImmutableList<int>>();\r\n                var indexes = new Dictionary<ImmutableList<int>, ImmutableList<int>>();\r\n                var modIndexComparer = Comparer<IList<int>>.Create(CompareModificationIndexes);\r\n                foreach (var group in items.Where(item=>item.LibraryKey is PeptideLibraryKey)\r\n                    .ToLookup(item => ((PeptideLibraryKey) item.LibraryKey).UnmodifiedSequence))\r\n                {\r\n                    _entries.Add(group.Key, ImmutableList.ValueOf(group\r\n                        .Select(item => PeptideEntry.NewInstance(singletonIndexes, indexes, item))\r\n                        .OrderBy(entry => entry.ModificationIndexes, modIndexComparer)));\r\n                }\r\n                Count = _entries.Values.Sum(list => list.Count);\r\n            }\r\n\r\n            public override IEnumerator<IndexItem> GetEnumerator()\r\n            {\r\n                return _entries.Values.SelectMany(list => list.Select(entry => entry.IndexItem)).GetEnumerator();\r\n            }\r\n\r\n            protected override IEnumerable<IndexItem> ItemsMatching(PeptideLibraryKey libraryKey)\r\n            {\r\n                var matchingEntries = ModificationIndexMatches(libraryKey, out var modifications);\r\n                if (modifications != null && modifications.Count != 0)\r\n                {\r\n                    matchingEntries = matchingEntries.Where(item =>\r\n                        ModificationListsMatch(item.ModificationNames, modifications.Select(mod => mod.Value)));\r\n                }\r\n                return matchingEntries.Select(item => item.IndexItem);\r\n            }\r\n\r\n            private static bool ModificationListsMatch(IEnumerable<string> list1, IEnumerable<string> list2)\r\n            {\r\n                return !list1.Zip(list2, ModificationsMatch).Contains(false);\r\n            }\r\n\r\n            /// <summary>\r\n            /// Returns the set of entries with modifications on the same amino acids.\r\n            /// </summary>\r\n            private IEnumerable<PeptideEntry> ModificationIndexMatches(PeptideLibraryKey peptideLibraryKey,\r\n                [CanBeNull] out IList<KeyValuePair<int, string>> modifications)\r\n            {\r\n                modifications = null;\r\n                ImmutableList<PeptideEntry> entries;\r\n                if (!_entries.TryGetValue(peptideLibraryKey.UnmodifiedSequence, out entries))\r\n                {\r\n                    return ImmutableList<PeptideEntry>.EMPTY;\r\n                }\r\n                modifications = peptideLibraryKey.GetModifications();\r\n\r\n                var peptideEntry = new PeptideEntry(new IndexItem(peptideLibraryKey, -1), modifications);\r\n                var range = CollectionUtil.BinarySearch(entries, item => item.CompareModIndexes(peptideEntry));\r\n                return Enumerable.Range(range.Start, range.Length)\r\n                    .Select(index => entries[index]);\r\n            }\r\n\r\n            protected override IEnumerable<IndexItem> ExactMatches(PeptideLibraryKey libraryKey)\r\n            {\r\n                return ModificationIndexMatches(libraryKey, out _)\r\n                    .Where(entry => Equals(libraryKey, entry.PeptideLibraryKey))\r\n                    .Select(entry => entry.IndexItem);\r\n            }\r\n\r\n            protected override IEnumerable<IndexItem> ItemsMatchingWithoutModifications(PeptideLibraryKey libraryKey)\r\n            {\r\n                ImmutableList<PeptideEntry> entries;\r\n                if (!_entries.TryGetValue(libraryKey.UnmodifiedSequence, out entries))\r\n                {\r\n                    return IndexItem.NONE;\r\n                }\r\n                return entries.Select(entry=>entry.IndexItem);\r\n            }\r\n\r\n            public struct PeptideEntry\r\n            {\r\n                public PeptideEntry(IndexItem indexItem, IList<KeyValuePair<int, string>> modifications)\r\n                {\r\n                    IndexItem = indexItem;\r\n                    ModificationIndexes = ImmutableList.ValueOf(modifications.Select(mod => mod.Key));\r\n                }\r\n\r\n                public PeptideLibraryKey PeptideLibraryKey\r\n                {\r\n                    get { return (PeptideLibraryKey) IndexItem.LibraryKey; }\r\n                }\r\n\r\n                [NotNull]\r\n                public ImmutableList<int> ModificationIndexes { get; private set; }\r\n\r\n                public IEnumerable<string> ModificationNames\r\n                {\r\n                    get\r\n                    {\r\n                        return PeptideLibraryKey.GetModifications().Select(mod => mod.Value);\r\n                    }\r\n                }\r\n\r\n                public IndexItem IndexItem { get; private set; }\r\n\r\n                public int CompareModIndexes(PeptideEntry that)\r\n                {\r\n                    return CompareModificationIndexes(ModificationIndexes, that.ModificationIndexes);\r\n                }\r\n\r\n                /// <summary>\r\n                /// Constructs a new PeptideEntry, and reuses ImmutableList values from the \r\n                /// passed in dictionaries to prevent redundant object creation.\r\n                /// </summary>\r\n                public static PeptideEntry NewInstance(IDictionary<int, ImmutableList<int>> singletonIndexCache,\r\n                    IDictionary<ImmutableList<int>, ImmutableList<int>> indexCache, IndexItem indexItem)\r\n                {\r\n                    var peptideEntry = new PeptideEntry(indexItem,\r\n                        ((PeptideLibraryKey)indexItem.LibraryKey).GetModifications());\r\n                    if (peptideEntry.ModificationIndexes.Count == 0)\r\n                    {\r\n                        return peptideEntry;\r\n                    }\r\n                    ImmutableList<int> newIndexes;\r\n                    if (peptideEntry.ModificationIndexes.Count == 1)\r\n                    {\r\n                        if (singletonIndexCache.TryGetValue(peptideEntry.ModificationIndexes[0], out newIndexes))\r\n                        {\r\n                            peptideEntry.ModificationIndexes = newIndexes;\r\n                        }\r\n                        else\r\n                        {\r\n                            singletonIndexCache.Add(peptideEntry.ModificationIndexes[0], peptideEntry.ModificationIndexes);\r\n                        }\r\n                    }\r\n                    else\r\n                    {\r\n                        if (indexCache.TryGetValue(peptideEntry.ModificationIndexes, out newIndexes))\r\n                        {\r\n                            peptideEntry.ModificationIndexes = newIndexes;\r\n                        }\r\n                        else\r\n                        {\r\n                            indexCache.Add(peptideEntry.ModificationIndexes, peptideEntry.ModificationIndexes);\r\n                        }\r\n                    }\r\n                    return peptideEntry;\r\n                }\r\n            }\r\n\r\n            private static int CompareModificationIndexes(IList<int> list1, IList<int> list2)\r\n            {\r\n                int count1 = list1.Count;\r\n                int count2 = list2.Count;\r\n                int result = count1.CompareTo(count2);\r\n                if (result != 0)\r\n                {\r\n                    return result;\r\n                }\r\n                for (int i = 0; i < count1; i++)\r\n                {\r\n                    result = list1[i].CompareTo(list2[i]);\r\n                    if (result != 0)\r\n                    {\r\n                        return result;\r\n                    }\r\n                }\r\n                return result;\r\n            }\r\n        }\r\n\r\n        private class MoleculeSubIndex : SubIndex<MoleculeLibraryKey>\r\n        {\r\n            private readonly ILookup<string, IndexItem> _entries;\r\n\r\n            public MoleculeSubIndex(IEnumerable<IndexItem> indexItems)\r\n            {\r\n                _entries = indexItems.Where(indexItem => indexItem.LibraryKey is MoleculeLibraryKey)\r\n                    .ToLookup(item => ((MoleculeLibraryKey) item.LibraryKey).PreferredKey);\r\n                Count = _entries.Sum(entry => entry.Count());\r\n            }\r\n\r\n            public override IEnumerator<IndexItem> GetEnumerator()\r\n            {\r\n                return _entries.SelectMany(entry => entry).GetEnumerator();\r\n            }\r\n\r\n            protected override IEnumerable<IndexItem> ItemsMatching(MoleculeLibraryKey libraryKey)\r\n            {\r\n                return _entries[libraryKey.PreferredKey];\r\n            }\r\n        }\r\n\r\n        private class PrecursorSubIndex : SubIndex<PrecursorLibraryKey>\r\n        {\r\n            private readonly ILookup<double, IndexItem> _entries;\r\n\r\n            public PrecursorSubIndex(IEnumerable<IndexItem> indexItems)\r\n            {\r\n                _entries = indexItems.Where(item => item.LibraryKey is PrecursorLibraryKey)\r\n                    .ToLookup(item => ((PrecursorLibraryKey) item.LibraryKey).Mz);\r\n                Count = _entries.Sum(group => group.Count());\r\n            }\r\n\r\n            public override IEnumerator<IndexItem> GetEnumerator()\r\n            {\r\n                return _entries.SelectMany(group => group).GetEnumerator();\r\n            }\r\n\r\n            protected override IEnumerable<IndexItem> ItemsMatching(PrecursorLibraryKey libraryKey)\r\n            {\r\n                return _entries[libraryKey.Mz];\r\n            }\r\n        }\r\n    }\r\n}\r\n\r\n", "idx": 1, "id": 12582, "msg": "Is this necessary? Are there duplicates in your LibKeyIndex?", "proj": "ProteoWizard-pwiz", "lang": ".cs"}
{"patch": "@@ -30,6 +30,13 @@ func VerifyTrustDomainMemberID(td spiffeid.TrustDomain, id spiffeid.ID) error {\n \treturn nil\n }\n \n+func VerifySameTrustDomain(td spiffeid.TrustDomain, id spiffeid.ID) error {\n+\tif !id.MemberOf(td) {\n+\t\treturn fmt.Errorf(\"%q is not a member of trust domain %q\", id, td)\n+\t}\n+\treturn nil\n+}\n+\n func TrustDomainAgentIDFromProto(td spiffeid.TrustDomain, protoID *types.SPIFFEID) (spiffeid.ID, error) {\n \tid, err := idFromProto(protoID)\n \tif err != nil {", "y": 1, "oldf": "package api\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\n\t\"github.com/spiffe/go-spiffe/v2/spiffeid\"\n\t\"github.com/spiffe/spire/pkg/common/idutil\"\n\t\"github.com/spiffe/spire/proto/spire/types\"\n)\n\nfunc TrustDomainMemberIDFromProto(td spiffeid.TrustDomain, protoID *types.SPIFFEID) (spiffeid.ID, error) {\n\tid, err := idFromProto(protoID)\n\tif err != nil {\n\t\treturn spiffeid.ID{}, err\n\t}\n\tif err := VerifyTrustDomainMemberID(td, id); err != nil {\n\t\treturn spiffeid.ID{}, err\n\t}\n\treturn id, nil\n}\n\nfunc VerifyTrustDomainMemberID(td spiffeid.TrustDomain, id spiffeid.ID) error {\n\tif !id.MemberOf(td) {\n\t\treturn fmt.Errorf(\"%q is not a member of trust domain %q\", id, td)\n\t}\n\tif id.Path() == \"\" {\n\t\treturn fmt.Errorf(\"%q is not a member of trust domain %q; path is empty\", id, td)\n\t}\n\treturn nil\n}\n\nfunc TrustDomainAgentIDFromProto(td spiffeid.TrustDomain, protoID *types.SPIFFEID) (spiffeid.ID, error) {\n\tid, err := idFromProto(protoID)\n\tif err != nil {\n\t\treturn spiffeid.ID{}, err\n\t}\n\tif err := VerifyTrustDomainAgentID(td, id); err != nil {\n\t\treturn spiffeid.ID{}, err\n\t}\n\treturn id, nil\n}\n\nfunc VerifyTrustDomainAgentID(td spiffeid.TrustDomain, id spiffeid.ID) error {\n\tif !id.MemberOf(td) {\n\t\treturn fmt.Errorf(\"%q is not a member of trust domain %q\", id, td)\n\t}\n\tif id.Path() == \"\" {\n\t\treturn fmt.Errorf(\"%q is not an agent in trust domain %q; path is empty\", id, td)\n\t}\n\tif !idutil.IsAgentPath(id.Path()) {\n\t\treturn fmt.Errorf(\"%q is not an agent in trust domain %q; path is not in the agent namespace\", id, td)\n\t}\n\treturn nil\n}\n\nfunc TrustDomainWorkloadIDFromProto(td spiffeid.TrustDomain, protoID *types.SPIFFEID) (spiffeid.ID, error) {\n\tid, err := idFromProto(protoID)\n\tif err != nil {\n\t\treturn spiffeid.ID{}, err\n\t}\n\tif err := VerifyTrustDomainWorkloadID(td, id); err != nil {\n\t\treturn spiffeid.ID{}, err\n\t}\n\treturn id, nil\n}\n\nfunc VerifyTrustDomainWorkloadID(td spiffeid.TrustDomain, id spiffeid.ID) error {\n\tif !id.MemberOf(td) {\n\t\treturn fmt.Errorf(\"%q is not a member of trust domain %q\", id, td)\n\t}\n\tif id.Path() == \"\" {\n\t\treturn fmt.Errorf(\"%q is not a workload in trust domain %q; path is empty\", id, td)\n\t}\n\tif idutil.IsReservedPath(id.Path()) {\n\t\treturn fmt.Errorf(\"%q is not a workload in trust domain %q; path is in the reserved namespace\", id, td)\n\t}\n\treturn nil\n}\n\n// ProtoFromID converts a SPIFFE ID from the given spiffeid.ID to\n// types.SPIFFEID\nfunc ProtoFromID(id spiffeid.ID) *types.SPIFFEID {\n\treturn &types.SPIFFEID{\n\t\tTrustDomain: id.TrustDomain().String(),\n\t\tPath:        id.Path(),\n\t}\n}\n\nfunc idFromProto(protoID *types.SPIFFEID) (spiffeid.ID, error) {\n\tif protoID == nil {\n\t\treturn spiffeid.ID{}, errors.New(\"request must specify SPIFFE ID\")\n\t}\n\treturn spiffeid.New(protoID.TrustDomain, protoID.Path)\n}\n", "idx": 1, "id": 15120, "msg": "This seems to only be used by the server/ca package.... maybe this can live there instead of being lumped into these API implementation helpers?", "proj": "spiffe-spire", "lang": "go"}
{"patch": "@@ -65,6 +65,14 @@ public final class MethodCallExpr extends Expression implements NodeWithTypeArgu\n         this(null, scope, new NodeList<>(), new SimpleName(name), new NodeList<>());\n     }\n \n+    public MethodCallExpr(final Expression scope, final SimpleName name) {\n+        this(null, scope, new NodeList<>(), name, new NodeList<>());\n+    }\n+\n+    public MethodCallExpr(final Expression scope, final String name, final NodeList<Expression> arguments) {\n+        this(null, scope, new NodeList<>(), new SimpleName(name), arguments);\n+    }\n+\n     public MethodCallExpr(final Expression scope, final SimpleName name, final NodeList<Expression> arguments) {\n         this(null, scope, new NodeList<>(), name, arguments);\n     }", "y": 1, "oldf": "/*\n * Copyright (C) 2007-2010 J\u00falio Vilmar Gesser.\n * Copyright (C) 2011, 2013-2016 The JavaParser Team.\n *\n * This file is part of JavaParser.\n *\n * JavaParser can be used either under the terms of\n * a) the GNU Lesser General Public License as published by\n *     the Free Software Foundation, either version 3 of the License, or\n *     (at your option) any later version.\n * b) the terms of the Apache License\n *\n * You should have received a copy of both licenses in LICENCE.LGPL and\n * LICENCE.APACHE. Please refer to those files for details.\n *\n * JavaParser is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU Lesser General Public License for more details.\n */\npackage com.github.javaparser.ast.expr;\n\nimport com.github.javaparser.Range;\nimport com.github.javaparser.ast.AllFieldsConstructor;\nimport com.github.javaparser.ast.NodeList;\nimport com.github.javaparser.ast.nodeTypes.NodeWithArguments;\nimport com.github.javaparser.ast.nodeTypes.NodeWithOptionalScope;\nimport com.github.javaparser.ast.nodeTypes.NodeWithSimpleName;\nimport com.github.javaparser.ast.nodeTypes.NodeWithTypeArguments;\nimport com.github.javaparser.ast.observer.ObservableProperty;\nimport com.github.javaparser.ast.type.Type;\nimport com.github.javaparser.ast.visitor.GenericVisitor;\nimport com.github.javaparser.ast.visitor.VoidVisitor;\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.Optional;\nimport static com.github.javaparser.utils.Utils.assertNotNull;\nimport com.github.javaparser.ast.Node;\nimport com.github.javaparser.ast.visitor.CloneVisitor;\nimport com.github.javaparser.metamodel.MethodCallExprMetaModel;\nimport com.github.javaparser.metamodel.JavaParserMetaModel;\nimport javax.annotation.Generated;\n\n/**\n * A method call on an object. <br/><code>circle.circumference()</code> <br/>In <code>a.&lt;String&gt;bb(15);</code> a\n * is the scope, String is a type argument, bb is the name and 15 is an argument.\n *\n * @author Julio Vilmar Gesser\n */\npublic final class MethodCallExpr extends Expression implements NodeWithTypeArguments<MethodCallExpr>, NodeWithArguments<MethodCallExpr>, NodeWithSimpleName<MethodCallExpr>, NodeWithOptionalScope<MethodCallExpr> {\n\n    private Expression scope;\n\n    private NodeList<Type> typeArguments;\n\n    private SimpleName name;\n\n    private NodeList<Expression> arguments;\n\n    public MethodCallExpr() {\n        this(null, null, new NodeList<>(), new SimpleName(), new NodeList<>());\n    }\n\n    public MethodCallExpr(final Expression scope, final String name) {\n        this(null, scope, new NodeList<>(), new SimpleName(name), new NodeList<>());\n    }\n\n    public MethodCallExpr(final Expression scope, final SimpleName name, final NodeList<Expression> arguments) {\n        this(null, scope, new NodeList<>(), name, arguments);\n    }\n\n    @AllFieldsConstructor\n    public MethodCallExpr(final Expression scope, final NodeList<Type> typeArguments, final SimpleName name, final NodeList<Expression> arguments) {\n        this(null, scope, typeArguments, name, arguments);\n    }\n\n    /**This constructor is used by the parser and is considered private.*/\n    @Generated(\"com.github.javaparser.generator.core.node.MainConstructorGenerator\")\n    public MethodCallExpr(Range range, Expression scope, NodeList<Type> typeArguments, SimpleName name, NodeList<Expression> arguments) {\n        super(range);\n        setScope(scope);\n        setTypeArguments(typeArguments);\n        setName(name);\n        setArguments(arguments);\n        customInitialization();\n    }\n\n    @Override\n    public <R, A> R accept(final GenericVisitor<R, A> v, final A arg) {\n        return v.visit(this, arg);\n    }\n\n    @Override\n    public <A> void accept(final VoidVisitor<A> v, final A arg) {\n        v.visit(this, arg);\n    }\n\n    @Generated(\"com.github.javaparser.generator.core.node.PropertyGenerator\")\n    public NodeList<Expression> getArguments() {\n        return arguments;\n    }\n\n    @Generated(\"com.github.javaparser.generator.core.node.PropertyGenerator\")\n    public SimpleName getName() {\n        return name;\n    }\n\n    @Generated(\"com.github.javaparser.generator.core.node.PropertyGenerator\")\n    public Optional<Expression> getScope() {\n        return Optional.ofNullable(scope);\n    }\n\n    @Generated(\"com.github.javaparser.generator.core.node.PropertyGenerator\")\n    public MethodCallExpr setArguments(final NodeList<Expression> arguments) {\n        assertNotNull(arguments);\n        if (arguments == this.arguments) {\n            return (MethodCallExpr) this;\n        }\n        notifyPropertyChange(ObservableProperty.ARGUMENTS, this.arguments, arguments);\n        if (this.arguments != null)\n            this.arguments.setParentNode(null);\n        this.arguments = arguments;\n        setAsParentNodeOf(arguments);\n        return this;\n    }\n\n    @Generated(\"com.github.javaparser.generator.core.node.PropertyGenerator\")\n    public MethodCallExpr setName(final SimpleName name) {\n        assertNotNull(name);\n        if (name == this.name) {\n            return (MethodCallExpr) this;\n        }\n        notifyPropertyChange(ObservableProperty.NAME, this.name, name);\n        if (this.name != null)\n            this.name.setParentNode(null);\n        this.name = name;\n        setAsParentNodeOf(name);\n        return this;\n    }\n\n    @Generated(\"com.github.javaparser.generator.core.node.PropertyGenerator\")\n    public MethodCallExpr setScope(final Expression scope) {\n        if (scope == this.scope) {\n            return (MethodCallExpr) this;\n        }\n        notifyPropertyChange(ObservableProperty.SCOPE, this.scope, scope);\n        if (this.scope != null)\n            this.scope.setParentNode(null);\n        this.scope = scope;\n        setAsParentNodeOf(scope);\n        return this;\n    }\n\n    @Generated(\"com.github.javaparser.generator.core.node.PropertyGenerator\")\n    public Optional<NodeList<Type>> getTypeArguments() {\n        return Optional.ofNullable(typeArguments);\n    }\n\n    /**\n     * Sets the typeArguments\n     *\n     * @param typeArguments the typeArguments, can be null\n     * @return this, the MethodCallExpr\n     */\n    @Generated(\"com.github.javaparser.generator.core.node.PropertyGenerator\")\n    public MethodCallExpr setTypeArguments(final NodeList<Type> typeArguments) {\n        if (typeArguments == this.typeArguments) {\n            return (MethodCallExpr) this;\n        }\n        notifyPropertyChange(ObservableProperty.TYPE_ARGUMENTS, this.typeArguments, typeArguments);\n        if (this.typeArguments != null)\n            this.typeArguments.setParentNode(null);\n        this.typeArguments = typeArguments;\n        setAsParentNodeOf(typeArguments);\n        return this;\n    }\n\n    @Override\n    @Generated(\"com.github.javaparser.generator.core.node.GetNodeListsGenerator\")\n    public List<NodeList<?>> getNodeLists() {\n        return Arrays.asList(getArguments(), getTypeArguments().orElse(null));\n    }\n\n    @Override\n    @Generated(\"com.github.javaparser.generator.core.node.RemoveMethodGenerator\")\n    public boolean remove(Node node) {\n        if (node == null)\n            return false;\n        for (int i = 0; i < arguments.size(); i++) {\n            if (arguments.get(i) == node) {\n                arguments.remove(i);\n                return true;\n            }\n        }\n        if (scope != null) {\n            if (node == scope) {\n                removeScope();\n                return true;\n            }\n        }\n        if (typeArguments != null) {\n            for (int i = 0; i < typeArguments.size(); i++) {\n                if (typeArguments.get(i) == node) {\n                    typeArguments.remove(i);\n                    return true;\n                }\n            }\n        }\n        return super.remove(node);\n    }\n\n    @Generated(\"com.github.javaparser.generator.core.node.RemoveMethodGenerator\")\n    public MethodCallExpr removeScope() {\n        return setScope((Expression) null);\n    }\n\n    @Override\n    @Generated(\"com.github.javaparser.generator.core.node.CloneGenerator\")\n    public MethodCallExpr clone() {\n        return (MethodCallExpr) accept(new CloneVisitor(), null);\n    }\n\n    @Override\n    @Generated(\"com.github.javaparser.generator.core.node.GetMetaModelGenerator\")\n    public MethodCallExprMetaModel getMetaModel() {\n        return JavaParserMetaModel.methodCallExprMetaModel;\n    }\n}\n", "idx": 1, "id": 11013, "msg": "Looks good. Eventually we could remove some of these constructors, but for now adding these two seems the way to go", "proj": "javaparser-javaparser", "lang": "java"}
{"patch": "@@ -22,6 +22,7 @@ import (\n \n \tcloudkms \"cloud.google.com/go/kms/apiv1\"\n \t\"gocloud.dev/gcp\"\n+\t\"gocloud.dev/internal/secrets\"\n \t\"google.golang.org/api/option\"\n \tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n )", "y": 1, "oldf": "// Copyright 2018 The Go Cloud Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     https://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limtations under the License.\n\n// Package gcpkms provides functionality to encrypt and decrypt secrets using\n// Google Cloud KMS.\npackage gcpkms\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\n\tcloudkms \"cloud.google.com/go/kms/apiv1\"\n\t\"gocloud.dev/gcp\"\n\t\"google.golang.org/api/option\"\n\tkmspb \"google.golang.org/genproto/googleapis/cloud/kms/v1\"\n)\n\n// endPoint is the address to access Google Cloud KMS API.\nconst endPoint = \"cloudkms.googleapis.com:443\"\n\n// Dial returns a client to use with Cloud KMS and a clean-up function to close\n// the client after used.\nfunc Dial(ctx context.Context, ts gcp.TokenSource) (*cloudkms.KeyManagementClient, func(), error) {\n\tc, err := cloudkms.NewKeyManagementClient(ctx, option.WithTokenSource(ts))\n\treturn c, func() { c.Close() }, err\n}\n\n// NewCrypter returns a new Crypter to to encryption and decryption.\nfunc NewCrypter(client *cloudkms.KeyManagementClient, ki *KeyID) *Crypter {\n\treturn &Crypter{\n\t\tkeyID:  ki,\n\t\tclient: client,\n\t}\n}\n\n// KeyID includes related information to construct a key name that is managed\n// by Cloud KMS.\n// See https://cloud.google.com/kms/docs/object-hierarchy#key for more\n// information.\ntype KeyID struct {\n\tProjectID, Location, KeyRing, Key string\n}\n\nfunc (ki *KeyID) String() string {\n\treturn fmt.Sprintf(\"projects/%s/locations/%s/keyRings/%s/cryptoKeys/%s\",\n\t\tki.ProjectID, ki.Location, ki.KeyRing, ki.Key)\n}\n\n// Crypter contains information to construct the pull path of a key.\n// TODO(#1066): make this unexported when there is a top-level portable API.\ntype Crypter struct {\n\tkeyID  *KeyID\n\tclient *cloudkms.KeyManagementClient\n}\n\n// Decrypt decrypts the ciphertext using the key constructed from ki.\nfunc (c *Crypter) Decrypt(ctx context.Context, ciphertext []byte) ([]byte, error) {\n\treq := &kmspb.DecryptRequest{\n\t\tName:       c.keyID.String(),\n\t\tCiphertext: ciphertext,\n\t}\n\tresp, err := c.client.Decrypt(ctx, req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn resp.GetPlaintext(), nil\n}\n\n// Encrypt encrypts the plaintext into a ciphertext.\nfunc (c *Crypter) Encrypt(ctx context.Context, plaintext []byte) ([]byte, error) {\n\treq := &kmspb.EncryptRequest{\n\t\tName:      c.keyID.String(),\n\t\tPlaintext: plaintext,\n\t}\n\tresp, err := c.client.Encrypt(ctx, req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn resp.GetCiphertext(), nil\n}\n", "idx": 1, "id": 13542, "msg": "`localsecrets` should be updated in the same way.", "proj": "google-go-cloud", "lang": "go"}
{"patch": "@@ -20,7 +20,16 @@\n   </div>\n \n   <% if current_user.subscription && current_user.stripe_customer %>\n-    <%= render 'credit_card_form' %>\n+    <div class='text-box'>\n+      <%= semantic_form_for current_user.subscription, url: subscription_path(current_user.subscription) do |form| %>\n+        <%= form.inputs \"Your Subscription Billing Info\", id: 'billing-information' do %>\n+          <%= render 'shared/credit_card_form' %>\n+        <% end %>\n+        <%= form.actions do %>\n+          <%= form.action :submit, label: 'Update Your Card' %>\n+        <% end %>\n+      <% end %>\n+    </div>\n   <% end %>\n </div>\n ", "y": 1, "oldf": "<%= content_for :subject, 'Account' %>\n\n<div class=\"text-box-wrapper\">\n  <div class=\"text-box\">\n    <%= semantic_form_for current_user, url: my_account_path do |form| %>\n      <%= form.inputs \"Your Information [#{link_to('Sign out', sign_out_path, method: :delete)}]\" do %>\n        <%= form.input :first_name, label: 'Your Name', input_html: { placeholder: \"First name\" } %>\n        <%= form.input :last_name, label: false, input_html: { placeholder: \"Last name\" } %>\n        <%= form.input :email, as: :email %>\n        <%= form.input :github_username %>\n        <% if !current_user.external_auth? %>\n          <%= form.input :password %>\n        <% end %>\n      <% end %>\n\n      <%= form.actions do %>\n        <li><%= form.submit 'Update account' %></li>\n      <% end %>\n    <% end %>\n  </div>\n\n  <% if current_user.subscription && current_user.stripe_customer %>\n    <%= render 'credit_card_form' %>\n  <% end %>\n</div>\n\n<aside id=\"account-sidebar\">\n  <% if current_user.has_purchased? %>\n    <h3>Your purchases</h3>\n    <ol class=\"purchases\">\n      <%= render current_user.paid_purchases %>\n    </ol>\n\n    <p class=\"chat\">Every product includes support for any questions you may have about the topic. Visit our <%= link_to \"live chat\", CHAT_LINK %>.</p>\n  <% end %>\n\n  <% if current_user.has_active_subscription? %>\n    <h3>Your Subscription</h3>\n    <ol class=\"purchases\">\n      <%= render current_user.subscription %>\n    </ol>\n  <% end %>\n</aside>\n\n<% content_for :javascript do -%>\n  <script type=\"text/javascript\" charset=\"utf-8\">\n    Stripe.setPublishableKey('<%= STRIPE_PUBLIC_KEY %>');\n\n    stripeResponseHandler = function(status, response){\n      if (response.error) {\n        $('fieldset.actions input').removeAttr('disabled');\n        $('.subscription-errors').html(response.error.message);\n      } else {\n        $form = $('form.subscription');\n        token = response['id'];\n        $form.append(\"<input type='hidden' name='stripe_token' value='\" + token + \"' />\");\n        $form.get(0).submit();\n      }\n    }\n\n    $(document).ready(function() {\n      $('form.subscription').submit(function(event){\n        $form = $(this);\n        $form.find('fieldset.actions input').prop('disabled', true);\n        Stripe.createToken({\n          number:    $('.card-number').val(),\n          cvc:       $('.card-cvc').val(),\n          exp_month: $('.card-expiry-month').val(),\n          exp_year:  $('.card-expiry-year').val()\n        }, stripeResponseHandler);\n\n        return false;\n      });\n    });\n  </script>\n<% end %>\n", "idx": 1, "id": 7332, "msg": "Could this line use `url: current_user.subscription`?", "proj": "thoughtbot-upcase", "lang": "rb"}
{"patch": "@@ -2290,14 +2290,6 @@ func (fbo *folderBranchOps) getConvID(\n \n func (fbo *folderBranchOps) sendEditNotifications(\n \tctx context.Context, rmd ImmutableRootMetadata, body string) error {\n-\t// For now only write out the notifications if we're in test mode,\n-\t// just in case we decide to change the notification format before\n-\t// we launch.  TODO: turn this on for admins once we can test it\n-\t// on staging.\n-\tif !fbo.config.Mode().IsTestMode() {\n-\t\treturn nil\n-\t}\n-\n \thandle := rmd.GetTlfHandle()\n \tconvID, err := fbo.getConvID(ctx, handle)\n \tif err != nil {", "y": 1, "oldf": "// Copyright 2016 Keybase Inc. All rights reserved.\n// Use of this source code is governed by a BSD\n// license that can be found in the LICENSE file.\n\npackage libkbfs\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"reflect\"\n\t\"sort\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/keybase/backoff\"\n\t\"github.com/keybase/client/go/libkb\"\n\t\"github.com/keybase/client/go/protocol/chat1\"\n\t\"github.com/keybase/client/go/protocol/keybase1\"\n\t\"github.com/keybase/go-framed-msgpack-rpc/rpc\"\n\t\"github.com/keybase/kbfs/kbfsblock\"\n\t\"github.com/keybase/kbfs/kbfscrypto\"\n\t\"github.com/keybase/kbfs/kbfsedits\"\n\t\"github.com/keybase/kbfs/kbfsmd\"\n\t\"github.com/keybase/kbfs/kbfssync\"\n\t\"github.com/keybase/kbfs/tlf\"\n\t\"github.com/pkg/errors\"\n\t\"golang.org/x/net/context\"\n)\n\n// mdReadType indicates whether a read needs identifies.\ntype mdReadType int\n\nconst (\n\t// A read request that doesn't need an identify to be\n\t// performed.\n\tmdReadNoIdentify mdReadType = iota\n\t// A read request that needs an identify to be performed (if\n\t// it hasn't been already).\n\tmdReadNeedIdentify\n)\n\n// mdUpdateType indicates update type.\ntype mdUpdateType int\n\nconst (\n\tmdWrite mdUpdateType = iota\n\t// A rekey request.  Doesn't need an identify to be performed, as\n\t// a rekey does its own (finer-grained) identifies.\n\tmdRekey\n)\n\ntype branchType int\n\nconst (\n\tstandard       branchType = iota // an online, read-write branch\n\tarchive                          // an online, read-only branch\n\toffline                          // an offline, read-write branch\n\tarchiveOffline                   // an offline, read-only branch\n)\n\n// Constants used in this file.  TODO: Make these configurable?\nconst (\n\t// MaxBlockSizeBytesDefault is the default maximum block size for KBFS.\n\t// 512K blocks by default, block changes embedded max == 8K.\n\t// Block size was chosen somewhat arbitrarily by trying to\n\t// minimize the overall size of the history written by a user when\n\t// appending 1KB writes to a file, up to a 1GB total file.  Here\n\t// is the output of a simple script that approximates that\n\t// calculation:\n\t//\n\t// Total history size for 0065536-byte blocks: 1134341128192 bytes\n\t// Total history size for 0131072-byte blocks: 618945052672 bytes\n\t// Total history size for 0262144-byte blocks: 412786622464 bytes\n\t// Total history size for 0524288-byte blocks: 412786622464 bytes\n\t// Total history size for 1048576-byte blocks: 618945052672 bytes\n\t// Total history size for 2097152-byte blocks: 1134341128192 bytes\n\t// Total history size for 4194304-byte blocks: 2216672886784 bytes\n\tMaxBlockSizeBytesDefault = 512 << 10\n\t// Maximum number of blocks that can be sent in parallel\n\tmaxParallelBlockPuts = 100\n\t// Maximum number of blocks that can be fetched in parallel\n\tmaxParallelBlockGets = 10\n\t// Max response size for a single DynamoDB query is 1MB.\n\tmaxMDsAtATime = 10\n\t// Cap the number of times we retry after a recoverable error\n\tmaxRetriesOnRecoverableErrors = 10\n\t// When the number of dirty bytes exceeds this level, force a sync.\n\tdirtyBytesThreshold = maxParallelBlockPuts * MaxBlockSizeBytesDefault\n\t// The timeout for any background task.\n\tbackgroundTaskTimeout = 1 * time.Minute\n\t// If it's been more than this long since our last update, check\n\t// the current head before downloading all of the new revisions.\n\tfastForwardTimeThresh = 15 * time.Minute\n\t// If there are more than this many new revisions, fast forward\n\t// rather than downloading them all.\n\tfastForwardRevThresh = 50\n)\n\ntype fboMutexLevel mutexLevel\n\nconst (\n\tfboMDWriter fboMutexLevel = 1\n\tfboHead     fboMutexLevel = 2\n\tfboBlock    fboMutexLevel = 3\n)\n\nfunc (o fboMutexLevel) String() string {\n\tswitch o {\n\tcase fboMDWriter:\n\t\treturn \"mdWriterLock\"\n\tcase fboHead:\n\t\treturn \"headLock\"\n\tcase fboBlock:\n\t\treturn \"blockLock\"\n\tdefault:\n\t\treturn fmt.Sprintf(\"Invalid fboMutexLevel %d\", int(o))\n\t}\n}\n\nfunc fboMutexLevelToString(o mutexLevel) string {\n\treturn (fboMutexLevel(o)).String()\n}\n\n// Rules for working with lockState in FBO:\n//\n//   - Every \"execution flow\" (i.e., program flow that happens\n//     sequentially) needs its own lockState object. This usually means\n//     that each \"public\" FBO method does:\n//\n//       lState := makeFBOLockState()\n//\n//     near the top.\n//\n//   - Plumb lState through to all functions that hold any of the\n//     relevant locks, or are called under those locks.\n//\n// This way, violations of the lock hierarchy will be detected at\n// runtime.\n\nfunc makeFBOLockState() *lockState {\n\treturn makeLevelState(fboMutexLevelToString)\n}\n\n// blockLock is just like a sync.RWMutex, but with an extra operation\n// (DoRUnlockedIfPossible).\ntype blockLock struct {\n\tleveledRWMutex\n\tlocked bool\n}\n\nfunc (bl *blockLock) Lock(lState *lockState) {\n\tbl.leveledRWMutex.Lock(lState)\n\tbl.locked = true\n}\n\nfunc (bl *blockLock) Unlock(lState *lockState) {\n\tbl.locked = false\n\tbl.leveledRWMutex.Unlock(lState)\n}\n\n// DoRUnlockedIfPossible must be called when r- or w-locked. If\n// r-locked, r-unlocks, runs the given function, and r-locks after\n// it's done. Otherwise, just runs the given function.\nfunc (bl *blockLock) DoRUnlockedIfPossible(lState *lockState, f func(*lockState)) {\n\tif !bl.locked {\n\t\tbl.RUnlock(lState)\n\t\tdefer bl.RLock(lState)\n\t}\n\n\tf(lState)\n}\n\n// headTrustStatus marks whether the head is from a trusted or\n// untrusted source. When rekeying we get the head MD by folder id\n// and do not check the tlf handle\ntype headTrustStatus int\n\nconst (\n\theadUntrusted headTrustStatus = iota\n\theadTrusted\n)\n\ntype cachedDirOp struct {\n\tdirOp op\n\tnodes []Node\n}\n\ntype editChannelActivity struct {\n\tconvID  chat1.ConversationID // set to nil to force a re-init\n\tname    string\n\tmessage string\n}\n\n// folderBranchOps implements the KBFSOps interface for a specific\n// branch of a specific folder.  It is go-routine safe for operations\n// within the folder.\n//\n// We use locks to protect against multiple goroutines accessing the\n// same folder-branch.  The goal with our locking strategy is maximize\n// concurrent access whenever possible.  See design/state_machine.md\n// for more details.  There are three important locks:\n//\n// 1) mdWriterLock: Any \"remote-sync\" operation (one which modifies the\n//    folder's metadata) must take this lock during the entirety of\n//    its operation, to avoid forking the MD.\n//\n// 2) headLock: This is a read/write mutex.  It must be taken for\n//    reading before accessing any part of the current head MD.  It\n//    should be taken for the shortest time possible -- that means in\n//    general that it should be taken, and the MD copied to a\n//    goroutine-local variable, and then it can be released.\n//    Remote-sync operations should take it for writing after pushing\n//    all of the blocks and MD to the KBFS servers (i.e., all network\n//    accesses), and then hold it until after all notifications have\n//    been fired, to ensure that no concurrent \"local\" operations ever\n//    see inconsistent state locally.\n//\n// 3) blockLock: This too is a read/write mutex.  It must be taken for\n//    reading before accessing any blocks in the block cache that\n//    belong to this folder/branch.  This includes checking their\n//    dirty status.  It should be taken for the shortest time possible\n//    -- that means in general it should be taken, and then the blocks\n//    that will be modified should be copied to local variables in the\n//    goroutine, and then it should be released.  The blocks should\n//    then be modified locally, and then readied and pushed out\n//    remotely.  Only after the blocks have been pushed to the server\n//    should a remote-sync operation take the lock again (this time\n//    for writing) and put/finalize the blocks.  Write and Truncate\n//    should take blockLock for their entire lifetime, since they\n//    don't involve writes over the network.  Furthermore, if a block\n//    is not in the cache and needs to be fetched, we should release\n//    the mutex before doing the network operation, and lock it again\n//    before writing the block back to the cache.\n//\n// We want to allow writes and truncates to a file that's currently\n// being sync'd, like any good networked file system.  The tricky part\n// is making sure the changes can both: a) be read while the sync is\n// happening, and b) be applied to the new file path after the sync is\n// done.\n//\n// For now, we just do the dumb, brute force thing for now: if a block\n// is currently being sync'd, it copies the block and puts it back\n// into the cache as modified.  Then, when the sync finishes, it\n// throws away the modified blocks and re-applies the change to the\n// new file path (which might have a completely different set of\n// blocks, so we can't just reuse the blocks that were modified during\n// the sync.)\ntype folderBranchOps struct {\n\tconfig       Config\n\tfolderBranch FolderBranch\n\tbid          kbfsmd.BranchID // protected by mdWriterLock\n\tbType        branchType\n\tobservers    *observerList\n\n\t// these locks, when locked concurrently by the same goroutine,\n\t// should only be taken in the following order to avoid deadlock:\n\tmdWriterLock leveledMutex // taken by any method making MD modifications\n\tdirOps       []cachedDirOp\n\n\t// protects access to head, headStatus, latestMergedRevision,\n\t// and hasBeenCleared.\n\theadLock   leveledRWMutex\n\thead       ImmutableRootMetadata\n\theadStatus headTrustStatus\n\t// latestMergedRevision tracks the latest heard merged revision on server\n\tlatestMergedRevision kbfsmd.Revision\n\t// Has this folder ever been cleared?\n\thasBeenCleared bool\n\n\tblocks  folderBlockOps\n\tprepper folderUpdatePrepper\n\n\t// nodeCache itself is goroutine-safe, but this object's use\n\t// of it has special requirements:\n\t//\n\t//   - Reads can call PathFromNode() unlocked, since there are\n\t//     no guarantees with concurrent reads.\n\t//\n\t//   - Operations that takes mdWriterLock always needs the\n\t//     most up-to-date paths, so those must call\n\t//     PathFromNode() under mdWriterLock.\n\t//\n\t//   - Block write operations (write/truncate/sync) need to\n\t//     coordinate. Specifically, sync must make sure that\n\t//     blocks referenced in a path (including all of the child\n\t//     blocks) must exist in the cache during calls to\n\t//     PathFromNode from write/truncate. This means that sync\n\t//     must modify dirty file blocks only under blockLock, and\n\t//     write/truncate must call PathFromNode() under\n\t//     blockLock.\n\t//\n\t//     Furthermore, calls to UpdatePointer() must happen\n\t//     before the copy-on-write mode induced by Sync() is\n\t//     finished.\n\tnodeCache NodeCache\n\n\t// Whether we've identified this TLF or not.\n\tidentifyLock sync.Mutex\n\tidentifyDone bool\n\tidentifyTime time.Time\n\n\t// The current status summary for this folder\n\tstatus *folderBranchStatusKeeper\n\n\t// How to log\n\tlog      traceLogger\n\tdeferLog traceLogger\n\n\t// Closed on shutdown\n\tshutdownChan chan struct{}\n\n\t// Can be used to turn off notifications for a while (e.g., for testing)\n\tupdatePauseChan chan (<-chan struct{})\n\n\tcancelUpdatesLock sync.Mutex\n\t// Cancels the goroutine currently waiting on TLF MD updates.\n\tcancelUpdates context.CancelFunc\n\n\t// After a shutdown, this channel will be closed when the register\n\t// goroutine completes.\n\tupdateDoneChan chan struct{}\n\n\t// forceSyncChan is read from by the background sync process\n\t// to know when it should sync immediately.\n\tforceSyncChan <-chan struct{}\n\n\t// syncNeededChan is signalled when a buffered write happens, and\n\t// lets the background syncer wait rather than waking up all the\n\t// time.\n\tsyncNeededChan chan struct{}\n\n\t// How to resolve conflicts\n\tcr *ConflictResolver\n\n\t// Helper class for archiving and cleaning up the blocks for this TLF\n\tfbm *folderBlockManager\n\n\trekeyFSM RekeyFSM\n\n\teditHistory  *kbfsedits.TlfHistory\n\teditChannels chan editChannelActivity\n\n\tcancelEditsLock sync.Mutex\n\t// Cancels the goroutine currently waiting on edits\n\tcancelEdits context.CancelFunc\n\n\tbranchChanges      kbfssync.RepeatedWaitGroup\n\tmdFlushes          kbfssync.RepeatedWaitGroup\n\tforcedFastForwards kbfssync.RepeatedWaitGroup\n\tmerkleFetches      kbfssync.RepeatedWaitGroup\n\teditActivity       kbfssync.RepeatedWaitGroup\n\n\tmuLastGetHead sync.Mutex\n\t// We record a timestamp everytime getHead or getTrustedHead is called, and\n\t// use this as a heuristic for whether user is actively using KBFS. If user\n\t// has been generating KBFS activities recently, it makes sense to try to\n\t// reconnect as soon as possible in case of a deployment causes\n\t// disconnection.\n\tlastGetHead time.Time\n\n\tconvLock sync.Mutex\n\tconvID   chat1.ConversationID\n}\n\nvar _ KBFSOps = (*folderBranchOps)(nil)\n\nvar _ fbmHelper = (*folderBranchOps)(nil)\n\n// newFolderBranchOps constructs a new folderBranchOps object.\nfunc newFolderBranchOps(ctx context.Context, config Config, fb FolderBranch,\n\tbType branchType) *folderBranchOps {\n\tvar nodeCache NodeCache\n\tif config.Mode().NodeCacheEnabled() {\n\t\tnodeCache = newNodeCacheStandard(fb)\n\t\tfor _, f := range config.RootNodeWrappers() {\n\t\t\tnodeCache.AddRootWrapper(f)\n\t\t}\n\t}\n\n\t// make logger\n\tbranchSuffix := \"\"\n\tif fb.Branch != MasterBranch {\n\t\tbranchSuffix = \" \" + string(fb.Branch)\n\t}\n\ttlfStringFull := fb.Tlf.String()\n\t// Shorten the TLF ID for the module name.  8 characters should be\n\t// unique enough for a local node.\n\tlog := config.MakeLogger(fmt.Sprintf(\"FBO %s%s\", tlfStringFull[:8],\n\t\tbranchSuffix))\n\t// But print it out once in full, just in case.\n\tlog.CInfof(ctx, \"Created new folder-branch for %s\", tlfStringFull)\n\n\tobservers := newObserverList()\n\n\tmdWriterLock := makeLeveledMutex(mutexLevel(fboMDWriter), &sync.Mutex{})\n\theadLock := makeLeveledRWMutex(mutexLevel(fboHead), &sync.RWMutex{})\n\tblockLockMu := makeLeveledRWMutex(mutexLevel(fboBlock), &sync.RWMutex{})\n\n\tforceSyncChan := make(chan struct{})\n\n\tfbo := &folderBranchOps{\n\t\tconfig:       config,\n\t\tfolderBranch: fb,\n\t\tbid:          kbfsmd.BranchID{},\n\t\tbType:        bType,\n\t\tobservers:    observers,\n\t\tstatus:       newFolderBranchStatusKeeper(config, nodeCache),\n\t\tmdWriterLock: mdWriterLock,\n\t\theadLock:     headLock,\n\t\tblocks: folderBlockOps{\n\t\t\tconfig:        config,\n\t\t\tlog:           log,\n\t\t\tfolderBranch:  fb,\n\t\t\tobservers:     observers,\n\t\t\tforceSyncChan: forceSyncChan,\n\t\t\tblockLock: blockLock{\n\t\t\t\tleveledRWMutex: blockLockMu,\n\t\t\t},\n\t\t\tdirtyFiles: make(map[BlockPointer]*dirtyFile),\n\t\t\tdeferred:   make(map[BlockRef]deferredState),\n\t\t\tunrefCache: make(map[BlockRef]*syncInfo),\n\t\t\tdeCache:    make(map[BlockRef]deCacheEntry),\n\t\t\tnodeCache:  nodeCache,\n\t\t},\n\t\tnodeCache:       nodeCache,\n\t\tlog:             traceLogger{log},\n\t\tdeferLog:        traceLogger{log.CloneWithAddedDepth(1)},\n\t\tshutdownChan:    make(chan struct{}),\n\t\tupdatePauseChan: make(chan (<-chan struct{})),\n\t\tforceSyncChan:   forceSyncChan,\n\t\tsyncNeededChan:  make(chan struct{}, 1),\n\t\teditHistory:     kbfsedits.NewTlfHistory(),\n\t\teditChannels:    make(chan editChannelActivity, 100),\n\t}\n\tfbo.prepper = folderUpdatePrepper{\n\t\tconfig:       config,\n\t\tfolderBranch: fb,\n\t\tblocks:       &fbo.blocks,\n\t\tlog:          log,\n\t}\n\tfbo.cr = NewConflictResolver(config, fbo)\n\tfbo.fbm = newFolderBlockManager(config, fb, fbo)\n\tfbo.rekeyFSM = NewRekeyFSM(fbo)\n\tif config.DoBackgroundFlushes() {\n\t\tgo fbo.backgroundFlusher()\n\t}\n\n\treturn fbo\n}\n\n// markForReIdentifyIfNeeded checks whether this tlf is identified and mark\n// it for lazy reidentification if it exceeds time limits.\nfunc (fbo *folderBranchOps) markForReIdentifyIfNeeded(now time.Time, maxValid time.Duration) {\n\tfbo.identifyLock.Lock()\n\tdefer fbo.identifyLock.Unlock()\n\tif fbo.identifyDone && (now.Before(fbo.identifyTime) || fbo.identifyTime.Add(maxValid).Before(now)) {\n\t\tfbo.log.CDebugf(nil, \"Expiring identify from %v\", fbo.identifyTime)\n\t\tfbo.identifyDone = false\n\t}\n}\n\n// Shutdown safely shuts down any background goroutines that may have\n// been launched by folderBranchOps.\nfunc (fbo *folderBranchOps) Shutdown(ctx context.Context) error {\n\tif fbo.config.CheckStateOnShutdown() {\n\t\tlState := makeFBOLockState()\n\n\t\tif fbo.blocks.GetState(lState) == dirtyState {\n\t\t\tfbo.log.CDebugf(ctx, \"Skipping state-checking due to dirty state\")\n\t\t} else if !fbo.isMasterBranch(lState) {\n\t\t\tfbo.log.CDebugf(ctx, \"Skipping state-checking due to being staged\")\n\t\t} else {\n\t\t\t// Make sure we're up to date first\n\t\t\tif err := fbo.SyncFromServer(ctx,\n\t\t\t\tfbo.folderBranch, nil); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\t// Check the state for consistency before shutting down.\n\t\t\tsc := NewStateChecker(fbo.config)\n\t\t\tif err := sc.CheckMergedState(ctx, fbo.id()); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\tclose(fbo.shutdownChan)\n\tfbo.merkleFetches.Wait(ctx)\n\tfbo.cr.Shutdown()\n\tfbo.fbm.shutdown()\n\tfbo.rekeyFSM.Shutdown()\n\t// Wait for the update goroutine to finish, so that we don't have\n\t// any races with logging during test reporting.\n\tif fbo.updateDoneChan != nil {\n\t\t<-fbo.updateDoneChan\n\t}\n\treturn nil\n}\n\nfunc (fbo *folderBranchOps) id() tlf.ID {\n\treturn fbo.folderBranch.Tlf\n}\n\nfunc (fbo *folderBranchOps) branch() BranchName {\n\treturn fbo.folderBranch.Branch\n}\n\nfunc (fbo *folderBranchOps) GetFavorites(ctx context.Context) (\n\t[]Favorite, error) {\n\treturn nil, errors.New(\"GetFavorites is not supported by folderBranchOps\")\n}\n\nfunc (fbo *folderBranchOps) RefreshCachedFavorites(ctx context.Context) {\n\t// no-op\n}\n\nfunc (fbo *folderBranchOps) DeleteFavorite(ctx context.Context,\n\tfav Favorite) error {\n\treturn errors.New(\"DeleteFavorite is not supported by folderBranchOps\")\n}\n\nfunc (fbo *folderBranchOps) AddFavorite(ctx context.Context,\n\tfav Favorite) error {\n\treturn errors.New(\"AddFavorite is not supported by folderBranchOps\")\n}\n\nfunc (fbo *folderBranchOps) addToFavorites(ctx context.Context,\n\tfavorites *Favorites, created bool) (err error) {\n\tlState := makeFBOLockState()\n\thead := fbo.getTrustedHead(lState)\n\tif head == (ImmutableRootMetadata{}) {\n\t\treturn OpsCantHandleFavorite{\"Can't add a favorite without a handle\"}\n\t}\n\n\treturn fbo.addToFavoritesByHandle(ctx, favorites, head.GetTlfHandle(), created)\n}\n\nfunc (fbo *folderBranchOps) addToFavoritesByHandle(ctx context.Context,\n\tfavorites *Favorites, handle *TlfHandle, created bool) (err error) {\n\tif _, err := fbo.config.KBPKI().GetCurrentSession(ctx); err != nil {\n\t\t// Can't favorite while not logged in\n\t\treturn nil\n\t}\n\n\tfavorites.AddAsync(ctx, handle.toFavToAdd(created))\n\treturn nil\n}\n\nfunc (fbo *folderBranchOps) deleteFromFavorites(ctx context.Context,\n\tfavorites *Favorites) error {\n\tif _, err := fbo.config.KBPKI().GetCurrentSession(ctx); err != nil {\n\t\t// Can't unfavorite while not logged in\n\t\treturn nil\n\t}\n\n\tlState := makeFBOLockState()\n\thead := fbo.getTrustedHead(lState)\n\tif head == (ImmutableRootMetadata{}) {\n\t\t// This can happen when identifies fail and the head is never set.\n\t\treturn OpsCantHandleFavorite{\"Can't delete a favorite without a handle\"}\n\t}\n\n\th := head.GetTlfHandle()\n\treturn favorites.Delete(ctx, h.ToFavorite())\n}\n\nfunc (fbo *folderBranchOps) doFavoritesOp(ctx context.Context,\n\tfavs *Favorites, fop FavoritesOp, handle *TlfHandle) error {\n\tswitch fop {\n\tcase FavoritesOpNoChange:\n\t\treturn nil\n\tcase FavoritesOpAdd:\n\t\tif handle != nil {\n\t\t\treturn fbo.addToFavoritesByHandle(ctx, favs, handle, false)\n\t\t}\n\t\treturn fbo.addToFavorites(ctx, favs, false)\n\tcase FavoritesOpAddNewlyCreated:\n\t\tif handle != nil {\n\t\t\treturn fbo.addToFavoritesByHandle(ctx, favs, handle, true)\n\t\t}\n\t\treturn fbo.addToFavorites(ctx, favs, true)\n\tcase FavoritesOpRemove:\n\t\treturn fbo.deleteFromFavorites(ctx, favs)\n\tdefault:\n\t\treturn InvalidFavoritesOpError{}\n\t}\n}\n\nfunc (fbo *folderBranchOps) updateLastGetHeadTimestamp() {\n\tfbo.muLastGetHead.Lock()\n\tdefer fbo.muLastGetHead.Unlock()\n\tfbo.lastGetHead = fbo.config.Clock().Now()\n}\n\n// getTrustedHead should not be called outside of folder_branch_ops.go.\n// Returns ImmutableRootMetadata{} when the head is not trusted.\n// See the comment on headTrustedStatus for more information.\nfunc (fbo *folderBranchOps) getTrustedHead(lState *lockState) ImmutableRootMetadata {\n\tfbo.headLock.RLock(lState)\n\tdefer fbo.headLock.RUnlock(lState)\n\tif fbo.headStatus == headUntrusted {\n\t\treturn ImmutableRootMetadata{}\n\t}\n\n\t// This triggers any mdserver backoff timer to fast forward. In case of a\n\t// deployment, this causes KBFS client to try to reconnect to mdserver\n\t// immediately rather than waiting until the random backoff timer is up.\n\t// Note that this doesn't necessarily guarantee that the fbo handler that\n\t// called this method would get latest MD.\n\tfbo.config.MDServer().FastForwardBackoff()\n\tfbo.updateLastGetHeadTimestamp()\n\n\treturn fbo.head\n}\n\n// getHead should not be called outside of folder_branch_ops.go.\nfunc (fbo *folderBranchOps) getHead(lState *lockState) (\n\tImmutableRootMetadata, headTrustStatus) {\n\tfbo.headLock.RLock(lState)\n\tdefer fbo.headLock.RUnlock(lState)\n\n\t// See getTrustedHead for explanation.\n\tfbo.config.MDServer().FastForwardBackoff()\n\tfbo.updateLastGetHeadTimestamp()\n\n\treturn fbo.head, fbo.headStatus\n}\n\n// isMasterBranch should not be called if mdWriterLock is already taken.\nfunc (fbo *folderBranchOps) isMasterBranch(lState *lockState) bool {\n\tfbo.mdWriterLock.Lock(lState)\n\tdefer fbo.mdWriterLock.Unlock(lState)\n\treturn fbo.bid == kbfsmd.NullBranchID\n}\n\nfunc (fbo *folderBranchOps) isMasterBranchLocked(lState *lockState) bool {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\n\treturn fbo.bid == kbfsmd.NullBranchID\n}\n\nfunc (fbo *folderBranchOps) setBranchIDLocked(lState *lockState, bid kbfsmd.BranchID) {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\n\tif fbo.bid != bid {\n\t\tfbo.cr.BeginNewBranch()\n\t}\n\n\tfbo.bid = bid\n\tif bid == kbfsmd.NullBranchID {\n\t\tfbo.status.setCRSummary(nil, nil)\n\t}\n}\n\nvar errNoFlushedRevisions = errors.New(\"No flushed MDs yet\")\nvar errNoMergedRevWhileStaged = errors.New(\n\t\"Cannot find most recent merged revision while staged\")\n\n// getJournalPredecessorRevision returns the revision that precedes\n// the current journal head if journaling enabled and there are\n// unflushed MD updates; otherwise it returns\n// kbfsmd.RevisionUninitialized.  If there aren't any flushed MD\n// revisions, it returns errNoFlushedRevisions.\nfunc (fbo *folderBranchOps) getJournalPredecessorRevision(ctx context.Context) (\n\tkbfsmd.Revision, error) {\n\tjServer, err := GetJournalServer(fbo.config)\n\tif err != nil {\n\t\t// Journaling is disabled entirely.\n\t\treturn kbfsmd.RevisionUninitialized, nil\n\t}\n\n\tjStatus, err := jServer.JournalStatus(fbo.id())\n\tif err != nil {\n\t\t// Journaling is disabled for this TLF, so use the local head.\n\t\t// TODO: JournalStatus could return other errors (likely\n\t\t// file/disk corruption) that indicate a real problem, so it\n\t\t// might be nice to type those errors so we can distinguish\n\t\t// them.\n\t\treturn kbfsmd.RevisionUninitialized, nil\n\t}\n\n\tif jStatus.BranchID != kbfsmd.NullBranchID.String() {\n\t\treturn kbfsmd.RevisionUninitialized, errNoMergedRevWhileStaged\n\t}\n\n\tif jStatus.RevisionStart == kbfsmd.RevisionUninitialized {\n\t\t// The journal is empty, so the local head must be the most recent.\n\t\treturn kbfsmd.RevisionUninitialized, nil\n\t} else if jStatus.RevisionStart == kbfsmd.RevisionInitial {\n\t\t// Nothing has been flushed to the servers yet, so don't\n\t\t// return anything.\n\t\treturn kbfsmd.RevisionUninitialized, errNoFlushedRevisions\n\t}\n\n\treturn jStatus.RevisionStart - 1, nil\n}\n\n// validateHeadLocked validates an untrusted head and sets it as trusted.\n// see headTrustedState comment for more information.\nfunc (fbo *folderBranchOps) validateHeadLocked(\n\tctx context.Context, lState *lockState, md ImmutableRootMetadata) error {\n\tfbo.headLock.AssertLocked(lState)\n\n\t// Validate fbo against fetched md and discard the fetched one.\n\tif fbo.head.TlfID() != md.TlfID() {\n\t\tfbo.log.CCriticalf(ctx, \"Fake untrusted TLF encountered %v %v %v %v\", fbo.head.TlfID(), md.TlfID(), fbo.head.mdID, md.mdID)\n\t\treturn kbfsmd.MDTlfIDMismatch{CurrID: fbo.head.TlfID(), NextID: md.TlfID()}\n\t}\n\tfbo.headStatus = headTrusted\n\treturn nil\n}\n\nfunc (fbo *folderBranchOps) setHeadLocked(\n\tctx context.Context, lState *lockState,\n\tmd ImmutableRootMetadata, headStatus headTrustStatus) error {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\tfbo.headLock.AssertLocked(lState)\n\n\tisFirstHead := fbo.head == ImmutableRootMetadata{}\n\twasReadable := false\n\tif !isFirstHead {\n\t\tif headStatus == headUntrusted {\n\t\t\tpanic(\"setHeadLocked: Trying to set an untrusted head over an existing head\")\n\t\t}\n\n\t\twasReadable = fbo.head.IsReadable()\n\n\t\tif fbo.headStatus == headUntrusted {\n\t\t\terr := fbo.validateHeadLocked(ctx, lState, md)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif fbo.head.mdID == md.mdID {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\n\t\tif fbo.head.mdID == md.mdID {\n\t\t\tpanic(errors.Errorf(\"Re-putting the same MD: %s\", md.mdID))\n\t\t}\n\t}\n\n\tfbo.log.CDebugf(ctx, \"Setting head revision to %d\", md.Revision())\n\n\t// If this is the first time the MD is being set, and we are\n\t// operating on unmerged data, initialize the state properly and\n\t// kick off conflict resolution.\n\tif isFirstHead && md.MergedStatus() == kbfsmd.Unmerged {\n\t\tfbo.setBranchIDLocked(lState, md.BID())\n\t\t// Use uninitialized for the merged branch; the unmerged\n\t\t// revision is enough to trigger conflict resolution.\n\t\tfbo.cr.Resolve(ctx, md.Revision(), kbfsmd.RevisionUninitialized)\n\t} else if md.MergedStatus() == kbfsmd.Merged {\n\t\tjournalEnabled := TLFJournalEnabled(fbo.config, fbo.id())\n\t\tif journalEnabled {\n\t\t\tif isFirstHead {\n\t\t\t\t// If journaling is on, and this is the first head\n\t\t\t\t// we're setting, we have to make sure we use the\n\t\t\t\t// server's notion of the latest MD, not the one\n\t\t\t\t// potentially coming from our journal.  If there are\n\t\t\t\t// no flushed revisions, it's not a hard error, and we\n\t\t\t\t// just leave the latest merged revision\n\t\t\t\t// uninitialized.\n\t\t\t\tjournalPred, err := fbo.getJournalPredecessorRevision(ctx)\n\t\t\t\tswitch err {\n\t\t\t\tcase nil:\n\t\t\t\t\t// journalPred will be\n\t\t\t\t\t// kbfsmd.RevisionUninitialized when the journal\n\t\t\t\t\t// is empty.\n\t\t\t\t\tif journalPred >= kbfsmd.RevisionInitial {\n\t\t\t\t\t\tfbo.setLatestMergedRevisionLocked(\n\t\t\t\t\t\t\tctx, lState, journalPred, false)\n\t\t\t\t\t} else {\n\t\t\t\t\t\tfbo.setLatestMergedRevisionLocked(ctx, lState,\n\t\t\t\t\t\t\tmd.Revision(), false)\n\t\t\t\t\t}\n\t\t\t\tcase errNoFlushedRevisions:\n\t\t\t\t\t// The server has no revisions, so leave the\n\t\t\t\t\t// latest merged revision uninitialized.\n\t\t\t\tdefault:\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t// If this isn't the first head, then this is either\n\t\t\t\t// an update from the server, or an update just\n\t\t\t\t// written by the client.  But since journaling is on,\n\t\t\t\t// then latter case will be handled by onMDFlush when\n\t\t\t\t// the update is properly flushed to the server.  So\n\t\t\t\t// ignore updates that haven't yet been put to the\n\t\t\t\t// server.\n\t\t\t\tif md.putToServer {\n\t\t\t\t\tfbo.setLatestMergedRevisionLocked(\n\t\t\t\t\t\tctx, lState, md.Revision(), false)\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\t// This is a merged revision, and journaling is disabled,\n\t\t\t// so it's definitely the latest revision on the server as\n\t\t\t// well.\n\t\t\tfbo.setLatestMergedRevisionLocked(ctx, lState, md.Revision(), false)\n\t\t}\n\t}\n\n\t// Make sure that any unembedded block changes have been swapped\n\t// back in.\n\tif fbo.config.Mode().BlockManagementEnabled() &&\n\t\tmd.data.Changes.Info.BlockPointer != zeroPtr &&\n\t\tlen(md.data.Changes.Ops) == 0 {\n\t\treturn errors.New(\"Must swap in block changes before setting head\")\n\t}\n\n\tfbo.head = md\n\tif isFirstHead && headStatus == headTrusted {\n\t\tfbo.headStatus = headTrusted\n\t}\n\tfbo.status.setRootMetadata(md)\n\tif isFirstHead {\n\t\t// Start registering for updates right away, using this MD\n\t\t// as a starting point. For now only the master branch can\n\t\t// get updates\n\t\tif fbo.branch() == MasterBranch {\n\t\t\tif fbo.config.Mode().TLFUpdatesEnabled() {\n\t\t\t\tfbo.updateDoneChan = make(chan struct{})\n\t\t\t\tgo fbo.registerAndWaitForUpdates()\n\t\t\t}\n\t\t\tif fbo.config.Mode().TLFEditHistoryEnabled() {\n\t\t\t\t// The first event should initialize all the data.\n\t\t\t\tfbo.editActivity.Add(1)\n\t\t\t\tfbo.editChannels <- editChannelActivity{nil, \"\", \"\"}\n\t\t\t\tgo fbo.monitorEditsChat()\n\t\t\t}\n\t\t}\n\n\t\t// If journaling is enabled, we should make sure to enable it\n\t\t// for this TLF.  That's because we may have received the TLF\n\t\t// ID from the service, rather than via a GetIDForHandle call,\n\t\t// and so we might have skipped the journal.\n\t\tif jServer, err := GetJournalServer(fbo.config); err == nil {\n\t\t\t_, _ = jServer.getTLFJournal(fbo.id(), md.GetTlfHandle())\n\t\t}\n\t}\n\tif !wasReadable && md.IsReadable() {\n\t\t// Let any listeners know that this folder is now readable,\n\t\t// which may indicate that a rekey successfully took place.\n\t\tfbo.config.Reporter().Notify(ctx, mdReadSuccessNotification(\n\t\t\tmd.GetTlfHandle(), md.TlfID().Type() == tlf.Public))\n\t}\n\treturn nil\n}\n\n// setInitialHeadUntrustedLocked is for when the given RootMetadata\n// was fetched not due to a user action, i.e. via a Rekey\n// notification, and we don't have a TLF name to check against.\nfunc (fbo *folderBranchOps) setInitialHeadUntrustedLocked(ctx context.Context,\n\tlState *lockState, md ImmutableRootMetadata) error {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\tfbo.headLock.AssertLocked(lState)\n\tif fbo.head != (ImmutableRootMetadata{}) {\n\t\treturn errors.New(\"Unexpected non-nil head in setInitialHeadUntrustedLocked\")\n\t}\n\treturn fbo.setHeadLocked(ctx, lState, md, headUntrusted)\n}\n\n// setNewInitialHeadLocked is for when we're creating a brand-new TLF.\n// This is trusted.\nfunc (fbo *folderBranchOps) setNewInitialHeadLocked(ctx context.Context,\n\tlState *lockState, md ImmutableRootMetadata) error {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\tfbo.headLock.AssertLocked(lState)\n\tif fbo.head != (ImmutableRootMetadata{}) {\n\t\treturn errors.New(\"Unexpected non-nil head in setNewInitialHeadLocked\")\n\t}\n\tif md.Revision() != kbfsmd.RevisionInitial {\n\t\treturn errors.Errorf(\"setNewInitialHeadLocked unexpectedly called with revision %d\", md.Revision())\n\t}\n\treturn fbo.setHeadLocked(ctx, lState, md, headTrusted)\n}\n\n// setInitialHeadTrustedLocked is for when the given RootMetadata\n// was fetched due to a user action, and will be checked against the\n// TLF name.\nfunc (fbo *folderBranchOps) setInitialHeadTrustedLocked(ctx context.Context,\n\tlState *lockState, md ImmutableRootMetadata) error {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\tfbo.headLock.AssertLocked(lState)\n\tif fbo.head != (ImmutableRootMetadata{}) {\n\t\treturn errors.New(\"Unexpected non-nil head in setInitialHeadUntrustedLocked\")\n\t}\n\treturn fbo.setHeadLocked(ctx, lState, md, headTrusted)\n}\n\n// setHeadSuccessorLocked is for when we're applying updates from the\n// server or when we're applying new updates we created ourselves.\nfunc (fbo *folderBranchOps) setHeadSuccessorLocked(ctx context.Context,\n\tlState *lockState, md ImmutableRootMetadata, rebased bool) error {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\tfbo.headLock.AssertLocked(lState)\n\tif fbo.head == (ImmutableRootMetadata{}) {\n\t\t// This can happen in tests via SyncFromServer().\n\t\treturn fbo.setInitialHeadTrustedLocked(ctx, lState, md)\n\t}\n\n\tif !rebased {\n\t\terr := fbo.head.CheckValidSuccessor(fbo.head.mdID, md.ReadOnly())\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\toldHandle := fbo.head.GetTlfHandle()\n\tnewHandle := md.GetTlfHandle()\n\n\t// Newer handles should be equal or more resolved over time.\n\t//\n\t// TODO: In some cases, they shouldn't, e.g. if we're on an\n\t// unmerged branch. Add checks for this.\n\tresolvesTo, partialResolvedOldHandle, err :=\n\t\toldHandle.ResolvesTo(\n\t\t\tctx, fbo.config.Codec(), fbo.config.KBPKI(),\n\t\t\tconstIDGetter{fbo.id()}, fbo.config.KBPKI(), *newHandle)\n\tif err != nil {\n\t\tfbo.log.CDebugf(ctx, \"oldHandle=%+v, newHandle=%+v: err=%+v\", oldHandle, newHandle, err)\n\t\treturn err\n\t}\n\n\toldName := oldHandle.GetCanonicalName()\n\tnewName := newHandle.GetCanonicalName()\n\n\tif !resolvesTo {\n\t\tfbo.log.CDebugf(ctx, \"Incompatible handle error, \"+\n\t\t\t\"oldHandle: %#v, partialResolvedOldHandle: %#v, newHandle: %#v\",\n\t\t\toldHandle, partialResolvedOldHandle, newHandle)\n\t\treturn IncompatibleHandleError{\n\t\t\toldName,\n\t\t\tpartialResolvedOldHandle.GetCanonicalName(),\n\t\t\tnewName,\n\t\t}\n\t}\n\n\terr = fbo.setHeadLocked(ctx, lState, md, headTrusted)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif oldName != newName {\n\t\tfbo.log.CDebugf(ctx, \"Handle changed (%s -> %s)\",\n\t\t\toldName, newName)\n\n\t\tfbo.config.MDCache().ChangeHandleForID(oldHandle, newHandle)\n\t\t// If the handle has changed, send out a notification.\n\t\tfbo.observers.tlfHandleChange(ctx, fbo.head.GetTlfHandle())\n\t\t// Also the folder should be re-identified given the\n\t\t// newly-resolved assertions.\n\t\tfunc() {\n\t\t\tfbo.identifyLock.Lock()\n\t\t\tdefer fbo.identifyLock.Unlock()\n\t\t\tfbo.identifyDone = false\n\t\t}()\n\t}\n\n\treturn nil\n}\n\n// setHeadPredecessorLocked is for when we're unstaging updates.\nfunc (fbo *folderBranchOps) setHeadPredecessorLocked(ctx context.Context,\n\tlState *lockState, md ImmutableRootMetadata) error {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\tfbo.headLock.AssertLocked(lState)\n\tif fbo.head == (ImmutableRootMetadata{}) {\n\t\treturn errors.New(\"Unexpected nil head in setHeadPredecessorLocked\")\n\t}\n\tif fbo.head.Revision() <= kbfsmd.RevisionInitial {\n\t\treturn errors.Errorf(\"setHeadPredecessorLocked unexpectedly called with revision %d\", fbo.head.Revision())\n\t}\n\n\tif fbo.head.MergedStatus() != kbfsmd.Unmerged {\n\t\treturn errors.New(\"Unexpected merged head in setHeadPredecessorLocked\")\n\t}\n\n\terr := md.CheckValidSuccessor(md.mdID, fbo.head.ReadOnly())\n\tif err != nil {\n\t\treturn err\n\t}\n\n\toldHandle := fbo.head.GetTlfHandle()\n\tnewHandle := md.GetTlfHandle()\n\n\t// The two handles must be the same, since no rekeying is done\n\t// while unmerged.\n\n\teq, err := oldHandle.Equals(fbo.config.Codec(), *newHandle)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif !eq {\n\t\treturn errors.Errorf(\n\t\t\t\"head handle %v unexpectedly not equal to new handle = %v\",\n\t\t\toldHandle, newHandle)\n\t}\n\n\treturn fbo.setHeadLocked(ctx, lState, md, headTrusted)\n}\n\n// setHeadConflictResolvedLocked is for when we're setting the merged\n// update with resolved conflicts.\nfunc (fbo *folderBranchOps) setHeadConflictResolvedLocked(ctx context.Context,\n\tlState *lockState, md ImmutableRootMetadata) error {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\tfbo.headLock.AssertLocked(lState)\n\tif fbo.head.MergedStatus() != kbfsmd.Unmerged {\n\t\treturn errors.New(\"Unexpected merged head in setHeadConflictResolvedLocked\")\n\t}\n\tif md.MergedStatus() != kbfsmd.Merged {\n\t\treturn errors.New(\"Unexpected unmerged update in setHeadConflictResolvedLocked\")\n\t}\n\n\treturn fbo.setHeadLocked(ctx, lState, md, headTrusted)\n}\n\nfunc (fbo *folderBranchOps) identifyOnce(\n\tctx context.Context, md ReadOnlyRootMetadata) error {\n\tfbo.identifyLock.Lock()\n\tdefer fbo.identifyLock.Unlock()\n\n\tei := getExtendedIdentify(ctx)\n\tif fbo.identifyDone && !ei.behavior.AlwaysRunIdentify() {\n\t\t// TODO: provide a way for the service to break this cache when identify\n\t\t// state changes on a TLF. For now, we do it this way to make chat work.\n\t\treturn nil\n\t}\n\n\th := md.GetTlfHandle()\n\tfbo.log.CDebugf(ctx, \"Running identifies on %s\", h.GetCanonicalPath())\n\tkbpki := fbo.config.KBPKI()\n\terr := identifyHandle(ctx, kbpki, kbpki, h)\n\tif err != nil {\n\t\tfbo.log.CDebugf(ctx, \"Identify finished with error: %v\", err)\n\t\t// For now, if the identify fails, let the\n\t\t// next function to hit this code path retry.\n\t\treturn err\n\t}\n\n\tif ei.behavior.WarningInsteadOfErrorOnBrokenTracks() &&\n\t\tlen(ei.getTlfBreakAndClose().Breaks) > 0 {\n\t\tfbo.log.CDebugf(ctx,\n\t\t\t\"Identify finished with no error but broken proof warnings\")\n\t} else if ei.behavior == keybase1.TLFIdentifyBehavior_CHAT_SKIP {\n\t\tfbo.log.CDebugf(ctx, \"Identify skipped\")\n\t} else {\n\t\tfbo.log.CDebugf(ctx, \"Identify finished successfully\")\n\t\tfbo.identifyDone = true\n\t\tfbo.identifyTime = fbo.config.Clock().Now()\n\t}\n\treturn nil\n}\n\n// getMDForRead returns an existing md for a read operation. Note that\n// mds will not be fetched here.\nfunc (fbo *folderBranchOps) getMDForRead(\n\tctx context.Context, lState *lockState, rtype mdReadType) (\n\tmd ImmutableRootMetadata, err error) {\n\tif rtype != mdReadNeedIdentify && rtype != mdReadNoIdentify {\n\t\tpanic(\"Invalid rtype in getMDLockedForRead\")\n\t}\n\n\tmd = fbo.getTrustedHead(lState)\n\tif md != (ImmutableRootMetadata{}) {\n\t\tif rtype != mdReadNoIdentify {\n\t\t\terr = fbo.identifyOnce(ctx, md.ReadOnly())\n\t\t}\n\t\treturn md, err\n\t}\n\n\treturn ImmutableRootMetadata{}, MDWriteNeededInRequest{}\n}\n\n// GetTLFHandle implements the KBFSOps interface for folderBranchOps.\nfunc (fbo *folderBranchOps) GetTLFHandle(ctx context.Context, node Node) (\n\t*TlfHandle, error) {\n\tlState := makeFBOLockState()\n\tmd, _ := fbo.getHead(lState)\n\treturn md.GetTlfHandle(), nil\n}\n\n// getMDForWriteOrRekeyLocked can fetch MDs, identify them and\n// contains the fancy logic. For reading use getMDLockedForRead.\n// Here we actually can fetch things from the server.\n// rekeys are untrusted.\nfunc (fbo *folderBranchOps) getMDForWriteOrRekeyLocked(\n\tctx context.Context, lState *lockState, mdType mdUpdateType) (\n\tmd ImmutableRootMetadata, err error) {\n\tdefer func() {\n\t\tif err != nil || mdType == mdRekey {\n\t\t\treturn\n\t\t}\n\t\terr = fbo.identifyOnce(ctx, md.ReadOnly())\n\t}()\n\n\tmd = fbo.getTrustedHead(lState)\n\tif md != (ImmutableRootMetadata{}) {\n\t\treturn md, nil\n\t}\n\n\t// MDs coming from from rekey notifications are marked untrusted.\n\t//\n\t// TODO: Make tests not take this code path.\n\tfbo.mdWriterLock.AssertLocked(lState)\n\n\t// Not in cache, fetch from server and add to cache.  First, see\n\t// if this device has any unmerged commits -- take the latest one.\n\tmdops := fbo.config.MDOps()\n\n\t// get the head of the unmerged branch for this device (if any)\n\tmd, err = mdops.GetUnmergedForTLF(ctx, fbo.id(), kbfsmd.NullBranchID)\n\tif err != nil {\n\t\treturn ImmutableRootMetadata{}, err\n\t}\n\n\tmergedMD, err := mdops.GetForTLF(ctx, fbo.id(), nil)\n\tif err != nil {\n\t\treturn ImmutableRootMetadata{}, err\n\t}\n\n\tif mergedMD == (ImmutableRootMetadata{}) {\n\t\treturn ImmutableRootMetadata{},\n\t\t\terrors.WithStack(NoMergedMDError{fbo.id()})\n\t}\n\n\tif md == (ImmutableRootMetadata{}) {\n\t\t// There are no unmerged MDs for this device, so just use the current head.\n\t\tmd = mergedMD\n\t} else {\n\t\tfunc() {\n\t\t\tfbo.headLock.Lock(lState)\n\t\t\tdefer fbo.headLock.Unlock(lState)\n\t\t\t// We don't need to do this for merged head\n\t\t\t// because the setHeadLocked() already does\n\t\t\t// that anyway.\n\t\t\tfbo.setLatestMergedRevisionLocked(ctx, lState, mergedMD.Revision(), false)\n\t\t}()\n\t}\n\n\tif md.data.Dir.Type != Dir && (!md.IsInitialized() || md.IsReadable()) {\n\t\treturn ImmutableRootMetadata{}, errors.Errorf(\"Got undecryptable RMD for %s: initialized=%t, readable=%t\", fbo.id(), md.IsInitialized(), md.IsReadable())\n\t}\n\n\tfbo.headLock.Lock(lState)\n\tdefer fbo.headLock.Unlock(lState)\n\theadStatus := headTrusted\n\tif mdType == mdRekey {\n\t\t// If we already have a head (that has been filled after the initial\n\t\t// check, but before we acquired the lock), then just return it.\n\t\tif fbo.head != (ImmutableRootMetadata{}) {\n\t\t\treturn fbo.head, nil\n\t\t}\n\t\theadStatus = headUntrusted\n\t}\n\terr = fbo.setHeadLocked(ctx, lState, md, headStatus)\n\tif err != nil {\n\t\treturn ImmutableRootMetadata{}, err\n\t}\n\n\treturn md, nil\n}\n\nfunc (fbo *folderBranchOps) getMDForReadHelper(\n\tctx context.Context, lState *lockState, rtype mdReadType) (ImmutableRootMetadata, error) {\n\tmd, err := fbo.getMDForRead(ctx, lState, rtype)\n\tif err != nil {\n\t\treturn ImmutableRootMetadata{}, err\n\t}\n\tif md.TlfID().Type() != tlf.Public {\n\t\tsession, err := fbo.config.KBPKI().GetCurrentSession(ctx)\n\t\tif err != nil {\n\t\t\treturn ImmutableRootMetadata{}, err\n\t\t}\n\t\tisReader, err := md.IsReader(ctx, fbo.config.KBPKI(), session.UID)\n\t\tif err != nil {\n\t\t\treturn ImmutableRootMetadata{}, err\n\t\t}\n\t\tif !isReader {\n\t\t\treturn ImmutableRootMetadata{}, NewReadAccessError(\n\t\t\t\tmd.GetTlfHandle(), session.Name, md.GetTlfHandle().GetCanonicalPath())\n\t\t}\n\t}\n\treturn md, nil\n}\n\n// getMostRecentFullyMergedMD is a helper method that returns the most\n// recent merged MD that has been flushed to the server.  This could\n// be different from the current local head if journaling is on.  If\n// the journal is on a branch, it returns an error.\nfunc (fbo *folderBranchOps) getMostRecentFullyMergedMD(ctx context.Context) (\n\tImmutableRootMetadata, error) {\n\tmergedRev, err := fbo.getJournalPredecessorRevision(ctx)\n\tif err != nil {\n\t\treturn ImmutableRootMetadata{}, err\n\t}\n\n\tif mergedRev == kbfsmd.RevisionUninitialized {\n\t\t// No unflushed journal entries, so use the local head.\n\t\tlState := makeFBOLockState()\n\t\treturn fbo.getMDForReadHelper(ctx, lState, mdReadNoIdentify)\n\t}\n\n\t// Otherwise, use the specified revision.\n\trmd, err := getSingleMD(ctx, fbo.config, fbo.id(), kbfsmd.NullBranchID,\n\t\tmergedRev, kbfsmd.Merged, nil)\n\tif err != nil {\n\t\treturn ImmutableRootMetadata{}, err\n\t}\n\n\tfbo.log.CDebugf(ctx, \"Most recent fully merged revision is %d\", mergedRev)\n\treturn rmd, nil\n}\n\nfunc (fbo *folderBranchOps) getMDForReadNoIdentify(\n\tctx context.Context, lState *lockState) (ImmutableRootMetadata, error) {\n\treturn fbo.getMDForReadHelper(ctx, lState, mdReadNoIdentify)\n}\n\nfunc (fbo *folderBranchOps) getMDForReadNeedIdentify(\n\tctx context.Context, lState *lockState) (ImmutableRootMetadata, error) {\n\treturn fbo.getMDForReadHelper(ctx, lState, mdReadNeedIdentify)\n}\n\n// getMDForReadNeedIdentifyOnMaybeFirstAccess should be called by a\n// code path (like chat) that might be accessing this folder for the\n// first time.  Other folderBranchOps methods like Lookup which know\n// the folder has already been accessed at least once (to get the root\n// node, for example) do not need to call this.  Unlike other getMD\n// calls, this one may return a nil ImmutableRootMetadata along with a\n// nil error, to indicate that there isn't any MD for this TLF yet and\n// one must be created by the caller.\nfunc (fbo *folderBranchOps) getMDForReadNeedIdentifyOnMaybeFirstAccess(\n\tctx context.Context, lState *lockState) (ImmutableRootMetadata, error) {\n\tmd, err := fbo.getMDForRead(ctx, lState, mdReadNeedIdentify)\n\n\tif _, ok := err.(MDWriteNeededInRequest); ok {\n\t\tfbo.mdWriterLock.Lock(lState)\n\t\tdefer fbo.mdWriterLock.Unlock(lState)\n\t\tmd, err = fbo.getMDForWriteOrRekeyLocked(ctx, lState, mdWrite)\n\t}\n\n\tif _, noMD := errors.Cause(err).(NoMergedMDError); noMD {\n\t\treturn ImmutableRootMetadata{}, nil\n\t}\n\n\tif err != nil {\n\t\treturn ImmutableRootMetadata{}, err\n\t}\n\n\tif md.TlfID().Type() != tlf.Public {\n\t\tsession, err := fbo.config.KBPKI().GetCurrentSession(ctx)\n\t\tif err != nil {\n\t\t\treturn ImmutableRootMetadata{}, err\n\t\t}\n\t\tisReader, err := md.IsReader(ctx, fbo.config.KBPKI(), session.UID)\n\t\tif !isReader {\n\t\t\treturn ImmutableRootMetadata{}, NewReadAccessError(\n\t\t\t\tmd.GetTlfHandle(), session.Name, md.GetTlfHandle().GetCanonicalPath())\n\t\t}\n\t}\n\n\treturn md, nil\n}\n\nfunc (fbo *folderBranchOps) getMDForWriteLockedForFilename(\n\tctx context.Context, lState *lockState, filename string) (\n\tImmutableRootMetadata, error) {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\n\tmd, err := fbo.getMDForWriteOrRekeyLocked(ctx, lState, mdWrite)\n\tif err != nil {\n\t\treturn ImmutableRootMetadata{}, err\n\t}\n\n\tsession, err := fbo.config.KBPKI().GetCurrentSession(ctx)\n\tif err != nil {\n\t\treturn ImmutableRootMetadata{}, err\n\t}\n\tisWriter, err := md.IsWriter(\n\t\tctx, fbo.config.KBPKI(), session.UID, session.VerifyingKey)\n\tif err != nil {\n\t\treturn ImmutableRootMetadata{}, err\n\t}\n\tif !isWriter {\n\t\treturn ImmutableRootMetadata{}, NewWriteAccessError(\n\t\t\tmd.GetTlfHandle(), session.Name, filename)\n\t}\n\n\treturn md, nil\n}\n\nfunc (fbo *folderBranchOps) getSuccessorMDForWriteLockedForFilename(\n\tctx context.Context, lState *lockState, filename string) (\n\t*RootMetadata, error) {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\n\tmd, err := fbo.getMDForWriteLockedForFilename(ctx, lState, filename)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Make a new successor of the current MD to hold the coming\n\t// writes.  The caller must pass this into `finalizeMDWriteLocked`\n\t// or the changes will be lost.\n\treturn md.MakeSuccessor(ctx, fbo.config.MetadataVersion(),\n\t\tfbo.config.Codec(),\n\t\tfbo.config.KeyManager(), fbo.config.KBPKI(), fbo.config.KBPKI(),\n\t\tmd.mdID, true)\n}\n\n// getSuccessorMDForWriteLocked returns a new RootMetadata object with\n// an incremented version number for modification. If the returned\n// object is put to the MDServer (via MDOps), mdWriterLock must be\n// held until then. (See comments for mdWriterLock above.)\nfunc (fbo *folderBranchOps) getSuccessorMDForWriteLocked(\n\tctx context.Context, lState *lockState) (*RootMetadata, error) {\n\treturn fbo.getSuccessorMDForWriteLockedForFilename(ctx, lState, \"\")\n}\n\nfunc (fbo *folderBranchOps) getMDForRekeyWriteLocked(\n\tctx context.Context, lState *lockState) (\n\trmd *RootMetadata, lastWriterVerifyingKey kbfscrypto.VerifyingKey,\n\twasRekeySet bool, err error) {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\n\tmd, err := fbo.getMDForWriteOrRekeyLocked(ctx, lState, mdRekey)\n\tif err != nil {\n\t\treturn nil, kbfscrypto.VerifyingKey{}, false, err\n\t}\n\n\tsession, err := fbo.config.KBPKI().GetCurrentSession(ctx)\n\tif err != nil {\n\t\treturn nil, kbfscrypto.VerifyingKey{}, false, err\n\t}\n\n\thandle := md.GetTlfHandle()\n\n\t// must be a reader or writer (it checks both.)\n\tif !handle.IsReader(session.UID) {\n\t\treturn nil, kbfscrypto.VerifyingKey{}, false,\n\t\t\tNewRekeyPermissionError(md.GetTlfHandle(), session.Name)\n\t}\n\n\tnewMd, err := md.MakeSuccessor(ctx, fbo.config.MetadataVersion(),\n\t\tfbo.config.Codec(),\n\t\tfbo.config.KeyManager(), fbo.config.KBPKI(), fbo.config.KBPKI(),\n\t\tmd.mdID, handle.IsWriter(session.UID))\n\tif err != nil {\n\t\treturn nil, kbfscrypto.VerifyingKey{}, false, err\n\t}\n\n\t// readers shouldn't modify writer metadata\n\tif !handle.IsWriter(session.UID) && !newMd.IsWriterMetadataCopiedSet() {\n\t\treturn nil, kbfscrypto.VerifyingKey{}, false,\n\t\t\tNewRekeyPermissionError(handle, session.Name)\n\t}\n\n\treturn newMd, md.LastModifyingWriterVerifyingKey(), md.IsRekeySet(), nil\n}\n\nfunc (fbo *folderBranchOps) nowUnixNano() int64 {\n\treturn fbo.config.Clock().Now().UnixNano()\n}\n\nfunc (fbo *folderBranchOps) maybeUnembedAndPutBlocks(ctx context.Context,\n\tmd *RootMetadata) (*blockPutState, error) {\n\tif fbo.config.BlockSplitter().ShouldEmbedBlockChanges(&md.data.Changes) {\n\t\treturn nil, nil\n\t}\n\n\tchargedTo, err := chargedToForTLF(\n\t\tctx, fbo.config.KBPKI(), fbo.config.KBPKI(), md.GetTlfHandle())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tbps := newBlockPutState(1)\n\terr = fbo.prepper.unembedBlockChanges(\n\t\tctx, bps, md, &md.data.Changes, chargedTo)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tdefer func() {\n\t\tif err != nil {\n\t\t\tfbo.fbm.cleanUpBlockState(md.ReadOnly(), bps, blockDeleteOnMDFail)\n\t\t}\n\t}()\n\n\tptrsToDelete, err := doBlockPuts(ctx, fbo.config.BlockServer(),\n\t\tfbo.config.BlockCache(), fbo.config.Reporter(), fbo.log, fbo.deferLog, md.TlfID(),\n\t\tmd.GetTlfHandle().GetCanonicalName(), *bps)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif len(ptrsToDelete) > 0 {\n\t\treturn nil, errors.Errorf(\"Unexpected pointers to delete after \"+\n\t\t\t\"unembedding block changes in gc op: %v\", ptrsToDelete)\n\t}\n\treturn bps, nil\n}\n\n// ResetRootBlock creates a new empty dir block and sets the given\n// metadata's root block to it.\nfunc ResetRootBlock(ctx context.Context, config Config,\n\trmd *RootMetadata) (Block, BlockInfo, ReadyBlockData, error) {\n\tnewDblock := NewDirBlock()\n\tchargedTo, err := chargedToForTLF(\n\t\tctx, config.KBPKI(), config.KBPKI(), rmd.GetTlfHandle())\n\tif err != nil {\n\t\treturn nil, BlockInfo{}, ReadyBlockData{}, err\n\t}\n\n\tinfo, plainSize, readyBlockData, err :=\n\t\tReadyBlock(ctx, config.BlockCache(), config.BlockOps(),\n\t\t\tconfig.Crypto(), rmd.ReadOnly(), newDblock, chargedTo,\n\t\t\tconfig.DefaultBlockType())\n\tif err != nil {\n\t\treturn nil, BlockInfo{}, ReadyBlockData{}, err\n\t}\n\n\tnow := config.Clock().Now().UnixNano()\n\trmd.data.Dir = DirEntry{\n\t\tBlockInfo: info,\n\t\tEntryInfo: EntryInfo{\n\t\t\tType:  Dir,\n\t\t\tSize:  uint64(plainSize),\n\t\t\tMtime: now,\n\t\t\tCtime: now,\n\t\t},\n\t}\n\tprevDiskUsage := rmd.DiskUsage()\n\trmd.SetDiskUsage(0)\n\t// Redundant, since this is called only for brand-new or\n\t// successor RMDs, but leave in to be defensive.\n\trmd.ClearBlockChanges()\n\tco := newCreateOpForRootDir()\n\trmd.AddOp(co)\n\trmd.AddRefBlock(rmd.data.Dir.BlockInfo)\n\t// Set unref bytes to the previous disk usage, so that the\n\t// accounting works out.\n\trmd.AddUnrefBytes(prevDiskUsage)\n\treturn newDblock, info, readyBlockData, nil\n}\n\nfunc (fbo *folderBranchOps) initMDLocked(\n\tctx context.Context, lState *lockState, md *RootMetadata) error {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\n\tsession, err := fbo.config.KBPKI().GetCurrentSession(ctx)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\thandle := md.GetTlfHandle()\n\n\t// make sure we're a writer before rekeying or putting any blocks.\n\tisWriter, err := md.IsWriter(\n\t\tctx, fbo.config.KBPKI(), session.UID, session.VerifyingKey)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif !isWriter {\n\t\treturn NewWriteAccessError(\n\t\t\thandle, session.Name, handle.GetCanonicalPath())\n\t}\n\n\tvar expectedKeyGen kbfsmd.KeyGen\n\tvar tlfCryptKey *kbfscrypto.TLFCryptKey\n\tswitch md.TypeForKeying() {\n\tcase tlf.PublicKeying:\n\t\texpectedKeyGen = kbfsmd.PublicKeyGen\n\tcase tlf.PrivateKeying:\n\t\tvar rekeyDone bool\n\t\t// create a new set of keys for this metadata\n\t\trekeyDone, tlfCryptKey, err = fbo.config.KeyManager().Rekey(ctx, md, false)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif !rekeyDone {\n\t\t\treturn errors.Errorf(\"Initial rekey unexpectedly not done for \"+\n\t\t\t\t\"private TLF %v\", md.TlfID())\n\t\t}\n\t\texpectedKeyGen = kbfsmd.FirstValidKeyGen\n\tcase tlf.TeamKeying:\n\t\t// Teams get their crypt key from the service, no need to\n\t\t// rekey in KBFS.\n\t\ttid, err := handle.FirstResolvedWriter().AsTeam()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tkeys, keyGen, err := fbo.config.KBPKI().GetTeamTLFCryptKeys(\n\t\t\tctx, tid, kbfsmd.UnspecifiedKeyGen)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif keyGen < kbfsmd.FirstValidKeyGen {\n\t\t\treturn errors.WithStack(\n\t\t\t\tkbfsmd.InvalidKeyGenerationError{TlfID: md.TlfID(), KeyGen: keyGen})\n\t\t}\n\t\texpectedKeyGen = keyGen\n\t\tmd.bareMd.SetLatestKeyGenerationForTeamTLF(keyGen)\n\t\tkey, ok := keys[keyGen]\n\t\tif !ok {\n\t\t\treturn errors.WithStack(\n\t\t\t\tkbfsmd.InvalidKeyGenerationError{TlfID: md.TlfID(), KeyGen: keyGen})\n\t\t}\n\t\ttlfCryptKey = &key\n\t}\n\tkeyGen := md.LatestKeyGeneration()\n\tif keyGen != expectedKeyGen {\n\t\treturn kbfsmd.InvalidKeyGenerationError{TlfID: md.TlfID(), KeyGen: keyGen}\n\t}\n\n\t// create a dblock since one doesn't exist yet\n\tnewDblock, info, readyBlockData, err := ResetRootBlock(ctx, fbo.config, md)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Some other thread got here first, so give up and let it go\n\t// before we push anything to the servers.\n\tif h, _ := fbo.getHead(lState); h != (ImmutableRootMetadata{}) {\n\t\tfbo.log.CDebugf(ctx, \"Head was already set, aborting\")\n\t\treturn nil\n\t}\n\n\tif err = PutBlockCheckLimitErrs(ctx, fbo.config.BlockServer(),\n\t\tfbo.config.Reporter(), md.TlfID(), info.BlockPointer, readyBlockData,\n\t\tmd.GetTlfHandle().GetCanonicalName()); err != nil {\n\t\treturn err\n\t}\n\terr = fbo.config.BlockCache().Put(\n\t\tinfo.BlockPointer, fbo.id(), newDblock, TransientEntry)\n\tif err != nil {\n\t\tfbo.log.CDebugf(\n\t\t\tctx, \"Error caching new block %v: %+v\", info.BlockPointer, err)\n\t}\n\n\tbps, err := fbo.maybeUnembedAndPutBlocks(ctx, md)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\terr = fbo.finalizeBlocks(ctx, bps)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Write out the new metadata.  If journaling is enabled, we don't\n\t// want the rekey to hit the journal and possibly end up on a\n\t// conflict branch, so push straight to the server.\n\tmdOps := fbo.config.MDOps()\n\tif jServer, err := GetJournalServer(fbo.config); err == nil {\n\t\tmdOps = jServer.delegateMDOps\n\t}\n\tirmd, err := mdOps.Put(\n\t\tctx, md, session.VerifyingKey, nil, keybase1.MDPriorityNormal)\n\tisConflict := isRevisionConflict(err)\n\tif err != nil && !isConflict {\n\t\treturn err\n\t} else if isConflict {\n\t\treturn RekeyConflictError{err}\n\t}\n\n\tmd.loadCachedBlockChanges(ctx, bps, fbo.log)\n\n\tfbo.headLock.Lock(lState)\n\tdefer fbo.headLock.Unlock(lState)\n\tif fbo.head != (ImmutableRootMetadata{}) {\n\t\treturn errors.Errorf(\n\t\t\t\"%v: Unexpected MD ID during new MD initialization: %v\",\n\t\t\tmd.TlfID(), fbo.head.mdID)\n\t}\n\n\tfbo.setNewInitialHeadLocked(ctx, lState, irmd)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// cache any new TLF crypt key\n\tif tlfCryptKey != nil {\n\t\terr = fbo.config.KeyCache().PutTLFCryptKey(\n\t\t\tmd.TlfID(), keyGen, *tlfCryptKey)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc (fbo *folderBranchOps) GetTLFCryptKeys(ctx context.Context,\n\th *TlfHandle) (keys []kbfscrypto.TLFCryptKey, id tlf.ID, err error) {\n\treturn nil, tlf.ID{}, errors.New(\"GetTLFCryptKeys is not supported by folderBranchOps\")\n}\n\nfunc (fbo *folderBranchOps) GetTLFID(ctx context.Context, h *TlfHandle) (tlf.ID, error) {\n\treturn tlf.ID{}, errors.New(\"GetTLFID is not supported by folderBranchOps\")\n}\n\nfunc (fbo *folderBranchOps) GetOrCreateRootNode(\n\tctx context.Context, h *TlfHandle, branch BranchName) (\n\tnode Node, ei EntryInfo, err error) {\n\treturn nil, EntryInfo{}, errors.New(\"GetOrCreateRootNode is not supported by folderBranchOps\")\n}\n\nfunc (fbo *folderBranchOps) GetRootNode(\n\tctx context.Context, h *TlfHandle, branch BranchName) (\n\tnode Node, ei EntryInfo, err error) {\n\treturn nil, EntryInfo{}, errors.New(\"GetRootNode is not supported by folderBranchOps\")\n}\n\nfunc (fbo *folderBranchOps) checkNode(node Node) error {\n\tfb := node.GetFolderBranch()\n\tif fb != fbo.folderBranch {\n\t\treturn WrongOpsError{fbo.folderBranch, fb}\n\t}\n\treturn nil\n}\n\nfunc (fbo *folderBranchOps) checkNodeForWrite(\n\tctx context.Context, node Node) error {\n\terr := fbo.checkNode(node)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif !node.Readonly(ctx) {\n\t\treturn nil\n\t}\n\n\t// This is a read-only node, so reject the write.\n\tp, err := fbo.pathFromNodeForRead(node)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn WriteToReadonlyNodeError{p.String()}\n}\n\n// SetInitialHeadFromServer sets the head to the given\n// ImmutableRootMetadata, which must be retrieved from the MD server.\nfunc (fbo *folderBranchOps) SetInitialHeadFromServer(\n\tctx context.Context, md ImmutableRootMetadata) (err error) {\n\tfbo.log.CDebugf(ctx, \"SetInitialHeadFromServer, revision=%d (%s)\",\n\t\tmd.Revision(), md.MergedStatus())\n\tdefer func() {\n\t\tfbo.deferLog.CDebugf(ctx,\n\t\t\t\"SetInitialHeadFromServer, revision=%d (%s) done: %+v\",\n\t\t\tmd.Revision(), md.MergedStatus(), err)\n\t}()\n\n\tif md.IsReadable() && fbo.config.Mode().PrefetchWorkers() > 0 {\n\t\t// We `Get` the root block to ensure downstream prefetches\n\t\t// occur.  Use a fresh context, in case `ctx` is canceled by\n\t\t// the caller before we complete.\n\t\tprefetchCtx := fbo.ctxWithFBOID(context.Background())\n\t\tfbo.log.CDebugf(ctx,\n\t\t\t\"Prefetching root block with a new context: FBOID=%s\",\n\t\t\tprefetchCtx.Value(CtxFBOIDKey))\n\t\t_ = fbo.config.BlockOps().BlockRetriever().Request(prefetchCtx,\n\t\t\tdefaultOnDemandRequestPriority, md, md.data.Dir.BlockPointer,\n\t\t\t&DirBlock{}, TransientEntry)\n\t} else {\n\t\tfbo.log.CDebugf(ctx,\n\t\t\t\"Setting an unreadable head with revision=%d\", md.Revision())\n\t}\n\n\t// Return early if the head is already set.  This avoids taking\n\t// mdWriterLock for no reason, and it also avoids any side effects\n\t// (e.g., calling `identifyOnce` and downloading the merged\n\t// head) if head is already set.\n\tlState := makeFBOLockState()\n\thead, headStatus := fbo.getHead(lState)\n\tif headStatus == headTrusted && head != (ImmutableRootMetadata{}) && head.mdID == md.mdID {\n\t\tfbo.log.CDebugf(ctx, \"Head MD already set to revision %d (%s), no \"+\n\t\t\t\"need to set initial head again\", md.Revision(), md.MergedStatus())\n\t\treturn nil\n\t}\n\n\treturn runUnlessCanceled(ctx, func() error {\n\t\tfb := FolderBranch{md.TlfID(), MasterBranch}\n\t\tif fb != fbo.folderBranch {\n\t\t\treturn WrongOpsError{fbo.folderBranch, fb}\n\t\t}\n\n\t\t// Always identify first when trying to initialize the folder,\n\t\t// even if we turn out not to be a writer.  (We can't rely on\n\t\t// the identifyOnce call in getMDLocked, because that isn't\n\t\t// called from the initialization code path when the local\n\t\t// user is not a valid writer.)  Also, we want to make sure we\n\t\t// fail before we set the head, otherwise future calls will\n\t\t// succeed incorrectly.\n\t\terr = fbo.identifyOnce(ctx, md.ReadOnly())\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tlState := makeFBOLockState()\n\n\t\tfbo.mdWriterLock.Lock(lState)\n\t\tdefer fbo.mdWriterLock.Unlock(lState)\n\n\t\tif md.MergedStatus() == kbfsmd.Unmerged {\n\t\t\tmdops := fbo.config.MDOps()\n\t\t\tmergedMD, err := mdops.GetForTLF(ctx, fbo.id(), nil)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tfunc() {\n\t\t\t\tfbo.headLock.Lock(lState)\n\t\t\t\tdefer fbo.headLock.Unlock(lState)\n\t\t\t\tfbo.setLatestMergedRevisionLocked(ctx, lState,\n\t\t\t\t\tmergedMD.Revision(), false)\n\t\t\t}()\n\t\t}\n\n\t\tfbo.headLock.Lock(lState)\n\t\tdefer fbo.headLock.Unlock(lState)\n\n\t\t// Only update the head the first time; later it will be\n\t\t// updated either directly via writes or through the\n\t\t// background update processor.\n\t\tif fbo.head == (ImmutableRootMetadata{}) {\n\t\t\terr = fbo.setInitialHeadTrustedLocked(ctx, lState, md)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t} else if headStatus == headUntrusted {\n\t\t\terr = fbo.validateHeadLocked(ctx, lState, md)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t})\n}\n\n// SetInitialHeadToNew creates a brand-new ImmutableRootMetadata\n// object and sets the head to that. This is trusted.\nfunc (fbo *folderBranchOps) SetInitialHeadToNew(\n\tctx context.Context, id tlf.ID, handle *TlfHandle) (err error) {\n\tfbo.log.CDebugf(ctx, \"SetInitialHeadToNew %s\", id)\n\tdefer func() {\n\t\tfbo.deferLog.CDebugf(ctx, \"SetInitialHeadToNew %s done: %+v\",\n\t\t\tid, err)\n\t}()\n\n\trmd, err := makeInitialRootMetadata(\n\t\tfbo.config.MetadataVersion(), id, handle)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn runUnlessCanceled(ctx, func() error {\n\t\tfb := FolderBranch{rmd.TlfID(), MasterBranch}\n\t\tif fb != fbo.folderBranch {\n\t\t\treturn WrongOpsError{fbo.folderBranch, fb}\n\t\t}\n\n\t\t// Always identify first when trying to initialize the folder,\n\t\t// even if we turn out not to be a writer.  (We can't rely on\n\t\t// the identifyOnce call in getMDLocked, because that isn't\n\t\t// called from the initialization code path when the local\n\t\t// user is not a valid writer.)  Also, we want to make sure we\n\t\t// fail before we set the head, otherwise future calls will\n\t\t// succeed incorrectly.\n\t\terr = fbo.identifyOnce(ctx, rmd.ReadOnly())\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tlState := makeFBOLockState()\n\n\t\tfbo.mdWriterLock.Lock(lState)\n\t\tdefer fbo.mdWriterLock.Unlock(lState)\n\t\treturn fbo.initMDLocked(ctx, lState, rmd)\n\t})\n}\n\nfunc getNodeIDStr(n Node) string {\n\tif n == nil {\n\t\treturn \"NodeID(nil)\"\n\t}\n\treturn fmt.Sprintf(\"NodeID(%v)\", n.GetID())\n}\n\nfunc (fbo *folderBranchOps) getRootNode(ctx context.Context) (\n\tnode Node, ei EntryInfo, handle *TlfHandle, err error) {\n\tfbo.log.CDebugf(ctx, \"getRootNode\")\n\tdefer func() {\n\t\tfbo.deferLog.CDebugf(ctx, \"getRootNode done: %s %+v\",\n\t\t\tgetNodeIDStr(node), err)\n\t}()\n\n\tlState := makeFBOLockState()\n\n\tvar md ImmutableRootMetadata\n\tmd, err = fbo.getMDForRead(ctx, lState, mdReadNoIdentify)\n\tif _, ok := err.(MDWriteNeededInRequest); ok {\n\t\tfunc() {\n\t\t\tfbo.mdWriterLock.Lock(lState)\n\t\t\tdefer fbo.mdWriterLock.Unlock(lState)\n\t\t\tmd, err = fbo.getMDForWriteOrRekeyLocked(ctx, lState, mdWrite)\n\t\t}()\n\t}\n\tif err != nil {\n\t\treturn nil, EntryInfo{}, nil, err\n\t}\n\n\t// we may be an unkeyed client\n\tif err := isReadableOrError(ctx, fbo.config.KBPKI(), md.ReadOnly()); err != nil {\n\t\treturn nil, EntryInfo{}, nil, err\n\t}\n\n\thandle = md.GetTlfHandle()\n\tnode, err = fbo.nodeCache.GetOrCreate(md.data.Dir.BlockPointer,\n\t\tstring(handle.GetCanonicalName()), nil)\n\tif err != nil {\n\t\treturn nil, EntryInfo{}, nil, err\n\t}\n\n\treturn node, md.Data().Dir.EntryInfo, handle, nil\n}\n\ntype makeNewBlock func() Block\n\n// pathFromNodeHelper() shouldn't be called except by the helper\n// functions below.\nfunc (fbo *folderBranchOps) pathFromNodeHelper(n Node) (path, error) {\n\tp := fbo.nodeCache.PathFromNode(n)\n\tif !p.isValid() {\n\t\treturn path{}, InvalidPathError{p}\n\t}\n\treturn p, nil\n}\n\n// Helper functions to clarify uses of pathFromNodeHelper() (see\n// nodeCache comments).\n\nfunc (fbo *folderBranchOps) pathFromNodeForRead(n Node) (path, error) {\n\treturn fbo.pathFromNodeHelper(n)\n}\n\nfunc (fbo *folderBranchOps) pathFromNodeForMDWriteLocked(\n\tlState *lockState, n Node) (path, error) {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\treturn fbo.pathFromNodeHelper(n)\n}\n\nfunc (fbo *folderBranchOps) getDirChildren(ctx context.Context, dir Node) (\n\tchildren map[string]EntryInfo, err error) {\n\tlState := makeFBOLockState()\n\n\tdirPath, err := fbo.pathFromNodeForRead(dir)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif fbo.nodeCache.IsUnlinked(dir) {\n\t\tfbo.log.CDebugf(ctx, \"Returning an empty children set for \"+\n\t\t\t\"unlinked directory %v\", dirPath.tailPointer())\n\t\treturn nil, nil\n\t}\n\n\tmd, err := fbo.getMDForReadNeedIdentify(ctx, lState)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn fbo.blocks.GetDirtyDirChildren(\n\t\tctx, lState, md.ReadOnly(), dirPath)\n}\n\nfunc (fbo *folderBranchOps) GetDirChildren(ctx context.Context, dir Node) (\n\tchildren map[string]EntryInfo, err error) {\n\tfbo.log.CDebugf(ctx, \"GetDirChildren %s\", getNodeIDStr(dir))\n\tdefer func() {\n\t\tfbo.deferLog.CDebugf(ctx, \"GetDirChildren %s done, %d entries: %+v\",\n\t\t\tgetNodeIDStr(dir), len(children), err)\n\t}()\n\n\terr = fbo.checkNode(dir)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar retChildren map[string]EntryInfo\n\terr = runUnlessCanceled(ctx, func() error {\n\t\tretChildren, err = fbo.getDirChildren(ctx, dir)\n\t\treturn err\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif dir.ShouldRetryOnDirRead(ctx) {\n\t\terr2 := fbo.SyncFromServer(ctx, fbo.folderBranch, nil)\n\t\tif err2 != nil {\n\t\t\tfbo.log.CDebugf(ctx, \"Error syncing before retry: %+v\", err2)\n\t\t\treturn nil, nil\n\t\t}\n\n\t\tfbo.log.CDebugf(ctx, \"Retrying GetDirChildren of an empty directory\")\n\t\terr = runUnlessCanceled(ctx, func() error {\n\t\t\tretChildren, err = fbo.getDirChildren(ctx, dir)\n\t\t\treturn err\n\t\t})\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn retChildren, nil\n}\n\nfunc (fbo *folderBranchOps) processMissedLookup(\n\tctx context.Context, dir Node, name string, missErr error) (\n\tnode Node, ei EntryInfo, err error) {\n\t// Check if the directory node wants to autocreate this.\n\tautocreate, ctx, et, sympath := dir.ShouldCreateMissedLookup(ctx, name)\n\tif !autocreate {\n\t\treturn nil, EntryInfo{}, missErr\n\t}\n\n\tif (sympath != \"\" && et != Sym) || (sympath == \"\" && et == Sym) {\n\t\treturn nil, EntryInfo{}, errors.Errorf(\n\t\t\t\"Invalid sympath %s for entry type %s\", sympath, et)\n\t}\n\n\tfbo.log.CDebugf(\n\t\tctx, \"Auto-creating %s of type %s after a missed lookup\", name, et)\n\tswitch et {\n\tcase File:\n\t\treturn fbo.CreateFile(ctx, dir, name, false, NoExcl)\n\tcase Exec:\n\t\treturn fbo.CreateFile(ctx, dir, name, true, NoExcl)\n\tcase Dir:\n\t\treturn fbo.CreateDir(ctx, dir, name)\n\tcase Sym:\n\t\tei, err := fbo.CreateLink(ctx, dir, name, sympath)\n\t\treturn nil, ei, err\n\tdefault:\n\t\treturn nil, EntryInfo{}, errors.Errorf(\"Unknown entry type %s\", et)\n\t}\n}\n\nfunc (fbo *folderBranchOps) lookup(ctx context.Context, dir Node, name string) (\n\tnode Node, de DirEntry, err error) {\n\tif fbo.nodeCache.IsUnlinked(dir) {\n\t\tfbo.log.CDebugf(ctx, \"Refusing a lookup for unlinked directory %v\",\n\t\t\tfbo.nodeCache.PathFromNode(dir).tailPointer())\n\t\treturn nil, DirEntry{}, NoSuchNameError{name}\n\t}\n\n\tlState := makeFBOLockState()\n\tmd, err := fbo.getMDForReadNeedIdentify(ctx, lState)\n\tif err != nil {\n\t\treturn nil, DirEntry{}, err\n\t}\n\n\tnode, de, err = fbo.blocks.Lookup(ctx, lState, md.ReadOnly(), dir, name)\n\tif _, isMiss := errors.Cause(err).(NoSuchNameError); isMiss {\n\t\tnode, de.EntryInfo, err = fbo.processMissedLookup(ctx, dir, name, err)\n\t\tif _, exists := errors.Cause(err).(NameExistsError); exists {\n\t\t\t// Someone raced us to create the entry, so return the\n\t\t\t// new entry.\n\t\t\tnode, de, err = fbo.blocks.Lookup(\n\t\t\t\tctx, lState, md.ReadOnly(), dir, name)\n\t\t}\n\t}\n\treturn node, de, err\n}\n\nfunc (fbo *folderBranchOps) Lookup(ctx context.Context, dir Node, name string) (\n\tnode Node, ei EntryInfo, err error) {\n\tfbo.log.CDebugf(ctx, \"Lookup %s %s\", getNodeIDStr(dir), name)\n\tdefer func() {\n\t\tfbo.deferLog.CDebugf(ctx, \"Lookup %s %s done: %v %+v\",\n\t\t\tgetNodeIDStr(dir), name, getNodeIDStr(node), err)\n\t}()\n\n\terr = fbo.checkNode(dir)\n\tif err != nil {\n\t\treturn nil, EntryInfo{}, err\n\t}\n\n\t// It's racy for the goroutine to write directly to return param\n\t// `node`, so use a new param for that.\n\tvar n Node\n\tvar de DirEntry\n\terr = runUnlessCanceled(ctx, func() error {\n\t\tvar err error\n\t\tn, de, err = fbo.lookup(ctx, dir, name)\n\t\treturn err\n\t})\n\t// Only retry the lookup potentially if the lookup missed.\n\tif err != nil {\n\t\tif _, isMiss := errors.Cause(err).(NoSuchNameError); !isMiss {\n\t\t\treturn nil, EntryInfo{}, err\n\t\t}\n\t}\n\n\tif dir.ShouldRetryOnDirRead(ctx) {\n\t\terr2 := fbo.SyncFromServer(ctx, fbo.folderBranch, nil)\n\t\tif err2 != nil {\n\t\t\tfbo.log.CDebugf(ctx, \"Error syncing before retry: %+v\", err2)\n\t\t\treturn n, de.EntryInfo, err\n\t\t}\n\n\t\tfbo.log.CDebugf(ctx, \"Retrying lookup of an empty directory\")\n\t\terr = runUnlessCanceled(ctx, func() error {\n\t\t\tvar err error\n\t\t\tn, de, err = fbo.lookup(ctx, dir, name)\n\t\t\treturn err\n\t\t})\n\t}\n\tif err != nil {\n\t\treturn nil, EntryInfo{}, err\n\t}\n\treturn n, de.EntryInfo, nil\n}\n\n// statEntry is like Stat, but it returns a DirEntry. This is used by\n// tests.\nfunc (fbo *folderBranchOps) statEntry(ctx context.Context, node Node) (\n\tde DirEntry, err error) {\n\terr = fbo.checkNode(node)\n\tif err != nil {\n\t\treturn DirEntry{}, err\n\t}\n\n\tlState := makeFBOLockState()\n\n\tnodePath, err := fbo.pathFromNodeForRead(node)\n\tif err != nil {\n\t\treturn DirEntry{}, err\n\t}\n\n\tvar md ImmutableRootMetadata\n\tif nodePath.hasValidParent() {\n\t\tmd, err = fbo.getMDForReadNeedIdentify(ctx, lState)\n\t} else {\n\t\t// If nodePath has no valid parent, it's just the TLF\n\t\t// root, so we don't need an identify in this case.\n\t\tmd, err = fbo.getMDForReadNoIdentify(ctx, lState)\n\t}\n\tif err != nil {\n\t\treturn DirEntry{}, err\n\t}\n\n\tif nodePath.hasValidParent() {\n\t\tde, err = fbo.blocks.GetDirtyEntryEvenIfDeleted(\n\t\t\tctx, lState, md.ReadOnly(), nodePath)\n\t\tif err != nil {\n\t\t\treturn DirEntry{}, err\n\t\t}\n\t} else {\n\t\t// nodePath is just the root.\n\t\tde = md.data.Dir\n\t\tde = fbo.blocks.UpdateDirtyEntry(ctx, lState, de)\n\t}\n\n\treturn de, nil\n}\n\nvar zeroPtr BlockPointer\n\ntype blockState struct {\n\tblockPtr       BlockPointer\n\tblock          Block\n\treadyBlockData ReadyBlockData\n\tsyncedCb       func() error\n\toldPtr         BlockPointer\n}\n\nfunc (fbo *folderBranchOps) Stat(ctx context.Context, node Node) (\n\tei EntryInfo, err error) {\n\tfbo.log.CDebugf(ctx, \"Stat %s\", getNodeIDStr(node))\n\tdefer func() {\n\t\tfbo.deferLog.CDebugf(ctx, \"Stat %s done: %+v\",\n\t\t\tgetNodeIDStr(node), err)\n\t}()\n\n\tvar de DirEntry\n\terr = runUnlessCanceled(ctx, func() error {\n\t\tde, err = fbo.statEntry(ctx, node)\n\t\treturn err\n\t})\n\tif err != nil {\n\t\treturn EntryInfo{}, err\n\t}\n\treturn de.EntryInfo, nil\n}\n\nfunc (fbo *folderBranchOps) GetNodeMetadata(ctx context.Context, node Node) (\n\tres NodeMetadata, err error) {\n\tfbo.log.CDebugf(ctx, \"GetNodeMetadata %s\", getNodeIDStr(node))\n\tdefer func() {\n\t\tfbo.deferLog.CDebugf(ctx, \"GetNodeMetadata %s done: %+v\",\n\t\t\tgetNodeIDStr(node), err)\n\t}()\n\n\tvar de DirEntry\n\terr = runUnlessCanceled(ctx, func() error {\n\t\tde, err = fbo.statEntry(ctx, node)\n\t\treturn err\n\t})\n\tif err != nil {\n\t\treturn res, err\n\t}\n\tres.BlockInfo = de.BlockInfo\n\n\tid := de.TeamWriter.AsUserOrTeam()\n\tif id.IsNil() {\n\t\tid = de.Writer\n\t}\n\tif id.IsNil() {\n\t\tid = de.Creator\n\t}\n\t// Only set the last resolved writer if it's really a user ID.\n\t// This works around an old teams bug where the TeamWriter isn't\n\t// set.  See KBFS-2939.\n\tif id.IsUser() {\n\t\tres.LastWriterUnverified, err =\n\t\t\tfbo.config.KBPKI().GetNormalizedUsername(ctx, id)\n\t\tif err != nil {\n\t\t\treturn res, err\n\t\t}\n\t}\n\tprefetchStatus := fbo.config.PrefetchStatus(ctx, fbo.id(),\n\t\tres.BlockInfo.BlockPointer)\n\tres.PrefetchStatus = prefetchStatus.String()\n\treturn res, nil\n}\n\n// blockPutState is an internal structure to track data when putting blocks\ntype blockPutState struct {\n\tblockStates []blockState\n}\n\nfunc newBlockPutState(length int) *blockPutState {\n\tbps := &blockPutState{}\n\tbps.blockStates = make([]blockState, 0, length)\n\treturn bps\n}\n\n// addNewBlock tracks a new block that will be put.  If syncedCb is\n// non-nil, it will be called whenever the put for that block is\n// complete (whether or not the put resulted in an error).  Currently\n// it will not be called if the block is never put (due to an earlier\n// error).\nfunc (bps *blockPutState) addNewBlock(\n\tblockPtr BlockPointer, block Block,\n\treadyBlockData ReadyBlockData, syncedCb func() error) {\n\tbps.blockStates = append(bps.blockStates,\n\t\tblockState{blockPtr, block, readyBlockData, syncedCb, zeroPtr})\n}\n\n// saveOldPtr stores the given BlockPointer as the old (pre-readied)\n// pointer for the most recent blockState.\nfunc (bps *blockPutState) saveOldPtr(oldPtr BlockPointer) {\n\tbps.blockStates[len(bps.blockStates)-1].oldPtr = oldPtr\n}\n\nfunc (bps *blockPutState) mergeOtherBps(other *blockPutState) {\n\tbps.blockStates = append(bps.blockStates, other.blockStates...)\n}\n\nfunc (bps *blockPutState) removeOtherBps(other *blockPutState) {\n\tif len(other.blockStates) == 0 {\n\t\treturn\n\t}\n\n\totherPtrs := make(map[BlockPointer]bool, len(other.blockStates))\n\tfor _, bs := range other.blockStates {\n\t\totherPtrs[bs.blockPtr] = true\n\t}\n\n\t// Assume that `other` is a subset of `bps` when initializing the\n\t// slice length.\n\tnewLen := len(bps.blockStates) - len(other.blockStates)\n\tif newLen < 0 {\n\t\tnewLen = 0\n\t}\n\n\t// Remove any blocks that appear in `other`.\n\tnewBlockStates := make([]blockState, 0, newLen)\n\tfor _, bs := range bps.blockStates {\n\t\tif otherPtrs[bs.blockPtr] {\n\t\t\tcontinue\n\t\t}\n\t\tnewBlockStates = append(newBlockStates, bs)\n\t}\n\tbps.blockStates = newBlockStates\n}\n\nfunc (bps *blockPutState) DeepCopy() *blockPutState {\n\tnewBps := &blockPutState{}\n\tnewBps.blockStates = make([]blockState, len(bps.blockStates))\n\tcopy(newBps.blockStates, bps.blockStates)\n\treturn newBps\n}\n\ntype localBcache map[BlockPointer]*DirBlock\n\n// Returns whether the given error is one that shouldn't block the\n// removal of a file or directory.\n//\n// TODO: Consider other errors recoverable, e.g. ones that arise from\n// present but corrupted blocks?\nfunc isRecoverableBlockErrorForRemoval(err error) bool {\n\treturn isRecoverableBlockError(err)\n}\n\nfunc isRetriableError(err error, retries int) bool {\n\t_, isExclOnUnmergedError := err.(ExclOnUnmergedError)\n\t_, isUnmergedSelfConflictError := err.(UnmergedSelfConflictError)\n\trecoverable := isExclOnUnmergedError || isUnmergedSelfConflictError ||\n\t\tisRecoverableBlockError(err)\n\treturn recoverable && retries < maxRetriesOnRecoverableErrors\n}\n\nfunc (fbo *folderBranchOps) finalizeBlocks(\n\tctx context.Context, bps *blockPutState) error {\n\tif bps == nil {\n\t\treturn nil\n\t}\n\tbcache := fbo.config.BlockCache()\n\tfor _, blockState := range bps.blockStates {\n\t\tnewPtr := blockState.blockPtr\n\t\t// only cache this block if we made a brand new block, not if\n\t\t// we just incref'd some other block.\n\t\tif !newPtr.IsFirstRef() {\n\t\t\tcontinue\n\t\t}\n\t\tif err := bcache.Put(newPtr, fbo.id(), blockState.block,\n\t\t\tTransientEntry); err != nil {\n\t\t\tfbo.log.CDebugf(\n\t\t\t\tctx, \"Error caching new block %v: %+v\", newPtr, err)\n\t\t}\n\t}\n\treturn nil\n}\n\n// Returns true if the passed error indicates a revision conflict.\nfunc isRevisionConflict(err error) bool {\n\tif err == nil {\n\t\treturn false\n\t}\n\t_, isConflictRevision := err.(kbfsmd.ServerErrorConflictRevision)\n\t_, isConflictPrevRoot := err.(kbfsmd.ServerErrorConflictPrevRoot)\n\t_, isConflictDiskUsage := err.(kbfsmd.ServerErrorConflictDiskUsage)\n\t_, isConditionFailed := err.(kbfsmd.ServerErrorConditionFailed)\n\t_, isConflictFolderMapping := err.(kbfsmd.ServerErrorConflictFolderMapping)\n\t_, isJournal := err.(MDJournalConflictError)\n\treturn isConflictRevision || isConflictPrevRoot ||\n\t\tisConflictDiskUsage || isConditionFailed ||\n\t\tisConflictFolderMapping || isJournal\n}\n\nfunc (fbo *folderBranchOps) getConvID(\n\tctx context.Context, handle *TlfHandle) (\n\tchat1.ConversationID, error) {\n\tfbo.convLock.Lock()\n\tdefer fbo.convLock.Unlock()\n\tif len(fbo.convID) == 0 {\n\t\tsession, err := fbo.config.KBPKI().GetCurrentSession(ctx)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tchannelName := string(session.Name)\n\n\t\tid, err := fbo.config.Chat().GetConversationID(\n\t\t\tctx, handle.GetCanonicalName(), fbo.id().Type(),\n\t\t\tchannelName, chat1.TopicType_KBFSFILEEDIT)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tfbo.log.CDebugf(ctx, \"Conversation ID is %s for this writer (%s)\",\n\t\t\tid, channelName)\n\t\tfbo.convID = id\n\t}\n\treturn fbo.convID, nil\n}\n\nfunc (fbo *folderBranchOps) sendEditNotifications(\n\tctx context.Context, rmd ImmutableRootMetadata, body string) error {\n\t// For now only write out the notifications if we're in test mode,\n\t// just in case we decide to change the notification format before\n\t// we launch.  TODO: turn this on for admins once we can test it\n\t// on staging.\n\tif !fbo.config.Mode().IsTestMode() {\n\t\treturn nil\n\t}\n\n\thandle := rmd.GetTlfHandle()\n\tconvID, err := fbo.getConvID(ctx, handle)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn fbo.config.Chat().SendTextMessage(\n\t\tctx, handle.GetCanonicalName(), fbo.id().Type(), convID, body)\n}\n\nfunc (fbo *folderBranchOps) makeEditNotifications(\n\tctx context.Context, rmd ImmutableRootMetadata) (\n\tedits []kbfsedits.NotificationMessage, err error) {\n\tif rmd.IsWriterMetadataCopiedSet() {\n\t\treturn nil, nil\n\t}\n\n\tif rmd.MergedStatus() != kbfsmd.Merged {\n\t\treturn nil, nil\n\t}\n\n\t// If this MD is coming from the journal or from the conflict\n\t// resolver, the final paths will not be set on the ops.  Use\n\t// crChains to set them.\n\tops := pathSortedOps(rmd.data.Changes.Ops)\n\n\tisResolution := false\n\tif len(ops) > 0 {\n\t\t_, isResolution = ops[0].(*resolutionOp)\n\t}\n\tif isResolution || TLFJournalEnabled(fbo.config, fbo.id()) {\n\t\tchains, err := newCRChainsForIRMDs(\n\t\t\tctx, fbo.config.Codec(), []ImmutableRootMetadata{rmd},\n\t\t\t&fbo.blocks, true)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\terr = fbo.blocks.populateChainPaths(ctx, fbo.log, chains, true)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tops = pathSortedOps(make([]op, 0, len(ops)))\n\t\tfor _, chain := range chains.byMostRecent {\n\t\t\tops = append(ops, chain.ops...)\n\t\t}\n\t\t// Make sure the ops are in increasing order by path length,\n\t\t// so e.g. file creates come before file modifies.\n\t\tsort.Sort(ops)\n\t}\n\n\trev := rmd.Revision()\n\t// We want the server's view of the time.\n\trevTime := rmd.localTimestamp\n\tif offset, ok := fbo.config.MDServer().OffsetFromServerTime(); ok {\n\t\trevTime = revTime.Add(-offset)\n\t}\n\n\tfor _, op := range ops {\n\t\tedit := op.ToEditNotification(\n\t\t\trev, revTime, rmd.lastWriterVerifyingKey,\n\t\t\trmd.LastModifyingWriter(), fbo.id())\n\t\tif edit != nil {\n\t\t\tedits = append(edits, *edit)\n\t\t}\n\t}\n\treturn edits, nil\n}\n\nfunc (fbo *folderBranchOps) handleEditNotifications(\n\tctx context.Context, rmd ImmutableRootMetadata) error {\n\tif !fbo.config.Mode().SendEditNotificationsEnabled() {\n\t\treturn nil\n\t}\n\n\tedits, err := fbo.makeEditNotifications(ctx, rmd)\n\tif err != nil {\n\t\treturn err\n\t}\n\tbody, err := kbfsedits.Prepare(edits)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn fbo.sendEditNotifications(ctx, rmd, body)\n}\n\nfunc (fbo *folderBranchOps) finalizeMDWriteLocked(ctx context.Context,\n\tlState *lockState, md *RootMetadata, bps *blockPutState, excl Excl,\n\tnotifyFn func(ImmutableRootMetadata) error) (\n\terr error) {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\n\t// finally, write out the new metadata\n\tmdops := fbo.config.MDOps()\n\n\tdoUnmergedPut := true\n\tmergedRev := kbfsmd.RevisionUninitialized\n\n\toldPrevRoot := md.PrevRoot()\n\n\tvar irmd ImmutableRootMetadata\n\n\t// This puts on a delay on any cancellations arriving to ctx. It is intended\n\t// to work sort of like a critical section, except that there isn't an\n\t// explicit call to exit the critical section. The cancellation, if any, is\n\t// triggered after a timeout (i.e.\n\t// fbo.config.DelayedCancellationGracePeriod()).\n\t//\n\t// The purpose of trying to avoid cancellation once we start MD write is to\n\t// avoid having an unpredictable perceived MD state. That is, when\n\t// runUnlessCanceled returns Canceled on cancellation, application receives\n\t// an EINTR, and would assume the operation didn't succeed. But the MD write\n\t// continues, and there's a chance the write will succeed, meaning the\n\t// operation succeeds. This contradicts with the application's perception\n\t// through error code and can lead to horrible situations. An easily caught\n\t// situation is when application calls Create with O_EXCL set, gets an EINTR\n\t// while MD write succeeds, retries and gets an EEXIST error. If users hit\n\t// Ctrl-C, this might not be a big deal. However, it also happens for other\n\t// interrupts.  For applications that use signals to communicate, e.g.\n\t// SIGALRM and SIGUSR1, this can happen pretty often, which renders broken.\n\tif err = EnableDelayedCancellationWithGracePeriod(\n\t\tctx, fbo.config.DelayedCancellationGracePeriod()); err != nil {\n\t\treturn err\n\t}\n\t// we don't explicitly clean up (by using a defer) CancellationDelayer here\n\t// because sometimes fuse makes another call using the same ctx.  For example, in\n\t// fuse's Create call handler, a dir.Create is followed by an Attr call. If\n\t// we do a deferred cleanup here, if an interrupt has been received, it can\n\t// cause ctx to be canceled before Attr call finishes, which causes FUSE to\n\t// return EINTR for the Create request. But at this point, the request may\n\t// have already succeeded. Returning EINTR makes application thinks the file\n\t// is not created successfully.\n\n\terr = fbo.finalizeBlocks(ctx, bps)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tsession, err := fbo.config.KBPKI().GetCurrentSession(ctx)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif fbo.isMasterBranchLocked(lState) {\n\t\t// only do a normal Put if we're not already staged.\n\t\tirmd, err = mdops.Put(\n\t\t\tctx, md, session.VerifyingKey, nil, keybase1.MDPriorityNormal)\n\t\tif doUnmergedPut = isRevisionConflict(err); doUnmergedPut {\n\t\t\tfbo.log.CDebugf(ctx, \"Conflict: %v\", err)\n\t\t\tmergedRev = md.Revision()\n\n\t\t\tif excl == WithExcl {\n\t\t\t\t// If this was caused by an exclusive create, we shouldn't do an\n\t\t\t\t// kbfsmd.UnmergedPut, but rather try to get newest update from server, and\n\t\t\t\t// retry afterwards.\n\t\t\t\terr = fbo.getAndApplyMDUpdates(ctx,\n\t\t\t\t\tlState, nil, fbo.applyMDUpdatesLocked)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\treturn ExclOnUnmergedError{}\n\t\t\t}\n\t\t} else if err != nil {\n\t\t\treturn err\n\t\t}\n\t} else if excl == WithExcl {\n\t\treturn ExclOnUnmergedError{}\n\t}\n\n\tdoResolve := false\n\tresolveMergedRev := mergedRev\n\tif doUnmergedPut {\n\t\t// We're out of date, and this is not an exclusive write, so put it as an\n\t\t// unmerged MD.\n\t\tirmd, err = mdops.PutUnmerged(ctx, md, session.VerifyingKey)\n\t\tif isRevisionConflict(err) {\n\t\t\t// Self-conflicts are retried in `doMDWriteWithRetry`.\n\t\t\treturn UnmergedSelfConflictError{err}\n\t\t} else if err != nil {\n\t\t\t// If a PutUnmerged fails, we are in a bad situation: if\n\t\t\t// we fail, but the put succeeded, then dirty data will\n\t\t\t// remain cached locally and will be re-tried\n\t\t\t// (non-idempotently) on the next sync call.  This should\n\t\t\t// be a very rare situation when journaling is enabled, so\n\t\t\t// instead let's pretend it succeeded so that the cached\n\t\t\t// data is cleared and the nodeCache is updated.  If we're\n\t\t\t// wrong, and the update didn't make it to the server,\n\t\t\t// then the next call will get an\n\t\t\t// kbfsmd.UnmergedSelfConflictError but fail to find any new\n\t\t\t// updates and fail the operation, but things will get\n\t\t\t// fixed up once conflict resolution finally completes.\n\t\t\t//\n\t\t\t// TODO: how confused will the kernel cache get if the\n\t\t\t// pointers are updated but the file system operation\n\t\t\t// still gets an error returned by the wrapper function\n\t\t\t// that calls us (in the event of a user cancellation)?\n\t\t\tfbo.log.CInfof(ctx, \"Ignoring a PutUnmerged error: %+v\", err)\n\t\t\terr = encryptMDPrivateData(\n\t\t\t\tctx, fbo.config.Codec(), fbo.config.Crypto(),\n\t\t\t\tfbo.config.Crypto(), fbo.config.KeyManager(), session.UID, md)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tmdID, err := kbfsmd.MakeID(fbo.config.Codec(), md.bareMd)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tirmd = MakeImmutableRootMetadata(\n\t\t\t\tmd, session.VerifyingKey, mdID, fbo.config.Clock().Now(), true)\n\t\t\terr = fbo.config.MDCache().Put(irmd)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\tbid := md.BID()\n\t\tfbo.setBranchIDLocked(lState, bid)\n\t\tdoResolve = true\n\t} else {\n\t\tfbo.setBranchIDLocked(lState, kbfsmd.NullBranchID)\n\n\t\tif md.IsRekeySet() && !md.IsWriterMetadataCopiedSet() {\n\t\t\t// Queue this folder for rekey if the bit was set and it's not a copy.\n\t\t\t// This is for the case where we're coming out of conflict resolution.\n\t\t\t// So why don't we do this in finalizeResolution? Well, we do but we don't\n\t\t\t// want to block on a rekey so we queue it. Because of that it may fail\n\t\t\t// due to a conflict with some subsequent write. By also handling it here\n\t\t\t// we'll always retry if we notice we haven't been successful in clearing\n\t\t\t// the bit yet. Note that I haven't actually seen this happen but it seems\n\t\t\t// theoretically possible.\n\t\t\tdefer fbo.config.RekeyQueue().Enqueue(md.TlfID())\n\t\t}\n\t}\n\n\tmd.loadCachedBlockChanges(ctx, bps, fbo.log)\n\n\trebased := (oldPrevRoot != md.PrevRoot())\n\tif rebased {\n\t\tbid := md.BID()\n\t\tfbo.setBranchIDLocked(lState, bid)\n\t\tdoResolve = true\n\t\tresolveMergedRev = kbfsmd.RevisionUninitialized\n\t}\n\n\tfbo.headLock.Lock(lState)\n\tdefer fbo.headLock.Unlock(lState)\n\terr = fbo.setHeadSuccessorLocked(ctx, lState, irmd, rebased)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Send edit notifications and archive the old, unref'd blocks if\n\t// journaling is off.\n\tif !TLFJournalEnabled(fbo.config, fbo.id()) {\n\t\tfbo.editActivity.Add(1)\n\t\tgo func() {\n\t\t\tdefer fbo.editActivity.Done()\n\t\t\tctx, cancelFunc := fbo.newCtxWithFBOID()\n\t\t\tdefer cancelFunc()\n\t\t\terr := fbo.handleEditNotifications(ctx, irmd)\n\t\t\tif err != nil {\n\t\t\t\tfbo.log.CWarningf(ctx, \"Couldn't send edit notifications for \"+\n\t\t\t\t\t\"revision %d: %+v\", irmd.Revision(), err)\n\t\t\t}\n\t\t}()\n\t\tfbo.fbm.archiveUnrefBlocks(irmd.ReadOnly())\n\t}\n\n\t// Call Resolve() after the head is set, to make sure it fetches\n\t// the correct unmerged MD range during resolution.\n\tif doResolve {\n\t\tfbo.cr.Resolve(ctx, md.Revision(), resolveMergedRev)\n\t}\n\n\tif notifyFn != nil {\n\t\terr := notifyFn(irmd)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (fbo *folderBranchOps) waitForJournalLocked(ctx context.Context,\n\tlState *lockState, jServer *JournalServer) error {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\n\tif !TLFJournalEnabled(fbo.config, fbo.id()) {\n\t\t// Nothing to do.\n\t\treturn nil\n\t}\n\n\tif err := jServer.Wait(ctx, fbo.id()); err != nil {\n\t\treturn err\n\t}\n\n\t// Make sure everything flushed successfully, since we're holding\n\t// the writer lock, no other revisions could have snuck in.\n\tjStatus, err := jServer.JournalStatus(fbo.id())\n\tif err != nil {\n\t\treturn err\n\t}\n\tif jStatus.RevisionEnd != kbfsmd.RevisionUninitialized {\n\t\treturn errors.Errorf(\"Couldn't flush all MD revisions; current \"+\n\t\t\t\"revision end for the journal is %d\", jStatus.RevisionEnd)\n\t}\n\tif jStatus.LastFlushErr != \"\" {\n\t\treturn errors.Errorf(\"Couldn't flush the journal: %s\",\n\t\t\tjStatus.LastFlushErr)\n\t}\n\n\treturn nil\n}\n\nfunc (fbo *folderBranchOps) finalizeMDRekeyWriteLocked(ctx context.Context,\n\tlState *lockState, md *RootMetadata,\n\tlastWriterVerifyingKey kbfscrypto.VerifyingKey) (err error) {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\n\toldPrevRoot := md.PrevRoot()\n\n\t// Write out the new metadata.  If journaling is enabled, we don't\n\t// want the rekey to hit the journal and possibly end up on a\n\t// conflict branch, so wait for the journal to flush and then push\n\t// straight to the server.  TODO: we're holding the writer lock\n\t// while flushing the journal here (just like for exclusive\n\t// writes), which may end up blocking incoming writes for a long\n\t// time.  Rekeys are pretty rare, but if this becomes an issue\n\t// maybe we should consider letting these hit the journal and\n\t// scrubbing them when converting it to a branch.\n\tmdOps := fbo.config.MDOps()\n\tif jServer, err := GetJournalServer(fbo.config); err == nil {\n\t\tif err = fbo.waitForJournalLocked(ctx, lState, jServer); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tmdOps = jServer.delegateMDOps\n\t}\n\n\tvar key kbfscrypto.VerifyingKey\n\tif md.IsWriterMetadataCopiedSet() {\n\t\tkey = lastWriterVerifyingKey\n\t} else {\n\t\tvar err error\n\t\tsession, err := fbo.config.KBPKI().GetCurrentSession(ctx)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tkey = session.VerifyingKey\n\t}\n\n\tirmd, err := mdOps.Put(ctx, md, key, nil, keybase1.MDPriorityNormal)\n\tisConflict := isRevisionConflict(err)\n\tif err != nil && !isConflict {\n\t\treturn err\n\t}\n\n\tif isConflict {\n\t\t// Drop this block. We've probably collided with someone also\n\t\t// trying to rekey the same folder but that's not necessarily\n\t\t// the case. We'll queue another rekey just in case. It should\n\t\t// be safe as it's idempotent. We don't want any rekeys present\n\t\t// in unmerged history or that will just make a mess.\n\t\tfbo.config.RekeyQueue().Enqueue(md.TlfID())\n\t\treturn RekeyConflictError{err}\n\t}\n\n\tfbo.setBranchIDLocked(lState, kbfsmd.NullBranchID)\n\n\trebased := (oldPrevRoot != md.PrevRoot())\n\tif rebased {\n\t\tbid := md.BID()\n\t\tfbo.setBranchIDLocked(lState, bid)\n\t\tfbo.cr.Resolve(ctx, md.Revision(), kbfsmd.RevisionUninitialized)\n\t}\n\n\tmd.loadCachedBlockChanges(ctx, nil, fbo.log)\n\n\tfbo.headLock.Lock(lState)\n\tdefer fbo.headLock.Unlock(lState)\n\terr = fbo.setHeadSuccessorLocked(ctx, lState, irmd, rebased)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Explicitly set the latest merged revision, since if journaling\n\t// is on, `setHeadLocked` will not do it for us (even though\n\t// rekeys bypass the journal).\n\tfbo.setLatestMergedRevisionLocked(ctx, lState, md.Revision(), false)\n\treturn nil\n}\n\nfunc (fbo *folderBranchOps) finalizeGCOp(ctx context.Context, gco *GCOp) (\n\terr error) {\n\tlState := makeFBOLockState()\n\t// Lock the folder so we can get an internally-consistent MD\n\t// revision number.\n\tfbo.mdWriterLock.Lock(lState)\n\tdefer fbo.mdWriterLock.Unlock(lState)\n\n\tmd, err := fbo.getSuccessorMDForWriteLocked(ctx, lState)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif md.MergedStatus() == kbfsmd.Unmerged {\n\t\treturn UnexpectedUnmergedPutError{}\n\t}\n\n\tmd.AddOp(gco)\n\t// TODO: if the revision number of this new commit is sequential\n\t// with `LatestRev`, we can probably change this to\n\t// `gco.LatestRev+1`.\n\tmd.SetLastGCRevision(gco.LatestRev)\n\n\tbps, err := fbo.maybeUnembedAndPutBlocks(ctx, md)\n\tif err != nil {\n\t\treturn err\n\t}\n\toldPrevRoot := md.PrevRoot()\n\n\terr = fbo.finalizeBlocks(ctx, bps)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tsession, err := fbo.config.KBPKI().GetCurrentSession(ctx)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// finally, write out the new metadata\n\tirmd, err := fbo.config.MDOps().Put(\n\t\tctx, md, session.VerifyingKey, nil, keybase1.MDPriorityNormal)\n\tif err != nil {\n\t\t// Don't allow garbage collection to put us into a conflicting\n\t\t// state; just wait for the next period.\n\t\treturn err\n\t}\n\n\tfbo.setBranchIDLocked(lState, kbfsmd.NullBranchID)\n\tmd.loadCachedBlockChanges(ctx, bps, fbo.log)\n\n\trebased := (oldPrevRoot != md.PrevRoot())\n\tif rebased {\n\t\tbid := md.BID()\n\t\tfbo.setBranchIDLocked(lState, bid)\n\t\tfbo.cr.Resolve(ctx, md.Revision(), kbfsmd.RevisionUninitialized)\n\t}\n\n\tfbo.headLock.Lock(lState)\n\tdefer fbo.headLock.Unlock(lState)\n\terr = fbo.setHeadSuccessorLocked(ctx, lState, irmd, rebased)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn fbo.notifyBatchLocked(ctx, lState, irmd)\n}\n\n// CtxAllowNameKeyType is the type for a context allowable name override key.\ntype CtxAllowNameKeyType int\n\nconst (\n\t// CtxAllowNameKey can be used to set a value in a context, and\n\t// that value will be treated as an allowable directory entry\n\t// name, even if it also matches a disallowed prefix.  The value\n\t// must be of type `string`, or it will panic.\n\tCtxAllowNameKey CtxAllowNameKeyType = iota\n)\n\nfunc checkDisallowedPrefixes(ctx context.Context, name string) error {\n\tfor _, prefix := range disallowedPrefixes {\n\t\tif strings.HasPrefix(name, prefix) {\n\t\t\tif allowedName := ctx.Value(CtxAllowNameKey); allowedName != nil {\n\t\t\t\t// Allow specialized KBFS programs (like the kbgit remote\n\t\t\t\t// helper) to bypass the disallowed prefix check.\n\t\t\t\tif name == allowedName.(string) {\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn DisallowedPrefixError{name, prefix}\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (fbo *folderBranchOps) checkNewDirSize(ctx context.Context,\n\tlState *lockState, md ReadOnlyRootMetadata,\n\tdirPath path, newName string) error {\n\t// Check that the directory isn't past capacity already.\n\tvar currSize uint64\n\tif dirPath.hasValidParent() {\n\t\tde, err := fbo.blocks.GetDirtyEntry(ctx, lState, md, dirPath)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcurrSize = de.Size\n\t} else {\n\t\t// dirPath is just the root.\n\t\tcurrSize = md.data.Dir.Size\n\t}\n\t// Just an approximation since it doesn't include the size of the\n\t// directory entry itself, but that's ok -- at worst it'll be an\n\t// off-by-one-entry error, and since there's a maximum name length\n\t// we can't get in too much trouble.\n\tif currSize+uint64(len(newName)) > fbo.config.MaxDirBytes() {\n\t\treturn DirTooBigError{dirPath, currSize + uint64(len(newName)),\n\t\t\tfbo.config.MaxDirBytes()}\n\t}\n\treturn nil\n}\n\n// PathType returns path type\nfunc (fbo *folderBranchOps) PathType() PathType {\n\tswitch fbo.folderBranch.Tlf.Type() {\n\tcase tlf.Public:\n\t\treturn PublicPathType\n\tcase tlf.Private:\n\t\treturn PrivatePathType\n\tcase tlf.SingleTeam:\n\t\treturn SingleTeamPathType\n\tdefault:\n\t\tpanic(fmt.Sprintf(\"Unknown TLF type: %s\", fbo.folderBranch.Tlf.Type()))\n\t}\n}\n\n// canonicalPath returns full canonical path for dir node and name.\nfunc (fbo *folderBranchOps) canonicalPath(ctx context.Context, dir Node, name string) (string, error) {\n\tdirPath, err := fbo.pathFromNodeForRead(dir)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\treturn BuildCanonicalPath(fbo.PathType(), dirPath.String(), name), nil\n}\n\nfunc (fbo *folderBranchOps) signalWrite() {\n\tselect {\n\tcase fbo.syncNeededChan <- struct{}{}:\n\t\t// Kick off a merkle root fetch in the background, so that it's\n\t\t// ready by the time we do the SyncAll.\n\t\tfbo.merkleFetches.Add(1)\n\t\tgo func() {\n\t\t\tdefer fbo.merkleFetches.Done()\n\t\t\tnewCtx := fbo.ctxWithFBOID(context.Background())\n\t\t\t_, _, err := fbo.config.KBPKI().GetCurrentMerkleRoot(newCtx)\n\t\t\tif err != nil {\n\t\t\t\tfbo.log.CDebugf(newCtx, \"Couldn't fetch merkle root: %+v\", err)\n\t\t\t}\n\t\t}()\n\tdefault:\n\t}\n\t// A local write always means any ongoing CR should be canceled,\n\t// because the set of unmerged writes has changed.\n\tfbo.cr.ForceCancel()\n}\n\nfunc (fbo *folderBranchOps) syncDirUpdateOrSignal(\n\tctx context.Context, lState *lockState) error {\n\tif fbo.config.BGFlushDirOpBatchSize() == 1 {\n\t\treturn fbo.syncAllLocked(ctx, lState, NoExcl)\n\t}\n\tfbo.signalWrite()\n\treturn nil\n}\n\nfunc (fbo *folderBranchOps) checkForUnlinkedDir(dir Node) error {\n\t// Disallow directory operations within an unlinked directory.\n\t// Shells don't seem to allow it, and it will just pollute the dir\n\t// entry cache with unsyncable entries.\n\tif fbo.nodeCache.IsUnlinked(dir) {\n\t\tdirPath := fbo.nodeCache.PathFromNode(dir).String()\n\t\treturn errors.WithStack(UnsupportedOpInUnlinkedDirError{dirPath})\n\t}\n\treturn nil\n}\n\n// entryType must not by Sym.\nfunc (fbo *folderBranchOps) createEntryLocked(\n\tctx context.Context, lState *lockState, dir Node, name string,\n\tentryType EntryType, excl Excl) (childNode Node, de DirEntry, err error) {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\n\tif err := checkDisallowedPrefixes(ctx, name); err != nil {\n\t\treturn nil, DirEntry{}, err\n\t}\n\n\tif uint32(len(name)) > fbo.config.MaxNameBytes() {\n\t\treturn nil, DirEntry{},\n\t\t\tNameTooLongError{name, fbo.config.MaxNameBytes()}\n\t}\n\n\tif err := fbo.checkForUnlinkedDir(dir); err != nil {\n\t\treturn nil, DirEntry{}, err\n\t}\n\n\tfilename, err := fbo.canonicalPath(ctx, dir, name)\n\tif err != nil {\n\t\treturn nil, DirEntry{}, err\n\t}\n\n\t// Verify we have permission to write (but don't make a successor yet).\n\tmd, err := fbo.getMDForWriteLockedForFilename(ctx, lState, filename)\n\tif err != nil {\n\t\treturn nil, DirEntry{}, err\n\t}\n\n\tdirPath, err := fbo.pathFromNodeForMDWriteLocked(lState, dir)\n\tif err != nil {\n\t\treturn nil, DirEntry{}, err\n\t}\n\n\t// We're not going to modify this copy of the dirblock, so just\n\t// fetch it for reading.\n\tdblock, err := fbo.blocks.GetDirtyDir(\n\t\tctx, lState, md.ReadOnly(), dirPath, blockRead)\n\tif err != nil {\n\t\treturn nil, DirEntry{}, err\n\t}\n\n\t// does name already exist?\n\tif _, ok := dblock.Children[name]; ok {\n\t\treturn nil, DirEntry{}, NameExistsError{name}\n\t}\n\n\tif err := fbo.checkNewDirSize(\n\t\tctx, lState, md.ReadOnly(), dirPath, name); err != nil {\n\t\treturn nil, DirEntry{}, err\n\t}\n\n\tparentPtr := dirPath.tailPointer()\n\tco, err := newCreateOp(name, parentPtr, entryType)\n\tif err != nil {\n\t\treturn nil, DirEntry{}, err\n\t}\n\tco.setFinalPath(dirPath)\n\t// create new data block\n\tvar newBlock Block\n\tif entryType == Dir {\n\t\tnewBlock = &DirBlock{\n\t\t\tChildren: make(map[string]DirEntry),\n\t\t}\n\t} else {\n\t\tnewBlock = &FileBlock{}\n\t}\n\n\t// Cache update and operations until batch happens.  Make a new\n\t// temporary ID and directory entry.\n\tnewID, err := fbo.config.cryptoPure().MakeTemporaryBlockID()\n\tif err != nil {\n\t\treturn nil, DirEntry{}, err\n\t}\n\n\tchargedTo, err := chargedToForTLF(\n\t\tctx, fbo.config.KBPKI(), fbo.config.KBPKI(), md.GetTlfHandle())\n\tif err != nil {\n\t\treturn nil, DirEntry{}, err\n\t}\n\n\tnewPtr := BlockPointer{\n\t\tID:         newID,\n\t\tKeyGen:     md.LatestKeyGeneration(),\n\t\tDataVer:    fbo.config.DataVersion(),\n\t\tDirectType: DirectBlock,\n\t\tContext: kbfsblock.MakeFirstContext(\n\t\t\tchargedTo, fbo.config.DefaultBlockType()),\n\t}\n\tco.AddRefBlock(newPtr)\n\tco.AddSelfUpdate(parentPtr)\n\n\tnode, err := fbo.nodeCache.GetOrCreate(newPtr, name, dir)\n\tif err != nil {\n\t\treturn nil, DirEntry{}, err\n\t}\n\n\terr = fbo.config.DirtyBlockCache().Put(\n\t\tfbo.id(), newPtr, fbo.branch(), newBlock)\n\tif err != nil {\n\t\treturn nil, DirEntry{}, err\n\t}\n\n\tnow := fbo.nowUnixNano()\n\tde = DirEntry{\n\t\tBlockInfo: BlockInfo{\n\t\t\tBlockPointer: newPtr,\n\t\t\tEncodedSize:  0,\n\t\t},\n\t\tEntryInfo: EntryInfo{\n\t\t\tType:  entryType,\n\t\t\tSize:  0,\n\t\t\tMtime: now,\n\t\t\tCtime: now,\n\t\t},\n\t}\n\n\t// Set the TeamWriter for team TLFs, so we can return the\n\t// LastWriterUnverified before the writes are flushed from memory.\n\tif fbo.id().Type() == tlf.SingleTeam {\n\t\tsession, err := fbo.config.KBPKI().GetCurrentSession(ctx)\n\t\tif err != nil {\n\t\t\treturn nil, DirEntry{}, err\n\t\t}\n\t\tde.TeamWriter = session.UID\n\t}\n\n\tdirCacheUndoFn := fbo.blocks.AddDirEntryInCache(lState, dirPath, name, de)\n\tfbo.dirOps = append(fbo.dirOps, cachedDirOp{co, []Node{dir, node}})\n\tadded := fbo.status.addDirtyNode(dir)\n\n\tcleanupFn := func() {\n\t\tif added {\n\t\t\tfbo.status.rmDirtyNode(dir)\n\t\t}\n\t\tfbo.dirOps = fbo.dirOps[:len(fbo.dirOps)-1]\n\t\tif dirCacheUndoFn != nil {\n\t\t\tdirCacheUndoFn(lState)\n\t\t}\n\t\t// Delete should never fail.\n\t\t_ = fbo.config.DirtyBlockCache().Delete(fbo.id(), newPtr, fbo.branch())\n\t}\n\tdefer func() {\n\t\tif err != nil && cleanupFn != nil {\n\t\t\tcleanupFn()\n\t\t}\n\t}()\n\n\tif entryType != Dir {\n\t\t// Dirty the file with a zero-byte write, to ensure the new\n\t\t// block is synced in SyncAll.  TODO: remove this if we ever\n\t\t// embed 0-byte files in the directory entry itself.\n\t\terr = fbo.blocks.Write(\n\t\t\tctx, lState, md.ReadOnly(), node, []byte{}, 0)\n\t\tif err != nil {\n\t\t\treturn nil, DirEntry{}, err\n\t\t}\n\t\toldCleanupFn := cleanupFn\n\t\tcleanupFn = func() {\n\t\t\tfbo.blocks.ClearCacheInfo(lState, fbo.nodeCache.PathFromNode(node))\n\t\t\toldCleanupFn()\n\t\t}\n\t}\n\n\t// It's safe to notify before we've synced, since it is only\n\t// sending invalidation notifications.  At worst the upper layer\n\t// will just have to refresh its cache needlessly.\n\terr = fbo.notifyOneOp(ctx, lState, co, md.ReadOnly(), false)\n\tif err != nil {\n\t\treturn nil, DirEntry{}, err\n\t}\n\n\tif excl == WithExcl {\n\t\t// Sync this change to the server.\n\t\terr := fbo.syncAllLocked(ctx, lState, WithExcl)\n\t\t_, isNoUpdatesWhileDirty := errors.Cause(err).(NoUpdatesWhileDirtyError)\n\t\tif isNoUpdatesWhileDirty {\n\t\t\t// If an exclusive write hits a conflict, it will try to\n\t\t\t// update, but won't be able to because of the dirty\n\t\t\t// directory entries.  We need to clean up the dirty\n\t\t\t// entries here first before trying to apply the updates\n\t\t\t// again.  By returning `ExclOnUnmergedError` below, we\n\t\t\t// force the caller to retry the whole operation again.\n\t\t\tfbo.log.CDebugf(ctx, \"Clearing dirty entry before applying new \"+\n\t\t\t\t\"updates for exclusive write\")\n\t\t\tcleanupFn()\n\t\t\tcleanupFn = nil\n\n\t\t\t// Sync anything else that might be buffered (non-exclusively).\n\t\t\terr = fbo.syncAllLocked(ctx, lState, NoExcl)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, DirEntry{}, err\n\t\t\t}\n\n\t\t\t// Now we should be in a clean state, so this should work.\n\t\t\terr = fbo.getAndApplyMDUpdates(\n\t\t\t\tctx, lState, nil, fbo.applyMDUpdatesLocked)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, DirEntry{}, err\n\t\t\t}\n\t\t\treturn nil, DirEntry{}, ExclOnUnmergedError{}\n\t\t} else if err != nil {\n\t\t\treturn nil, DirEntry{}, err\n\t\t}\n\t} else {\n\t\terr = fbo.syncDirUpdateOrSignal(ctx, lState)\n\t\tif err != nil {\n\t\t\treturn nil, DirEntry{}, err\n\t\t}\n\t}\n\n\treturn node, de, nil\n}\n\nfunc (fbo *folderBranchOps) maybeWaitForSquash(\n\tctx context.Context, bid kbfsmd.BranchID) {\n\tif bid != kbfsmd.PendingLocalSquashBranchID {\n\t\treturn\n\t}\n\n\tfbo.log.CDebugf(ctx, \"Blocking until squash finishes\")\n\t// Limit the time we wait to just under the ctx deadline if there\n\t// is one, or 10s if there isn't.\n\tdeadline, ok := ctx.Deadline()\n\tif ok {\n\t\tdeadline = deadline.Add(-1 * time.Second)\n\t} else {\n\t\t// Can't use config.Clock() since context doesn't respect it.\n\t\tdeadline = time.Now().Add(10 * time.Second)\n\t}\n\tctx, cancel := context.WithDeadline(ctx, deadline)\n\tdefer cancel()\n\t// Wait for CR to finish.  Note that if the user is issuing\n\t// concurrent writes, the current CR could be canceled, and when\n\t// the call belows returns, the branch still won't be squashed.\n\t// That's ok, this is just an optimization.\n\terr := fbo.cr.Wait(ctx)\n\tif err != nil {\n\t\tfbo.log.CDebugf(ctx, \"Error while waiting for CR: %+v\", err)\n\t}\n}\n\nfunc (fbo *folderBranchOps) doMDWriteWithRetry(ctx context.Context,\n\tlState *lockState, fn func(lState *lockState) error) error {\n\tdoUnlock := false\n\tdefer func() {\n\t\tif doUnlock {\n\t\t\tbid := fbo.bid\n\t\t\tfbo.mdWriterLock.Unlock(lState)\n\t\t\t// Don't let a pending squash get too big.\n\t\t\tfbo.maybeWaitForSquash(ctx, bid)\n\t\t}\n\t}()\n\n\tfor i := 0; ; i++ {\n\t\tfbo.mdWriterLock.Lock(lState)\n\t\tdoUnlock = true\n\n\t\t// Make sure we haven't been canceled before doing anything\n\t\t// too serious.\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t}\n\n\t\terr := fn(lState)\n\t\tif isRetriableError(err, i) {\n\t\t\tfbo.log.CDebugf(ctx, \"Trying again after retriable error: %v\", err)\n\t\t\t// Release the lock to give someone else a chance\n\t\t\tdoUnlock = false\n\t\t\tfbo.mdWriterLock.Unlock(lState)\n\t\t\tif _, ok := err.(ExclOnUnmergedError); ok {\n\t\t\t\tif err = fbo.cr.Wait(ctx); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t} else if _, ok := err.(UnmergedSelfConflictError); ok {\n\t\t\t\t// We can only get here if we are already on an\n\t\t\t\t// unmerged branch and an errored PutUnmerged did make\n\t\t\t\t// it to the mdserver.  Let's force sync, with a fresh\n\t\t\t\t// context so the observer doesn't ignore the updates\n\t\t\t\t// (but tie the cancels together).\n\t\t\t\tnewCtx := fbo.ctxWithFBOID(context.Background())\n\t\t\t\tnewCtx, cancel := context.WithCancel(newCtx)\n\t\t\t\tdefer cancel()\n\t\t\t\tgo func() {\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\tcancel()\n\t\t\t\t\tcase <-newCtx.Done():\n\t\t\t\t\t}\n\t\t\t\t}()\n\t\t\t\tfbo.log.CDebugf(ctx, \"Got a revision conflict while unmerged \"+\n\t\t\t\t\t\"(%v); forcing a sync\", err)\n\t\t\t\terr = fbo.getAndApplyNewestUnmergedHead(newCtx, lState)\n\t\t\t\tif err != nil {\n\t\t\t\t\t// TODO: we might be stuck at this point if we're\n\t\t\t\t\t// ahead of the unmerged branch on the server, in\n\t\t\t\t\t// which case we might want to just abandon any\n\t\t\t\t\t// cached updates and force a sync to the head.\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tcancel()\n\t\t\t}\n\t\t\tcontinue\n\t\t} else if err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn nil\n\t}\n}\n\nfunc (fbo *folderBranchOps) doMDWriteWithRetryUnlessCanceled(\n\tctx context.Context, fn func(lState *lockState) error) error {\n\treturn runUnlessCanceled(ctx, func() error {\n\t\tlState := makeFBOLockState()\n\t\treturn fbo.doMDWriteWithRetry(ctx, lState, fn)\n\t})\n}\n\nfunc (fbo *folderBranchOps) CreateDir(\n\tctx context.Context, dir Node, path string) (\n\tn Node, ei EntryInfo, err error) {\n\tfbo.log.CDebugf(ctx, \"CreateDir %s %s\", getNodeIDStr(dir), path)\n\tdefer func() {\n\t\tfbo.deferLog.CDebugf(ctx, \"CreateDir %s %s done: %v %+v\",\n\t\t\tgetNodeIDStr(dir), path, getNodeIDStr(n), err)\n\t}()\n\n\terr = fbo.checkNodeForWrite(ctx, dir)\n\tif err != nil {\n\t\treturn nil, EntryInfo{}, err\n\t}\n\n\tvar retNode Node\n\tvar retEntryInfo EntryInfo\n\terr = fbo.doMDWriteWithRetryUnlessCanceled(ctx,\n\t\tfunc(lState *lockState) error {\n\t\t\tnode, de, err :=\n\t\t\t\tfbo.createEntryLocked(ctx, lState, dir, path, Dir, NoExcl)\n\t\t\t// Don't set node and ei directly, as that can cause a\n\t\t\t// race when the Create is canceled.\n\t\t\tretNode = node\n\t\t\tretEntryInfo = de.EntryInfo\n\t\t\treturn err\n\t\t})\n\tif err != nil {\n\t\treturn nil, EntryInfo{}, err\n\t}\n\treturn retNode, retEntryInfo, nil\n}\n\nfunc (fbo *folderBranchOps) CreateFile(\n\tctx context.Context, dir Node, path string, isExec bool, excl Excl) (\n\tn Node, ei EntryInfo, err error) {\n\tfbo.log.CDebugf(ctx, \"CreateFile %s %s isExec=%v Excl=%s\",\n\t\tgetNodeIDStr(dir), path, isExec, excl)\n\tdefer func() {\n\t\tfbo.deferLog.CDebugf(ctx,\n\t\t\t\"CreateFile %s %s isExec=%v Excl=%s done: %v %+v\",\n\t\t\tgetNodeIDStr(dir), path, isExec, excl,\n\t\t\tgetNodeIDStr(n), err)\n\t}()\n\n\terr = fbo.checkNodeForWrite(ctx, dir)\n\tif err != nil {\n\t\treturn nil, EntryInfo{}, err\n\t}\n\n\tvar entryType EntryType\n\tif isExec {\n\t\tentryType = Exec\n\t} else {\n\t\tentryType = File\n\t}\n\n\t// If journaling is turned on, an exclusive create may end up on a\n\t// conflict branch.\n\tif excl == WithExcl && TLFJournalEnabled(fbo.config, fbo.id()) {\n\t\tfbo.log.CDebugf(ctx, \"Exclusive create status is being discarded.\")\n\t\texcl = NoExcl\n\t}\n\n\tif excl == WithExcl {\n\t\tif err = fbo.cr.Wait(ctx); err != nil {\n\t\t\treturn nil, EntryInfo{}, err\n\t\t}\n\t}\n\n\tvar retNode Node\n\tvar retEntryInfo EntryInfo\n\terr = fbo.doMDWriteWithRetryUnlessCanceled(ctx,\n\t\tfunc(lState *lockState) error {\n\t\t\t// Don't set node and ei directly, as that can cause a\n\t\t\t// race when the Create is canceled.\n\t\t\tnode, de, err :=\n\t\t\t\tfbo.createEntryLocked(ctx, lState, dir, path, entryType, excl)\n\t\t\tretNode = node\n\t\t\tretEntryInfo = de.EntryInfo\n\t\t\treturn err\n\t\t})\n\tif err != nil {\n\t\treturn nil, EntryInfo{}, err\n\t}\n\treturn retNode, retEntryInfo, nil\n}\n\n// notifyAndSyncOrSignal caches an op in memory and dirties the\n// relevant node, and then sends a notification for it.  If batching\n// is on, it signals the write; otherwise it syncs the change.  It\n// should only be called as the final instruction that can fail in a\n// method.\nfunc (fbo *folderBranchOps) notifyAndSyncOrSignal(\n\tctx context.Context, lState *lockState, undoFn dirCacheUndoFn,\n\tnodesToDirty []Node, op op, md ReadOnlyRootMetadata) (err error) {\n\tfbo.dirOps = append(fbo.dirOps, cachedDirOp{op, nodesToDirty})\n\tvar addedNodes []Node\n\tfor _, n := range nodesToDirty {\n\t\tadded := fbo.status.addDirtyNode(n)\n\t\tif added {\n\t\t\taddedNodes = append(addedNodes, n)\n\t\t}\n\t}\n\n\tdefer func() {\n\t\tif err != nil {\n\t\t\tfor _, n := range addedNodes {\n\t\t\t\tfbo.status.rmDirtyNode(n)\n\t\t\t}\n\t\t\tfbo.dirOps = fbo.dirOps[:len(fbo.dirOps)-1]\n\t\t\tif undoFn != nil {\n\t\t\t\tundoFn(lState)\n\t\t\t}\n\t\t}\n\t}()\n\n\t// It's safe to notify before we've synced, since it is only\n\t// sending invalidation notifications.  At worst the upper layer\n\t// will just have to refresh its cache needlessly.\n\terr = fbo.notifyOneOp(ctx, lState, op, md, false)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn fbo.syncDirUpdateOrSignal(ctx, lState)\n}\n\nfunc (fbo *folderBranchOps) createLinkLocked(\n\tctx context.Context, lState *lockState, dir Node, fromName string,\n\ttoPath string) (DirEntry, error) {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\n\tif err := checkDisallowedPrefixes(ctx, fromName); err != nil {\n\t\treturn DirEntry{}, err\n\t}\n\n\tif uint32(len(fromName)) > fbo.config.MaxNameBytes() {\n\t\treturn DirEntry{},\n\t\t\tNameTooLongError{fromName, fbo.config.MaxNameBytes()}\n\t}\n\n\tif err := fbo.checkForUnlinkedDir(dir); err != nil {\n\t\treturn DirEntry{}, err\n\t}\n\n\t// Verify we have permission to write (but don't make a successor yet).\n\tmd, err := fbo.getMDForWriteLockedForFilename(ctx, lState, \"\")\n\tif err != nil {\n\t\treturn DirEntry{}, err\n\t}\n\n\tdirPath, err := fbo.pathFromNodeForMDWriteLocked(lState, dir)\n\tif err != nil {\n\t\treturn DirEntry{}, err\n\t}\n\n\t// We're not going to modify this copy of the dirblock, so just\n\t// fetch it for reading.\n\tdblock, err := fbo.blocks.GetDirtyDir(\n\t\tctx, lState, md.ReadOnly(), dirPath, blockRead)\n\tif err != nil {\n\t\treturn DirEntry{}, err\n\t}\n\n\t// TODO: validate inputs\n\n\t// does name already exist?\n\tif _, ok := dblock.Children[fromName]; ok {\n\t\treturn DirEntry{}, NameExistsError{fromName}\n\t}\n\n\tif err := fbo.checkNewDirSize(ctx, lState, md.ReadOnly(),\n\t\tdirPath, fromName); err != nil {\n\t\treturn DirEntry{}, err\n\t}\n\n\tparentPtr := dirPath.tailPointer()\n\tco, err := newCreateOp(fromName, parentPtr, Sym)\n\tif err != nil {\n\t\treturn DirEntry{}, err\n\t}\n\tco.setFinalPath(dirPath)\n\tco.AddSelfUpdate(parentPtr)\n\n\t// Nothing below here can fail, so no need to clean up the dir\n\t// entry cache on a failure.  If this ever panics, we need to add\n\t// cleanup code.\n\n\t// Create a direntry for the link, and then sync\n\tnow := fbo.nowUnixNano()\n\tde := DirEntry{\n\t\tEntryInfo: EntryInfo{\n\t\t\tType:    Sym,\n\t\t\tSize:    uint64(len(toPath)),\n\t\t\tSymPath: toPath,\n\t\t\tMtime:   now,\n\t\t\tCtime:   now,\n\t\t},\n\t}\n\n\tdirCacheUndoFn := fbo.blocks.AddDirEntryInCache(\n\t\tlState, dirPath, fromName, de)\n\n\terr = fbo.notifyAndSyncOrSignal(\n\t\tctx, lState, dirCacheUndoFn, []Node{dir}, co, md.ReadOnly())\n\tif err != nil {\n\t\treturn DirEntry{}, err\n\t}\n\treturn de, nil\n}\n\nfunc (fbo *folderBranchOps) CreateLink(\n\tctx context.Context, dir Node, fromName string, toPath string) (\n\tei EntryInfo, err error) {\n\tfbo.log.CDebugf(ctx, \"CreateLink %s %s -> %s\",\n\t\tgetNodeIDStr(dir), fromName, toPath)\n\tdefer func() {\n\t\tfbo.deferLog.CDebugf(ctx, \"CreateLink %s %s -> %s done: %+v\",\n\t\t\tgetNodeIDStr(dir), fromName, toPath, err)\n\t}()\n\n\terr = fbo.checkNodeForWrite(ctx, dir)\n\tif err != nil {\n\t\treturn EntryInfo{}, err\n\t}\n\n\tvar retEntryInfo EntryInfo\n\terr = fbo.doMDWriteWithRetryUnlessCanceled(ctx,\n\t\tfunc(lState *lockState) error {\n\t\t\t// Don't set ei directly, as that can cause a race when\n\t\t\t// the Create is canceled.\n\t\t\tde, err := fbo.createLinkLocked(ctx, lState, dir, fromName, toPath)\n\t\t\tretEntryInfo = de.EntryInfo\n\t\t\treturn err\n\t\t})\n\tif err != nil {\n\t\treturn EntryInfo{}, err\n\t}\n\treturn retEntryInfo, nil\n}\n\n// unrefEntry modifies md to unreference all relevant blocks for the\n// given entry.\nfunc (fbo *folderBranchOps) unrefEntryLocked(ctx context.Context,\n\tlState *lockState, kmd KeyMetadata, ro op, dir path, de DirEntry,\n\tname string) error {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\tif de.Type == Sym {\n\t\treturn nil\n\t}\n\n\tunrefsToAdd := make(map[BlockPointer]bool)\n\tfbo.prepper.cacheBlockInfos([]BlockInfo{de.BlockInfo})\n\tunrefsToAdd[de.BlockPointer] = true\n\t// construct a path for the child so we can unlink with it.\n\tchildPath := dir.ChildPath(name, de.BlockPointer)\n\n\t// If this is an indirect block, we need to delete all of its\n\t// children as well. NOTE: non-empty directories can't be\n\t// removed, so no need to check for indirect directory blocks\n\t// here.\n\tif de.Type == File || de.Type == Exec {\n\t\tblockInfos, err := fbo.blocks.GetIndirectFileBlockInfos(\n\t\t\tctx, lState, kmd, childPath)\n\t\tif isRecoverableBlockErrorForRemoval(err) {\n\t\t\tmsg := fmt.Sprintf(\"Recoverable block error encountered for unrefEntry(%v); continuing\", childPath)\n\t\t\tfbo.log.CWarningf(ctx, \"%s\", msg)\n\t\t\tfbo.log.CDebugf(ctx, \"%s (err=%v)\", msg, err)\n\t\t} else if err != nil {\n\t\t\treturn err\n\t\t}\n\t\tfbo.prepper.cacheBlockInfos(blockInfos)\n\t\tfor _, blockInfo := range blockInfos {\n\t\t\tunrefsToAdd[blockInfo.BlockPointer] = true\n\t\t}\n\t}\n\n\t// Any referenced blocks that were unreferenced since the last\n\t// sync can just be forgotten about.  Note that any updated\n\t// pointers that are unreferenced will be fixed up during syncing.\n\tfor _, dirOp := range fbo.dirOps {\n\t\tfor i := len(dirOp.dirOp.Refs()) - 1; i >= 0; i-- {\n\t\t\tref := dirOp.dirOp.Refs()[i]\n\t\t\tif _, ok := unrefsToAdd[ref]; ok {\n\t\t\t\tdirOp.dirOp.DelRefBlock(ref)\n\t\t\t\tdelete(unrefsToAdd, ref)\n\t\t\t}\n\t\t}\n\t}\n\tfor unref := range unrefsToAdd {\n\t\tro.AddUnrefBlock(unref)\n\t}\n\n\treturn nil\n}\n\nfunc (fbo *folderBranchOps) removeEntryLocked(ctx context.Context,\n\tlState *lockState, md ReadOnlyRootMetadata, dir Node, dirPath path,\n\tname string) error {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\n\tif err := fbo.checkForUnlinkedDir(dir); err != nil {\n\t\treturn err\n\t}\n\n\t// We're not going to modify this copy of the dirblock, so just\n\t// fetch it for reading.\n\tpblock, err := fbo.blocks.GetDirtyDir(ctx, lState, md, dirPath, blockRead)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// make sure the entry exists\n\tde, ok := pblock.Children[name]\n\tif !ok {\n\t\treturn NoSuchNameError{name}\n\t}\n\n\tparentPtr := dirPath.tailPointer()\n\tro, err := newRmOp(name, parentPtr, de.Type)\n\tif err != nil {\n\t\treturn err\n\t}\n\tro.setFinalPath(dirPath)\n\tro.AddSelfUpdate(parentPtr)\n\terr = fbo.unrefEntryLocked(ctx, lState, md, ro, dirPath, de, name)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tdirCacheUndoFn := fbo.blocks.RemoveDirEntryInCache(\n\t\tlState, dirPath, name, de)\n\tif de.Type == Dir {\n\t\tremovedNode := fbo.nodeCache.Get(de.BlockPointer.Ref())\n\t\tif removedNode != nil {\n\t\t\t// If it was a dirty directory, the removed node no longer\n\t\t\t// counts as dirty (it will never be sync'd). Note that\n\t\t\t// removed files will still be synced since any data\n\t\t\t// written to them via a handle stays in memory until the\n\t\t\t// sync actually happens.\n\t\t\tremoved := fbo.status.rmDirtyNode(removedNode)\n\t\t\tif removed {\n\t\t\t\toldUndoFn := dirCacheUndoFn\n\t\t\t\tdirCacheUndoFn = func(lState *lockState) {\n\t\t\t\t\toldUndoFn(lState)\n\t\t\t\t\tfbo.status.addDirtyNode(removedNode)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn fbo.notifyAndSyncOrSignal(\n\t\tctx, lState, dirCacheUndoFn, []Node{dir}, ro, md.ReadOnly())\n}\n\nfunc (fbo *folderBranchOps) removeDirLocked(ctx context.Context,\n\tlState *lockState, dir Node, dirName string) (err error) {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\n\t// Verify we have permission to write (but don't make a successor yet).\n\tmd, err := fbo.getMDForWriteLockedForFilename(ctx, lState, \"\")\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tdirPath, err := fbo.pathFromNodeForMDWriteLocked(lState, dir)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tpblock, err := fbo.blocks.GetDirtyDir(\n\t\tctx, lState, md.ReadOnly(), dirPath, blockRead)\n\tde, ok := pblock.Children[dirName]\n\tif !ok {\n\t\treturn NoSuchNameError{dirName}\n\t}\n\n\t// construct a path for the child so we can check for an empty dir\n\tchildPath := dirPath.ChildPath(dirName, de.BlockPointer)\n\n\tchildBlock, err := fbo.blocks.GetDirtyDir(\n\t\tctx, lState, md.ReadOnly(), childPath, blockRead)\n\tif isRecoverableBlockErrorForRemoval(err) {\n\t\tmsg := fmt.Sprintf(\"Recoverable block error encountered for removeDirLocked(%v); continuing\", childPath)\n\t\tfbo.log.CWarningf(ctx, \"%s\", msg)\n\t\tfbo.log.CDebugf(ctx, \"%s (err=%v)\", msg, err)\n\t} else if err != nil {\n\t\treturn err\n\t} else if len(childBlock.Children) > 0 {\n\t\treturn DirNotEmptyError{dirName}\n\t}\n\n\treturn fbo.removeEntryLocked(\n\t\tctx, lState, md.ReadOnly(), dir, dirPath, dirName)\n}\n\nfunc (fbo *folderBranchOps) RemoveDir(\n\tctx context.Context, dir Node, dirName string) (err error) {\n\tfbo.log.CDebugf(ctx, \"RemoveDir %s %s\", getNodeIDStr(dir), dirName)\n\tdefer func() {\n\t\tfbo.deferLog.CDebugf(ctx, \"RemoveDir %s %s done: %+v\",\n\t\t\tgetNodeIDStr(dir), dirName, err)\n\t}()\n\n\tremoveDone, err := dir.RemoveDir(ctx, dirName)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif removeDone {\n\t\treturn nil\n\t}\n\n\terr = fbo.checkNodeForWrite(ctx, dir)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn fbo.doMDWriteWithRetryUnlessCanceled(ctx,\n\t\tfunc(lState *lockState) error {\n\t\t\treturn fbo.removeDirLocked(ctx, lState, dir, dirName)\n\t\t})\n}\n\nfunc (fbo *folderBranchOps) RemoveEntry(ctx context.Context, dir Node,\n\tname string) (err error) {\n\tfbo.log.CDebugf(ctx, \"RemoveEntry %s %s\", getNodeIDStr(dir), name)\n\tdefer func() {\n\t\tfbo.deferLog.CDebugf(ctx, \"RemoveEntry %s %s done: %+v\",\n\t\t\tgetNodeIDStr(dir), name, err)\n\t}()\n\n\terr = fbo.checkNodeForWrite(ctx, dir)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn fbo.doMDWriteWithRetryUnlessCanceled(ctx,\n\t\tfunc(lState *lockState) error {\n\t\t\t// Verify we have permission to write (but no need to make\n\t\t\t// a successor yet).\n\t\t\tmd, err := fbo.getMDForWriteLockedForFilename(ctx, lState, \"\")\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tdirPath, err := fbo.pathFromNodeForMDWriteLocked(lState, dir)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\treturn fbo.removeEntryLocked(\n\t\t\t\tctx, lState, md.ReadOnly(), dir, dirPath, name)\n\t\t})\n}\n\nfunc (fbo *folderBranchOps) renameLocked(\n\tctx context.Context, lState *lockState, oldParent Node, oldName string,\n\tnewParent Node, newName string) (err error) {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\n\tif err := fbo.checkForUnlinkedDir(oldParent); err != nil {\n\t\treturn err\n\t}\n\tif err := fbo.checkForUnlinkedDir(newParent); err != nil {\n\t\treturn err\n\t}\n\n\tif err := checkDisallowedPrefixes(ctx, newName); err != nil {\n\t\treturn err\n\t}\n\n\toldParentPath, err := fbo.pathFromNodeForMDWriteLocked(lState, oldParent)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tnewParentPath, err := fbo.pathFromNodeForMDWriteLocked(lState, newParent)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Verify we have permission to write (but no need to make a\n\t// successor yet).\n\tmd, err := fbo.getMDForWriteLockedForFilename(ctx, lState, \"\")\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t_, newPBlock, newDe, ro, err := fbo.blocks.PrepRename(\n\t\tctx, lState, md.ReadOnly(), oldParentPath, oldName, newParentPath,\n\t\tnewName)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// does name exist?\n\treplacedDe, ok := newPBlock.Children[newName]\n\tif ok {\n\t\t// Usually higher-level programs check these, but just in case.\n\t\tif replacedDe.Type == Dir && newDe.Type != Dir {\n\t\t\treturn NotDirError{newParentPath.ChildPathNoPtr(newName)}\n\t\t} else if replacedDe.Type != Dir && newDe.Type == Dir {\n\t\t\treturn NotFileError{newParentPath.ChildPathNoPtr(newName)}\n\t\t}\n\n\t\tif replacedDe.Type == Dir {\n\t\t\t// The directory must be empty.\n\t\t\toldTargetDir, err := fbo.blocks.GetDirBlockForReading(ctx, lState,\n\t\t\t\tmd.ReadOnly(), replacedDe.BlockPointer, newParentPath.Branch,\n\t\t\t\tnewParentPath.ChildPathNoPtr(newName))\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif len(oldTargetDir.Children) != 0 {\n\t\t\t\tfbo.log.CWarningf(ctx, \"Renaming over a non-empty directory \"+\n\t\t\t\t\t\" (%s/%s) not allowed.\", newParentPath, newName)\n\t\t\t\treturn DirNotEmptyError{newName}\n\t\t\t}\n\t\t}\n\n\t\t// Delete the old block pointed to by this direntry.\n\t\terr := fbo.unrefEntryLocked(\n\t\t\tctx, lState, md.ReadOnly(), ro, newParentPath, replacedDe, newName)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t} else {\n\t\t// If the entry doesn't exist yet, see if the new name will\n\t\t// make the new parent directory too big.  If the entry is\n\t\t// remaining in the same directory, only check the size\n\t\t// difference.\n\t\tcheckName := newName\n\t\tif oldParent == newParent {\n\t\t\tif extra := len(newName) - len(oldName); extra <= 0 {\n\t\t\t\tcheckName = \"\"\n\t\t\t} else {\n\t\t\t\tcheckName = newName[:extra]\n\t\t\t}\n\t\t}\n\t\tif len(checkName) > 0 {\n\t\t\tif err := fbo.checkNewDirSize(\n\t\t\t\tctx, lState, md.ReadOnly(), newParentPath,\n\t\t\t\tcheckName); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\t// Only the ctime changes on the directory entry itself.\n\tnewDe.Ctime = fbo.nowUnixNano()\n\n\tdirCacheUndoFn, err := fbo.blocks.RenameDirEntryInCache(\n\t\tlState, oldParentPath, oldName, newParentPath, newName, newDe,\n\t\treplacedDe)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tnodesToDirty := []Node{oldParent}\n\tif oldParent.GetID() != newParent.GetID() {\n\t\tnodesToDirty = append(nodesToDirty, newParent)\n\t}\n\treturn fbo.notifyAndSyncOrSignal(\n\t\tctx, lState, dirCacheUndoFn, nodesToDirty, ro, md.ReadOnly())\n}\n\nfunc (fbo *folderBranchOps) Rename(\n\tctx context.Context, oldParent Node, oldName string, newParent Node,\n\tnewName string) (err error) {\n\tfbo.log.CDebugf(ctx, \"Rename %s/%s -> %s/%s\", getNodeIDStr(oldParent),\n\t\toldName, getNodeIDStr(newParent), newName)\n\tdefer func() {\n\t\tfbo.deferLog.CDebugf(ctx, \"Rename %s/%s -> %s/%s done: %+v\",\n\t\t\tgetNodeIDStr(oldParent), oldName,\n\t\t\tgetNodeIDStr(newParent), newName, err)\n\t}()\n\n\terr = fbo.checkNodeForWrite(ctx, oldParent)\n\tif err != nil {\n\t\treturn err\n\t}\n\terr = fbo.checkNodeForWrite(ctx, newParent)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn fbo.doMDWriteWithRetryUnlessCanceled(ctx,\n\t\tfunc(lState *lockState) error {\n\t\t\t// only works for paths within the same topdir\n\t\t\tif oldParent.GetFolderBranch() != newParent.GetFolderBranch() {\n\t\t\t\treturn RenameAcrossDirsError{}\n\t\t\t}\n\n\t\t\treturn fbo.renameLocked(ctx, lState, oldParent, oldName,\n\t\t\t\tnewParent, newName)\n\t\t})\n}\n\nfunc (fbo *folderBranchOps) Read(\n\tctx context.Context, file Node, dest []byte, off int64) (\n\tn int64, err error) {\n\tfbo.log.CDebugf(ctx, \"Read %s %d %d\", getNodeIDStr(file),\n\t\tlen(dest), off)\n\tdefer func() {\n\t\tfbo.deferLog.CDebugf(ctx, \"Read %s %d %d (n=%d) done: %+v\",\n\t\t\tgetNodeIDStr(file), len(dest), off, n, err)\n\t}()\n\n\terr = fbo.checkNode(file)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\t{\n\t\tfilePath, err := fbo.pathFromNodeForRead(file)\n\t\tif err != nil {\n\t\t\treturn 0, err\n\t\t}\n\n\t\t// It seems git isn't handling EINTR from some of its read calls (likely\n\t\t// fread), which causes it to get corrupted data (which leads to coredumps\n\t\t// later) when a read system call on pack files gets interrupted. This\n\t\t// enables delayed cancellation for Read if the file path contains `.git`.\n\t\t//\n\t\t// TODO: get a patch in git, wait for sufficiently long time for people to\n\t\t// upgrade, and remove this.\n\n\t\t// allow turning this feature off by env var to make life easier when we\n\t\t// try to fix git.\n\t\tif _, isSet := os.LookupEnv(\"KBFS_DISABLE_GIT_SPECIAL_CASE\"); !isSet {\n\t\t\tfor _, n := range filePath.path {\n\t\t\t\tif n.Name == \".git\" {\n\t\t\t\t\tEnableDelayedCancellationWithGracePeriod(ctx, fbo.config.DelayedCancellationGracePeriod())\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Don't let the goroutine below write directly to the return\n\t// variable, since if the context is canceled the goroutine might\n\t// outlast this function call, and end up in a read/write race\n\t// with the caller.\n\tvar bytesRead int64\n\terr = runUnlessCanceled(ctx, func() error {\n\t\tlState := makeFBOLockState()\n\n\t\t// verify we have permission to read\n\t\tmd, err := fbo.getMDForReadNeedIdentify(ctx, lState)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Read using the `file` Node, not `filePath`, since the path\n\t\t// could change until we take `blockLock` for reading.\n\t\tbytesRead, err = fbo.blocks.Read(\n\t\t\tctx, lState, md.ReadOnly(), file, dest, off)\n\t\treturn err\n\t})\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\treturn bytesRead, nil\n}\n\nfunc (fbo *folderBranchOps) Write(\n\tctx context.Context, file Node, data []byte, off int64) (err error) {\n\tfbo.log.CDebugf(ctx, \"Write %s %d %d\", getNodeIDStr(file),\n\t\tlen(data), off)\n\tdefer func() {\n\t\tfbo.deferLog.CDebugf(ctx, \"Write %s %d %d done: %+v\",\n\t\t\tgetNodeIDStr(file), len(data), off, err)\n\t}()\n\n\terr = fbo.checkNodeForWrite(ctx, file)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn runUnlessCanceled(ctx, func() error {\n\t\tlState := makeFBOLockState()\n\n\t\t// Get the MD for reading.  We won't modify it; we'll track the\n\t\t// unref changes on the side, and put them into the MD during the\n\t\t// sync.\n\t\tmd, err := fbo.getMDForRead(ctx, lState, mdReadNeedIdentify)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\terr = fbo.blocks.Write(\n\t\t\tctx, lState, md.ReadOnly(), file, data, off)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tfbo.status.addDirtyNode(file)\n\t\tfbo.signalWrite()\n\t\treturn nil\n\t})\n}\n\nfunc (fbo *folderBranchOps) Truncate(\n\tctx context.Context, file Node, size uint64) (err error) {\n\tfbo.log.CDebugf(ctx, \"Truncate %s %d\", getNodeIDStr(file), size)\n\tdefer func() {\n\t\tfbo.deferLog.CDebugf(ctx, \"Truncate %s %d done: %+v\",\n\t\t\tgetNodeIDStr(file), size, err)\n\t}()\n\n\terr = fbo.checkNodeForWrite(ctx, file)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn runUnlessCanceled(ctx, func() error {\n\t\tlState := makeFBOLockState()\n\n\t\t// Get the MD for reading.  We won't modify it; we'll track the\n\t\t// unref changes on the side, and put them into the MD during the\n\t\t// sync.\n\t\tmd, err := fbo.getMDForRead(ctx, lState, mdReadNeedIdentify)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\terr = fbo.blocks.Truncate(\n\t\t\tctx, lState, md.ReadOnly(), file, size)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tfbo.status.addDirtyNode(file)\n\t\tfbo.signalWrite()\n\t\treturn nil\n\t})\n}\n\nfunc (fbo *folderBranchOps) setExLocked(\n\tctx context.Context, lState *lockState, file Node, ex bool) (err error) {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\n\tfilePath, err := fbo.pathFromNodeForMDWriteLocked(lState, file)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Verify we have permission to write (no need to make a successor yet).\n\tmd, err := fbo.getMDForWriteLockedForFilename(ctx, lState, \"\")\n\tif err != nil {\n\t\treturn\n\t}\n\n\tde, err := fbo.blocks.GetDirtyEntryEvenIfDeleted(\n\t\tctx, lState, md.ReadOnly(), filePath)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// If the file is a symlink, do nothing (to match ext4\n\t// behavior).\n\tif de.Type == Sym || de.Type == Dir {\n\t\tfbo.log.CDebugf(ctx, \"Ignoring setex on type %s\", de.Type)\n\t\treturn nil\n\t}\n\n\tif ex && (de.Type == File) {\n\t\tde.Type = Exec\n\t} else if !ex && (de.Type == Exec) {\n\t\tde.Type = File\n\t} else {\n\t\t// Treating this as a no-op, without updating the ctime, is a\n\t\t// POSIX violation, but it's an important optimization to keep\n\t\t// permissions-preserving rsyncs fast.\n\t\tfbo.log.CDebugf(ctx, \"Ignoring no-op setex\")\n\t\treturn nil\n\t}\n\n\tde.Ctime = fbo.nowUnixNano()\n\n\tparentPtr := filePath.parentPath().tailPointer()\n\tsao, err := newSetAttrOp(filePath.tailName(), parentPtr,\n\t\texAttr, filePath.tailPointer())\n\tif err != nil {\n\t\treturn err\n\t}\n\tsao.AddSelfUpdate(parentPtr)\n\n\t// If the node has been unlinked, we can safely ignore this setex.\n\tif fbo.nodeCache.IsUnlinked(file) {\n\t\tfbo.log.CDebugf(ctx, \"Skipping setex for a removed file %v\",\n\t\t\tfilePath.tailPointer())\n\t\tfbo.blocks.UpdateCachedEntryAttributesOnRemovedFile(\n\t\t\tctx, lState, sao, de)\n\t\treturn nil\n\t}\n\n\tsao.setFinalPath(filePath)\n\n\tdirCacheUndoFn := fbo.blocks.SetAttrInDirEntryInCache(\n\t\tlState, filePath, de, sao.Attr)\n\treturn fbo.notifyAndSyncOrSignal(\n\t\tctx, lState, dirCacheUndoFn, []Node{file}, sao, md.ReadOnly())\n}\n\nfunc (fbo *folderBranchOps) SetEx(\n\tctx context.Context, file Node, ex bool) (err error) {\n\tfbo.log.CDebugf(ctx, \"SetEx %s %t\", getNodeIDStr(file), ex)\n\tdefer func() {\n\t\tfbo.deferLog.CDebugf(ctx, \"SetEx %s %t done: %+v\",\n\t\t\tgetNodeIDStr(file), ex, err)\n\t}()\n\n\terr = fbo.checkNodeForWrite(ctx, file)\n\tif err != nil {\n\t\treturn\n\t}\n\n\treturn fbo.doMDWriteWithRetryUnlessCanceled(ctx,\n\t\tfunc(lState *lockState) error {\n\t\t\treturn fbo.setExLocked(ctx, lState, file, ex)\n\t\t})\n}\n\nfunc (fbo *folderBranchOps) setMtimeLocked(\n\tctx context.Context, lState *lockState, file Node,\n\tmtime *time.Time) error {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\n\tfilePath, err := fbo.pathFromNodeForMDWriteLocked(lState, file)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Verify we have permission to write (no need to make a successor yet).\n\tmd, err := fbo.getMDForWriteLockedForFilename(ctx, lState, \"\")\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tde, err := fbo.blocks.GetDirtyEntryEvenIfDeleted(\n\t\tctx, lState, md.ReadOnly(), filePath)\n\tif err != nil {\n\t\treturn err\n\t}\n\tde.Mtime = mtime.UnixNano()\n\t// setting the mtime counts as changing the file MD, so must set ctime too\n\tde.Ctime = fbo.nowUnixNano()\n\n\tparentPtr := filePath.parentPath().tailPointer()\n\tsao, err := newSetAttrOp(filePath.tailName(), parentPtr,\n\t\tmtimeAttr, filePath.tailPointer())\n\tif err != nil {\n\t\treturn err\n\t}\n\tsao.AddSelfUpdate(parentPtr)\n\n\t// If the node has been unlinked, we can safely ignore this\n\t// setmtime.\n\tif fbo.nodeCache.IsUnlinked(file) {\n\t\tfbo.log.CDebugf(ctx, \"Skipping setmtime for a removed file %v\",\n\t\t\tfilePath.tailPointer())\n\t\tfbo.blocks.UpdateCachedEntryAttributesOnRemovedFile(\n\t\t\tctx, lState, sao, de)\n\t\treturn nil\n\t}\n\n\tsao.setFinalPath(filePath)\n\n\tdirCacheUndoFn := fbo.blocks.SetAttrInDirEntryInCache(\n\t\tlState, filePath, de, sao.Attr)\n\treturn fbo.notifyAndSyncOrSignal(\n\t\tctx, lState, dirCacheUndoFn, []Node{file}, sao, md.ReadOnly())\n}\n\nfunc (fbo *folderBranchOps) SetMtime(\n\tctx context.Context, file Node, mtime *time.Time) (err error) {\n\tfbo.log.CDebugf(ctx, \"SetMtime %s %v\", getNodeIDStr(file), mtime)\n\tdefer func() {\n\t\tfbo.deferLog.CDebugf(ctx, \"SetMtime %s %v done: %+v\",\n\t\t\tgetNodeIDStr(file), mtime, err)\n\t}()\n\n\tif mtime == nil {\n\t\t// Can happen on some OSes (e.g. OSX) when trying to set the atime only\n\t\treturn nil\n\t}\n\n\terr = fbo.checkNodeForWrite(ctx, file)\n\tif err != nil {\n\t\treturn\n\t}\n\n\treturn fbo.doMDWriteWithRetryUnlessCanceled(ctx,\n\t\tfunc(lState *lockState) error {\n\t\t\treturn fbo.setMtimeLocked(ctx, lState, file, mtime)\n\t\t})\n}\n\ntype cleanupFn func(context.Context, *lockState, []BlockPointer, error)\n\n// startSyncLocked readies the blocks and other state needed to sync a\n// single file.  It returns:\n//\n// * `doSync`: Whether or not the sync should actually happen.\n// * `stillDirty`: Whether the file should still be considered dirty when\n//   this function returns.  (That is, if `doSync` is false, and `stillDirty`\n//   is true, then the file has outstanding changes but the sync was vetoed for\n//   some other reason.)\n// * `fblock`: the root file block for the file being sync'd.\n// * `lbc`: A local block cache consisting of a dirtied version of the parent\n//   directory for this file.\n// * `bps`: All the blocks that need to be put to the server.\n// * `syncState`: Must be passed to the `FinishSyncLocked` call after the\n//   update completes.\n// * `cleanupFn`: A function that, if non-nil, must be called after the sync\n//   is done.  `cleanupFn` should be passed the set of bad blocks that couldn't\n//   be sync'd (if any), and the error.\n// * `err`: The best, greatest return value, everyone says it's absolutely\n//   stunning.\nfunc (fbo *folderBranchOps) startSyncLocked(ctx context.Context,\n\tlState *lockState, md *RootMetadata, node Node, file path) (\n\tdoSync, stillDirty bool, fblock *FileBlock, lbc localBcache,\n\tbps *blockPutState, syncState fileSyncState,\n\tcleanup cleanupFn, err error) {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\n\t// if the cache for this file isn't dirty, we're done\n\tif !fbo.blocks.IsDirty(lState, file) {\n\t\treturn false, false, nil, nil, nil, fileSyncState{}, nil, nil\n\t}\n\n\t// If the MD doesn't match the MD expected by the path, that\n\t// implies we are using a cached path, which implies the node has\n\t// been unlinked.  In that case, we can safely ignore this sync.\n\tif fbo.nodeCache.IsUnlinked(node) {\n\t\tfbo.log.CDebugf(ctx, \"Skipping sync for a removed file %v\",\n\t\t\tfile.tailPointer())\n\t\t// Removing the cached info here is a little sketchy,\n\t\t// since there's no guarantee that this sync comes\n\t\t// from closing the file, and we still want to serve\n\t\t// stat calls accurately if the user still has an open\n\t\t// handle to this file.\n\t\t//\n\t\t// Note in particular that if a file just had a dirty\n\t\t// directory entry cached (due to an attribute change on a\n\t\t// removed file, for example), this will clear that attribute\n\t\t// change.  If there's still an open file handle, the user\n\t\t// won't be able to see the change anymore.\n\t\t//\n\t\t// TODO: Hook this in with the node cache GC logic to be\n\t\t// perfectly accurate (but at the same time, we'd then have to\n\t\t// fix up the intentional panic in the background flusher to\n\t\t// be more tolerant of long-lived dirty, removed files).\n\t\terr := fbo.blocks.ClearCacheInfo(lState, file)\n\t\tif err != nil {\n\t\t\treturn false, false, nil, nil, nil, fileSyncState{}, nil, err\n\t\t}\n\t\tfbo.status.rmDirtyNode(node)\n\t\treturn false, true, nil, nil, nil, fileSyncState{}, nil, nil\n\t}\n\n\tif file.isValidForNotification() {\n\t\t// notify the daemon that a write is being performed\n\t\tfbo.config.Reporter().Notify(ctx, writeNotification(file, false))\n\t\tdefer fbo.config.Reporter().Notify(ctx, writeNotification(file, true))\n\t}\n\n\tfblock, bps, lbc, syncState, err =\n\t\tfbo.blocks.StartSync(ctx, lState, md, file)\n\tcleanup = func(ctx context.Context, lState *lockState,\n\t\tblocksToRemove []BlockPointer, err error) {\n\t\tfbo.blocks.CleanupSyncState(\n\t\t\tctx, lState, md.ReadOnly(), file, blocksToRemove, syncState, err)\n\t}\n\tif err != nil {\n\t\treturn false, true, nil, nil, nil, fileSyncState{}, cleanup, err\n\t}\n\n\treturn true, true, fblock, lbc, bps, syncState, cleanup, nil\n}\n\nfunc addSelfUpdatesAndParent(\n\tp path, op op, parentsToAddChainsFor map[BlockPointer]bool) {\n\tfor i, pn := range p.path {\n\t\tif i == len(p.path)-1 {\n\t\t\top.AddSelfUpdate(pn.BlockPointer)\n\t\t} else {\n\t\t\tparentsToAddChainsFor[pn.BlockPointer] = true\n\t\t}\n\t}\n}\n\nfunc (fbo *folderBranchOps) syncAllLocked(\n\tctx context.Context, lState *lockState, excl Excl) (err error) {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\n\tdirtyFiles := fbo.blocks.GetDirtyFileBlockRefs(lState)\n\tdirtyDirs := fbo.blocks.GetDirtyDirBlockRefs(lState)\n\tif len(dirtyFiles) == 0 && len(dirtyDirs) == 0 {\n\t\treturn nil\n\t}\n\n\tctx = fbo.config.MaybeStartTrace(ctx, \"FBO.SyncAll\",\n\t\tfmt.Sprintf(\"%d files, %d dirs\", len(dirtyFiles), len(dirtyDirs)))\n\tdefer func() { fbo.config.MaybeFinishTrace(ctx, err) }()\n\n\t// Verify we have permission to write.  We do this after the dirty\n\t// check because otherwise readers who call syncAll would get an\n\t// error.\n\tmd, err := fbo.getSuccessorMDForWriteLocked(ctx, lState)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tbps := newBlockPutState(0)\n\tresolvedPaths := make(map[BlockPointer]path)\n\tlbc := make(localBcache)\n\n\tvar cleanups []func(context.Context, *lockState, error)\n\tdefer func() {\n\t\tfor _, cf := range cleanups {\n\t\t\tcf(ctx, lState, err)\n\t\t}\n\t}()\n\n\tfbo.log.LazyTrace(ctx, \"Syncing %d dir(s)\", len(dirtyDirs))\n\n\t// First prep all the directories.\n\tfbo.log.CDebugf(ctx, \"Syncing %d dir(s)\", len(dirtyDirs))\n\tfor _, ref := range dirtyDirs {\n\t\tnode := fbo.nodeCache.Get(ref)\n\t\tif node == nil {\n\t\t\tcontinue\n\t\t}\n\n\t\tdir := fbo.nodeCache.PathFromNode(node)\n\t\tdblock, err := fbo.blocks.GetDirtyDir(ctx, lState, md, dir, blockWrite)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tlbc[dir.tailPointer()] = dblock\n\t\tif !fbo.nodeCache.IsUnlinked(node) {\n\t\t\tresolvedPaths[dir.tailPointer()] = dir\n\t\t}\n\n\t\t// On a successful sync, clean up the cached entries and the\n\t\t// dirty blocks.  TODO: avoid closures by saving `dir` and\n\t\t// `node` in a list for deferred processing.\n\t\tcleanups = append(cleanups,\n\t\t\tfunc(ctx context.Context, lState *lockState, err error) {\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tfbo.blocks.ClearCachedDirEntry(lState, dir)\n\t\t\t\tfbo.status.rmDirtyNode(node)\n\t\t\t})\n\t}\n\tdefer func() {\n\t\t// If the sync is successful, we can clear out all buffered\n\t\t// directory operations.\n\t\tif err == nil {\n\t\t\tfbo.dirOps = nil\n\t\t}\n\t}()\n\n\tfbo.log.LazyTrace(ctx, \"Processing %d op(s)\", len(fbo.dirOps))\n\n\tnewBlocks := make(map[BlockPointer]bool)\n\tfileBlocks := make(fileBlockMap)\n\tparentsToAddChainsFor := make(map[BlockPointer]bool)\n\tfor _, dop := range fbo.dirOps {\n\t\t// Copy the op before modifying it, in case there's an error\n\t\t// and we have to retry with the original ops.\n\t\tnewOp := dop.dirOp.deepCopy()\n\t\tmd.AddOp(newOp)\n\n\t\t// Add \"updates\" for all the op updates, and make chains for\n\t\t// the rest of the parent directories, so they're treated like\n\t\t// updates during the prepping.\n\t\tfor _, n := range dop.nodes {\n\t\t\tp := fbo.nodeCache.PathFromNode(n)\n\t\t\tif _, ok := newOp.(*setAttrOp); ok {\n\t\t\t\t// For a setattr, the node is the file, but that\n\t\t\t\t// doesn't get updated, so use the current parent\n\t\t\t\t// node.\n\t\t\t\tp = *p.parentPath()\n\t\t\t}\n\n\t\t\taddSelfUpdatesAndParent(p, newOp, parentsToAddChainsFor)\n\t\t}\n\n\t\tvar ref BlockRef\n\t\tswitch realOp := newOp.(type) {\n\t\tcase *createOp:\n\t\t\tif realOp.Type == Sym {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// New files and directories explicitly need\n\t\t\t// pointer-updating, because the sync process will turn\n\t\t\t// them into simple refs and will forget about the local,\n\t\t\t// temporary ID.\n\t\t\tnewNode := dop.nodes[1]\n\t\t\tnewPath := fbo.nodeCache.PathFromNode(newNode)\n\t\t\tnewPointer := newPath.tailPointer()\n\t\t\tnewBlocks[newPointer] = true\n\n\t\t\tif realOp.Type != Dir {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tdblock, ok := lbc[newPointer]\n\t\t\tif !ok {\n\t\t\t\t// New directories that aren't otherwise dirty need to\n\t\t\t\t// be added to both the `lbc` and `resolvedPaths` so\n\t\t\t\t// they are properly synced, and removed from the\n\t\t\t\t// dirty block.\n\t\t\t\tdblock, err = fbo.blocks.GetDirtyDir(\n\t\t\t\t\tctx, lState, md, newPath, blockWrite)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tlbc[newPointer] = dblock\n\t\t\t\tif !fbo.nodeCache.IsUnlinked(newNode) {\n\t\t\t\t\tresolvedPaths[newPointer] = newPath\n\t\t\t\t}\n\t\t\t\t// TODO: avoid closures by saving `newPath` and\n\t\t\t\t// `newNode` in a list for deferred processing.\n\t\t\t\tcleanups = append(cleanups,\n\t\t\t\t\tfunc(ctx context.Context, lState *lockState, err error) {\n\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\t}\n\t\t\t\t\t\tfbo.blocks.ClearCachedDirEntry(lState, newPath)\n\t\t\t\t\t\tfbo.status.rmDirtyNode(newNode)\n\t\t\t\t\t})\n\t\t\t}\n\n\t\t\tif len(dblock.Children) > 0 {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// If the directory is empty, we need to explicitly clean\n\t\t\t// up its entry after syncing.\n\t\t\tref = newPath.tailRef()\n\t\tcase *renameOp:\n\t\t\tref = realOp.Renamed.Ref()\n\t\tcase *setAttrOp:\n\t\t\tref = realOp.File.Ref()\n\t\tdefault:\n\t\t\tcontinue\n\t\t}\n\n\t\t// For create, rename and setattr ops, the target will have a\n\t\t// dirty entry, but may not have any outstanding operations on\n\t\t// it, so it needs to be cleaned up manually.\n\t\tdefer func() {\n\t\t\tif err != nil {\n\t\t\t\treturn\n\t\t\t}\n\t\t\twasCleared := fbo.blocks.ClearCachedRef(lState, ref)\n\t\t\tif wasCleared {\n\t\t\t\tnode := fbo.nodeCache.Get(ref)\n\t\t\t\tif node != nil {\n\t\t\t\t\tfbo.status.rmDirtyNode(node)\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\tvar blocksToRemove []BlockPointer\n\t// TODO: find a way to avoid so many dynamic closure dispatches.\n\tvar afterUpdateFns []func() error\n\n\tafterUpdateFns = append(afterUpdateFns, func() error {\n\t\t// Any new files or directories need their pointers explicitly\n\t\t// updated, because the sync will be treating them as a new\n\t\t// ref, and not an update.\n\t\tfor _, bs := range bps.blockStates {\n\t\t\tif newBlocks[bs.oldPtr] {\n\t\t\t\tfbo.blocks.updatePointer(\n\t\t\t\t\tmd.ReadOnly(), bs.oldPtr, bs.blockPtr, false)\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t})\n\n\tfbo.log.LazyTrace(ctx, \"Syncing %d file(s)\", len(dirtyFiles))\n\n\tfbo.log.CDebugf(ctx, \"Syncing %d file(s)\", len(dirtyFiles))\n\tfileSyncBlocks := newBlockPutState(1)\n\tfor _, ref := range dirtyFiles {\n\t\tnode := fbo.nodeCache.Get(ref)\n\t\tif node == nil {\n\t\t\tcontinue\n\t\t}\n\t\tfile := fbo.nodeCache.PathFromNode(node)\n\t\tfbo.log.CDebugf(ctx, \"Syncing file %v (%s)\", ref, file)\n\n\t\t// Start the sync for this dirty file.\n\t\tdoSync, stillDirty, fblock, newLbc, newBps, syncState, cleanup, err :=\n\t\t\tfbo.startSyncLocked(ctx, lState, md, node, file)\n\t\tif cleanup != nil {\n\t\t\t// Note: This passes the same `blocksToRemove` into each\n\t\t\t// cleanup function.  That's ok, as only the ones\n\t\t\t// pertaining to a particular syncing file will be acted\n\t\t\t// on.\n\t\t\tcleanups = append(cleanups,\n\t\t\t\tfunc(ctx context.Context, lState *lockState, err error) {\n\t\t\t\t\tcleanup(ctx, lState, blocksToRemove, err)\n\t\t\t\t})\n\t\t}\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif !doSync {\n\t\t\tif !stillDirty {\n\t\t\t\tfbo.status.rmDirtyNode(node)\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\t// Merge the per-file sync info into the batch sync info.\n\t\tbps.mergeOtherBps(newBps)\n\t\tfileSyncBlocks.mergeOtherBps(newBps)\n\t\tresolvedPaths[file.tailPointer()] = file\n\t\tparent := file.parentPath().tailPointer()\n\t\tif _, ok := fileBlocks[parent]; !ok {\n\t\t\tfileBlocks[parent] = make(map[string]*FileBlock)\n\t\t}\n\t\tfileBlocks[parent][file.tailName()] = fblock\n\n\t\t// Collect its `afterUpdateFn` along with all the others, so\n\t\t// they all get invoked under the same lock, to avoid any\n\t\t// weird races.\n\t\tafterUpdateFns = append(afterUpdateFns, func() error {\n\t\t\t// This will be called after the node cache is updated, so\n\t\t\t// this newPath will be correct.\n\t\t\tnewPath := fbo.nodeCache.PathFromNode(node)\n\t\t\tstillDirty, err := fbo.blocks.FinishSyncLocked(\n\t\t\t\tctx, lState, file, newPath, md.ReadOnly(), syncState, fbo.fbm)\n\t\t\tif !stillDirty {\n\t\t\t\tfbo.status.rmDirtyNode(node)\n\t\t\t}\n\t\t\treturn err\n\t\t})\n\n\t\t// Add an \"update\" for all the parent directory updates, and\n\t\t// make a chain for the file itself, so they're treated like\n\t\t// updates during the prepping.\n\t\tlastOp := md.Data().Changes.Ops[len(md.Data().Changes.Ops)-1]\n\t\taddSelfUpdatesAndParent(file, lastOp, parentsToAddChainsFor)\n\n\t\t// Update the combined local block cache with this file's\n\t\t// dirty entry.\n\t\tparentPtr := file.parentPath().tailPointer()\n\t\tif _, ok := lbc[parentPtr]; ok {\n\t\t\tlbc[parentPtr].Children[file.tailName()] =\n\t\t\t\tnewLbc[parentPtr].Children[file.tailName()]\n\t\t} else {\n\t\t\tlbc[parentPtr] = newLbc[parentPtr]\n\t\t}\n\t}\n\n\tsession, err := fbo.config.KBPKI().GetCurrentSession(ctx)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\ttempIRMD := ImmutableRootMetadata{\n\t\tReadOnlyRootMetadata:   md.ReadOnly(),\n\t\tlastWriterVerifyingKey: session.VerifyingKey,\n\t}\n\n\tfbo.log.LazyTrace(ctx, \"Prepping update\")\n\n\t// Create a set of chains for this batch, a succinct summary of\n\t// the file and directory blocks that need to change during this\n\t// sync.\n\tsyncChains, err := newCRChains(\n\t\tctx, fbo.config.Codec(), []chainMetadata{tempIRMD}, &fbo.blocks, false)\n\tif err != nil {\n\t\treturn err\n\t}\n\tfor ptr := range parentsToAddChainsFor {\n\t\tsyncChains.addNoopChain(ptr)\n\t}\n\n\t// All originals never made it to the server, so don't unmerged\n\t// them.\n\tsyncChains.doNotUnrefPointers = syncChains.createdOriginals\n\thead, _ := fbo.getHead(lState)\n\tdummyHeadChains := newCRChainsEmpty()\n\tdummyHeadChains.mostRecentChainMDInfo = mostRecentChainMetadataInfo{\n\t\thead, head.Data().Dir.BlockInfo}\n\n\t// Squash the batch of updates together into a set of blocks and\n\t// ready `md` for putting to the server.\n\tmd.AddOp(newResolutionOp())\n\t_, newBps, blocksToDelete, err := fbo.prepper.prepUpdateForPaths(\n\t\tctx, lState, md, syncChains, dummyHeadChains, tempIRMD, head,\n\t\tresolvedPaths, lbc, fileBlocks, fbo.config.DirtyBlockCache(),\n\t\tprepFolderDontCopyIndirectFileBlocks)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif len(blocksToDelete) > 0 {\n\t\treturn errors.Errorf(\"Unexpectedly found unflushed blocks to delete \"+\n\t\t\t\"during syncAllLocked: %v\", blocksToDelete)\n\t}\n\tbps.mergeOtherBps(newBps)\n\n\tdefer func() {\n\t\tif err != nil {\n\t\t\t// Remove any blocks that are covered by file syncs --\n\t\t\t// those might get reused upon sync retry.  All other\n\t\t\t// blocks are fair game for cleanup though.\n\t\t\tbps.removeOtherBps(fileSyncBlocks)\n\t\t\tfbo.fbm.cleanUpBlockState(md.ReadOnly(), bps, blockDeleteOnMDFail)\n\t\t}\n\t}()\n\n\t// Put all the blocks.\n\tblocksToRemove, err = doBlockPuts(ctx, fbo.config.BlockServer(),\n\t\tfbo.config.BlockCache(), fbo.config.Reporter(), fbo.log, fbo.deferLog, md.TlfID(),\n\t\tmd.GetTlfHandle().GetCanonicalName(), *bps)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Call this under the same blockLock as when the pointers are\n\t// updated, so there's never any point in time where a read or\n\t// write might slip in after the pointers are updated, but before\n\t// the deferred writes are re-applied.\n\tafterUpdateFn := func() error {\n\t\tvar errs []error\n\t\tfor _, auf := range afterUpdateFns {\n\t\t\terr := auf()\n\t\t\tif err != nil {\n\t\t\t\terrs = append(errs, err)\n\t\t\t}\n\t\t}\n\t\tif len(errs) == 1 {\n\t\t\treturn errs[0]\n\t\t} else if len(errs) > 1 {\n\t\t\treturn errors.Errorf(\"Got errors %+v\", errs)\n\t\t}\n\t\treturn nil\n\t}\n\n\treturn fbo.finalizeMDWriteLocked(ctx, lState, md, bps, excl,\n\t\tfunc(md ImmutableRootMetadata) error {\n\t\t\t// Just update the pointers using the resolutionOp, all\n\t\t\t// the ops have already been notified.\n\t\t\taffectedNodeIDs, err := fbo.blocks.UpdatePointers(\n\t\t\t\tmd, lState, md.data.Changes.Ops[0], false, afterUpdateFn)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tfbo.observers.batchChanges(ctx, nil, affectedNodeIDs)\n\t\t\treturn nil\n\t\t})\n}\n\nfunc (fbo *folderBranchOps) syncAllUnlocked(\n\tctx context.Context, lState *lockState) error {\n\tfbo.mdWriterLock.Lock(lState)\n\tdefer fbo.mdWriterLock.Unlock(lState)\n\n\tselect {\n\tcase <-ctx.Done():\n\t\t// We've already been canceled, possibly because we're a CR\n\t\t// and a write just called cr.ForceCancel.  Don't allow the\n\t\t// SyncAll to complete, because if no other writes happen\n\t\t// we'll get stuck forever (see KBFS-2505).  Instead, wait for\n\t\t// the next `SyncAll` to trigger.\n\t\treturn ctx.Err()\n\tdefault:\n\t}\n\n\treturn fbo.syncAllLocked(ctx, lState, NoExcl)\n}\n\n// SyncAll implements the KBFSOps interface for folderBranchOps.\nfunc (fbo *folderBranchOps) SyncAll(\n\tctx context.Context, folderBranch FolderBranch) (err error) {\n\tfbo.log.CDebugf(ctx, \"SyncAll\")\n\tdefer func() { fbo.deferLog.CDebugf(ctx, \"SyncAll done: %+v\", err) }()\n\n\tif folderBranch != fbo.folderBranch {\n\t\treturn WrongOpsError{fbo.folderBranch, folderBranch}\n\t}\n\n\treturn fbo.doMDWriteWithRetryUnlessCanceled(ctx,\n\t\tfunc(lState *lockState) error {\n\t\t\treturn fbo.syncAllLocked(ctx, lState, NoExcl)\n\t\t})\n}\n\nfunc (fbo *folderBranchOps) FolderStatus(\n\tctx context.Context, folderBranch FolderBranch) (\n\tfbs FolderBranchStatus, updateChan <-chan StatusUpdate, err error) {\n\tfbo.log.CDebugf(ctx, \"Status\")\n\tdefer func() { fbo.deferLog.CDebugf(ctx, \"Status done: %+v\", err) }()\n\n\tif folderBranch != fbo.folderBranch {\n\t\treturn FolderBranchStatus{}, nil,\n\t\t\tWrongOpsError{fbo.folderBranch, folderBranch}\n\t}\n\n\treturn fbo.status.getStatus(ctx, &fbo.blocks)\n}\n\nfunc (fbo *folderBranchOps) Status(\n\tctx context.Context) (\n\tfbs KBFSStatus, updateChan <-chan StatusUpdate, err error) {\n\treturn KBFSStatus{}, nil, InvalidOpError{}\n}\n\n// RegisterForChanges registers a single Observer to receive\n// notifications about this folder/branch.\nfunc (fbo *folderBranchOps) RegisterForChanges(obs Observer) error {\n\t// It's the caller's responsibility to make sure\n\t// RegisterForChanges isn't called twice for the same Observer\n\tfbo.observers.add(obs)\n\treturn nil\n}\n\n// UnregisterFromChanges stops an Observer from getting notifications\n// about the folder/branch.\nfunc (fbo *folderBranchOps) UnregisterFromChanges(obs Observer) error {\n\tfbo.observers.remove(obs)\n\treturn nil\n}\n\n// notifyBatchLocked sends out a notification for all the ops in md.\nfunc (fbo *folderBranchOps) notifyBatchLocked(\n\tctx context.Context, lState *lockState, md ImmutableRootMetadata) error {\n\tfbo.headLock.AssertLocked(lState)\n\n\tfor _, op := range md.data.Changes.Ops {\n\t\terr := fbo.notifyOneOpLocked(ctx, lState, op, md.ReadOnly(), false)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\n// searchForNode tries to figure out the path to the given\n// blockPointer, using only the block updates that happened as part of\n// a given MD update operation.\nfunc (fbo *folderBranchOps) searchForNode(ctx context.Context,\n\tptr BlockPointer, md ReadOnlyRootMetadata) (Node, error) {\n\t// Record which pointers are new to this update, and thus worth\n\t// searching.\n\tnewPtrs := make(map[BlockPointer]bool)\n\tfor _, op := range md.data.Changes.Ops {\n\t\tfor _, update := range op.allUpdates() {\n\t\t\tnewPtrs[update.Ref] = true\n\t\t}\n\t\tfor _, ref := range op.Refs() {\n\t\t\tnewPtrs[ref] = true\n\t\t}\n\t}\n\n\tnodeMap, _, err := fbo.blocks.SearchForNodes(ctx, fbo.nodeCache,\n\t\t[]BlockPointer{ptr}, newPtrs, md, md.data.Dir.BlockPointer)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tn, ok := nodeMap[ptr]\n\tif !ok {\n\t\treturn nil, NodeNotFoundError{ptr}\n\t}\n\n\treturn n, nil\n}\n\nfunc (fbo *folderBranchOps) getUnlinkPathBeforeUpdatingPointers(\n\tctx context.Context, lState *lockState, md ReadOnlyRootMetadata, op op) (\n\tunlinkPath path, unlinkDe DirEntry, toUnlink bool, err error) {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\tif len(md.data.Changes.Ops) == 0 {\n\t\treturn path{}, DirEntry{}, false, errors.New(\"md needs at least one op\")\n\t}\n\n\tvar node Node\n\tvar childName string\n\n\trequireResFix := false\n\tswitch realOp := op.(type) {\n\tcase *rmOp:\n\t\tif realOp.Dir.Ref == realOp.Dir.Unref {\n\t\t\trequireResFix = true\n\t\t}\n\t\tnode = fbo.nodeCache.Get(realOp.Dir.Unref.Ref())\n\t\tchildName = realOp.OldName\n\tcase *renameOp:\n\t\tif realOp.NewDir.Unref != zeroPtr {\n\t\t\t// moving to a new dir\n\t\t\tif realOp.NewDir.Ref == realOp.NewDir.Unref {\n\t\t\t\trequireResFix = true\n\t\t\t}\n\t\t\tnode = fbo.nodeCache.Get(realOp.NewDir.Unref.Ref())\n\t\t} else {\n\t\t\t// moving to the same dir\n\t\t\tif realOp.OldDir.Ref == realOp.OldDir.Unref {\n\t\t\t\trequireResFix = true\n\t\t\t}\n\t\t\tnode = fbo.nodeCache.Get(realOp.OldDir.Unref.Ref())\n\t\t}\n\t\tchildName = realOp.NewName\n\t}\n\tif node == nil {\n\t\treturn path{}, DirEntry{}, false, nil\n\t}\n\n\tp, err := fbo.pathFromNodeForRead(node)\n\tif err != nil {\n\t\treturn path{}, DirEntry{}, false, err\n\t}\n\n\t// If the first op in this MD update is a resolutionOp, we need to\n\t// inspect it to look for the *real* original pointer for this\n\t// node.  Though only do that if the op we're processing is\n\t// actually a part of this MD object; if it's the latest cached\n\t// dirOp, then the resOp we're looking at belongs to a previous\n\t// revision.\n\tif resOp, ok := md.data.Changes.Ops[0].(*resolutionOp); ok &&\n\t\t(len(fbo.dirOps) == 0 || op != fbo.dirOps[len(fbo.dirOps)-1].dirOp) {\n\t\tfor _, update := range resOp.allUpdates() {\n\t\t\tif update.Ref == p.tailPointer() {\n\t\t\t\tfbo.log.CDebugf(ctx,\n\t\t\t\t\t\"Backing up ptr %v in op %s to original pointer %v\",\n\t\t\t\t\tp.tailPointer(), op, update.Unref)\n\t\t\t\tp.path[len(p.path)-1].BlockPointer = update.Unref\n\t\t\t\trequireResFix = false\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\n\tif requireResFix {\n\t\t// If we didn't fix up the pointer using a resolutionOp, the\n\t\t// directory was likely created during this md update, and so\n\t\t// no unlinking is needed.\n\t\tfbo.log.CDebugf(ctx,\n\t\t\t\"Ignoring unlink when resolutionOp never fixed up %v\",\n\t\t\tp.tailPointer())\n\t\treturn path{}, DirEntry{}, false, nil\n\t}\n\n\t// If the original (clean) parent block is already GC'd from the\n\t// server, this might not work, but hopefully we'd be\n\t// fast-forwarding in that case anyway.\n\tdblock, err := fbo.blocks.GetDir(ctx, lState, md, p, blockRead)\n\tif err != nil {\n\t\tfbo.log.CDebugf(ctx, \"Couldn't get the dir entry for %s in %v: %+v\",\n\t\t\tchildName, p.tailPointer(), err)\n\t\treturn path{}, DirEntry{}, false, nil\n\t}\n\tde, ok := dblock.Children[childName]\n\tif !ok {\n\t\treturn path{}, DirEntry{}, false, nil\n\t}\n\tchildPath := p.ChildPath(childName, de.BlockPointer)\n\treturn childPath, de, true, nil\n}\n\nfunc (fbo *folderBranchOps) notifyOneOpLocked(ctx context.Context,\n\tlState *lockState, op op, md ReadOnlyRootMetadata,\n\tshouldPrefetch bool) error {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\tfbo.headLock.AssertLocked(lState)\n\n\tif !fbo.config.Mode().NodeCacheEnabled() {\n\t\t// There is no node cache in minimal mode, so there's nothing\n\t\t// to update.\n\t\treturn nil\n\t}\n\n\t// We need to get unlinkPath before calling UpdatePointers so that\n\t// nodeCache.Unlink can properly update cachedPath.\n\tunlinkPath, unlinkDe, toUnlink, err :=\n\t\tfbo.getUnlinkPathBeforeUpdatingPointers(ctx, lState, md, op)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\taffectedNodeIDs, err := fbo.blocks.UpdatePointers(\n\t\tmd, lState, op, shouldPrefetch, nil)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Cancel any block prefetches for unreferenced blocks.\n\tfor _, ptr := range op.Unrefs() {\n\t\tfbo.config.BlockOps().Prefetcher().CancelPrefetch(ptr.ID)\n\t}\n\n\tvar changes []NodeChange\n\tswitch realOp := op.(type) {\n\tdefault:\n\t\tfbo.log.CDebugf(ctx, \"Unknown op: %s\", op)\n\tcase *createOp:\n\t\tnode := fbo.nodeCache.Get(realOp.Dir.Ref.Ref())\n\t\tif node == nil {\n\t\t\tbreak\n\t\t}\n\t\tfbo.log.CDebugf(ctx, \"notifyOneOp: create %s in node %s\",\n\t\t\trealOp.NewName, getNodeIDStr(node))\n\t\tchanges = append(changes, NodeChange{\n\t\t\tNode:       node,\n\t\t\tDirUpdated: []string{realOp.NewName},\n\t\t})\n\tcase *rmOp:\n\t\tnode := fbo.nodeCache.Get(realOp.Dir.Ref.Ref())\n\t\tif node == nil {\n\t\t\tbreak\n\t\t}\n\t\tfbo.log.CDebugf(ctx, \"notifyOneOp: remove %s in node %s\",\n\t\t\trealOp.OldName, getNodeIDStr(node))\n\t\tchanges = append(changes, NodeChange{\n\t\t\tNode:       node,\n\t\t\tDirUpdated: []string{realOp.OldName},\n\t\t})\n\n\t\t// If this node exists, then the child node might exist too,\n\t\t// and we need to unlink it in the node cache.\n\t\tif toUnlink {\n\t\t\t_ = fbo.nodeCache.Unlink(unlinkDe.Ref(), unlinkPath, unlinkDe)\n\t\t}\n\tcase *renameOp:\n\t\toldNode := fbo.nodeCache.Get(realOp.OldDir.Ref.Ref())\n\t\tif oldNode != nil {\n\t\t\tchanges = append(changes, NodeChange{\n\t\t\t\tNode:       oldNode,\n\t\t\t\tDirUpdated: []string{realOp.OldName},\n\t\t\t})\n\t\t}\n\t\tvar newNode Node\n\t\tif realOp.NewDir.Ref != zeroPtr {\n\t\t\tnewNode = fbo.nodeCache.Get(realOp.NewDir.Ref.Ref())\n\t\t\tif newNode != nil {\n\t\t\t\tchanges = append(changes, NodeChange{\n\t\t\t\t\tNode:       newNode,\n\t\t\t\t\tDirUpdated: []string{realOp.NewName},\n\t\t\t\t})\n\t\t\t}\n\t\t} else {\n\t\t\tnewNode = oldNode\n\t\t\tif oldNode != nil {\n\t\t\t\t// Add another name to the existing NodeChange.\n\t\t\t\tchanges[len(changes)-1].DirUpdated =\n\t\t\t\t\tappend(changes[len(changes)-1].DirUpdated, realOp.NewName)\n\t\t\t}\n\t\t}\n\n\t\tif oldNode != nil {\n\t\t\tfbo.log.CDebugf(ctx, \"notifyOneOp: rename %v from %s/%s to %s/%s\",\n\t\t\t\trealOp.Renamed, realOp.OldName, getNodeIDStr(oldNode),\n\t\t\t\trealOp.NewName, getNodeIDStr(newNode))\n\n\t\t\tif newNode == nil {\n\t\t\t\tif childNode :=\n\t\t\t\t\tfbo.nodeCache.Get(realOp.Renamed.Ref()); childNode != nil {\n\t\t\t\t\t// if the childNode exists, we still have to update\n\t\t\t\t\t// its path to go through the new node.  That means\n\t\t\t\t\t// creating nodes for all the intervening paths.\n\t\t\t\t\t// Unfortunately we don't have enough information to\n\t\t\t\t\t// know what the newPath is; we have to guess it from\n\t\t\t\t\t// the updates.\n\t\t\t\t\tvar err error\n\t\t\t\t\tnewNode, err =\n\t\t\t\t\t\tfbo.searchForNode(ctx, realOp.NewDir.Ref, md)\n\t\t\t\t\tif newNode == nil {\n\t\t\t\t\t\tfbo.log.CErrorf(ctx, \"Couldn't find the new node: %v\",\n\t\t\t\t\t\t\terr)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif newNode != nil {\n\t\t\t\tif toUnlink {\n\t\t\t\t\t_ = fbo.nodeCache.Unlink(\n\t\t\t\t\t\tunlinkDe.Ref(), unlinkPath, unlinkDe)\n\t\t\t\t}\n\t\t\t\t_, err := fbo.nodeCache.Move(\n\t\t\t\t\trealOp.Renamed.Ref(), newNode, realOp.NewName)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\tcase *syncOp:\n\t\tnode := fbo.nodeCache.Get(realOp.File.Ref.Ref())\n\t\tif node == nil {\n\t\t\tbreak\n\t\t}\n\t\tfbo.log.CDebugf(ctx, \"notifyOneOp: sync %d writes in node %s\",\n\t\t\tlen(realOp.Writes), getNodeIDStr(node))\n\n\t\tchanges = append(changes, NodeChange{\n\t\t\tNode:        node,\n\t\t\tFileUpdated: realOp.Writes,\n\t\t})\n\tcase *setAttrOp:\n\t\tnode := fbo.nodeCache.Get(realOp.Dir.Ref.Ref())\n\t\tif node == nil {\n\t\t\tbreak\n\t\t}\n\t\tfbo.log.CDebugf(ctx, \"notifyOneOp: setAttr %s for file %s in node %s\",\n\t\t\trealOp.Attr, realOp.Name, getNodeIDStr(node))\n\n\t\tp, err := fbo.pathFromNodeForRead(node)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tchildNode, err := fbo.blocks.UpdateCachedEntryAttributes(\n\t\t\tctx, lState, md, p, realOp)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif childNode == nil {\n\t\t\tbreak\n\t\t}\n\n\t\tchanges = append(changes, NodeChange{\n\t\t\tNode: childNode,\n\t\t})\n\tcase *GCOp:\n\t\t// Unreferenced blocks in a GCOp mean that we shouldn't cache\n\t\t// them anymore\n\t\tfbo.log.CDebugf(ctx, \"notifyOneOp: GCOp with latest rev %d and %d unref'd blocks\", realOp.LatestRev, len(realOp.Unrefs()))\n\t\tbcache := fbo.config.BlockCache()\n\t\tidsToDelete := make([]kbfsblock.ID, 0, len(realOp.Unrefs()))\n\t\tfor _, ptr := range realOp.Unrefs() {\n\t\t\tidsToDelete = append(idsToDelete, ptr.ID)\n\t\t\tif err := bcache.DeleteTransient(ptr, fbo.id()); err != nil {\n\t\t\t\tfbo.log.CDebugf(ctx,\n\t\t\t\t\t\"Couldn't delete transient entry for %v: %v\", ptr, err)\n\t\t\t}\n\t\t}\n\t\tdiskCache := fbo.config.DiskBlockCache()\n\t\tif diskCache != nil {\n\t\t\tgo diskCache.Delete(ctx, idsToDelete)\n\t\t}\n\tcase *resolutionOp:\n\t\t// If there are any unrefs of blocks that have a node, this is an\n\t\t// implied rmOp (see KBFS-1424).\n\t\treverseUpdates := make(map[BlockPointer]BlockPointer)\n\t\tfor _, unref := range op.Unrefs() {\n\t\t\tnode := fbo.nodeCache.Get(unref.Ref())\n\t\t\tif node == nil {\n\t\t\t\t// TODO: even if we don't have the node that was\n\t\t\t\t// unreferenced, we might have its parent, and that\n\t\t\t\t// parent might need an invalidation.\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// If there is a node, unlink and invalidate.\n\t\t\tp, err := fbo.pathFromNodeForRead(node)\n\t\t\tif err != nil {\n\t\t\t\tfbo.log.CErrorf(ctx, \"Couldn't get path: %v\", err)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif !p.hasValidParent() {\n\t\t\t\tfbo.log.CErrorf(ctx, \"Removed node %s has no parent\", p)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tparentPath := p.parentPath()\n\t\t\tparentNode := fbo.nodeCache.Get(parentPath.tailRef())\n\t\t\tif parentNode != nil {\n\t\t\t\tchanges = append(changes, NodeChange{\n\t\t\t\t\tNode:       parentNode,\n\t\t\t\t\tDirUpdated: []string{p.tailName()},\n\t\t\t\t})\n\t\t\t}\n\n\t\t\tfbo.log.CDebugf(ctx, \"resolutionOp: remove %s, node %s\",\n\t\t\t\tp.tailPointer(), getNodeIDStr(node))\n\t\t\t// Revert the path back to the original BlockPointers,\n\t\t\t// before the updates were applied.\n\t\t\tif len(reverseUpdates) == 0 {\n\t\t\t\tfor _, update := range op.allUpdates() {\n\t\t\t\t\treverseUpdates[update.Ref] = update.Unref\n\t\t\t\t}\n\t\t\t}\n\t\t\tfor i, pNode := range p.path {\n\t\t\t\tif oldPtr, ok := reverseUpdates[pNode.BlockPointer]; ok {\n\t\t\t\t\tp.path[i].BlockPointer = oldPtr\n\t\t\t\t}\n\t\t\t}\n\t\t\tde, err := fbo.blocks.GetDirtyEntry(ctx, lState, md, p)\n\t\t\tif err != nil {\n\t\t\t\tfbo.log.CDebugf(ctx,\n\t\t\t\t\t\"Couldn't get the dir entry for %s/%v: %+v\",\n\t\t\t\t\tp, p.tailPointer(), err)\n\t\t\t}\n\t\t\t_ = fbo.nodeCache.Unlink(p.tailRef(), p, de)\n\t\t}\n\t}\n\n\tif len(changes) > 0 || len(affectedNodeIDs) > 0 {\n\t\tfbo.observers.batchChanges(ctx, changes, affectedNodeIDs)\n\t}\n\treturn nil\n}\n\nfunc (fbo *folderBranchOps) notifyOneOp(ctx context.Context,\n\tlState *lockState, op op, md ReadOnlyRootMetadata,\n\tshouldPrefetch bool) error {\n\tfbo.headLock.Lock(lState)\n\tdefer fbo.headLock.Unlock(lState)\n\treturn fbo.notifyOneOpLocked(ctx, lState, op, md, shouldPrefetch)\n}\n\nfunc (fbo *folderBranchOps) getCurrMDRevisionLocked(lState *lockState) kbfsmd.Revision {\n\tfbo.headLock.AssertAnyLocked(lState)\n\n\tif fbo.head != (ImmutableRootMetadata{}) {\n\t\treturn fbo.head.Revision()\n\t}\n\treturn kbfsmd.RevisionUninitialized\n}\n\nfunc (fbo *folderBranchOps) getCurrMDRevision(\n\tlState *lockState) kbfsmd.Revision {\n\tfbo.headLock.RLock(lState)\n\tdefer fbo.headLock.RUnlock(lState)\n\treturn fbo.getCurrMDRevisionLocked(lState)\n}\n\ntype applyMDUpdatesFunc func(context.Context, *lockState, []ImmutableRootMetadata) error\n\nfunc (fbo *folderBranchOps) applyMDUpdatesLocked(ctx context.Context,\n\tlState *lockState, rmds []ImmutableRootMetadata) error {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\n\t// If there's anything in the journal, don't apply these MDs.\n\t// Wait for CR to happen.\n\tif fbo.isMasterBranchLocked(lState) {\n\t\tmergedRev, err := fbo.getJournalPredecessorRevision(ctx)\n\t\tif err == errNoFlushedRevisions {\n\t\t\t// If the journal is still on the initial revision, ignore\n\t\t\t// the error and fall through to ignore CR.\n\t\t\tmergedRev = kbfsmd.RevisionInitial\n\t\t} else if err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif mergedRev != kbfsmd.RevisionUninitialized {\n\t\t\tif len(rmds) > 0 {\n\t\t\t\t// We should update our view of the merged master though,\n\t\t\t\t// to avoid re-registering for the same updates again.\n\t\t\t\tfunc() {\n\t\t\t\t\tfbo.headLock.Lock(lState)\n\t\t\t\t\tdefer fbo.headLock.Unlock(lState)\n\t\t\t\t\tfbo.setLatestMergedRevisionLocked(\n\t\t\t\t\t\tctx, lState, rmds[len(rmds)-1].Revision(), false)\n\t\t\t\t}()\n\t\t\t}\n\n\t\t\tfbo.log.CDebugf(ctx,\n\t\t\t\t\"Ignoring fetched revisions while MDs are in journal\")\n\t\t\treturn nil\n\t\t}\n\t}\n\n\tfbo.headLock.Lock(lState)\n\tdefer fbo.headLock.Unlock(lState)\n\n\t// if we have staged changes, ignore all updates until conflict\n\t// resolution kicks in.  TODO: cache these for future use.\n\tif !fbo.isMasterBranchLocked(lState) {\n\t\tif len(rmds) > 0 {\n\t\t\tlatestMerged := rmds[len(rmds)-1]\n\t\t\t// Don't trust un-put updates here because they might have\n\t\t\t// come from our own journal before the conflict was\n\t\t\t// detected.  Assume we'll hear about the conflict via\n\t\t\t// callbacks from the journal.\n\t\t\tif !latestMerged.putToServer {\n\t\t\t\treturn UnmergedError{}\n\t\t\t}\n\n\t\t\t// setHeadLocked takes care of merged case\n\t\t\tfbo.setLatestMergedRevisionLocked(\n\t\t\t\tctx, lState, latestMerged.Revision(), false)\n\n\t\t\tunmergedRev := kbfsmd.RevisionUninitialized\n\t\t\tif fbo.head != (ImmutableRootMetadata{}) {\n\t\t\t\tunmergedRev = fbo.head.Revision()\n\t\t\t}\n\t\t\tfbo.cr.Resolve(ctx, unmergedRev, latestMerged.Revision())\n\t\t}\n\t\treturn UnmergedError{}\n\t}\n\n\t// Don't allow updates while we're in the dirty state; the next\n\t// sync will put us into an unmerged state anyway and we'll\n\t// require conflict resolution.\n\tif fbo.blocks.GetState(lState) != cleanState {\n\t\treturn errors.WithStack(NoUpdatesWhileDirtyError{})\n\t}\n\n\tappliedRevs := make([]ImmutableRootMetadata, 0, len(rmds))\n\tfor _, rmd := range rmds {\n\t\t// check that we're applying the expected MD revision\n\t\tif rmd.Revision() <= fbo.getCurrMDRevisionLocked(lState) {\n\t\t\t// Already caught up!\n\t\t\tcontinue\n\t\t}\n\t\tif err := isReadableOrError(ctx, fbo.config.KBPKI(), rmd.ReadOnly()); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\terr := fbo.setHeadSuccessorLocked(ctx, lState, rmd, false)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\t// No new operations in these.\n\t\tif rmd.IsWriterMetadataCopiedSet() {\n\t\t\tcontinue\n\t\t}\n\t\tfor _, op := range rmd.data.Changes.Ops {\n\t\t\terr := fbo.notifyOneOpLocked(ctx, lState, op, rmd.ReadOnly(), true)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\tif rmd.IsRekeySet() {\n\t\t\t// One might have concern that a MD update written by the device\n\t\t\t// itself can slip in here, for example during the rekey after\n\t\t\t// setting paper prompt, and the event may cause the paper prompt\n\t\t\t// to be unset. This is not a problem because 1) the revision check\n\t\t\t// above shouldn't allow MD update written by this device to reach\n\t\t\t// here; 2) the rekey FSM doesn't touch anything if it has the\n\t\t\t// paper prompt set and is in scheduled state.\n\t\t\tfbo.rekeyFSM.Event(NewRekeyRequestEvent())\n\t\t} else {\n\t\t\tfbo.rekeyFSM.Event(NewRekeyNotNeededEvent())\n\t\t}\n\t\tappliedRevs = append(appliedRevs, rmd)\n\t}\n\treturn nil\n}\n\nfunc (fbo *folderBranchOps) undoMDUpdatesLocked(ctx context.Context,\n\tlState *lockState, rmds []ImmutableRootMetadata) error {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\n\tfbo.headLock.Lock(lState)\n\tdefer fbo.headLock.Unlock(lState)\n\n\t// Don't allow updates while we're in the dirty state; the next\n\t// sync will put us into an unmerged state anyway and we'll\n\t// require conflict resolution.\n\tif fbo.blocks.GetState(lState) != cleanState {\n\t\treturn NotPermittedWhileDirtyError{}\n\t}\n\n\t// go backwards through the updates\n\tfor i := len(rmds) - 1; i >= 0; i-- {\n\t\trmd := rmds[i]\n\t\t// on undo, it's ok to re-apply the current revision since you\n\t\t// need to invert all of its ops.\n\t\t//\n\t\t// This duplicates a check in\n\t\t// fbo.setHeadPredecessorLocked. TODO: Remove this\n\t\t// duplication.\n\t\tif rmd.Revision() != fbo.getCurrMDRevisionLocked(lState) &&\n\t\t\trmd.Revision() != fbo.getCurrMDRevisionLocked(lState)-1 {\n\t\t\treturn MDUpdateInvertError{rmd.Revision(),\n\t\t\t\tfbo.getCurrMDRevisionLocked(lState)}\n\t\t}\n\n\t\t// TODO: Check that the revisions are equal only for\n\t\t// the first iteration.\n\t\tif rmd.Revision() < fbo.getCurrMDRevisionLocked(lState) {\n\t\t\terr := fbo.setHeadPredecessorLocked(ctx, lState, rmd)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\t// iterate the ops in reverse and invert each one\n\t\tops := rmd.data.Changes.Ops\n\t\tfor j := len(ops) - 1; j >= 0; j-- {\n\t\t\tio, err := invertOpForLocalNotifications(ops[j])\n\t\t\tif err != nil {\n\t\t\t\tfbo.log.CWarningf(ctx,\n\t\t\t\t\t\"got error %v when invert op %v; \"+\n\t\t\t\t\t\t\"skipping. Open file handles \"+\n\t\t\t\t\t\t\"may now be in an invalid \"+\n\t\t\t\t\t\t\"state, which can be fixed by \"+\n\t\t\t\t\t\t\"either closing them all or \"+\n\t\t\t\t\t\t\"restarting KBFS.\",\n\t\t\t\t\terr, ops[j])\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\terr = fbo.notifyOneOpLocked(ctx, lState, io, rmd.ReadOnly(), false)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\t// TODO: update the edit history?\n\treturn nil\n}\n\nfunc (fbo *folderBranchOps) applyMDUpdates(ctx context.Context,\n\tlState *lockState, rmds []ImmutableRootMetadata) error {\n\tfbo.mdWriterLock.Lock(lState)\n\tdefer fbo.mdWriterLock.Unlock(lState)\n\treturn fbo.applyMDUpdatesLocked(ctx, lState, rmds)\n}\n\nfunc (fbo *folderBranchOps) getLatestMergedRevision(lState *lockState) kbfsmd.Revision {\n\tfbo.headLock.RLock(lState)\n\tdefer fbo.headLock.RUnlock(lState)\n\treturn fbo.latestMergedRevision\n}\n\n// caller should have held fbo.headLock\nfunc (fbo *folderBranchOps) setLatestMergedRevisionLocked(ctx context.Context, lState *lockState, rev kbfsmd.Revision, allowBackward bool) {\n\tfbo.headLock.AssertLocked(lState)\n\tif rev == kbfsmd.RevisionUninitialized {\n\t\tpanic(\"Cannot set latest merged revision to an uninitialized value\")\n\t}\n\n\tif fbo.latestMergedRevision < rev || allowBackward {\n\t\tfbo.latestMergedRevision = rev\n\t\tfbo.log.CDebugf(ctx, \"Updated latestMergedRevision to %d.\", rev)\n\t} else {\n\t\tfbo.log.CDebugf(ctx, \"Local latestMergedRevision (%d) is higher than \"+\n\t\t\t\"the new revision (%d); won't update.\", fbo.latestMergedRevision, rev)\n\t}\n}\n\n// Assumes all necessary locking is either already done by caller, or\n// is done by applyFunc.\nfunc (fbo *folderBranchOps) getAndApplyMDUpdates(ctx context.Context,\n\tlState *lockState, lockBeforeGet *keybase1.LockID,\n\tapplyFunc applyMDUpdatesFunc) error {\n\t// first look up all MD revisions newer than my current head\n\tstart := fbo.getLatestMergedRevision(lState) + 1\n\trmds, err := getMergedMDUpdates(ctx,\n\t\tfbo.config, fbo.id(), start, lockBeforeGet)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\terr = applyFunc(ctx, lState, rmds)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n\nfunc (fbo *folderBranchOps) getAndApplyNewestUnmergedHead(ctx context.Context,\n\tlState *lockState) error {\n\tfbo.log.CDebugf(ctx, \"Fetching the newest unmerged head\")\n\tbid := func() kbfsmd.BranchID {\n\t\tfbo.mdWriterLock.Lock(lState)\n\t\tdefer fbo.mdWriterLock.Unlock(lState)\n\t\treturn fbo.bid\n\t}()\n\n\t// We can only ever be at most one revision behind, so fetch the\n\t// latest unmerged revision and apply it as a successor.\n\tmd, err := fbo.config.MDOps().GetUnmergedForTLF(ctx, fbo.id(), bid)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif md == (ImmutableRootMetadata{}) {\n\t\t// There is no unmerged revision, oops!\n\t\treturn errors.New(\"Couldn't find an unmerged head\")\n\t}\n\n\tfbo.mdWriterLock.Lock(lState)\n\tdefer fbo.mdWriterLock.Unlock(lState)\n\tif fbo.bid != bid {\n\t\t// The branches switched (apparently CR completed), so just\n\t\t// try again.\n\t\tfbo.log.CDebugf(ctx, \"Branches switched while fetching unmerged head\")\n\t\treturn nil\n\t}\n\n\tfbo.headLock.Lock(lState)\n\tdefer fbo.headLock.Unlock(lState)\n\tif err := fbo.setHeadSuccessorLocked(ctx, lState, md, false); err != nil {\n\t\treturn err\n\t}\n\tif err := fbo.notifyBatchLocked(ctx, lState, md); err != nil {\n\t\treturn err\n\t}\n\treturn fbo.config.MDCache().Put(md)\n}\n\n// getUnmergedMDUpdates returns a slice of the unmerged MDs for this\n// TLF's current unmerged branch and unmerged branch, between the\n// merge point for the branch and the current head.  The returned MDs\n// are the same instances that are stored in the MD cache, so they\n// should be modified with care.\nfunc (fbo *folderBranchOps) getUnmergedMDUpdates(\n\tctx context.Context, lState *lockState) (\n\tkbfsmd.Revision, []ImmutableRootMetadata, error) {\n\t// acquire mdWriterLock to read the current branch ID.\n\tbid := func() kbfsmd.BranchID {\n\t\tfbo.mdWriterLock.Lock(lState)\n\t\tdefer fbo.mdWriterLock.Unlock(lState)\n\t\treturn fbo.bid\n\t}()\n\treturn getUnmergedMDUpdates(ctx, fbo.config, fbo.id(),\n\t\tbid, fbo.getCurrMDRevision(lState))\n}\n\nfunc (fbo *folderBranchOps) getUnmergedMDUpdatesLocked(\n\tctx context.Context, lState *lockState) (\n\tkbfsmd.Revision, []ImmutableRootMetadata, error) {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\n\treturn getUnmergedMDUpdates(ctx, fbo.config, fbo.id(),\n\t\tfbo.bid, fbo.getCurrMDRevision(lState))\n}\n\n// Returns a list of block pointers that were created during the\n// staged era.\nfunc (fbo *folderBranchOps) undoUnmergedMDUpdatesLocked(\n\tctx context.Context, lState *lockState) ([]BlockPointer, error) {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\n\tcurrHead, unmergedRmds, err := fbo.getUnmergedMDUpdatesLocked(ctx, lState)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\terr = fbo.undoMDUpdatesLocked(ctx, lState, unmergedRmds)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// We have arrived at the branch point.  The new root is\n\t// the previous revision from the current head.  Find it\n\t// and apply.  TODO: somehow fake the current head into\n\t// being currHead-1, so that future calls to\n\t// applyMDUpdates will fetch this along with the rest of\n\t// the updates.\n\tfbo.setBranchIDLocked(lState, kbfsmd.NullBranchID)\n\n\trmd, err := getSingleMD(ctx, fbo.config, fbo.id(), kbfsmd.NullBranchID,\n\t\tcurrHead, kbfsmd.Merged, nil)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\terr = func() error {\n\t\tfbo.headLock.Lock(lState)\n\t\tdefer fbo.headLock.Unlock(lState)\n\t\terr = fbo.setHeadPredecessorLocked(ctx, lState, rmd)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tfbo.setLatestMergedRevisionLocked(ctx, lState, rmd.Revision(), true)\n\t\treturn nil\n\t}()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Return all new refs\n\tvar unmergedPtrs []BlockPointer\n\tfor _, rmd := range unmergedRmds {\n\t\tfor _, op := range rmd.data.Changes.Ops {\n\t\t\tfor _, ptr := range op.Refs() {\n\t\t\t\tif ptr != zeroPtr {\n\t\t\t\t\tunmergedPtrs = append(unmergedPtrs, ptr)\n\t\t\t\t}\n\t\t\t}\n\t\t\tfor _, update := range op.allUpdates() {\n\t\t\t\tif update.Ref != zeroPtr {\n\t\t\t\t\tunmergedPtrs = append(unmergedPtrs, update.Ref)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn unmergedPtrs, nil\n}\n\nfunc (fbo *folderBranchOps) unstageLocked(ctx context.Context,\n\tlState *lockState) error {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\n\t// fetch all of my unstaged updates, and undo them one at a time\n\tbid, wasMasterBranch := fbo.bid, fbo.isMasterBranchLocked(lState)\n\tunmergedPtrs, err := fbo.undoUnmergedMDUpdatesLocked(ctx, lState)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// let the server know we no longer have need\n\tif !wasMasterBranch {\n\t\terr = fbo.config.MDOps().PruneBranch(ctx, fbo.id(), bid)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// now go forward in time, if possible\n\terr = fbo.getAndApplyMDUpdates(ctx, lState, nil,\n\t\tfbo.applyMDUpdatesLocked)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tmd, err := fbo.getSuccessorMDForWriteLocked(ctx, lState)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Finally, create a resolutionOp with the newly-unref'd pointers.\n\tresOp := newResolutionOp()\n\tfor _, ptr := range unmergedPtrs {\n\t\tresOp.AddUnrefBlock(ptr)\n\t}\n\tmd.AddOp(resOp)\n\n\tbps, err := fbo.maybeUnembedAndPutBlocks(ctx, md)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn fbo.finalizeMDWriteLocked(ctx, lState, md, bps, NoExcl,\n\t\tfunc(md ImmutableRootMetadata) error {\n\t\t\treturn fbo.notifyBatchLocked(ctx, lState, md)\n\t\t})\n}\n\n// TODO: remove once we have automatic conflict resolution\nfunc (fbo *folderBranchOps) UnstageForTesting(\n\tctx context.Context, folderBranch FolderBranch) (err error) {\n\tfbo.log.CDebugf(ctx, \"UnstageForTesting\")\n\tdefer func() {\n\t\tfbo.deferLog.CDebugf(ctx, \"UnstageForTesting done: %+v\", err)\n\t}()\n\n\tif folderBranch != fbo.folderBranch {\n\t\treturn WrongOpsError{fbo.folderBranch, folderBranch}\n\t}\n\n\treturn runUnlessCanceled(ctx, func() error {\n\t\tlState := makeFBOLockState()\n\n\t\tif fbo.isMasterBranch(lState) {\n\t\t\t// no-op\n\t\t\treturn nil\n\t\t}\n\n\t\tif fbo.blocks.GetState(lState) != cleanState {\n\t\t\treturn NotPermittedWhileDirtyError{}\n\t\t}\n\n\t\t// launch unstaging in a new goroutine, because we don't want to\n\t\t// use the provided context because upper layers might ignore our\n\t\t// notifications if we do.  But we still want to wait for the\n\t\t// context to cancel.\n\t\tc := make(chan error, 1)\n\t\tfreshCtx, cancel := fbo.newCtxWithFBOID()\n\t\tdefer cancel()\n\t\tfbo.log.CDebugf(freshCtx, \"Launching new context for UnstageForTesting\")\n\t\tgo func() {\n\t\t\tlState := makeFBOLockState()\n\t\t\tc <- fbo.doMDWriteWithRetry(ctx, lState,\n\t\t\t\tfunc(lState *lockState) error {\n\t\t\t\t\treturn fbo.unstageLocked(freshCtx, lState)\n\t\t\t\t})\n\t\t}()\n\n\t\tselect {\n\t\tcase err := <-c:\n\t\t\treturn err\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\t}\n\t})\n}\n\n// mdWriterLock must be taken by the caller.\nfunc (fbo *folderBranchOps) rekeyLocked(ctx context.Context,\n\tlState *lockState, promptPaper bool) (res RekeyResult, err error) {\n\tfbo.log.CDebugf(ctx, \"rekeyLocked\")\n\tdefer func() {\n\t\tfbo.deferLog.CDebugf(ctx, \"rekeyLocked done: %+v %+v\", res, err)\n\t}()\n\n\tfbo.mdWriterLock.AssertLocked(lState)\n\n\tif !fbo.isMasterBranchLocked(lState) {\n\t\treturn RekeyResult{}, errors.New(\"can't rekey while staged\")\n\t}\n\n\t// untrusted head is ok here.\n\thead, _ := fbo.getHead(lState)\n\tif head != (ImmutableRootMetadata{}) {\n\t\t// If we already have a cached revision, make sure we're\n\t\t// up-to-date with the latest revision before inspecting the\n\t\t// metadata, since Rekey doesn't let us go into CR mode, and\n\t\t// we don't actually get folder update notifications when the\n\t\t// rekey bit is set, just a \"folder needs rekey\" update.\n\t\tif err := fbo.getAndApplyMDUpdates(\n\t\t\tctx, lState, nil, fbo.applyMDUpdatesLocked); err != nil {\n\t\t\tif applyErr, ok := err.(kbfsmd.MDRevisionMismatch); !ok ||\n\t\t\t\tapplyErr.Rev != applyErr.Curr {\n\t\t\t\treturn RekeyResult{}, err\n\t\t\t}\n\t\t}\n\t}\n\n\tmd, lastWriterVerifyingKey, rekeyWasSet, err :=\n\t\tfbo.getMDForRekeyWriteLocked(ctx, lState)\n\tif err != nil {\n\t\treturn RekeyResult{}, err\n\t}\n\n\tcurrKeyGen := md.LatestKeyGeneration()\n\trekeyDone, tlfCryptKey, err := fbo.config.KeyManager().\n\t\tRekey(ctx, md, promptPaper)\n\n\tstillNeedsRekey := false\n\tswitch err.(type) {\n\tcase nil:\n\t\t// TODO: implement a \"forced\" option that rekeys even when the\n\t\t// devices haven't changed?\n\t\tif !rekeyDone {\n\t\t\tfbo.log.CDebugf(ctx, \"No rekey necessary\")\n\t\t\treturn RekeyResult{\n\t\t\t\tDidRekey:      false,\n\t\t\t\tNeedsPaperKey: false,\n\t\t\t}, nil\n\t\t}\n\t\t// Clear the rekey bit if any.\n\t\tmd.clearRekeyBit()\n\t\tsession, err := fbo.config.KBPKI().GetCurrentSession(ctx)\n\t\tif err != nil {\n\t\t\treturn RekeyResult{}, err\n\t\t}\n\t\t// Readers can't clear the last revision, because:\n\t\t// 1) They don't have access to the writer metadata, so can't clear the\n\t\t//    block changes.\n\t\t// 2) Readers need the kbfsmd.MetadataFlagWriterMetadataCopied bit set for\n\t\t//\t  MDServer to authorize the write.\n\t\t// Without this check, MDServer returns an Unauthorized error.\n\t\tif md.GetTlfHandle().IsWriter(session.UID) {\n\t\t\tmd.clearLastRevision()\n\t\t}\n\n\tcase RekeyIncompleteError:\n\t\tif !rekeyDone && rekeyWasSet {\n\t\t\t// The rekey bit was already set, and there's nothing else\n\t\t\t// we can to do, so don't put any new revisions.\n\t\t\tfbo.log.CDebugf(ctx, \"No further rekey possible by this user.\")\n\t\t\treturn RekeyResult{\n\t\t\t\tDidRekey:      false,\n\t\t\t\tNeedsPaperKey: false,\n\t\t\t}, nil\n\t\t}\n\n\t\t// Rekey incomplete, fallthrough without early exit, to ensure\n\t\t// we write the metadata with any potential changes\n\t\tfbo.log.CDebugf(ctx,\n\t\t\t\"Rekeyed reader devices, but still need writer rekey\")\n\n\tcase NeedOtherRekeyError, NeedSelfRekeyError:\n\t\tstillNeedsRekey = true\n\n\tdefault:\n\t\t_, isInputCanceled := err.(libkb.InputCanceledError)\n\t\tif isInputCanceled || err == context.DeadlineExceeded {\n\t\t\tfbo.log.CDebugf(ctx, \"Paper key prompt timed out\")\n\t\t\t// Reschedule the prompt in the timeout case.\n\t\t\tstillNeedsRekey = true\n\t\t} else {\n\t\t\treturn RekeyResult{}, err\n\t\t}\n\t}\n\n\tif stillNeedsRekey {\n\t\tfbo.log.CDebugf(ctx, \"Device doesn't have access to rekey\")\n\t\t// If we didn't have read access, then we don't have any\n\t\t// unlocked paper keys.  Wait for some time, and then if we\n\t\t// still aren't rekeyed, try again but this time prompt the\n\t\t// user for any known paper keys.  We do this even if the\n\t\t// rekey bit is already set, since we may have restarted since\n\t\t// the previous rekey attempt, before prompting for the paper\n\t\t// key.  Only schedule this as a one-time event, since direct\n\t\t// folder accesses from the user will also cause a\n\t\t// rekeyWithPrompt.\n\n\t\tif rekeyWasSet {\n\t\t\t// Devices not yet keyed shouldn't set the rekey bit again\n\t\t\tfbo.log.CDebugf(ctx, \"Rekey bit already set\")\n\t\t\treturn RekeyResult{\n\t\t\t\tDidRekey:      rekeyDone,\n\t\t\t\tNeedsPaperKey: true,\n\t\t\t}, nil\n\t\t}\n\t\t// This device hasn't been keyed yet, fall through to set the rekey bit\n\t}\n\n\t// add an empty operation to satisfy assumptions elsewhere\n\tmd.AddOp(newRekeyOp())\n\n\t// we still let readers push a new md block that we validate against reader\n\t// permissions\n\terr = fbo.finalizeMDRekeyWriteLocked(\n\t\tctx, lState, md, lastWriterVerifyingKey)\n\tif err != nil {\n\t\treturn RekeyResult{\n\t\t\tDidRekey:      rekeyDone,\n\t\t\tNeedsPaperKey: stillNeedsRekey,\n\t\t}, err\n\t}\n\n\t// cache any new TLF crypt key\n\tif tlfCryptKey != nil {\n\t\tkeyGen := md.LatestKeyGeneration()\n\t\terr = fbo.config.KeyCache().PutTLFCryptKey(md.TlfID(), keyGen, *tlfCryptKey)\n\t\tif err != nil {\n\t\t\treturn RekeyResult{\n\t\t\t\tDidRekey:      rekeyDone,\n\t\t\t\tNeedsPaperKey: stillNeedsRekey,\n\t\t\t}, err\n\t\t}\n\t}\n\n\t// send rekey finish notification\n\thandle := md.GetTlfHandle()\n\tif currKeyGen >= kbfsmd.FirstValidKeyGen && rekeyDone {\n\t\tfbo.config.Reporter().Notify(ctx,\n\t\t\trekeyNotification(ctx, fbo.config, handle, true))\n\t}\n\n\treturn RekeyResult{\n\t\tDidRekey:      rekeyDone,\n\t\tNeedsPaperKey: stillNeedsRekey,\n\t}, nil\n}\n\nfunc (fbo *folderBranchOps) RequestRekey(_ context.Context, tlf tlf.ID) {\n\tfb := FolderBranch{tlf, MasterBranch}\n\tif fb != fbo.folderBranch {\n\t\t// TODO: log instead of panic?\n\t\tpanic(WrongOpsError{fbo.folderBranch, fb})\n\t}\n\tfbo.rekeyFSM.Event(NewRekeyRequestEvent())\n}\n\nfunc (fbo *folderBranchOps) SyncFromServer(ctx context.Context,\n\tfolderBranch FolderBranch, lockBeforeGet *keybase1.LockID) (err error) {\n\tfbo.log.CDebugf(ctx, \"SyncFromServer\")\n\tdefer func() {\n\t\tfbo.deferLog.CDebugf(ctx, \"SyncFromServer done: %+v\", err)\n\t}()\n\n\tif folderBranch != fbo.folderBranch {\n\t\treturn WrongOpsError{fbo.folderBranch, folderBranch}\n\t}\n\n\tlState := makeFBOLockState()\n\n\t// Make sure everything outstanding syncs to disk at least.\n\tif err := fbo.syncAllUnlocked(ctx, lState); err != nil {\n\t\treturn err\n\t}\n\n\t// A journal flush before CR, if needed.\n\tif err := WaitForTLFJournal(ctx, fbo.config, fbo.id(),\n\t\tfbo.log); err != nil {\n\t\treturn err\n\t}\n\n\tif err := fbo.mdFlushes.Wait(ctx); err != nil {\n\t\treturn err\n\t}\n\n\tif err := fbo.branchChanges.Wait(ctx); err != nil {\n\t\treturn err\n\t}\n\n\t// Loop until we're fully updated on the master branch.\n\tfor {\n\t\tif !fbo.isMasterBranch(lState) {\n\t\t\tif err := fbo.cr.Wait(ctx); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\t// If we are still staged after the wait, then we have a problem.\n\t\t\tif !fbo.isMasterBranch(lState) {\n\t\t\t\treturn errors.Errorf(\"Conflict resolution didn't take us out \" +\n\t\t\t\t\t\"of staging.\")\n\t\t\t}\n\t\t}\n\n\t\tdirtyFiles := fbo.blocks.GetDirtyFileBlockRefs(lState)\n\t\tif len(dirtyFiles) > 0 {\n\t\t\tfor _, ref := range dirtyFiles {\n\t\t\t\tfbo.log.CDebugf(ctx, \"DeCache entry left: %v\", ref)\n\t\t\t}\n\t\t\treturn errors.New(\"can't sync from server while dirty\")\n\t\t}\n\n\t\t// A journal flush after CR, if needed.\n\t\tif err := WaitForTLFJournal(ctx, fbo.config, fbo.id(),\n\t\t\tfbo.log); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif err := fbo.mdFlushes.Wait(ctx); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif err := fbo.branchChanges.Wait(ctx); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif err := fbo.getAndApplyMDUpdates(\n\t\t\tctx, lState, lockBeforeGet, fbo.applyMDUpdates); err != nil {\n\t\t\tif applyErr, ok := err.(kbfsmd.MDRevisionMismatch); ok {\n\t\t\t\tif applyErr.Rev == applyErr.Curr {\n\t\t\t\t\tfbo.log.CDebugf(ctx, \"Already up-to-date with server\")\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\t\t\t}\n\t\t\tif _, isUnmerged := err.(UnmergedError); isUnmerged {\n\t\t\t\tcontinue\n\t\t\t} else if err == errNoMergedRevWhileStaged {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\t\tbreak\n\t}\n\n\t// Wait for all the asynchronous block archiving and quota\n\t// reclamation to hit the block server.\n\tif err := fbo.fbm.waitForArchives(ctx); err != nil {\n\t\treturn err\n\t}\n\tif err := fbo.fbm.waitForDeletingBlocks(ctx); err != nil {\n\t\treturn err\n\t}\n\tif err := fbo.editActivity.Wait(ctx); err != nil {\n\t\treturn err\n\t}\n\tif err := fbo.fbm.waitForQuotaReclamations(ctx); err != nil {\n\t\treturn err\n\t}\n\n\t// A second journal flush if needed, to clear out any\n\t// archive/remove calls caused by the above operations.\n\treturn WaitForTLFJournal(ctx, fbo.config, fbo.id(), fbo.log)\n}\n\n// CtxFBOTagKey is the type used for unique context tags within folderBranchOps\ntype CtxFBOTagKey int\n\nconst (\n\t// CtxFBOIDKey is the type of the tag for unique operation IDs\n\t// within folderBranchOps.\n\tCtxFBOIDKey CtxFBOTagKey = iota\n)\n\n// CtxFBOOpID is the display name for the unique operation\n// folderBranchOps ID tag.\nconst CtxFBOOpID = \"FBOID\"\n\nfunc (fbo *folderBranchOps) ctxWithFBOID(ctx context.Context) context.Context {\n\treturn CtxWithRandomIDReplayable(ctx, CtxFBOIDKey, CtxFBOOpID, fbo.log)\n}\n\nfunc (fbo *folderBranchOps) newCtxWithFBOID() (context.Context, context.CancelFunc) {\n\t// No need to call NewContextReplayable since ctxWithFBOID calls\n\t// ctxWithRandomIDReplayable, which attaches replayably.\n\tctx := fbo.ctxWithFBOID(context.Background())\n\tctx, cancelFunc := context.WithCancel(ctx)\n\tctx, err := NewContextWithCancellationDelayer(ctx)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn ctx, cancelFunc\n}\n\n// Run the passed function with a context that's canceled on shutdown.\nfunc (fbo *folderBranchOps) runUnlessShutdown(fn func(ctx context.Context) error) error {\n\tctx, cancelFunc := fbo.newCtxWithFBOID()\n\tdefer cancelFunc()\n\terrChan := make(chan error, 1)\n\tgo func() {\n\t\terrChan <- fn(ctx)\n\t}()\n\n\tselect {\n\tcase err := <-errChan:\n\t\treturn err\n\tcase <-fbo.shutdownChan:\n\t\treturn ShutdownHappenedError{}\n\t}\n}\n\nfunc (fbo *folderBranchOps) doFastForwardLocked(ctx context.Context,\n\tlState *lockState, currHead ImmutableRootMetadata) error {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\tfbo.headLock.AssertLocked(lState)\n\n\tfbo.log.CDebugf(ctx, \"Fast-forwarding from rev %d to rev %d\",\n\t\tfbo.latestMergedRevision, currHead.Revision())\n\tchanges, affectedNodeIDs, err := fbo.blocks.FastForwardAllNodes(\n\t\tctx, lState, currHead.ReadOnly())\n\tif err != nil {\n\t\treturn err\n\t}\n\n\terr = fbo.setHeadSuccessorLocked(ctx, lState, currHead, true /*rebase*/)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Invalidate all the affected nodes.\n\tif len(changes) > 0 {\n\t\tfbo.observers.batchChanges(ctx, changes, affectedNodeIDs)\n\t}\n\n\treturn nil\n}\n\nfunc (fbo *folderBranchOps) maybeFastForward(ctx context.Context,\n\tlState *lockState, lastUpdate time.Time, currUpdate time.Time) (\n\tfastForwardDone bool, err error) {\n\t// Has it been long enough to try fast-forwarding?\n\tif currUpdate.Before(lastUpdate.Add(fastForwardTimeThresh)) ||\n\t\t!fbo.isMasterBranch(lState) {\n\t\treturn false, nil\n\t}\n\n\tfbo.log.CDebugf(ctx, \"Checking head for possible \"+\n\t\t\"fast-forwarding (last update time=%s)\", lastUpdate)\n\tcurrHead, err := fbo.config.MDOps().GetForTLF(ctx, fbo.id(), nil)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\tfbo.log.CDebugf(ctx, \"Current head is revision %d\", currHead.Revision())\n\n\tfbo.mdWriterLock.Lock(lState)\n\tdefer fbo.mdWriterLock.Unlock(lState)\n\t// Don't update while the in-memory state is dirty.\n\tif fbo.blocks.GetState(lState) != cleanState {\n\t\treturn false, nil\n\t}\n\n\t// If the journal has anything in it, don't fast-forward since we\n\t// haven't finished flushing yet.  If there was really a remote\n\t// update on the server, we'll end up in CR eventually.\n\tmergedRev, err := fbo.getJournalPredecessorRevision(ctx)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\tif mergedRev != kbfsmd.RevisionUninitialized {\n\t\treturn false, nil\n\t}\n\n\tif !fbo.isMasterBranchLocked(lState) {\n\t\t// Don't update if we're staged.\n\t\treturn false, nil\n\t}\n\n\tfbo.headLock.Lock(lState)\n\tdefer fbo.headLock.Unlock(lState)\n\n\tif currHead.Revision() < fbo.latestMergedRevision+fastForwardRevThresh {\n\t\t// Might as well fetch all the revisions.\n\t\treturn false, nil\n\t}\n\n\terr = fbo.doFastForwardLocked(ctx, lState, currHead)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\treturn true, nil\n}\n\nfunc (fbo *folderBranchOps) locallyFinalizeTLF(ctx context.Context) {\n\tlState := makeFBOLockState()\n\tfbo.mdWriterLock.Lock(lState)\n\tdefer fbo.mdWriterLock.Unlock(lState)\n\tfbo.headLock.Lock(lState)\n\tdefer fbo.headLock.Unlock(lState)\n\n\tif fbo.head == (ImmutableRootMetadata{}) {\n\t\treturn\n\t}\n\n\t// It's safe to give this a finalized number of 1 and a fake user\n\t// name.  The whole point here is to move the old finalized TLF\n\t// name away to a new name, where the user won't be able to access\n\t// it anymore, and if there's a conflict with a previously-moved\n\t// TLF that shouldn't matter.\n\tnow := fbo.config.Clock().Now()\n\tfinalizedInfo, err := tlf.NewHandleExtension(\n\t\ttlf.HandleExtensionFinalized, 1, libkb.NormalizedUsername(\"<unknown>\"),\n\t\tnow)\n\tif err != nil {\n\t\tfbo.log.CErrorf(ctx, \"Couldn't make finalized info: %+v\", err)\n\t\treturn\n\t}\n\n\tfakeSignedHead := &RootMetadataSigned{RootMetadataSigned: kbfsmd.RootMetadataSigned{MD: fbo.head.bareMd}}\n\tfinalRmd, err := fakeSignedHead.MakeFinalCopy(\n\t\tfbo.config.Codec(), now, finalizedInfo)\n\tif err != nil {\n\t\tfbo.log.CErrorf(ctx, \"Couldn't finalize MD: %+v\", err)\n\t\treturn\n\t}\n\n\t// Construct the data needed to fake a new head.\n\tmdID, err := kbfsmd.MakeID(fbo.config.Codec(), finalRmd.MD)\n\tif err != nil {\n\t\tfbo.log.CErrorf(ctx, \"Couldn't get finalized MD ID: %+v\", err)\n\t\treturn\n\t}\n\tbareHandle, err := finalRmd.MD.MakeBareTlfHandle(fbo.head.Extra())\n\tif err != nil {\n\t\tfbo.log.CErrorf(ctx, \"Couldn't get finalized bare handle: %+v\", err)\n\t\treturn\n\t}\n\thandle, err := MakeTlfHandle(\n\t\tctx, bareHandle, fbo.id().Type(), fbo.config.KBPKI(),\n\t\tfbo.config.KBPKI(), fbo.config.MDOps())\n\tif err != nil {\n\t\tfbo.log.CErrorf(ctx, \"Couldn't get finalized handle: %+v\", err)\n\t\treturn\n\t}\n\tfinalBrmd, ok := finalRmd.MD.(kbfsmd.MutableRootMetadata)\n\tif !ok {\n\t\tfbo.log.CErrorf(ctx, \"Couldn't get finalized mutable bare MD: %+v\", err)\n\t\treturn\n\t}\n\n\t// We don't have a way to sign this with a valid key (and we might\n\t// be logged out anyway), so just directly make the md immutable.\n\tfinalIrmd := ImmutableRootMetadata{\n\t\tReadOnlyRootMetadata: makeRootMetadata(\n\t\t\tfinalBrmd, fbo.head.Extra(), handle).ReadOnly(),\n\t\tmdID: mdID,\n\t}\n\n\t// This will trigger the handle change notification to observers.\n\terr = fbo.setHeadSuccessorLocked(ctx, lState, finalIrmd, false)\n\tif err != nil {\n\t\tfbo.log.CErrorf(ctx, \"Couldn't set finalized MD: %+v\", err)\n\t\treturn\n\t}\n}\n\nfunc (fbo *folderBranchOps) registerAndWaitForUpdates() {\n\tdefer close(fbo.updateDoneChan)\n\tchildDone := make(chan struct{})\n\tvar lastUpdate time.Time\n\terr := fbo.runUnlessShutdown(func(ctx context.Context) error {\n\t\tdefer close(childDone)\n\t\t// If we fail to register for or process updates, try again\n\t\t// with an exponential backoff, so we don't overwhelm the\n\t\t// server or ourselves with too many attempts in a hopeless\n\t\t// situation.\n\t\texpBackoff := backoff.NewExponentialBackOff()\n\t\t// Never give up hope until we shut down\n\t\texpBackoff.MaxElapsedTime = 0\n\t\t// Register and wait in a loop unless we hit an unrecoverable error\n\t\tfbo.cancelUpdatesLock.Lock()\n\t\tif fbo.cancelUpdates != nil {\n\t\t\t// It should be impossible to get here without having\n\t\t\t// already called the cancel function, but just in case\n\t\t\t// call it here again.\n\t\t\tfbo.cancelUpdates()\n\t\t}\n\t\tctx, fbo.cancelUpdates = context.WithCancel(ctx)\n\t\tfbo.cancelUpdatesLock.Unlock()\n\t\tfor {\n\t\t\terr := backoff.RetryNotifyWithContext(ctx, func() error {\n\t\t\t\t// Replace the FBOID one with a fresh id for every attempt\n\t\t\t\tnewCtx := fbo.ctxWithFBOID(ctx)\n\t\t\t\tupdateChan, err := fbo.registerForUpdates(newCtx)\n\t\t\t\tif err != nil {\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\t// Shortcut the retry, we're done.\n\t\t\t\t\t\treturn nil\n\t\t\t\t\tdefault:\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tcurrUpdate, err := fbo.waitForAndProcessUpdates(\n\t\t\t\t\tnewCtx, lastUpdate, updateChan)\n\t\t\t\tswitch errors.Cause(err).(type) {\n\t\t\t\tcase UnmergedError:\n\t\t\t\t\t// skip the back-off timer and continue directly to next\n\t\t\t\t\t// registerForUpdates\n\t\t\t\t\treturn nil\n\t\t\t\tcase kbfsmd.NewMetadataVersionError:\n\t\t\t\t\tfbo.log.CDebugf(ctx, \"Abandoning updates since we can't \"+\n\t\t\t\t\t\t\"read the newest metadata: %+v\", err)\n\t\t\t\t\tfbo.status.setPermErr(err)\n\t\t\t\t\t// No need to lock here, since `cancelUpdates` is\n\t\t\t\t\t// only set within this same goroutine.\n\t\t\t\t\tfbo.cancelUpdates()\n\t\t\t\t\treturn context.Canceled\n\t\t\t\tcase kbfsmd.ServerErrorCannotReadFinalizedTLF:\n\t\t\t\t\tfbo.log.CDebugf(ctx, \"Abandoning updates since we can't \"+\n\t\t\t\t\t\t\"read the finalized metadata for this TLF: %+v\", err)\n\t\t\t\t\tfbo.status.setPermErr(err)\n\n\t\t\t\t\t// Locally finalize the TLF so new accesses\n\t\t\t\t\t// through to the old folder name will find the\n\t\t\t\t\t// new folder.\n\t\t\t\t\tfbo.locallyFinalizeTLF(newCtx)\n\n\t\t\t\t\t// No need to lock here, since `cancelUpdates` is\n\t\t\t\t\t// only set within this same goroutine.\n\t\t\t\t\tfbo.cancelUpdates()\n\t\t\t\t\treturn context.Canceled\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t// Shortcut the retry, we're done.\n\t\t\t\t\treturn nil\n\t\t\t\tdefault:\n\t\t\t\t\tif err == nil {\n\t\t\t\t\t\tlastUpdate = currUpdate\n\t\t\t\t\t}\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t},\n\t\t\t\texpBackoff,\n\t\t\t\tfunc(err error, nextTime time.Duration) {\n\t\t\t\t\tfbo.log.CDebugf(ctx,\n\t\t\t\t\t\t\"Retrying registerForUpdates in %s due to err: %v\",\n\t\t\t\t\t\tnextTime, err)\n\t\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t})\n\n\tif err != nil && err != context.Canceled {\n\t\tfbo.log.CWarningf(context.Background(),\n\t\t\t\"registerAndWaitForUpdates failed unexpectedly with an error: %v\",\n\t\t\terr)\n\t}\n\t<-childDone\n}\n\nfunc (fbo *folderBranchOps) registerForUpdatesShouldFireNow() bool {\n\tfbo.muLastGetHead.Lock()\n\tdefer fbo.muLastGetHead.Unlock()\n\treturn fbo.config.Clock().Now().Sub(fbo.lastGetHead) < registerForUpdatesFireNowThreshold\n}\n\nfunc (fbo *folderBranchOps) registerForUpdates(ctx context.Context) (\n\tupdateChan <-chan error, err error) {\n\tlState := makeFBOLockState()\n\tcurrRev := fbo.getLatestMergedRevision(lState)\n\n\tfireNow := false\n\tif fbo.registerForUpdatesShouldFireNow() {\n\t\tctx = rpc.WithFireNow(ctx)\n\t\tfireNow = true\n\t}\n\n\tfbo.log.CDebugf(ctx,\n\t\t\"Registering for updates (curr rev = %d, fire now = %v)\",\n\t\tcurrRev, fireNow)\n\tdefer func() {\n\t\tfbo.deferLog.CDebugf(ctx,\n\t\t\t\"Registering for updates (curr rev = %d, fire now = %v) done: %+v\",\n\t\t\tcurrRev, fireNow, err)\n\t}()\n\t// RegisterForUpdate will itself retry on connectivity issues\n\treturn fbo.config.MDServer().RegisterForUpdate(ctx, fbo.id(), currRev)\n}\n\nfunc (fbo *folderBranchOps) waitForAndProcessUpdates(\n\tctx context.Context, lastUpdate time.Time,\n\tupdateChan <-chan error) (currUpdate time.Time, err error) {\n\t// successful registration; now, wait for an update or a shutdown\n\tfbo.log.CDebugf(ctx, \"Waiting for updates\")\n\tdefer func() {\n\t\tfbo.deferLog.CDebugf(ctx, \"Waiting for updates done: %+v\", err)\n\t}()\n\n\tlState := makeFBOLockState()\n\n\tfor {\n\t\tselect {\n\t\tcase err := <-updateChan:\n\t\t\tfbo.log.CDebugf(ctx, \"Got an update: %v\", err)\n\t\t\tif err != nil {\n\t\t\t\treturn time.Time{}, err\n\t\t\t}\n\t\t\t// Getting and applying the updates requires holding\n\t\t\t// locks, so make sure it doesn't take too long.\n\t\t\tctx, cancel := context.WithTimeout(ctx, backgroundTaskTimeout)\n\t\t\tdefer cancel()\n\n\t\t\tcurrUpdate := fbo.config.Clock().Now()\n\t\t\tffDone, err :=\n\t\t\t\tfbo.maybeFastForward(ctx, lState, lastUpdate, currUpdate)\n\t\t\tif err != nil {\n\t\t\t\treturn time.Time{}, err\n\t\t\t}\n\t\t\tif ffDone {\n\t\t\t\treturn currUpdate, nil\n\t\t\t}\n\n\t\t\terr = fbo.getAndApplyMDUpdates(ctx, lState, nil, fbo.applyMDUpdates)\n\t\t\tif err != nil {\n\t\t\t\tfbo.log.CDebugf(ctx, \"Got an error while applying \"+\n\t\t\t\t\t\"updates: %v\", err)\n\t\t\t\treturn time.Time{}, err\n\t\t\t}\n\t\t\treturn currUpdate, nil\n\t\tcase unpause := <-fbo.updatePauseChan:\n\t\t\tfbo.log.CInfof(ctx, \"Updates paused\")\n\t\t\t// wait to be unpaused\n\t\t\tselect {\n\t\t\tcase <-unpause:\n\t\t\t\tfbo.log.CInfof(ctx, \"Updates unpaused\")\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn time.Time{}, ctx.Err()\n\t\t\t}\n\t\tcase <-ctx.Done():\n\t\t\treturn time.Time{}, ctx.Err()\n\t\t}\n\t}\n}\n\nfunc (fbo *folderBranchOps) getCachedDirOpsCount(lState *lockState) int {\n\tfbo.mdWriterLock.Lock(lState)\n\tdefer fbo.mdWriterLock.Unlock(lState)\n\treturn len(fbo.dirOps)\n}\n\nfunc (fbo *folderBranchOps) backgroundFlusher() {\n\tlState := makeFBOLockState()\n\tvar prevDirtyFileMap map[BlockRef]bool\n\tsameDirtyFileCount := 0\n\tfor {\n\t\tdoSelect := true\n\t\tif fbo.blocks.GetState(lState) == dirtyState &&\n\t\t\tfbo.config.DirtyBlockCache().ShouldForceSync(fbo.id()) &&\n\t\t\tsameDirtyFileCount < 10 {\n\t\t\t// We have dirty files, and the system has a full buffer,\n\t\t\t// so don't bother waiting for a signal, just get right to\n\t\t\t// the main attraction.\n\t\t\tdoSelect = false\n\t\t} else if fbo.getCachedDirOpsCount(lState) >=\n\t\t\tfbo.config.BGFlushDirOpBatchSize() {\n\t\t\tdoSelect = false\n\t\t}\n\n\t\tif doSelect {\n\t\t\t// Wait until we really have a write waiting.\n\t\t\tdoWait := true\n\t\t\tselect {\n\t\t\tcase <-fbo.syncNeededChan:\n\t\t\t\tif fbo.getCachedDirOpsCount(lState) >=\n\t\t\t\t\tfbo.config.BGFlushDirOpBatchSize() {\n\t\t\t\t\tdoWait = false\n\t\t\t\t}\n\t\t\tcase <-fbo.forceSyncChan:\n\t\t\t\tdoWait = false\n\t\t\tcase <-fbo.shutdownChan:\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tif doWait {\n\t\t\t\ttimer := time.NewTimer(fbo.config.BGFlushPeriod())\n\t\t\t\t// Loop until either a tick's worth of time passes,\n\t\t\t\t// the batch size of directory ops is full, a sync is\n\t\t\t\t// forced, or a shutdown happens.\n\t\t\tloop:\n\t\t\t\tfor {\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-timer.C:\n\t\t\t\t\t\tbreak loop\n\t\t\t\t\tcase <-fbo.syncNeededChan:\n\t\t\t\t\t\tif fbo.getCachedDirOpsCount(lState) >=\n\t\t\t\t\t\t\tfbo.config.BGFlushDirOpBatchSize() {\n\t\t\t\t\t\t\tbreak loop\n\t\t\t\t\t\t}\n\t\t\t\t\tcase <-fbo.forceSyncChan:\n\t\t\t\t\t\tbreak loop\n\t\t\t\t\tcase <-fbo.shutdownChan:\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tdirtyFiles := fbo.blocks.GetDirtyFileBlockRefs(lState)\n\t\tdirOpsCount := fbo.getCachedDirOpsCount(lState)\n\t\tif len(dirtyFiles) == 0 && dirOpsCount == 0 {\n\t\t\tsameDirtyFileCount = 0\n\t\t\tcontinue\n\t\t}\n\n\t\t// Make sure we are making some progress\n\t\tcurrDirtyFileMap := make(map[BlockRef]bool)\n\t\tfor _, ref := range dirtyFiles {\n\t\t\tcurrDirtyFileMap[ref] = true\n\t\t}\n\t\tif reflect.DeepEqual(currDirtyFileMap, prevDirtyFileMap) {\n\t\t\tsameDirtyFileCount++\n\t\t} else {\n\t\t\tsameDirtyFileCount = 0\n\t\t}\n\t\tprevDirtyFileMap = currDirtyFileMap\n\n\t\tfbo.runUnlessShutdown(func(ctx context.Context) (err error) {\n\t\t\t// Denote that these are coming from a background\n\t\t\t// goroutine, not directly from any user.\n\t\t\tctx = NewContextReplayable(ctx,\n\t\t\t\tfunc(ctx context.Context) context.Context {\n\t\t\t\t\treturn context.WithValue(ctx, CtxBackgroundSyncKey, \"1\")\n\t\t\t\t})\n\n\t\t\tfbo.log.CDebugf(ctx, \"Background sync triggered: %d dirty files, \"+\n\t\t\t\t\"%d dir ops in batch\", len(dirtyFiles), dirOpsCount)\n\n\t\t\tif sameDirtyFileCount >= 100 {\n\t\t\t\t// If the local journal is full, we might not be able to\n\t\t\t\t// make progress until more data is flushed to the\n\t\t\t\t// servers, so just warn here rather than just an outright\n\t\t\t\t// panic.\n\t\t\t\tfbo.log.CWarningf(ctx, \"Making no Sync progress on dirty \"+\n\t\t\t\t\t\"files after %d attempts: %v\", sameDirtyFileCount,\n\t\t\t\t\tdirtyFiles)\n\t\t\t}\n\n\t\t\t// Just in case network access or a bug gets stuck for a\n\t\t\t// long time, time out the sync eventually.\n\t\t\tlongCtx, longCancel :=\n\t\t\t\tcontext.WithTimeout(ctx, backgroundTaskTimeout)\n\t\t\tdefer longCancel()\n\t\t\terr = fbo.SyncAll(longCtx, fbo.folderBranch)\n\t\t\tif err != nil {\n\t\t\t\t// Just log the warning and keep trying to\n\t\t\t\t// sync the rest of the dirty files.\n\t\t\t\tfbo.log.CWarningf(ctx, \"Couldn't sync all: %+v\", err)\n\t\t\t}\n\t\t\treturn nil\n\t\t})\n\t}\n}\n\nfunc (fbo *folderBranchOps) blockUnmergedWrites(lState *lockState) {\n\tfbo.mdWriterLock.Lock(lState)\n}\n\nfunc (fbo *folderBranchOps) unblockUnmergedWrites(lState *lockState) {\n\tfbo.mdWriterLock.Unlock(lState)\n}\n\nfunc (fbo *folderBranchOps) finalizeResolutionLocked(ctx context.Context,\n\tlState *lockState, md *RootMetadata, bps *blockPutState,\n\tnewOps []op, blocksToDelete []kbfsblock.ID) error {\n\tfbo.mdWriterLock.AssertLocked(lState)\n\n\t// Put the blocks into the cache so that, even if we fail below,\n\t// future attempts may reuse the blocks.\n\terr := fbo.finalizeBlocks(ctx, bps)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Last chance to get pre-empted.\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tdefault:\n\t}\n\n\tsession, err := fbo.config.KBPKI().GetCurrentSession(ctx)\n\tif err != nil {\n\t\treturn err\n\t}\n\tirmd, err := fbo.config.MDOps().ResolveBranch(ctx, fbo.id(), fbo.bid,\n\t\tblocksToDelete, md, session.VerifyingKey)\n\tdoUnmergedPut := isRevisionConflict(err)\n\tif doUnmergedPut {\n\t\tfbo.log.CDebugf(ctx, \"Got a conflict after resolution; aborting CR\")\n\t\treturn err\n\t}\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Queue a rekey if the bit was set.\n\tif md.IsRekeySet() {\n\t\tdefer fbo.config.RekeyQueue().Enqueue(md.TlfID())\n\t}\n\n\tmd.loadCachedBlockChanges(ctx, bps, fbo.log)\n\n\t// Set the head to the new MD.\n\tfbo.headLock.Lock(lState)\n\tdefer fbo.headLock.Unlock(lState)\n\terr = fbo.setHeadConflictResolvedLocked(ctx, lState, irmd)\n\tif err != nil {\n\t\tfbo.log.CWarningf(ctx, \"Couldn't set local MD head after a \"+\n\t\t\t\"successful put: %v\", err)\n\t\treturn err\n\t}\n\tfbo.setBranchIDLocked(lState, kbfsmd.NullBranchID)\n\n\t// Send edit notifications and archive the old, unref'd blocks if\n\t// journaling is off.\n\tif !TLFJournalEnabled(fbo.config, fbo.id()) {\n\t\tfbo.editActivity.Add(1)\n\t\tgo func() {\n\t\t\tdefer fbo.editActivity.Done()\n\t\t\tctx, cancelFunc := fbo.newCtxWithFBOID()\n\t\t\tdefer cancelFunc()\n\t\t\terr := fbo.handleEditNotifications(ctx, irmd)\n\t\t\tif err != nil {\n\t\t\t\tfbo.log.CWarningf(ctx, \"Couldn't send edit notifications for \"+\n\t\t\t\t\t\"revision %d: %+v\", irmd.Revision(), err)\n\t\t\t}\n\t\t}()\n\t\tfbo.fbm.archiveUnrefBlocks(irmd.ReadOnly())\n\t}\n\n\tmdCopyWithLocalOps, err := md.deepCopy(fbo.config.Codec())\n\tif err != nil {\n\t\treturn err\n\t}\n\tmdCopyWithLocalOps.data.Changes.Ops = newOps\n\n\t// notifyOneOp for every fixed-up merged op.\n\tfor _, op := range newOps {\n\t\terr := fbo.notifyOneOpLocked(\n\t\t\tctx, lState, op, mdCopyWithLocalOps.ReadOnly(), false)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\n// finalizeResolution caches all the blocks, and writes the new MD to\n// the merged branch, failing if there is a conflict.  It also sends\n// out the given newOps notifications locally.  This is used for\n// completing conflict resolution.\nfunc (fbo *folderBranchOps) finalizeResolution(ctx context.Context,\n\tlState *lockState, md *RootMetadata, bps *blockPutState,\n\tnewOps []op, blocksToDelete []kbfsblock.ID) error {\n\t// Take the writer lock.\n\tfbo.mdWriterLock.Lock(lState)\n\tdefer fbo.mdWriterLock.Unlock(lState)\n\treturn fbo.finalizeResolutionLocked(\n\t\tctx, lState, md, bps, newOps, blocksToDelete)\n}\n\nfunc (fbo *folderBranchOps) unstageAfterFailedResolution(ctx context.Context,\n\tlState *lockState) error {\n\t// Take the writer lock.\n\tfbo.mdWriterLock.Lock(lState)\n\tdefer fbo.mdWriterLock.Unlock(lState)\n\n\t// Last chance to get pre-empted.\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn ctx.Err()\n\tdefault:\n\t}\n\n\t// We don't want context cancellation after this point, so use a linked\n\t// context. There is no race since the linked context has an independent\n\t// Done channel.\n\t//\n\t// Generally we don't want to have any errors in unstageLocked since and\n\t// this solution is chosen because:\n\t// * If the error is caused by a cancelled context then the recovery (archiving)\n\t//   would need to use a separate context anyways.\n\t// * In such cases we would have to be very careful where the error occurs\n\t//   and what to archive, making that solution much more complicated.\n\t// * The other \"common\" error case is losing server connection and after\n\t//   detecting that we won't have much luck archiving things anyways.\n\n\tctx = newLinkedContext(ctx)\n\tfbo.log.CWarningf(ctx, \"Unstaging branch %s after a resolution failure\",\n\t\tfbo.bid)\n\treturn fbo.unstageLocked(ctx, lState)\n}\n\nfunc (fbo *folderBranchOps) handleTLFBranchChange(ctx context.Context,\n\tnewBID kbfsmd.BranchID) {\n\tlState := makeFBOLockState()\n\tfbo.mdWriterLock.Lock(lState)\n\tdefer fbo.mdWriterLock.Unlock(lState)\n\n\tfbo.log.CDebugf(ctx, \"Journal branch change: %s\", newBID)\n\n\tif !fbo.isMasterBranchLocked(lState) {\n\t\tif fbo.bid == newBID {\n\t\t\tfbo.log.CDebugf(ctx, \"Already on branch %s\", newBID)\n\t\t\treturn\n\t\t}\n\t\tpanic(fmt.Sprintf(\"Cannot switch to branch %s while on branch %s\",\n\t\t\tnewBID, fbo.bid))\n\t}\n\n\tmd, err := fbo.config.MDOps().GetUnmergedForTLF(ctx, fbo.id(), newBID)\n\tif err != nil {\n\t\tfbo.log.CWarningf(ctx,\n\t\t\t\"No unmerged head on journal branch change (bid=%s)\", newBID)\n\t\treturn\n\t}\n\n\tif md == (ImmutableRootMetadata{}) || md.MergedStatus() != kbfsmd.Unmerged ||\n\t\tmd.BID() != newBID {\n\t\t// This can happen if CR got kicked off in some other way and\n\t\t// completed before we took the lock to process this\n\t\t// notification.\n\t\tfbo.log.CDebugf(ctx, \"Ignoring stale branch change: md=%v, newBID=%d\",\n\t\t\tmd, newBID)\n\t\treturn\n\t}\n\n\t// Everything we thought we knew about quota reclamation is now\n\t// called into question.\n\tfbo.fbm.clearLastQRData()\n\n\t// Kick off conflict resolution and set the head to the correct branch.\n\tfbo.setBranchIDLocked(lState, newBID)\n\tfbo.cr.Resolve(ctx, md.Revision(), kbfsmd.RevisionUninitialized)\n\n\tfbo.headLock.Lock(lState)\n\tdefer fbo.headLock.Unlock(lState)\n\terr = fbo.setHeadSuccessorLocked(ctx, lState, md, true /*rebased*/)\n\tif err != nil {\n\t\tfbo.log.CWarningf(ctx,\n\t\t\t\"Could not set head on journal branch change: %v\", err)\n\t\treturn\n\t}\n}\n\nfunc (fbo *folderBranchOps) onTLFBranchChange(newBID kbfsmd.BranchID) {\n\tfbo.branchChanges.Add(1)\n\n\tgo func() {\n\t\tdefer fbo.branchChanges.Done()\n\t\tctx, cancelFunc := fbo.newCtxWithFBOID()\n\t\tdefer cancelFunc()\n\n\t\t// This only happens on a `PruneBranch` call, in which case we\n\t\t// would have already updated fbo's local view of the branch/head.\n\t\tif newBID == kbfsmd.NullBranchID {\n\t\t\tfbo.log.CDebugf(ctx, \"Ignoring branch change back to master\")\n\t\t\treturn\n\t\t}\n\n\t\tfbo.handleTLFBranchChange(ctx, newBID)\n\t}()\n}\n\nfunc (fbo *folderBranchOps) handleMDFlush(ctx context.Context, bid kbfsmd.BranchID,\n\trev kbfsmd.Revision) {\n\tfbo.log.CDebugf(ctx, \"Considering archiving references for flushed MD revision %d\", rev)\n\n\tlState := makeFBOLockState()\n\tfunc() {\n\t\tfbo.headLock.Lock(lState)\n\t\tdefer fbo.headLock.Unlock(lState)\n\t\tfbo.setLatestMergedRevisionLocked(ctx, lState, rev, false)\n\t}()\n\n\t// Get that revision.\n\trmd, err := getSingleMD(ctx, fbo.config, fbo.id(), kbfsmd.NullBranchID,\n\t\trev, kbfsmd.Merged, nil)\n\tif err != nil {\n\t\tfbo.log.CWarningf(ctx, \"Couldn't get revision %d for archiving: %v\",\n\t\t\trev, err)\n\t\treturn\n\t}\n\n\terr = fbo.handleEditNotifications(ctx, rmd)\n\tif err != nil {\n\t\tfbo.log.CWarningf(ctx, \"Couldn't send edit notifications for \"+\n\t\t\t\"revision %d: %+v\", rev, err)\n\t}\n\n\tif err := isArchivableMDOrError(rmd.ReadOnly()); err != nil {\n\t\tfbo.log.CDebugf(\n\t\t\tctx, \"Skipping archiving references for flushed MD revision %d: %s\", rev, err)\n\t\treturn\n\t}\n\n\tfbo.fbm.archiveUnrefBlocks(rmd.ReadOnly())\n}\n\nfunc (fbo *folderBranchOps) onMDFlush(bid kbfsmd.BranchID, rev kbfsmd.Revision) {\n\tfbo.mdFlushes.Add(1)\n\n\tgo func() {\n\t\tdefer fbo.mdFlushes.Done()\n\t\tctx, cancelFunc := fbo.newCtxWithFBOID()\n\t\tdefer cancelFunc()\n\n\t\tif bid != kbfsmd.NullBranchID {\n\t\t\tfbo.log.CDebugf(ctx, \"Ignoring MD flush on branch %v for \"+\n\t\t\t\t\"revision %d\", bid, rev)\n\t\t\treturn\n\t\t}\n\n\t\tfbo.handleMDFlush(ctx, bid, rev)\n\t}()\n}\n\n// TeamNameChanged implements the KBFSOps interface for folderBranchOps\nfunc (fbo *folderBranchOps) TeamNameChanged(\n\tctx context.Context, tid keybase1.TeamID) {\n\tctx, cancelFunc := fbo.newCtxWithFBOID()\n\tdefer cancelFunc()\n\tfbo.log.CDebugf(ctx, \"Starting name change for team %s\", tid)\n\n\t// First check if this is an implicit team.\n\tvar newName libkb.NormalizedUsername\n\tif fbo.id().Type() != tlf.SingleTeam {\n\t\titeamInfo, err := fbo.config.KBPKI().ResolveImplicitTeamByID(\n\t\t\tctx, tid, fbo.id().Type())\n\t\tif err == nil {\n\t\t\tnewName = iteamInfo.Name\n\t\t}\n\t}\n\n\tif newName == \"\" {\n\t\tvar err error\n\t\tnewName, err = fbo.config.KBPKI().GetNormalizedUsername(\n\t\t\tctx, tid.AsUserOrTeam())\n\t\tif err != nil {\n\t\t\tfbo.log.CWarningf(ctx, \"Error getting new team name: %+v\", err)\n\t\t\treturn\n\t\t}\n\t}\n\n\tlState := makeFBOLockState()\n\tfbo.mdWriterLock.Lock(lState)\n\tdefer fbo.mdWriterLock.Unlock(lState)\n\tfbo.headLock.Lock(lState)\n\tdefer fbo.headLock.Unlock(lState)\n\n\tif fbo.head == (ImmutableRootMetadata{}) {\n\t\tfbo.log.CWarningf(ctx, \"No head to update\")\n\t\treturn\n\t}\n\n\toldHandle := fbo.head.GetTlfHandle()\n\n\tif string(oldHandle.GetCanonicalName()) == string(newName) {\n\t\tfbo.log.CDebugf(ctx, \"Name didn't change: %s\", newName)\n\t\treturn\n\t}\n\n\tif oldHandle.FirstResolvedWriter() != tid.AsUserOrTeam() {\n\t\tfbo.log.CWarningf(ctx,\n\t\t\t\"Old handle doesn't include changed team ID: %s\",\n\t\t\toldHandle.FirstResolvedWriter())\n\t\treturn\n\t}\n\n\t// Make a copy of `head` with the new handle.\n\tnewHandle := oldHandle.deepCopy()\n\tnewHandle.name = tlf.CanonicalName(newName)\n\tnewHandle.resolvedWriters[tid.AsUserOrTeam()] = newName\n\tnewHead, err := fbo.head.deepCopy(fbo.config.Codec())\n\tif err != nil {\n\t\tfbo.log.CWarningf(ctx, \"Error copying head: %+v\", err)\n\t\treturn\n\t}\n\tnewHead.tlfHandle = newHandle\n\n\tfbo.log.CDebugf(ctx, \"Team name changed from %s to %s\",\n\t\toldHandle.GetCanonicalName(), newHandle.GetCanonicalName())\n\tfbo.head = MakeImmutableRootMetadata(\n\t\tnewHead, fbo.head.lastWriterVerifyingKey, fbo.head.mdID,\n\t\tfbo.head.localTimestamp, fbo.head.putToServer)\n\tif err != nil {\n\t\tfbo.log.CWarningf(ctx, \"Error setting head: %+v\", err)\n\t\treturn\n\t}\n\n\tfbo.config.MDCache().ChangeHandleForID(oldHandle, newHandle)\n\tfbo.observers.tlfHandleChange(ctx, newHandle)\n}\n\n// TeamAbandoned implements the KBFSOps interface for folderBranchOps.\nfunc (fbo *folderBranchOps) TeamAbandoned(\n\tctx context.Context, tid keybase1.TeamID) {\n\tctx, cancelFunc := fbo.newCtxWithFBOID()\n\tdefer cancelFunc()\n\tfbo.log.CDebugf(ctx, \"Abandoning team %s\", tid)\n\tfbo.locallyFinalizeTLF(ctx)\n}\n\n// MigrateToImplicitTeam implements the KBFSOps interface for folderBranchOps.\nfunc (fbo *folderBranchOps) MigrateToImplicitTeam(\n\tctx context.Context, id tlf.ID) (err error) {\n\tfb := FolderBranch{id, MasterBranch}\n\tif fb != fbo.folderBranch {\n\t\t// TODO: log instead of panic?\n\t\tpanic(WrongOpsError{fbo.folderBranch, fb})\n\t}\n\n\tfbo.log.CDebugf(ctx, \"Starting migration of TLF %s\", id)\n\tdefer func() {\n\t\tfbo.log.CDebugf(ctx, \"Finished migration of TLF %s, err=%+v\", id, err)\n\t}()\n\n\tif id.Type() != tlf.Private && id.Type() != tlf.Public {\n\t\treturn errors.Errorf(\"Cannot migrate a TLF of type: %s\", id.Type())\n\t}\n\n\tlState := makeFBOLockState()\n\tfbo.mdWriterLock.Lock(lState)\n\tdefer fbo.mdWriterLock.Unlock(lState)\n\n\tmd, err := fbo.getMDForWriteLockedForFilename(ctx, lState, \"\")\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif md == (ImmutableRootMetadata{}) {\n\t\tfbo.log.CDebugf(ctx, \"Nothing to upgrade\")\n\t\treturn nil\n\t}\n\n\tif md.IsFinal() {\n\t\tfbo.log.CDebugf(ctx, \"No need to upgrade a finalized TLF\")\n\t\treturn nil\n\t}\n\n\tif md.TypeForKeying() == tlf.TeamKeying {\n\t\tfbo.log.CDebugf(ctx, \"Already migrated\")\n\t\treturn nil\n\t}\n\n\tname := string(md.GetTlfHandle().GetCanonicalName())\n\tfbo.log.CDebugf(ctx, \"Looking up implicit team for %s\", name)\n\tnewHandle, err := ParseTlfHandle(\n\t\tctx, fbo.config.KBPKI(), fbo.config.MDOps(), name, id.Type())\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Make sure the new handle contains just a team.\n\tif newHandle.TypeForKeying() != tlf.TeamKeying {\n\t\treturn errors.New(\"No corresponding implicit team yet\")\n\t}\n\n\tsession, err := fbo.config.KBPKI().GetCurrentSession(ctx)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tisWriter := true // getMDForWriteLockedForFilename already checked this.\n\tnewMD, err := md.MakeSuccessorWithNewHandle(\n\t\tctx, newHandle, fbo.config.MetadataVersion(), fbo.config.Codec(),\n\t\tfbo.config.KeyManager(), fbo.config.KBPKI(), fbo.config.KBPKI(),\n\t\tmd.mdID, isWriter)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif newMD.TypeForKeying() != tlf.TeamKeying {\n\t\treturn errors.New(\"Migration failed\")\n\t}\n\n\t// Add an empty operation to satisfy assumptions elsewhere.\n\tnewMD.AddOp(newRekeyOp())\n\n\treturn fbo.finalizeMDRekeyWriteLocked(\n\t\tctx, lState, newMD, session.VerifyingKey)\n}\n\n// GetUpdateHistory implements the KBFSOps interface for folderBranchOps\nfunc (fbo *folderBranchOps) GetUpdateHistory(ctx context.Context,\n\tfolderBranch FolderBranch) (history TLFUpdateHistory, err error) {\n\tfbo.log.CDebugf(ctx, \"GetUpdateHistory\")\n\tdefer func() {\n\t\tfbo.deferLog.CDebugf(ctx, \"GetUpdateHistory done: %+v\", err)\n\t}()\n\n\tif folderBranch != fbo.folderBranch {\n\t\treturn TLFUpdateHistory{}, WrongOpsError{fbo.folderBranch, folderBranch}\n\t}\n\n\trmds, err := getMergedMDUpdates(ctx, fbo.config, fbo.id(),\n\t\tkbfsmd.RevisionInitial, nil)\n\tif err != nil {\n\t\treturn TLFUpdateHistory{}, err\n\t}\n\n\tif len(rmds) > 0 {\n\t\trmd := rmds[len(rmds)-1]\n\t\thistory.ID = rmd.TlfID().String()\n\t\thistory.Name = rmd.GetTlfHandle().GetCanonicalPath()\n\t}\n\thistory.Updates = make([]UpdateSummary, 0, len(rmds))\n\twriterNames := make(map[keybase1.UID]string)\n\tfor _, rmd := range rmds {\n\t\twriter, ok := writerNames[rmd.LastModifyingWriter()]\n\t\tif !ok {\n\t\t\tname, err := fbo.config.KBPKI().GetNormalizedUsername(\n\t\t\t\tctx, rmd.LastModifyingWriter().AsUserOrTeam())\n\t\t\tif err != nil {\n\t\t\t\treturn TLFUpdateHistory{}, err\n\t\t\t}\n\t\t\twriter = string(name)\n\t\t\twriterNames[rmd.LastModifyingWriter()] = writer\n\t\t}\n\t\tupdateSummary := UpdateSummary{\n\t\t\tRevision:  rmd.Revision(),\n\t\t\tDate:      rmd.localTimestamp,\n\t\t\tWriter:    writer,\n\t\t\tLiveBytes: rmd.DiskUsage(),\n\t\t\tOps:       make([]OpSummary, 0, len(rmd.data.Changes.Ops)),\n\t\t}\n\t\tfor _, op := range rmd.data.Changes.Ops {\n\t\t\topSummary := OpSummary{\n\t\t\t\tOp:      op.String(),\n\t\t\t\tRefs:    make([]string, 0, len(op.Refs())),\n\t\t\t\tUnrefs:  make([]string, 0, len(op.Unrefs())),\n\t\t\t\tUpdates: make(map[string]string),\n\t\t\t}\n\t\t\tfor _, ptr := range op.Refs() {\n\t\t\t\topSummary.Refs = append(opSummary.Refs, ptr.String())\n\t\t\t}\n\t\t\tfor _, ptr := range op.Unrefs() {\n\t\t\t\topSummary.Unrefs = append(opSummary.Unrefs, ptr.String())\n\t\t\t}\n\t\t\tfor _, update := range op.allUpdates() {\n\t\t\t\topSummary.Updates[update.Unref.String()] = update.Ref.String()\n\t\t\t}\n\t\t\tupdateSummary.Ops = append(updateSummary.Ops, opSummary)\n\t\t}\n\t\thistory.Updates = append(history.Updates, updateSummary)\n\t}\n\treturn history, nil\n}\n\n// GetEditHistory implements the KBFSOps interface for folderBranchOps\nfunc (fbo *folderBranchOps) GetEditHistory(\n\tctx context.Context, _ FolderBranch) (\n\ttlfHistory keybase1.FSFolderEditHistory, err error) {\n\t// Wait for any outstanding edit requests.\n\tif err := fbo.editActivity.Wait(ctx); err != nil {\n\t\treturn keybase1.FSFolderEditHistory{}, err\n\t}\n\n\tlState := makeFBOLockState()\n\tmd, _ := fbo.getHead(lState)\n\tname := md.GetTlfHandle().GetCanonicalName()\n\treturn fbo.config.UserHistory().GetTlfHistory(name, fbo.id().Type()), nil\n}\n\n// PushStatusChange forces a new status be fetched by status listeners.\nfunc (fbo *folderBranchOps) PushStatusChange() {\n\tfbo.config.KBFSOps().PushStatusChange()\n}\n\n// ClearPrivateFolderMD implements the KBFSOps interface for\n// folderBranchOps.\nfunc (fbo *folderBranchOps) ClearPrivateFolderMD(ctx context.Context) {\n\tfunc() {\n\t\t// Cancel the edits goroutine and forget the old history, evem\n\t\t// for public folders, since some of the state in the history\n\t\t// is dependent on your login state.\n\t\tfbo.cancelEditsLock.Lock()\n\t\tdefer fbo.cancelEditsLock.Unlock()\n\t\tif fbo.cancelEdits != nil {\n\t\t\tfbo.cancelEdits()\n\t\t\tfbo.cancelEdits = nil\n\t\t}\n\t\tfbo.editHistory = kbfsedits.NewTlfHistory()\n\t\tfbo.convLock.Lock()\n\t\tdefer fbo.convLock.Unlock()\n\t\tfbo.convID = nil\n\t}()\n\n\tif fbo.folderBranch.Tlf.Type() == tlf.Public {\n\t\treturn\n\t}\n\n\tlState := makeFBOLockState()\n\tfbo.mdWriterLock.Lock(lState)\n\tdefer fbo.mdWriterLock.Unlock(lState)\n\tfbo.headLock.Lock(lState)\n\tdefer fbo.headLock.Unlock(lState)\n\tif fbo.head == (ImmutableRootMetadata{}) {\n\t\t// Nothing to clear.\n\t\treturn\n\t}\n\n\tfbo.log.CDebugf(ctx, \"Clearing folder MD\")\n\n\t// First cancel the background goroutine that's registered for\n\t// updates, because the next time we set the head in this FBO\n\t// we'll launch another one.\n\tfbo.cancelUpdatesLock.Lock()\n\tdefer fbo.cancelUpdatesLock.Unlock()\n\tif fbo.cancelUpdates != nil {\n\t\tfbo.cancelUpdates()\n\t\tselect {\n\t\tcase <-fbo.updateDoneChan:\n\t\tcase <-ctx.Done():\n\t\t\tfbo.log.CDebugf(\n\t\t\t\tctx, \"Context canceled before updater was canceled\")\n\t\t\treturn\n\t\t}\n\t\tfbo.config.MDServer().CancelRegistration(ctx, fbo.id())\n\t}\n\n\tfbo.head = ImmutableRootMetadata{}\n\tfbo.headStatus = headUntrusted\n\tfbo.latestMergedRevision = kbfsmd.RevisionUninitialized\n\tfbo.hasBeenCleared = true\n}\n\n// ForceFastForward implements the KBFSOps interface for\n// folderBranchOps.\nfunc (fbo *folderBranchOps) ForceFastForward(ctx context.Context) {\n\tlState := makeFBOLockState()\n\tfbo.headLock.RLock(lState)\n\tdefer fbo.headLock.RUnlock(lState)\n\tif fbo.head != (ImmutableRootMetadata{}) {\n\t\t// We're already up to date.\n\t\treturn\n\t}\n\tif !fbo.hasBeenCleared {\n\t\t// No reason to fast-forward here if it hasn't ever been\n\t\t// cleared.\n\t\treturn\n\t}\n\n\tfbo.forcedFastForwards.Add(1)\n\tgo func() {\n\t\tdefer fbo.forcedFastForwards.Done()\n\t\tctx, cancelFunc := fbo.newCtxWithFBOID()\n\t\tdefer cancelFunc()\n\n\t\tfbo.log.CDebugf(ctx, \"Forcing a fast-forward\")\n\t\tcurrHead, err := fbo.config.MDOps().GetForTLF(ctx, fbo.id(), nil)\n\t\tif err != nil {\n\t\t\tfbo.log.CDebugf(ctx, \"Fast-forward failed: %v\", err)\n\t\t\treturn\n\t\t}\n\t\tif currHead == (ImmutableRootMetadata{}) {\n\t\t\tfbo.log.CDebugf(ctx, \"No MD yet\")\n\t\t\treturn\n\t\t}\n\t\tfbo.log.CDebugf(ctx, \"Current head is revision %d\", currHead.Revision())\n\n\t\tlState := makeFBOLockState()\n\t\tfbo.mdWriterLock.Lock(lState)\n\t\tdefer fbo.mdWriterLock.Unlock(lState)\n\t\tfbo.headLock.Lock(lState)\n\t\tdefer fbo.headLock.Unlock(lState)\n\t\tif fbo.head != (ImmutableRootMetadata{}) {\n\t\t\t// We're already up to date.\n\t\t\tfbo.log.CDebugf(ctx, \"Already up-to-date: %v\", err)\n\t\t\treturn\n\t\t}\n\n\t\terr = fbo.doFastForwardLocked(ctx, lState, currHead)\n\t\tif err != nil {\n\t\t\tfbo.log.CDebugf(ctx, \"Fast-forward failed: %v\", err)\n\t\t}\n\t}()\n}\n\n// KickoffAllOutstandingRekeys (does not) implement the KBFSOps interface for\n// folderBranchOps.\nfunc (fbo *folderBranchOps) KickoffAllOutstandingRekeys() error {\n\treturn errors.New(\n\t\t\"KickoffAllOutstandingRekeys is not supported on *folderBranchOps\")\n}\n\n// NewNotificationChannel implements the KBFSOps interface for\n// folderBranchOps.\nfunc (fbo *folderBranchOps) NewNotificationChannel(\n\tctx context.Context, handle *TlfHandle, convID chat1.ConversationID,\n\tchannelName string) {\n\tfbo.log.CDebugf(ctx, \"New notification channel: %s %s\", convID, channelName)\n\tfbo.editActivity.Add(1)\n\tfbo.editChannels <- editChannelActivity{convID, channelName, \"\"}\n}\n\n// PushConnectionStatusChange pushes human readable connection status changes.\nfunc (fbo *folderBranchOps) PushConnectionStatusChange(service string, newStatus error) {\n\tswitch service {\n\tcase KeybaseServiceName, GregorServiceName:\n\tdefault:\n\t\treturn\n\t}\n\n\tif newStatus == nil {\n\t\tfbo.log.CDebugf(nil, \"Asking for an edit re-init after reconnection\")\n\t\tfbo.editActivity.Add(1)\n\t\tfbo.editChannels <- editChannelActivity{nil, \"\", \"\"}\n\t}\n}\n\nfunc (fbo *folderBranchOps) receiveNewEditChat(\n\tconvID chat1.ConversationID, message string) {\n\tfbo.editActivity.Add(1)\n\tfbo.editChannels <- editChannelActivity{convID, \"\", message}\n}\n\nfunc (fbo *folderBranchOps) initEditChatChannels(\n\tctx context.Context, name tlf.CanonicalName) (\n\tidToName map[string]string,\n\tnameToID map[string]chat1.ConversationID,\n\tnameToNextPage map[string][]byte) {\n\tconvIDs, channelNames, err := fbo.config.Chat().GetChannels(\n\t\tctx, name, fbo.id().Type(), chat1.TopicType_KBFSFILEEDIT)\n\tif err != nil {\n\t\t// TODO: schedule a retry?\n\t\tfbo.log.CWarningf(ctx, \"Couldn't monitor kbfs-edits chats: %+v\", err)\n\t\treturn\n\t}\n\n\tidToName = make(map[string]string, len(convIDs))\n\tnameToID = make(map[string]chat1.ConversationID, len(convIDs))\n\tnameToNextPage = make(map[string][]byte, len(convIDs))\n\tfor i, id := range convIDs {\n\t\tfbo.config.Chat().RegisterForMessages(id, fbo.receiveNewEditChat)\n\t\tname := channelNames[i]\n\t\tidToName[id.String()] = name\n\t\tnameToID[name] = id\n\t\tnextPage := fbo.getEditMessages(ctx, id, name, nil)\n\t\tif nextPage != nil {\n\t\t\tnameToNextPage[name] = nextPage\n\t\t}\n\t}\n\treturn idToName, nameToID, nameToNextPage\n}\n\nfunc (fbo *folderBranchOps) getEditMessages(\n\tctx context.Context, id chat1.ConversationID, channelName string,\n\tstartPage []byte) (nextPage []byte) {\n\t// TODO: be smarter about not fetching messages we've already\n\t// seen?  `AddNotifications` below will filter out any duplicates,\n\t// so it's not strictly needed for correctness.\n\tmessages, nextPage, err := fbo.config.Chat().ReadChannel(ctx, id, startPage)\n\tif err != nil {\n\t\tfbo.log.CWarningf(ctx, \"Couldn't get messages for conv %s: %+v\",\n\t\t\tid, err)\n\t\treturn nil\n\t}\n\terr = fbo.editHistory.AddNotifications(channelName, messages)\n\tif err != nil {\n\t\tfbo.log.CWarningf(ctx, \"Couldn't add messages for conv %s: %+v\",\n\t\t\tid, err)\n\t\treturn nil\n\t}\n\treturn nextPage\n}\n\nfunc (fbo *folderBranchOps) recomputeEditHistory(\n\tctx context.Context,\n\ttlfName tlf.CanonicalName,\n\tnameToID map[string]chat1.ConversationID,\n\tnameToNextPage map[string][]byte) {\n\tgotMore := true\n\n\tsession, err := GetCurrentSessionIfPossible(ctx, fbo.config.KBPKI(), true)\n\tif err != nil {\n\t\tfbo.log.CWarningf(ctx, \"Error getting session: %+v\", err)\n\t\treturn\n\t}\n\n\tfor gotMore {\n\t\t// Recompute the history, and fetch more messages for any\n\t\t// writers who need them.\n\t\twritersWhoNeedMore := fbo.editHistory.Recompute(string(session.Name))\n\t\tgotMore = false\n\t\tfor w, needsMore := range writersWhoNeedMore {\n\t\t\tif !needsMore {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif startPage, ok := nameToNextPage[w]; ok && startPage != nil {\n\t\t\t\tid, ok := nameToID[w]\n\t\t\t\tif !ok {\n\t\t\t\t\tfbo.log.CDebugf(ctx, \"No channel found for %s\", w)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tfbo.log.CDebugf(\n\t\t\t\t\tctx, \"Going to fetch more messages for writer %s\", w)\n\t\t\t\tgotMore = true\n\t\t\t\tnextPage := fbo.getEditMessages(ctx, id, w, startPage)\n\t\t\t\tif nextPage == nil {\n\t\t\t\t\tdelete(nameToNextPage, w)\n\t\t\t\t} else {\n\t\t\t\t\tnameToNextPage[w] = nextPage\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t// Update the overall user history.  TODO: if the TLF name\n\t// changed, we should clean up the old user history.\n\tfbo.config.UserHistory().UpdateHistory(\n\t\ttlfName, fbo.id().Type(), fbo.editHistory, string(session.Name))\n}\n\nfunc (fbo *folderBranchOps) handleEditActivity(\n\tctx context.Context,\n\ta editChannelActivity,\n\ttlfName tlf.CanonicalName,\n\tidToName map[string]string,\n\tnameToID map[string]chat1.ConversationID,\n\tnameToNextPage map[string][]byte) (\n\tidToNameRet map[string]string,\n\tnameToIDRet map[string]chat1.ConversationID,\n\tnameToNextPageRet map[string][]byte) {\n\tdefer func() {\n\t\tfbo.recomputeEditHistory(ctx, tlfName, nameToIDRet, nameToNextPageRet)\n\t\tfbo.editActivity.Done()\n\t}()\n\n\tif a.convID == nil {\n\t\tfbo.log.CDebugf(ctx, \"Re-initializing chat channels\")\n\t\treturn fbo.initEditChatChannels(ctx, tlfName)\n\t}\n\n\tidStr := a.convID.String()\n\tname, ok := idToName[idStr]\n\tif !ok {\n\t\t// This is a new channel that we need to monitor.\n\t\tfbo.config.Chat().RegisterForMessages(\n\t\t\ta.convID, fbo.receiveNewEditChat)\n\t\tidToName[idStr] = a.name\n\t\tnameToID[a.name] = a.convID\n\t\tname = a.name\n\t}\n\tif a.message != \"\" {\n\t\tfbo.log.CDebugf(ctx, \"New edit message for %s\", name)\n\t\terr := fbo.editHistory.AddNotifications(name, []string{a.message})\n\t\tif err != nil {\n\t\t\tfbo.log.CWarningf(ctx,\n\t\t\t\t\"Couldn't add messages for conv %s: %+v\", a.convID, err)\n\t\t\treturn\n\t\t}\n\t} else {\n\t\tfbo.log.CDebugf(ctx, \"New edit channel for %s\", name)\n\t\tnextPage := fbo.getEditMessages(ctx, a.convID, name, nil)\n\t\tif nextPage != nil {\n\t\t\tnameToNextPage[name] = nextPage\n\t\t}\n\t}\n\n\treturn idToName, nameToID, nameToNextPage\n}\n\nfunc (fbo *folderBranchOps) monitorEditsChat() {\n\tctx, cancelFunc := fbo.newCtxWithFBOID()\n\tdefer cancelFunc()\n\tfbo.log.CDebugf(ctx, \"Starting kbfs-edits chat monitoring\")\n\n\tfbo.cancelEditsLock.Lock()\n\tfbo.cancelEdits = cancelFunc\n\tfbo.cancelEditsLock.Unlock()\n\n\t// Register for all the channels of this chat.\n\tlState := makeFBOLockState()\n\tmd, _ := fbo.getHead(lState)\n\ttlfName := md.GetTlfHandle().GetCanonicalName()\n\n\tidToName := make(map[string]string)\n\tnameToID := make(map[string]chat1.ConversationID)\n\tnameToNextPage := make(map[string][]byte)\n\n\tfor {\n\t\tselect {\n\t\tcase <-fbo.shutdownChan:\n\t\t\tfbo.log.CDebugf(ctx, \"Shutting down chat monitoring\")\n\t\t\treturn\n\t\tcase a := <-fbo.editChannels:\n\t\t\tidToName, nameToID, nameToNextPage = fbo.handleEditActivity(\n\t\t\t\tctx, a, tlfName, idToName, nameToID, nameToNextPage)\n\t\tcase <-ctx.Done():\n\t\t\treturn\n\t\t}\n\t}\n}\n", "idx": 1, "id": 19763, "msg": "Do we still want the \"admins\" gate?", "proj": "keybase-kbfs", "lang": "go"}
{"patch": "@@ -159,3 +159,19 @@ class GCSTargetTest(_GCSBaseTestCase, FileSystemTargetTestMixin):\n \n     def create_target(self, format=None):\n         return gcs.GCSTarget(bucket_url(self.id()), format=format, client=self.client)\n+\n+    def test_close_twice(self):\n+        # Ensure gcs._DeleteOnCloseFile().close() can be called multiple times\n+        tgt = self.create_target()\n+\n+        with tgt.open('w') as dst:\n+            dst.write('data')\n+        assert dst.closed\n+        dst.close()\n+        assert dst.closed\n+\n+        with tgt.open() as src:\n+            assert src.read().strip() == 'data'\n+        assert src.closed\n+        src.close()\n+        assert src.closed", "y": 1, "oldf": "# -*- coding: utf-8 -*-\n#\n# Copyright 2015 Twitter Inc\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n\"\"\"This is an integration test for the GCS-luigi binding.\n\nThis test requires credentials that can access GCS & access to a bucket below.\nFollow the directions in the gcloud tools to set up local credentials.\n\"\"\"\n\nfrom helpers import unittest\ntry:\n    import googleapiclient.errors\n    import oauth2client\nexcept ImportError:\n    raise unittest.SkipTest('Unable to load googleapiclient module')\nimport os\nimport tempfile\nimport unittest\n\nfrom luigi.contrib import gcs\nfrom target_test import FileSystemTargetTestMixin\nfrom nose.plugins.attrib import attr\n\n# In order to run this test, you should set these to your GCS project/bucket.\n# Unfortunately there's no mock\nPROJECT_ID = os.environ.get('GCS_TEST_PROJECT_ID', 'your_project_id_here')\nBUCKET_NAME = os.environ.get('GCS_TEST_BUCKET', 'your_test_bucket_here')\nTEST_FOLDER = os.environ.get('TRAVIS_BUILD_ID', 'gcs_test_folder')\n\nCREDENTIALS = oauth2client.client.GoogleCredentials.get_application_default()\nATTEMPTED_BUCKET_CREATE = False\n\n\ndef bucket_url(suffix):\n    \"\"\"\n    Actually it's bucket + test folder name\n    \"\"\"\n    return 'gs://{}/{}/{}'.format(BUCKET_NAME, TEST_FOLDER, suffix)\n\n\nclass _GCSBaseTestCase(unittest.TestCase):\n    def setUp(self):\n        self.client = gcs.GCSClient(CREDENTIALS)\n\n        global ATTEMPTED_BUCKET_CREATE\n        if not ATTEMPTED_BUCKET_CREATE:\n            try:\n                self.client.client.buckets().insert(\n                    project=PROJECT_ID, body={'name': BUCKET_NAME}).execute()\n            except googleapiclient.errors.HttpError as ex:\n                if ex.resp.status != 409:  # bucket already exists\n                    raise\n\n            ATTEMPTED_BUCKET_CREATE = True\n\n        self.client.remove(bucket_url(''), recursive=True)\n        self.client.mkdir(bucket_url(''))\n\n    def tearDown(self):\n        self.client.remove(bucket_url(''), recursive=True)\n\n\n@attr('gcloud')\nclass GCSClientTest(_GCSBaseTestCase):\n\n    def test_not_exists(self):\n        self.assertFalse(self.client.exists(bucket_url('does_not_exist')))\n        self.assertFalse(self.client.isdir(bucket_url('does_not_exist')))\n\n    def test_exists(self):\n        self.client.put_string('hello', bucket_url('exists_test'))\n        self.assertTrue(self.client.exists(bucket_url('exists_test')))\n        self.assertFalse(self.client.isdir(bucket_url('exists_test')))\n\n    def test_mkdir(self):\n        self.client.mkdir(bucket_url('exists_dir_test'))\n        self.assertTrue(self.client.exists(bucket_url('exists_dir_test')))\n        self.assertTrue(self.client.isdir(bucket_url('exists_dir_test')))\n\n    def test_mkdir_by_upload(self):\n        self.client.put_string('hello', bucket_url('test_dir_recursive/yep/file'))\n        self.assertTrue(self.client.exists(bucket_url('test_dir_recursive')))\n        self.assertTrue(self.client.isdir(bucket_url('test_dir_recursive')))\n\n    def test_download(self):\n        self.client.put_string('hello', bucket_url('test_download'))\n        fp = self.client.download(bucket_url('test_download'))\n        self.assertEquals(b'hello', fp.read())\n\n    def test_rename(self):\n        self.client.put_string('hello', bucket_url('test_rename_1'))\n        self.client.rename(bucket_url('test_rename_1'), bucket_url('test_rename_2'))\n        self.assertFalse(self.client.exists(bucket_url('test_rename_1')))\n        self.assertTrue(self.client.exists(bucket_url('test_rename_2')))\n\n    def test_rename_recursive(self):\n        self.client.mkdir(bucket_url('test_rename_recursive'))\n        self.client.put_string('hello', bucket_url('test_rename_recursive/1'))\n        self.client.put_string('hello', bucket_url('test_rename_recursive/2'))\n        self.client.rename(bucket_url('test_rename_recursive'), bucket_url('test_rename_recursive_dest'))\n        self.assertFalse(self.client.exists(bucket_url('test_rename_recursive')))\n        self.assertFalse(self.client.exists(bucket_url('test_rename_recursive/1')))\n        self.assertTrue(self.client.exists(bucket_url('test_rename_recursive_dest')))\n        self.assertTrue(self.client.exists(bucket_url('test_rename_recursive_dest/1')))\n\n    def test_remove(self):\n        self.client.put_string('hello', bucket_url('test_remove'))\n        self.client.remove(bucket_url('test_remove'))\n        self.assertFalse(self.client.exists(bucket_url('test_remove')))\n\n    def test_remove_recursive(self):\n        self.client.mkdir(bucket_url('test_remove_recursive'))\n        self.client.put_string('hello', bucket_url('test_remove_recursive/1'))\n        self.client.put_string('hello', bucket_url('test_remove_recursive/2'))\n        self.client.remove(bucket_url('test_remove_recursive'))\n\n        self.assertFalse(self.client.exists(bucket_url('test_remove_recursive')))\n        self.assertFalse(self.client.exists(bucket_url('test_remove_recursive/1')))\n        self.assertFalse(self.client.exists(bucket_url('test_remove_recursive/2')))\n\n    def test_listdir(self):\n        self.client.put_string('hello', bucket_url('test_listdir/1'))\n        self.client.put_string('hello', bucket_url('test_listdir/2'))\n\n        self.assertEqual([bucket_url('test_listdir/1'), bucket_url('test_listdir/2')],\n                         list(self.client.listdir(bucket_url('test_listdir/'))))\n        self.assertEqual([bucket_url('test_listdir/1'), bucket_url('test_listdir/2')],\n                         list(self.client.listdir(bucket_url('test_listdir'))))\n\n    def test_put_file(self):\n        with tempfile.NamedTemporaryFile() as fp:\n            lorem = 'Lorem ipsum dolor sit amet, consectetuer adipiscing elit, sed diam nonummy nibh euismod tincidunt\\n'\n            # Larger file than chunk size, fails with incorrect progress set up\n            big = lorem * 41943\n            fp.write(big)\n            fp.flush()\n\n            self.client.put(fp.name, bucket_url('test_put_file'))\n            self.assertTrue(self.client.exists(bucket_url('test_put_file')))\n            self.assertEquals(big, self.client.download(bucket_url('test_put_file')).read())\n\n\n@attr('gcloud')\nclass GCSTargetTest(_GCSBaseTestCase, FileSystemTargetTestMixin):\n\n    def create_target(self, format=None):\n        return gcs.GCSTarget(bucket_url(self.id()), format=format, client=self.client)\n", "idx": 1, "id": 13062, "msg": "You don't need to fix this (you've done so many iterations). But for next time, you can make this into a docstring so it'll have a nicer descriptive name when the tests are running.", "proj": "spotify-luigi", "lang": "py"}
{"patch": "@@ -42,4 +42,13 @@ public interface RewriteFiles extends SnapshotUpdate<RewriteFiles> {\n    * @return this for method chaining\n    */\n   RewriteFiles rewriteFiles(Set<DataFile> filesToDelete, Set<DataFile> filesToAdd);\n+\n+  /**\n+   * Add a rewrite that replaces one set of deletes with another that contains the same deleted rows.\n+   *\n+   * @param deletesToDelete files that will be replaced, cannot be null or empty.\n+   * @param deletesToAdd files that will be added, cannot be null or empty.\n+   * @return this for method chaining\n+   */\n+  RewriteFiles rewriteDeletes(Set<DeleteFile> deletesToDelete, Set<DeleteFile> deletesToAdd);\n }", "y": 1, "oldf": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\n\npackage org.apache.iceberg;\n\nimport java.util.Set;\nimport org.apache.iceberg.exceptions.ValidationException;\n\n/**\n * API for replacing files in a table.\n * <p>\n * This API accumulates file additions and deletions, produces a new {@link Snapshot} of the\n * changes, and commits that snapshot as the current.\n * <p>\n * When committing, these changes will be applied to the latest table snapshot. Commit conflicts\n * will be resolved by applying the changes to the new latest snapshot and reattempting the commit.\n * If any of the deleted files are no longer in the latest snapshot when reattempting, the commit\n * will throw a {@link ValidationException}.\n */\npublic interface RewriteFiles extends SnapshotUpdate<RewriteFiles> {\n  /**\n   * Add a rewrite that replaces one set of files with another set that contains the same data.\n   *\n   * @param filesToDelete files that will be replaced (deleted), cannot be null or empty.\n   * @param filesToAdd files that will be added, cannot be null or empty.\n   * @return this for method chaining\n   */\n  RewriteFiles rewriteFiles(Set<DataFile> filesToDelete, Set<DataFile> filesToAdd);\n}\n", "idx": 1, "id": 33317, "msg": "Before we start the replacing equality deletes with position deletes, I think we need to refactor the RewriteFiles API to adjust more cases: 1. Rewrite data files and remove all the delete rows. The files to delete will be a set of data files and a set of delete files, and the files to add will be a set of data files. 2. Replace equality deletes with position deletes, the files to delete will be a set of equality delete files (we will need to ensure that all delete files are equality delete files ? ) , the files to add will be a set of position delete files. 3. Merging small delete files into a bigger delete files. The files to delete will be a set of equality/position delete files, the files to add will be a set of equality/position delete files.", "proj": "apache-iceberg", "lang": "java"}
{"patch": "@@ -7367,6 +7367,7 @@ check_thread_vm_area(dcontext_t *dcontext, app_pc pc, app_pc tag, void **vmlist,\n             read_lock(&executable_areas->lock);\n         ok = lookup_addr(executable_areas, pc, &area);\n         if (ok && TEST(VM_DELAY_READONLY, area->vm_flags)) {\n+            bool is_allocated_mem;\n             /* need to mark region read only for consistency\n              * need to upgrade to write lock, have to release lock first\n              * then recheck conditions after grabbing hotp + write lock */", "y": 1, "oldf": "/* **********************************************************\n * Copyright (c) 2010-2017 Google, Inc.  All rights reserved.\n * Copyright (c) 2002-2010 VMware, Inc.  All rights reserved.\n * **********************************************************/\n\n/*\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n * * Redistributions of source code must retain the above copyright notice,\n *   this list of conditions and the following disclaimer.\n *\n * * Redistributions in binary form must reproduce the above copyright notice,\n *   this list of conditions and the following disclaimer in the documentation\n *   and/or other materials provided with the distribution.\n *\n * * Neither the name of VMware, Inc. nor the names of its contributors may be\n *   used to endorse or promote products derived from this software without\n *   specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED. IN NO EVENT SHALL VMWARE, INC. OR CONTRIBUTORS BE LIABLE\n * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\n * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH\n * DAMAGE.\n */\n\n/* Copyright (c) 2003-2007 Determina Corp. */\n/* Copyright (c) 2002-2003 Massachusetts Institute of Technology */\n\n/*\n * vmareas.c - virtual memory executable areas\n */\n\n#include \"globals.h\"\n\n/* all of this for selfmod handling */\n#include \"fragment.h\"\n#include \"instr.h\"\n#include \"decode.h\"\n#include \"decode_fast.h\"\n\n#include \"link.h\"\n#include \"disassemble.h\"\n#include \"fcache.h\"\n#include \"hotpatch.h\"\n#include \"moduledb.h\"\n#include \"module_shared.h\"\n#include \"perscache.h\"\n#include \"translate.h\"\n#include \"jit_opt.h\"\n\n#ifdef WINDOWS\n# include \"events.h\"             /* event log messages - not supported yet on Linux  */\n#endif\n\n#ifdef CLIENT_INTERFACE\n# include \"instrument.h\"\n#endif\n\n#ifdef DEBUG\n# include \"synch.h\" /* all_threads_synch_lock */\n#endif\n\n#include <string.h>\n\nenum {\n    /* VM_ flags to distinguish region types\n     * We also use some FRAG_ flags (but in a separate field so no value space overlap)\n     * Adjacent regions w/ different flags are never merged.\n     */\n    VM_WRITABLE     = 0x0001,    /* app memory writable? */\n    /* UNMOD_IMAGE means the region was mmapped in and has been read-only since then\n     * this excludes even loader modifications (IAT update, relocate, etc.) on win32!\n     */\n    VM_UNMOD_IMAGE  = 0x0002,\n    VM_DELETE_ME    = 0x0004,    /* on delete queue -- for thread-local only */\n     /* NOTE : if a new area is added that overlaps an existing area with a\n      * different VM_WAS_FUTURE flag, the areas will be merged with the flag\n      * taken from the new area, see FIXME in add_vm_area */\n    VM_WAS_FUTURE   = 0x0008,    /* moved from future list to exec list */\n    VM_DR_HEAP      = 0x0010,    /* DR heap area */\n    VM_ONCE_ONLY    = 0x0020,    /* on future list but should be removed on\n                                  * first exec */\n    /* FIXME case 7877, 3744: need to properly merge pageprot regions with\n     * existing selfmod regions before we can truly separate this.  For now we\n     * continue to treat selfmod as pageprot.\n     * Once we separate, we should update DR_MADE_READONLY.\n     */\n    VM_MADE_READONLY = VM_WRITABLE/* FIXME: should be 0x0040 -- see above */,\n                                 /* DR has marked this region read\n                                  * only for consistency, should only be used\n                                  * in conjunction with VM_WRITABLE */\n    VM_DELAY_READONLY = 0x0080,  /* dr has not yet marked this region read\n                                  * only for consistency, should only be used\n                                  * in conjunction with VM_WRITABLE */\n#ifdef PROGRAM_SHEPHERDING\n    /* re-verify this region for code origins policies every time it is\n     * encountered.  only used with selfmod regions that are only allowed if\n     * they match patterns, to prevent other threads from writing non-pattern\n     * code though and executing after the region has been approved.\n     * xref case 4020.  can remove once we split code origins list from\n     * cache consistency list (case 3744).\n     */\n    VM_PATTERN_REVERIFY = 0x0100,\n#endif\n\n    VM_DRIVER_ADDRESS   = 0x0200,\n    /* a driver hooker area, needed for case 9022.  Note we can\n     * normally read properties only of user mode addresses, so we\n     * have to probe addresses in this area.  Also note that we're\n     * still executing all of this code in user mode e.g. there is no\n     * mode switch, no conforming segments, etc.\n     */\n\n    /* Does this region contain a persisted cache?\n     * Must also be FRAG_COARSE_GRAIN of course.\n     * This is a shortcut to reading custom.client->persisted.\n     * This is not guaranteed to be set on shared_data: only on executable_areas.\n     */\n    VM_PERSISTED_CACHE     = 0x0400,\n\n    /* Case 10584: avoid flush synch when no code has been executed */\n    VM_EXECUTED_FROM       = 0x0800,\n\n    /* A workaround for lock rank issues: we delay adding loaded persisted\n     * units to shared_data until first asked about.\n     * This flags is NOT propagated on vmarea splits.\n     */\n    VM_ADD_TO_SHARED_DATA  = 0x1000,\n\n    /* i#1114: for areas containing JIT code flushed via annotation or inference */\n    VM_JIT_MANAGED         = 0x2000,\n};\n\n/* simple way to disable sandboxing */\n#define SANDBOX_FLAG() \\\n    (INTERNAL_OPTION(hw_cache_consistency) ? FRAG_SELFMOD_SANDBOXED : 0)\n\n/* Because VM_MADE_READONLY == VM_WRITABLE it's not sufficient on its own */\n#define DR_MADE_READONLY(flags) \\\n    (INTERNAL_OPTION(hw_cache_consistency) && TEST(VM_MADE_READONLY, flags))\n\n/* Fields only used for written_areas */\ntypedef struct _ro_vs_sandbox_data_t {\n    /* written_count only used for written_areas vector.\n     * if > 0, areas will NOT be merged, so we can keep separate\n     * counts by page (hopefully not making the list too long).\n     */\n    uint written_count;\n    /* Used only for -sandbox2ro_threshold.  It's only in the\n     * written_areas vector b/c executable_areas has its regions removed\n     * on a flush while threads could still be accessing counters in\n     * selfmod fragments in the cache.  We lose some granularity here but\n     * it's not a big deal.\n     * We could make these both ushorts, but it'd be more of a pain\n     * to increment this counter from the cache then, worrying about overflows.\n     */\n    uint selfmod_execs;\n#ifdef DEBUG\n    uint ro2s_xfers;\n    uint s2ro_xfers;\n#endif\n} ro_vs_sandbox_data_t;\n\n/* Our executable area list has three types of areas.  Each type can be merged\n * with adjacent areas of the same type but not with any of the other types!\n * 1) originally RO code   == we leave alone\n * 2) originally RW code   == we mark RO\n * 3) originally RW code, written to from within itself  == we leave RW and sandbox\n * We keep all three types in the same list b/c any particular address interval\n * can only be of one type at any one time, and all three are executable, meaning\n * code cache code was copied from there.\n */\ntypedef struct vm_area_t {\n    app_pc start;\n    app_pc end;         /* open end interval */\n    /* We have two different flags fields to allow easy use of the FRAG_ flags.\n     * The two combined are used to distinguish different regions.\n     * Adjacent regions w/ different flags are never merged.\n     */\n    /* Flags that start with VM_ */\n    uint vm_flags;\n    /* Flags that start with FRAG_\n     * In use now are FRAG_SELFMOD_SANDBOXED and FRAG_DYNGEN.\n     */\n    uint frag_flags;\n#ifdef DEBUG\n    char *comment;\n#endif\n    /********************\n     * custom fields not used in all vectors\n     * FIXME: separate into separately-allocated piece?  or have a struct\n     * extension (poor man's subclass, like trace_t, etc.) and make our vector\n     * iterators handle it?\n     * once we have a generic interval data structure (case 6208) this\n     * hardcoding of individual uses will go away.\n     */\n    union {\n        /* Used in per-thread and shared vectors, not in master area lists.\n         * We identify vectors using this via VECTOR_FRAGMENT_LIST, needed\n         * b/c {add,remove}_vm_area have special behavior for frags.\n         */\n        fragment_t *frags;\n        /* for clients' custom use via vmvector interfaces */\n        void *client;\n    } custom;\n} vm_area_t;\n\n/* for each thread we record all executable areas, to make it faster\n * to decide whether we need to flush any fragments on an munmap\n */\ntypedef struct thread_data_t {\n    vm_area_vector_t areas;\n    /* cached pointer to last area encountered by thread */\n    vm_area_t *last_area;\n    /* FIXME: for locality would be nice to have per-thread last_shared_area\n     * (cannot put shared in private last_area, that would void its usefulness\n     *  since couldn't tell if area really in shared list or not)\n     * but then have to update all other threads whenever change shared\n     * vmarea vector, so for now we use a global last_area\n     */\n    /* cached pointer of a PC in the last page decoded by thread -- set only\n     * in thread-private structures, not in shared structures like shared_data */\n    app_pc last_decode_area_page_pc;\n    bool   last_decode_area_valid; /* since no sentinel exists */\n#ifdef PROGRAM_SHEPHERDING\n    uint thrown_exceptions; /* number of responses to execution violations */\n#endif\n} thread_data_t;\n\n#define SHOULD_LOCK_VECTOR(v)                               \\\n       (TEST(VECTOR_SHARED, (v)->flags) &&                  \\\n        !TEST(VECTOR_NO_LOCK, (v)->flags) &&                \\\n        !self_owns_write_lock(&(v)->lock))\n\n#define LOCK_VECTOR(v, release_lock, RW) do {               \\\n    if (SHOULD_LOCK_VECTOR(v)) {                            \\\n        (release_lock) = true;                              \\\n        RW##_lock(&(v)->lock);                              \\\n    }                                                       \\\n    else                                                    \\\n        (release_lock) = false;                             \\\n} while (0);\n\n#define UNLOCK_VECTOR(v, release_lock, RW) do {             \\\n    if ((release_lock)) {                                   \\\n        ASSERT(TEST(VECTOR_SHARED, (v)->flags));            \\\n        ASSERT(!TEST(VECTOR_NO_LOCK, (v)->flags));          \\\n        ASSERT_OWN_READWRITE_LOCK(true, &(v)->lock);        \\\n        RW##_unlock(&v->lock);                              \\\n    }                                                       \\\n} while (0);\n\n/* these two global vectors store all executable areas and all dynamo\n * areas (executable or otherwise).\n * executable_areas' custom field is used to store coarse unit info.\n * for a FRAG_COARSE_GRAIN region, an info struct is always present, even\n * if not yet executed from (initially, or after a flush).\n */\nstatic vm_area_vector_t *executable_areas;\nstatic vm_area_vector_t *dynamo_areas;\n\n/* Protected by executable_areas lock; used only to delete coarse_info_t\n * while holding executable_areas lock during execute-less flushes\n * (case 10995).  Extra layer of indirection to get on heap and avoid .data\n * unprotection.\n */\nstatic coarse_info_t **coarse_to_delete;\n\n/* used for DYNAMO_OPTION(handle_DR_modify),\n * DYNAMO_OPTION(handle_ntdll_modify) == DR_MODIFY_NOP or\n * DYNAMO_OPTION(patch_proof_list)\n */\nstatic vm_area_vector_t *pretend_writable_areas;\n\n/* used for DYNAMO_OPTION(patch_proof_list) areas to watch */\nvm_area_vector_t *patch_proof_areas;\n\n/* used for DYNAMO_OPTION(emulate_IAT_writes), though in future may be\n * expanded, so not just ifdef WINDOWS or ifdef PROGRAM_SHEPHERDING\n */\nvm_area_vector_t *emulate_write_areas;\n\n/* used for DYNAMO_OPTION(IAT_convert)\n * IAT or GOT areas of all mapped DLLs - note the exact regions are added here.\n * While the IATs for modules in native_exec_areas are not added here -\n * note that any module's IAT may still be importing native modules.\n */\nvm_area_vector_t *IAT_areas;\n\n/* Keeps persistent written-to and execution counts for switching back and\n * forth from page prot to sandboxing.\n */\nstatic vm_area_vector_t *written_areas;\n\nstatic void free_written_area(void *data);\n\n#ifdef PROGRAM_SHEPHERDING\n/* for executable_if_flush and executable_if_alloc, we need a future list, so their regions\n * are considered executable until de-allocated -- even if written to!\n */\nstatic vm_area_vector_t *futureexec_areas;\n# ifdef WINDOWS\n/* FIXME: for -xdata_rct we only need start pc called on, so htable would do,\n * once we have reusable htable for storing single pc\n */\nstatic vm_area_vector_t *app_flushed_areas;\n\n# endif\n#endif\n\n/* tamper resistant region see tamper_resistant_region_add() for current use.\n * If needed this should be turned into a vm_area_vector_t as well.\n */\nstatic app_pc tamper_resistant_region_start, tamper_resistant_region_end;\n\n\n/* shared_data is synchronized via either single_thread_in_DR or\n * the vector lock (cannot use bb_building_lock b/c both trace building\n * and pc translation need read access and neither can/should grab\n * the bb building lock, plus it's cleaner to not depend on it, and now\n * with -shared_traces it's not sufficient).\n * N.B.: the vector lock is used to protect not just the vector, but also\n * the whole thread_data_t struct (including last_area) and sequences\n * of vector operations.\n * Kept on the heap for selfprot (case 7957).\n */\nstatic thread_data_t *shared_data; /* set in vm_areas_reset_init() */\n\ntypedef struct _pending_delete_t {\n#ifdef DEBUG\n    /* record bounds of original deleted region, for debugging only */\n    app_pc start;\n    app_pc end;\n#endif\n    /* list of unlinked fragments that are waiting to be deleted */\n    fragment_t *frags;\n    /* ref count and timestamp to determine when it's safe to delete them */\n    uint ref_count;\n    uint flushtime_deleted;\n    /* we use a simple linked list of entries */\n    struct _pending_delete_t *next;\n} pending_delete_t;\n\n/* We keep these list pointers on the heap for selfprot (case 8074). */\ntypedef struct _deletion_lists_t {\n    /* Unlike private vm lists, we cannot simply mark shared_data vm areas as\n     * deleted since new fragments come in concurrently, so we have to have a\n     * separate list of flushed-but-not-yet-deleted areas.  We can't use a\n     * vm_area_vector_t b/c newly flushed fragments spoil our ref count by resetting\n     * it, so we keep a linked list of fragment lists.\n     */\n    pending_delete_t *shared_delete;\n    /* We maintain the tail solely for fcache_free_pending_units() */\n    pending_delete_t *shared_delete_tail;\n    /* count used for reset threshold */\n    uint shared_delete_count;\n\n    /* shared lazy deletion: a list of fragment_t chained via next_vmarea that\n     * are pending deletion, but are only freed when a shared deletion event\n     * shows that it is safe to do so.\n     */\n    fragment_t *lazy_delete_list;\n    /* stores the end of the list, for appending */\n    fragment_t *lazy_delete_tail;\n    /* stores the length of the lazy list */\n    uint lazy_delete_count;\n    /* ensure only one thread tries to move to pending deletion list */\n    bool move_pending;\n} deletion_lists_t;\n\nstatic deletion_lists_t *todelete;\n\ntypedef struct _last_deallocated_t {\n    /* case 9330 - we want to detect races during DLL unloads, and to\n     * silence a reported violation during unload.  At least DLLs are\n     * expected to be already serialized by the loader so keeping only\n     * one is sufficient (note Win2K3 doesn't hold lock only during\n     * process initialization).  We'll also keep references to the\n     * last DLL that was unloaded for diagnostics.  Although, that is\n     * not reliable enough when multiple DLLs are involved - case 6061\n     * should be used for better tracking after unload.\n     */\n    /* Yet loss of integrity is tolerable, as long as detected.  Since\n     * we currently mark all mappings they are not necessarily\n     * serialized (and potentially other apps can directly map, so\n     * can't really count on the loader lock for integrity).  We\n     * should make sure that we do not set unload_in_progress unless\n     * [last_unload_base, last_unload_size) is really still the\n     * current module.\n     */\n    bool unload_in_progress;\n    app_pc last_unload_base;\n    size_t last_unload_size;\n    /* FIXME: we may want to overload the above or add different\n     * fields for non image (MEM_MAPPED) unmaps, and DGC (MEM_PRIVATE)\n     * frees.  Note that we avoid keeping lists of active unloads, or\n     * even to deal with case 9371 we would need intersection of\n     * overlapping app syscalls.  If we serialize app syscalls as\n     * proposed case 545 a single one will be sufficient.\n     */\n} last_deallocated_t;\nstatic last_deallocated_t *last_deallocated;\n/* synchronization currently used only for the contents of\n * last_deallocated: last_unload_base and last_unload_size\n */\nDECLARE_CXTSWPROT_VAR(static mutex_t last_deallocated_lock,\n                      INIT_LOCK_FREE(last_deallocated_lock));\n\n/* synchronization for shared_delete, not a rw lock since readers usually write */\nDECLARE_CXTSWPROT_VAR(mutex_t shared_delete_lock, INIT_LOCK_FREE(shared_delete_lock));\n/* synchronization for the lazy deletion list */\nDECLARE_CXTSWPROT_VAR(static mutex_t lazy_delete_lock, INIT_LOCK_FREE(lazy_delete_lock));\n\n/* multi_entry_t allocation is either global or local heap */\n#define MULTI_ALLOC_DC(dc, flags) FRAGMENT_ALLOC_DC(dc, flags)\n#define GET_DATA(dc, flags) \\\n    (((dc) == GLOBAL_DCONTEXT || TEST(FRAG_SHARED, (flags))) ? shared_data : \\\n     (thread_data_t *) (dc)->vm_areas_field)\n#define GET_VECTOR(dc, flags)                                                  \\\n    (((dc) == GLOBAL_DCONTEXT || TEST(FRAG_SHARED, (flags))) ?                 \\\n     (TEST(FRAG_WAS_DELETED, (flags)) ? NULL : &shared_data->areas) :           \\\n     (&((thread_data_t *)(dc)->vm_areas_field)->areas))\n#define SHARED_VECTOR_RWLOCK(v, rw, op) do    { \\\n    if (TEST(VECTOR_SHARED, (v)->flags)) {      \\\n        ASSERT(SHARED_FRAGMENTS_ENABLED());     \\\n        rw##_##op(&(v)->lock);                  \\\n    }                                           \\\n} while (0)\n#define ASSERT_VMAREA_DATA_PROTECTED(data, RW)                      \\\n    ASSERT_OWN_##RW##_LOCK((data == shared_data &&                 \\\n                            !INTERNAL_OPTION(single_thread_in_DR)), \\\n                           &shared_data->areas.lock)\n\n/* FIXME: find a way to assert that an area by itself is synchronized if\n * it points into a vector for the routines that take in only areas\n */\n#ifdef DEBUG\n# define ASSERT_VMAREA_VECTOR_PROTECTED(v, RW) do {                    \\\n    ASSERT_OWN_##RW##_LOCK(SHOULD_LOCK_VECTOR(v) &&                    \\\n                           !dynamo_exited, &(v)->lock);                \\\n    if ((v) == dynamo_areas) {                                         \\\n        ASSERT(dynamo_areas_uptodate || dynamo_areas_synching);        \\\n    }                                                                  \\\n} while (0);\n#else\n# define ASSERT_VMAREA_VECTOR_PROTECTED(v, RW) /* nothing */\n#endif\n\n/* size of security violation string - must be at least 16 */\n#define MAXIMUM_VIOLATION_NAME_LENGTH 16\n\n#define VMVECTOR_INITIALIZE_VECTOR(v, flags, lockname) do {    \\\n        vmvector_init_vector((v), (flags));            \\\n        ASSIGN_INIT_READWRITE_LOCK_FREE((v)->lock, lockname); \\\n    } while (0);\n\n/* forward declarations */\nstatic void\nvmvector_free_vector(dcontext_t *dcontext, vm_area_vector_t *v);\n\nstatic void\nvm_area_clean_fraglist(dcontext_t *dcontext, vm_area_t *area);\nstatic bool\nlookup_addr(vm_area_vector_t *v, app_pc addr, vm_area_t **area);\n#if defined(DEBUG) && defined(INTERNAL)\nstatic void\nprint_fraglist(dcontext_t *dcontext, vm_area_t *area, const char *prefix);\nstatic void\nprint_written_areas(file_t outf);\n#endif\n#ifdef DEBUG\nstatic void\nexec_area_bounds_match(dcontext_t *dcontext, thread_data_t *data);\n#endif\n\nstatic void\nupdate_dynamo_vm_areas(bool have_writelock);\nstatic void\ndynamo_vm_areas_start_reading(void);\nstatic void\ndynamo_vm_areas_done_reading(void);\n\n#ifdef PROGRAM_SHEPHERDING\nstatic bool\nremove_futureexec_vm_area(app_pc start, app_pc end);\n\nDECLARE_CXTSWPROT_VAR(static mutex_t threads_killed_lock,\n                      INIT_LOCK_FREE(threads_killed_lock));\nvoid\nmark_unload_future_added(app_pc module_base, size_t size);\n#endif\n\nstatic void\nvm_area_coarse_region_freeze(dcontext_t *dcontext, coarse_info_t *info,\n                             vm_area_t *area, bool in_place);\n\n#ifdef SIMULATE_ATTACK\n/* synch simulate_at string parsing */\nDECLARE_CXTSWPROT_VAR(static mutex_t simulate_lock, INIT_LOCK_FREE(simulate_lock));\n#endif\n\n/* used to determine when we need to do another heap walk to keep\n * dynamo vm areas up to date (can't do it incrementally b/c of\n * circular dependencies).\n * protected for both read and write by dynamo_areas->lock\n */\n/* Case 3045: areas inside the vmheap reservation are not added to the list,\n * so the vector is considered uptodate until we run out of reservation\n */\nDECLARE_FREQPROT_VAR(static bool dynamo_areas_uptodate, true);\n\n#ifdef DEBUG\n/* used for debugging to tell when uptodate can be false.\n * protected for both read and write by dynamo_areas->lock\n */\nDECLARE_FREQPROT_VAR(static bool dynamo_areas_synching, false);\n#endif\n\n/* HACK to make dynamo_areas->lock recursive\n * protected for both read and write by dynamo_areas->lock\n * FIXME: provide general rwlock w/ write portion recursive\n */\nDECLARE_CXTSWPROT_VAR(uint dynamo_areas_recursion, 0);\n\n/* used for DR area debugging */\nbool vm_areas_exited = false;\n\n/***************************************************\n * flushing by walking entire hashtable is too slow, so we keep a list of\n * all fragments in each region.\n * to save memory, we use the fragment_t struct as the linked list entry\n * for these lists.  However, some fragments are on multiple lists due to\n * crossing boundaries (usually traces).  For those, the other entries are\n * pointed to by an \"also\" field, and the entries themselves use this struct,\n * which plays games (similar to fcache's empty_slot_t) to be able to be used\n * like a fragment_t struct in the lists.\n *\n * this is better than the old fragment_t->app_{min,max}_pc performance wise,\n * and granularity-wise for blocks that bounce over regions, but worse\n * granularity-wise since if want to flush singe page in text\n * section, will end up flushing entire region.  especially scary in face of\n * merges of adjacent regions, but merges are rare for images since\n * they usually have more than just text, so texts aren't adjacent.\n *\n * FIXME: better way, now that fcache supports multiple units, is to have\n * a separate unit for each source vmarea.  common case will be a flush to\n * an un-merged or clipped area, so just toss whole unit.\n */\ntypedef struct _multi_entry_t {\n    fragment_t *f; /* backpointer */\n    /* flags MUST be at same location as fragment_t->flags\n     * we set flags==FRAG_IS_EXTRA_VMAREA to indicate a multi_entry_t\n     * we also use FRAG_SHARED to indicate that a multi_entry_t is on global heap\n     */\n    uint      flags;\n    /* officially all list entries are fragment_t *, really some are multi_entry_t */\n    fragment_t *next_vmarea;\n    fragment_t *prev_vmarea;\n    fragment_t *also_vmarea; /* if in multiple areas */\n    /* need to be able to look up vmarea: area not stored since vmareas\n     * shift and merge, so we store original pc */\n    app_pc pc;\n} multi_entry_t;\n\n/* macros to make dealing with both fragment_t and multi_entry_t easier */\n#define FRAG_MULTI(f) (TEST(FRAG_IS_EXTRA_VMAREA, (f)->flags))\n\n#define FRAG_MULTI_INIT(f) (TESTALL((FRAG_IS_EXTRA_VMAREA|FRAG_IS_EXTRA_VMAREA_INIT), (f)->flags))\n\n#define FRAG_NEXT(f) ((TEST(FRAG_IS_EXTRA_VMAREA, (f)->flags)) ? \\\n    ((multi_entry_t *)(f))->next_vmarea : (f)->next_vmarea)\n\n#define FRAG_NEXT_ASSIGN(f, val) do { \\\n    if (TEST(FRAG_IS_EXTRA_VMAREA, (f)->flags)) \\\n        ((multi_entry_t *)(f))->next_vmarea = (val); \\\n    else \\\n        (f)->next_vmarea = (val); \\\n} while (0)\n\n#define FRAG_PREV(f) ((TEST(FRAG_IS_EXTRA_VMAREA, (f)->flags)) ? \\\n    ((multi_entry_t *)(f))->prev_vmarea : (f)->prev_vmarea)\n\n#define FRAG_PREV_ASSIGN(f, val) do { \\\n    if (TEST(FRAG_IS_EXTRA_VMAREA, (f)->flags)) \\\n        ((multi_entry_t *)(f))->prev_vmarea = (val); \\\n    else \\\n        (f)->prev_vmarea = (val); \\\n} while (0)\n\n/* Case 8419: also_vmarea is invalid once we 1st-stage-delete a fragment */\n#define FRAG_ALSO(f) ((TEST(FRAG_IS_EXTRA_VMAREA, (f)->flags)) ? \\\n    ((multi_entry_t *)(f))->also_vmarea : \\\n    (ASSERT(!TEST(FRAG_WAS_DELETED, (f)->flags)), (f)->also.also_vmarea))\n/* Only call this one to avoid the assert when you know it's safe */\n#define FRAG_ALSO_DEL_OK(f) ((TEST(FRAG_IS_EXTRA_VMAREA, (f)->flags)) ? \\\n    ((multi_entry_t *)(f))->also_vmarea : (f)->also.also_vmarea)\n\n#define FRAG_ALSO_ASSIGN(f, val) do { \\\n    if (TEST(FRAG_IS_EXTRA_VMAREA, (f)->flags)) \\\n        ((multi_entry_t *)(f))->also_vmarea = (val); \\\n    else { \\\n        ASSERT(!TEST(FRAG_WAS_DELETED, (f)->flags)); \\\n        (f)->also.also_vmarea = (val); \\\n    } \\\n} while (0)\n\n/* assumption: if multiple units, fragment_t is on list of region owning tag */\n#define FRAG_PC(f) ((TEST(FRAG_IS_EXTRA_VMAREA, (f)->flags)) ? \\\n    ((multi_entry_t *)(f))->pc : (f)->tag)\n\n#define FRAG_PC_ASSIGN(f, val) do { \\\n    if (TEST(FRAG_IS_EXTRA_VMAREA, (f)->flags)) \\\n        ((multi_entry_t *)(f))->pc = (val); \\\n    else \\\n        ASSERT_NOT_REACHED(); \\\n} while (0)\n\n#define FRAG_FRAG(fr) ((TEST(FRAG_IS_EXTRA_VMAREA, (fr)->flags)) ? \\\n    ((multi_entry_t *)(fr))->f : (fr))\n\n#define FRAG_FRAG_ASSIGN(fr, val) do { \\\n    if (TEST(FRAG_IS_EXTRA_VMAREA, (fr)->flags)) \\\n        ((multi_entry_t *)(fr))->f = (val); \\\n    else \\\n        ASSERT_NOT_REACHED(); \\\n} while (0)\n\n#define FRAG_ID(fr) ((TEST(FRAG_IS_EXTRA_VMAREA, (fr)->flags)) ? \\\n    ((multi_entry_t *)(fr))->f->id : (fr)->id)\n\n/***************************************************/\n\n/* FIXME : is problematic to page align subpage regions */\nstatic void\nvm_make_writable(byte *pc, size_t size)\n{\n    byte *start_pc = (byte *)ALIGN_BACKWARD(pc, PAGE_SIZE);\n    size_t final_size = ALIGN_FORWARD(size + (pc - start_pc), PAGE_SIZE);\n    DEBUG_DECLARE(bool ok = )\n        make_writable(start_pc, final_size);\n    ASSERT(ok);\n    ASSERT(INTERNAL_OPTION(hw_cache_consistency));\n}\n\nstatic void\nvm_make_unwritable(byte *pc, size_t size)\n{\n    byte *start_pc = (byte *)ALIGN_BACKWARD(pc, PAGE_SIZE);\n    size_t final_size = ALIGN_FORWARD(size + (pc - start_pc), PAGE_SIZE);\n    ASSERT(INTERNAL_OPTION(hw_cache_consistency));\n    make_unwritable(start_pc, final_size);\n\n    /* case 8308: We should never call vm_make_unwritable if\n     * -sandbox_writable is on, or if -sandbox_non_text is on and this\n     * is a non-text region.\n     */\n    ASSERT(!DYNAMO_OPTION(sandbox_writable));\n    DOCHECK(1, {\n        if (DYNAMO_OPTION(sandbox_non_text)) {\n            app_pc modbase = get_module_base(pc);\n            ASSERT(modbase != NULL && is_range_in_code_section(modbase, pc,\n                                                               pc + size,\n                                                               NULL, NULL));\n        }\n    });\n}\n\n/* since dynamorio changes some readwrite memory regions to read only,\n * this changes all regions memory permissions back to what they should be,\n * since dynamorio uses this mechanism to ensure code cache coherency,\n * once this method is called stale code could be executed out of the\n * code cache */\nvoid\nrevert_memory_regions()\n{\n    int i;\n\n    /* executable_areas doesn't exist in thin_client mode. */\n    ASSERT(!DYNAMO_OPTION(thin_client));\n\n    read_lock(&executable_areas->lock);\n    for (i = 0; i < executable_areas->length; i++) {\n        if (DR_MADE_READONLY(executable_areas->buf[i].vm_flags)) {\n            /* this is a region that dynamorio has marked read only, fix */\n            LOG(GLOBAL, LOG_VMAREAS, 1,\n                \" fixing permissions for RW executable area \"PFX\"-\"PFX\" %s\\n\",\n                executable_areas->buf[i].start, executable_areas->buf[i].end,\n                executable_areas->buf[i].comment);\n            vm_make_writable(executable_areas->buf[i].start,\n                             executable_areas->buf[i].end -\n                             executable_areas->buf[i].start);\n        }\n    }\n    read_unlock(&executable_areas->lock);\n}\n\nstatic void\nprint_vm_flags(uint vm_flags, uint frag_flags, file_t outf)\n{\n    print_file(outf, \" %s%s%s%s\",\n               (vm_flags & VM_WRITABLE) != 0 ? \"W\" : \"-\",\n               (vm_flags & VM_WAS_FUTURE) != 0 ? \"F\" : \"-\",\n               (frag_flags & FRAG_SELFMOD_SANDBOXED) != 0 ? \"S\" : \"-\",\n               TEST(FRAG_COARSE_GRAIN, frag_flags) ? \"C\" : \"-\");\n#ifdef PROGRAM_SHEPHERDING\n    print_file(outf, \"%s%s\",\n               TEST(VM_PATTERN_REVERIFY, vm_flags) ? \"P\" : \"-\",\n               (frag_flags & FRAG_DYNGEN) != 0 ? \"D\" : \"-\");\n#endif\n}\n\n/* ok to pass NULL for v, only used to identify use of custom field */\nstatic void\nprint_vm_area(vm_area_vector_t *v, vm_area_t *area, file_t outf, const char *prefix)\n{\n    print_file(outf, \"%s\"PFX\"-\"PFX, prefix, area->start, area->end);\n    print_vm_flags(area->vm_flags, area->frag_flags, outf);\n    if (v == executable_areas && TEST(FRAG_COARSE_GRAIN, area->frag_flags)) {\n        coarse_info_t *info = (coarse_info_t *) area->custom.client;\n        if (info != NULL) {\n            if (info->persisted)\n                print_file(outf, \"R\");\n            else if (info->frozen)\n                print_file(outf, \"Z\");\n            else\n                print_file(outf, \"-\");\n        }\n    }\n#ifdef DEBUG\n    print_file(outf, \" %s\", area->comment);\n    DOLOG(1, LOG_VMAREAS, {\n        IF_NO_MEMQUERY(extern vm_area_vector_t *all_memory_areas;)\n        app_pc modbase =\n            /* avoid rank order violation */\n            IF_NO_MEMQUERY(v == all_memory_areas ? NULL :)\n            /* i#1649: avoid rank order for dynamo_areas */\n            (v == dynamo_areas ? NULL : get_module_base(area->start));\n        if (modbase != NULL &&\n            /* avoid rank order violations */\n            v != dynamo_areas &&\n            v != written_areas &&\n            /* we free module list before vmareas */\n            !dynamo_exited_and_cleaned &&\n            is_mapped_as_image(modbase)/*avoid asserts in getting name */) {\n            const char *name;\n            os_get_module_info_lock();\n            os_get_module_name(modbase, &name);\n            print_file(outf, \" %s\", name == NULL ? \"\" : name);\n            os_get_module_info_unlock();\n        }\n    });\n#endif\n    if (v == written_areas) {\n        ro_vs_sandbox_data_t *ro2s = (ro_vs_sandbox_data_t *) area->custom.client;\n#ifdef DEBUG\n        if (ro2s != NULL) { /* can be null if in middle of adding */\n            uint tot_w = ro2s->ro2s_xfers * DYNAMO_OPTION(ro2sandbox_threshold);\n            uint tot_s = ro2s->s2ro_xfers * DYNAMO_OPTION(sandbox2ro_threshold);\n            print_file(outf, \" w %3d, %3d tot; x %3d, %5d tot; ro2s %d, s2ro %d\",\n                       ro2s->written_count, tot_w, ro2s->selfmod_execs, tot_s,\n                       ro2s->ro2s_xfers, ro2s->s2ro_xfers);\n        }\n#else\n        print_file(outf, \" written %3d, exec %5d\",\n                   ro2s->written_count, ro2s->selfmod_execs);\n#endif\n    }\n    print_file(outf, \"\\n\");\n}\n\n/* Assumes caller holds v->lock for coherency */\nstatic void\nprint_vm_areas(vm_area_vector_t *v, file_t outf)\n{\n    int i;\n    ASSERT_VMAREA_VECTOR_PROTECTED(v, READWRITE);\n    for(i = 0; i < v->length; i++) {\n        print_vm_area(v, &v->buf[i], outf, \"  \");\n    }\n}\n\n#if defined(DEBUG) && defined(INTERNAL)\nstatic void\nprint_contig_vm_areas(vm_area_vector_t *v, app_pc start, app_pc end, file_t outf,\n                      const char *prefix)\n{\n    vm_area_t *new_area;\n    app_pc pc = start;\n    do {\n        lookup_addr(v, pc, &new_area);\n        if (new_area == NULL)\n            break;\n        print_vm_area(v, new_area, outf, prefix);\n        pc = new_area->end + 1;\n    } while (new_area->end < end);\n}\n#endif\n\n#if defined(DEBUG) && defined(INTERNAL)\nstatic void\nprint_pending_list(file_t outf)\n{\n    pending_delete_t *pend;\n    int i;\n    ASSERT_OWN_MUTEX(true, &shared_delete_lock);\n    for (i = 0, pend = todelete->shared_delete; pend != NULL; i++, pend = pend->next) {\n        print_file(outf, \"%d: \"PFX\"-\"PFX\" ref=%d, stamp=%d\\n\",\n                   i, pend->start, pend->end, pend->ref_count, pend->flushtime_deleted);\n    }\n}\n#endif\n\n/* If v requires a lock and the calling thread does not hold that lock,\n * this routine acquires the lock and returns true; else it returns false.\n */\nstatic bool\nwritelock_if_not_already(vm_area_vector_t *v)\n{\n    if (TEST(VECTOR_SHARED, v->flags) && !self_owns_write_lock(&v->lock)) {\n        SHARED_VECTOR_RWLOCK(v, write, lock);\n        return true;\n    }\n    return false;\n}\n\nstatic void\nvm_area_vector_check_size(vm_area_vector_t *v)\n{\n    /* only called by add_vm_area which does the assert that the vector is\n     * protected */\n    /* check if at capacity */\n    if (v->size == v->length){\n        if (v->length == 0) {\n            v->size = INTERNAL_OPTION(vmarea_initial_size);\n            v->buf = (vm_area_t*) global_heap_alloc(v->size*sizeof(struct vm_area_t)\n                                                  HEAPACCT(ACCT_VMAREAS));\n        }\n        else {\n            /* FIXME: case 4471 we should be doubling size here */\n            int new_size = (INTERNAL_OPTION(vmarea_increment_size) + v->length);\n            STATS_INC(num_vmareas_resized);\n            v->buf = global_heap_realloc(v->buf, v->size, new_size,\n                                         sizeof(struct vm_area_t)\n                                         HEAPACCT(ACCT_VMAREAS));\n            v->size = new_size;\n        }\n        ASSERT(v->buf != NULL);\n    }\n}\n\nstatic void\nvm_area_merge_fraglists(vm_area_t *dst, vm_area_t *src)\n{\n    /* caller must hold write lock for vector of course: FIXME: assert that here */\n    LOG(THREAD_GET, LOG_VMAREAS, 2,\n        \"\\tmerging frag lists for \"PFX\"-\"PFX\" and \"PFX\"-\"PFX\"\\n\",\n        src->start, src->end, dst->start, dst->end);\n    if (dst->custom.frags == NULL)\n        dst->custom.frags = src->custom.frags;\n    else if (src->custom.frags == NULL)\n        return;\n    else {\n        /* put src's frags at end of dst's frags */\n        fragment_t *top1 = dst->custom.frags;\n        fragment_t *top2 = src->custom.frags;\n        fragment_t *tmp = FRAG_PREV(top1);\n        FRAG_NEXT_ASSIGN(tmp, top2);\n        FRAG_PREV_ASSIGN(top1, FRAG_PREV(top2));\n        FRAG_PREV_ASSIGN(top2, tmp);\n        DOLOG(4, LOG_VMAREAS, {\n            print_fraglist(get_thread_private_dcontext(),\n                           dst, \"after merging fraglists:\");\n        });\n    }\n}\n\n/* Assumes caller holds v->lock, if necessary.\n * Does not return the area added since it may be merged or split depending\n * on existing areas->\n * If a last_area points into this vector, the caller must make sure to\n *   clear or update the last_area pointer.\n *   FIXME: make it easier to keep them in synch -- too easy to add_vm_area\n *   somewhere to a thread vector and forget to clear last_area.\n * Adds a new area to v, merging it with adjacent areas of the same type.\n * A new area is only allowed to overlap an old area of a different type if it\n *   meets certain criteria (see asserts below).  For VM_WAS_FUTURE and\n *   VM_ONCE_ONLY we may clear the flag from an existing region if the new\n *   region doesn't have the flag and overlaps the existing region.  Otherwise\n *   the new area is split such that the overlapping portion remains part of\n *   the old area.  This tries to keep entire new area from becoming selfmod\n *   for instance. FIXME : for VM_WAS_FUTURE and VM_ONCE_ONLY may want to split\n *   region if only paritally overlapping\n *\n * FIXME: change add_vm_area to return NULL when merged, and otherwise\n * return the new complete area, so callers don't have to do a separate lookup\n * to access the added area.\n */\nstatic void\nadd_vm_area(vm_area_vector_t *v, app_pc start, app_pc end,\n            uint vm_flags, uint frag_flags, void *data _IF_DEBUG(const char *comment))\n{\n    int i, j, diff;\n    /* if we have overlap, we extend an existing area -- else we add a new area */\n    int overlap_start = -1, overlap_end = -1;\n    DEBUG_DECLARE(uint flagignore;)\n    IF_UNIX(IF_DEBUG(IF_NO_MEMQUERY(extern vm_area_vector_t *all_memory_areas;)))\n\n    ASSERT(start < end);\n\n    ASSERT_VMAREA_VECTOR_PROTECTED(v, WRITE);\n    LOG(GLOBAL, LOG_VMAREAS, 4, \"in add_vm_area%s \"PFX\" \"PFX\" %s\\n\",\n        (v == executable_areas ? \" executable_areas\" :\n         (v == IF_LINUX_ELSE(all_memory_areas, NULL) ? \" all_memory_areas\" :\n          (v == dynamo_areas ? \" dynamo_areas\" : \"\"))), start, end, comment);\n    /* N.B.: new area could span multiple existing areas! */\n    for (i = 0; i < v->length; i++) {\n        /* look for overlap, or adjacency of same type (including all flags, and never\n         * merge adjacent if keeping write counts)\n         */\n        if ((start < v->buf[i].end && end > v->buf[i].start) ||\n            (start <= v->buf[i].end && end >= v->buf[i].start &&\n             vm_flags == v->buf[i].vm_flags &&\n             frag_flags == v->buf[i].frag_flags &&\n             /* never merge coarse-grain */\n             !TEST(FRAG_COARSE_GRAIN, v->buf[i].frag_flags) &&\n             !TEST(VECTOR_NEVER_MERGE_ADJACENT, v->flags) &&\n             (v->should_merge_func == NULL ||\n              v->should_merge_func(true/*adjacent*/, data, v->buf[i].custom.client)))) {\n            ASSERT(!(start < v->buf[i].end && end > v->buf[i].start) ||\n                   !TEST(VECTOR_NEVER_OVERLAP, v->flags));\n            if (overlap_start == -1) {\n                /* assume we'll simply expand an existing area rather than\n                 * add a new one -- we'll reset this if we hit merge conflicts */\n                overlap_start = i;\n            }\n            /* overlapping regions of different properties are often\n             * problematic so we add a lot of debugging output\n             */\n            DOLOG(4, LOG_VMAREAS, {\n                LOG(GLOBAL, LOG_VMAREAS, 1,\n                    \"==================================================\\n\"\n                    \"add_vm_area \"PFX\"-\"PFX\" %s %x-%x overlaps \"PFX\"-\"PFX\" %s %x-%x\\n\",\n                    start, end, comment, vm_flags, frag_flags,\n                    v->buf[i].start, v->buf[i].end,\n                    v->buf[i].comment, v->buf[i].vm_flags, v->buf[i].frag_flags);\n                print_vm_areas(v, GLOBAL);\n                /* rank order problem if holding heap_unit_lock, so only print\n                 * if not holding a lock for v right now, though ok to print\n                 * for shared vm areas since its lock is higher than the lock\n                 * for executable/written areas\n                 */\n                if (v != dynamo_areas &&\n                    (!TEST(VECTOR_SHARED, v->flags) || v == &shared_data->areas)) {\n                    LOG(GLOBAL, LOG_VMAREAS, 1, \"\\nexecutable areas:\\n\");\n                    print_executable_areas(GLOBAL);\n                    LOG(GLOBAL, LOG_VMAREAS, 1, \"\\nwritten areas:\\n\");\n                    print_written_areas(GLOBAL);\n                }\n                LOG(GLOBAL, LOG_VMAREAS, 1,\n                    \"==================================================\\n\\n\");\n            });\n\n            /* we have some restrictions on overlapping regions with\n             * different flags */\n\n            /* no restrictions on WAS_FUTURE flag, but if new region is\n             * not was future and old region is then should drop from old\n             * region FIXME : partial overlap? we don't really care about\n             * this flag anyways */\n            if (TEST(VM_WAS_FUTURE, v->buf[i].vm_flags) &&\n                !TEST(VM_WAS_FUTURE, vm_flags)) {\n                v->buf[i].vm_flags &= ~VM_WAS_FUTURE;\n                LOG(GLOBAL, LOG_VMAREAS, 1,\n                    \"Warning : removing was_future flag from area \"PFX\n                    \"-\"PFX\" %s that overlaps new area \"PFX\"-\"PFX\" %s\\n\",\n                     v->buf[i].start, v->buf[i].end, v->buf[i].comment,\n                    start, end, comment);\n            }\n            /* no restrictions on ONCE_ONLY flag, but if new region is not\n             * should drop fom existing region FIXME : partial overlap? is\n             * not much of an additional security risk */\n            if (TEST(VM_ONCE_ONLY, v->buf[i].vm_flags) &&\n                !TEST(VM_ONCE_ONLY, vm_flags)) {\n                v->buf[i].vm_flags &= ~VM_ONCE_ONLY;\n                LOG(GLOBAL, LOG_VMAREAS, 1,\n                    \"Warning : removing once_only flag from area \"PFX\n                    \"-\"PFX\" %s that overlaps new area \"PFX\"-\"PFX\" %s\\n\",\n                     v->buf[i].start, v->buf[i].end, v->buf[i].comment,\n                    start, end, comment);\n            }\n            /* shouldn't be adding unmod image over existing not unmod image,\n             * reverse could happen with os region merging though */\n            ASSERT(TEST(VM_UNMOD_IMAGE, v->buf[i].vm_flags) ||\n                   !TEST(VM_UNMOD_IMAGE, vm_flags));\n            /* for VM_WRITABLE only allow new region to not be writable and\n             * existing region to be writable to handle cases of os region\n             * merging due to our consistency protection changes */\n            ASSERT(TEST(VM_WRITABLE, v->buf[i].vm_flags) ||\n                   !TEST(VM_WRITABLE, vm_flags) ||\n                   !INTERNAL_OPTION(hw_cache_consistency));\n            /* FIXME: case 7877: if new is VM_MADE_READONLY and old is not, we\n             * must mark old overlapping portion as VM_MADE_READONLY.  Things only\n             * worked now b/c VM_MADE_READONLY==VM_WRITABLE, so we can add\n             * pageprot regions that overlap w/ selfmod.\n             */\n#ifdef PROGRAM_SHEPHERDING\n            /* !VM_PATTERN_REVERIFY trumps having the flag on, so for new having\n             * the flag and old not, we're fine, but when old has it we'd like\n             * to remove it from the overlap portion: FIXME: need better merging\n             * control, also see all the partial overlap fixmes above.\n             * for this flag not a big deal, just a possible perf hit as we\n             * re-check every time.\n             */\n#endif\n            /* disallow any other vm_flag differences */\n            DODEBUG({ flagignore = VM_UNMOD_IMAGE | VM_WAS_FUTURE |\n                          VM_ONCE_ONLY | VM_WRITABLE; });\n#ifdef PROGRAM_SHEPHERDING\n            DODEBUG({ flagignore = flagignore | VM_PATTERN_REVERIFY; });\n#endif\n            ASSERT((v->buf[i].vm_flags & ~flagignore) == (vm_flags & ~flagignore));\n\n            /* new region must be more innocent with respect to selfmod */\n            ASSERT(TEST(FRAG_SELFMOD_SANDBOXED, v->buf[i].frag_flags) ||\n                   !TEST(FRAG_SELFMOD_SANDBOXED, frag_flags));\n            /* disallow other frag_flag differences */\n#ifndef PROGRAM_SHEPHERDING\n            ASSERT((v->buf[i].frag_flags & ~FRAG_SELFMOD_SANDBOXED) ==\n                   (frag_flags & ~FRAG_SELFMOD_SANDBOXED));\n#else\n# ifdef DGC_DIAGNOSTICS\n            /* FIXME : no restrictions on differing FRAG_DYNGEN_RESTRICTED\n             * flags? */\n            ASSERT((v->buf[i].frag_flags &\n                    ~(FRAG_SELFMOD_SANDBOXED|FRAG_DYNGEN|FRAG_DYNGEN_RESTRICTED)) ==\n                   (frag_flags &\n                    ~(FRAG_SELFMOD_SANDBOXED|FRAG_DYNGEN|FRAG_DYNGEN_RESTRICTED)));\n# else\n            ASSERT((v->buf[i].frag_flags &\n                    ~(FRAG_SELFMOD_SANDBOXED|FRAG_DYNGEN)) ==\n                   (frag_flags &\n                    ~(FRAG_SELFMOD_SANDBOXED|FRAG_DYNGEN)));\n# endif\n            /* shouldn't add non-dyngen overlapping existing dyngen, FIXME\n             * is the reverse possible? right now we allow it */\n            ASSERT(TEST(FRAG_DYNGEN, frag_flags) ||\n                   !TEST(FRAG_DYNGEN, v->buf[i].frag_flags));\n#endif\n            /* Never split FRAG_COARSE_GRAIN */\n            ASSERT(TEST(FRAG_COARSE_GRAIN, frag_flags) ||\n                   !TEST(FRAG_COARSE_GRAIN, v->buf[i].frag_flags));\n\n            /* for overlapping region: must overlap same type -- else split */\n            if ((vm_flags != v->buf[i].vm_flags || frag_flags != v->buf[i].frag_flags) &&\n                (v->should_merge_func == NULL ||\n                 !v->should_merge_func(false/*not adjacent*/,\n                                       data, v->buf[i].custom.client))) {\n                LOG(GLOBAL, LOG_VMAREAS, 1,\n                    \"add_vm_area \"PFX\"-\"PFX\" %s vm_flags=0x%08x \"\n                    \"frag_flags=0x%08x\\n  overlaps diff type \"PFX\"-\"PFX\" %s\"\n                    \"vm_flags=0x%08x frag_flags=0x%08x\\n  in vect at \"PFX\"\\n\",\n                    start, end, comment, vm_flags, frag_flags,\n                    v->buf[i].start, v->buf[i].end, v->buf[i].comment,\n                    v->buf[i].vm_flags, v->buf[i].frag_flags, v);\n                LOG(GLOBAL, LOG_VMAREAS, 3,\n                    \"before splitting b/c adding \"PFX\"-\"PFX\":\\n\",\n                    start, end);\n                DOLOG(3, LOG_VMAREAS, { print_vm_areas(v, GLOBAL); });\n\n                /* split off the overlapping part from the new region\n                 * reasoning: old regions get marked selfmod, then see new code,\n                 * its region overlaps old selfmod -- don't make new all selfmod,\n                 * split off the part that hasn't been proved selfmod yet.\n                 * since we never split the old region, we don't need to worry\n                 * about splitting its frags list.\n                 */\n                if (start < v->buf[i].start) {\n                    if (end > v->buf[i].end) {\n                        void *add_data = data;\n                        /* need two areas, one for either side */\n                        LOG(GLOBAL, LOG_VMAREAS, 3,\n                            \"=> will add \"PFX\"-\"PFX\" after i\\n\", v->buf[i].end, end);\n                        /* safe to recurse here, new area will be after the area\n                         * we are currently looking at in the vector */\n                        if (v->split_payload_func != NULL)\n                            add_data = v->split_payload_func(data);\n                        add_vm_area(v, v->buf[i].end, end, vm_flags, frag_flags,\n                                    add_data _IF_DEBUG(comment));\n                    }\n                    /* if had been merging, let this routine finish that off -- else,\n                     * need to add a new area\n                     */\n                    end = v->buf[i].start;\n                    if (overlap_start == i) {\n                        /* no merging */\n                        overlap_start = -1;\n                    }\n                    LOG(GLOBAL, LOG_VMAREAS, 3,\n                        \"=> will add/merge \"PFX\"-\"PFX\" before i\\n\", start, end);\n                    overlap_end = i;\n                    break;\n                } else if (end > v->buf[i].end) {\n                    /* shift area of consideration to end of i, and keep going,\n                     * can't act now since don't know areas overlapping beyond i\n                     */\n                    LOG(GLOBAL, LOG_VMAREAS, 3,\n                        \"=> ignoring \"PFX\"-\"PFX\", only adding \"PFX\"-\"PFX\"\\n\",\n                        start, v->buf[i].end, v->buf[i].end, end);\n                    start = v->buf[i].end;\n                    /* reset overlap vars */\n                    ASSERT(overlap_start <= i);\n                    overlap_start = -1;\n                } else {\n                    /* completely inside -- ok, we'll leave it that way and won't split */\n                    LOG(GLOBAL, LOG_VMAREAS, 3,\n                        \"=> ignoring \"PFX\"-\"PFX\", forcing to be part of \"PFX\"-\"PFX\"\\n\",\n                        start, end, v->buf[i].start, v->buf[i].end);\n                }\n                ASSERT(end > start);\n            }\n        } else if (overlap_start > -1) {\n            overlap_end = i; /* not inclusive */\n            break;\n        } else if (end <= v->buf[i].start)\n            break;\n    }\n\n    if (overlap_start == -1) {\n        /* brand-new area, goes before v->buf[i] */\n        struct vm_area_t new_area = {start, end, vm_flags, frag_flags, /* rest 0 */};\n#ifdef DEBUG\n        /* get comment */\n        size_t len = strlen(comment);\n        ASSERT(len < 1024);\n        new_area.comment = (char *) global_heap_alloc(len+1 HEAPACCT(ACCT_VMAREAS));\n        strncpy(new_area.comment, comment, len);\n        new_area.comment[len]  = '\\0'; /* if max no null */\n#endif\n        new_area.custom.client = data;\n        LOG(GLOBAL, LOG_VMAREAS, 3, \"=> adding \"PFX\"-\"PFX\"\\n\", start, end);\n        vm_area_vector_check_size(v);\n        /* shift subsequent entries */\n        for (j = v->length; j > i; j--)\n            v->buf[j] = v->buf[j-1];\n        v->buf[i] = new_area;\n        /* assumption: no overlaps between areas in list! */\n#ifdef DEBUG\n        if (!((i == 0 || v->buf[i-1].end <= v->buf[i].start) &&\n              (i == v->length || v->buf[i].end <= v->buf[i+1].start))) {\n            LOG(GLOBAL, LOG_VMAREAS, 1,\n                \"ERROR: add_vm_area illegal overlap \"PFX\" \"PFX\" %s\\n\", start, end, comment);\n            print_vm_areas(v, GLOBAL);\n        }\n#endif\n        ASSERT((i == 0 || v->buf[i-1].end <= v->buf[i].start) &&\n               (i == v->length || v->buf[i].end <= v->buf[i+1].start));\n        v->length++;\n        STATS_TRACK_MAX(max_vmareas_length, v->length);\n        DOSTATS({\n            if (v == dynamo_areas)\n                STATS_TRACK_MAX(max_DRareas_length, v->length);\n            else if (v == executable_areas)\n                STATS_TRACK_MAX(max_execareas_length, v->length);\n        });\n#ifdef WINDOWS\n        DOSTATS({\n            extern vm_area_vector_t *loaded_module_areas;\n            if (v == loaded_module_areas)\n                STATS_TRACK_MAX(max_modareas_length, v->length);\n        });\n#endif\n    } else {\n        /* overlaps one or more areas, modify first to equal entire range,\n         * delete rest\n         */\n        if (overlap_end == -1)\n            overlap_end = v->length;\n        LOG(GLOBAL, LOG_VMAREAS, 3, \"=> changing \"PFX\"-\"PFX,\n            v->buf[overlap_start].start, v->buf[overlap_start].end);\n        if (start < v->buf[overlap_start].start)\n            v->buf[overlap_start].start = start;\n        if (end > v->buf[overlap_end-1].end)\n            v->buf[overlap_start].end = end;\n        else\n            v->buf[overlap_start].end = v->buf[overlap_end-1].end;\n        if (v->merge_payload_func != NULL) {\n            v->buf[overlap_start].custom.client =\n                v->merge_payload_func(data, v->buf[overlap_start].custom.client);\n        } else if (v->free_payload_func != NULL) {\n            /* if a merge exists we assume it will free if necessary */\n            v->free_payload_func(v->buf[overlap_start].custom.client);\n        }\n        LOG(GLOBAL, LOG_VMAREAS, 3, \" to \"PFX\"-\"PFX\"\\n\",\n            v->buf[overlap_start].start, v->buf[overlap_start].end);\n        /* when merge, use which comment?  could combine them all\n         * FIXME\n         */\n        /* now delete */\n        for (i = overlap_start+1; i < overlap_end; i++) {\n            LOG(GLOBAL, LOG_VMAREAS, 3, \"=> completely removing \"PFX\"-\"PFX\" %s\\n\",\n                v->buf[i].start, v->buf[i].end, v->buf[i].comment);\n#ifdef DEBUG\n            global_heap_free(v->buf[i].comment, strlen(v->buf[i].comment)+1\n                             HEAPACCT(ACCT_VMAREAS));\n#endif\n            if (v->merge_payload_func != NULL) {\n                v->buf[overlap_start].custom.client =\n                    v->merge_payload_func(v->buf[overlap_start].custom.client,\n                                          v->buf[i].custom.client);\n            } else if (v->free_payload_func != NULL) {\n                /* if a merge exists we assume it will free if necessary */\n                v->free_payload_func(v->buf[i].custom.client);\n            }\n            /* merge frags lists */\n            /* FIXME: switch this to a merge_payload_func.  It won't be able\n             * to print out the bounds, and it will have to do the work of\n             * vm_area_clean_fraglist() on each merge, but we could then get\n             * rid of VECTOR_FRAGMENT_LIST.\n             */\n            if (TEST(VECTOR_FRAGMENT_LIST, v->flags) && v->buf[i].custom.frags != NULL)\n                vm_area_merge_fraglists(&v->buf[overlap_start], &v->buf[i]);\n        }\n        diff = overlap_end - (overlap_start+1);\n        for (i = overlap_start+1; i < v->length-diff; i++)\n            v->buf[i] = v->buf[i+diff];\n        v->length -= diff;\n        i = overlap_start; /* for return value */\n        if (TEST(VECTOR_FRAGMENT_LIST, v->flags) && v->buf[i].custom.frags != NULL) {\n            dcontext_t *dcontext = get_thread_private_dcontext();\n            ASSERT(dcontext != NULL);\n            /* have to remove all alsos that are now in same area as frag */\n            vm_area_clean_fraglist(dcontext, &v->buf[i]);\n        }\n    }\n    DOLOG(5, LOG_VMAREAS, { print_vm_areas(v, GLOBAL); });\n}\n\nstatic void\nadjust_coarse_unit_bounds(vm_area_t *area, bool if_invalid)\n{\n    coarse_info_t *info = (coarse_info_t *) area->custom.client;\n    ASSERT(TEST(FRAG_COARSE_GRAIN, area->frag_flags));\n    ASSERT(!RUNNING_WITHOUT_CODE_CACHE());\n    ASSERT(info != NULL);\n    if (info == NULL) /* be paranoid */\n        return;\n    /* FIXME: we'd like to grab info->lock but we have a rank order w/\n     * exec_areas lock -- so instead we rely on all-thread-synch flushing\n     * being the only reason to get here; an empty flush won't have synchall,\n     * but we won't be able to get_executable_area_coarse_info w/o the\n     * exec areas write lock so we're ok there.\n     */\n    ASSERT(dynamo_all_threads_synched ||\n           (!TEST(VM_EXECUTED_FROM, area->vm_flags) &&\n            READWRITE_LOCK_HELD(&executable_areas->lock)));\n    if (!if_invalid && TEST(PERSCACHE_CODE_INVALID, info->flags)) {\n        /* Don't change bounds of primary or secondary; we expect vm_area_t to\n         * be merged back to this size post-rebind; if not, we'll throw out this\n         * pcache at validation time due to not matching the vm_area_t.\n         */\n        return;\n    }\n    LOG(THREAD_GET, LOG_VMAREAS, 3, \"%s: \"PFX\"-\"PFX\" vs area \"PFX\"-\"PFX\"\\n\",\n        __FUNCTION__, info->base_pc, info->end_pc, area->start, area->end);\n    while (info != NULL) { /* loop over primary and secondary unit */\n        /* We should have reset this coarse info when flushing */\n        ASSERT((info->cache == NULL && !info->frozen && !info->persisted) ||\n               /* i#1652: if nothing was flushed a pcache may remain */\n               (info->base_pc == area->start &&\n                info->end_pc == area->end));\n        /* No longer covers the removed region */\n        if (info->base_pc < area->start)\n            info->base_pc = area->start;\n        if (info->end_pc > area->end)\n            info->end_pc = area->end;\n        ASSERT(info->frozen || info->non_frozen == NULL);\n        info = info->non_frozen;\n        ASSERT(info == NULL || !info->frozen);\n    }\n}\n\n/* Assumes caller holds v->lock, if necessary\n * Returns false if no area contains start..end\n * Ignores type of area -- removes all within start..end\n * Caller should probably clear last_area as well\n */\nstatic bool\nremove_vm_area(vm_area_vector_t *v, app_pc start, app_pc end, bool restore_prot)\n{\n    int i, diff;\n    int overlap_start = -1, overlap_end = -1;\n    bool add_new_area = false;\n    vm_area_t new_area = {0};     /* used only when add_new_area, wimpy compiler */\n    /* FIXME: cleaner test? shared_data copies flags, but uses\n     * custom.frags and not custom.client\n     */\n    bool official_coarse_vector = (v == executable_areas);\n\n    ASSERT_VMAREA_VECTOR_PROTECTED(v, WRITE);\n    LOG(GLOBAL, LOG_VMAREAS, 4, \"in remove_vm_area \"PFX\" \"PFX\"\\n\", start, end);\n    /* N.B.: removed area could span multiple areas! */\n    for (i = 0; i < v->length; i++) {\n        /* look for overlap */\n        if (start < v->buf[i].end && end > v->buf[i].start) {\n            if (overlap_start == -1)\n                overlap_start = i;\n        } else if (overlap_start > -1) {\n            overlap_end = i; /* not inclusive */\n            break;\n        } else if (end <= v->buf[i].start)\n            break;\n    }\n    if (overlap_start == -1)\n        return false;\n    if (overlap_end == -1)\n        overlap_end = v->length;\n    /* since it's sorted and there are no overlaps, we do not have to re-sort.\n     * we just delete entire intervals affected, and shorten non-entire\n     */\n    if (start > v->buf[overlap_start].start) {\n        /* need to split? */\n        if (overlap_start == overlap_end-1 && end < v->buf[overlap_start].end) {\n            /* don't call add_vm_area now, that will mess up our vector */\n            new_area = v->buf[overlap_start]; /* make a copy */\n            new_area.start = end;\n            /* rest of fields are correct */\n            add_new_area = true;\n        }\n        /* move ending bound backward */\n        LOG(GLOBAL, LOG_VMAREAS, 3, \"\\tchanging \"PFX\"-\"PFX\" to \"PFX\"-\"PFX\"\\n\",\n            v->buf[overlap_start].start, v->buf[overlap_start].end,\n            v->buf[overlap_start].start, start);\n        if (restore_prot && DR_MADE_READONLY(v->buf[overlap_start].vm_flags)) {\n            vm_make_writable(start, end - start);\n        }\n        v->buf[overlap_start].end = start;\n        /* FIXME: add a vmvector callback function for changing bounds? */\n        if (TEST(FRAG_COARSE_GRAIN, v->buf[overlap_start].frag_flags) &&\n            official_coarse_vector) {\n            adjust_coarse_unit_bounds(&v->buf[overlap_start], false/*leave invalid*/);\n        }\n        overlap_start++; /* don't delete me */\n    }\n    if (end < v->buf[overlap_end-1].end) {\n        /* move starting bound forward */\n        LOG(GLOBAL, LOG_VMAREAS, 3, \"\\tchanging \"PFX\"-\"PFX\" to \"PFX\"-\"PFX\"\\n\",\n            v->buf[overlap_end-1].start, v->buf[overlap_end-1].end,\n            end, v->buf[overlap_end-1].end);\n        if (restore_prot && DR_MADE_READONLY(v->buf[overlap_end-1].vm_flags)) {\n            vm_make_writable(v->buf[overlap_end-1].start, end - v->buf[overlap_end-1].start);\n        }\n        v->buf[overlap_end-1].start = end;\n        /* FIXME: add a vmvector callback function for changing bounds? */\n        if (TEST(FRAG_COARSE_GRAIN, v->buf[overlap_end-1].frag_flags) &&\n            official_coarse_vector) {\n            adjust_coarse_unit_bounds(&v->buf[overlap_end-1], false/*leave invalid*/);\n        }\n        overlap_end--; /* don't delete me */\n    }\n    /* now delete */\n    if (overlap_start < overlap_end) {\n        for (i = overlap_start; i < overlap_end; i++) {\n            LOG(GLOBAL, LOG_VMAREAS, 3, \"\\tcompletely removing \"PFX\"-\"PFX\" %s\\n\",\n                v->buf[i].start, v->buf[i].end, v->buf[i].comment);\n            if (restore_prot && DR_MADE_READONLY(v->buf[i].vm_flags)) {\n                vm_make_writable(v->buf[i].start, v->buf[i].end - v->buf[i].start);\n            }\n            /* FIXME: use a free_payload_func instead of this custom\n             * code.  But then we couldn't assert on the bounds and on\n             * VM_EXECUTED_FROM.  Could add bounds to callback params, but\n             * vm_flags are not exposed to vmvector interface...\n             */\n            if (TEST(FRAG_COARSE_GRAIN, v->buf[i].frag_flags) &&\n                official_coarse_vector) {\n                coarse_info_t *info = (coarse_info_t *) v->buf[i].custom.client;\n                coarse_info_t *next_info;\n                ASSERT(info != NULL);\n                ASSERT(!RUNNING_WITHOUT_CODE_CACHE());\n                while (info != NULL) { /* loop over primary and secondary unit */\n                    ASSERT(info->base_pc >= v->buf[i].start &&\n                           info->end_pc <= v->buf[i].end);\n                    ASSERT(info->frozen || info->non_frozen == NULL);\n                    /* Should have already freed fields, unless we flushed a region\n                     * that has not been executed from (case 10995): in which case\n                     * we must delay as we cannot grab change_linking_lock or\n                     * special_heap_lock or info->lock while holding exec_areas lock.\n                     */\n                    if (info->cache != NULL) {\n                        ASSERT(info->persisted);\n                        ASSERT(!TEST(VM_EXECUTED_FROM, v->buf[i].vm_flags));\n                        ASSERT(info->non_frozen != NULL);\n                        ASSERT(coarse_to_delete != NULL);\n                        /* Both primary and secondary must be un-executed */\n                        info->non_frozen->non_frozen = *coarse_to_delete;\n                        *coarse_to_delete = info;\n                        info = NULL;\n                    } else {\n                        ASSERT(info->cache == NULL && info->stubs == NULL);\n                        next_info = info->non_frozen;\n                        coarse_unit_free(GLOBAL_DCONTEXT, info);\n                        info = next_info;\n                        ASSERT(info == NULL || !info->frozen);\n                    }\n                }\n                v->buf[i].custom.client = NULL;\n            }\n            if (v->free_payload_func != NULL) {\n                v->free_payload_func(v->buf[i].custom.client);\n            }\n#ifdef DEBUG\n            global_heap_free(v->buf[i].comment, strlen(v->buf[i].comment)+1\n                             HEAPACCT(ACCT_VMAREAS));\n#endif\n            /* frags list should always be null here (flush should have happened,\n             * etc.) */\n            ASSERT(!TEST(VECTOR_FRAGMENT_LIST, v->flags) || v->buf[i].custom.frags == NULL);\n        }\n        diff = overlap_end - overlap_start;\n        for (i = overlap_start; i < v->length-diff; i++)\n            v->buf[i] = v->buf[i+diff];\n#ifdef DEBUG\n        memset(v->buf + v->length - diff, 0, diff * sizeof(vm_area_t));\n#endif\n        v->length -= diff;\n    }\n    if (add_new_area) {\n        /* Case 8640: Do not propagate coarse-grain-ness to split-off region,\n         * for now only for simplicity.  FIXME: come up with better policy.  We\n         * do keep it on original part of split region.  FIXME: assert that\n         * there the unit is fully flushed.  Better to remove in\n         * vm_area_allsynch_flush_fragments() and then re-add if warranted?\n         */\n        new_area.frag_flags &= ~FRAG_COARSE_GRAIN;\n        /* With flush of partial module region w/o remove (e.g., from\n         * -unsafe_ignore_IAT_writes) we can have VM_ADD_TO_SHARED_DATA set\n         */\n        new_area.vm_flags &= ~VM_ADD_TO_SHARED_DATA;\n        LOG(GLOBAL, LOG_VMAREAS, 3, \"\\tadding \"PFX\"-\"PFX\"\\n\", new_area.start, new_area.end);\n        /* we copied v->buf[overlap_start] above and so already have a copy\n         * of the client field\n         */\n        if (v->split_payload_func != NULL) {\n            new_area.custom.client = v->split_payload_func(new_area.custom.client);\n        } /* else, just keep the copy */\n        add_vm_area(v, new_area.start, new_area.end, new_area.vm_flags,\n                    new_area.frag_flags, new_area.custom.client\n                    _IF_DEBUG(new_area.comment));\n    }\n    DOLOG(5, LOG_VMAREAS, { print_vm_areas(v, GLOBAL); });\n    return true;\n}\n\n/* Returns true if start..end overlaps any area in v.\n * If end==NULL, assumes that end is very top of address space (wraparound).\n * If area!=NULL, sets *area to an overlapping area in v\n *   If index!=NULL, sets *index to the vector index of area; if no match\n *   is found, sets *index to the index before [start,end) (may be -1).\n *   If first, makes sure *area is the 1st overlapping area\n * Assumes caller holds v->lock, if necessary\n * N.B.: the pointer returned by this routine is volatile!  Only use it while\n * you have exclusive control over the vector v, either by holding its lock\n * or by being its owning thread if it has no lock.\n */\nstatic bool\nbinary_search(vm_area_vector_t *v, app_pc start, app_pc end, vm_area_t **area/*OUT*/,\n              int *index/*OUT*/, bool first)\n{\n    /* BINARY SEARCH -- assumes the vector is kept sorted by add & remove! */\n    int min = 0;\n    int max = v->length - 1;\n\n    ASSERT(start < end || end == NULL /* wraparound */);\n\n    ASSERT_VMAREA_VECTOR_PROTECTED(v, READWRITE);\n    LOG(GLOBAL, LOG_VMAREAS, 7, \"Binary search for \"PFX\"-\"PFX\" on this vector:\\n\",\n        start, end);\n    DOLOG(7, LOG_VMAREAS, { print_vm_areas(v, GLOBAL); });\n    /* binary search */\n    while (max >= min) {\n        int i = (min + max) / 2;\n        if (end != NULL && end <= v->buf[i].start)\n            max = i - 1;\n        else if (start >= v->buf[i].end)\n            min = i + 1;\n        else {\n            if (area != NULL || index != NULL) {\n                if (first) {\n                    /* caller wants 1st matching area */\n                    for (; i >= 1 && v->buf[i-1].end > start; i--)\n                        ;\n                }\n                /* returning pointer to volatile array dangerous -- see comment above */\n                if (area != NULL)\n                    *area = &(v->buf[i]);\n                if (index != NULL)\n                    *index = i;\n            }\n            LOG(GLOBAL, LOG_VMAREAS, 7, \"\\tfound \"PFX\"-\"PFX\" in area \"PFX\"-\"PFX\"\\n\",\n                start, end, v->buf[i].start, v->buf[i].end);\n            return true;\n        }\n    }\n    /* now max < min */\n    LOG(GLOBAL, LOG_VMAREAS, 7, \"\\tdid not find \"PFX\"-\"PFX\"!\\n\", start, end);\n    if (index != NULL) {\n        ASSERT((max < 0 || v->buf[max].end <= start) &&\n               (min > v->length - 1 || v->buf[min].start >= end));\n        *index = max;\n    }\n    return false;\n}\n\n/* lookup an addr in the current area\n * RETURN true if address area is found, false otherwise\n * if area is non NULL it is set to the area found\n * Assumes caller holds v->lock, if necessary\n * N.B.: the pointer returned by this routine is volatile!  Only use it while\n * you have exclusive control over the vector v, either by holding its lock\n * or by being its owning thread if it has no lock.\n */\n/* FIXME: change lookup_addr to two routines, one for readers which\n * returns a copy, and the other for writers who must hold a lock\n * across all uses of the pointer\n */\nstatic bool\nlookup_addr(vm_area_vector_t *v, app_pc addr, vm_area_t **area)\n{\n    /* binary search asserts v is protected */\n    return binary_search(v, addr, addr+1/*open end*/, area, NULL, false);\n}\n\n/* returns true if the passed in area overlaps any known executable areas\n * Assumes caller holds v->lock, if necessary\n */\nstatic bool\nvm_area_overlap(vm_area_vector_t *v, app_pc start, app_pc end)\n{\n    /* binary search asserts v is protected */\n    return binary_search(v, start, end, NULL, NULL, false);\n}\n\n/*********************** EXPORTED ROUTINES **********************/\n\n/* thread-shared initialization that should be repeated after a reset */\nvoid\nvm_areas_reset_init(void)\n{\n    memset(shared_data, 0, sizeof(*shared_data));\n    VMVECTOR_INITIALIZE_VECTOR(&shared_data->areas,\n                               VECTOR_SHARED | VECTOR_FRAGMENT_LIST, shared_vm_areas);\n}\n\nvoid\ndynamo_vm_areas_init()\n{\n    VMVECTOR_ALLOC_VECTOR(dynamo_areas, GLOBAL_DCONTEXT, VECTOR_SHARED,\n                          dynamo_areas);\n}\n\n/* calls find_executable_vm_areas to get per-process map\n * N.B.: add_dynamo_vm_area can be called before this init routine!\n * N.B.: this is called after vm_areas_thread_init()\n */\nint\nvm_areas_init()\n{\n    int areas;\n\n    /* Case 7957: we allocate all vm vectors on the heap for self-prot reasons.\n     * We're already paying the indirection cost by passing their addresses\n     * to generic routines, after all.\n     */\n    VMVECTOR_ALLOC_VECTOR(executable_areas, GLOBAL_DCONTEXT, VECTOR_SHARED,\n                          executable_areas);\n    VMVECTOR_ALLOC_VECTOR(pretend_writable_areas, GLOBAL_DCONTEXT, VECTOR_SHARED,\n                          pretend_writable_areas);\n    VMVECTOR_ALLOC_VECTOR(patch_proof_areas, GLOBAL_DCONTEXT, VECTOR_SHARED,\n                          patch_proof_areas);\n    VMVECTOR_ALLOC_VECTOR(emulate_write_areas, GLOBAL_DCONTEXT, VECTOR_SHARED,\n                          emulate_write_areas);\n    VMVECTOR_ALLOC_VECTOR(IAT_areas, GLOBAL_DCONTEXT, VECTOR_SHARED,\n                          IAT_areas);\n    VMVECTOR_ALLOC_VECTOR(written_areas, GLOBAL_DCONTEXT,\n                          VECTOR_SHARED | VECTOR_NEVER_MERGE,\n                          written_areas);\n    vmvector_set_callbacks(written_areas, free_written_area, NULL, NULL, NULL);\n#ifdef PROGRAM_SHEPHERDING\n    VMVECTOR_ALLOC_VECTOR(futureexec_areas, GLOBAL_DCONTEXT, VECTOR_SHARED,\n                          futureexec_areas);\n# ifdef WINDOWS\n    VMVECTOR_ALLOC_VECTOR(app_flushed_areas, GLOBAL_DCONTEXT, VECTOR_SHARED,\n                          app_flushed_areas);\n# endif\n#endif\n\n    shared_data = HEAP_TYPE_ALLOC(GLOBAL_DCONTEXT, thread_data_t, ACCT_VMAREAS, PROTECTED);\n\n    todelete = HEAP_TYPE_ALLOC(GLOBAL_DCONTEXT, deletion_lists_t, ACCT_VMAREAS, PROTECTED);\n    memset(todelete, 0, sizeof(*todelete));\n\n    coarse_to_delete = HEAP_TYPE_ALLOC(GLOBAL_DCONTEXT, coarse_info_t *,\n                                       ACCT_VMAREAS, PROTECTED);\n    *coarse_to_delete = NULL;\n\n    if (DYNAMO_OPTION(unloaded_target_exception)) {\n        last_deallocated = HEAP_TYPE_ALLOC(GLOBAL_DCONTEXT, last_deallocated_t,\n                                           ACCT_VMAREAS, PROTECTED);\n        memset(last_deallocated, 0, sizeof(*last_deallocated));\n    } else\n        ASSERT(last_deallocated == NULL);\n\n    vm_areas_reset_init();\n\n    /* initialize dynamo list first */\n    LOG(GLOBAL, LOG_VMAREAS, 2,\n        \"\\n--------------------------------------------------------------------------\\n\");\n    dynamo_vm_areas_lock();\n    areas = find_dynamo_library_vm_areas();\n    dynamo_vm_areas_unlock();\n\n    /* initialize executable list\n     * this routine calls app_memory_allocation() w/ dcontext==NULL and so we\n     * won't go adding rwx regions, like the linux stack, to our list, even w/\n     * -executable_if_alloc\n     */\n    areas = find_executable_vm_areas();\n    DOLOG(1, LOG_VMAREAS, {\n        if (areas > 0) {\n            LOG(GLOBAL, LOG_VMAREAS, 1, \"\\nExecution is allowed in %d areas\\n\", areas);\n            print_executable_areas(GLOBAL);\n        }\n        LOG(GLOBAL, LOG_VMAREAS, 2,\n            \"--------------------------------------------------------------------------\\n\");\n    });\n\n    return areas;\n}\n\nstatic void\nvm_areas_statistics()\n{\n#ifdef PROGRAM_SHEPHERDING\n    DOLOG(1, LOG_VMAREAS|LOG_STATS, {\n        uint top; uint bottom;\n        divide_uint64_print(GLOBAL_STAT(looked_up_in_last_area),\n                            GLOBAL_STAT(checked_addresses), true, 2, &top, &bottom);\n        LOG(GLOBAL, LOG_VMAREAS|LOG_STATS, 1,\n            \"Code Origin: %d address lookups, %d in last area, hit ratio %u.%.2u\\n\",\n            GLOBAL_STAT(checked_addresses), GLOBAL_STAT(looked_up_in_last_area),\n            top, bottom);\n    });\n#endif /* PROGRAM_SHEPHERDING */\n    DOLOG(1, LOG_VMAREAS, {\n        LOG(GLOBAL, LOG_VMAREAS, 1, \"\\nexecutable_areas at exit:\\n\");\n        print_executable_areas(GLOBAL);\n    });\n}\n\n/* Free all thread-shared state not critical to forward progress;\n * vm_areas_reset_init() will be called before continuing.\n */\nvoid\nvm_areas_reset_free(void)\n{\n    if (SHARED_FRAGMENTS_ENABLED()) {\n        /* all deletion entries should be removed in fragment_exit(),\n         * else we'd have to free the frags lists and entries here\n         */\n        ASSERT(todelete->shared_delete == NULL);\n        ASSERT(todelete->shared_delete_tail == NULL);\n        /* FIXME: don't free lock so init has less work */\n        vmvector_free_vector(GLOBAL_DCONTEXT, &shared_data->areas);\n    }\n    /* vm_area_coarse_units_reset_free() is called in fragment_reset_free() */\n}\n\nint\nvm_areas_exit()\n{\n    vm_areas_exited = true;\n    vm_areas_statistics();\n\n    if (DYNAMO_OPTION(thin_client)) {\n        vmvector_delete_vector(GLOBAL_DCONTEXT, dynamo_areas);\n        dynamo_areas = NULL;\n        /* For thin_client none of the following areas should have been\n         * initialized because they aren't used.\n         * FIXME: wonder if I can do something like this for -client and see\n         * what I am using unnecessarily.\n         */\n        ASSERT(shared_data == NULL);\n        ASSERT(todelete == NULL);\n        ASSERT(executable_areas == NULL);\n        ASSERT(pretend_writable_areas == NULL);\n        ASSERT(patch_proof_areas == NULL);\n        ASSERT(emulate_write_areas == NULL);\n        ASSERT(written_areas == NULL);\n#ifdef PROGRAM_SHEPHERDING\n        ASSERT(futureexec_areas == NULL);\n        IF_WINDOWS(ASSERT(app_flushed_areas == NULL);)\n#endif\n        ASSERT(IAT_areas == NULL);\n        return 0;\n    }\n\n    vm_areas_reset_free();\n    DELETE_LOCK(shared_delete_lock);\n    DELETE_LOCK(lazy_delete_lock);\n    ASSERT(todelete->lazy_delete_count == 0);\n    ASSERT(!todelete->move_pending);\n\n    HEAP_TYPE_FREE(GLOBAL_DCONTEXT, shared_data, thread_data_t, ACCT_VMAREAS, PROTECTED);\n    shared_data = NULL;\n\n    HEAP_TYPE_FREE(GLOBAL_DCONTEXT, todelete, deletion_lists_t, ACCT_VMAREAS, PROTECTED);\n    todelete = NULL;\n\n    ASSERT(coarse_to_delete != NULL);\n    /* should be freed immediately after each use, during a no-exec flush */\n    ASSERT(*coarse_to_delete == NULL);\n    HEAP_TYPE_FREE(GLOBAL_DCONTEXT, coarse_to_delete, coarse_info_t *,\n                   ACCT_VMAREAS, PROTECTED);\n\n    if (DYNAMO_OPTION(unloaded_target_exception)) {\n        HEAP_TYPE_FREE(GLOBAL_DCONTEXT, last_deallocated,\n                       last_deallocated_t, ACCT_VMAREAS, PROTECTED);\n        last_deallocated = NULL;\n    } else\n        ASSERT(last_deallocated == NULL);\n    DELETE_LOCK(last_deallocated_lock);\n\n    vmvector_delete_vector(GLOBAL_DCONTEXT, executable_areas);\n    executable_areas = NULL;\n    DOLOG(1, LOG_VMAREAS, {\n        if (dynamo_areas->buf != NULL) {\n            LOG(GLOBAL, LOG_VMAREAS, 1, \"DR regions at exit are:\\n\");\n            print_dynamo_areas(GLOBAL);\n            LOG(GLOBAL, LOG_VMAREAS, 1, \"\\n\");\n        }\n    });\n    vmvector_delete_vector(GLOBAL_DCONTEXT, dynamo_areas);\n    dynamo_areas = NULL;\n    DOLOG(1, LOG_VMAREAS, {\n        if (written_areas->buf != NULL) {\n            LOG(GLOBAL, LOG_VMAREAS, 1, \"Code write and selfmod exec counts:\\n\");\n            print_written_areas(GLOBAL);\n            LOG(GLOBAL, LOG_VMAREAS, 1, \"\\n\");\n        }\n    });\n    vmvector_delete_vector(GLOBAL_DCONTEXT, pretend_writable_areas);\n    pretend_writable_areas = NULL;\n    vmvector_delete_vector(GLOBAL_DCONTEXT, patch_proof_areas);\n    patch_proof_areas = NULL;\n    vmvector_delete_vector(GLOBAL_DCONTEXT, emulate_write_areas);\n    emulate_write_areas = NULL;\n\n    vmvector_delete_vector(GLOBAL_DCONTEXT, written_areas);\n    written_areas = NULL;\n\n#ifdef PROGRAM_SHEPHERDING\n    DOLOG(1, LOG_VMAREAS, {\n        if (futureexec_areas->buf != NULL)\n            LOG(GLOBAL, LOG_VMAREAS, 1, \"futureexec %d regions at exit are:\\n\",\n                futureexec_areas->length);\n        print_futureexec_areas(GLOBAL);\n    });\n    vmvector_delete_vector(GLOBAL_DCONTEXT, futureexec_areas);\n    futureexec_areas = NULL;\n    DELETE_LOCK(threads_killed_lock);\n# ifdef WINDOWS\n    ASSERT(DYNAMO_OPTION(xdata_rct) || vmvector_empty(app_flushed_areas));\n    vmvector_delete_vector(GLOBAL_DCONTEXT, app_flushed_areas);\n    app_flushed_areas = NULL;\n# endif\n#endif\n#ifdef SIMULATE_ATTACK\n    DELETE_LOCK(simulate_lock);\n#endif\n    vmvector_delete_vector(GLOBAL_DCONTEXT, IAT_areas);\n    IAT_areas = NULL;\n\n    tamper_resistant_region_start = NULL;\n    tamper_resistant_region_end = NULL;\n\n    return 0;\n}\n\nvoid\nvm_areas_thread_reset_init(dcontext_t *dcontext)\n{\n    thread_data_t *data = (thread_data_t *) dcontext->vm_areas_field;\n    memset(dcontext->vm_areas_field, 0, sizeof(thread_data_t));\n    VMVECTOR_INITIALIZE_VECTOR(&data->areas, VECTOR_FRAGMENT_LIST, thread_vm_areas);\n    /* data->areas.lock is never used, but we may want to grab it one day,\n       e.g. to print other thread areas */\n}\n\n/* N.B.: this is called before vm_areas_init() */\nvoid\nvm_areas_thread_init(dcontext_t *dcontext)\n{\n    thread_data_t *data = HEAP_TYPE_ALLOC(dcontext, thread_data_t, ACCT_OTHER, PROTECTED);\n    dcontext->vm_areas_field = data;\n    vm_areas_thread_reset_init(dcontext);\n}\n\nvoid\nvm_areas_thread_reset_free(dcontext_t *dcontext)\n{\n    /* we free the local areas vector so it will match fragments post-reset\n     * FIXME: put it in nonpersistent heap\n     */\n    thread_data_t *data = (thread_data_t *) dcontext->vm_areas_field;\n    /* yes, we end up using global heap for the thread-local area\n     * vector...not a big deal, but FIXME sometime\n     */\n    vmvector_free_vector(GLOBAL_DCONTEXT, &data->areas);\n}\n\nvoid\nvm_areas_thread_exit(dcontext_t *dcontext)\n{\n    vm_areas_thread_reset_free(dcontext);\n#ifdef DEBUG\n    /* for non-debug we do fast exit path and don't free local heap */\n    HEAP_TYPE_FREE(dcontext, dcontext->vm_areas_field, thread_data_t, ACCT_OTHER, PROTECTED);\n#endif\n}\n\n/****************************************************************************\n * external interface to vm_area_vector_t\n *\n * FIXME: add user data field to vector and to add routine\n * FIXME: have init and destroy routines so don't have to expose\n *        vm_area_vector_t struct or declare vector in this file\n */\n\nvoid\nvmvector_set_callbacks(vm_area_vector_t *v,\n                       void (*free_func)(void*),\n                       void *(*split_func)(void*),\n                       bool (*should_merge_func)(bool, void*, void*),\n                       void *(*merge_func)(void*, void*))\n{\n    bool release_lock; /* 'true' means this routine needs to unlock */\n    ASSERT(v != NULL);\n    LOCK_VECTOR(v, release_lock, read);\n    v->free_payload_func = free_func;\n    v->split_payload_func = split_func;\n    v->should_merge_func = should_merge_func;\n    v->merge_payload_func = merge_func;\n    UNLOCK_VECTOR(v, release_lock, read);\n}\n\nvoid\nvmvector_print(vm_area_vector_t *v, file_t outf)\n{\n    bool release_lock; /* 'true' means this routine needs to unlock */\n    LOCK_VECTOR(v, release_lock, read);\n    print_vm_areas(v, outf);\n    UNLOCK_VECTOR(v, release_lock, read);\n}\n\nvoid\nvmvector_add(vm_area_vector_t *v, app_pc start, app_pc end, void *data)\n{\n    bool release_lock; /* 'true' means this routine needs to unlock */\n    LOCK_VECTOR(v, release_lock, write);\n    ASSERT_OWN_WRITE_LOCK(SHOULD_LOCK_VECTOR(v), &v->lock);\n    add_vm_area(v, start, end, 0, 0, data _IF_DEBUG(\"\"));\n    UNLOCK_VECTOR(v, release_lock, write);\n}\n\nvoid *\nvmvector_add_replace(vm_area_vector_t *v, app_pc start, app_pc end, void *data)\n{\n    bool overlap;\n    vm_area_t *area = NULL;\n    void *old_data = NULL;\n    bool release_lock; /* 'true' means this routine needs to unlock */\n\n    LOCK_VECTOR(v, release_lock, write);\n    ASSERT_OWN_WRITE_LOCK(SHOULD_LOCK_VECTOR(v), &v->lock);\n    overlap = lookup_addr(v, start, &area);\n    if (overlap && start == area->start && end == area->end) {\n        old_data = area->custom.client;\n        area->custom.client = data;\n    } else\n        add_vm_area(v, start, end, 0, 0, data _IF_DEBUG(\"\"));\n    UNLOCK_VECTOR(v, release_lock, write);\n    return old_data;\n}\n\nbool\nvmvector_remove(vm_area_vector_t *v, app_pc start, app_pc end)\n{\n    bool ok;\n    bool release_lock; /* 'true' means this routine needs to unlock */\n    LOCK_VECTOR(v, release_lock, write);\n    ASSERT_OWN_WRITE_LOCK(SHOULD_LOCK_VECTOR(v), &v->lock);\n    ok = remove_vm_area(v, start, end, false);\n    UNLOCK_VECTOR(v, release_lock, write);\n    return ok;\n}\n\n/* Looks up area encapsulating target pc and removes.\n * returns true if found and removed, and optional area boundaries are set\n * returns false if not found\n */\nbool\nvmvector_remove_containing_area(vm_area_vector_t *v, app_pc pc,\n                                app_pc *area_start /* OUT optional */,\n                                app_pc *area_end /* OUT optional */)\n{\n    vm_area_t *a;\n    bool ok;\n    bool release_lock; /* 'true' means this routine needs to unlock */\n\n    /* common path should be to find one, and would need write lock to\n     * remove */\n    LOCK_VECTOR(v, release_lock, write);\n    ASSERT_OWN_WRITE_LOCK(SHOULD_LOCK_VECTOR(v), &v->lock);\n    ok = lookup_addr(v, pc, &a);\n    if (ok) {\n        if (area_start != NULL)\n            *area_start = a->start;\n        if (area_end != NULL)\n            *area_end = a->end;\n        remove_vm_area(v, a->start, a->end, false);\n    }\n    UNLOCK_VECTOR(v, release_lock, write);\n    return ok;\n}\n\n\nbool\nvmvector_overlap(vm_area_vector_t *v, app_pc start, app_pc end)\n{\n    bool overlap;\n    bool release_lock; /* 'true' means this routine needs to unlock */\n    if (vmvector_empty(v))\n        return false;\n    LOCK_VECTOR(v, release_lock, read);\n    ASSERT_OWN_READWRITE_LOCK(SHOULD_LOCK_VECTOR(v), &v->lock);\n    overlap = vm_area_overlap(v, start, end);\n    UNLOCK_VECTOR(v, release_lock, read);\n    return overlap;\n}\n\n/* returns custom data field, or NULL if not found.  NOTE: Access to\n * custom data needs explicit synchronization in addition to\n * vm_area_vector_t's locks!\n */\nvoid *\nvmvector_lookup(vm_area_vector_t *v, app_pc pc)\n{\n    void *data = NULL;\n    vmvector_lookup_data(v, pc, NULL, NULL, &data);\n    return data;\n}\n\n/* Looks up if pc is in a vmarea and optionally returns the areas's bounds\n * and any custom data. NOTE: Access to custom data needs explicit\n * synchronization in addition to vm_area_vector_t's locks!\n */\nbool\nvmvector_lookup_data(vm_area_vector_t *v, app_pc pc,\n                     app_pc *start /* OUT */, app_pc *end /* OUT */,\n                     void **data /* OUT */)\n{\n    bool overlap;\n    vm_area_t *area = NULL;\n    bool release_lock; /* 'true' means this routine needs to unlock */\n\n    LOCK_VECTOR(v, release_lock, read);\n    ASSERT_OWN_READWRITE_LOCK(SHOULD_LOCK_VECTOR(v), &v->lock);\n    overlap = lookup_addr(v, pc, &area);\n    if (overlap) {\n        if (start != NULL)\n            *start = area->start;\n        if (end != NULL)\n            *end = area->end;\n        if (data != NULL)\n            *data = area->custom.client;\n    }\n    UNLOCK_VECTOR(v, release_lock, read);\n    return overlap;\n}\n\n/* Returns false if pc is in a vmarea in v.\n * Otherwise, returns the start pc of the vmarea prior to pc in prev and\n * the start pc of the vmarea after pc in next.\n * FIXME: most callers will call this and vmvector_lookup_data():\n * should this routine do both to avoid an extra binary search?\n */\nbool\nvmvector_lookup_prev_next(vm_area_vector_t *v, app_pc pc,\n                          OUT app_pc *prev, OUT app_pc *next)\n{\n    bool success;\n    int index;\n    bool release_lock; /* 'true' means this routine needs to unlock */\n\n    LOCK_VECTOR(v, release_lock, read);\n    ASSERT_OWN_READWRITE_LOCK(SHOULD_LOCK_VECTOR(v), &v->lock);\n    success = !binary_search(v, pc, pc+1, NULL, &index, false);\n    if (success) {\n        if (prev != NULL) {\n            if (index == -1)\n                *prev = NULL;\n            else\n                *prev = v->buf[index].start;\n        }\n        if (next != NULL) {\n            if (index >= v->length - 1)\n                *next = (app_pc) POINTER_MAX;\n            else\n                *next = v->buf[index+1].start;\n        }\n    }\n    UNLOCK_VECTOR(v, release_lock, read);\n    return success;\n}\n\n/* Sets custom data field if a vmarea is present. Returns true if found,\n * false if not found.  NOTE: Access to custom data needs explicit\n * synchronization in addition to vm_area_vector_t's locks!\n */\nbool\nvmvector_modify_data(vm_area_vector_t *v, app_pc start, app_pc end, void *data)\n{\n    bool overlap;\n    vm_area_t *area = NULL;\n    bool release_lock; /* 'true' means this routine needs to unlock */\n\n    LOCK_VECTOR(v, release_lock, write);\n    ASSERT_OWN_WRITE_LOCK(SHOULD_LOCK_VECTOR(v), &v->lock);\n    overlap = lookup_addr(v, start, &area);\n    if (overlap && start == area->start && end == area->end)\n        area->custom.client = data;\n    UNLOCK_VECTOR(v, release_lock, write);\n    return overlap;\n}\n\n/* this routine does NOT initialize the rw lock!  use VMVECTOR_INITIALIZE_VECTOR */\nvoid\nvmvector_init_vector(vm_area_vector_t *v, uint flags)\n{\n    memset(v, 0, sizeof(*v));\n    v->flags = flags;\n}\n\n/* this routine does NOT initialize the rw lock!  use VMVECTOR_ALLOC_VECTOR instead */\nvm_area_vector_t *\nvmvector_create_vector(dcontext_t *dcontext, uint flags)\n{\n    vm_area_vector_t *v =\n        HEAP_TYPE_ALLOC(dcontext, vm_area_vector_t, ACCT_VMAREAS, PROTECTED);\n    vmvector_init_vector(v, flags);\n    return v;\n}\n\n/* frees the fields of vm_area_vector_t v (not v itself) */\nvoid\nvmvector_reset_vector(dcontext_t *dcontext, vm_area_vector_t *v)\n{\n    DODEBUG({\n        int i;\n        /* walk areas and delete coarse info and comments */\n        for (i = 0; i < v->length; i++) {\n            /* FIXME: this code is duplicated in remove_vm_area() */\n            if (TEST(FRAG_COARSE_GRAIN, v->buf[i].frag_flags) &&\n                /* FIXME: cleaner test? shared_data copies flags, but uses\n                 * custom.frags and not custom.client\n                 */\n                v == executable_areas) {\n                coarse_info_t *info = (coarse_info_t *) v->buf[i].custom.client;\n                coarse_info_t *next_info;\n                ASSERT(!RUNNING_WITHOUT_CODE_CACHE());\n                ASSERT(info != NULL);\n                while (info != NULL) { /* loop over primary and secondary unit */\n                    next_info = info->non_frozen;\n                    ASSERT(info->frozen || info->non_frozen == NULL);\n                    coarse_unit_free(GLOBAL_DCONTEXT, info);\n                    info = next_info;\n                    ASSERT(info == NULL || !info->frozen);\n                }\n                v->buf[i].custom.client = NULL;\n            }\n            global_heap_free(v->buf[i].comment, strlen(v->buf[i].comment)+1\n                             HEAPACCT(ACCT_VMAREAS));\n        }\n    });\n    /* with thread shared cache it is in fact possible to have no thread local vmareas */\n    if (v->buf != NULL) {\n        /* FIXME: walk through and make sure frags lists are all freed */\n        global_heap_free(v->buf, v->size*sizeof(struct vm_area_t) HEAPACCT(ACCT_VMAREAS));\n        v->size = 0;\n        v->length = 0;\n        v->buf = NULL;\n    } else\n        ASSERT(v->size == 0 && v->length == 0);\n}\n\nstatic void\nvmvector_free_vector(dcontext_t *dcontext, vm_area_vector_t *v)\n{\n    vmvector_reset_vector(dcontext, v);\n    DELETE_READWRITE_LOCK(v->lock);\n}\n\n/* frees the vm_area_vector_t v and its associated memory */\nvoid\nvmvector_delete_vector(dcontext_t *dcontext, vm_area_vector_t *v)\n{\n    if (v->free_payload_func != NULL) {\n        int i;\n        for (i = 0; i < v->length; i++) {\n            v->free_payload_func(v->buf[i].custom.client);\n        }\n    }\n    vmvector_free_vector(dcontext, v);\n    HEAP_TYPE_FREE(dcontext, v, vm_area_vector_t, ACCT_VMAREAS, PROTECTED);\n}\n\n/* vmvector iterator */\n/* initialize an iterator, has to be released with\n * vmvector_iterator_stop.  The iterator doesn't support mutations.\n * In fact shared vectors should detect a deadlock\n * if vmvector_add() and vmvector_remove() is erroneously called.\n */\nvoid\nvmvector_iterator_start(vm_area_vector_t *v, vmvector_iterator_t *vmvi)\n{\n    ASSERT(v != NULL);\n    ASSERT(vmvi != NULL);\n    if (SHOULD_LOCK_VECTOR(v))\n        read_lock(&v->lock);\n    vmvi->vector = v;\n    vmvi->index = -1;\n}\n\nbool\nvmvector_iterator_hasnext(vmvector_iterator_t *vmvi)\n{\n    ASSERT_VMAREA_VECTOR_PROTECTED(vmvi->vector, READWRITE);\n    return (vmvi->index + 1) < vmvi->vector->length;\n}\n\nvoid\nvmvector_iterator_startover(vmvector_iterator_t *vmvi)\n{\n    ASSERT_VMAREA_VECTOR_PROTECTED(vmvi->vector, READWRITE);\n    vmvi->index = -1;\n}\n\n/* iterator accessor\n * has to be initialized with vmvector_iterator_start, and should be\n * called only when vmvector_iterator_hasnext() is true\n *\n * returns custom data and\n * sets the area boundaries in area_start and area_end\n *\n * does not increment the iterator\n */\nvoid*\nvmvector_iterator_peek(vmvector_iterator_t *vmvi, /* IN/OUT */\n                       app_pc *area_start /* OUT */, app_pc *area_end /* OUT */)\n{\n    int idx = vmvi->index + 1;\n    ASSERT(vmvector_iterator_hasnext(vmvi));\n    ASSERT_VMAREA_VECTOR_PROTECTED(vmvi->vector, READWRITE);\n    ASSERT(idx < vmvi->vector->length);\n    if (area_start != NULL)\n        *area_start = vmvi->vector->buf[idx].start;\n    if (area_end != NULL)\n        *area_end = vmvi->vector->buf[idx].end;\n    return vmvi->vector->buf[idx].custom.client;\n}\n\n/* iterator accessor\n * has to be initialized with vmvector_iterator_start, and should be\n * called only when vmvector_iterator_hasnext() is true\n *\n * returns custom data and\n * sets the area boundaries in area_start and area_end\n */\nvoid*\nvmvector_iterator_next(vmvector_iterator_t *vmvi, /* IN/OUT */\n                       app_pc *area_start /* OUT */, app_pc *area_end /* OUT */)\n{\n    void *res = vmvector_iterator_peek(vmvi, area_start, area_end);\n    vmvi->index++;\n    return res;\n}\n\nvoid\nvmvector_iterator_stop(vmvector_iterator_t *vmvi)\n{\n    ASSERT_VMAREA_VECTOR_PROTECTED(vmvi->vector, READWRITE);\n    if (SHOULD_LOCK_VECTOR(vmvi->vector))\n        read_unlock(&vmvi->vector->lock);\n    DODEBUG({\n        vmvi->vector = NULL;    /* crash incorrect reuse */\n        vmvi->index = -1;\n    });\n}\n\n/****************************************************************************\n * routines specific to our own vectors\n */\n\nvoid\nprint_executable_areas(file_t outf)\n{\n    vmvector_print(executable_areas, outf);\n}\n\nvoid\nprint_dynamo_areas(file_t outf)\n{\n    dynamo_vm_areas_start_reading();\n    print_vm_areas(dynamo_areas, outf);\n    dynamo_vm_areas_done_reading();\n}\n\n#ifdef PROGRAM_SHEPHERDING\nvoid\nprint_futureexec_areas(file_t outf)\n{\n    vmvector_print(futureexec_areas, outf);\n}\n#endif\n\n#if defined(DEBUG) && defined(INTERNAL)\nstatic void\nprint_written_areas(file_t outf)\n{\n    vmvector_print(written_areas, outf);\n}\n#endif\n\nstatic void\nfree_written_area(void *data)\n{\n    HEAP_TYPE_FREE(GLOBAL_DCONTEXT, (ro_vs_sandbox_data_t *) data,\n                   ro_vs_sandbox_data_t, ACCT_VMAREAS, UNPROTECTED);\n}\n\n/* Functions as a lookup routine if an entry is already present.\n * Returns true if an entry was already present, false if not, in which\n * case an entry containing tag with suggested bounds of [start, end)\n * (actual bounds may be smaller to avoid overlap) is added.\n */\nstatic bool\nadd_written_area(vm_area_vector_t *v, app_pc tag, app_pc start,\n                 app_pc end, vm_area_t **area)\n{\n    vm_area_t *a = NULL;\n    bool already;\n    DEBUG_DECLARE(bool ok;)\n    /* currently only one vector */\n    ASSERT(v == written_areas);\n    ASSERT_OWN_WRITE_LOCK(true, &v->lock);\n    ASSERT(tag >= start && tag < end);\n    /* re-adding fails for written_areas since no merging, so lookup first */\n    already = lookup_addr(v, tag, &a);\n    if (!already) {\n        app_pc prev_start = NULL, next_start = NULL;\n        LOG(GLOBAL, LOG_VMAREAS, 2,\n            \"new written executable vm area: \"PFX\"-\"PFX\"\\n\",\n            start, end);\n        /* case 9179: With no flags, any overlap (in non-tag portion of [start,\n         * end)) will result in a merge: so we'll inherit and share counts from\n         * any adjacent region(s): maybe better to split?  Rare in any case and\n         * not critical.  In case of simultaneous overlap, we take counter from\n         * first region, since that's how add_vm_area does the merge.\n         */\n        /* we can't merge b/c we have hardcoded counter pointers in code\n         * in the cache, so we make sure to only add the non-overlap\n         */\n        DEBUG_DECLARE(ok = ) vmvector_lookup_prev_next(v, tag, &prev_start, &next_start);\n        ASSERT(ok); /* else already should be true */\n        if (prev_start != NULL) {\n            vm_area_t *prev_area = NULL;\n            DEBUG_DECLARE(ok = ) lookup_addr(v, prev_start, &prev_area);\n            ASSERT(ok); /* we hold the lock after all */\n            if (prev_area->end > start)\n                start = prev_area->end;\n        }\n        if (next_start < (app_pc) POINTER_MAX && end > next_start)\n            end = next_start;\n        add_vm_area(v, start, end, /* no flags */ 0, 0, NULL _IF_DEBUG(\"\"));\n        DEBUG_DECLARE(ok = ) lookup_addr(v, tag, &a);\n        ASSERT(ok && a != NULL);\n        /* If we merged, we already have an ro2s struct */\n        /* FIXME: now that we have merge callback support, should just pass\n         * a struct into add_vm_area and avoid this post-lookup\n         */\n        if (a->custom.client == NULL) {\n            /* Since selfmod_execs is written from the cache this must be\n             * unprotected.  Attacker changing selfmod_execs or written_count\n             * shouldn't be able to cause problems.\n             */\n            ro_vs_sandbox_data_t *ro2s =\n                HEAP_TYPE_ALLOC(GLOBAL_DCONTEXT, ro_vs_sandbox_data_t,\n                                ACCT_VMAREAS, UNPROTECTED);\n            /* selfmod_execs is inc-ed from the cache, and if it crosses a cache\n             * line we could have a problem with large thresholds.  We assert on\n             * 32-bit alignment here, which our heap alloc currently provides, to\n             * ensure no cache line is crossed.\n             */\n            ASSERT(ALIGNED(ro2s, sizeof(uint)));\n            memset(ro2s, 0, sizeof(*ro2s));\n            a->custom.client = (void *) ro2s;\n        }\n    } else {\n        LOG(GLOBAL, LOG_VMAREAS, 3,\n            \"request for written area \"PFX\"-\"PFX\" vs existing \"PFX\"-\"PFX\"\\n\",\n            start, end, a->start, a->end);\n    }\n    ASSERT(a != NULL);\n    if (area != NULL)\n        *area = a;\n    return already;\n}\n\n#ifdef WINDOWS\n/* Adjusts a new executable area with respect to the IAT.\n * Returns whether it should remain coarse or not.\n */\nstatic bool\nadd_executable_vm_area_check_IAT(app_pc *start /*IN/OUT*/, app_pc *end /*IN/OUT*/,\n                                 uint vm_flags,\n                                 vm_area_t **existing_area /*OUT*/,\n                                 coarse_info_t **info_out /*OUT*/,\n                                 coarse_info_t **tofree /*OUT*/,\n                                 app_pc *delay_start /*OUT*/,\n                                 app_pc *delay_end /*OUT*/)\n{\n    bool keep_coarse = false;\n    app_pc IAT_start = NULL, IAT_end = NULL;\n    app_pc orig_start = *start, orig_end = *end;\n    ASSERT(existing_area != NULL && info_out != NULL && tofree != NULL);\n    ASSERT(delay_start != NULL && delay_end != NULL);\n    if (DYNAMO_OPTION(coarse_merge_iat) &&\n        get_module_base(*start) != NULL &&\n        get_IAT_section_bounds(get_module_base(*start), &IAT_start, &IAT_end) &&\n        /* case 1094{5,7}: to match the assumptions of case 10600 we adjust\n         * to post-IAT even if the IAT is in the middle, if it's toward the front\n         */\n        (*start >= IAT_start || (IAT_start - *start < *end - IAT_end)) &&\n        *start < IAT_end &&\n        /* be paranoid: multi-page IAT where hooker fooled our loader matching\n         * could add just 1st page of IAT? */\n        *end > IAT_end /* for == avoid an empty region */) {\n        /* If a pre-IAT region exists, split if off separately (case 10945).\n         * We want to keep as coarse, but we need the post-IAT region to be the\n         * primary coarse and the one we try to load a pcache for: so we delay\n         * the add.\n         * FIXME: should we do a general split around the IAT and make both sides\n         * coarse with larger the primary instead of assuming pre-IAT is smaller?\n         */\n        if (orig_start < IAT_start) {\n            LOG(GLOBAL, LOG_VMAREAS, 2,\n                \"splitting pre-IAT \"PFX\"-\"PFX\" off from exec area \"PFX\"-\"PFX\"\\n\",\n                orig_start, IAT_start, orig_start, orig_end);\n            *delay_start = orig_start;\n            *delay_end = IAT_start;\n            DOCHECK(1, {\n                /* When IAT is in the middle of +rx region we expect .orpc */\n                app_pc orpc_start = NULL;\n                app_pc orpc_end = NULL;\n                get_named_section_bounds(get_module_base(orig_start), \".orpc\",\n                                         &orpc_start, &orpc_end);\n                ASSERT_CURIOSITY(orpc_start == orig_start && orpc_end == IAT_start);\n            });\n        }\n        /* Just abandon [*start, IAT_end) */\n        *start = IAT_end;\n        ASSERT(*end > *start);\n        LOG(GLOBAL, LOG_VMAREAS, 2,\n            \"adjusting exec area \"PFX\"-\"PFX\" to post-IAT \"PFX\"-\"PFX\"\\n\",\n            orig_start, *end, *start, *end);\n    } else {\n        LOG(GLOBAL, LOG_VMAREAS, 2,\n            \"NOT adjusting exec area \"PFX\"-\"PFX\" vs IAT \"PFX\"-\"PFX\"\\n\",\n            orig_start, *end, IAT_start, IAT_end);\n    }\n    if (TEST(VM_UNMOD_IMAGE, vm_flags))\n        keep_coarse = true;\n    else {\n        /* Keep the coarse-grain flag for modified pages only if IAT pages.\n         * We want to avoid repeated coarse flushes, so we are\n         * very conservative about marking if_rx_text regions coarse: we count on\n         * our IAT loader check to make this a do-once.\n         * FIXME: Should extend this to also merge on left with .orpc:\n         * .orpc at page 1, IAT on page 2, and .text continuing on\n         */\n        ASSERT(ALIGNED(*end, PAGE_SIZE));\n        if (DYNAMO_OPTION(coarse_merge_iat) &&\n            vm_flags == 0 /* no other flags */ &&\n            /* FIXME: used our stored bounds */\n            is_IAT(orig_start, orig_end, true/*page-align*/, NULL, NULL) &&\n            is_module_patch_region(GLOBAL_DCONTEXT, orig_start, orig_end,\n                                   true/*be conservative*/) &&\n            /* We stored the IAT code at +rw time */\n            os_module_cmp_IAT_code(orig_start)) {\n            vm_area_t *area = NULL;\n            bool all_new = !executable_vm_area_overlap(orig_start, orig_end-1,\n                                                       true/*wlock*/);\n            ASSERT(IAT_start != NULL); /* should have found bounds above */\n            if (all_new && /* elseif assumes next call happened */\n                lookup_addr(executable_areas, *end, &area) &&\n                TEST(FRAG_COARSE_GRAIN, area->frag_flags) &&\n                /* Only merge if no execution has yet occurred: else this\n                 * must not be normal rebinding */\n                !TEST(VM_EXECUTED_FROM, area->vm_flags) &&\n                /* Should be marked invalid; else no loader +rw => not rebinding */\n                area->custom.client != NULL &&\n                TEST(PERSCACHE_CODE_INVALID,\n                     ((coarse_info_t *)area->custom.client)->flags)) {\n                /* Case 8640: merge IAT page back in to coarse area.\n                 * Easier to merge here than in add_vm_area.\n                 */\n                coarse_info_t *info = (coarse_info_t *) area->custom.client;\n                keep_coarse = true;\n                LOG(GLOBAL, LOG_VMAREAS, 2,\n                    \"merging post-IAT (\"PFX\"-\"PFX\") with \"PFX\"-\"PFX\"\\n\",\n                    IAT_end, orig_end, area->start, area->end);\n                ASSERT(area != NULL);\n                ASSERT(area->start == *end);\n                ASSERT(IAT_end > orig_start && IAT_end < area->start);\n                ASSERT(*start == IAT_end); /* set up above */\n                *end = area->end;\n                area->start = *start;\n                *existing_area = area;\n                STATS_INC(coarse_merge_IAT);\n                /* If info was loaded prior to rebinding just use it.\n                 * Else, we need a fresh coarse_info_t if persisted, so rather than\n                 * adjust_coarse_unit_bounds on info we must free it.\n                 * Due to lock constraints we can't do that while holding\n                 * exec areas lock.\n                 */\n                /* Bounds should match exactly, since we did not adjust them\n                 * on the flush; if they don't, don't use the pcache. */\n                if (info->base_pc == area->start && info->end_pc == area->end) {\n                    info->flags &= ~PERSCACHE_CODE_INVALID;\n                    *info_out = info;\n                    STATS_INC(coarse_marked_valid);\n                    LOG(GLOBAL, LOG_VMAREAS, 2,\n                        \"\\tkeeping now-valid info %s \"PFX\"-\"PFX\"\\n\",\n                        info->module, info->base_pc, info->end_pc);\n                } else {\n                    /* Go ahead and merge, but don't use this pcache */\n                    ASSERT_CURIOSITY(false && \"post-rebind pcache bounds mismatch\");\n                    *tofree = info;\n                    area->custom.client = NULL;\n                    /* FIXME: we'll try to load again: prevent that?  We\n                     * know the image hasn't been modified so no real danger. */\n                    STATS_INC(perscache_rebind_load);\n                }\n            } else if (all_new && area == NULL /*nothing following*/) {\n                /* Code section is a single page, so was completely flushed\n                 * We'll try to re-load the pcache.\n                 * FIXME: we already merged the persisted rct tables into\n                 * the live tables when we flushed the pcache: so now\n                 * we'll have redundancy, and if we flush again we'll waste\n                 * time tryingn to re-add (we do check for dups).\n                 */\n                ASSERT(!lookup_addr(executable_areas, *start, NULL));\n                LOG(GLOBAL, LOG_VMAREAS, 2,\n                    \"marking IAT/code region (\"PFX\"-\"PFX\" vs \"PFX\"-\"PFX\") as coarse\\n\",\n                    IAT_start, IAT_end, orig_start, orig_end);\n                keep_coarse = true;\n                STATS_INC(coarse_merge_IAT); /* we use same stat */\n            } else {\n                LOG(GLOBAL, LOG_VMAREAS, 2,\n                    \"NOT merging IAT-containing \"PFX\"-\"PFX\": abuts non-inv-coarse\\n\",\n                    orig_start, orig_end);\n                DOCHECK(1, {\n                    if (all_new && area != NULL &&\n                        TEST(FRAG_COARSE_GRAIN, area->frag_flags) &&\n                        TEST(VM_EXECUTED_FROM, area->vm_flags)) {\n                        coarse_info_t *info = (coarse_info_t *) area->custom.client;\n                        ASSERT(!info->persisted);\n                        ASSERT(!TEST(PERSCACHE_CODE_INVALID, info->flags));\n                    }\n                });\n            }\n        } else {\n            LOG(GLOBAL, LOG_VMAREAS, 2,\n                \"NOT merging .text \"PFX\"-\"PFX\" vs IAT \"PFX\"-\"PFX\" %d %d %d %d %d\\n\",\n                orig_start, orig_end, IAT_start, IAT_end,\n                DYNAMO_OPTION(coarse_merge_iat), vm_flags == 0,\n                is_IAT(orig_start, *end, true/*page-align*/, NULL, NULL),\n                is_module_patch_region(GLOBAL_DCONTEXT, orig_start, orig_end,\n                                       true/*be conservative*/),\n                os_module_cmp_IAT_code(orig_start));\n        }\n    }\n    return keep_coarse;\n}\n#endif\n\nstatic void\nadd_executable_vm_area_helper(app_pc start, app_pc end, uint vm_flags, uint frag_flags,\n                              coarse_info_t *info _IF_DEBUG(const char *comment))\n{\n    ASSERT_OWN_WRITE_LOCK(true, &executable_areas->lock);\n\n    add_vm_area(executable_areas, start, end,\n                vm_flags, frag_flags, NULL _IF_DEBUG(comment));\n\n    if (TEST(VM_WRITABLE, vm_flags)) {\n        /* N.B.: the writable flag indicates the natural state of the memory,\n         * not what we have made it be -- we make it read-only before adding\n         * to the executable list!\n         * FIXME: win32 callback's intercept_call code appears in fragments\n         * and is writable...would like to fix that, and coalesce that memory\n         * with the generated routines or something\n         */\n        LOG(GLOBAL, LOG_VMAREAS, 2,\n            \"WARNING: new executable vm area is writable: \"PFX\"-\"PFX\" %s\\n\",\n            start, end, comment);\n#if 0\n        /* this syslog causes services.exe to hang (ref case 666) once case 666\n         * is fixed re-enable if desired FIXME */\n        SYSLOG_INTERNAL_WARNING_ONCE(\"new executable vm area is writable.\");\n#endif\n    }\n#ifdef PROGRAM_SHEPHERDING\n    if (!DYNAMO_OPTION(selfmod_futureexec) &&\n        TEST(FRAG_SELFMOD_SANDBOXED, frag_flags)) {\n        /* We do not need future entries for selfmod regions.  We mark\n         * the futures as once-only when they are selfmod at future add time, and\n         * here we catch those who weren't selfmod then but are now.\n         */\n        remove_futureexec_vm_area(start, end);\n    }\n#endif\n    if (TEST(FRAG_COARSE_GRAIN, frag_flags)) {\n        vm_area_t *area = NULL;\n        DEBUG_DECLARE(bool found = )\n            lookup_addr(executable_areas, start, &area);\n        ASSERT(found && area != NULL);\n        /* case 9521: always have one non-frozen coarse unit per coarse region */\n        if (info == NULL || info->frozen) {\n            coarse_info_t *new_info = coarse_unit_create(start, end,\n                                                         (info == NULL) ? NULL :\n                                                         &info->module_md5,\n                                                         true/*for execution*/);\n            LOG(GLOBAL, LOG_VMAREAS, 1, \"new %scoarse unit %s \"PFX\"-\"PFX\"\\n\",\n                info == NULL ? \"\" : \"secondary \", new_info->module, start, end);\n            if (info == NULL)\n                info = new_info;\n            else\n                info->non_frozen = new_info;\n        }\n        area->custom.client = (void *) info;\n    }\n    DOLOG(2, LOG_VMAREAS, {\n        /* new area could have been split into multiple */\n        print_contig_vm_areas(executable_areas, start, end, GLOBAL, \"new executable vm area: \");\n    });\n}\n\nstatic coarse_info_t *\nvm_area_load_coarse_unit(app_pc *start INOUT, app_pc *end INOUT,\n                         uint vm_flags, uint frag_flags,\n                         bool delayed _IF_DEBUG(const char *comment))\n{\n    coarse_info_t *info;\n    /* We load persisted cache files at mmap time primarily for RCT\n     * tables; but to avoid duplicated code, and for simplicity, we do\n     * so if -use_persisted even if not -use_persisted_rct.\n     */\n    dcontext_t *dcontext = get_thread_private_dcontext();\n    ASSERT_OWN_WRITE_LOCK(true, &executable_areas->lock);\n    /* FIXME: we're called before 1st thread is set up.  Only a problem\n     * right now for rac_entries_resurrect() w/ private after-call\n     * which won't happen w/ -coarse_units that requires shared bbs.\n     */\n    info = coarse_unit_load(dcontext == NULL ? GLOBAL_DCONTEXT : dcontext,\n                            *start, *end, true/*for execution*/);\n    if (info != NULL) {\n        ASSERT(info->base_pc >= *start && info->end_pc <= *end);\n        LOG(GLOBAL, LOG_VMAREAS, 1,\n            \"using persisted coarse unit %s \"PFX\"-\"PFX\" for \"PFX\"-\"PFX\"\\n\",\n            info->module, info->base_pc, info->end_pc, *start, *end);\n        /* Case 8640/9653/8639: adjust region bounds so that a\n         * cache consistency event outside the persisted region\n         * does not invalidate it (mainly targeting loader rebinding).\n         * We count on FRAG_COARSE_GRAIN preventing any merging of regions.\n         * We could delay this until code validation, as RCT tables don't care,\n         * and then we could avoid splitting the region in case validation\n         * fails: but our plan for lazy per-page validation (case 10601)\n         * means we can fail post-split even that way.  So we go ahead and split\n         * up front here.  For 4.4 we should move this to 1st exec.\n         */\n        if (delayed && (info->base_pc > *start || info->end_pc < *end)) {\n            /* we already added a region for the whole range earlier */\n            remove_vm_area(executable_areas, *start, *end, false/*leave writability*/);\n            add_executable_vm_area_helper(info->base_pc, info->end_pc,\n                                          vm_flags, frag_flags, info\n                                          _IF_DEBUG(comment));\n        }\n        if (info->base_pc > *start) {\n            add_executable_vm_area_helper(*start, info->base_pc,\n                                          vm_flags, frag_flags, NULL\n                                          _IF_DEBUG(comment));\n            *start = info->base_pc;\n        }\n        if (info->end_pc < *end) {\n            add_executable_vm_area_helper(info->end_pc, *end,\n                                          vm_flags, frag_flags, NULL\n                                          _IF_DEBUG(comment));\n            *end = info->end_pc;\n        }\n        /* if !delayed we'll add the region for the unit in caller */\n        ASSERT(info->frozen && info->persisted);\n        vm_flags |= VM_PERSISTED_CACHE;\n        /* For 4.4 we would mark as PERSCACHE_CODE_INVALID here and\n         * mark valid only at 1st execution when we do md5 checks;\n         * for 4.3 we're valid until a rebind action.\n         */\n        ASSERT(!TEST(PERSCACHE_CODE_INVALID, info->flags));\n        /* We must add to shared_data, but we cannot here due to lock\n         * rank issues (shared_vm_areas lock is higher rank than\n         * executable_areas, and we have callers doing flushes and\n         * already holding executable_areas), so we delay.\n         */\n        vm_flags |= VM_ADD_TO_SHARED_DATA;\n    }\n    return info;\n}\n\n/* NOTE : caller is responsible for ensuring that consistency conditions are\n * met, thus if the region is writable the caller must either mark it read\n * only or pass in the VM_DELAY_READONLY flag in which case\n * check_thread_vm_area will mark it read only when a thread goes to build a\n * block from the region */\nstatic bool\nadd_executable_vm_area(app_pc start, app_pc end, uint vm_flags, uint frag_flags,\n                       bool have_writelock _IF_DEBUG(const char *comment))\n{\n    vm_area_t *existing_area = NULL;\n    coarse_info_t *info = NULL;\n    coarse_info_t *tofree = NULL;\n    app_pc delay_start = NULL, delay_end = NULL;\n    /* only expect to see the *_READONLY flags on WRITABLE regions */\n    ASSERT(!TEST(VM_DELAY_READONLY, vm_flags) ||\n           TEST(VM_WRITABLE, vm_flags));\n    ASSERT(!TEST(VM_MADE_READONLY, vm_flags) ||\n           TEST(VM_WRITABLE, vm_flags));\n#ifdef DEBUG /* can't use DODEBUG b/c of ifdef inside */\n    {\n        /* we only expect certain flags */\n        uint expect = VM_WRITABLE|VM_UNMOD_IMAGE|VM_MADE_READONLY|\n            VM_DELAY_READONLY|VM_WAS_FUTURE|VM_EXECUTED_FROM|VM_DRIVER_ADDRESS;\n# ifdef PROGRAM_SHEPHERDING\n        expect |= VM_PATTERN_REVERIFY;\n# endif\n        ASSERT(!TESTANY(~expect, vm_flags));\n    }\n#endif /* DEBUG */\n    if (!have_writelock) {\n#ifdef HOT_PATCHING_INTERFACE\n        /* case 9970: need to check hotp vs perscache; rank order hotp < exec_areas */\n        if (DYNAMO_OPTION(hot_patching))\n            read_lock(hotp_get_lock());\n#endif\n        write_lock(&executable_areas->lock);\n    }\n    ASSERT_OWN_WRITE_LOCK(true, &executable_areas->lock);\n    /* FIXME: rather than change all callers who already hold exec_areas lock\n     * to first grab hotp lock, we don't support perscache in those cases.\n     * We expect to only be adding a coarse-grain area for module loads.\n     */\n    ASSERT(!TEST(FRAG_COARSE_GRAIN, frag_flags) || !have_writelock);\n    if (TEST(FRAG_COARSE_GRAIN, frag_flags) && !have_writelock) {\n#ifdef WINDOWS\n        if (!add_executable_vm_area_check_IAT(&start, &end, vm_flags,\n                                              &existing_area, &info, &tofree,\n                                              &delay_start, &delay_end))\n            frag_flags &= ~FRAG_COARSE_GRAIN;\n#else\n        ASSERT(TEST(VM_UNMOD_IMAGE, vm_flags));\n#endif\n        ASSERT(!RUNNING_WITHOUT_CODE_CACHE());\n        if (TEST(FRAG_COARSE_GRAIN, frag_flags) && DYNAMO_OPTION(use_persisted) &&\n            info == NULL\n            /* if clients are present, don't load until after they're initialized */\n            IF_CLIENT_INTERFACE(&& (dynamo_initialized || !CLIENTS_EXIST()))) {\n            info = vm_area_load_coarse_unit(&start, &end, vm_flags, frag_flags, false\n                                            _IF_DEBUG(comment));\n        }\n    }\n\n    if (existing_area == NULL) {\n        add_executable_vm_area_helper(start, end, vm_flags, frag_flags, info\n                                      _IF_DEBUG(comment));\n    } else {\n        /* we shouldn't need the other parts of _helper() */\n        ASSERT(!TEST(VM_WRITABLE, vm_flags));\n#ifdef PROGRAM_SHEPHERDING\n        ASSERT(DYNAMO_OPTION(selfmod_futureexec) ||\n               !TEST(FRAG_SELFMOD_SANDBOXED, frag_flags));\n#endif\n    }\n\n    if (delay_start != NULL) {\n        ASSERT(delay_end > delay_start);\n        add_executable_vm_area_helper(delay_start, delay_end, vm_flags, frag_flags, NULL\n                                      _IF_DEBUG(comment));\n    }\n\n    DOLOG(2, LOG_VMAREAS, {\n        /* new area could have been split into multiple */\n        print_contig_vm_areas(executable_areas, start, end, GLOBAL, \"new executable vm area: \");\n    });\n\n    if (!have_writelock) {\n        write_unlock(&executable_areas->lock);\n#ifdef HOT_PATCHING_INTERFACE\n        if (DYNAMO_OPTION(hot_patching))\n            read_unlock(hotp_get_lock());\n#endif\n    }\n    if (tofree != NULL) {\n        /* Since change_linking_lock and info->lock are higher rank than exec areas we\n         * must free down here.  FIXME: this should move to 1st exec for 4.4.\n         */\n        ASSERT(tofree->non_frozen == NULL);\n        coarse_unit_reset_free(GLOBAL_DCONTEXT, tofree, false/*no locks*/,\n                               true/*unlink*/, true/*give up primary*/);\n        coarse_unit_free(GLOBAL_DCONTEXT, tofree);\n    }\n    return true;\n}\n\n/* Used to add dr allocated memory regions that may execute out of the cache */\n/* NOTE : region is assumed to not be writable, caller is responsible for\n * ensuring this (see fixme in signal.c adding sigreturn code)\n */\nbool\nadd_executable_region(app_pc start, size_t size _IF_DEBUG(const char *comment))\n{\n    return add_executable_vm_area(start, start+size, 0, 0, false/*no lock*/\n                                  _IF_DEBUG(comment));\n}\n\n/* remove an executable area from the area list\n * the caller is responsible for ensuring that all threads' local vm lists\n * are updated by calling flush_fragments_and_remove_region (can't just\n * remove local vm areas and leave existing fragments hanging...)\n */\nstatic bool\nremove_executable_vm_area(app_pc start, app_pc end, bool have_writelock)\n{\n    bool ok;\n    LOG(GLOBAL, LOG_VMAREAS, 2, \"removing executable vm area: \"PFX\"-\"PFX\"\\n\",\n        start, end);\n    if (!have_writelock)\n        write_lock(&executable_areas->lock);\n    ok = remove_vm_area(executable_areas, start, end, true/*restore writability!*/);\n    if (!have_writelock)\n        write_unlock(&executable_areas->lock);\n    return ok;\n}\n\n/* removes a region from the executable list */\n/* NOTE :the caller is responsible for ensuring that all threads' local\n * vm lists are updated by calling flush_fragments_and_remove_region\n */\nbool\nremove_executable_region(app_pc start, size_t size, bool have_writelock)\n{\n    return remove_executable_vm_area(start, start+size, have_writelock);\n}\n\n#ifdef CLIENT_INTERFACE\n/* To give clients a chance to process pcaches as we load them, we\n * delay the loading until we've initialized the clients.\n */\nvoid\nvm_area_delay_load_coarse_units(void)\n{\n    int i;\n    ASSERT(!dynamo_initialized);\n    if (!DYNAMO_OPTION(use_persisted) ||\n        /* we already loaded if there's no client */\n        !CLIENTS_EXIST())\n        return;\n    write_lock(&executable_areas->lock);\n    for (i = 0; i < executable_areas->length; i++) {\n        if (TEST(FRAG_COARSE_GRAIN, executable_areas->buf[i].frag_flags)) {\n            vm_area_t *a = &executable_areas->buf[i];\n            /* store cur_info b/c a might be blown away */\n            coarse_info_t *cur_info = (coarse_info_t *) a->custom.client;\n            if (cur_info == NULL || !cur_info->frozen) {\n                app_pc start = a->start, end = a->end;\n                coarse_info_t *info =\n                    vm_area_load_coarse_unit(&start, &end, a->vm_flags,\n                                             a->frag_flags, true _IF_DEBUG(a->comment));\n                if (info != NULL) {\n                    /* re-acquire a and i */\n                    DEBUG_DECLARE(bool ok = )\n                        binary_search(executable_areas, info->base_pc,\n                                      info->base_pc+1/*open end*/, &a, &i, false);\n                    ASSERT(ok);\n                    if (cur_info != NULL)\n                        info->non_frozen = cur_info;\n                    a->custom.client = (void *) info;\n                }\n            } else\n                ASSERT_NOT_REACHED(); /* shouldn't have been loaded already */\n        }\n    }\n    write_unlock(&executable_areas->lock);\n}\n#endif\n\n/* case 10995: we have to delay freeing un-executed coarse units until\n * we can release the exec areas lock when we flush an un-executed region.\n * This routine frees the queued-up coarse units, and releases the\n * executable areas lock, which the caller must hold.\n */\nbool\nfree_nonexec_coarse_and_unlock()\n{\n    bool freed_any = false;\n    coarse_info_t *info = NULL;\n    coarse_info_t *next_info;\n    /* We must hold the exec areas lock while traversing the to-delete list,\n     * yet we cannot delete while holding it, so we use a temp var\n     */\n    ASSERT_OWN_WRITE_LOCK(true, &executable_areas->lock);\n    ASSERT(coarse_to_delete != NULL);\n    if (coarse_to_delete != NULL/*paranoid*/ && *coarse_to_delete != NULL) {\n        freed_any = true;\n        info = *coarse_to_delete;\n        *coarse_to_delete = NULL;\n    }\n    /* Now we can unlock, and then it's safe to delete */\n    executable_areas_unlock();\n    if (freed_any) {\n        /* units are chained by non_frozen field */\n        while (info != NULL) {\n            next_info = info->non_frozen;\n            if (info->cache != NULL) {\n                ASSERT(info->persisted);\n                /* We shouldn't need to unlink since no execution has occurred\n                 * (lazy linking)\n                 */\n                ASSERT(info->incoming == NULL);\n                ASSERT(!coarse_unit_outgoing_linked(GLOBAL_DCONTEXT, info));\n            }\n            coarse_unit_reset_free(GLOBAL_DCONTEXT, info,\n                                   false/*no locks*/, false/*!unlink*/,\n                                   true/*give up primary*/);\n            coarse_unit_free(GLOBAL_DCONTEXT, info);\n            info = next_info;\n        }\n    }\n    return freed_any;\n}\n\n#ifdef PROGRAM_SHEPHERDING\n/* add a \"future executable area\" (e.g., mapped EW) to the future list\n *\n * FIXME: now that this is vmareas.c-internal we should change it to\n * take in direct VM_ flags, and make separate flags for each future-adding\n * code origins policy.  Then we can have policy-specific removal from future list.\n */\nstatic bool\nadd_futureexec_vm_area(app_pc start, app_pc end, bool once_only\n                       _IF_DEBUG(const char *comment))\n{\n    /* FIXME: don't add portions that overlap w/ exec areas */\n    LOG(GLOBAL, LOG_VMAREAS, 2, \"new FUTURE executable vm area: \"PFX\"-\"PFX\" %s%s\\n\",\n        start, end, (once_only?\"ONCE \":\"\"), comment);\n\n    if (DYNAMO_OPTION(unloaded_target_exception)) {\n        /* case 9371 - to avoid possible misclassification in a tight race\n         * between NtUnmapViewOfSection and a consecutive future area\n         * allocated in the same place, we clear our the unload in progress flag\n         */\n        mark_unload_future_added(start, end - start);\n    }\n\n    write_lock(&futureexec_areas->lock);\n    add_vm_area(futureexec_areas, start, end,\n                (once_only ? VM_ONCE_ONLY : 0),\n                0 /* frag_flags */, NULL _IF_DEBUG(comment));\n    write_unlock(&futureexec_areas->lock);\n    return true;\n}\n\n/* remove a \"future executable area\" from the future list */\nstatic bool\nremove_futureexec_vm_area(app_pc start, app_pc end)\n{\n    bool ok;\n    LOG(GLOBAL, LOG_VMAREAS, 2, \"removing FUTURE executable vm area: \"PFX\"-\"PFX\"\\n\",\n        start, end);\n    write_lock(&futureexec_areas->lock);\n    ok = remove_vm_area(futureexec_areas, start, end, false);\n    write_unlock(&futureexec_areas->lock);\n    return ok;\n}\n\n/* returns true if the passed in area overlaps any known future executable areas */\nstatic bool\nfutureexec_vm_area_overlap(app_pc start, app_pc end)\n{\n    bool overlap;\n    read_lock(&futureexec_areas->lock);\n    overlap = vm_area_overlap(futureexec_areas, start, end);\n    read_unlock(&futureexec_areas->lock);\n    return overlap;\n}\n#endif /* PROGRAM_SHEPHERDING */\n\n/* lookup against the per-process executable addresses map */\nbool\nis_executable_address(app_pc addr)\n{\n    bool found;\n    read_lock(&executable_areas->lock);\n    found = lookup_addr(executable_areas, addr, NULL);\n    read_unlock(&executable_areas->lock);\n    return found;\n}\n\n/* returns any VM_ flags associated with addr's vm area\n * returns 0 if no area is found\n * cf. get_executable_area_flags() for FRAG_ flags\n */\nbool\nget_executable_area_vm_flags(app_pc addr, uint *vm_flags)\n{\n    bool found = false;\n    vm_area_t *area;\n    read_lock(&executable_areas->lock);\n    if (lookup_addr(executable_areas, addr, &area)) {\n        *vm_flags = area->vm_flags;\n        found = true;\n    }\n    read_unlock(&executable_areas->lock);\n    return found;\n}\n\n/* if addr is an executable area, returns true and returns in *flags\n *   any FRAG_ flags associated with addr's vm area\n * returns false if area not found\n *\n * cf. get_executable_area_vm_flags() for VM_ flags\n */\nbool\nget_executable_area_flags(app_pc addr, uint *frag_flags)\n{\n    bool found = false;\n    vm_area_t *area;\n    read_lock(&executable_areas->lock);\n    if (lookup_addr(executable_areas, addr, &area)) {\n        *frag_flags = area->frag_flags;\n        found = true;\n    }\n    read_unlock(&executable_areas->lock);\n    return found;\n}\n\n/* For coarse-grain operation, we use a separate cache and htable per region.\n * See coarse_info_t notes on synchronization model.\n * Returns NULL when region is not coarse.\n * Assumption: this routine is called prior to the first execution from a\n * coarse vm area region.\n */\nstatic coarse_info_t *\nget_coarse_info_internal(app_pc addr, bool init, bool have_shvm_lock)\n{\n    coarse_info_t *coarse = NULL;\n    vm_area_t *area = NULL;\n    vm_area_t area_copy = {0,};\n    bool is_coarse = false;\n    bool add_to_shared = false;\n    bool reset_unit = false;\n    /* FIXME perf opt: have a last_area */\n    /* FIXME: could use vmvector_lookup_data() but I need area->{vm,frag}_flags */\n    read_lock(&executable_areas->lock);\n    if (lookup_addr(executable_areas, addr, &area)) {\n        ASSERT(area != NULL);\n        /* The custom field is initialized to 0 in add_vm_area */\n        coarse = (coarse_info_t *) area->custom.client;\n        is_coarse = TEST(FRAG_COARSE_GRAIN, area->frag_flags);\n        /* We always create coarse_info_t up front in add_executable_vm_area */\n        ASSERT((is_coarse && coarse != NULL) || (!is_coarse && coarse == NULL));\n        if (init && coarse != NULL && TEST(PERSCACHE_CODE_INVALID, coarse->flags)) {\n            /* Reset the unit as the validating event did not occur\n             * (can't do it here due to lock rank order vs exec areas lock) */\n            reset_unit = true;\n            /* We do need to adjust coarse unit bounds for 4.3 when we don't see\n             * the rebind +rx event */\n            adjust_coarse_unit_bounds(area, true/*even if invalid*/);\n            STATS_INC(coarse_executed_invalid);\n            /* FIXME for 4.4: validation won't happen post-rebind like 4.3, so we\n             * will always get here marked as invalid.  Here we'll do full md5\n             * modulo rebasing check (split into per-page via read-only as opt).\n             */\n        }\n        /* We cannot add to shared_data when we load in a persisted unit\n         * due to lock rank issues, so we delay until first asked about.\n         */\n        if (init && TEST(VM_ADD_TO_SHARED_DATA, area->vm_flags)) {\n            add_to_shared = true;\n            area->vm_flags &= ~VM_ADD_TO_SHARED_DATA;\n            area->vm_flags |= VM_EXECUTED_FROM;\n            area_copy = *area;\n        } else {\n            DODEBUG({ area_copy = *area; }); /* for ASSERT below */\n        }\n    }\n    read_unlock(&executable_areas->lock);\n\n    if (coarse != NULL && init) {\n        /* For 4.3, bounds check is done at post-rebind validation;\n         * FIXME: in 4.4, we need to do it here and adjust bounds or invalidate\n         * pcache if not a superset (we'll allow any if_rx_text to merge into coarse).\n         */\n        ASSERT(coarse->base_pc == area_copy.start && coarse->end_pc == area_copy.end);\n        if (reset_unit) {\n            coarse_unit_reset_free(get_thread_private_dcontext(),\n                                   coarse, false/*no locks*/, true/*unlink*/,\n                                   true/*give up primary*/);\n        }\n        if (add_to_shared) {\n            if (!have_shvm_lock)\n                SHARED_VECTOR_RWLOCK(&shared_data->areas, write, lock);\n            ASSERT_VMAREA_VECTOR_PROTECTED(&shared_data->areas, WRITE);\n            /* avoid double-add from a race */\n            if (!lookup_addr(&shared_data->areas, coarse->base_pc, NULL)) {\n                LOG(GLOBAL, LOG_VMAREAS, 2,\n                    \"adding coarse region \"PFX\"-\"PFX\" to shared vm areas\\n\",\n                    area_copy.start, area_copy.end);\n                add_vm_area(&shared_data->areas, area_copy.start, area_copy.end,\n                            area_copy.vm_flags, area_copy.frag_flags, NULL\n                            _IF_DEBUG(area_copy.comment));\n            }\n            if (!have_shvm_lock)\n                SHARED_VECTOR_RWLOCK(&shared_data->areas, write, unlock);\n        }\n    } else\n        ASSERT(!add_to_shared && !reset_unit);\n\n    return coarse;\n}\n\ncoarse_info_t *\nget_executable_area_coarse_info(app_pc addr)\n{\n    return get_coarse_info_internal(addr, true/*init*/, false/*no lock*/);\n}\n\n/* Ensures there is a non-frozen coarse unit for the executable_areas region\n * corresponding to \"frozen\", which is now frozen.\n */\nvoid\nmark_executable_area_coarse_frozen(coarse_info_t *frozen)\n{\n    vm_area_t *area = NULL;\n    coarse_info_t *info;\n    ASSERT(frozen->frozen); /* caller should mark */\n    write_lock(&executable_areas->lock); /* since writing flags */\n    if (lookup_addr(executable_areas, frozen->base_pc, &area)) {\n        ASSERT(area != NULL);\n        /* The custom field is initialized to 0 in add_vm_area */\n        if (area->custom.client != NULL) {\n            ASSERT(TEST(FRAG_COARSE_GRAIN, area->frag_flags));\n            info = (coarse_info_t *) area->custom.client;\n            ASSERT(info == frozen && frozen->non_frozen == NULL);\n            info = coarse_unit_create(frozen->base_pc, frozen->end_pc,\n                                      &frozen->module_md5, true/*for execution*/);\n            LOG(GLOBAL, LOG_VMAREAS, 1,\n                \"new secondary coarse unit %s \"PFX\"-\"PFX\"\\n\",\n                info->module, frozen->base_pc, frozen->end_pc);\n            frozen->non_frozen = info;\n        } else\n            ASSERT(!TEST(FRAG_COARSE_GRAIN, area->frag_flags));\n    }\n    write_unlock(&executable_areas->lock);\n}\n\n/* iterates through all executable areas overlapping the pages touched\n * by the region addr_[start,end)\n * if are_all_matching is false\n *    returns true if any overlapping region has matching vm_flags and frag_flags;\n *    false otherwise\n * if are_all_matching is true\n *    returns true only if all overlapping regions have matching vm_flags\n *    and matching frag_flags, or if there are no overlapping regions;\n *    false otherwise\n * a match of 0 matches all\n */\nstatic bool\nexecutable_areas_match_flags(app_pc addr_start, app_pc addr_end, bool *found_area,\n                             bool are_all_matching /* ALL when true,\n                                                      EXISTS when false */,\n                             uint match_vm_flags, uint match_frag_flags)\n{\n    /* binary search below will assure that we hold an executable_areas lock */\n    app_pc page_start = (app_pc)ALIGN_BACKWARD(addr_start, PAGE_SIZE);\n    app_pc page_end = (app_pc)ALIGN_FORWARD(addr_end, PAGE_SIZE);\n    vm_area_t *area;\n    if (found_area != NULL)\n        *found_area = false;\n    ASSERT(page_start < page_end || page_end == NULL); /* wraparound */\n    /* We have subpage regions from some of our rules, we should return true\n     * if any area on the list that overlaps the pages enclosing the addr_[start,end)\n     * region is writable */\n    while (binary_search(executable_areas, page_start,\n                         page_end, &area, NULL, true)) {\n        if (found_area != NULL)\n            *found_area = true;\n        /* TESTALL will return true for a match of 0 */\n        if (are_all_matching) {\n            if (!TESTALL(match_vm_flags, area->vm_flags) ||\n                !TESTALL(match_frag_flags, area->frag_flags))\n                return false;\n        } else {\n            if (TESTALL(match_vm_flags, area->vm_flags) &&\n                TESTALL(match_frag_flags, area->frag_flags))\n                return true;\n        }\n        if (area->end < page_end || page_end == NULL)\n            page_start = area->end;\n        else\n            break;\n    }\n    return are_all_matching;    /* false for EXISTS, true for ALL */\n}\n\n/* returns true if addr is on a page that was marked writable by the\n * application but that we marked RO b/c it contains executable code\n * does NOT check if addr is executable, only that something on its page is!\n */\nbool\nis_executable_area_writable(app_pc addr)\n{\n    bool writable;\n    read_lock(&executable_areas->lock);\n    writable = executable_areas_match_flags(addr, addr+1 /* open ended */,\n                                            NULL, false /* EXISTS */,\n                                            VM_MADE_READONLY, 0);\n    read_unlock(&executable_areas->lock);\n    return writable;\n}\n\n#if defined(DEBUG) /* since only used for a stat right now */\n/* returns true if region [start, end) overlaps pages that match match_vm_flags\n * e.g. VM_WRITABLE is set when all pages marked writable by the\n *      application but that we marked RO b/c they contain executable code.\n *\n * Does NOT check if region is executable, only that something\n * overlapping its pages is!  are_all_matching determines\n * whether all regions need to match flags, or whether a matching\n * region exists.\n */\nstatic bool\nis_executable_area_writable_overlap(app_pc start, app_pc end,\n                                    bool are_all_matching, uint match_vm_flags)\n{\n    bool writable;\n    read_lock(&executable_areas->lock);\n    writable = executable_areas_match_flags(start, end, NULL,\n                                            are_all_matching, match_vm_flags, 0);\n    read_unlock(&executable_areas->lock);\n    return writable;\n}\n#endif\n\nbool\nis_pretend_or_executable_writable(app_pc addr)\n{\n    /* see if asking about an executable area we made read-only */\n    return (!standalone_library &&\n            (is_executable_area_writable(addr) ||\n             (USING_PRETEND_WRITABLE() &&\n              is_pretend_writable_address(addr))));\n}\n\n/* Returns true if region [start, end) overlaps any regions that are\n * marked as FRAG_COARSE_GRAIN.\n */\nbool\nexecutable_vm_area_coarse_overlap(app_pc start, app_pc end)\n{\n    bool match;\n    read_lock(&executable_areas->lock);\n    match = executable_areas_match_flags(start, end, NULL, false/*exists, not all*/,\n                                         0, FRAG_COARSE_GRAIN);\n    read_unlock(&executable_areas->lock);\n    return match;\n}\n\n/* Returns true if region [start, end) overlaps any regions that are\n * marked as VM_PERSISTED_CACHE.\n */\nbool\nexecutable_vm_area_persisted_overlap(app_pc start, app_pc end)\n{\n    bool match;\n    read_lock(&executable_areas->lock);\n    match = executable_areas_match_flags(start, end, NULL, false/*exists, not all*/,\n                                         VM_PERSISTED_CACHE, 0);\n    read_unlock(&executable_areas->lock);\n    return match;\n}\n\n/* Returns true if any part of region [start, end) has ever been executed from */\nbool\nexecutable_vm_area_executed_from(app_pc start, app_pc end)\n{\n    bool match;\n    read_lock(&executable_areas->lock);\n    match = executable_areas_match_flags(start, end, NULL, false/*exists, not all*/,\n                                         VM_EXECUTED_FROM, 0);\n    read_unlock(&executable_areas->lock);\n    return match;\n}\n\n/* If there is no overlap between executable_areas and [start,end), returns false.\n * Else, returns true and sets [overlap_start,overlap_end) as the bounds of the first\n * and last executable_area regions that overlap [start,end); i.e.,\n *   overlap_start starts the first area that overlaps [start,end);\n *   overlap_end ends the last area that overlaps [start,end).\n * Note that overlap_start may be > start and overlap_end may be < end.\n *\n * If frag_flags != 0, the region described above is expanded such that the regions\n * before and after [overlap_start,overlap_end) do NOT match\n * [overlap_start,overlap_end) in TESTALL of frag_flags, but only considering\n * non-contiguous regions if !contig.\n * For example, we pass in FRAG_COARSE_GRAIN and contig=true; then, if\n * the overlap_start region is FRAG_COARSE_GRAIN and it has a contiguous region\n * to its left that is also FRAG_COARSE_GRAIN, but beyond that there is no\n * contiguous region, we will return the start of the region to the left rather than\n * the regular overlap_start.\n */\nbool\nexecutable_area_overlap_bounds(app_pc start, app_pc end,\n                               app_pc *overlap_start/*OUT*/, app_pc *overlap_end/*OUT*/,\n                               uint frag_flags, bool contig)\n{\n    int start_index, end_index; /* must be signed */\n    int i; /* must be signed */\n    ASSERT(overlap_start != NULL && overlap_end != NULL);\n    read_lock(&executable_areas->lock);\n\n    /* Find first overlapping region */\n    if (!binary_search(executable_areas, start, end, NULL, &start_index, true/*first*/))\n        return false;\n    ASSERT(start_index >= 0);\n    if (frag_flags != 0) {\n        for (i = start_index - 1; i >= 0; i--) {\n            if ((contig &&\n                 executable_areas->buf[i].end != executable_areas->buf[i+1].start) ||\n                (TESTALL(frag_flags, executable_areas->buf[i].frag_flags) !=\n                 TESTALL(frag_flags, executable_areas->buf[start_index].frag_flags)))\n                break;\n        }\n        ASSERT(i + 1 >= 0);\n        *overlap_start = executable_areas->buf[i + 1].start;\n    } else\n        *overlap_start = executable_areas->buf[start_index].start;\n\n    /* Now find region just at or before end */\n    binary_search(executable_areas, end-1, end, NULL, &end_index, true/*first*/);\n    ASSERT(end_index >= 0); /* else 1st binary search would have failed */\n    ASSERT(end_index >= start_index);\n    if (end_index < executable_areas->length - 1 && frag_flags != 0) {\n        for (i = end_index + 1; i < executable_areas->length; i++) {\n            if ((contig &&\n                 executable_areas->buf[i].start != executable_areas->buf[i-1].end) ||\n                (TESTALL(frag_flags, executable_areas->buf[i].frag_flags) !=\n                 TESTALL(frag_flags, executable_areas->buf[end_index].frag_flags)))\n                break;\n        }\n        ASSERT(i - 1 < executable_areas->length);\n        *overlap_end = executable_areas->buf[i - 1].end;\n    } else /* no extension asked for, or nowhere to extend to */\n        *overlap_end = executable_areas->buf[end_index].end;\n\n    read_unlock(&executable_areas->lock);\n    return true;\n}\n\n/***************************************************\n * Iterator over coarse units in executable_areas that overlap [start,end) */\nvoid\nvm_area_coarse_iter_start(vmvector_iterator_t *vmvi, app_pc start)\n{\n    int start_index; /* must be signed */\n    ASSERT(vmvi != NULL);\n    vmvector_iterator_start(executable_areas, vmvi);\n    ASSERT_OWN_READ_LOCK(true, &executable_areas->lock);\n    /* Find first overlapping region */\n    if (start != NULL &&\n        binary_search(executable_areas, start, start+1, NULL,\n                      &start_index, true/*first*/)) {\n        ASSERT(start_index >= 0);\n        vmvi->index = start_index - 1 /*since next is +1*/;\n    }\n}\nstatic bool\nvm_area_coarse_iter_find_next(vmvector_iterator_t *vmvi, app_pc end, bool mutate,\n                              coarse_info_t **info_out/*OUT*/)\n{\n    int forw;\n    ASSERT_VMAREA_VECTOR_PROTECTED(vmvi->vector, READWRITE);\n    ASSERT(vmvi->vector == executable_areas);\n    for (forw = 1; vmvi->index + forw < vmvi->vector->length; forw++) {\n        if (end != NULL && executable_areas->buf[vmvi->index+forw].start >= end)\n            break;\n        if (TEST(FRAG_COARSE_GRAIN,\n                 executable_areas->buf[vmvi->index+forw].frag_flags)) {\n            coarse_info_t *info = executable_areas->buf[vmvi->index+forw].custom.client;\n            if (mutate)\n                vmvi->index = vmvi->index+forw;\n            ASSERT(info != NULL); /* we always allocate up front */\n            if (info_out != NULL)\n                *info_out = info;\n            return true;\n        }\n    }\n    return false;\n}\nbool\nvm_area_coarse_iter_hasnext(vmvector_iterator_t *vmvi, app_pc end)\n{\n    return vm_area_coarse_iter_find_next(vmvi, end, false/*no mutate*/, NULL);\n}\n/* May want to return region bounds if have callers who care about that. */\ncoarse_info_t *\nvm_area_coarse_iter_next(vmvector_iterator_t *vmvi, app_pc end)\n{\n    coarse_info_t *info = NULL;\n    vm_area_coarse_iter_find_next(vmvi, end, true/*mutate*/, &info);\n    return info;\n}\nvoid\nvm_area_coarse_iter_stop(vmvector_iterator_t *vmvi)\n{\n    ASSERT(vmvi->vector == executable_areas);\n    vmvector_iterator_stop(vmvi);\n}\n/***************************************************/\n\n/* returns true if addr is on a page that contains at least one selfmod\n * region and no non-selfmod regions.\n */\nbool\nis_executable_area_on_all_selfmod_pages(app_pc start, app_pc end)\n{\n    bool all_selfmod;\n    bool found;\n    read_lock(&executable_areas->lock);\n    all_selfmod = executable_areas_match_flags(start, end,\n                                               &found, true /* ALL */,\n                                               0, FRAG_SELFMOD_SANDBOXED);\n    read_unlock(&executable_areas->lock);\n    /* we require at least one area to be present */\n    return all_selfmod && found;\n}\n\n/* Meant to be called from a seg fault handler.\n * Returns true if addr is on a page that was marked writable by the\n * application but that we marked RO b/c it contains executable code, OR if\n * addr is on a writable page (since another thread could have removed addr\n * from exec list before seg fault handler was scheduled).\n * does NOT check if addr is executable, only that something on its page is!\n */\nbool\nwas_executable_area_writable(app_pc addr)\n{\n    bool found_area = false, was_writable = false;\n    read_lock(&executable_areas->lock);\n    was_writable = executable_areas_match_flags(addr, addr+1, &found_area,\n                                                false /* EXISTS */,\n                                                VM_MADE_READONLY, 0);\n    /* seg fault could have happened, then area was made writable before\n     * thread w/ exception was scheduled.\n     * we assume that area was writable at time of seg fault if it's\n     * exec writable now (above) OR no area was found and it's writable now\n     * and not on DR area list (below).\n     * Need to check DR area list since a write to protected DR area from code\n     * cache can end up here, as DR area may be made writable once in fault handler\n     * due to self-protection un-protection for entering DR!\n     * FIXME: checking for threads_ever_created==1 could further rule out other\n     * causes for some apps.\n     * Keep readlock to avoid races.\n     */\n    if (!found_area) {\n        uint prot;\n        if (get_memory_info(addr, NULL, NULL, &prot))\n            was_writable = TEST(MEMPROT_WRITE, prot) && !is_dynamo_address(addr);\n    }\n    read_unlock(&executable_areas->lock);\n    return was_writable;\n}\n\n/* returns true if addr is in an executable area that contains\n * self-modifying code, and so should be sandboxed\n */\nbool\nis_executable_area_selfmod(app_pc addr)\n{\n    uint flags;\n    if (get_executable_area_flags(addr, &flags))\n        return TEST(FRAG_SELFMOD_SANDBOXED, flags);\n    else\n        return false;\n}\n\n#ifdef DGC_DIAGNOSTICS\n/* returns false if addr is not in an executable area marked as dyngen */\nbool\nis_executable_area_dyngen(app_pc addr)\n{\n    uint flags;\n    if (get_executable_area_flags(addr, &flags))\n        return TEST(FRAG_DYNGEN, flags);\n    else\n        return false;\n}\n#endif\n\n/* lookup against the per-process addresses map */\nbool\nis_valid_address(app_pc addr)\n{\n    ASSERT_NOT_IMPLEMENTED(false && \"is_valid_address not implemented\");\n    return false;\n}\n\n/* Due to circular dependencies bet vmareas and global heap, we cannot\n * incrementally keep dynamo_areas up to date.\n * Instead, we wait until people ask about it, when we do a complete\n * walk through the heap units and add them all (yes, re-adding\n * ones we've seen).\n */\nstatic void\nupdate_dynamo_vm_areas(bool have_writelock)\n{\n    if (dynamo_areas_uptodate)\n        return;\n    if (!have_writelock)\n        dynamo_vm_areas_lock();\n    ASSERT(dynamo_areas != NULL);\n    ASSERT_OWN_WRITE_LOCK(true, &dynamo_areas->lock);\n    /* avoid uptodate asserts from heap needed inside add_vm_area */\n    DODEBUG({ dynamo_areas_synching = true; });\n    /* check again with lock, and repeat until done since\n     * could require more memory in the middle for vm area vector\n     */\n    while (!dynamo_areas_uptodate) {\n        dynamo_areas_uptodate = true;\n        heap_vmareas_synch_units();\n        LOG(GLOBAL, LOG_VMAREAS, 3, \"after updating dynamo vm areas:\\n\");\n        DOLOG(3, LOG_VMAREAS, { print_vm_areas(dynamo_areas, GLOBAL); });\n    }\n    DODEBUG({ dynamo_areas_synching = false; });\n    if (!have_writelock)\n        dynamo_vm_areas_unlock();\n}\n\nbool\nare_dynamo_vm_areas_stale(void)\n{\n    return !dynamo_areas_uptodate;\n}\n\n/* Used for DR heap area changes as circular dependences prevent\n * directly adding or removing DR vm areas->\n * Must hold the DR areas lock across the combination of calling this and\n * modifying the heap lists.\n */\nvoid\nmark_dynamo_vm_areas_stale()\n{\n    /* ok to ask for locks or mark stale before dynamo_areas is allocated */\n    ASSERT((dynamo_areas == NULL && get_num_threads() <= 1 /*must be only DR thread*/)\n           || self_owns_write_lock(&dynamo_areas->lock));\n    dynamo_areas_uptodate = false;\n}\n\n/* HACK to get recursive write lock for internal and external use */\nvoid\ndynamo_vm_areas_lock()\n{\n    all_memory_areas_lock();\n    /* ok to ask for locks or mark stale before dynamo_areas is allocated,\n     * during heap init and before we can allocate it.  no lock needed then.\n     */\n    ASSERT(dynamo_areas != NULL || get_num_threads() <= 1 /*must be only DR thread*/);\n    if (dynamo_areas == NULL)\n        return;\n    if (self_owns_write_lock(&dynamo_areas->lock)) {\n        dynamo_areas_recursion++;\n        /* we have a 5-deep path:\n         *   global_heap_alloc | heap_create_unit | get_guarded_real_memory |\n         *   heap_low_on_memory | release_guarded_real_memory\n         */\n        ASSERT_CURIOSITY(dynamo_areas_recursion <= 4);\n    } else\n        write_lock(&dynamo_areas->lock);\n}\n\nvoid\ndynamo_vm_areas_unlock()\n{\n    /* ok to ask for locks or mark stale before dynamo_areas is allocated,\n     * during heap init and before we can allocate it.  no lock needed then.\n     */\n    ASSERT(dynamo_areas != NULL || get_num_threads() <= 1 /*must be only DR thread*/);\n    if (dynamo_areas == NULL)\n        return;\n    if (dynamo_areas_recursion > 0) {\n        ASSERT_OWN_WRITE_LOCK(true, &dynamo_areas->lock);\n        dynamo_areas_recursion--;\n    } else\n        write_unlock(&dynamo_areas->lock);\n    all_memory_areas_unlock();\n}\n\nbool\nself_owns_dynamo_vm_area_lock()\n{\n    /* heap inits before dynamo_areas (which now needs heap to init) so\n     * we ignore the lock prior to dynamo_areas init, assuming single-DR-thread.\n     */\n    ASSERT(dynamo_areas != NULL || get_num_threads() <= 1 /*must be only DR thread*/);\n    return dynamo_areas == NULL || self_owns_write_lock(&dynamo_areas->lock);\n}\n\n/* grabs read lock and checks for update -- when it returns it guarantees\n * to hold read lock with no updates pending\n */\nstatic void\ndynamo_vm_areas_start_reading()\n{\n    read_lock(&dynamo_areas->lock);\n    while (!dynamo_areas_uptodate) {\n        /* switch to write lock\n         * cannot rely on uptodate value prior to a lock so must\n         * grab read and then check it, and back out if necessary\n         * as we have no reader->writer transition\n         */\n        read_unlock(&dynamo_areas->lock);\n        dynamo_vm_areas_lock();\n        update_dynamo_vm_areas(true);\n        /* FIXME: more efficient if we could safely drop from write to read\n         * lock -- could simply reverse order here and then while becomes if,\n         * but a little fragile in that properly nested rwlocks may be assumed\n         * elsewhere\n         */\n        dynamo_vm_areas_unlock();\n        read_lock(&dynamo_areas->lock);\n    }\n}\n\nstatic void\ndynamo_vm_areas_done_reading()\n{\n    read_unlock(&dynamo_areas->lock);\n}\n\n/* add dynamo-internal area to the dynamo-internal area list\n * this should be atomic wrt the memory being allocated to avoid races\n * w/ the app executing from it -- thus caller must hold DR areas write lock!\n */\nbool\nadd_dynamo_vm_area(app_pc start, app_pc end, uint prot, bool unmod_image\n                   _IF_DEBUG(const char *comment))\n{\n    uint vm_flags = (TEST(MEMPROT_WRITE, prot) ? VM_WRITABLE : 0) |\n                    (unmod_image ? VM_UNMOD_IMAGE : 0);\n    /* case 3045: areas inside the vmheap reservation are not added to the list */\n    ASSERT(!is_vmm_reserved_address(start, end - start));\n    LOG(GLOBAL, LOG_VMAREAS, 2, \"new dynamo vm area: \"PFX\"-\"PFX\" %s\\n\",\n        start, end, comment);\n    ASSERT(dynamo_areas != NULL);\n    ASSERT_OWN_WRITE_LOCK(true, &dynamo_areas->lock);\n    if (!dynamo_areas_uptodate)\n        update_dynamo_vm_areas(true);\n    ASSERT(!vm_area_overlap(dynamo_areas, start, end));\n    add_vm_area(dynamo_areas, start, end, vm_flags, 0 /* frag_flags */,\n                NULL _IF_DEBUG(comment));\n    update_all_memory_areas(start, end, prot,\n                            unmod_image ? DR_MEMTYPE_IMAGE : DR_MEMTYPE_DATA);\n    return true;\n}\n\n/* remove dynamo-internal area from the dynamo-internal area list\n * this should be atomic wrt the memory being freed to avoid races\n * w/ it being re-used and problems w/ the app executing from it --\n * thus caller must hold DR areas write lock!\n */\nbool\nremove_dynamo_vm_area(app_pc start, app_pc end)\n{\n    bool ok;\n    DEBUG_DECLARE(bool removed);\n    LOG(GLOBAL, LOG_VMAREAS, 2, \"removing dynamo vm area: \"PFX\"-\"PFX\"\\n\",\n        start, end);\n    ASSERT(dynamo_areas != NULL);\n    ASSERT_OWN_WRITE_LOCK(true, &dynamo_areas->lock);\n    if (!dynamo_areas_uptodate)\n        update_dynamo_vm_areas(true);\n    ok = remove_vm_area(dynamo_areas, start, end, false);\n    DEBUG_DECLARE(removed = )\n        remove_from_all_memory_areas(start, end);\n    ASSERT(removed);\n    return ok;\n}\n\n/* adds dynamo-internal area to the dynamo-internal area list, but\n * doesn't grab the dynamo areas lock.  intended to be only used for\n * heap walk updates, where the lock is grabbed prior to the walk and held\n * throughout the entire walk.\n */\nbool\nadd_dynamo_heap_vm_area(app_pc start, app_pc end, bool writable, bool unmod_image\n                        _IF_DEBUG(const char *comment))\n{\n    LOG(GLOBAL, LOG_VMAREAS, 2, \"new dynamo vm area: \"PFX\"-\"PFX\" %s\\n\",\n        start, end, comment);\n    ASSERT(!vm_area_overlap(dynamo_areas, start, end));\n    /* case 3045: areas inside the vmheap reservation are not added to the list */\n    ASSERT(!is_vmm_reserved_address(start, end - start));\n    /* add_vm_area will assert that write lock is held */\n    add_vm_area(dynamo_areas, start, end,\n                VM_DR_HEAP |\n                (writable ? VM_WRITABLE : 0) |\n                (unmod_image ? VM_UNMOD_IMAGE : 0),\n                0 /* frag_flags */, NULL _IF_DEBUG(comment));\n    return true;\n}\n\n/* breaking most abstractions here we return whether current vmarea\n * vector starts at given heap_pc.  The price of circular dependency\n * is that abstractions can no longer be safely used.  case 4196\n */\nbool\nis_dynamo_area_buffer(byte *heap_unit_start_pc)\n{\n    return (void*)heap_unit_start_pc == dynamo_areas->buf;\n}\n\n/* assumes caller holds dynamo_areas->lock */\nvoid\nremove_dynamo_heap_areas()\n{\n    int i;\n    /* remove_vm_area will assert that write lock is held, but let's make\n     * sure we're holding it as we walk the vector, even if make no removals\n     */\n    ASSERT_VMAREA_VECTOR_PROTECTED(dynamo_areas, WRITE);\n    LOG(GLOBAL, LOG_VMAREAS, 4, \"remove_dynamo_heap_areas:\\n\");\n    /* walk backwards to avoid O(n^2) */\n    for (i = dynamo_areas->length - 1; i >= 0; i--) {\n        if (TEST(VM_DR_HEAP, dynamo_areas->buf[i].vm_flags)) {\n            app_pc start = dynamo_areas->buf[i].start;\n            app_pc end = dynamo_areas->buf[i].end;\n            /* ASSUMPTION: remove_vm_area, given exact bounds, simply shifts later\n             * areas down in vector!\n             */\n            LOG(GLOBAL, LOG_VMAREAS, 4, \"Before removing vm area:\\n\");\n            DOLOG(3, LOG_VMAREAS, { print_vm_areas(dynamo_areas, GLOBAL); });\n            remove_vm_area(dynamo_areas, start, end, false);\n            LOG(GLOBAL, LOG_VMAREAS, 4, \"After removing vm area:\\n\");\n            DOLOG(3, LOG_VMAREAS, { print_vm_areas(dynamo_areas, GLOBAL); });\n            remove_from_all_memory_areas(start, end);\n        }\n    }\n}\n\nbool\nis_dynamo_address(app_pc addr)\n{\n    bool found;\n    /* case 3045: areas inside the vmheap reservation are not added to the list */\n    if (is_vmm_reserved_address(addr, 1))\n        return true;\n    dynamo_vm_areas_start_reading();\n    found = lookup_addr(dynamo_areas, addr, NULL);\n    dynamo_vm_areas_done_reading();\n    return found;\n}\n\n/* returns true iff address is an address that the app thinks is writable\n * but really is not, as it overlaps DR memory (or did at the prot time);\n * or we're preventing function patching in specified application modules.\n */\nbool\nis_pretend_writable_address(app_pc addr)\n{\n    bool found;\n    ASSERT(DYNAMO_OPTION(handle_DR_modify) == DR_MODIFY_NOP ||\n           DYNAMO_OPTION(handle_ntdll_modify) == DR_MODIFY_NOP\n           || !IS_STRING_OPTION_EMPTY(patch_proof_list)\n           || !IS_STRING_OPTION_EMPTY(patch_proof_default_list));\n    read_lock(&pretend_writable_areas->lock);\n    found = lookup_addr(pretend_writable_areas, addr, NULL);\n    read_unlock(&pretend_writable_areas->lock);\n    return found;\n}\n\n/* returns true if the passed in area overlaps any known pretend writable areas */\nstatic bool\npretend_writable_vm_area_overlap(app_pc start, app_pc end)\n{\n    bool overlap;\n    read_lock(&pretend_writable_areas->lock);\n    overlap = vm_area_overlap(pretend_writable_areas, start, end);\n    read_unlock(&pretend_writable_areas->lock);\n    return overlap;\n}\n\n#ifdef DEBUG\n/* returns comment for addr, if there is one, else NULL\n */\nchar *\nget_address_comment(app_pc addr)\n{\n    char *res = NULL;\n    vm_area_t *area;\n    bool ok;\n    read_lock(&executable_areas->lock);\n    ok = lookup_addr(executable_areas, addr, &area);\n    if (ok)\n        res = area->comment;\n    read_unlock(&executable_areas->lock);\n    if (!ok) {\n        read_lock(&dynamo_areas->lock);\n        ok = lookup_addr(dynamo_areas, addr, &area);\n        if (ok)\n            res = area->comment;\n        read_unlock(&dynamo_areas->lock);\n    }\n    return res;\n}\n#endif\n\n/* returns true if the passed in area overlaps any known executable areas\n * if !have_writelock, acquires the executable_areas read lock\n */\nbool\nexecutable_vm_area_overlap(app_pc start, app_pc end, bool have_writelock)\n{\n    bool overlap;\n    if (!have_writelock)\n        read_lock(&executable_areas->lock);\n    overlap = vm_area_overlap(executable_areas, start, end);\n    if (!have_writelock)\n        read_unlock(&executable_areas->lock);\n    return overlap;\n}\n\nvoid\nexecutable_areas_lock()\n{\n    write_lock(&executable_areas->lock);\n}\n\nvoid\nexecutable_areas_unlock()\n{\n    ASSERT_OWN_WRITE_LOCK(true, &executable_areas->lock);\n    write_unlock(&executable_areas->lock);\n}\n\n/* returns true if the passed in area overlaps any dynamo areas */\nbool\ndynamo_vm_area_overlap(app_pc start, app_pc end)\n{\n    bool overlap;\n    /* case 3045: areas inside the vmheap reservation are not added to the list */\n    if (is_vmm_reserved_address(start, end - start))\n        return true;\n    dynamo_vm_areas_start_reading();\n    overlap = vm_area_overlap(dynamo_areas, start, end);\n    dynamo_vm_areas_done_reading();\n    return overlap;\n}\n\n/* Checks to see if pc is on the stack\n * If pc has already been resolved into an area, pass that in.\n */\nstatic bool\nis_on_stack(dcontext_t *dcontext, app_pc pc, vm_area_t *area)\n{\n    byte *stack_base, *stack_top; /* \"official\" stack */\n    byte *esp = (byte *) get_mcontext(dcontext)->xsp;\n    byte *esp_base;\n    size_t size;\n    bool ok, query_esp = true;\n    /* First check the area if we're supplied one. */\n    if (area != NULL) {\n        LOG(THREAD, LOG_VMAREAS, 3,\n            \"stack vs \"PFX\": area \"PFX\"..\"PFX\", esp \"PFX\"\\n\",\n            pc, area->start, area->end, esp);\n        ASSERT(pc >= area->start && pc < area->end);\n        if (esp >= area->start && esp < area->end)\n            return true;\n    }\n    /* Now check the \"official\" stack bounds.  These are cached so cheap to\n     * look up.  Xref case 8180, these might not always be available,\n     * get_stack_bounds() takes care of any asserts on availability. */\n    ok = get_stack_bounds(dcontext, &stack_base, &stack_top);\n    if (ok) {\n        LOG(THREAD, LOG_VMAREAS, 3,\n            \"stack vs \"PFX\": official \"PFX\"..\"PFX\", esp \"PFX\"\\n\",\n            pc, stack_base, stack_top, esp);\n        ASSERT(stack_base < stack_top);\n        if (pc >= stack_base && pc < stack_top)\n            return true;\n        /* We optimize away the expensive query of esp region bounds if esp\n         * is in within the \"official\" stack cached allocation bounds. */\n        if (esp >= stack_base && esp < stack_top)\n            query_esp = false;\n    }\n    if (query_esp) {\n        ok = get_memory_info(esp, &esp_base, &size, NULL);\n        ASSERT(ok);\n        LOG(THREAD, LOG_VMAREAS, 3,\n            \"stack vs \"PFX\": region \"PFX\"..\"PFX\", esp \"PFX\"\\n\",\n            pc, esp_base, esp_base+size, esp);\n        /* FIXME - stack could be split into multiple os regions by prot\n         * differences, could check alloc base equivalence. */\n        if (pc >= esp_base && pc < esp_base + size)\n            return true;\n    }\n    return false;\n}\n\nbool\nis_address_on_stack(dcontext_t *dcontext, app_pc address)\n{\n    return is_on_stack(dcontext, address, NULL);\n}\n\n/* returns true if an executable area exists with VM_DRIVER_ADDRESS,\n * not a strict opposite of is_user_address() */\nbool\nis_driver_address(app_pc addr)\n{\n    uint vm_flags;\n    if (get_executable_area_vm_flags(addr, &vm_flags)) {\n        return TEST(VM_DRIVER_ADDRESS, vm_flags);\n    }\n    return false;\n}\n\n#ifdef PROGRAM_SHEPHERDING /********************************************/\n\n/* forward declaration */\nstatic int\ncheck_origins_bb_pattern(dcontext_t *dcontext, app_pc addr, app_pc *base, size_t *size,\n                         uint *vm_flags, uint *frag_flags);\n\n/* The following two arrays need to be in synch with enum action_type_t defined in\n * vmareas.h.\n */\n#define MESSAGE_EXEC_VIOLATION \"Execution security violation was intercepted!\\n\"\n#define MESSAGE_CONTACT_VENDOR \"Contact your vendor for a security vulnerability fix.\\n\"\nconst char * const action_message[] = {\n    /* no trailing newlines for SYSLOG_INTERNAL */\n    MESSAGE_EXEC_VIOLATION MESSAGE_CONTACT_VENDOR \"Program terminated.\",\n    MESSAGE_EXEC_VIOLATION MESSAGE_CONTACT_VENDOR \"Program continuing!\",\n    MESSAGE_EXEC_VIOLATION MESSAGE_CONTACT_VENDOR \"Program continuing after terminating thread.\",\n    MESSAGE_EXEC_VIOLATION MESSAGE_CONTACT_VENDOR \"Program continuing after throwing an exception.\"\n};\n\n/* event log message IDs */\n#ifdef WINDOWS\nconst uint action_event_id[] = {\n    MSG_SEC_VIOLATION_TERMINATED,\n    MSG_SEC_VIOLATION_CONTINUE,\n    MSG_SEC_VIOLATION_THREAD,\n    MSG_SEC_VIOLATION_EXCEPTION,\n# ifdef HOT_PATCHING_INTERFACE\n    MSG_HOT_PATCH_VIOLATION,\n# endif\n};\n#endif\n\n/* fills the target component of a threat ID */\nstatic void\nfill_security_violation_target(char name[MAXIMUM_VIOLATION_NAME_LENGTH],\n                               const byte target_contents[4])\n{\n    int i;\n    for (i = 0; i < 4; i++)\n        name[i + 5] = (char) ((target_contents[i] % 10) + '0');\n}\n\nstatic void\nget_security_violation_name(dcontext_t *dcontext,\n                            app_pc addr, char *name, int name_length,\n                            security_violation_t violation_type,\n                            const char *threat_id)\n{\n    ptr_uint_t addr_as_int;\n    app_pc name_addr = NULL;\n    int i;\n\n    ASSERT(name_length >= MAXIMUM_VIOLATION_NAME_LENGTH);\n\n    /* Hot patches & process_control use their own threat IDs. */\n    if (IF_HOTP(violation_type == HOT_PATCH_DETECTOR_VIOLATION ||\n                violation_type == HOT_PATCH_PROTECTOR_VIOLATION ||)\n        IF_PROC_CTL(violation_type == PROCESS_CONTROL_VIOLATION ||) false) {\n        ASSERT(threat_id != NULL);\n        strncpy(name, threat_id, MAXIMUM_VIOLATION_NAME_LENGTH);\n    } else {\n        bool unreadable_addr = false;\n        byte target_contents[4];    /* 4 instruction bytes read from target */\n        ASSERT(threat_id == NULL);  /* Supplied only for hot patch violations.*/\n\n        /* First four characters are alphabetics calculated from the address\n           of the beginning of the basic block from which the violating\n           contol transfer instruction originated.  Ideally we would use the\n           exact CTI address rather than the beginning of its block, but\n           we don't want to translate it back to an app address to reduce\n           possible failure points on this critical path. */\n        name_addr = dcontext->last_fragment->tag;\n#ifdef WINDOWS\n        /* Move PC relative to preferred base for consistent naming */\n        name_addr += get_module_preferred_base_delta(name_addr);\n#endif\n        addr_as_int = (ptr_uint_t) name_addr;\n        for (i = 0; i < 4; i++) {\n            name[i] = (char) ((addr_as_int % 26) + 'A');\n            addr_as_int /= 256;\n        }\n\n        /* Fifth character is a '.' */\n        name[4] = '.';\n\n        unreadable_addr = !safe_read(addr,\n                                     sizeof(target_contents), &target_contents);\n\n        /* if at unreadable memory see if an ASLR preferred address can be used */\n        if (unreadable_addr) {\n            app_pc likely_target_pc =\n                aslr_possible_preferred_address(addr);\n            if (likely_target_pc != NULL) {\n                unreadable_addr =\n                    !safe_read(likely_target_pc,\n                               sizeof(target_contents), &target_contents);\n            } else {\n                unreadable_addr = true;\n            }\n        }\n\n        /* Next four characters are decimal numerics from the target code */\n        if (unreadable_addr) {\n            for (i = 0; i < 4; i++)\n                name[i + 5] = 'X';\n        } else {\n            fill_security_violation_target(name, target_contents);\n        }\n    }\n\n    /* Tenth character is a '.' */\n    name[9] = '.';\n\n    /* Next character indicates the security violation type;\n     * sequential letter choices used rather than semantic ones to\n     * obfuscate meaning.   */\n    switch (violation_type) {\n    case STACK_EXECUTION_VIOLATION:    name[10] = 'A'; break;\n    case HEAP_EXECUTION_VIOLATION:     name[10] = 'B'; break;\n    case RETURN_TARGET_VIOLATION:      name[10] = 'C'; break;\n    case RETURN_DIRECT_RCT_VIOLATION:  name[10] = 'D'; ASSERT_NOT_IMPLEMENTED(false); break;\n    case INDIRECT_CALL_RCT_VIOLATION:  name[10] = 'E'; break;\n    case INDIRECT_JUMP_RCT_VIOLATION:  name[10] = 'F'; break;\n#ifdef HOT_PATCHING_INTERFACE\n    case HOT_PATCH_DETECTOR_VIOLATION: name[10] = 'H'; break;\n    case HOT_PATCH_PROTECTOR_VIOLATION:name[10] = 'P'; break;\n#endif\n#ifdef PROCESS_CONTROL\n    case PROCESS_CONTROL_VIOLATION:    name[10] = 'K'; break;\n#endif\n#ifdef GBOP\n    case GBOP_SOURCE_VIOLATION:        name[10] = 'O'; break;\n#endif\n    case ASLR_TARGET_VIOLATION:        name[10] = 'R'; break;\n    case ATTACK_SIM_NUDGE_VIOLATION: /* share w/ normal attack sim */\n    case ATTACK_SIMULATION_VIOLATION:  name[10] = 'S'; break;\n    case APC_THREAD_SHELLCODE_VIOLATION:\n        /* injected shellcode threat names are custom generated */\n        ASSERT_NOT_REACHED();\n        name[10] = 'B';\n        break;\n    default:\n        name[10] = 'X';\n        ASSERT_NOT_REACHED();\n    }\n\n    /* Null-terminate */\n    name[11] = '\\0';\n\n    LOG(GLOBAL, LOG_ALL, 1, \"Security violation name: %s\\n\", name);\n}\n\n\nbool\nis_exempt_threat_name(const char *name)\n{\n    if (DYNAMO_OPTION(exempt_threat) &&\n        !IS_STRING_OPTION_EMPTY(exempt_threat_list)) {\n        bool onlist;\n        string_option_read_lock();\n        onlist = check_filter_with_wildcards(DYNAMO_OPTION(exempt_threat_list), name);\n        string_option_read_unlock();\n        if (onlist) {\n            LOG(THREAD_GET, LOG_INTERP|LOG_VMAREAS, 1,\n                \"WARNING: threat %s is on exempt list, suppressing violation\\n\", name);\n            SYSLOG_INTERNAL_WARNING_ONCE(\"threat %s exempt\", name);\n            STATS_INC(num_exempt_threat);\n            return true;\n        }\n    }\n    return false;\n}\n\n/***************************************************************************\n * Case 8075: we don't want to unprotect .data during violation reporting, so we\n * place all the local-scope static vars (from DO_THRESHOLD) into .fspdata.\n */\nSTART_DATA_SECTION(FREQ_PROTECTED_SECTION, \"w\");\n\n/* Report security violation to all outputs - syslog, diagnostics, and interactive\n * returns false if violation was not reported\n */\nstatic bool\nsecurity_violation_report(app_pc addr, security_violation_t violation_type,\n                          const char *name, action_type_t action)\n{\n    bool dump_forensics = true;\n    /* shouldn't report anything if on silent_block_threat_list */\n    if (!IS_STRING_OPTION_EMPTY(silent_block_threat_list)) {\n        bool onlist;\n        string_option_read_lock();\n        onlist = check_filter_with_wildcards(DYNAMO_OPTION(silent_block_threat_list), name);\n        string_option_read_unlock();\n        if (onlist) {\n            LOG(THREAD_GET, LOG_INTERP|LOG_VMAREAS, 1,\n                \"WARNING: threat %s is on silent block list, suppressing reporting\\n\", name);\n            SYSLOG_INTERNAL_WARNING_ONCE(\"threat %s silently blocked\", name);\n            STATS_INC(num_silently_blocked_threat);\n            return false;\n        }\n    }\n\n    if (dynamo_options.report_max) {\n        /* need bool since ctr only inc-ed when < threshold, so no way\n         * to tell 1st instance beyond threshold from subsequent\n         */\n        static bool reached_max = false;\n        /* do not report in any way if report threshold is reached */\n        DO_THRESHOLD_SAFE(dynamo_options.report_max, FREQ_PROTECTED_SECTION,\n                          {/* < report_max */}, {\n            /* >= report_max */\n            if (!reached_max) {\n                reached_max = true;\n                SYSLOG(SYSLOG_WARNING, WARNING_REPORT_THRESHOLD, 2,\n                       get_application_name(), get_application_pid());\n            }\n            return false;\n        });\n    }\n\n    /* options already synchronized by security_violation() */\n    if ((TEST(DUMPCORE_SECURITY_VIOLATION, DYNAMO_OPTION(dumpcore_mask))\n#ifdef HOT_PATCHING_INTERFACE   /* Part of fix for 5367. */\n         && violation_type != HOT_PATCH_DETECTOR_VIOLATION\n         && violation_type != HOT_PATCH_PROTECTOR_VIOLATION\n#endif\n        )\n#ifdef HOT_PATCHING_INTERFACE   /* Part of fix for 5367. */\n        /* Dump core if violation was for hot patch detector/protector and\n         * the corresponding dumpcore_mask flag was set.\n         */\n        || (TEST(DUMPCORE_HOTP_DETECTION, DYNAMO_OPTION(dumpcore_mask)) &&\n         violation_type == HOT_PATCH_DETECTOR_VIOLATION) ||\n        (TEST(DUMPCORE_HOTP_PROTECTION, DYNAMO_OPTION(dumpcore_mask)) &&\n         violation_type == HOT_PATCH_PROTECTOR_VIOLATION)\n#endif\n       ) {\n        DO_THRESHOLD_SAFE(DYNAMO_OPTION(dumpcore_violation_threshold),\n                          FREQ_PROTECTED_SECTION, os_dump_core(name) /* < threshold */,);\n    }\n\n#ifdef HOT_PATCHING_INTERFACE\n    if (violation_type == HOT_PATCH_DETECTOR_VIOLATION ||\n        violation_type == HOT_PATCH_PROTECTOR_VIOLATION) {\n        SYSLOG_CUSTOM_NOTIFY(SYSLOG_ERROR,\n                             IF_WINDOWS_ELSE_0(MSG_HOT_PATCH_VIOLATION), 3,\n                             (char *) action_message[action], get_application_name(),\n                             get_application_pid(), name);\n    } else\n#endif\n        SYSLOG_CUSTOM_NOTIFY(SYSLOG_ERROR,\n                             IF_WINDOWS_ELSE_0(action_event_id[action]), 3,\n                             (char *) action_message[action], get_application_name(),\n                             get_application_pid(), name);\n\n#ifdef HOT_PATCHING_INTERFACE\n    /* Part of fix for 5367.  For hot patches core dumps and forensics should\n     * be generated only if needed, which is not the case for other violations.\n     */\n    if (!(DYNAMO_OPTION(hotp_diagnostics)) &&\n        (violation_type == HOT_PATCH_DETECTOR_VIOLATION ||\n         violation_type == HOT_PATCH_PROTECTOR_VIOLATION))\n        dump_forensics = false;\n#endif\n#ifdef PROCESS_CONTROL\n    if (!DYNAMO_OPTION(pc_diagnostics) &&           /* Case 11023. */\n        violation_type == PROCESS_CONTROL_VIOLATION)\n        dump_forensics = false;\n#endif\n    /* report_max (above) will limit the number of files created */\n    if (dump_forensics)\n        report_diagnostics(action_message[action], name, violation_type);\n\n    return true;\n}\n\n/* attack handling - reports violation and decides on action - possibly terminates the process\n * N.B.: we make assumptions about whether the callers of this routine hold\n * various locks, so be careful when adding new callers.\n *\n * type_handling prescribes per-type handling and is combined with\n * global options.  It can be used to specify whether to take an\n * action (and may request specific alternative handling with\n * OPTION_HANDLING), and whether to report.\n *\n * The optional out value result_type can differ from the passed-in violation_type\n * for exemptions.\n * Returns an action, with the caller responsible for calling\n * security_violation_action() if action != ACTION_CONTINUE\n */\nstatic action_type_t\nsecurity_violation_internal_main(dcontext_t *dcontext, app_pc addr,\n                                 security_violation_t violation_type,\n                                 security_option_t type_handling, const char *threat_id,\n                                 const action_type_t desired_action,\n                                 read_write_lock_t *lock,\n                                 security_violation_t *result_type/*OUT*/)\n{\n    /* All violations except hot patch ones will request the safest solution, i.e.,\n     * to terminate the process.  Based on the options used, different ones may be\n     * selected in this function.  However, hot patches can request specific actions\n     * as specified by the hot patch writer.\n     */\n    action_type_t action = desired_action;\n    /* probably best to simply use the default TERMINATE_PROCESS */\n    char name[MAXIMUM_VIOLATION_NAME_LENGTH];\n    bool action_selected = false;\n    bool found_unsupported = false;\n#ifdef HOT_PATCHING_INTERFACE\n    /* Passing the hotp lock as an argument is ugly, but it is the cleanest way\n     * to release the hotp lock for case 7988, otherwise, will have to release\n     * it in hotp_event_notify and re-acquire it after reporting - really ugly.\n     * Anyway, cleaning up the interface to security_violation is in plan\n     * for Marlin, a FIXME, case 8079.\n     */\n    ASSERT((DYNAMO_OPTION(hot_patching) && lock == hotp_get_lock()) || lock == NULL);\n#else\n    ASSERT(lock == NULL);\n#endif\n    /* though ASLR handling is currently not using this routine */\n    ASSERT(violation_type != ASLR_TARGET_VIOLATION);\n\n    DOLOG(2, LOG_ALL, {\n        SYSLOG_INTERNAL_INFO(\"security_violation(\"PFX\", %d)\", addr, violation_type);\n        LOG(THREAD, LOG_VMAREAS, 2, \"executable areas are:\\n\");\n        print_executable_areas(THREAD);\n        LOG(THREAD, LOG_VMAREAS, 2, \"future executable areas are:\\n\");\n        read_lock(&futureexec_areas->lock);\n        print_vm_areas(futureexec_areas, THREAD);\n        read_unlock(&futureexec_areas->lock);\n    });\n\n    /* case 8075: we no longer unprot .data on the violation path */\n    ASSERT(check_should_be_protected(DATASEC_RARELY_PROT));\n\n    /* CHECK: all options for attack handling and reporting are dynamic, synchronized only once */\n    synchronize_dynamic_options();\n\n#ifdef HOT_PATCHING_INTERFACE\n    if (violation_type == HOT_PATCH_DETECTOR_VIOLATION ||\n        violation_type == HOT_PATCH_PROTECTOR_VIOLATION) {\n        /* For hot patches, the action is provided by the hot patch writer;\n         * nothing should be selected here.\n         */\n        action_selected = true;\n    }\n#endif\n#ifdef PROCESS_CONTROL\n    /* A process control violation (which can only happen if process control is\n     * turned on) results in the process being killed unless it is running in\n     * detect mode.\n     */\n    if (violation_type == PROCESS_CONTROL_VIOLATION) {\n        ASSERT(IS_PROCESS_CONTROL_ON());\n        ASSERT((action == ACTION_TERMINATE_PROCESS &&\n                !DYNAMO_OPTION(pc_detect_mode)) ||\n               (action == ACTION_CONTINUE && DYNAMO_OPTION(pc_detect_mode)));\n        action_selected = true;\n    }\n#endif\n    /* one last chance to avoid a violation */\n    get_security_violation_name(dcontext, addr, name,\n                                MAXIMUM_VIOLATION_NAME_LENGTH, violation_type,\n                                threat_id);\n    if (!IS_STRING_OPTION_EMPTY(exempt_threat_list)) {\n        if (is_exempt_threat_name(name)) {\n            if (result_type != NULL)\n                *result_type = ALLOWING_BAD;\n            mark_module_exempted(addr);\n            return ACTION_CONTINUE;\n        }\n    }\n\n    /* FIXME: if we reinstate case 6141 where we acquire the thread_initexit_lock\n     * we'll need to release our locks!\n     * See ifdef FORENSICS_ACQUIRES_INITEXIT_LOCK in the Attic.\n     * FIXME: even worse, we'll crash w/ case 9381 if we get a flush\n     * while we're nolinking due to init-extra-vmareas on the frags list!\n     */\n\n    /* diagnose_violation_mode says to check if would have allowed if were allowing patterns */\n    if (dynamo_options.diagnose_violation_mode && !dynamo_options.executable_if_trampoline) {\n        size_t junk;\n        if (check_origins_bb_pattern(dcontext, addr, (app_pc *) &junk, &junk,\n                                     (uint *) &junk, (uint *) &junk)\n            == ALLOWING_OK) {\n            /* FIXME: change later user-visible message to indicate this may be\n             * a false positive\n             */\n            SYSLOG_INTERNAL_WARNING_ONCE(\"would have allowed pattern DGC.\");\n        }\n    }\n#ifdef DGC_DIAGNOSTICS\n    LOG(GLOBAL, LOG_VMAREAS, 1, \"violating basic block target:\\n\");\n    DOLOG(1, LOG_VMAREAS, { disassemble_app_bb(dcontext, addr, GLOBAL); });\n#endif\n    /* for non-debug build, give some info on violating block */\n    DODEBUG({\n        if (is_readable_without_exception(addr, 12)) {\n            SYSLOG_INTERNAL_WARNING(\"violating basic block target @\"PFX\": \"\n                                    \"%x %x %x %x %x %x %x %x %x %x %x %x\", addr,\n                                    *addr, *(addr+1), *(addr+2), *(addr+3), *(addr+4),\n                                    *(addr+5), *(addr+6), *(addr+7), *(addr+8),\n                                    *(addr+9), *(addr+10), *(addr+11));\n        } else\n            SYSLOG_INTERNAL_WARNING(\"violating basic block target @\"PFX\": not readable!\",\n                                    addr);\n    });\n\n    if (DYNAMO_OPTION(detect_mode) && !TEST(OPTION_BLOCK_IGNORE_DETECT, type_handling)\n        /* As of today, detect mode for hot patches is set using modes files. */\n        IF_HOTP(&& violation_type != HOT_PATCH_DETECTOR_VIOLATION\n                && violation_type != HOT_PATCH_PROTECTOR_VIOLATION)) {\n        bool allow = true;\n        /* would be nice to keep the count going when no max, so if dynamically impose\n         * one later all the previous ones count toward it, but then have to worry about\n         * overflow of counter, etc. -- so we ignore count while there's no max\n         */\n        if (DYNAMO_OPTION(detect_mode_max) > 0) {\n            /* global counter for violations in all threads */\n            DO_THRESHOLD_SAFE(DYNAMO_OPTION(detect_mode_max), FREQ_PROTECTED_SECTION,\n                              {/* < max */\n                                  LOG(GLOBAL, LOG_ALL, 1,\n                                      \"security_violation: allowing violation #%d [max %d], tid=\"TIDFMT\"\\n\",\n                                      do_threshold_cur, DYNAMO_OPTION(detect_mode_max),\n                                      get_thread_id());\n                              },\n                              {/* >= max */\n                                  allow = false;\n                                  LOG(GLOBAL, LOG_ALL, 1,\n                                      \"security_violation: reached maximum allowed %d, tid=\"TIDFMT\"\\n\",\n                                      DYNAMO_OPTION(detect_mode_max), get_thread_id());\n                              });\n        } else {\n            LOG(GLOBAL, LOG_ALL, 1,\n                \"security_violation: allowing violation, no max, tid=%d\\n\", get_thread_id());\n        }\n        if (allow) {\n            /* we have priority over other handling options */\n            action = ACTION_CONTINUE;\n            action_selected = true;\n            mark_module_exempted(addr);\n       }\n    }\n\n    /* FIXME: case 2144 we need to TEST(OPTION_BLOCK early on so that\n     * we do not impact the counters, in addition we need to\n     * TEST(OPTION_HANDLING to specify an alternative attack handling\n     * (e.g. -throw_exception if default is -kill_thread)\n     * FIXME: We may also want a different message to allow 'staging' events to be\n     * considered differently, maybe with a DO_ONCE semantics...\n     */\n\n    /* decide on specific attack handling action if not continuing */\n    if (!action_selected && DYNAMO_OPTION(throw_exception)) {\n        thread_data_t *thread_local = (thread_data_t *) dcontext->vm_areas_field;\n        /* maintain a thread local counter to bail out and avoid infinite exceptions */\n        if (thread_local->thrown_exceptions < DYNAMO_OPTION(throw_exception_max_per_thread)) {\n#  ifdef WINDOWS\n            /* If can't verify consistent SEH chain should fall through to kill path */\n            /* UnhandledExceptionFilter is always installed. */\n            /* There is no point in throwing an exception if no other\n               handlers are installed to unwind.\n               We may still get there when our exception is not handled,\n               but at least cleanup code will be given a chance.\n            */\n            enum {\n                MIN_SEH_DEPTH = 1\n                /* doesn't seem to deserve a separate option */\n            };\n            int seh_chain_depth = exception_frame_chain_depth(dcontext);\n            if (seh_chain_depth > MIN_SEH_DEPTH) {\n                /* note the check is best effort,\n                   e.g. attacked handler can still point to valid RET */\n                bool global_max_reached = true;\n                /* check global counter as well */\n                DO_THRESHOLD_SAFE(DYNAMO_OPTION(throw_exception_max),\n                                  FREQ_PROTECTED_SECTION,\n                                  {global_max_reached = false;},\n                                  {global_max_reached = true;});\n                if (!global_max_reached) {\n                    thread_local->thrown_exceptions++;\n                    LOG(GLOBAL, LOG_ALL, 1,\n                        \"security_violation: throwing exception %d for this thread [max pt %d] [global max %d]\\n\",\n                        thread_local->thrown_exceptions,\n                        dynamo_options.throw_exception_max_per_thread,\n                        dynamo_options.throw_exception_max);\n                    action = ACTION_THROW_EXCEPTION;\n                    action_selected = true;\n                }\n            } else {\n                LOG(GLOBAL, LOG_ALL, 1,\n                    \"security_violation: SEH chain invalid [%d], better kill\\n\", seh_chain_depth);\n            }\n#  else\n            ASSERT_NOT_IMPLEMENTED(false);\n#  endif /* WINDOWS */\n        } else {\n            LOG(GLOBAL, LOG_ALL, 1,\n                \"security_violation: reached maximum exception count, kill now\\n\");\n        }\n    }\n\n    /* kill process or maybe thread */\n    if (!action_selected) {\n        ASSERT(action == ACTION_TERMINATE_PROCESS);\n        if (DYNAMO_OPTION(kill_thread)) {\n            /* check global counter as well */\n            DO_THRESHOLD_SAFE(DYNAMO_OPTION(kill_thread_max), FREQ_PROTECTED_SECTION,\n                {/* < max */\n                    LOG(GLOBAL, LOG_ALL, 1,\n                        \"security_violation: \\t killing thread #%d [max %d], tid=%d\\n\",\n                        do_threshold_cur, DYNAMO_OPTION(kill_thread_max),\n                        get_thread_id());\n                    /* FIXME: can't check if get_num_threads()==1 then say we're killing process\n                     * because it is possible that another thread has not been scheduled yet\n                     * and we wouldn't have seen it.\n                     * Still, only our message will be wrong if we end up killing the process,\n                     * when we terminate the last thread\n                     */\n                    action = ACTION_TERMINATE_THREAD;\n                    action_selected = true;\n                },\n                {/* >= max */\n                    LOG(GLOBAL, LOG_ALL, 1,\n                        \"security_violation: reached maximum thread kill, kill process now\\n\");\n                    action = ACTION_TERMINATE_PROCESS;\n                    action_selected = true;\n                });\n        } else {\n            action = ACTION_TERMINATE_PROCESS;\n            action_selected = true;\n        }\n    }\n    ASSERT(action_selected);\n\n#ifdef CLIENT_INTERFACE\n    /* Case 9712: Inform the client of the security violation and\n     * give it a chance to modify the action.\n     */\n    if (CLIENTS_EXIST()) {\n        instrument_security_violation(dcontext, addr, violation_type, &action);\n    }\n#endif\n\n    /* now we know what is the chosen action and we can report */\n    if (TEST(OPTION_REPORT, type_handling))\n        security_violation_report(addr, violation_type, name, action);\n\n    /* FIXME: walking the loader data structures at arbitrary\n     * points is dangerous due to data races with other threads\n     * -- see is_module_being_initialized and get_module_name */\n    if (check_for_unsupported_modules()) {\n        /* found an unsupported module */\n        action = ACTION_TERMINATE_PROCESS;\n        found_unsupported = true;\n        /* NOTE that because of the violation_threshold this\n         * check isn't actually sufficient to ensure we get a dump file\n         * (if for instance already got several violations) but it's good\n         * enough */\n        if (TEST(DUMPCORE_UNSUPPORTED_APP,\n                 DYNAMO_OPTION(dumpcore_mask)) &&\n            !TEST(DUMPCORE_SECURITY_VIOLATION,\n                  DYNAMO_OPTION(dumpcore_mask))) {\n            os_dump_core(\"unsupported module\");\n        }\n    }\n\n#ifdef WINDOWS\n    if (ACTION_TERMINATE_PROCESS == action &&\n        (TEST(DETACH_UNHANDLED_VIOLATION,\n              DYNAMO_OPTION(internal_detach_mask)) ||\n         (found_unsupported && TEST(DETACH_UNSUPPORTED_MODULE,\n                                    DYNAMO_OPTION(internal_detach_mask))))) {\n        /* set pc to right value and detach */\n        get_mcontext(dcontext)->pc = addr;\n        /* FIXME - currently detach_internal creates a new thread to do the\n         * detach (case 3312) and if we hold an app lock used by the init apc\n         * such as the loader lock (case 4486) we could livelock the process\n         * if we used a synchronous detach.  Instead, we set detach in motion\n         * disable all future violations and continue.\n         */\n        detach_internal();\n        options_make_writable();\n        /* make sure synchronizes won't clobber the changes here */\n        dynamo_options.dynamic_options = false;\n        dynamo_options.detect_mode = true;\n        dynamo_options.detect_mode_max = 0; /* no limit on detections */\n        dynamo_options.report_max = 1; /* don't report any more */\n        options_restore_readonly();\n        action = ACTION_CONTINUE;\n    }\n#endif\n\n    /* FIXME: move this into hotp code like we've done for bb building so we\n     * don't need to pass the lock in anymore\n     */\n#ifdef HOT_PATCHING_INTERFACE\n    /* Fix for case 7988.  Release the hotp lock when the remediation action\n     * is to terminate the {thread,process} or to throw an exception, otherwise\n     * we will deadlock trying to access the hotp_vul_table in another thread.\n     */\n    if (lock != NULL && (action == ACTION_TERMINATE_THREAD ||\n                         action == ACTION_TERMINATE_PROCESS ||\n                         action == ACTION_THROW_EXCEPTION)) {\n#ifdef GBOP\n        ASSERT(violation_type == HOT_PATCH_DETECTOR_VIOLATION ||\n               violation_type == HOT_PATCH_PROTECTOR_VIOLATION ||\n               violation_type == GBOP_SOURCE_VIOLATION);\n#else\n        ASSERT(violation_type == HOT_PATCH_DETECTOR_VIOLATION ||\n               violation_type == HOT_PATCH_PROTECTOR_VIOLATION);\n#endif\n        ASSERT_OWN_READ_LOCK(true, lock);\n        read_unlock(lock);\n    }\n#endif\n\n    if (result_type != NULL)\n        *result_type = violation_type;\n    return action;\n}\n\n/* Meant to be called after security_violation_internal_main().\n * Caller should only call for action!=ACTION_CONTINUE.\n */\nvoid\nsecurity_violation_action(dcontext_t *dcontext, action_type_t action, app_pc addr)\n{\n    ASSERT(action != ACTION_CONTINUE);\n    if (action == ACTION_CONTINUE)\n        return;\n\n    /* timeout before we take an action */\n    if (dynamo_options.timeout) {\n        /* For now assuming only current thread sleeps.\n           FIXME: If we are about the kill the process anyways,\n           it may be safer to stop_the_world,\n           so attacks in this time window do not get through.\n\n           TODO: On the other hand sleeping in one thread,\n           while the rest are preparing for controlled shutdown sounds better,\n           yet we have no way of telling them that process death is pending.\n        */\n        /* FIXME: shouldn't we suspend all other threads for the messagebox too? */\n\n        /* For services you can get a similar effect to -timeout on kill process\n           by settings in Services\\service properties\\Recovery.\n           Restart service after x minutes.\n           0 is very useful - then you get your app back immediately.\n           1 minute however may be too much in some circumstances,\n           Our option is then useful for finer control, e.g. -timeout 10s\n        */\n        os_timeout(dynamo_options.timeout);\n    }\n\n    if (ACTION_THROW_EXCEPTION == action) {\n        os_forge_exception(addr, UNREADABLE_MEMORY_EXECUTION_EXCEPTION);\n        ASSERT_NOT_REACHED();\n    }\n    if (ACTION_CONTINUE != action) {\n        uint terminate_flags_t = TERMINATE_PROCESS;\n        if (is_self_couldbelinking()) {\n            /* must be nolinking for terminate cleanup to avoid deadlock w/ flush */\n            enter_nolinking(dcontext, NULL, false/*not a real cache transition*/);\n        }\n        if (action == ACTION_TERMINATE_THREAD) {\n            terminate_flags_t = TERMINATE_THREAD;\n            /* clean up when terminating a thread */\n            terminate_flags_t |= TERMINATE_CLEANUP;\n        } else {\n            ASSERT(action == ACTION_TERMINATE_PROCESS &&\n                   terminate_flags_t == TERMINATE_PROCESS);\n        }\n#ifdef HOT_PATCHING_INTERFACE\n        ASSERT(!DYNAMO_OPTION(hot_patching) ||\n               !READ_LOCK_HELD(hotp_get_lock()));   /* See case 7998. */\n#endif\n        os_terminate(dcontext, terminate_flags_t);\n        ASSERT_NOT_REACHED();\n    }\n    ASSERT_NOT_REACHED();\n}\n\n/* Caller must call security_violation_action() if return != ACTION_CONTINUE */\nstatic action_type_t\nsecurity_violation_main(dcontext_t *dcontext, app_pc addr,\n                        security_violation_t violation_type,\n                        security_option_t type_handling)\n{\n    return security_violation_internal_main(dcontext, addr, violation_type,\n                                            type_handling, NULL,\n                                            ACTION_TERMINATE_PROCESS, NULL, NULL);\n}\n\n/* See security_violation_internal_main() for further comments.\n *\n * Returns ALLOWING_BAD if on exempt_threat_list, or if in detect mode\n * returns the passed violation_type (a negative value)\n * Does not return if protection action is taken.\n */\nsecurity_violation_t\nsecurity_violation_internal(dcontext_t *dcontext, app_pc addr,\n                            security_violation_t violation_type,\n                            security_option_t type_handling, const char *threat_id,\n                            const action_type_t desired_action,\n                            read_write_lock_t *lock)\n{\n    security_violation_t result_type;\n    action_type_t action =\n        security_violation_internal_main(dcontext, addr, violation_type,\n                                         type_handling, threat_id, desired_action,\n                                         lock, &result_type);\n    DOKSTATS(if (ACTION_CONTINUE != action) {\n        KSTOP_REWIND_UNTIL(dispatch_num_exits);\n    });\n    if (action != ACTION_CONTINUE)\n        security_violation_action(dcontext, action, addr);\n    return result_type;\n}\n\n/* security_violation_internal() is the real function.  This a wrapper exists\n * for two reasons; one, hot patching needs to send extra arguments for event\n * notification and two, existing calls to security_violation() in the code\n * shouldn't have to change the interface.\n */\nsecurity_violation_t\nsecurity_violation(dcontext_t *dcontext, app_pc addr,\n                   security_violation_t violation_type,\n                   security_option_t type_handling)\n{\n    return security_violation_internal(dcontext, addr, violation_type,\n                                       type_handling, NULL,\n                                       ACTION_TERMINATE_PROCESS, NULL);\n}\n\n/* back to normal section */\nEND_DATA_SECTION()\n/****************************************************************************/\n\nbool\nis_dyngen_vsyscall(app_pc addr)\n{\n    /* FIXME: on win32, should we only allow portion of page? */\n    /* CHECK: likely to be true on all Linux versions by the time we ship */\n    /* if vsyscall_page_start == 0, then this exception doesn't apply */\n    /* Note vsyscall_page_start is a global defined in the corresponding os.c files */\n    if (vsyscall_page_start == 0)\n        return false;\n    return (addr >= (app_pc) vsyscall_page_start &&\n            addr < (app_pc) (vsyscall_page_start+PAGE_SIZE));\n}\n\nbool\nis_in_futureexec_area(app_pc addr)\n{\n    bool future;\n    read_lock(&futureexec_areas->lock);\n    future = lookup_addr(futureexec_areas, addr, NULL);\n    read_unlock(&futureexec_areas->lock);\n    return future;\n}\n\nbool\nis_dyngen_code(app_pc addr)\n{\n    uint flags;\n    if (get_executable_area_flags(addr, &flags)) {\n        /* assuming only true DGC is marked DYNGEN  */\n        return TEST(FRAG_DYNGEN, flags);\n    }\n\n    return is_in_futureexec_area(addr);\n}\n\n/* Returns true if in is a direct jmp targeting a known piece of non-DGC code\n */\nstatic bool\nis_direct_jmp_to_image(dcontext_t *dcontext, instr_t *in)\n{\n    bool ok = false;\n    if (instr_get_opcode(in) == OP_jmp && /* no short jmps */\n        opnd_is_near_pc(instr_get_target(in))) {\n        app_pc target = opnd_get_pc(instr_get_target(in));\n        uint flags;\n        if (get_executable_area_flags(target, &flags)) {\n            /* we could test for UNMOD_IMAGE but that would ruin windows\n             * loader touch-ups, which can happen for any dll!\n             * so we test FRAG_DYNGEN instead\n             */\n            ok = !TEST(FRAG_DYNGEN, flags);\n        }\n    }\n    return ok;\n}\n\n/* allow original code displaced by a hook, seen for Citrix 4.0 (case 6615):\n *   <zero or more non-cti and non-syscall instrs whose length < 5>\n *   <one more such instr, making length sum X>\n *   jmp <dll:Y>, where <dll:Y-X> contains a jmp to this page\n */\nstatic bool\ncheck_trampoline_displaced_code(dcontext_t *dcontext, app_pc addr, bool on_stack,\n                                instrlist_t *ilist, size_t *len)\n{\n    uint size = 0;\n    bool match = false;\n    instr_t *in, *last = instrlist_last(ilist);\n    ASSERT(DYNAMO_OPTION(trampoline_displaced_code));\n    if (on_stack || !is_direct_jmp_to_image(dcontext, last))\n        return false;\n    ASSERT(instr_length(dcontext, last) == JMP_LONG_LENGTH);\n    for (in = instrlist_first(ilist);\n         in != NULL/*sanity*/ && in != last;\n         in = instr_get_next(in)) {\n        /* build_app_bb_ilist should fully decode everything */\n        ASSERT(instr_opcode_valid(in));\n        if (instr_is_cti(in) || instr_is_syscall(in) || instr_is_interrupt(in))\n            break;\n        size += instr_length(dcontext, in);\n        if (instr_get_next(in) == last) {\n            if (size < JMP_LONG_LENGTH)\n                break;\n        } else {\n            if (size >= JMP_LONG_LENGTH)\n                break;\n        }\n    }\n    ASSERT(in != NULL);\n    if (in == last) {\n        app_pc target;\n        LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 3,\n            \"check_trampoline_displaced_code @\"PFX\": size=%d\\n\",\n            addr, size);\n        DOLOG(3, LOG_INTERP|LOG_VMAREAS, {\n            instrlist_disassemble(dcontext, addr, ilist, THREAD);\n        });\n        /* is_direct_jmp_to_image should have checked for us */\n        ASSERT(opnd_is_near_pc(instr_get_target(last)));\n        target = opnd_get_pc(instr_get_target(last));\n        if (is_readable_without_exception(target - size, JMP_LONG_LENGTH)) {\n            instr_t *tramp = instr_create(dcontext);\n            /* Ensure a racy unmap causing a decode crash is passed to the app */\n            set_thread_decode_page_start(dcontext, (app_pc) PAGE_START(target - size));\n            target = decode_cti(dcontext, target - size, tramp);\n            if (target != NULL && instr_opcode_valid(tramp) &&\n                instr_is_ubr(tramp) && opnd_is_near_pc(instr_get_target(tramp))) {\n                app_pc hook = opnd_get_pc(instr_get_target(tramp));\n                /* FIXME: could be tighter by ensuring that hook targets a jmp\n                 * or call right before addr but that may be too specific.\n                 * FIXME: if the pattern crosses a page we could fail to match.\n                 * we could check for being inside region instead.\n                 */\n                if (PAGE_START(hook) == PAGE_START(addr)) {\n                    *len = size + JMP_LONG_LENGTH;\n                    LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 2,\n                        \"WARNING: allowing hook-displaced code \"PFX\" -> \"PFX\" -> \"PFX\"\\n\",\n                        addr, target, hook);\n                    SYSLOG_INTERNAL_WARNING_ONCE(\"hook-displaced code allowed.\");\n                    STATS_INC(trampolines_displaced_code);\n                    match = true;\n                }\n            }\n            instr_destroy(dcontext, tramp);\n        }\n    }\n    return match;\n}\n\n/* other than JITed code, we allow a small set of specific patterns of DGC such\n * as function closure trampolines, which this routine checks for.\n * returns ALLOWING_OK if bb matches, else returns ALLOWING_BAD\n */\nstatic int\ncheck_origins_bb_pattern(dcontext_t *dcontext, app_pc addr, app_pc *base, size_t *size,\n                         uint *vm_flags, uint *frag_flags)\n{\n    /* we assume this is not a cti target (flag diffs will prevent direct cti here)\n     * we only check for the bb beginning at addr\n     */\n    instrlist_t *ilist;\n    instr_t *in, *first;\n    opnd_t op;\n    size_t len = 0;\n    int res = ALLOWING_BAD; /* signal to caller not a match */\n    bool on_stack = is_on_stack(dcontext, addr, NULL);\n\n    /* FIXME: verify bb memory is readable prior to decoding it\n     * we shouldn't get here if addr is unreadable, but rest of bb could be\n     * note that may end up looking at win32 GUARD page -- don't need to do\n     * anything special since that will look unreadable\n     */\n    /* FIXME bug 9376: if unreadable check_thread_vm_area() will\n     * assert vmlist!=NULL and throw an exception, which is ok\n     */\n    ilist = build_app_bb_ilist(dcontext, addr, INVALID_FILE);\n    first = instrlist_first(ilist);\n    if (first == NULL) /* empty bb: perhaps invalid instr */\n        goto check_origins_bb_pattern_exit;\n\n    LOG(GLOBAL, LOG_VMAREAS, 3, \"check_origins_bb_pattern:\\n\");\n    DOLOG(3, LOG_VMAREAS, { instrlist_disassemble(dcontext, addr, ilist, GLOBAL); });\n\n#ifndef X86\n    /* FIXME: move the x86-specific analysis to an arch/ file! */\n    ASSERT_NOT_IMPLEMENTED();\n#endif\n\n#ifdef UNIX\n    /* is this a sigreturn pattern placed by kernel on the stack or vsyscall page? */\n    if (is_signal_restorer_code(addr, &len)) {\n        LOG(GLOBAL, LOG_INTERP|LOG_VMAREAS, 2,\n            \"found signal restorer code @\"PFX\", allowing it\\n\", addr);\n        SYSLOG_INTERNAL_WARNING_ONCE(\"signal restorer code allowed.\");\n        res = ALLOWING_OK;\n        goto check_origins_bb_pattern_exit;\n    }\n#endif\n\n    /* is this a closure trampoline that looks like this:\n     *   mov immed -> 0x4(esp)             (put frame ptr directly in slot)\n     *   jmp known-non-DGC-address\n     * or like this (gcc-style, also seen in dfrgui):\n     *   mov immed -> %ecx                 (put frame ptr in ecx, callee puts in slot)\n     *   jmp known-non-DGC-address\n     * OR, is this some sort of C++ exception chaining (seen in soffice):\n     *   mov immed -> %eax                 (put try index in eax)\n     *   jmp known-non-DGC-address\n     * these can be on the stack or on the heap, except the soffice one, which must\n     * be on the heap (simply b/c we've never seen it on the stack)\n     * all of these must be targeted by a call\n     */\n    if (instr_get_opcode(first) == OP_mov_imm ||\n        /* funny case where store of immed is mov_st -- see arch/decode_table.c */\n        (instr_get_opcode(first) == OP_mov_st &&\n         opnd_is_immed(instr_get_src(first, 0)))) {\n        bool ok = false;\n        LOG(GLOBAL, LOG_VMAREAS, 3, \"testing for mov immed pattern\\n\");\n        /* mov_imm always has immed src, just check dst */\n        op = instr_get_dst(first, 0);\n        ok = (opnd_is_near_base_disp(op) && opnd_get_base(op) == REG_XSP &&\n              opnd_get_disp(op) == 4 && opnd_get_scale(op) == REG_NULL);\n\n        if (!ok && opnd_is_reg(op) && opnd_get_size(instr_get_src(first, 0)) == OPSZ_4) {\n            uint immed = (uint) opnd_get_immed_int(instr_get_src(first, 0));\n            /* require immed be addr for ecx, non-addr plus on heap for eax */\n            /* FIXME: PAGE_SIZE is arbitrary restriction, assuming eax values\n             * are small indices, and it's a nice way to distinguish pointers\n             */\n            IF_X64(ASSERT_NOT_TESTED()); /* on x64 will these become rcx & rax? */\n            ok = (opnd_get_reg(op) == REG_ECX && immed > PAGE_SIZE) ||\n                (opnd_get_reg(op) == REG_EAX && immed < PAGE_SIZE && !on_stack);\n        }\n\n        if (ok) {\n            /* check 2nd instr */\n            ok = false;\n            len += instr_length(dcontext, first);\n            in = instr_get_next(first);\n            if (instr_get_next(in) == NULL && /* only 2 instrs in this bb */\n                is_direct_jmp_to_image(dcontext, in)) {\n                len += instr_length(dcontext, in);\n                ok = true;\n            } else\n                LOG(GLOBAL, LOG_VMAREAS, 3, \"2nd instr not jmp to good code!\\n\");\n        } else\n            LOG(GLOBAL, LOG_VMAREAS, 3, \"immed bad!\\n\");\n\n        if (ok) {\n            /* require source to be known and to be a call\n             * cases where source is unknown are fairly pathological\n             * (another thread flushing and deleting the fragment, etc.)\n             */\n            ok = EXIT_IS_CALL(dcontext->last_exit->flags);\n        }\n        if (ok) {\n            LOG(GLOBAL, LOG_INTERP|LOG_VMAREAS, 2,\n                \"WARNING: found trampoline block @\"PFX\", allowing it\\n\", addr);\n            SYSLOG_INTERNAL_WARNING_ONCE(\"trampoline DGC allowed.\");\n            res = ALLOWING_OK;\n            goto check_origins_bb_pattern_exit;\n        }\n    }\n\n    /* is this a PLT-type push/jmp, where the push uses its own address\n     * (this is seen in soffice):\n     *   push own-address\n     *   jmp known-non-DGC-address\n     */\n    if (instr_get_opcode(first) == OP_push_imm &&\n        opnd_get_size(instr_get_src(first, 0)) == OPSZ_4) {\n        ptr_uint_t immed = opnd_get_immed_int(instr_get_src(first, 0));\n        LOG(GLOBAL, LOG_VMAREAS, 3, \"testing for push immed pattern\\n\");\n        if ((app_pc)immed == addr) {\n            len += instr_length(dcontext, first);\n            in = instr_get_next(first);\n            if (instr_get_next(in) == NULL && /* only 2 instrs in this bb */\n                is_direct_jmp_to_image(dcontext, in)) {\n                len += instr_length(dcontext, in);\n                LOG(GLOBAL, LOG_INTERP|LOG_VMAREAS, 2,\n                    \"WARNING: found push/jmp block @\"PFX\", allowing it\\n\", addr);\n                SYSLOG_INTERNAL_WARNING_ONCE(\"push/jmp DGC allowed.\");\n                res = ALLOWING_OK;\n                goto check_origins_bb_pattern_exit;\n            }\n        }\n    }\n\n    /* look for the DGC ret on the stack that office xp uses, beyond TOS!\n     * it varies between having no arg or having an immed arg -- my guess\n     * is they use it to handle varargs with stdcall: callee must\n     * clean up args but has to deal w/ dynamically varying #args, so\n     * they use DGC ret, only alternative is jmp* and no ret\n     */\n    if (instr_is_return(first) && on_stack &&\n        addr < (app_pc) get_mcontext(dcontext)->xsp) { /* beyond TOS */\n        ASSERT(instr_get_next(first) == NULL); /* bb should have only ret in it */\n        len = instr_length(dcontext, first);\n        LOG(GLOBAL, LOG_INTERP|LOG_VMAREAS, 2,\n            \"WARNING: found ret-beyond-TOS @\"PFX\", allowing it\\n\", addr);\n        SYSLOG_INTERNAL_WARNING_ONCE(\"ret-beyond-TOS DGC allowed.\");\n        res = ALLOWING_OK;\n        goto check_origins_bb_pattern_exit;\n    }\n\n    if (DYNAMO_OPTION(trampoline_dirjmp) &&\n        !on_stack && is_direct_jmp_to_image(dcontext, first)) {\n        /* should be a lone jmp */\n        ASSERT(instr_get_next(first) == NULL);\n        len = instr_length(dcontext, first);\n        LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 2,\n            \"WARNING: allowing targeted direct jmp @\"PFX\"\\n\", addr);\n        SYSLOG_INTERNAL_WARNING_ONCE(\"trampoline direct jmp allowed.\");\n        STATS_INC(trampolines_direct_jmps);\n        res = ALLOWING_OK;\n        goto check_origins_bb_pattern_exit;\n    }\n\n    /* allow a .NET COM method table: a lone direct call on the heap, and a\n     * ret immediately preceding it (see case 3558 and case 3564)\n     */\n    if (DYNAMO_OPTION(trampoline_dircall) &&\n        !on_stack && instr_is_call_direct(first)) {\n        len = instr_length(dcontext, first);\n        /* ignore rest of ilist -- may or may not follow call for real bb, as\n         * will have separate calls to check_thread_vm_area() and thus\n         * separate code origins checks being applied to the target, making this\n         * not really a security hole at all as attack could have sent control\n         * directly to target\n         */\n        LOG(GLOBAL, LOG_INTERP|LOG_VMAREAS, 2,\n            \"WARNING: allowing targeted direct call @\"PFX\"\\n\", addr);\n        SYSLOG_INTERNAL_WARNING_ONCE(\"trampoline direct call allowed.\");\n        STATS_INC(trampolines_direct_calls);\n        res = ALLOWING_OK;\n        goto check_origins_bb_pattern_exit;\n    }\n    if (DYNAMO_OPTION(trampoline_com_ret) && !on_stack && instr_is_return(first)) {\n        app_pc nxt_pc = addr + instr_length(dcontext, first);\n        if (is_readable_without_exception(nxt_pc, MAX_INSTR_LENGTH)) {\n            instr_t *nxt = instr_create(dcontext);\n            /* WARNING: until our decoding is more robust, as this is AFTER a\n             * ret this could fire a decode assert if not actually code there,\n             * so we avoid any more decoding than we have to do w/ decode_cti.\n             */\n            /* A racy unmap could cause a fault here so we track the page\n             * that's being decoded. */\n            set_thread_decode_page_start(dcontext, (app_pc) PAGE_START(nxt_pc));\n            nxt_pc = decode_cti(dcontext, nxt_pc, nxt);\n            if (nxt_pc != NULL && instr_opcode_valid(nxt) && instr_is_call_direct(nxt)) {\n                /* actually we don't get here w/ current native_exec early-gateway\n                 * design since we go native at the PREVIOUS call to this ret's call\n                 */\n                ASSERT_NOT_TESTED();\n                instr_destroy(dcontext, nxt);\n                len = instr_length(dcontext, first);\n                LOG(GLOBAL, LOG_INTERP|LOG_VMAREAS, 2,\n                    \"WARNING: allowing .NET COM ret in method table @\"PFX\"\\n\", addr);\n                SYSLOG_INTERNAL_WARNING_ONCE(\".NET COM method table ret allowed.\");\n                STATS_INC(trampolines_com_rets);\n                res = ALLOWING_OK;\n                goto check_origins_bb_pattern_exit;\n            }\n            instr_destroy(dcontext, nxt);\n        }\n    }\n\n    if (DYNAMO_OPTION(trampoline_displaced_code) &&\n        check_trampoline_displaced_code(dcontext, addr, on_stack, ilist, &len)) {\n        res = ALLOWING_OK;\n        goto check_origins_bb_pattern_exit;\n    }\n\n check_origins_bb_pattern_exit:\n    if (res == ALLOWING_OK) {\n        /* bb matches pattern, let's allow it, but only this block, not entire region! */\n        LOG(GLOBAL, LOG_INTERP|LOG_VMAREAS, 2,\n            \"Trimming exec area \"PFX\"-\"PFX\" to match pattern bb \"PFX\"-\"PFX\"\\n\",\n            *base, *base+*size, addr, addr+len);\n        *base = addr;\n        ASSERT(len > 0);\n        *size = len;\n        /* Since this is a sub-page region that shouldn't be frequently\n         * executed, it's best to use sandboxing.\n         */\n        *frag_flags |= SANDBOX_FLAG();\n        /* ensure another thread is not able to use this memory region for\n         * a non-pattern-matching code sequence\n         */\n        *vm_flags |= VM_PATTERN_REVERIFY;\n        STATS_INC(num_selfmod_vm_areas);\n    }\n    instrlist_clear_and_destroy(dcontext, ilist);\n    return res;\n}\n\n/* trims [base, base+size) to its intersection with [start, end)\n * NOTE - regions are required to intersect */\nstatic void\ncheck_origins_trim_region_helper(app_pc *base /*INOUT*/, size_t *size /*INOUT*/,\n                                 app_pc start, app_pc end) {\n    app_pc original_base = *base;\n    ASSERT(!POINTER_OVERFLOW_ON_ADD(*base, *size)); /* shouldn't overflow */\n    ASSERT(start < end); /* [start, end) should be an actual region */\n    ASSERT(*base + *size > start &&  *base < end); /* region must intersect */\n    LOG(GLOBAL, LOG_INTERP|LOG_VMAREAS, 2,\n        \"Trimming exec area \"PFX\"-\"PFX\" to intersect area \"PFX\"-\"PFX\"\\n\",\n        *base, *base+*size, start, end);\n    *base = MAX(*base, start);\n    /* don't use new base here! (case 8152) */\n    *size = MIN(original_base+*size, end) - *base;\n}\n\n/* Checks if the given PC is trusted and to what level\n * if execution for the referenced area is not allowed program execution\n * should be aborted\n */\nstatic INLINE_ONCE security_violation_t\ncheck_origins_helper(dcontext_t *dcontext, app_pc addr, app_pc *base, size_t *size,\n                     uint prot, uint *vm_flags, uint *frag_flags, const char *modname)\n{\n    vm_area_t *fut_area;\n\n    if (is_dyngen_vsyscall(addr) && *size == PAGE_SIZE && (prot & MEMPROT_WRITE) == 0) {\n        /* FIXME: don't allow anyone to make this region writable? */\n        LOG(GLOBAL, LOG_INTERP|LOG_VMAREAS, 2,\n            PFX\" is the vsyscall page, ok to execute\\n\", addr);\n        return ALLOWING_OK;\n    }\n#if 0\n    /* this syslog causes services.exe to hang (ref case 666) once case 666\n     * is fixed re-enable if desired FIXME */\n    SYSLOG_INTERNAL_WARNING_ONCE(\"executing region at \"PFX\" not on executable list.\",\n                                 addr);\n#else\n    LOG(GLOBAL, LOG_VMAREAS, 1,\n        \"executing region at \"PFX\" not on executable list. Thread %d\\n\",\n        addr, dcontext->owning_thread);\n#endif\n\n    if (USING_FUTURE_EXEC_LIST) {\n        bool ok;\n        bool once_only;\n        read_lock(&futureexec_areas->lock);\n        ok = lookup_addr(futureexec_areas, addr, &fut_area);\n        if (!ok)\n            read_unlock(&futureexec_areas->lock);\n        else {\n            LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 2,\n                \"WARNING: pc = \"PFX\" is future executable, allowing\\n\", addr);\n            LOG(GLOBAL, LOG_INTERP|LOG_VMAREAS, 2,\n                \"WARNING: pc = \"PFX\" is future executable, allowing\\n\", addr);\n#if 0\n            /* this syslog causes services.exe to hang (ref case 666)\n             * once case 666 is fixed re-enable if desired FIXME */\n            SYSLOG_INTERNAL_WARNING_ONCE(\"future executable region allowed.\");\n#else\n            DODEBUG_ONCE(LOG(GLOBAL, LOG_ALL, 1, \"future executable region allowed.\"));\n#endif\n            if (*base < fut_area->start || *base+*size > fut_area->end) {\n                check_origins_trim_region_helper(base, size,\n                                                 fut_area->start, fut_area->end);\n            }\n            once_only = TEST(VM_ONCE_ONLY, fut_area->vm_flags);\n            /* now done w/ fut_area */\n            read_unlock(&futureexec_areas->lock);\n            fut_area = NULL;\n            if (is_on_stack(dcontext, addr, NULL)) {\n                /* normally futureexec regions are persistent, to allow app to\n                 * repeatedly write and then execute (yes this happens a lot).\n                 * we don't want to do that for the stack, b/c it amounts to\n                 * permanently allowing a certain piece of stack to be executed!\n                 * besides, we don't see the write-exec iter scheme for the stack.\n                 */\n                STATS_INC(num_exec_future_stack);\n                LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 2,\n                    \"future exec \"PFX\"-\"PFX\" is on stack, removing from future list\\n\",\n                    *base, *base+*size);\n                ok = remove_futureexec_vm_area(*base, *base+*size);\n                ASSERT(ok);\n            } else {\n                STATS_INC(num_exec_future_heap);\n                if (!DYNAMO_OPTION(selfmod_futureexec)) {\n                    /* if on all-selfmod pages, then we shouldn't need to keep it on\n                     * the futureexec list\n                     */\n                    if (is_executable_area_on_all_selfmod_pages(*base, *base+*size))\n                        once_only = true;\n                }\n                if (once_only) {\n                    LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 2,\n                        \"future exec \"PFX\"-\"PFX\" is once-only, removing from future list\\n\",\n                        *base, *base+*size);\n                    ok = remove_futureexec_vm_area(*base, *base+*size);\n                    ASSERT(ok);\n                    STATS_INC(num_exec_future_once);\n                }\n            }\n            *vm_flags |= VM_WAS_FUTURE;\n            return ALLOWING_OK;\n        }\n    }\n\n    if (DYNAMO_OPTION(executable_if_text) ||\n        DYNAMO_OPTION(executable_if_rx_text) ||\n        (DYNAMO_OPTION(exempt_text) ||\n        !IS_STRING_OPTION_EMPTY(exempt_text_list))) {\n        app_pc modbase = get_module_base(addr);\n        if (modbase != NULL) { /* PE, and is readable */\n            /* note that it could still be a PRIVATE mapping */\n            /* don't expand region to match actual text section bounds -- if we split\n             * let's keep this region smaller.\n             */\n            app_pc sec_start = NULL, sec_end = NULL;\n            if (is_in_code_section(modbase, addr, &sec_start, &sec_end)) {\n                bool allow = false;\n                if (DYNAMO_OPTION(executable_if_text)) {\n                    LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 2,\n                        \"exec region is in code section of module @\"PFX\" (%s), allowing\\n\",\n                        modbase, modname == NULL? \"<invalid name>\" : modname);\n                    STATS_INC(num_text);\n                    mark_module_exempted(addr);\n                    allow = true;\n                } else {\n                    uint prot = 0;\n                    list_default_or_append_t deflist = LIST_NO_MATCH;\n                    /* Xref case 10526, in the common case app_mem_prot_change() adds\n                     * this region, however it can miss -> rx transitions if they\n                     * overlapped more then one section (fixing it to do so would\n                     * require signifigant restructuring of that routine, see comments\n                     * there) so we also check here. */\n                    if (DYNAMO_OPTION(executable_if_rx_text) &&\n                        get_memory_info(addr, NULL, NULL, &prot) &&\n                        (TEST(MEMPROT_EXEC, prot) && !TEST(MEMPROT_WRITE, prot))) {\n                        /* matches -executable_if_rx_text */\n                        /* case 9799: we don't mark exempted for default-on options */\n                        allow = true;\n                        SYSLOG_INTERNAL_WARNING_ONCE(\"allowable rx text section not \"\n                                                     \"found till check_origins\");\n                    }\n                    if (!allow && modname != NULL) {\n                        bool onlist;\n                        string_option_read_lock();\n                        LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 3,\n                            \"exec region is in code section of module %s, vs list %s\\n\",\n                            modname, DYNAMO_OPTION(exempt_text_list));\n                        onlist = check_filter(DYNAMO_OPTION(exempt_text_list), modname);\n                        string_option_read_unlock();\n                        if (onlist) {\n                            LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 2,\n                                \"module %s is on text list, allowing execution\\n\", modname);\n                            STATS_INC(num_text_list);\n                            SYSLOG_INTERNAL_WARNING_ONCE(\"code origins: module %s text \"\n                                                         \"section exempt\", modname);\n                            mark_module_exempted(addr);\n                            allow = true;\n                        }\n                    }\n\n                    if (!allow && modname != NULL) {\n                        deflist =\n                            check_list_default_and_append(dynamo_options.\n                                                          exempt_mapped_image_text_default_list,\n                                                          dynamo_options.\n                                                          exempt_mapped_image_text_list,\n                                                          modname);\n                    }\n                    if (deflist != LIST_NO_MATCH) {\n                        bool image_mapping = is_mapped_as_image(modbase);\n                        if (image_mapping) {\n                            LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 2,\n                                \"module %s is on text list, of a mapped IMAGE\"\n                                \" allowing execution\\n\", modname);\n                            STATS_INC(num_image_text_list);\n                            SYSLOG_INTERNAL_WARNING_ONCE(\"code origins: module %s IMAGE text \"\n                                                         \"section exempt\", modname);\n                            if (deflist == LIST_ON_APPEND) /* case 9799: not default */\n                                mark_module_exempted(addr);\n                            allow = true;\n                        } else {\n                            ASSERT_NOT_TESTED();\n                            SYSLOG_INTERNAL_WARNING_ONCE(\"code origins: module %s text \"\n                                                         \"not IMAGE, attack!\", modname);\n                        }\n                    }\n                }\n                if (allow) {\n                    /* trim exec area to allowed bounds */\n                    check_origins_trim_region_helper(base, size, sec_start, sec_end);\n                    return ALLOWING_OK;\n                }\n            }\n        }\n    }\n\n    if (DYNAMO_OPTION(executable_if_dot_data) ||\n        DYNAMO_OPTION(executable_if_dot_data_x) ||\n        (DYNAMO_OPTION(exempt_dot_data) &&\n         !IS_STRING_OPTION_EMPTY(exempt_dot_data_list)) ||\n        (DYNAMO_OPTION(exempt_dot_data_x) &&\n         !IS_STRING_OPTION_EMPTY(exempt_dot_data_x_list))) {\n        /* FIXME: get_module_base() is called all over in this function.\n         *        This function could do with some refactoring. */\n        app_pc modbase = get_module_base(addr);\n        if (modbase != NULL) {\n            /* A loaded module exists for addr; now see if addr is in .data. */\n            app_pc sec_start = NULL, sec_end = NULL;\n            if (is_in_dot_data_section(modbase, addr, &sec_start, &sec_end)) {\n                bool allow = false;\n                bool onlist = false;\n                uint prot = 0;\n                if (!DYNAMO_OPTION(executable_if_dot_data) &&\n                    DYNAMO_OPTION(exempt_dot_data) &&\n                    !IS_STRING_OPTION_EMPTY(exempt_dot_data_list)) {\n                    if (modname != NULL) {\n                        string_option_read_lock();\n                        LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 3,\n                            \"exec region is in data of module %s, vs list %s\\n\",\n                            modname, DYNAMO_OPTION(exempt_dot_data_list));\n                        onlist = check_filter(DYNAMO_OPTION(exempt_dot_data_list), modname);\n                        string_option_read_unlock();\n                        DOSTATS({\n                            if (onlist)\n                                STATS_INC(num_dot_data_list);\n                        });\n                    }\n                }\n                DOSTATS({\n                    if (DYNAMO_OPTION(executable_if_dot_data))\n                        STATS_INC(num_dot_data);\n                });\n                if (onlist || DYNAMO_OPTION(executable_if_dot_data)) {\n                    LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 2,\n                        \"exec region is in .data section of module %s\\n\",\n                        modname == NULL? \"<invalid name>\" : modname);\n                    SYSLOG_INTERNAL_WARNING_ONCE(\n                            \"code origins: .data section of module %s exempt\",\n                            modname == NULL? \"<invalid name>\" : modname);\n                    /* case 9799: FIXME: we don't want to mark as exempted for the\n                     * default modules on the list: should split into a separate\n                     * default list so we can tell!  Those modules will have private\n                     * pcaches if in a process w/ ANY exemption options */\n                    mark_module_exempted(addr);\n                    allow = true;;\n                }\n                if (!allow && get_memory_info(addr, NULL, NULL, &prot) &&\n                    TEST(MEMPROT_EXEC, prot)) {\n                    /* check the _x versions */\n                    if (!DYNAMO_OPTION(executable_if_dot_data_x) &&\n                        DYNAMO_OPTION(exempt_dot_data_x) &&\n                        !IS_STRING_OPTION_EMPTY(exempt_dot_data_x_list)) {\n                        if (modname != NULL) {\n                            string_option_read_lock();\n                            LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 3,\n                                \"exec region is in x data of module %s, vs list %s\\n\",\n                                modname, DYNAMO_OPTION(exempt_dot_data_x_list));\n                            onlist = check_filter_with_wildcards(DYNAMO_OPTION(exempt_dot_data_x_list), modname);\n                            string_option_read_unlock();\n                            DOSTATS({\n                                if (onlist)\n                                    STATS_INC(num_dot_data_x_list);\n                            });\n                        }\n                        DOSTATS({\n                            if (DYNAMO_OPTION(executable_if_dot_data_x))\n                                STATS_INC(num_dot_data_x);\n                        });\n                    }\n                    if (DYNAMO_OPTION(executable_if_dot_data_x) || onlist) {\n                        LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 2,\n                            \"exec region is in x .data section of module %s\\n\",\n                            modname == NULL? \"<invalid name>\" : modname);\n                        SYSLOG_INTERNAL_WARNING_ONCE(\n                                \"code origins: .data section of module %s exempt\",\n                                modname == NULL? \"<invalid name>\" : modname);\n                        /* case 9799: FIXME: we don't want to mark as exempted for\n                         * the default modules on the list: should split into a\n                         * separate default list so we can tell!  Those modules will\n                         * have private pcaches if in a process w/ ANY exemption\n                         * options */\n                        mark_module_exempted(addr);\n                        allow = true;\n                    }\n                }\n                if (allow) {\n                    /* trim exec area to allowed bounds */\n                    check_origins_trim_region_helper(base, size, sec_start, sec_end);\n                    return ALLOWING_OK;\n                }\n            }\n        }\n    }\n\n    if (DYNAMO_OPTION(executable_if_image) ||\n        (DYNAMO_OPTION(exempt_image) &&\n         !IS_STRING_OPTION_EMPTY(exempt_image_list)) ||\n        !moduledb_exempt_list_empty(MODULEDB_EXEMPT_IMAGE)) {\n        app_pc modbase = get_module_base(addr);\n        if (modbase != NULL) {\n            /* A loaded module exists for addr; we allow the module (xref 10526 we\n             * used to limit to just certain sections).  FIXME - we could use the\n             * relaxed is_in_any_section here, but other relaxations (such as dll2heap)\n             * exclude the entire module so need to match that to prevent there being\n             * non exemptable areas. */\n            bool onlist = false;\n            bool mark_exempted = true;\n            if (!DYNAMO_OPTION(executable_if_image)) {\n                if (modname != NULL) {\n                    string_option_read_lock();\n                    LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 3,\n                        \"exec region is in image of module %s, vs list %s\\n\",\n                        modname, DYNAMO_OPTION(exempt_image_list));\n                    onlist = check_filter(DYNAMO_OPTION(exempt_image_list),\n                                          modname);\n                    string_option_read_unlock();\n                    DOSTATS({\n                        if (onlist)\n                            STATS_INC(num_exempt_image_list);\n                    });\n                    if (!onlist &&\n                        !moduledb_exempt_list_empty(MODULEDB_EXEMPT_IMAGE)) {\n                        onlist =\n                            moduledb_check_exempt_list(MODULEDB_EXEMPT_IMAGE,\n                                                       modname);\n                        DOSTATS({\n                            if (onlist)\n                                STATS_INC(num_moduledb_exempt_image);\n                        });\n                        /* FIXME - could be that a later policy would\n                         * allow this in which case we shouldn't report,\n                         * however from layout this is should be the last\n                         * place that could allow this target. */\n                        if (onlist) {\n                            /* Case 9799: We don't want to set this for\n                             * default-on options like moduledb to avoid\n                             * non-shared pcaches when other exemption options\n                             * are turned on in the process.\n                             */\n                            mark_exempted = false;\n                            moduledb_report_exemption(\"Moduledb image exemption\"\n                                                      \" \"PFX\" to \"PFX\" from \"\n                                                      \"module %s\", *base,\n                                                      *base + *size, modname);\n                        }\n                    }\n                }\n            } else {\n                STATS_INC(num_exempt_image);\n            }\n            if (onlist || DYNAMO_OPTION(executable_if_image)) {\n                LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 2,\n                        \"exec region is in the loaded image of module %s\\n\",\n                    modname == NULL ? \"<invalid name>\" : modname);\n                SYSLOG_INTERNAL_WARNING_ONCE(\"code origins: loaded image of module %s\"\n                                             \"exempt\", modname == NULL ?\n                                             \"<invalid name>\" : modname);\n                if (mark_exempted)\n                    mark_module_exempted(addr);\n                return ALLOWING_OK;\n            }\n        }\n    }\n\n    if (((DYNAMO_OPTION(exempt_dll2heap) &&\n          !IS_STRING_OPTION_EMPTY(exempt_dll2heap_list)) ||\n         !moduledb_exempt_list_empty(MODULEDB_EXEMPT_DLL2HEAP) ||\n         (DYNAMO_OPTION(exempt_dll2stack) &&\n          !IS_STRING_OPTION_EMPTY(exempt_dll2stack_list)) ||\n         !moduledb_exempt_list_empty(MODULEDB_EXEMPT_DLL2STACK)) &&\n        /* FIXME: any way to find module info for deleted source? */\n        !LINKSTUB_FAKE(dcontext->last_exit)) {\n        /* no cutting corners here -- find exact module that exit cti is from */\n        app_pc modbase;\n        app_pc translated_pc =\n            recreate_app_pc(dcontext, EXIT_CTI_PC(dcontext->last_fragment,\n                                                  dcontext->last_exit),\n                            dcontext->last_fragment);\n        ASSERT(translated_pc != NULL);\n        modbase = get_module_base(translated_pc);\n        LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 3,\n            \"check_origins: dll2heap and dll2stack for \"PFX\": cache \"PFX\" => app \"PFX\" == mod \"PFX\"\\n\",\n            addr, EXIT_CTI_PC(dcontext->last_fragment, dcontext->last_exit),\n            translated_pc, modbase);\n        if (modbase != NULL) { /* PE, and is readable */\n            if (modname != NULL) {\n                bool onheaplist = false, onstacklist = false;\n                bool on_moddb_heaplist = false, on_moddb_stacklist = false;\n                string_option_read_lock();\n                LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 3,\n                    \"source region is in module %s\\n\", modname);\n                if (DYNAMO_OPTION(exempt_dll2heap)) {\n                    onheaplist = check_filter(DYNAMO_OPTION(exempt_dll2heap_list),\n                                              modname);\n                    LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 3, \"exempt heap list: %s\\n\",\n                        DYNAMO_OPTION(exempt_dll2heap_list));\n                }\n                if (DYNAMO_OPTION(exempt_dll2stack)) {\n                    onstacklist = check_filter(DYNAMO_OPTION(exempt_dll2stack_list),\n                                               modname);\n                    LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 3, \"exempt stack list: %s\\n\",\n                        DYNAMO_OPTION(exempt_dll2stack_list));\n                }\n                string_option_read_unlock();\n                if (!onheaplist) {\n                    on_moddb_heaplist =\n                        moduledb_check_exempt_list(MODULEDB_EXEMPT_DLL2HEAP, modname);\n                }\n                if (!onstacklist) {\n                    on_moddb_stacklist =\n                        moduledb_check_exempt_list(MODULEDB_EXEMPT_DLL2STACK, modname);\n                }\n\n                /* make sure targeting non-stack, non-module memory */\n                if ((onheaplist || on_moddb_heaplist) &&\n                    !is_on_stack(dcontext, addr, NULL) &&\n                    get_module_base(addr) == NULL) {\n                    LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 2,\n                        \"source module %s is on exempt list, target is heap => allowing \"\n                        \"execution\\n\", modname);\n                    if (on_moddb_heaplist) {\n                        STATS_INC(num_moduledb_exempt_dll2heap);\n                        moduledb_report_exemption(\"Moduledb dll2heap exemption \"PFX\" to\"\n                                                  \" \"PFX\" from module %s\",\n                                                  translated_pc, addr, modname);\n                    } else {\n                        STATS_INC(num_exempt_dll2heap);\n                        SYSLOG_INTERNAL_WARNING_ONCE(\"code origins: dll2heap from %s \"\n                                                     \"exempt\", modname);\n                    }\n                    return ALLOWING_OK;\n                }\n                if ((onstacklist || on_moddb_stacklist) &&\n                    is_on_stack(dcontext, addr, NULL)) {\n                    LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 2,\n                        \"source module %s is on exempt list, target is stack => allowing\"\n                        \"execution\\n\", modname);\n                    if (on_moddb_stacklist) {\n                        STATS_INC(num_moduledb_exempt_dll2stack);\n                        moduledb_report_exemption(\"Moduledb dll2stack exemption \"PFX\" \"\n                                                  \"to \"PFX\" from module %s\",\n                                                  translated_pc, addr, modname);\n                    } else {\n                        SYSLOG_INTERNAL_WARNING_ONCE(\"code origins: dll2stack from %s is\"\n                                                     \" exempt\", modname);\n                        STATS_INC(num_exempt_dll2stack);\n                    }\n                    return ALLOWING_OK;\n                }\n            }\n        }\n    }\n\n    if (dynamo_options.executable_if_trampoline) {\n        /* check for specific bb patterns we allow */\n        if (check_origins_bb_pattern(dcontext, addr, base, size, vm_flags, frag_flags)\n            == ALLOWING_OK) {\n            DOSTATS({\n                if (is_on_stack(dcontext, addr, NULL)) {\n                    STATS_INC(num_trampolines_stack);\n                } else {\n                    STATS_INC(num_trampolines_heap);\n                }\n            });\n            return ALLOWING_OK;\n        }\n    }\n\n    if (DYNAMO_OPTION(executable_if_driver)) {\n        if (TEST(VM_DRIVER_ADDRESS, *vm_flags)) {\n            ASSERT(*size == PAGE_SIZE);\n            LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 2,\n                \"check origins: pc = \"PFX\" is in a new driver area\\n\", addr);\n            STATS_INC(num_driver_areas);\n            return ALLOWING_OK;\n        }\n    }\n\n    if (is_on_stack(dcontext, addr, NULL)) {\n        /* WARNING: stack check not bulletproof since attackers control esp */\n        LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 2,\n            \"check origins: pc = \"PFX\" is on the stack\\n\", addr);\n        STATS_INC(num_stack_violations);\n        if (!dynamo_options.executable_stack) {\n            LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 1,\n                \"ERROR: Address \"PFX\" on the stack is not executable!\\n\",\n                addr);\n            return STACK_EXECUTION_VIOLATION;\n        } else {\n            LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 1,\n                \"WARNING: Execution violation @ stack address \"PFX\" detected. \"\n                \"Continuing...\\n\", addr);\n            return ALLOWING_BAD;\n        }\n    } else {\n        STATS_INC(num_heap_violations);\n        if (!dynamo_options.executable_heap) {\n            LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 1,\n                \"ERROR: Address \"PFX\" on the heap is not executable!\\n\", addr);\n            SYSLOG_INTERNAL_WARNING_ONCE(\"Address \"PFX\" on the heap is not executable\",\n                                         addr);\n            return HEAP_EXECUTION_VIOLATION;\n        } else {\n            LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 1,\n                \"WARNING: Execution violation @ heap address \"PFX\" detected. \"\n                \"Continuing...\\n\", addr);\n            return ALLOWING_BAD;\n        }\n    }\n\n    /* CHECK: why did we get here? */\n    ASSERT_NOT_REACHED();\n}\n\n/* It is up to the caller to raise a violation if return value is < 0 */\nstatic INLINE_ONCE int\ncheck_origins(dcontext_t *dcontext, app_pc addr, app_pc *base, size_t *size,\n              uint prot, uint *vm_flags, uint *frag_flags, bool xfer)\n{\n    security_violation_t res;\n    /* Many exemptions need to know the module name, so we obtain here */\n    char modname_buf[MAX_MODNAME_INTERNAL];\n    const char *modname =\n        os_get_module_name_buf_strdup(addr, modname_buf,\n                                      BUFFER_SIZE_ELEMENTS(modname_buf)\n                                      HEAPACCT(ACCT_VMAREAS));\n\n    ASSERT(DYNAMO_OPTION(code_origins));\n    LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 3,\n        \"check origins: pc = \"PFX\"\\n\", addr);\n    res = check_origins_helper(dcontext, addr, base, size, prot, vm_flags, frag_flags,\n                               modname);\n# ifdef DGC_DIAGNOSTICS\n    if (res != ALLOWING_OK) {\n        /* set flag so we can call this area BAD in the future */\n        *frag_flags |= FRAG_DYNGEN_RESTRICTED;\n    }\n# endif\n    if (res < 0) {\n        /* if_x shouldn't have to check here, should catch all regions marked x\n         * at DR init time or app allocation time\n         */\n        /* FIXME: turn these into a SYSLOG_INTERNAL_WARNING_ONCE(in case an\n         * external agent has added that code)\n         * and then we'd need to add them now.\n         * FIXME: xref case 3742\n         */\n        ASSERT_BUG_NUM(3742, !DYNAMO_OPTION(executable_if_x) || !TEST(MEMPROT_EXEC, prot));\n        ASSERT(!DYNAMO_OPTION(executable_if_rx) || !TEST(MEMPROT_EXEC, prot) ||\n                              TEST(MEMPROT_WRITE, prot));\n    }\n    if (modname != NULL && modname != modname_buf)\n        dr_strfree(modname HEAPACCT(ACCT_VMAREAS));\n    return res;\n}\n\n/* returns whether it ended up deleting the self-writing fragment\n * by flushing the region\n */\nbool\nvm_area_fragment_self_write(dcontext_t *dcontext, app_pc tag)\n{\n    if (!dynamo_options.executable_stack && is_on_stack(dcontext, tag, NULL)) {\n        /* stack code is NOT persistently executable, nor is it allowed to be\n         * written, period!  however, in keeping with our philosophy of only\n         * interfering with the program when it executes, we don't stop it\n         * at the write here, we simply remove the code from the executable\n         * list and remove its sandboxing.  after all, the code on the stack\n         * may be finished with, and now the stack is just being used as data!\n         *\n         * FIXME: there is a hole here due to selfmod fragments\n         * being private: a second thread can write to a stack region and then\n         * execute from the changed region w/o kicking it off the executable\n         * list.  case 4020 fixed this for pattern-matched regions.\n         */\n        bool ok;\n        vm_area_t *area = NULL;\n        app_pc start, end;\n        read_lock(&executable_areas->lock);\n        ok = lookup_addr(executable_areas, tag, &area);\n        ASSERT(ok);\n        /* grab fields since can't hold lock entire time */\n        start = area->start;\n        end = area->end;\n        read_unlock(&executable_areas->lock);\n        LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 1,\n            \"WARNING: code on stack \"PFX\"-\"PFX\" @tag \"PFX\" written to\\n\",\n            start, end, tag);\n        SYSLOG_INTERNAL_WARNING_ONCE(\"executable code on stack written to.\");\n        /* FIXME: fragment could extend into multiple areas, we should flush\n         * them all to cover the written-to region (which we don't know)\n         */\n        flush_fragments_and_remove_region(dcontext, start, end - start,\n                                          false /* don't own initexit_lock */,\n                                          false /* keep futures */);\n        return true;\n    }\n    return false;\n}\n#endif /* PROGRAM_SHEPHERDING ******************************************/\n\n#ifdef SIMULATE_ATTACK\n\nenum {\n    SIMULATE_INIT       = 0,\n    SIMULATE_GENERIC    = 1,\n    SIMULATE_AT_ADDR    = 2,\n    SIMULATE_AT_FRAGNUM = 4,\n    SIMULATE_WIPE_STACK = 8,\n    SIMULATE_OVER       = 0x1000,\n};\n\n/* attack simulation list */\n/* comma separated list of simulate points.\n     @fragnum\n        fragment number available only in DEBUG builds\n     0xfragpc\n        will test addr only whenever check_thread_vm_area is called\n        start of bb, pc at end of direct cti instr, target of direct cti,\n        pc at end of final instr in bb\n     s: prefix wipes the stack\n   Ex: -simulate_at @100,s:@150,0x77e9e8d6,s:0x77e9e8f0,@777,@2000,s:@19999,@29999\n*/\n/* simulate_at is modified in place, hence caller needs to synchronize\n   and should be 0 after the first call just like strtok */\nint\nnext_simulate_at_fragment(char **tokpos /* OUT */, int *action /* OUT */)\n{\n    char *fragnum;\n\n    // assumes sscanf won't get confused with the ,s\n    for(fragnum = *tokpos; fragnum; fragnum = *tokpos) {\n        int num;\n        *tokpos = strchr(fragnum, ','); /* next ptr */\n        if (*tokpos)\n            (*tokpos)++;\n\n        if (sscanf(fragnum, PIFX, &num) == 1) {\n            LOG(GLOBAL, LOG_VMAREAS, 1,\n                \"next_simulate_at_fragment: %s=\"PIFX\" addr\\n\", fragnum, num);\n            *action = SIMULATE_AT_ADDR;\n            return num;\n        } else if (sscanf(fragnum, \"s:\"PIFX, &num) == 1) {\n            LOG(GLOBAL, LOG_VMAREAS, 1,\n                \"next_simulate_at_fragment: wipe stack %s=\"PIFX\"\\n\", fragnum, num);\n            *action = SIMULATE_WIPE_STACK | SIMULATE_AT_ADDR;\n            return num;\n        }\n#ifdef DEBUG                    /* for fragment count */\n        else if (sscanf(fragnum, \"s:@%d\", &num) == 1) {\n            LOG(GLOBAL, LOG_VMAREAS, 1,\n                \"next_simulate_at_fragment: wipe stack %s=%d\\n\", fragnum, num);\n            *action = SIMULATE_WIPE_STACK | SIMULATE_AT_FRAGNUM;\n            return num;\n        } else if (sscanf(fragnum, \"@%d\", &num) == 1) {\n            LOG(GLOBAL, LOG_VMAREAS, 1,\n                \"next_simulate_at_fragment: %s=%d num\\n\", fragnum, num);\n            *action = SIMULATE_AT_FRAGNUM;\n            return num;\n        }\n#endif\n        else {\n            LOG(GLOBAL, LOG_VMAREAS, 1,\n                \"next_simulate_at_fragment: frg=%s ignored\\n\", fragnum);\n        }\n    }\n\n    *action = SIMULATE_OVER;\n    LOG(GLOBAL, LOG_VMAREAS, 1,\n        \"next_simulate_at_fragment: simulate attack over\\n\");\n\n    return 0;\n}\n\nvoid\nsimulate_attack(dcontext_t *dcontext, app_pc pc)\n{\n    static char *tokpos;\n    static int next_frag = 0;   /* number or address */\n    static int action = SIMULATE_INIT;\n\n    bool attack = false;\n\n    if (TEST(SIMULATE_AT_FRAGNUM, action)) {\n        attack = GLOBAL_STAT(num_fragments) > next_frag;\n    }\n    if (TEST(SIMULATE_AT_ADDR, action)) {\n        if (pc == (app_pc)next_frag)\n            attack = true;\n    }\n\n    if (attack) {\n        LOG(GLOBAL, LOG_VMAREAS, 1,\n            \"SIMULATE ATTACK for \"PFX\" @%d frags\\n\", pc, GLOBAL_STAT(num_fragments));\n\n        if (TEST(SIMULATE_WIPE_STACK, action)) {\n            reg_t esp = get_mcontext(dcontext)->xsp;\n            uint overflow_size = 1024;\n            LOG(THREAD_GET, LOG_VMAREAS, 1, \"simulate_attack: wipe stack \"PFX\"-\"PFX\"\\n\",\n                esp, esp + overflow_size-1);\n\n            /* wipe out a good portion of the app stack */\n            memset((void*)esp, 0xbf, overflow_size); /* LOOK for 0xbf in the log */\n            LOG(THREAD_GET, LOG_VMAREAS, 1, \"simulate_attack: wiped stack \"PFX\"-\"PFX\"\\n\",\n                esp, esp + overflow_size-1);\n\n            /* FIXME: we may want to just wipe the stack and return to app */\n        }\n    }\n\n    /* prepare for what to do next */\n    if (attack || action == SIMULATE_INIT) {\n        mutex_lock(&simulate_lock);\n        string_option_read_lock();\n        tokpos = dynamo_options.simulate_at;\n        if (action == SIMULATE_INIT) {\n            if ('\\0' == *tokpos)\n                tokpos = NULL;\n        }\n        next_frag = next_simulate_at_fragment(&tokpos, &action);\n        /* dynamic changes to the string may have truncated it in front of original */\n        ASSERT(tokpos < strchr(dynamo_options.simulate_at, '\\0'));\n        string_option_read_unlock();\n        /* FIXME: tokpos ptr is kept beyond release of lock! */\n        mutex_unlock(&simulate_lock);\n    }\n\n    if (attack) {\n        security_violation(dcontext, pc, ATTACK_SIMULATION_VIOLATION,\n                           OPTION_BLOCK|OPTION_REPORT);\n    }\n}\n#endif /* SIMULATE_ATTACK */\n\n#if defined(DEBUG) && defined(INTERNAL)\nstatic void\nprint_entry(dcontext_t *dcontext, fragment_t *entry, const char *prefix)\n{\n    if (entry == NULL)\n        LOG(THREAD, LOG_VMAREAS, 1, \"%s<NULL>\\n\", prefix);\n    else if (FRAG_MULTI(entry)) {\n        if (FRAG_MULTI_INIT(entry)) {\n            LOG(THREAD, LOG_VMAREAS, 1, \"%s\"PFX\" <init: tag=\"PFX\"> pc=\"PFX\"\\n\",\n                prefix, entry, FRAG_FRAG(entry), FRAG_PC(entry));\n        } else {\n            LOG(THREAD, LOG_VMAREAS, 1, \"%s\"PFX\" F=\"PFX\" pc=\"PFX\"\\n\",\n                prefix, entry, FRAG_FRAG(entry), FRAG_PC(entry));\n        }\n    } else {\n        fragment_t *f = (fragment_t *) entry;\n        LOG(THREAD, LOG_VMAREAS, 1, \"%s\"PFX\" F%d tag=\"PFX\"\\n\",\n            prefix, f, f->id, f->tag);\n    }\n}\n\nstatic void\nprint_fraglist(dcontext_t *dcontext, vm_area_t *area, const char *prefix)\n{\n    fragment_t *entry, *last;\n    LOG(THREAD, LOG_VMAREAS, 1, \"%sFragments for area (\"PFX\") \"PFX\"..\"PFX\"\\n\",\n        prefix, area, area->start, area->end);\n    for (entry = area->custom.frags, last = NULL; entry != NULL;\n         last = entry, entry = FRAG_NEXT(entry)) {\n        print_entry(dcontext, entry, \"\\t\");\n        DOLOG(7, LOG_VMAREAS, {\n            print_entry(dcontext, FRAG_PREV(entry), \"\\t    <=\");\n            print_entry(dcontext, FRAG_NEXT(entry), \"\\t    =>\");\n        });\n        if (FRAG_ALSO(entry) != NULL) {\n            fragment_t *also = FRAG_ALSO(entry);\n            print_entry(dcontext, FRAG_ALSO(entry), \"\\t    also =>\");\n\n            /* check for also in same area == inconsistency in data structs */\n            if (FRAG_PC(also) >= area->start && FRAG_PC(also) < area->end) {\n                if (FRAG_MULTI_INIT(also)) {\n                    LOG(THREAD, LOG_VMAREAS, 1, \"WARNING: self-also frag tag \"PFX\"\\n\",\n                        FRAG_FRAG(also));\n                } else {\n                    fragment_t *f = FRAG_FRAG(also);\n                    LOG(THREAD, LOG_VMAREAS, 1, \"WARNING: self-also frag F%d(\"PFX\")%s\\n\",\n                        f->id, f->tag, TEST(FRAG_IS_TRACE, f->flags) ? \" trace\" : \"\");\n                }\n                /* not an assertion b/c we sometimes print prior to cleaning */\n            }\n        }\n\n        ASSERT(last == NULL || last == FRAG_PREV(entry));\n    }\n    ASSERT(area->custom.frags == NULL || FRAG_PREV(area->custom.frags) == last);\n}\n\nstatic void\nprint_fraglists(dcontext_t *dcontext)\n{\n    thread_data_t *data = GET_DATA(dcontext, 0);\n    int i;\n    ASSERT_VMAREA_DATA_PROTECTED(data, READWRITE);\n    LOG(THREAD, LOG_VMAREAS, 1, \"\\nFragment lists for ALL AREAS:\\n\");\n    for (i = 0; i < data->areas.length; i++) {\n        print_fraglist(dcontext, &(data->areas.buf[i]), \"\");\n    }\n    LOG(THREAD, LOG_VMAREAS, 1, \"\\n\");\n}\n\nstatic void\nprint_frag_arealist(dcontext_t *dcontext, fragment_t *f)\n{\n    fragment_t *entry;\n    if (FRAG_MULTI(f)) {\n        LOG(THREAD, LOG_VMAREAS, 1, \"Areas for F=\"PFX\" (\"PFX\")\\n\",\n            FRAG_FRAG(f), FRAG_PC(f));\n    } else\n        LOG(THREAD, LOG_VMAREAS, 1, \"Areas for F%d (\"PFX\")\\n\", f->id, f->tag);\n    for (entry = f; entry != NULL; entry = FRAG_ALSO(entry)) {\n        print_entry(dcontext, entry, \"\\t\");\n    }\n}\n#endif /* DEBUG && INTERNAL */\n\n#ifdef DEBUG\nstatic bool\narea_contains_frag_pc(vm_area_t *area, fragment_t *f)\n{\n    app_pc pc = FRAG_PC(f);\n    if (area == NULL)\n        return true;\n    return (pc >= area->start && pc < area->end);\n}\n#endif /* DEBUG */\n\n/* adds entry to front of area's frags list\n * caller must synchronize modification of area\n * FIXME: how assert that caller has done that w/o asking for whole vector\n * to be passed in, or having backpointer from area?\n * See general FIXME of same flavor at top of file.\n */\nstatic void\nprepend_entry_to_fraglist(vm_area_t *area, fragment_t *entry)\n{\n    /* Can't assert area_contains_frag_pc() because vm_area_unlink_fragments\n     * moves all also entries onto the area fraglist that's being flushed.\n     */\n    LOG(THREAD_GET, LOG_VMAREAS, 4,\n        \"%s: putting fragment @\"PFX\" (%s) on vmarea \"PFX\"-\"PFX\"\\n\",\n        /* i#1215: FRAG_ID(entry) can crash if entry->f hold tag temporarily */\n        __FUNCTION__, FRAG_PC(entry),\n        TEST(FRAG_SHARED, entry->flags) ? \"shared\" : \"private\",\n        area->start, area->end);\n    FRAG_NEXT_ASSIGN(entry, area->custom.frags);\n    /* prev wraps around, but not next */\n    if (area->custom.frags != NULL) {\n        FRAG_PREV_ASSIGN(entry, FRAG_PREV(area->custom.frags));\n        FRAG_PREV_ASSIGN(area->custom.frags, entry);\n    } else\n        FRAG_PREV_ASSIGN(entry, entry);\n    area->custom.frags = entry;\n}\n\n/* adds a multi_entry_t to the list of fragments for area.\n * cross-links with prev if prev != NULL.\n * sticks tag in for f (will be fixed in vm_area_add_fragment, once f is created)\n */\nstatic fragment_t *\nprepend_fraglist(dcontext_t *dcontext, vm_area_t *area, app_pc entry_pc,\n                 app_pc tag, fragment_t *prev)\n{\n    multi_entry_t *e = (multi_entry_t *)\n        nonpersistent_heap_alloc(dcontext, sizeof(multi_entry_t) HEAPACCT(ACCT_VMAREA_MULTI));\n    fragment_t * entry = (fragment_t *) e;\n    e->flags = FRAG_FAKE | FRAG_IS_EXTRA_VMAREA | /* distinguish from fragment_t */\n        FRAG_IS_EXTRA_VMAREA_INIT; /* indicate f field is a tag, not a fragment_t yet */\n    if (dcontext == GLOBAL_DCONTEXT) /* shared */\n        e->flags |= FRAG_SHARED;\n    e->f = (fragment_t *) tag; /* placeholder */\n    e->pc = entry_pc;\n    if (prev != NULL)\n        FRAG_ALSO_ASSIGN(prev, entry);\n    FRAG_ALSO_ASSIGN(entry, NULL);\n    ASSERT(area_contains_frag_pc(area, entry));\n    prepend_entry_to_fraglist(area, entry);\n    DOLOG(7, LOG_VMAREAS, {\n        print_fraglist(dcontext, area, \"after prepend_fraglist, \");\n    });\n    return entry;\n}\n\n#ifdef DGC_DIAGNOSTICS\nvoid\ndyngen_diagnostics(dcontext_t *dcontext, app_pc pc, app_pc base_pc, size_t size,\n                   uint prot)\n{\n    bool future, stack;\n    char buf[MAXIMUM_SYMBOL_LENGTH];\n    app_pc translated_pc;\n\n    read_lock(&futureexec_areas->lock);\n    future = lookup_addr(futureexec_areas, pc, NULL);\n    read_unlock(&futureexec_areas->lock);\n    stack = is_on_stack(dcontext, pc, NULL);\n\n    if (!future)\n        future = is_dyngen_vsyscall(pc);\n\n    print_symbolic_address(pc, buf, sizeof(buf), false);\n    LOG(GLOBAL, LOG_VMAREAS, 1,\n        \"DYNGEN in %d: target=\"PFX\" => \"PFX\"-\"PFX\" %s%s%s%s%s %s\\n\",\n        dcontext->owning_thread, pc, base_pc, base_pc+size,\n        ((prot & MEMPROT_READ) != 0) ? \"R\":\"\",\n        ((prot & MEMPROT_WRITE) != 0)? \"W\":\"\",\n        ((prot & MEMPROT_EXEC) != 0) ? \"E\":\"\",\n        future ? \" future\":\" BAD\", stack ? \" stack\":\"\", buf);\n\n    if (LINKSTUB_FAKE(dcontext->last_exit)) {\n        LOG(GLOBAL, LOG_VMAREAS, 1,\n            \"source=!!! fake last_exit, must have been flushed?\\n\");\n        return;\n    }\n\n    /* FIXME: risky if last fragment is deleted -- should check for that\n     * here and instead just print type from last_exit, since recreate\n     * may fail\n     */\n    translated_pc =\n        recreate_app_pc(dcontext, EXIT_CTI_PC(dcontext->last_fragment,\n                                              dcontext->last_exit),\n                        dcontext->last_fragment);\n    if (translated_pc != NULL) {\n        print_symbolic_address(translated_pc, buf, sizeof(buf), false);\n        LOG(GLOBAL, LOG_VMAREAS, 1,\n            \"source=F%d(\"PFX\") @\"PFX\" \\\"%s\\\"\\n\",\n            dcontext->last_fragment->id,\n            dcontext->last_fragment->tag,\n            EXIT_CTI_PC(dcontext->last_fragment, dcontext->last_exit), buf);\n        disassemble_with_bytes(dcontext, translated_pc, main_logfile);\n    }\n    DOLOG(4, LOG_VMAREAS, {\n        disassemble_fragment(dcontext, dcontext->last_fragment, false);\n    });\n}\n#endif\n\n/***************************************************************************\n * APPLICATION MEMORY STATE TRACKING\n */\n\n/* Checks whether a requested allocation at a particular base will change\n * the protection bits of any code.  Returns whether or not to allow\n * the operation to go through.\n */\nbool\napp_memory_pre_alloc(dcontext_t *dcontext, byte *base, size_t size, uint prot,\n                     bool hint)\n{\n    byte *pb = base;\n    dr_mem_info_t info;\n    while (pb < base + size &&\n           /* i#1462: getting the true bounds on Windows is expensive so we get just\n            * the cur base first.  This can result in an extra syscall in some cases,\n            * but in large-region cases it saves huge number of syscalls.\n            */\n           query_memory_cur_base(pb, &info)) {\n        if (info.type != DR_MEMTYPE_FREE &&\n            info.type != DR_MEMTYPE_RESERVED) {\n            size_t change_sz;\n            uint subset_memprot;\n            uint res;\n            /* We need the real base */\n            if (!query_memory_ex(pb, &info))\n                break;\n            change_sz = MIN(info.base_pc + info.size - pb,  base + size - pb);\n            if (hint) {\n                /* Just have caller remove the hint, before we go through\n                 * -handle_dr_modify handling.\n                 */\n                return false;\n            }\n            res = app_memory_protection_change(dcontext, pb, change_sz, prot,\n                                               &subset_memprot, NULL);\n            if (res != DO_APP_MEM_PROT_CHANGE) {\n                if (res == FAIL_APP_MEM_PROT_CHANGE) {\n                    return false;\n                } else if (res == PRETEND_APP_MEM_PROT_CHANGE ||\n                           res == SUBSET_APP_MEM_PROT_CHANGE) {\n                    /* This gets complicated to handle.  If the syscall is\n                     * changing a few existing pages and then allocating new\n                     * pages beyond them, we could adjust the base: but there\n                     * are many corner cases.  Thus we fail the syscall, which\n                     * is the right thing for cases we've seen like i#1178\n                     * where the app tries to commit to a random address!\n                     */\n                    SYSLOG_INTERNAL_WARNING_ONCE(\"Failing app alloc w/ suspect overlap\");\n                    return false;\n                }\n            }\n        }\n        if (POINTER_OVERFLOW_ON_ADD(info.base_pc, info.size))\n            break;\n        pb = info.base_pc + info.size;\n    }\n    return true;\n}\n\n/* newly allocated or mapped in memory region, returns true if added to exec list\n * ok to pass in NULL for dcontext -- in fact, assumes dcontext is NULL at initialization\n *\n * It's up to the caller to handle any changes in protection in a new alloc that\n * overlaps an existing alloc, by calling app_memory_protection_change().\n */\nbool\napp_memory_allocation(dcontext_t *dcontext, app_pc base, size_t size, uint prot,\n                      bool image _IF_DEBUG(const char *comment))\n{\n    /* FIXME (case 68): to guard against external agents freeing memory, we\n     * could remove this region from the executable list here -- is it worth the\n     * performance hit?  DR itself could allocate memory that was freed\n     * externally -- but our DR overlap checks would catch that.\n     */\n    ASSERT_CURIOSITY(!executable_vm_area_overlap(base, base + size,\n                                                 false/*have no lock*/) ||\n                     /* This happens during module loading if we don't flush on mprot */\n                     (!INTERNAL_OPTION(hw_cache_consistency) &&\n                      /* .bss has !image so we just check for existing module overlap */\n                      pc_is_in_module(base)));\n#ifdef PROGRAM_SHEPHERDING\n    DODEBUG({\n        /* case 4175 - reallocations will overlap with no easy way to\n         * enforce this\n         */\n        if (futureexec_vm_area_overlap(base, base + size)) {\n            SYSLOG_INTERNAL_WARNING_ONCE(\"existing future area overlapping [\"PFX\", \"\n                                         PFX\")\", base, base + size);\n        }\n    });\n#endif\n\n    /* no current policies allow non-x code at allocation time onto exec list */\n    if (!TEST(MEMPROT_EXEC, prot))\n        return false;\n\n    /* Do not add our own code cache and other data structures\n     * to executable list -- but do add our code segment\n     * FIXME: checking base only is good enough?\n     */\n    if (dynamo_vm_area_overlap(base, base + size)) {\n        LOG(GLOBAL, LOG_VMAREAS, 2, \"\\t<dynamorio region>\\n\");\n        /* assumption: preload/preinject library is not on DR area list since unloaded */\n        if (!is_in_dynamo_dll(base) /* our own text section is ok */\n            /* client lib text section is ok (xref i#487) */\n            IF_CLIENT_INTERFACE(&& !is_in_client_lib(base)))\n            return false;\n    }\n\n    LOG(GLOBAL, LOG_VMAREAS, 1, \"New +x app memory region: \"PFX\"-\"PFX\" %s\\n\",\n        base, base+size, memprot_string(prot));\n\n    if (!TEST(MEMPROT_WRITE, prot)) {\n        uint frag_flags = 0;\n        if (DYNAMO_OPTION(coarse_units) && image && !RUNNING_WITHOUT_CODE_CACHE()) {\n            /* all images start out with coarse-grain management */\n            frag_flags |= FRAG_COARSE_GRAIN;\n        }\n        add_executable_vm_area(base, base + size, image ? VM_UNMOD_IMAGE : 0, frag_flags,\n                               false/*no lock*/ _IF_DEBUG(comment));\n        return true;\n    } else if (dcontext==NULL ||\n               /* i#626: we skip is_no_stack because of no mcontext at init time,\n                * we also assume that no alloc overlaps w/ stack at init time.\n                */\n               (IF_CLIENT_INTERFACE(dynamo_initialized &&)\n                !is_on_stack(dcontext, base, NULL))) {\n        LOG(GLOBAL, LOG_VMAREAS, 1,\n            \"WARNING: \"PFX\"-\"PFX\" is writable, NOT adding to executable list\\n\",\n            base, base+size);\n\n#ifdef PROGRAM_SHEPHERDING\n        if (DYNAMO_OPTION(executable_if_x)) {\n            LOG(GLOBAL, LOG_VMAREAS, 1,\n                \"app_memory_allocation: New future exec region b/c x: \"PFX\"-\"PFX\" %s\\n\",\n                base, base+size, memprot_string(prot));\n            STATS_INC(num_mark_if_x);\n            add_futureexec_vm_area(base, base+size, false/*permanent*/\n                                   _IF_DEBUG(\"alloc executable_if_x\"));\n            mark_module_exempted(base);\n        } else if (DYNAMO_OPTION(executable_if_alloc)) {\n            bool future = false;\n            /* rwx regions are not added at init time unless in images */\n# ifdef WINDOWS\n            if (image) {\n                /* anything marked rwx in an image is added to future list\n                 * otherwise it is not added -- must be separately allocated,\n                 * not just be present at init or in a mapped non-image file\n                 */\n                future = true;\n                LOG(GLOBAL, LOG_VMAREAS, 1,\n                    \"New future exec region b/c x from image: \"PFX\"-\"PFX\" %s\\n\",\n                    base, base+size, memprot_string(prot));\n            } else if (dcontext != NULL && dcontext->alloc_no_reserve) {\n                /* we only add a region marked rwx at allocation time to the\n                 * future list if it is allocated and reserved at the same time\n                 * (to distinguish from the rwx heap on 2003)\n                 */\n                future = true;\n                LOG(GLOBAL, LOG_VMAREAS, 1,\n                    \"New future exec region b/c x @alloc & no reserve: \"PFX\"-\"PFX\" %s\\n\",\n                    base, base+size, memprot_string(prot));\n            }\n# else\n            if (dcontext != NULL || image) {\n                /* can't distinguish stack -- saved at init time since we don't add rwx then,\n                 * but what about stacks whose creation we see?  FIXME\n                 */\n                future = true;\n                LOG(GLOBAL, LOG_VMAREAS, 1,\n                    \"New future exec region b/c x @alloc: \"PFX\"-\"PFX\" %s\\n\",\n                    base, base+size, memprot_string(prot));\n            }\n# endif\n            if (future) {\n                STATS_INC(num_alloc_exec);\n                add_futureexec_vm_area(base, base+size, false/*permanent*/\n                                       _IF_DEBUG(\"alloc x\"));\n            }\n        }\n#endif /* PROGRAM_SHEPHERDING */\n    }\n    return false;\n}\n\n/* de-allocated or un-mapped memory region */\nvoid\napp_memory_deallocation(dcontext_t *dcontext, app_pc base, size_t size,\n                        bool own_initexit_lock, bool image)\n{\n    ASSERT(!dynamo_vm_area_overlap(base, base + size));\n    /* we check for overlap regardless of memory protections, to allow flexible\n     * policies that are independent of rwx bits -- if any overlap we remove,\n     * no shortcuts\n     */\n    if (executable_vm_area_overlap(base, base + size, false/*have no lock*/)) {\n        /* ok for overlap to have changed in between, flush checks again */\n        flush_fragments_and_remove_region(dcontext, base, size, own_initexit_lock,\n                                          true/*free futures*/);\n\n#ifdef RETURN_AFTER_CALL\n        if (DYNAMO_OPTION(ret_after_call) && !image\n            && !DYNAMO_OPTION(rac_dgc_sticky)) {\n            /* we can have after call targets in DGC in addition to DLLs */\n            /* Note IMAGE mappings are handled in process_image() on\n             * Windows, so that they can be handled more efficiently\n             * as a single region. FIXME: case 4983 on Linux\n             */\n            /* only freeing if we have ever interp/executed from this area */\n\n            /* FIXME: note that on app_memory_protection_change() we\n             * do NOT want to free these entries, therefore we'd have\n             * a leak if a portion gets marked writable and is thus no\n             * longer on our list.  Note we can't flush the areas on\n             * memory protection because the likelihood of introducing\n             * a false positives in doing so is vastly greater than\n             * the security risk of not flushing.  (Many valid after\n             * call locations may still be active, and our vmarea\n             * boundaries can not precisely capture the application\n             * intent.)  Note that we would not leak on DLLs even if\n             * they are made writable, because we treat separately.\n             */\n            /* FIXME: see proposal in case 2236 about using a\n             * heuristic that removes only when too numerous, if that\n             * works well as a heuristic that DGC is being reused, and\n             * unlikely that it will be so densely filled.\n             */\n\n            /* FIXME: [perf] case 9331 this is not so good on all\n             * deallocations, if we can't tell whether we have\n             * executed from it.  On every module LOAD, before mapping\n             * it as MEM_IMAGE the loader first maps a DLL as\n             * MEM_MAPPED, and on each of the corresponding unmaps\n             * during LoadLibrary(), we'd be walking the cumulative\n             * hashtable.  Although there shouldn't be that many valid\n             * AC entries at process startup, maybe best to leave the\n             * DGC leak for now if this will potentially hurt startup\n             * time in say svchost.exe.  Currently rac_dgc_sticky is\n             * on by default so we don't reach this code.\n             */\n            /* case 9331: should find out if there was any true\n             * execution in any thread here before we go through a\n             * linear walk of the hashtable.  More directly we need a\n             * vmvector matching all vmareas that had a .C added for\n             * them, considering the common case should be that this\n             * is an app memory deallocation that has nothing to do\n             * with us.\n             *\n             * FIXME: for now just checking if base is declared DGC,\n             * and ignoring any others possible vm_areas for the same\n             * OS region, so we may still have a leak.\n             */\n            if (is_dyngen_code(base)) {\n                ASSERT_NOT_TESTED();\n                invalidate_after_call_target_range(dcontext, base, base+size);\n            }\n        }\n#endif /* RETURN_AFTER_CALL */\n    }\n\n#ifdef PROGRAM_SHEPHERDING\n    if (USING_FUTURE_EXEC_LIST && futureexec_vm_area_overlap(base, base + size)) {\n        remove_futureexec_vm_area(base, base + size);\n        LOG(GLOBAL, LOG_VMAREAS, 2,\n            \"removing future exec \"PFX\"-\"PFX\" since now freed\\n\", base, base+size);\n    }\n#endif\n}\n\n/* A convenience routine that starts the two-phase flushing protocol */\n/* Note this is not flush_fragments_and_remove_region */\nstatic bool\nflush_and_remove_executable_vm_area(dcontext_t *dcontext,\n                                    app_pc base, size_t size)\n{\n    DEBUG_DECLARE(bool res;)\n    flush_fragments_in_region_start(dcontext, base, size,\n                                    false /* don't own initexit_lock */,\n                                    false /* case 2236: keep futures */,\n                                    true /* exec invalid */,\n                                    false /* don't force synchall */\n                                    _IF_DGCDIAG(NULL));\n    DEBUG_DECLARE(res = )\n        remove_executable_vm_area(base, base + size, true/*have lock*/);\n    DODEBUG(if (!res) {\n        /* area doesn't have to be executable in fact when called\n         * on executable_if_hook path\n         */\n        LOG(THREAD, LOG_VMAREAS, 2,\n            \"\\tregion was in fact not on executable_areas, so nothing to remove\\n\");\n    });\n    /* making sure there is no overlap now */\n    ASSERT(!executable_vm_area_overlap(base, base+size, true /* holding lock */));\n\n    return true;\n}\n\nvoid\ntamper_resistant_region_add(app_pc start, app_pc end)\n{\n    /* For now assuming a single area for specially protected areas\n     * that is looked up in addition to dynamo_vm_areas.  Assuming\n     * modifications to any location is ntdll.dll is always\n     * interesting to us, instead of only those pieces we trampoline\n     * this should be sufficient.\n     *\n     * FIXME: we could add a new vm_area_vector_t for protected possibly\n     * subpage regions that we later turn into pretend_writable_areas\n     *\n     * Note that ntdll doesn't have an IAT section so we only worry\n     * about function patching\n     */\n    ASSERT(tamper_resistant_region_start == NULL);\n    tamper_resistant_region_start = start;\n    tamper_resistant_region_end = end;\n}\n\n/* returns true if [start, end) overlaps with a tamper_resistant region\n * as needed for DYNAMO_OPTION(handle_ntdll_modify)\n */\nbool\ntamper_resistant_region_overlap(app_pc start, app_pc end)\n{\n    return (end > tamper_resistant_region_start &&\n            start < tamper_resistant_region_end);\n}\n\nbool\nis_jit_managed_area(app_pc addr)\n{\n    uint vm_flags;\n    if (get_executable_area_vm_flags(addr, &vm_flags))\n        return TEST(VM_JIT_MANAGED, vm_flags);\n    else\n        return false;\n}\n\nvoid\nset_region_jit_managed(app_pc start, size_t len)\n{\n    vm_area_t *region;\n\n    ASSERT(DYNAMO_OPTION(opt_jit));\n    write_lock(&executable_areas->lock);\n    if (lookup_addr(executable_areas, start, &region)) {\n        LOG(GLOBAL, LOG_VMAREAS, 1, \"set_region_jit_managed(\"PFX\" +0x%x)\\n\", start, len);\n        ASSERT(region->start == start && region->end == (start+len));\n        if (!TEST(VM_JIT_MANAGED, region->vm_flags)) {\n            if (TEST(VM_MADE_READONLY, region->vm_flags))\n               vm_make_writable(region->start, region->end - region->start);\n            region->vm_flags |= VM_JIT_MANAGED;\n            region->vm_flags &= ~(VM_MADE_READONLY | VM_DELAY_READONLY);\n            LOG(GLOBAL, LOG_VMAREAS, 1,\n                \"Region (\"PFX\" +0x%x) no longer 'made readonly'\\n\", start, len);\n        }\n    } else {\n        LOG(GLOBAL, LOG_VMAREAS, 1, \"Generating new jit-managed vmarea: \"PFX\"-\"PFX\"\\n\",\n            start, start+len);\n\n        add_vm_area(executable_areas, start, start+len, VM_JIT_MANAGED, 0, NULL\n                    _IF_DEBUG(\"jit-managed\"));\n    }\n    write_unlock(&executable_areas->lock);\n}\n\n/* memory region base:base+size now has privileges prot\n * returns a value from the enum in vmareas->h about whether to perform the\n * system call or not and if not what the return code to the app should be\n */\n/* FIXME : This is called before the system call that will change\n * the memory permission which could be race condition prone! If another\n * thread executes from a region added by this function before the system call\n * goes through we could get a disconnect on what the memory premissions of the\n * region really are vs what vmareas expects for consistency, see bug 2833\n*/\n/* N.B.: be careful about leaving code read-only and returning\n * PRETEND_APP_MEM_PROT_CHANGE or SUBSET_APP_MEM_PROT_CHANGE, or other\n * cases where mixed with native execution we may have incorrect page settings -\n * e.g. make sure all pages that need to be executable are executable!\n *\n * Note new_memprot is set only for SUBSET_APP_MEM_PROT_CHANGE,\n * and old_memprot is set for PRETEND_APP_MEM_PROT_CHANGE or SUBSET_APP_MEM_PROT_CHANGE.\n */\n/* Note: hotp_only_mem_prot_change() relies on executable_areas to find out\n * previous state, so eliminating it should be carefully; see case 6669.\n */\nuint\napp_memory_protection_change(dcontext_t *dcontext, app_pc base, size_t size,\n                             uint prot, /* platform independent MEMPROT_ */\n                             uint *new_memprot, /* OUT */\n                             uint *old_memprot /* OPTIONAL OUT*/)\n{\n    /* FIXME: look up whether image, etc. here?\n     * but could overlap multiple regions!\n     */\n    bool is_executable;\n\n    bool should_finish_flushing = false;\n\n    bool dr_overlap = DYNAMO_OPTION(handle_DR_modify) != DR_MODIFY_OFF /* we don't care */\n        && dynamo_vm_area_overlap(base, base + size);\n\n    bool system_overlap = DYNAMO_OPTION(handle_ntdll_modify) != DR_MODIFY_OFF /* we don't care */\n        && tamper_resistant_region_overlap(base, base + size);\n\n    bool patch_proof_overlap = false;\n#ifdef WINDOWS\n    uint frag_flags;\n#endif\n    ASSERT(new_memprot != NULL);\n    /* old_memprot is optional */\n\n#if defined(PROGRAM_SHEPHERDING) && defined(WINDOWS)\n    patch_proof_overlap = (!IS_STRING_OPTION_EMPTY(patch_proof_default_list) ||\n                           !IS_STRING_OPTION_EMPTY(patch_proof_list)) &&\n        vmvector_overlap(patch_proof_areas, base, base + size);\n    /* FIXME: [minor perf] all the above tests can be combined into a\n     * single vmarea lookup when this feature default on, case 6632 */\n    ASSERT(base != NULL);\n    if (patch_proof_overlap) {\n        app_pc modbase = get_module_base(base);\n        bool loader = is_module_patch_region(dcontext, base, base+size,\n                                             false/*be liberal: don't miss loader*/);\n        bool patching_code = is_range_in_code_section(modbase, base, base+size,\n                                                      NULL, NULL);\n        bool patching_IAT = is_IAT(base, base+size, true/*page-align*/, NULL, NULL);\n        /* FIXME: [perf] could have added CODE sections instead of modules to patch_proof_areas */\n        /* FIXME: [minor perf] is_module_patch_region already collected these */\n        /* FIXME: [minor perf] same check is done later for all IATs for emulate_IAT_writes */\n\n        bool patch_proof_IAT = false; /* NYI - case 6622 */\n        /* FIXME: case 6622 IAT hooker protection for some modules is\n         * expected to conflict with emulate_IAT_writes, need to make\n         * sure emulate_write_areas will not overlap with this\n         */\n        ASSERT_NOT_IMPLEMENTED(!patch_proof_IAT);\n\n        patch_proof_overlap = !loader && patching_code &&\n            /* even if it is not the loader we protect IAT sections only */\n            (!patching_IAT || patch_proof_IAT);\n\n        LOG(THREAD, LOG_VMAREAS, 1, \"patch proof module \"PFX\"-\"PFX\" modified %s, by %s,%s=>%s\\n\",\n            base, base+size,\n            patching_code ? \"code!\" : \"data --ok\",\n            loader ? \"loader --ok\" : patching_code ? \"hooker!\" : \"loader or hooker\",\n            patching_IAT ? \"IAT hooker\" : \"patching!\",\n            patch_proof_overlap ? \"SQUASH\" : \"allow\");\n        /* curiosly the loader modifies the .reloc section of Dell\\QuickSet\\dadkeyb.dll */\n    }\n#endif /* defined(PROGRAM_SHEPHERDING) && defined(WINDOWS) */\n\n    /* FIXME: case 6622 IAT hooking should be controlled separately,\n     * note that when it is not protecting all IAT areas - exemptions\n     * tracked by module name there may have to handle two different\n     * cases.  If making sure a particular DLL is always using the\n     * real exports current implementation above will work.  Yet in\n     * the use case of avoiding a particular IAT hooker replacing\n     * imports from kernel32, _all_ modules will have to be pretend\n     * writable.  xref case 1948 for tracking read/written values\n     */\n\n    if (dr_overlap || system_overlap || patch_proof_overlap) {\n        uint how_handle;\n        const char *target_area_name;\n        /* FIXME: separate this in a function */\n        if (dr_overlap) {\n            how_handle = DYNAMO_OPTION(handle_DR_modify);\n            STATS_INC(app_modify_DR_prot);\n            target_area_name = PRODUCT_NAME;\n        } else if (system_overlap) {\n            ASSERT(system_overlap);\n            how_handle = DYNAMO_OPTION(handle_ntdll_modify);\n            STATS_INC(app_modify_ntdll_prot);\n            target_area_name = \"system\";\n        } else {\n            ASSERT(patch_proof_overlap);\n            target_area_name = \"module\";\n            how_handle = DR_MODIFY_NOP; /* use pretend writable */\n            STATS_INC(app_modify_module_prot);\n        }\n\n        /* we can't be both pretend writable and emulate write */\n        ASSERT(!vmvector_overlap(emulate_write_areas, base, base+size));\n\n        if (how_handle == DR_MODIFY_HALT) {\n            /* Until we've fixed our DR area list problems and gotten shim.dll to work,\n             * we will issue an unrecoverable error\n             */\n            report_dynamorio_problem(dcontext, DUMPCORE_SECURITY_VIOLATION, NULL, NULL,\n                                     \"Application changing protections of \"\n                                     \"%s memory @\"PFX\"-\"PFX,\n                                     target_area_name, base, base+size);\n            /* FIXME: walking the loader data structures at arbitrary\n             * points is dangerous due to data races with other threads\n             * -- see is_module_being_initialized and get_module_name\n             */\n            check_for_unsupported_modules();\n            os_terminate(dcontext, TERMINATE_PROCESS);\n            ASSERT_NOT_REACHED();\n        } else {\n            SYSLOG_INTERNAL_WARNING_ONCE(\"Application changing protections of \"\n                                         \"%s memory at least once (\"PFX\"-\"PFX\")\",\n                                         target_area_name, base, base+size);\n            if (how_handle == DR_MODIFY_NOP) {\n                /* we use a separate list, rather than a flag on DR areas, as the\n                 * affected region could include non-DR memory\n                 */\n                /* FIXME: note that we do not intersect with a concrete\n                 * region that we want to protect - considering Win32\n                 * protection changes allowed only separately\n                 * allocated regions this may be ok.  If we want to\n                 * have subpage regions then it becomes an issue:\n                 * we'd have to be able to emulate a write on a\n                 * page that has pretend writable regions.\n                 * For now we ensure pretend_writable_areas is always page-aligned.\n                 */\n                app_pc page_base;\n                size_t page_size;\n                ASSERT_CURIOSITY(ALIGNED(base, PAGE_SIZE));\n                ASSERT_CURIOSITY(ALIGNED(size, PAGE_SIZE));\n                page_base = (app_pc) PAGE_START(base);\n                page_size = ALIGN_FORWARD(base + size, PAGE_SIZE) - (size_t)page_base;\n                write_lock(&pretend_writable_areas->lock);\n                if (TEST(MEMPROT_WRITE, prot)) {\n                    LOG(THREAD, LOG_VMAREAS, 2, \"adding pretend-writable region \"PFX\"-\"PFX\"\\n\",\n                        page_base, page_base+page_size);\n                    add_vm_area(pretend_writable_areas, page_base, page_base+page_size,\n                                true, 0, NULL _IF_DEBUG(\"DR_MODIFY_NOP\"));\n                } else {\n                    LOG(THREAD, LOG_VMAREAS, 2, \"removing pretend-writable region \"PFX\"-\"PFX\"\\n\",\n                        page_base, page_base+page_size);\n                    remove_vm_area(pretend_writable_areas, page_base,\n                                   page_base+page_size, false);\n                }\n                write_unlock(&pretend_writable_areas->lock);\n                LOG(THREAD, LOG_VMAREAS, 2, \"turning system call into a nop\\n\");\n\n                if (old_memprot != NULL) {\n                    /* FIXME: case 10437 we should keep track of any previous values */\n                    if (!get_memory_info(base, NULL, NULL, old_memprot)) {\n                        /* FIXME: should we fail instead of feigning success? */\n                        ASSERT_CURIOSITY(false && \"prot change nop should fail\");\n                        *old_memprot = MEMPROT_NONE;\n                    }\n                }\n                return PRETEND_APP_MEM_PROT_CHANGE; /* have syscall be a nop! */\n            } else if (how_handle == DR_MODIFY_FAIL) {\n                /* not the default b/c hooks that target our DLL often ignore the return\n                 * code of the syscall and blindly write, failing on the write fault.\n                 */\n                LOG(THREAD, LOG_VMAREAS, 2, \"turning system call into a failure\\n\");\n                return FAIL_APP_MEM_PROT_CHANGE; /* have syscall fail! */\n            } else if (how_handle == DR_MODIFY_ALLOW) {\n                LOG(THREAD, LOG_VMAREAS, 2, \"ALLOWING system call!\\n\");\n                /* continue down below */\n            }\n        }\n        ASSERT(how_handle == DR_MODIFY_ALLOW);\n    }\n\n    /* DR areas may have changed, but we still have to remove from pretend list */\n    if (USING_PRETEND_WRITABLE() && !TEST(MEMPROT_WRITE, prot) &&\n        pretend_writable_vm_area_overlap(base, base+size)) {\n        ASSERT_NOT_TESTED();\n        /* FIXME: again we have the race -- if we could go from read to write\n         * it would be a simple fix, else have to grab write up front, or check again\n         */\n        write_lock(&pretend_writable_areas->lock);\n        LOG(THREAD, LOG_VMAREAS, 2, \"removing pretend-writable region \"PFX\"-\"PFX\"\\n\",\n            base, base+size);\n        remove_vm_area(pretend_writable_areas, base, base+size, false);\n        write_unlock(&pretend_writable_areas->lock);\n    }\n\n#ifdef PROGRAM_SHEPHERDING\n    if (USING_FUTURE_EXEC_LIST && futureexec_vm_area_overlap(base, base + size)) {\n        /* something changed */\n        if (!TEST(MEMPROT_EXEC, prot)) {\n            /* we DO remove future regions just b/c they're now marked non-x\n             * but we may want to re-consider this -- some hooks briefly go to rw, e.g.\n             * although we MUST do this for executable_if_exec\n             * we should add flags to future areas indicating which policy put it here\n             * (have to not merge different policies, I guess -- problematic for\n             * sub-page flush combined w/ other policies?)\n             */\n            DEBUG_DECLARE(bool ok =) remove_futureexec_vm_area(base, base + size);\n            ASSERT(ok);\n            LOG(THREAD, LOG_SYSCALLS|LOG_VMAREAS, 1,\n                \"future region \"PFX\"-\"PFX\" is being made non-x, removing\\n\",\n                base, base + size);\n        } else {\n            /* Maybe nothing is changed in fact. */\n            /* In fact this happens when a protection size larger than\n             * necessary for a hook leaves some pages on the\n             * futureexec_vm_area_overlap region (case 2871 for a two\n             * page hooker).  There is nothing to do here,\n             * executable_if_hook should re-add the pages.\n             */\n            /* case 3279 - probably similar behaviour -- when a second\n             * NOP memory protection change happens to a region\n             * already on the future list - we'd need to power it up\n             * again\n             */\n            /* xref case 3102 - where we don't care about VM_WRITABLE */\n#if 0 /* this syslog may causes services.exe to hang (ref case 666)  */\n            SYSLOG_INTERNAL_WARNING(\"future executable area overlapping with \"PFX\"-\"PFX\" made %s\",\n                                    base, base + size, memprot_string(prot));\n#endif\n        }\n    }\n#endif\n\n#if defined(PROGRAM_SHEPHERDING) && defined(WINDOWS)\n    /* Just remove up front if changing anything about an emulation region.\n     * Should certainly remove if becoming -w, but should also remove if\n     * being added to exec list -- current usage expects to be removed on\n     * next protection change (hooker restoring IAT privileges).\n     * FIXME: should make the ->rx restoration syscall a NOP for performance\n     */\n    if (DYNAMO_OPTION(emulate_IAT_writes) &&\n        !vmvector_empty(emulate_write_areas) &&\n        vmvector_overlap(emulate_write_areas, base, base+size)) {\n        LOG(THREAD, LOG_SYSCALLS|LOG_VMAREAS, 2,\n            \"removing emulation region \"PFX\"-\"PFX\"\\n\", base, base+size);\n        vmvector_remove(emulate_write_areas, base, base+size);\n    }\n#endif\n\n#ifndef PROGRAM_SHEPHERDING\n    if (!INTERNAL_OPTION(hw_cache_consistency))\n        return DO_APP_MEM_PROT_CHANGE; /* let syscall go through */\n#endif\n\n    /* look for calls making code writable!\n     * cache is_executable here w/o holding lock -- if decide to perform state\n     * change via flushing, we'll re-check overlap there and all will be atomic\n     * at that point, no reason to try and make atomic from here, will hit\n     * deadlock issues w/ thread_initexit_lock\n     */\n    is_executable = executable_vm_area_overlap(base, base + size, false/*have no lock*/);\n    if (is_executable && TEST(MEMPROT_WRITE, prot) && !TEST(MEMPROT_EXEC, prot) &&\n        INTERNAL_OPTION(hw_cache_consistency)) {\n#ifdef WINDOWS\n        app_pc IAT_start, IAT_end;\n        /* Could not page-align and ask for original params but some hookers\n         * page-align even when targeting only IAT */\n        bool is_iat = is_IAT(base, base+size, true/*page-align*/, &IAT_start, &IAT_end);\n        bool is_patch = is_module_patch_region(dcontext, base, base+size,\n                                               true/*be conservative*/);\n        DOSTATS({\n            if (is_iat && is_patch)\n                STATS_INC(num_app_rebinds);\n        });\n#ifdef PROGRAM_SHEPHERDING\n        /* This potentially unsafe option is superseded by -coarse_merge_iat\n         * FIXME: this should be available for !PROGRAM_SHEPHERDING\n         */\n        if (DYNAMO_OPTION(unsafe_ignore_IAT_writes) && is_iat && is_patch) {\n            /* do nothing: let go writable and then come back */\n            LOG(THREAD, LOG_SYSCALLS|LOG_VMAREAS, 1,\n                \"WARNING: letting IAT be written w/o flushing: potentially unsafe\\n\");\n            return DO_APP_MEM_PROT_CHANGE; /* let syscall go through */\n        }\n#endif\n        /* Case 11072: must match these conditions w/ the assert on freeing */\n        if (DYNAMO_OPTION(coarse_units) && DYNAMO_OPTION(coarse_merge_iat) &&\n# ifdef PROGRAM_SHEPHERDING\n            /* Ensure we'll re-mark as valid */\n            (DYNAMO_OPTION(executable_if_rx_text) ||\n             DYNAMO_OPTION(executable_after_load)) &&\n# endif\n            is_iat && is_patch &&\n            !executable_vm_area_executed_from(IAT_start, IAT_end) &&\n            /* case 10830/11072: ensure currently marked coarse-grain to avoid\n             * blessing the IAT region as coarse when it was in fact made non-coarse\n             * due to a rebase (or anything else) prior to a rebind.  check the end,\n             * since we may have adjusted the exec area bounds to be post-IAT.\n             */\n            get_executable_area_flags(base+size-1, &frag_flags) &&\n            TEST(FRAG_COARSE_GRAIN, frag_flags)) {\n            coarse_info_t *info =\n                get_coarse_info_internal(IAT_end, false/*no init*/, false/*no lock*/);\n            /* loader rebinding\n             * We cmp and free the stored code at +rx time; if that doesn't happen,\n             * we free at module unload time.\n             */\n            DEBUG_DECLARE(bool success =)\n                os_module_store_IAT_code(base);\n            ASSERT(success);\n            ASSERT(!RUNNING_WITHOUT_CODE_CACHE()); /* FRAG_COARSE_GRAIN excludes */\n            LOG(GLOBAL, LOG_VMAREAS, 2,\n                \"storing IAT code for \"PFX\"-\"PFX\"\\n\", IAT_start, IAT_end);\n            if (info != NULL) {\n                /* Only expect to do this for empty or persisted units */\n                ASSERT(info->cache == NULL ||\n                       (info->persisted && info->non_frozen != NULL &&\n                        info->non_frozen->cache == NULL));\n                /* Do not reset/free during flush as we hope to see a validating\n                 * event soon.\n                 */\n                ASSERT(!TEST(PERSCACHE_CODE_INVALID, info->flags));\n                info->flags |= PERSCACHE_CODE_INVALID;\n                STATS_INC(coarse_marked_invalid);\n            }\n        }\n# ifdef PROGRAM_SHEPHERDING\n        if (DYNAMO_OPTION(emulate_IAT_writes) && is_iat &&\n            /* We do NOT want to emulate hundreds of writes by the loader -- we\n             * assume no other thread will execute in the module until it's\n             * initialized.  We only need our emulation for hookers who come in\n             * after initialization when another thread may be in there.\n             */\n            !is_patch) {\n            /* To avoid having the IAT page (which often includes the start of the\n             * text section) off the exec areas list, we only remove the IAT itself,\n             * and emulate writes to it.\n             * FIXME: perhaps this should become an IAT-only vector, and be used\n             * for when we have the IAT read-only to protect it security-wise.\n             */\n            /* unfortunately we have to flush to be conservative */\n            should_finish_flushing =\n                flush_and_remove_executable_vm_area(dcontext, IAT_start,\n                                                    IAT_end - IAT_start);\n            /* a write to IAT gets emulated, but to elsewhere on page is a code mod */\n            vmvector_add(emulate_write_areas, IAT_start, IAT_end, NULL);\n            /* must release the exec areas lock, even if expect no flush */\n            if (should_finish_flushing) {\n                flush_fragments_in_region_finish(dcontext,\n                                                 false /*don't keep initexit_lock*/);\n            }\n            LOG(THREAD, LOG_SYSCALLS|LOG_VMAREAS, 1,\n                \"executable region == IAT so not marking %s, emulating writes\\n\",\n                memprot_string(prot));\n            /* now leave as read-only.\n             * we do not record what other flags they're using here -- we assume\n             * they're going to restore IAT back to what it was\n             */\n            /* FIXME: case 10437 we should keep track of any previous values */\n            if (old_memprot != NULL) {\n                if (!get_memory_info(base, NULL, NULL, old_memprot)) {\n                    /* FIXME: should we fail instead of feigning success? */\n                    ASSERT_CURIOSITY(false && \"prot change nop should fail\");\n                    *old_memprot = MEMPROT_NONE;\n                }\n            }\n            return PRETEND_APP_MEM_PROT_CHANGE;\n        }\n# endif /* PROGRAM_SHEPHERDING */\n#endif /* WINDOWS */\n        /* being made writable but non-executable!\n         * kill all current fragments in the region (since a\n         * non-executable region is ignored by flush routine)\n         */\n        LOG(THREAD, LOG_SYSCALLS|LOG_VMAREAS, 1,\n            \"WARNING: executable region being made writable and non-executable\\n\");\n        flush_fragments_and_remove_region(dcontext, base, size,\n                                          false /* don't own initexit_lock */,\n                                          false /* case 2236: keep futures */);\n#ifdef HOT_PATCHING_INTERFACE\n        if (DYNAMO_OPTION(hotp_only))\n            hotp_only_mem_prot_change(base, size, true, false);\n#endif\n    }\n    else if (is_executable && TESTALL(MEMPROT_WRITE | MEMPROT_EXEC, prot) &&\n             INTERNAL_OPTION(hw_cache_consistency)) {\n        /* Need to flush all fragments in [base, base+size), unless\n         * they are ALL already writable\n         */\n        DOSTATS({\n            /* If all the overlapping executable areas are VM_WRITABLE|\n             * VM_DELAY_READONLY then we could optimize away the flush since\n             * we haven't made any portion of this region read only for\n             * consistency purposes.  We haven't implemented this optimization\n             * as it's quite rare (though does happen xref case 8104) and\n             * previous implementations of this optimization proved buggy. */\n            if (is_executable_area_writable_overlap(base, base + size,\n                                                     true /* ALL regions are: */,\n                                                     VM_WRITABLE|VM_DELAY_READONLY)) {\n                STATS_INC(num_possible_app_to_rwx_skip_flush);\n            }\n        });\n        /* executable region being made writable\n         * flush all current fragments, and mark as non-executable\n         */\n        LOG(THREAD, LOG_SYSCALLS|LOG_VMAREAS, 1,\n            \"WARNING: executable region \"PFX\"-\"PFX\" is being made writable!\\n\"\n            \"\\tRemoving from executable list\\n\",\n            base, base + size);\n        /* use two-part flush to make futureexec & exec changes atomic w/ flush */\n        should_finish_flushing = flush_and_remove_executable_vm_area(dcontext, base, size);\n        /* we flush_fragments_finish after security checks to keep them atomic */\n    }\n    else if (is_executable && is_executable_area_writable(base) &&\n             !TEST(MEMPROT_WRITE, prot) && TEST(MEMPROT_EXEC, prot) &&\n             INTERNAL_OPTION(hw_cache_consistency)) {\n        /* executable & writable region being made read-only\n         * make sure any future write faults are given to app, not us\n         */\n        LOG(THREAD, LOG_SYSCALLS|LOG_VMAREAS, 1,\n            \"executable writable region \"PFX\"-\"PFX\" => read-only!\\n\",\n            base, base + size);\n        /* remove writable exec area, then add read-only exec area */\n        /* use two-part flush to make futureexec & exec changes atomic w/ flush */\n        should_finish_flushing = flush_and_remove_executable_vm_area(dcontext, base, size);\n        /* FIXME: this is wrong -- this will make all pieces in the middle executable,\n         * which is not what we want -- we want all pieces ON THE EXEC LIST to\n         * change from rw to r.  thus this should be like the change-to-selfmod case\n         * in handle_modified_code => add new vector routine?  (case 3570)\n         */\n        add_executable_vm_area(base, base + size,\n                               0 /* not image? FIXME */, 0,\n                               should_finish_flushing/* own lock if flushed */\n                               _IF_DEBUG(\"protection change\"));\n    }\n    /* also look for calls making data executable\n     * FIXME: perhaps should do a write_keep for this is_executable, to bind\n     * to the subsequent exec areas changes -- though case 2833 would still be there\n     */\n    else if (!is_executable && TEST(MEMPROT_EXEC, prot) &&\n             INTERNAL_OPTION(hw_cache_consistency)) {\n        if (TEST(MEMPROT_WRITE, prot)) {\n            /* do NOT add to executable list if writable */\n            LOG(THREAD, LOG_SYSCALLS|LOG_VMAREAS, 1,\n                \"WARNING: data region \"PFX\"-\"PFX\" made executable and \"\n                \"writable, not adding to exec list\\n\", base, base + size);\n        } else {\n            bool add_to_exec_list = false;\n#ifdef WINDOWS\n            bool check_iat = false;\n            bool free_iat = false;\n#endif\n            uint frag_flags = 0;\n            DEBUG_DECLARE(const char *comment = \"\";)\n            LOG(THREAD, LOG_SYSCALLS|LOG_VMAREAS, 1,\n                \"WARNING: data region \"PFX\"-\"PFX\" is being made executable\\n\",\n                base, base+size);\n#ifdef PROGRAM_SHEPHERDING\n            /* if on future, no reason to add to exec list now\n             * if once-only, no reason to add to exec list and remove from future\n             * wait until actually executed!\n             */\n            /* none of our policies allow this on the stack */\n            if (is_address_on_stack(dcontext, base)) {\n                LOG(THREAD, LOG_VMAREAS, 2,\n                    \"not allowing data->x for stack region\\n\");\n# ifdef WINDOWS\n            } else if (DYNAMO_OPTION(executable_after_load) &&\n                       is_module_patch_region(dcontext, base, base+size,\n                                              false/*be liberal: can't miss loader*/)) {\n                STATS_INC(num_mark_after_load);\n                add_to_exec_list = true;\n                check_iat = true;\n                DODEBUG({ comment = \"if_after_load\"; });\n                LOG(THREAD, LOG_VMAREAS, 2,\n                    \"module is being initialized, adding region to executable list\\n\");\n\n# endif\n            } else if (DYNAMO_OPTION(executable_if_rx_text)) {\n                /* FIXME: this should be moved out of the if (!executable) branch?\n                 * to where executable_if_x is handled\n                 */\n                /* NOTE - xref case 10526, the check here is insufficient to implement\n                 * this policy because [*base, *base+*size) could overlap multiple\n                 * sections (some of which might not be code) which would cause this\n                 * check to fail.  Fixing this here would require us to find the\n                 * intersection of this region and any code section(s) and add the\n                 * resulting region(s) (there could be more then one). Instead we leave\n                 * this check here to catch the common case but extend\n                 * check_origins_helper to catch anything unusual. */\n                app_pc modbase = get_module_base(base);\n                if (modbase != NULL &&\n                    is_range_in_code_section(modbase, base, base+size, NULL, NULL)) {\n                    STATS_INC(num_2rx_text);\n                    add_to_exec_list = true;\n                    IF_WINDOWS(check_iat = true;)\n                    DODEBUG({ comment = \"if_rx_text\"; });\n                    LOG(THREAD, LOG_VMAREAS, 2,\n                        \"adding code region being marked rx to executable list\\n\");\n                }\n            } /* Don't use an  else if here, the else if for\n               * -executable_if_rx_text if doesn't check all its\n               * conditionals in the first if */\n\n            if (DYNAMO_OPTION(executable_if_rx)) {\n                STATS_INC(num_mark_if_rx);\n                add_to_exec_list = true;\n                mark_module_exempted(base);\n                DODEBUG({ comment = \"if_rx\"; });\n                LOG(THREAD, LOG_VMAREAS, 2, \"adding region marked only rx \"\n                                            \"to executable list\\n\");\n            }\n#else\n            add_to_exec_list = true;\n            IF_WINDOWS(check_iat = true;)\n#endif\n#ifdef WINDOWS\n            if (check_iat) {\n                if (DYNAMO_OPTION(coarse_units) && DYNAMO_OPTION(coarse_merge_iat) &&\n                    is_IAT(base, base+size, true/*page-align*/, NULL, NULL))\n                    free_iat = true;\n                LOG(THREAD, LOG_VMAREAS, 2,\n                    \".text or IAT is being made rx again \"PFX\"-\"PFX\"\\n\", base, base+size);\n                if (!RUNNING_WITHOUT_CODE_CACHE()) {\n                    /* case 8640: let add_executable_vm_area() decide whether to\n                     * keep the coarse-grain flag\n                     */\n                    frag_flags |= FRAG_COARSE_GRAIN;\n                } else {\n                    free_iat = false;\n                    ASSERT(!os_module_free_IAT_code(base));\n                }\n            }\n#endif\n            if (add_to_exec_list) {\n                /* FIXME : see note at top of function about bug 2833 */\n                ASSERT(!TEST(MEMPROT_WRITE, prot)); /* sanity check */\n                add_executable_vm_area(base, base + size,\n                                       0 /* not an unmodified image */, frag_flags,\n                                       false/*no lock*/ _IF_DEBUG(comment));\n            }\n#ifdef WINDOWS\n            if (free_iat) {\n                DEBUG_DECLARE(bool had_iat =)\n                    os_module_free_IAT_code(base);\n                DEBUG_DECLARE(app_pc text_start;)\n                DEBUG_DECLARE(app_pc text_end;)\n                DEBUG_DECLARE(app_pc iat_start = NULL;)\n                DEBUG_DECLARE(app_pc iat_end = NULL;)\n                /* calculate IAT bounds */\n                ASSERT(is_IAT(base, base+size, true/*page-align*/,\n                              &iat_start, &iat_end));\n                ASSERT(had_iat ||\n                       /* duplicate the reasons we wouldn't have stored the IAT: */\n                       !is_module_patch_region(dcontext, base, base+size,\n                                               true/*be conservative*/) ||\n                       executable_vm_area_executed_from(iat_start, iat_end) ||\n                       /* case 11072: rebase prior to rebind prevents IAT storage */\n                       (get_module_preferred_base_delta(base) != 0 &&\n                        is_in_code_section(get_module_base(base), base,\n                                           &text_start, &text_end) &&\n                        iat_start >= text_start && iat_end <= text_end));\n            }\n#endif\n#ifdef HOT_PATCHING_INTERFACE\n            if (DYNAMO_OPTION(hotp_only))\n                hotp_only_mem_prot_change(base, size, false, true);\n#endif\n        }\n    }\n\n#ifdef PROGRAM_SHEPHERDING\n    /* These policies do not depend on a transition taking place. */\n    /* Make sure weaker policies are considered first, so that\n     * the region is kept on the futureexec list with the least restrictions\n     */\n    if (DYNAMO_OPTION(executable_if_x) && TEST(MEMPROT_EXEC, prot)) {\n        /* The executable_if_x policy considers all code marked ..x to be executable */\n\n        /* Note that executable_if_rx may have added a region directly\n         * to the executable_areas, while here we only add to the futureexec_areas\n         * FIXME: move executable_if_rx checks as an 'else if' following this if.\n         */\n        LOG(GLOBAL, LOG_VMAREAS, 1,\n            \"New future region b/c x, \"PFX\"-\"PFX\" %s, was %sexecutable\\n\",\n            base, base+size, memprot_string(prot), is_executable ? \"\" : \"not \");\n        STATS_INC(num_mark_if_x);\n        add_futureexec_vm_area(base, base+size, false/*permanent*/\n                               _IF_DEBUG(TEST(MEMPROT_WRITE, prot) ?\n                                         \"executable_if_x protect exec .wx\" :\n                                         \"executable_if_x protect exec .-x\"\n                                         ));\n        mark_module_exempted(base);\n    } else if (DYNAMO_OPTION(executable_if_hook) && TESTALL(MEMPROT_WRITE | MEMPROT_EXEC, prot)) {\n        /* Note here we're strict in requesting a .WX setting by the\n         * hooker, won't be surprising if some don't do even this\n         */\n        /* FIXME: could restrict to sub-page piece of text section,\n         * since should only be targeting 4 or 5 byte area\n         */\n        app_pc modbase = get_module_base(base);\n        if (modbase != NULL) { /* PE, and is readable */\n            /* FIXME - xref case 10526, if the base - base+size overlaps more than\n             * one section then this policy won't apply, though not clear if we'd want\n             * it to for such an unusual hooker. */\n            if (is_range_in_code_section(modbase, base, base+size, NULL, NULL)) {\n                uint vm_flags;\n                DOLOG(2, LOG_INTERP|LOG_VMAREAS, {\n                    char modname[MAX_MODNAME_INTERNAL];\n                    os_get_module_name_buf(modbase, modname,\n                                           BUFFER_SIZE_ELEMENTS(modname));\n                    LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 2,\n                        \"adding hook to future list: \"PFX\"-\"PFX\" in code of \"\n                        \"module @\"PFX\" == %s made rwx\\n\",\n                        base, base+size, modbase,\n                        modname == NULL? \"<invalid name>\" : modname);\n                });\n                STATS_INC(num_hook);\n\n                /* add as a once-only future area */\n                add_futureexec_vm_area(base, base + size,\n                                       true/*once-only*/\n                                       _IF_DEBUG(memprot_string(prot)));\n                /* This is text section, leave area on executable list\n                 * so app can execute here, write, and then execute\n                 * again (via future list) to handle cases of hooking\n                 * kernel32 functions ref case 2803 and case 3097 */\n\n                if (!should_finish_flushing) {\n                    /* FIXME: as a quick fix we flush the existing area\n                     * just in case anyways, so that we don't think about\n                     * merging properly the FRAG_DYNGEN\n                     */\n                    should_finish_flushing =\n                        flush_and_remove_executable_vm_area(dcontext, base, size);\n                }\n\n                /* FIXME: we could optimize away the VM_DELAY_READONLY\n                 * path if we actually knew that the current real\n                 * protection flag is not writable.  Yet we've removed\n                 * any internal data about it, so we need\n                 * restructuring or an extra system call here vs the\n                 * safe one at make_unwritable().\n                 *\n                 * case 8308: Don't mark as DELAY_READONLY if -sandbox_writable\n                 * is on.  We don't need to check for -sandbox_non_text here\n                 * since we know we're in a text region here.\n                 */\n                vm_flags = VM_WRITABLE;\n                if (!DYNAMO_OPTION(sandbox_writable))\n                    vm_flags |= VM_DELAY_READONLY;\n\n                add_executable_vm_area(base, base + size, vm_flags,\n                                       0, should_finish_flushing/* own the lock if\n                                                                   we have flushed */\n                                       _IF_DEBUG(\"prot chg text rx->rwx not yet written\"));\n                /* leave read only since we are leaving on exec list */\n                if (should_finish_flushing) {\n                    flush_fragments_in_region_finish(dcontext,\n                                                     false /*don't keep initexit_lock*/);\n                }\n\n                if (old_memprot != NULL) {\n                    /* FIXME: case 10437 we should keep track of any previous values */\n                    if (!get_memory_info(base, NULL, NULL, old_memprot)) {\n                        /* FIXME: should we fail instead of feigning success? */\n                        ASSERT_CURIOSITY(false && \"prot change nop should fail\");\n                        *old_memprot = MEMPROT_NONE;\n                    }\n                }\n                /* case 10387 initial fix - on a DEP machine to\n                 * support properly native execution we must set the X\n                 * bit: most needed for -hotp_only when we provide our\n                 * code origins policies for GBOP enforcement, but\n                 * similar need in native_exec or other possible mixed\n                 * modes.\n                 */\n\n                /* We really should be setting everything according to\n                 * app request except for writability.  Hopefully we\n                 * don't have sophisticated hookers using PAGE_GUARD\n                 * so ok to use only the memprot supported flags.\n                 */\n                prot &= ~MEMPROT_WRITE;\n                ASSERT_CURIOSITY(TESTALL(MEMPROT_READ|MEMPROT_EXEC, prot));\n\n                *new_memprot = prot;\n                return SUBSET_APP_MEM_PROT_CHANGE;\n            }\n        }\n    }\n#endif /* PROGRAM_SHEPHERDING */\n    if (should_finish_flushing) {\n        flush_fragments_in_region_finish(dcontext, false /*don't keep initexit_lock*/);\n\n        if (DYNAMO_OPTION(opt_jit) && is_jit_managed_area(base))\n            jitopt_clear_span(base, base+size);\n    }\n    return DO_APP_MEM_PROT_CHANGE; /* let syscall go through */\n}\n\n#ifdef WINDOWS\n/* memory region base:base+size was flushed from hardware icache by app */\nvoid\napp_memory_flush(dcontext_t *dcontext, app_pc base, size_t size, uint prot)\n{\n# ifdef PROGRAM_SHEPHERDING\n    if (DYNAMO_OPTION(executable_if_flush)) {\n        /* We want to ignore the loader calling flush, since our current\n         * impl makes a flush region permanently executable.\n         * The loader always follows the order \"rw, rx, flush\", but we have\n         * seen real DGC marking rx before flushing as well, so we use\n         * our module-being-loaded test:\n         */\n        if (!is_module_patch_region(dcontext, base, base+size,\n                                    false/*be liberal: don't miss loader*/)) {\n            /* FIXME case 280: we'd like to always be once-only, but writes\n             * to data on the same page make it hard to do that.\n             */\n            bool onceonly = false;\n            /* we do NOT go to page boundaries, instead we put sub-page\n             * regions on our future list\n             */\n            LOG(GLOBAL, LOG_VMAREAS, 1,\n                \"New future exec region b/c flushed: \"PFX\"-\"PFX\" %s\\n\",\n                base, base+size, memprot_string(prot));\n            if (!DYNAMO_OPTION(selfmod_futureexec) &&\n                is_executable_area_on_all_selfmod_pages(base, base+size)) {\n                /* for selfmod we can be onceonly, as writes to data on the\n                 * same page won't kick us off the executable list\n                 */\n                onceonly = true;\n            }\n            add_futureexec_vm_area(base, base + size, onceonly\n                                   _IF_DEBUG(\"NtFlushInstructionCache\"));\n            if (DYNAMO_OPTION(xdata_rct)) {\n                /* FIXME: for now we only care about start pc */\n                vmvector_add(app_flushed_areas, base, base+1, NULL);\n                /* FIXME: remove when region de-allocated? */\n            }\n            DOSTATS({\n                if (is_executable_area_writable(base))\n                    STATS_INC(num_NT_flush_w2r); /* pretend writable (we made RO) */\n                if (TEST(MEMPROT_WRITE, prot))\n                    STATS_INC(num_NT_flush_w);\n                else\n                    STATS_INC(num_NT_flush_r);\n                if (is_address_on_stack(dcontext, base)) {\n                    STATS_INC(num_NT_flush_stack);\n                } else {\n                    STATS_INC(num_NT_flush_heap);\n                }\n            });\n        } else {\n            LOG(THREAD, LOG_VMAREAS, 1, \"module is being loaded, ignoring flush\\n\");\n            STATS_INC(num_NT_flush_loader);\n        }\n    }\n# else\n    /* NOP */\n# endif /* PROGRAM_SHEPHERDING */\n}\n\n# ifdef PROGRAM_SHEPHERDING\nbool\nwas_address_flush_start(dcontext_t *dcontext, app_pc pc)\n{\n    ASSERT(DYNAMO_OPTION(xdata_rct));\n    /* FIXME: once we have flags marking where each futureexec region\n     * came from we can distinguish NtFlush, but for now we need our own list,\n     * which as FIXME above says could be simply htable since we only care about\n     * start_pc (for now).\n     * We assume we only add start pcs to the vector.\n     */\n    return vmvector_overlap(app_flushed_areas, pc, pc + 1);\n}\n# endif\n#endif\n\n/****************************************************************************/\n\n/* a helper function for check_thread_vm_area\n * assumes caller owns executable_areas write lock */\nstatic void\nhandle_delay_readonly(dcontext_t *dcontext, app_pc pc, vm_area_t *area)\n{\n    ASSERT_OWN_WRITE_LOCK(true, &executable_areas->lock);\n    ASSERT(TESTALL(VM_DELAY_READONLY|VM_WRITABLE, area->vm_flags));\n    /* should never get a selfmod region here, to be marked selfmod\n     * would already have had to execute (to get faulting write)\n     * so region would already have had to go through here */\n    ASSERT(!TEST(FRAG_SELFMOD_SANDBOXED, area->frag_flags));\n    if (!is_on_stack(dcontext, pc, NULL) && INTERNAL_OPTION(hw_cache_consistency)) {\n        vm_make_unwritable(area->start, area->end - area->start);\n        area->vm_flags |= VM_MADE_READONLY;\n    } else {\n        /* this could happen if app changed mem protection on its\n         * stack that triggered us adding a delay_readonly writable\n         * region to the executable list in\n         * app_memory_protection_change() */\n        ASSERT_CURIOSITY(false);\n        area->frag_flags |= FRAG_SELFMOD_SANDBOXED;\n    }\n    area->vm_flags &= ~VM_DELAY_READONLY;\n    LOG(GLOBAL, LOG_VMAREAS, 2,\n        \"\\tMarking existing wx vm_area_t ro for consistency, \"\n        \"area \"PFX\" - \"PFX\", target pc \"PFX\"\\n\",\n        area->start, area->end, pc);\n    STATS_INC(num_delayed_rw2r);\n}\n\n/* Frees resources acquired in check_thread_vm_area().\n * data and vmlist need to match those used in check_thread_vm_area().\n * abort indicates that we are forging and exception or killing a thread\n * or some other drastic action that will not return to the caller\n * of check_thread_vm_area.\n * own_execareas_writelock indicates whether the executable_areas\n * write lock is currently held, while caller_execareas_writelock\n * indicates whether the caller held that lock and thus we should not\n * free it unless we're aborting.\n * If both clean_bb and abort are true, calls bb_build_abort.\n */\nstatic void\ncheck_thread_vm_area_cleanup(dcontext_t *dcontext, bool abort, bool clean_bb,\n                             thread_data_t *data, void **vmlist,\n                             bool own_execareas_writelock,\n                             bool caller_execareas_writelock)\n{\n    if (own_execareas_writelock && (!caller_execareas_writelock || abort)) {\n        ASSERT(self_owns_write_lock(&executable_areas->lock));\n        write_unlock(&executable_areas->lock);\n#ifdef HOT_PATCHING_INTERFACE\n        if (DYNAMO_OPTION(hot_patching)) {\n            ASSERT(self_owns_write_lock(hotp_get_lock()));\n            write_unlock(hotp_get_lock());\n        }\n#endif\n    }\n    ASSERT(!caller_execareas_writelock || self_owns_write_lock(&executable_areas->lock));\n    /* FIXME: could we have multiply-nested vmlist==NULL where we'd need to\n     * release read lock more than once? */\n    if (vmlist == NULL)\n        SHARED_VECTOR_RWLOCK(&data->areas, read, unlock);\n    if (self_owns_write_lock(&data->areas.lock) && (vmlist != NULL || abort)) {\n        /* Case 9376: we can forge an exception for vmlist==NULL, in which case\n         * we must release the write lock from the prior layer;\n         * we can also have a decode fault with vmlist!=NULL but w/o holding\n         * the vm areas lock.\n         */\n        SHARED_VECTOR_RWLOCK(&data->areas, write, unlock);\n    } /* we need to not unlock vmareas for nested check_thread_vm_area() call */\n    if (abort) {\n        if (vmlist != NULL && *vmlist != NULL) {\n            vm_area_destroy_list(dcontext, *vmlist);\n        }\n        if (clean_bb) {\n            /* clean up bb_building_lock and IR */\n            bb_build_abort(dcontext, false/*don't call back*/, true/*unlock*/);\n        }\n    }\n}\n\n/* Releases any held locks.  Up to caller to free vmlist.\n * Flags are reverse logic, just like for check_thread_vm_area()\n */\nvoid\ncheck_thread_vm_area_abort(dcontext_t *dcontext, void **vmlist, uint flags)\n{\n    thread_data_t *data;\n    if (DYNAMO_OPTION(shared_bbs) &&\n        !TEST(FRAG_SHARED, flags)) { /* yes, reverse logic, see comment above */\n        data = shared_data;\n    } else {\n        data = (thread_data_t *) dcontext->vm_areas_field;\n    }\n    check_thread_vm_area_cleanup(dcontext, true, false/*caller takes care of bb*/,\n                                 data, vmlist,\n                                 self_owns_write_lock(&executable_areas->lock),\n                                 self_owns_write_lock(&data->areas.lock));\n}\n\nstatic bool\nallow_xfer_for_frag_flags(dcontext_t *dcontext, app_pc pc,\n                          uint src_flags, uint tgt_flags)\n{\n    /* the flags we don't allow a direct cti to bridge if different */\n    const uint frag_flags_cmp = FRAG_SELFMOD_SANDBOXED | FRAG_COARSE_GRAIN\n#ifdef PROGRAM_SHEPHERDING\n        | FRAG_DYNGEN\n#endif\n        ;\n    uint src_cmp = src_flags & frag_flags_cmp;\n    uint tgt_cmp = tgt_flags & frag_flags_cmp;\n    bool allow = (src_cmp == tgt_cmp) ||\n        /* Case 8917: hack to allow elision of call* to vsyscall-in-ntdll,\n         * while still ruling out fine fragments coming in to coarse regions\n         * (where we'd rather stop the fine and build a (cheaper) coarse bb).\n         * Use == instead of TEST to rule out any other funny flags.\n         */\n        (src_cmp == 0 /* we removed FRAG_COARSE_GRAIN to make this fine */\n         && tgt_cmp == FRAG_COARSE_GRAIN /* still in coarse region though */\n         && TEST(FRAG_HAS_SYSCALL, src_flags));\n    if (TEST(FRAG_COARSE_GRAIN, src_flags)) {\n        /* FIXME case 8606: we can allow intra-module xfers but we have no\n         * way of checking here -- would have to check in\n         * interp.c:check_new_page_jmp().  So for now we disallow all xfers.\n         * If our regions match modules exactly we shouldn't see any\n         * intra-module direct xfers anyway.\n         */\n        /* N.B.: ibl entry removal (case 9636) assumes coarse fragments\n         * stay bounded within contiguous FRAG_COARSE_GRAIN regions\n         */\n        allow = false;\n    }\n    if (!allow) {\n        LOG(THREAD, LOG_VMAREAS, 3,\n            \"change in vm area flags (0x%08x vs. 0x%08x %d): \"\n            \"stopping at \"PFX\"\\n\", src_flags, tgt_flags,\n            TEST(FRAG_COARSE_GRAIN, src_flags), pc);\n        DOSTATS({\n            if (TEST(FRAG_COARSE_GRAIN, tgt_flags))\n                STATS_INC(elisions_prevented_for_coarse);\n        });\n    }\n    return allow;\n}\n\n/* check origins of code for several purposes:\n * 1) we need list of areas where this thread's fragments come\n *    from, for faster flushing on munmaps\n * 2) also for faster flushing, each vmarea has a list of fragments\n * 3) we need to mark as read-only any writable region that\n *    has a fragment come from it, to handle self-modifying code\n * 4) for PROGRAM_SHEPHERDING for security\n *\n * We keep a list of vm areas per thread, to make flushing fragments\n * due to memory unmaps faster\n * This routine adds the page containing start to the thread's list.\n * Adds any FRAG_ flags relevant for a fragment overlapping start's page.\n * If xfer and encounters change in vmareas flags, returns false and does NOT\n * add the new page to the list for this fragment -- assumes caller will NOT add\n * it to the current bb.  This allows for selectively not following direct ctis.\n * Assumes only building a real app bb if vmlist!=NULL -- assumes that otherwise\n * caller is reconstructing an app bb or some other secondary bb walk.\n * If returns true, returns in the optional stop OUT parameter the final pc of\n * this region (open-ended).\n */\nbool\ncheck_thread_vm_area(dcontext_t *dcontext, app_pc pc, app_pc tag, void **vmlist,\n                     uint *flags, app_pc *stop, bool xfer)\n{\n    bool result;\n    thread_data_t *data;\n    bool in_last = false;\n    uint frag_flags = 0;\n    uint vm_flags = 0;\n    bool ok;\n    bool shared_to_private = false;\n    /* used for new area */\n    app_pc base_pc = 0;\n    size_t size = 0;                  /* set only for unknown areas */\n    uint prot = 0;              /* set only for unknown areas */\n    /* both area and local_area either point to thread-local vector, for which\n     * we do not need a lock, or to a shared area, for which we hold\n     * a read or a write lock (either is sufficient) the entire time\n     */\n    vm_area_t *area = NULL;\n    vm_area_t *local_area = NULL; /* entry for this thread */\n    vm_area_t area_copy; /* local copy, so can let go of lock */\n    /* we can be recursively called (check_origins() calling build_app_bb_ilist())\n     * so make sure we don't re-try to get a lock we already hold\n     */\n    bool caller_execareas_writelock = self_owns_write_lock(&executable_areas->lock);\n    bool own_execareas_writelock = caller_execareas_writelock;\n    DEBUG_DECLARE(const char *new_area_prefix;)\n\n    /* deadlock issues if write lock is held already for vmlist!=NULL case */\n    ASSERT(vmlist == NULL || !caller_execareas_writelock);\n#ifdef HOT_PATCHING_INTERFACE\n    /* hotp_vul_table_lock goes hand in hand w/ executable_areas lock here */\n    ASSERT(!DYNAMO_OPTION(hot_patching) ||\n           (own_execareas_writelock && self_owns_write_lock(hotp_get_lock())) ||\n           (!own_execareas_writelock && !self_owns_write_lock(hotp_get_lock())));\n#endif\n\n    ASSERT(flags != NULL);\n\n    /* don't know yet whether this bb will be shared, but a good chance,\n     * so we guess shared and will rectify later.\n     * later, to add to local instead, we call again, and to tell the difference\n     * we perversely pass FRAG_SHARED\n     */\n    if (DYNAMO_OPTION(shared_bbs) &&\n        /* for TEMP_PRIVATE we make private up front */\n        !TEST(FRAG_TEMP_PRIVATE, *flags) &&\n        !TEST(FRAG_SHARED, *flags)) { /* yes, reverse logic, see comment above */\n        data = shared_data;\n        DODEBUG({new_area_prefix = \"new shared vm area: \";});\n        if (vmlist == NULL) { /* not making any state changes to vm lists */\n            /* need read access only, for lookup and holding ptr into vector */\n            SHARED_VECTOR_RWLOCK(&data->areas, read, lock);\n        } else { /* building a bb */\n            /* need write access later, and want our lookup to be bundled\n             * with our writes so we don't rely on the bb building lock,\n             * so we grab the write lock for the whole routine\n             */\n            SHARED_VECTOR_RWLOCK(&data->areas, write, lock);\n        }\n    } else {\n        DODEBUG({new_area_prefix = \"new vm area for thread: \";});\n        data = (thread_data_t *) dcontext->vm_areas_field;\n        if (DYNAMO_OPTION(shared_bbs) && TEST(FRAG_SHARED, *flags))\n            shared_to_private = true;\n    }\n\n    LOG(THREAD, LOG_INTERP|LOG_VMAREAS, 4,\n        \"check_thread_vm_area: pc = \"PFX\"\\n\", pc);\n\n    /* no lock on data->areas needed if thread-local,\n     * if shared we grabbed either read or write lock above\n     */\n    /* check cached last area first to avoid lookup cost */\n    if (data->last_area != NULL)\n        in_last = (pc < data->last_area->end && data->last_area->start <= pc);\n\n    DOSTATS({\n        STATS_INC(checked_addresses);\n        if (in_last)\n            STATS_INC(looked_up_in_last_area);\n    });\n\n    if (in_last) {\n        local_area = data->last_area;\n        area = local_area;\n    } else if (lookup_addr(&data->areas, pc, &local_area)) {\n        /* ok to hold onto pointer since it's this thread's */\n        area = local_area;\n    } else {\n        /* not in this thread's current executable list\n         * try the global executable area list\n         */\n#ifdef LINUX\n        /* i#1760: an app module loaded by custom loader (e.g., bionic libc)\n         * might not be detected by DynamoRIO in process_mmap, so we check\n         * whether it is an unseen module here.\n         */\n        os_check_new_app_module(dcontext, pc);\n#endif\n#ifdef CLIENT_INTERFACE\n        /* i#884: module load event is now on first execution */\n        instrument_module_load_trigger(pc);\n#endif\n        if (!own_execareas_writelock)\n            read_lock(&executable_areas->lock);\n        ok = lookup_addr(executable_areas, pc, &area);\n        if (ok && TEST(VM_DELAY_READONLY, area->vm_flags)) {\n            /* need to mark region read only for consistency\n             * need to upgrade to write lock, have to release lock first\n             * then recheck conditions after grabbing hotp + write lock */\n            if (!own_execareas_writelock) {\n                read_unlock(&executable_areas->lock);\n#ifdef HOT_PATCHING_INTERFACE\n                /* Case 8780: due to lock rank issues we must grab the hotp lock\n                 * prior to the exec areas lock, as the hotp lock may be needed\n                 * for pc recreation in check_origins().  We assume this will\n                 * not cause noticeable lock contention.\n                 */\n                if (DYNAMO_OPTION(hot_patching))\n                    write_lock(hotp_get_lock());\n#endif\n                write_lock(&executable_areas->lock);\n                own_execareas_writelock = true;\n                ok = lookup_addr(executable_areas, pc, &area);\n            }\n            if (ok && TEST(VM_DELAY_READONLY, area->vm_flags))\n                handle_delay_readonly(dcontext, pc, area);\n        }\n        if ((!ok || (ok && vmlist != NULL && !TEST(VM_EXECUTED_FROM, area->vm_flags))) &&\n            !own_execareas_writelock) {\n            /* we must hold the write lock until we add the new region, as we\n             * may want to give it selfmod or other properties that will not mix\n             * well if we have a race and another thread adds an overlapping\n             * region with different properties!\n             * or if never executed from, we need to mark the area as such\n             * (if we didn't support thread-private, we would just grab write\n             * lock up front and not bother with read lock).\n             */\n            read_unlock(&executable_areas->lock);\n#ifdef HOT_PATCHING_INTERFACE\n            if (DYNAMO_OPTION(hot_patching))\n                write_lock(hotp_get_lock()); /* case 8780 -- see comments above */\n#endif\n            write_lock(&executable_areas->lock);\n            own_execareas_writelock = true;\n            ok = lookup_addr(executable_areas, pc, &area);\n        }\n        if (ok) {\n            if (vmlist != NULL && !TEST(VM_EXECUTED_FROM, area->vm_flags)) {\n                ASSERT(self_owns_write_lock(&executable_areas->lock));\n                area->vm_flags |= VM_EXECUTED_FROM;\n            }\n            area_copy = *area;\n            area = &area_copy;\n            /* if we already have an area, we do not need to hold an execareas\n             * lock, as there is no race within this routine.  any removal of\n             * the area must go through the flush synch and so cannot be\n             * concurrent to this routine.\n             */\n            if (own_execareas_writelock) {\n                if (!caller_execareas_writelock) {\n                    write_unlock(&executable_areas->lock);\n#ifdef HOT_PATCHING_INTERFACE\n                    if (DYNAMO_OPTION(hot_patching))\n                        write_unlock(hotp_get_lock()); /* case 8780 -- see above */\n#endif\n                    own_execareas_writelock = false;\n                }\n            } else\n                read_unlock(&executable_areas->lock);\n        }\n        /* if ok we should not own the readlock but we can't assert on that */\n        ASSERT(ok || (self_owns_write_lock(&executable_areas->lock) &&\n                      own_execareas_writelock\n                      IF_HOTP(&& (!DYNAMO_OPTION(hot_patching) ||\n                                  self_owns_write_lock(hotp_get_lock())))));\n        ASSERT(!ok || area != NULL);\n        if (!ok) {\n            /* we no longer allow execution from arbitrary dr mem, our dll is\n             * on the executable list and we specifically add the callback\n             * interception code */\n            bool is_in_dr = is_dynamo_address(pc);\n            /* this is an unknown or dr area\n             * we may need to return false, if flags change or if pc is\n             * unreadable (and so we don't want to follow a direct cti there\n             * until the app actually does)\n             */\n            bool is_allocated_mem = get_memory_info(pc, &base_pc, &size, &prot);\n            bool is_being_unloaded = false;\n\n#ifdef CLIENT_INTERFACE\n            /* Clients are allowed to use DR-allocated memory as app code:\n             * we give up some robustness by allowing any DR-allocated memory\n             * outside of the code cache that is marked as +x (we do not allow\n             * -x to avoid a wild jump targeting our own heap and our own cache\n             * cons policy making the heap read-only and causing a DR crash:\n             * xref DrM#1820).\n             * XXX i#852: should we instead have some dr_appcode_alloc() or\n             * dr_appcode_mark() API?\n             */\n            if (is_in_dr && INTERNAL_OPTION(code_api) &&\n                TEST(MEMPROT_EXEC, prot) && !in_fcache(pc))\n                is_in_dr = false; /* allow it */\n#endif\n\n            if (!is_allocated_mem) {\n                /* case 9022 - Kaspersky sports JMPs to a driver in\n                 * kernel address space e.g. jmp f7ab7d67\n                 * and system call queries refuse to provide any information.\n                 * We need to just try reading from that address.\n                 */\n\n                /* we first compare to\n                 * SYSTEM_BASIC_INFORMATION.HighestUserAddress (2GB or\n                 * 3GB) to know for sure we're testing a kernel\n                 * address, and not dealing with a race instead.\n                 */\n\n                if (!is_user_address(pc) &&\n                    is_readable_without_exception_try(pc, 1)) {\n                    SYSLOG_INTERNAL_WARNING_ONCE(\n                       \"Readable kernel address space memory at \"PFX\".\\n\"\n                       \"case 9022 seen with Kaspersky AV\",\n                       pc);\n                    /* FIXME: we're constructing these flags with the\n                     * intent to allow this region, any other\n                     * characteristics are hard to validate\n                     */\n                    is_allocated_mem = true;\n                    base_pc = (app_pc)ALIGN_BACKWARD(pc, PAGE_SIZE);\n                    size = PAGE_SIZE;\n                    prot = MEMPROT_READ | MEMPROT_EXEC;\n\n                    /* FIXME: note we could also test for\n                     * MEMPROT_WRITE, note that explicitly turn on\n                     * SANDBOX_FLAG() anyways.  Luckily, the one known\n                     * case where this is needed doesn't leave its\n                     * driver space writable.\n                     */\n\n                    vm_flags |= VM_DRIVER_ADDRESS;\n                    /* we mark so that we can add to executable_areas\n                     * list later, and as in the only current example\n                     * so that we can allow execution.  FIXME: Note\n                     * we'll never remove this area.  We could check\n                     * on a future access whether such an address is\n                     * still readable, and then we can remove it if\n                     * the address stops being readable.  Note that we\n                     * can never tell if this area has disappeared -\n                     * since we won't get notified on memory changes.\n                     * So we may be more likely to get a decode fault\n                     * if these ever happen.\n                     */\n                    /* FIXME: we don't support this on Linux where\n                     * we'd have to also add to all_memory_areas */\n\n                    /* Note it is better to ALWAYS turn on\n                     * SANDBOX_FLAG for these fragments since it is\n                     * not clear that we can control any writes to\n                     * them from kernel space FIXME: may be\n                     * unnecessary in the case of Kaspersky.\n                     * insert_selfmod_sandbox() will suppress\n                     * sandbox2ro_threshold for VM_DRIVER_ADDRESS areas\n                     */\n                    frag_flags |= SANDBOX_FLAG();\n                    /* FIXME: could do this under an option */\n                } else {\n                    /* just a bad address in kernel space - like 0xdeadbeef */\n                }\n            } else {\n                /* check for race where DLL is still present, but no\n                 * longer on our list.\n                 */\n                is_being_unloaded = is_unreadable_or_currently_unloaded_region(pc);\n                /* note here we'll forge an exception to the app,\n                 * even if the address is practically still readable\n                 */\n                if (is_being_unloaded) {\n                    STATS_INC(num_unloaded_race_code_origins);\n                    SYSLOG_INTERNAL_WARNING_ONCE(\"Application executing from unloaded \"\n                                                 \"address \"PFX\"\\n\", pc);\n                }\n            }\n\n            /* if target unreadable, app will die, so make sure we don't die\n             * instead, NOTE we treat dr memory as unreadable because of app\n             * races (see bug 2574) and the fact that we don't yet expect\n             * targeted attacks against dr */\n            /* case 9330 tracks a violation while we are unloading,\n             * but address shouldn't be on a new futureexec_area (case 9371)\n             */\n#ifdef WINDOWS\n            if (in_private_library(pc)) {\n                /* Privately-loaded libs are put on the DR list, and if the app\n                 * ends up executing from them they can come here.  We assert\n                 * in debug build but let it go in release.  But, we first\n                 * have to swap to native execution of FLS callbacks, which\n                 * we cannot use our do-not-inline on b/c they're call* targets.\n                 */\n                if (private_lib_handle_cb(dcontext, pc)) {\n                    /* Did the native call and set up to interpret at retaddr */\n                    check_thread_vm_area_cleanup(dcontext, true/*redirecting*/,\n                                                 true/*clean bb*/, data, vmlist,\n                                                 own_execareas_writelock,\n                                                 caller_execareas_writelock);\n                    /* avoid assert in dispatch_enter_dynamorio() */\n                    dcontext->whereami = WHERE_TRAMPOLINE;\n                    set_last_exit(dcontext, (linkstub_t *)\n                                  get_ibl_sourceless_linkstub(LINK_RETURN, 0));\n                    if (is_couldbelinking(dcontext))\n                        enter_nolinking(dcontext, NULL, false);\n                    KSTART(fcache_default);\n                    transfer_to_dispatch(dcontext, get_mcontext(dcontext),\n                                         true/*full_DR_state*/);\n                    ASSERT_NOT_REACHED();\n                }\n                CLIENT_ASSERT(false, \"privately-loaded library executed by app: \"\n                              \"please report this transparency violation\");\n            }\n#endif\n            if ((is_in_dr IF_WINDOWS(&& !in_private_library(pc))) ||\n                !is_allocated_mem || prot == 0/*no access flags*/ || is_being_unloaded) {\n                if (xfer) {\n                    /* don't follow cti, wait for app to get there and then\n                     * handle this (might be pathological case where cti is\n                     * never really followed)\n                     */\n\n                    /* Note for case 9330 that for direct xfer we want\n                     * to be able to recreate the scenario after we\n                     * stop.  Even though is_being_unloaded is a\n                     * transient property, since we treat unreadable\n                     * the same way, next time we get here we'll be\n                     * ok.  We already have to make sure we don't\n                     * missclassify futureexec_areas so can't really\n                     * get here.  Normal module unloads would have\n                     * flushed all other bb's.\n                     */\n\n                    LOG(THREAD, LOG_VMAREAS, 3,\n                        \"cti targets %s \"PFX\", stopping bb here\\n\",\n                        is_in_dr ? \"dr\" : \"unreadable\", pc);\n                    result = false;\n                    goto check_thread_return;\n                } else {\n                    /* generate sigsegv as though target application\n                     * instruction being decoded generated it\n                     */\n                    /* FIXME : might be pathalogical selfmod case where\n                     * app in fact jumps out of block before reaching the\n                     * unreadable memory */\n                    if (vmlist == NULL) {\n                        /* Case 9376: check_origins_bb_pattern() can get here\n                         * w/ vmlist==NULL.  We have to be careful to free\n                         * resources of the prior vmlist and the vmarea write lock.\n                         */\n                        SYSLOG_INTERNAL_INFO(\"non-bb-build app decode found \"\n                                             \"unreadable memory\");\n                    }\n                    LOG(GLOBAL, LOG_VMAREAS, 1,\n                        \"application tried to execute from %s \"PFX\n                        \" is_allocated_mem=%d prot=0x%x\\n\",\n                        is_in_dr ? \"dr\" : \"unreadable\", pc, is_allocated_mem, prot);\n                    LOG(THREAD, LOG_VMAREAS, 1,\n                        \"application tried to execute from %s \"PFX\n                        \" is_allocated_mem=%d prot=0x%x\\n\",\n                        is_in_dr ? \"dr\" : \"unreadable\", pc, is_allocated_mem, prot);\n                    DOLOG(1, LOG_VMAREAS, {\n                        dump_callstack\n                            (pc,\n                             (app_pc)get_mcontext_frame_ptr(dcontext,\n                                                            get_mcontext(dcontext)),\n                             THREAD, DUMP_NOT_XML);\n                    });\n\n                    /* FIXME: what if the app masks it with an exception\n                     * handler? */\n                    SYSLOG_INTERNAL_WARNING_ONCE(\n                        \"Application tried to execute from %s memory \"PFX\".\\n\"\n                        \"This may be a result of an unsuccessful attack or a potential \"\n                        \"application vulnerability.\", is_in_dr ? \"dr\" : \"unreadable\",\n                        pc);\n                    /* Not logged as a security violation, but still an\n                     * external warning, We don't want to take blame for all\n                     * program bugs that overwrite EIP with invalid addresses,\n                     * yet it may help discovering new security holes.\n                     * [Although, watching for crashes of 0x41414141 can't read\n                     *  0x41414141 helps.]\n                     *It may also be a failing attack..\n                     */\n\n                    check_thread_vm_area_cleanup(dcontext, true/*abort*/,\n                                                 true/*clean bb*/, data, vmlist,\n                                                 own_execareas_writelock,\n                                                 caller_execareas_writelock);\n\n                    /* Create an exception record for this failure */\n                    if (TEST(DUMPCORE_FORGE_UNREAD_EXEC,\n                             DYNAMO_OPTION(dumpcore_mask)))\n                        os_dump_core(\"Warning: App trying to execute from unreadable memory\");\n                    os_forge_exception(pc, UNREADABLE_MEMORY_EXECUTION_EXCEPTION);\n                    ASSERT_NOT_REACHED();\n                }\n            }\n\n            /* set all flags that don't intermix now */\n#ifdef PROGRAM_SHEPHERDING\n# ifdef WINDOWS\n            /* Don't classify the vsyscall code page as DGC for our purposes,\n             * since we permit execution from that region. This is needed\n             * for Windows XP/2003 pre-SP2 on which the code page is not\n             * part of ntdll.\n             * FIXME What about SP1?\n             * FIXME A better soln is to add the region to the exec list\n             * during os init and remove this specialized check.\n             */\n            if (!is_dyngen_vsyscall(pc))\n# endif\n                frag_flags |= FRAG_DYNGEN;\n#endif\n#ifdef WINDOWS\n            if ((prot & MEMPROT_WRITE) != 0 && is_on_stack(dcontext, pc, NULL)) {\n                /* On win32, kernel kills process if esp is bad,\n                 * doesn't even call KiUserExceptionDispatcher entry point!\n                 * Thus we cannot make this region read-only.\n                 * We must treat it as self-modifying code, and sandbox\n                 * the whole thing, to guarantee cache consistency.\n                 * FIXME: esp can point anywhere, so other regions we make\n                 * read-only may end up becoming \"stack\", and then we'll\n                 * just silently fail on a write there!!!\n                 */\n                frag_flags |= SANDBOX_FLAG();\n                STATS_INC(num_selfmod_vm_areas);\n            }\n#endif\n        }\n    }\n    if (area != NULL) {\n        ASSERT_CURIOSITY(vmlist == NULL || !TEST(VM_DELETE_ME, area->vm_flags));\n        if (vmlist != NULL && TEST(FRAG_COARSE_GRAIN, area->frag_flags)) {\n            /* We assume get_executable_area_coarse_info() is called prior to\n             * execution in a coarse region.  We go ahead and initialize here\n             * though we could wait if a xfer since the bb will not cross.\n             */\n            DEBUG_DECLARE(coarse_info_t *info =)\n                get_coarse_info_internal(pc, true/*init*/, true/*have shvm lock*/);\n            ASSERT(info != NULL);\n        }\n        ASSERT(!TEST(FRAG_COARSE_GRAIN, area->frag_flags) ||\n               get_coarse_info_internal(pc, false/*no init*/, false/*no lock*/) != NULL);\n        frag_flags |= area->frag_flags;\n\n#ifdef PROGRAM_SHEPHERDING\n        if (vmlist != NULL && /* only for bb building */\n            TEST(VM_PATTERN_REVERIFY, area->vm_flags) &&\n            !shared_to_private /* ignore shared-to-private conversion */) {\n            /* case 8168: sandbox2ro_threshold can turn into a non-sandboxed region,\n             * and our re-verify won't change that as the region is already on the\n             * executable list.  It will all work fine though.\n             */\n            ASSERT(DYNAMO_OPTION(sandbox2ro_threshold) > 0 ||\n                   TEST(FRAG_SELFMOD_SANDBOXED, area->frag_flags));\n            /* Re-verify the code origins policies, unless we are ensuring that\n             * the end of the pattern is ok.  This fixes case 4020 where another\n             * thread can use a pattern region for non-pattern code.\n             */\n            area = NULL; /* clear to force a re-verify */\n            /* Ensure we have prot */\n            get_memory_info(pc, &base_pc, &size, &prot);\n            /* satisfy lock asumptions when area == NULL */\n            if (!own_execareas_writelock) {\n# ifdef HOT_PATCHING_INTERFACE\n                if (DYNAMO_OPTION(hot_patching))\n                    write_lock(hotp_get_lock()); /* case 8780 -- see comments above */\n# endif\n                write_lock(&executable_areas->lock);\n                own_execareas_writelock = true;\n            }\n       }\n#endif\n    }\n\n    /* Ensure we looked up the mem attributes, if a new area */\n    ASSERT(area != NULL || size > 0);\n    /* FIXME: fits nicely down below as alternative to marking read-only,\n     * but must be here for vm==NULL so will stop bb at cti -- although\n     * here it gets executed multiple times until actually switch to sandboxing\n     */\n    if (area == NULL && DYNAMO_OPTION(ro2sandbox_threshold) > 0 &&\n        TEST(MEMPROT_WRITE, prot) && !TEST(FRAG_SELFMOD_SANDBOXED, frag_flags)) {\n        vm_area_t *w_area; /* can't clobber area here */\n        ro_vs_sandbox_data_t *ro2s = NULL;\n        /* even though area==NULL this can still be an exec-writable area\n         * if area is sub-page!  we can't change to sandboxing w/ sub-page\n         * regions on the same page, so we wait until come here the 1st time\n         * after a flush (which will flush the whole os region).  thus, the\n         * threshold is really just a lower bound.  FIXME: add stats on this case!\n         */\n        ASSERT(own_execareas_writelock);\n#ifdef HOT_PATCHING_INTERFACE\n        ASSERT(!DYNAMO_OPTION(hot_patching) || self_owns_write_lock(hotp_get_lock()));\n#endif\n        ASSERT(self_owns_write_lock(&executable_areas->lock));\n        if (!is_executable_area_writable(pc)) { /* ok to read as a writer */\n            /* see whether this region has been cycling on and off the list due\n             * to being written to -- if so, switch to sandboxing\n             */\n            read_lock(&written_areas->lock);\n            ok = lookup_addr(written_areas, pc, &w_area);\n            if (ok)\n                ro2s = (ro_vs_sandbox_data_t *) w_area->custom.client;\n            if (ok && ro2s->written_count >=\n                DYNAMO_OPTION(ro2sandbox_threshold)) {\n                LOG(GLOBAL, LOG_VMAREAS, 1,\n                    \"new executable area \"PFX\"-\"PFX\" written >= %dX => \"\n                    \"switch to sandboxing\\n\",\n                    base_pc, base_pc+size, DYNAMO_OPTION(ro2sandbox_threshold));\n                DOSTATS({\n                    if (vmlist != NULL) /* don't count non-build calls */\n                        STATS_INC(num_ro2sandbox);\n                });\n                /* TODO FOR PERFORMANCE:\n                 * -- if app appending to area of jitted code, make threshold big enough\n                 * so will get off page\n                 * -- modern jit shouldn't really have data on same page: all jitted\n                 * code should be combined\n                 * -- we're using OS regions b/c we merge ours, but if writer and writee\n                 * are on sep pages but in same OS region, we'll keep in cycle when we\n                 * could simply split region!  even if peel off written-to pages here,\n                 * (can't at flush time as must flush whole vm region)\n                 * if exec even once from target page, will add entire since we\n                 * merge, and will flush entire since flush bounds suggested by\n                 * OS regions (and must flush entire merged vmarea since that's\n                 * granularity of frags list).  still, worth splitting, even if\n                 * will merge back, to not lose perf if writee is on\n                 * never-executed page!  to impl, want another vm vector in\n                 * which, at flush time, we store bounds for next exec.\n                 */\n                frag_flags |= SANDBOX_FLAG();\n                /* for sandboxing best to stay at single-page regions */\n                base_pc = (app_pc) PAGE_START(pc);\n                size = PAGE_SIZE;\n                /* We do not clear the written count as we're only doing one page\n                 * here.  We want the next exec in the same region to also be\n                 * over the threshold.\n                 */\n                DODEBUG({ ro2s->ro2s_xfers++; });\n                LOG(GLOBAL, LOG_VMAREAS, 2,\n                    \"\\tsandboxing just the page \"PFX\"-\"PFX\"\\n\", base_pc, base_pc+size);\n            }\n            read_unlock(&written_areas->lock);\n        } else\n            STATS_INC(num_ro2sandbox_other_sub);\n    }\n\n    /* now that we know about new area, decide whether it's compatible to be\n     * in the same bb as previous areas, as dictated by old flags\n     * N.B.: we only care about FRAG_ flags here, not VM_ flags\n     */\n    if (xfer && !allow_xfer_for_frag_flags(dcontext, pc, *flags, frag_flags)) {\n        result = false;\n        goto check_thread_return;\n    }\n\n    /* Normally we return the union of flags from all vmarea regions touched.\n     * But if one region is coarse and another fine, we do NOT want the union,\n     * but rather we want the whole thing to be fine.  FIXME: We could also try\n     * to put in functionality to truncate at the region boundary.\n     * Case 9932: in fact we cannot allow touching two adjacent coarse regions.\n     */\n    /* N.B.: ibl entry removal (case 9636) assumes coarse fragments\n     * stay bounded within a single FRAG_COARSE_GRAIN region\n     */\n    if (TEST(FRAG_COARSE_GRAIN, frag_flags) && pc != tag/*don't cmp to nothing*/ &&\n        ((*flags & FRAG_COARSE_GRAIN) != (frag_flags & FRAG_COARSE_GRAIN) ||\n         area == NULL || area->start > tag)) {\n        *flags &= ~FRAG_COARSE_GRAIN;\n        frag_flags &= ~FRAG_COARSE_GRAIN; /* else we'll re-add below */\n        DOSTATS({\n            if (vmlist != NULL)\n                STATS_INC(coarse_overlap_with_fine);\n        });\n    }\n\n    if (vmlist == NULL) {\n        /* caller only cared about whether to follow direct cti, so exit now, don't\n         * make any persistent state changes\n         */\n        *flags |= frag_flags;\n        if (stop != NULL) {\n            if (area == NULL)\n                *stop = base_pc + size;\n            else\n                *stop = area->end;\n        }\n        ASSERT(*stop != NULL);\n        result = true;\n        goto check_thread_return;\n    }\n    /* once reach this point we're building a real bb */\n\n#ifdef SIMULATE_ATTACK\n    simulate_attack(dcontext, pc);\n#endif /* SIMULATE_ATTACK */\n\n    if (area == NULL /* unknown area */) {\n        LOG(GLOBAL, LOG_VMAREAS, 2,\n            \"WARNING: \"PFX\" -> \"PFX\"-\"PFX\" %s%s is not on executable list (thread \"TIDFMT\")\\n\",\n            pc, base_pc, base_pc+size,\n            ((prot & MEMPROT_WRITE) != 0)?\"W\":\"\", ((prot & MEMPROT_EXEC) != 0)?\"E\":\"\",\n            dcontext->owning_thread);\n        DOLOG(3, LOG_VMAREAS, { print_executable_areas(GLOBAL); });\n        DODEBUG({\n            if (is_on_stack(dcontext, pc, NULL))\n                SYSLOG_INTERNAL_WARNING_ONCE(\"executing region with pc \"PFX\" on \"\n                                             \"the stack.\", pc);\n        });\n#ifdef DGC_DIAGNOSTICS\n        dyngen_diagnostics(dcontext, pc, base_pc, size, prot);\n#endif\n\n#ifdef PROGRAM_SHEPHERDING\n        /* give origins checker a chance to change region\n         * N.B.: security violation reports in detect_mode assume that at\n         * this point we aren't holding pointers into vectors, since the\n         * shared vm write lock is released briefly for the diagnostic report.\n         */\n        if (DYNAMO_OPTION(code_origins) &&\n            !shared_to_private) { /* don't check for shared-to-private conversion */\n            int res = check_origins(dcontext, pc, &base_pc, &size, prot, &vm_flags,\n                                    &frag_flags, xfer);\n            if (res < 0) {\n                if (!xfer) {\n                    action_type_t action =\n                        security_violation_main(dcontext, pc, res,\n                                                OPTION_BLOCK|OPTION_REPORT);\n                    if (action != ACTION_CONTINUE) {\n                        check_thread_vm_area_cleanup(dcontext, true/*abort*/,\n                                                     true/*clean bb*/, data, vmlist,\n                                                     own_execareas_writelock,\n                                                     caller_execareas_writelock);\n                        security_violation_action(dcontext, action, pc);\n                        ASSERT_NOT_REACHED();\n                    }\n                } else {\n                    /* if xfer, we simply don't follow the xfer */\n                    LOG(THREAD, LOG_VMAREAS, 3,\n                        \"xfer to \"PFX\" => violation, so stopping at \"PFX\"\\n\",\n                        base_pc, pc);\n                    result = false;\n                    goto check_thread_return;\n                }\n            }\n        }\n#endif\n\n        /* make sure code is either read-only or selfmod sandboxed */\n        /* making unwritable and adding to exec areas must be atomic\n         * (another thread could get what would look like app seg fault in between!)\n         * and selfmod flag additions, etc. have restrictions, so we must have\n         * held the write lock the whole time\n         */\n        ASSERT(own_execareas_writelock);\n        ok = lookup_addr(executable_areas, pc, &area);\n        if (ok) {\n            LOG(GLOBAL, LOG_VMAREAS, 1,\n                \"\\tNew executable region is on page already added!\\n\");\n#ifdef FORENSICS_ACQUIRES_INITEXIT_LOCK\n            /* disabled until case 6141 is resolved: no lock release needed for now */\n            /* if we release the exec areas lock to emit forensic info, then\n             * someone else could have added the region since we checked above.\n             * see if we need to handle the DELAY_READONLY flag.\n             */\n            if (TEST(VM_DELAY_READONLY, area->vm_flags))\n                handle_delay_readonly(dcontext, pc, area);\n            else {\n#endif\n#ifdef PROGRAM_SHEPHERDING\n                /* else, this can only happen for pattern reverification: no races! */\n                ASSERT(TEST(VM_PATTERN_REVERIFY, area->vm_flags) &&\n                       TEST(FRAG_SELFMOD_SANDBOXED, area->frag_flags));\n#else\n                ASSERT_NOT_REACHED();\n#endif\n#ifdef FORENSICS_ACQUIRES_INITEXIT_LOCK\n            }\n#endif\n        } else {\n            /* need to add the region */\n            if (TEST(MEMPROT_WRITE, prot)) {\n                vm_flags |= VM_WRITABLE;\n                STATS_INC(num_writable_code_regions);\n                /* Now that new area bounds are finalized, see if it should be\n                 * selfmod.  Mainly this is a problem with a subpage region on the\n                 * same page as an existing subpage selfmod region.  We want the new\n                 * region to be selfmod to avoid forcing the old to switch to page\n                 * protection.  We won't have to do this once we separate the\n                 * consistency region list from the code origins list (case 3744):\n                 * then we'd have the whole page as selfmod on the consistency list,\n                 * with only the valid subpage on the origins list.  We don't mark\n                 * pieces of a large region, for simplicity.\n                 */\n                if (is_executable_area_on_all_selfmod_pages(base_pc, base_pc+size)) {\n                    frag_flags |= SANDBOX_FLAG();\n                }\n                /* case 8308: We've added options to force certain regions to\n                 * use selfmod instead of RO.  -sandbox_writable causes all writable\n                 * regions to be selfmod.  -sandbox_non_text causes all non-text\n                 * writable regions to be selfmod.\n                 */\n                else if (DYNAMO_OPTION(sandbox_writable)) {\n                    frag_flags |= SANDBOX_FLAG();\n                }\n                else if (DYNAMO_OPTION(sandbox_non_text)) {\n                    app_pc modbase = get_module_base(base_pc);\n                    if (modbase == NULL || !is_range_in_code_section\n                        (modbase, base_pc, base_pc + size, NULL, NULL)) {\n                        frag_flags |= SANDBOX_FLAG();\n                    }\n                }\n\n                if (TEST(FRAG_SELFMOD_SANDBOXED, frag_flags)) {\n                    LOG(GLOBAL, LOG_VMAREAS, 2,\n                        \"\\tNew executable region \"PFX\"-\"PFX\" is writable, but selfmod, \"\n                        \"so leaving as writable\\n\", base_pc, base_pc+size);\n                } else if (INTERNAL_OPTION(hw_cache_consistency)) {\n                    /* Make entire region read-only\n                     * If that's too big, i.e., it contains some data, the\n                     * region size will be corrected when we get a write\n                     * fault in the region\n                     */\n                    LOG(GLOBAL, LOG_VMAREAS, 2,\n                        \"\\tNew executable region \"PFX\"-\"PFX\" is writable, \"\n                        \"making it read-only\\n\", base_pc, base_pc+size);\n#if 0\n                    /* this syslog causes services.exe to hang\n                     * (ref case 666) once case 666 is fixed re-enable if\n                     * desired FIXME */\n                    SYSLOG_INTERNAL_WARNING_ONCE(\"new executable vm area is writable.\");\n#endif\n                    vm_make_unwritable(base_pc, size);\n                    vm_flags |= VM_MADE_READONLY;\n                    STATS_INC(num_rw2r_code_regions);\n                }\n            }\n            /* now add the new region to the global list */\n            ASSERT(!TEST(FRAG_COARSE_GRAIN, frag_flags)); /* else no pre-exec query */\n            add_executable_vm_area(base_pc, base_pc+size, vm_flags | VM_EXECUTED_FROM,\n                                   frag_flags, true/*own lock*/\n                                   _IF_DEBUG(\"unexpected vm area\"));\n            ok = lookup_addr(executable_areas, pc, &area);\n            ASSERT(ok);\n            DOLOG(2, LOG_VMAREAS, {\n                /* new area could have been split into multiple */\n                print_contig_vm_areas(executable_areas, base_pc, base_pc+size,\n                                      GLOBAL, \"new executable vm area: \");\n            });\n        }\n        ASSERT(area != NULL);\n        area_copy = *area;\n        area = &area_copy;\n\n        if (xfer && !allow_xfer_for_frag_flags(dcontext, pc, *flags, frag_flags)) {\n            result = false;\n            goto check_thread_return;\n        }\n    }\n    if (local_area == NULL) {\n        /* new area for this thread */\n        ASSERT(TEST(VM_EXECUTED_FROM, area->vm_flags)); /* marked above */\n#ifdef DGC_DIAGNOSTICS\n        if (!TESTANY(VM_UNMOD_IMAGE|VM_WAS_FUTURE, area->vm_flags)) {\n            LOG(GLOBAL, LOG_VMAREAS, 1,\n                \"DYNGEN in %d: non-unmod-image exec area \"PFX\"-\"PFX\" %s\\n\",\n                get_thread_id(), area->start, area->end, area->comment);\n        }\n#endif\n#ifdef PROGRAM_SHEPHERDING\n        DOSTATS({\n            if (!TEST(VM_UNMOD_IMAGE, area->vm_flags) && TEST(VM_WAS_FUTURE, area->vm_flags)) {\n                /* increment for other threads (1st thread will be inc-ed in check_origins_helper) */\n                if (is_on_stack(dcontext, area->start, area)) {\n                    STATS_INC(num_exec_future_stack);\n                } else {\n                    STATS_INC(num_exec_future_heap);\n                }\n            }\n        });\n# ifdef WINDOWS\n        DOSTATS({\n            if (!TEST(VM_UNMOD_IMAGE, area->vm_flags) && !TEST(VM_WAS_FUTURE, area->vm_flags))\n                STATS_INC(num_exec_after_load);\n        });\n# endif\n#endif\n\n        add_vm_area(&data->areas, area->start, area->end, area->vm_flags,\n                    area->frag_flags, NULL _IF_DEBUG(area->comment));\n        /* get area for actual pc (new area could have been split up) */\n        ok = lookup_addr(&data->areas, pc, &local_area);\n        ASSERT(ok);\n        DOLOG(2, LOG_VMAREAS, { print_vm_area(&data->areas, local_area,\n                                              THREAD, new_area_prefix); });\n        DOLOG(5, LOG_VMAREAS, { print_vm_areas(&data->areas, THREAD); });\n        DOCHECK(CHKLVL_ASSERTS, {\n            LOG(THREAD, 1, LOG_VMAREAS,\n                \"checking thread vmareas against executable_areas\\n\");\n            exec_area_bounds_match(dcontext, data);\n        });\n    }\n\n    ASSERT(local_area != NULL);\n    data->last_area = local_area;\n\n    /* for adding new bbs to frag lists */\n    if (tag != NULL) {\n        bool already = false;\n        fragment_t *entry, *prev;\n        /* see if this frag is already on this area's list.\n         * prev entry may not be first on list due to area merging or due to\n         * trace building that requires bb creation in middle.\n         */\n        /* vmlist has to point to front, so must walk every time\n         * along the way check to see if existing entry points to this area\n         */\n        for (entry = (fragment_t *) *vmlist, prev = NULL; entry != NULL;\n             prev = entry, entry = FRAG_ALSO(entry)) {\n            if (FRAG_PC(entry) >= local_area->start && FRAG_PC(entry) < local_area->end) {\n                already = true;\n                break;\n            }\n        }\n        if (!already) {\n            /* always allocate global, will re-allocate later if not shared */\n            prev = prepend_fraglist(MULTI_ALLOC_DC(dcontext,\n                       (data == shared_data) ? FRAG_SHARED : 0),\n                       local_area, pc, tag, prev);\n            ASSERT(FRAG_PREV(prev) != NULL);\n            if (*vmlist == NULL) {\n                /* write back first */\n                *vmlist = (void *) prev;\n            }\n        }\n        DOLOG(6, LOG_VMAREAS, {\n            print_fraglist(dcontext, local_area, \"after check_thread_vm_area, \");\n        });\n        DOLOG(7, LOG_VMAREAS, { print_fraglists(dcontext); });\n    }\n\n    *flags |= frag_flags;\n    if (stop != NULL) {\n        *stop = area->end;\n        ASSERT(*stop != NULL);\n    }\n    result = true;\n\n    /* we are building a real bb, assert consistency checks */\n    DOCHECK(1, {\n        uint prot2;\n        ok = get_memory_info(pc, NULL, NULL, &prot2);\n        ASSERT(!ok || !TEST(MEMPROT_WRITE, prot2) ||\n               TEST(FRAG_SELFMOD_SANDBOXED, *flags) ||\n               !INTERNAL_OPTION(hw_cache_consistency));\n        ASSERT(is_readable_without_exception_try(pc, 1));\n    });\n\n check_thread_return:\n    check_thread_vm_area_cleanup(dcontext, false/*not aborting*/,\n                                 false/*leave bb*/, data, vmlist,\n                                 own_execareas_writelock,\n                                 caller_execareas_writelock);\n    return result;\n}\n\nstatic void\nremove_fraglist_entry(dcontext_t *dcontext, fragment_t *entry, vm_area_t *area);\n\n/* page_pc must be aligned to the start of a page */\nvoid\nset_thread_decode_page_start(dcontext_t *dcontext, app_pc page_pc)\n{\n    thread_data_t *data;\n    /* Regardless of the dcontext that's passed in, we want to track the\n     * page_pc for the thread so get a real dcontext. */\n#ifdef UNIX\n    /* FIXME On Linux, fetching a context requires a syscall, which is a\n     * relatively costly operation, so we don't even try. Note that this can\n     * be misleading when the dcontext that's passed in isn't the one for\n     * the executing thread (such as in case 5388 on Windows).\n     */\n    if (dcontext == GLOBAL_DCONTEXT) {\n        ASSERT_CURIOSITY(dynamo_exited);\n        return;\n    }\n#else\n    dcontext = get_thread_private_dcontext();\n    if (dcontext == NULL) {\n        ASSERT_CURIOSITY(dynamo_exited);\n        return;\n    }\n#endif\n    data = (thread_data_t *) dcontext->vm_areas_field;\n    ASSERT(page_pc == (app_pc) PAGE_START(page_pc));\n    data->last_decode_area_page_pc = page_pc;\n    data->last_decode_area_valid = true;\n}\n\n/* Check if address is in the last area that passed the check_thread_vm_area tests.\n * Used for testing for an application race condition (case 845),\n * where code executed by one thread is unmapped by another.\n * The last decoded application pc should always be in the thread's last area.\n */\nbool\ncheck_in_last_thread_vm_area(dcontext_t *dcontext, app_pc pc)\n{\n    thread_data_t *data = NULL;\n    bool in_last = false;\n    app_pc last_decode_area_page_pc;\n    /* extra paranoia since called by intercept_exception */\n    if (is_readable_without_exception((app_pc)&dcontext->vm_areas_field, 4))\n        data = (thread_data_t *) dcontext->vm_areas_field;\n    /* note that if data is NULL &data->last_area will not be readable either */\n    if (is_readable_without_exception((app_pc)&data->last_area, 4) &&\n        is_readable_without_exception((app_pc)&data->last_area->end, 4) &&\n        is_readable_without_exception((app_pc)&data->last_area->start, 4))\n        /* we can walk off to the next page */\n        in_last = (pc < data->last_area->end + MAX_INSTR_LENGTH &&\n                   data->last_area->start <= pc);\n    /* last decoded app pc may be in last shared area instead */\n    if (!in_last && DYNAMO_OPTION(shared_bbs)) {\n        /* FIXME: bad to grab on failure path...\n         * can we assume only grabbed then, and not synch?\n         */\n        SHARED_VECTOR_RWLOCK(&shared_data->areas, read, lock);\n        if (is_readable_without_exception((app_pc)&shared_data->last_area->end, 4) &&\n            is_readable_without_exception((app_pc)&shared_data->last_area->start, 4))\n            /* we can walk off to the next page */\n            in_last = (pc < shared_data->last_area->end + MAX_INSTR_LENGTH &&\n                       shared_data->last_area->start <= pc);\n        SHARED_VECTOR_RWLOCK(&shared_data->areas, read, unlock);\n    }\n    /* the last decoded app pc may be in the last decoded page or the page after\n     * if the instr crosses a page boundary. This can help us more gracefully\n     * handle a race during the origins pattern check between a thread unmapping\n     * a region and another thread decoding in that region (xref case 7103).\n     */\n    if (!in_last && data != NULL &&\n        safe_read(&data->last_decode_area_page_pc, sizeof(last_decode_area_page_pc),\n                  &last_decode_area_page_pc) &&\n        /* I think the above \"safety\" checks are ridiculous so not doing them here */\n        data->last_decode_area_valid) {\n        /* Check the last decoded pc's current page and the page after. */\n        app_pc last_decode_page_end = last_decode_area_page_pc + 2*PAGE_SIZE;\n        in_last = ((POINTER_OVERFLOW_ON_ADD(last_decode_area_page_pc, 2*PAGE_SIZE) ||\n                    pc < last_decode_page_end) && last_decode_area_page_pc <= pc);\n    }\n    return in_last;\n}\n\n/* Removes vmlist entries added to the global vmarea list for f.\n * If new_vmlist != NULL, adds locally in addition to removing globally, and\n * removes the global area itself if empty.\n */\nstatic void\nremove_shared_vmlist(dcontext_t *dcontext, void *vmlist, fragment_t *f,\n                     void **local_vmlist)\n{\n    vm_area_t *area = NULL;\n    fragment_t *entry = (fragment_t *) vmlist;\n    fragment_t *next;\n    bool remove;\n    bool ok;\n    uint check_flags = 0;\n    app_pc pc;\n    LOG(THREAD, LOG_VMAREAS, 4, \"\\tremoving shared vm data for F%d(\"PFX\")\\n\",\n        f->id, f->tag);\n    SHARED_VECTOR_RWLOCK(&shared_data->areas, write, lock);\n    while (entry != NULL) {\n        ASSERT(FRAG_MULTI_INIT(entry));\n        ASSERT(FRAG_FRAG(entry) == (fragment_t *) f->tag); /* for this frag */\n        /* If area will become empty, remove it, since it was only added for\n         * this bb that is not actually shared.\n         * Case 8906: do NOT remove the area for coarse fragments, as they are\n         * still shared!  We need the area, just not the fragment on the frags\n         * list(s).\n         */\n        remove = (local_vmlist != NULL && FRAG_PREV(entry) == entry &&\n                  !TEST(FRAG_COARSE_GRAIN, f->flags));\n        if (remove) {\n            ok = lookup_addr(&shared_data->areas, FRAG_PC(entry), &area);\n            ASSERT(ok && area != NULL);\n            if (TEST(FRAG_COARSE_GRAIN, area->frag_flags)) {\n                /* Case 9806: do NOT remove the coarse area even if this\n                 * particular fragment is fine-grained.  We also test f->flags\n                 * up front to avoid the lookup cost as an optimization.\n                 */\n                remove = false;\n            } else {\n                LOG(THREAD, LOG_VMAREAS, 4,\n                    \"sole fragment in added shared area, removing\\n\");\n            }\n        } else\n            area = NULL;\n        next = FRAG_ALSO(entry);\n        pc = FRAG_PC(entry);\n        remove_fraglist_entry(GLOBAL_DCONTEXT, entry, area /* ok to be NULL */);\n        if (remove) {\n            /* FIXME case 8629: lots of churn if frequent removals (e.g., coarse grain) */\n            remove_vm_area(&shared_data->areas, area->start, area->end, false);\n            shared_data->last_area = NULL;\n        }\n        if (local_vmlist != NULL) {\n            /* add area to local and add local heap also entry */\n            if (DYNAMO_OPTION(shared_bbs))\n                check_flags = f->flags | FRAG_SHARED; /*indicator to NOT use global*/\n            ok = check_thread_vm_area(dcontext, pc, f->tag, local_vmlist, &check_flags,\n                                      NULL, false /*xfer should not matter now*/);\n            ASSERT(ok);\n        }\n        entry = next;\n    }\n    SHARED_VECTOR_RWLOCK(&shared_data->areas, write, unlock);\n}\n\nvoid\nvm_area_add_fragment(dcontext_t *dcontext, fragment_t *f, void *vmlist)\n{\n    thread_data_t *data;\n    vm_area_t *area = NULL;\n    fragment_t *entry = (fragment_t *) vmlist;\n    fragment_t *prev = NULL;\n\n    LOG(THREAD, LOG_VMAREAS, 4, \"vm_area_add_fragment for F%d(\"PFX\")\\n\", f->id, f->tag);\n\n    if (TEST(FRAG_COARSE_GRAIN, f->flags)) {\n        /* We went ahead and built up vmlist since we might decide later to not\n         * make a fragment coarse-grain.  If it is emitted as coarse-grain,\n         * we need to clean up the vmlist as it is not needed.\n         */\n        remove_shared_vmlist(dcontext, vmlist, f, NULL/*do not add local*/);\n        return;\n    }\n\n    if (TEST(FRAG_SHARED, f->flags)) {\n        data = shared_data;\n        /* need write lock since writing area->frags */\n        SHARED_VECTOR_RWLOCK(&shared_data->areas, write, lock);\n    } else if (!DYNAMO_OPTION(shared_bbs) ||\n               /* should already be in private vmareas */\n               TESTANY(FRAG_IS_TRACE | FRAG_TEMP_PRIVATE, f->flags))\n        data = (thread_data_t *) dcontext->vm_areas_field;\n    else {\n        void *local_vmlist = NULL;\n        /* turns out bb isn't shared, so we have to transfer also entries\n         * to local heap and vector.  we do that by removing from global\n         * and then calling check_thread_vm_area, telling it to add local.\n         */\n        ASSERT(dcontext != GLOBAL_DCONTEXT);\n        /* only bbs do we build shared and then switch to private */\n        ASSERT(!TEST(FRAG_IS_TRACE, f->flags));\n        data = (thread_data_t *) dcontext->vm_areas_field;\n        LOG(THREAD, LOG_VMAREAS, 4, \"\\tbb not shared, shifting vm data to thread-local\\n\");\n        remove_shared_vmlist(dcontext, vmlist, f, &local_vmlist);\n        /* now proceed as though everything were local to begin with */\n        vmlist = local_vmlist;\n        entry = (fragment_t *) vmlist;\n    }\n\n    /* swap f for the first multi_entry_t (the one in region of f->tag) */\n    ASSERT(entry != NULL);\n    FRAG_NEXT_ASSIGN(f, FRAG_NEXT(entry));\n    FRAG_PREV_ASSIGN(f, FRAG_PREV(entry));\n    FRAG_ALSO_ASSIGN(f, FRAG_ALSO(entry));\n    prev = FRAG_PREV(f);\n    ASSERT(prev != NULL); /* prev is never null */\n    if (FRAG_NEXT(prev) == NULL) {\n        DEBUG_DECLARE(bool ok =)\n            /* need to know area */\n            lookup_addr(&data->areas, FRAG_PC(entry), &area);\n        ASSERT(ok);\n        /* remember: prev wraps around, next does not */\n        ASSERT(area->custom.frags == entry);\n        area->custom.frags = f;\n        /* if single entry will be circular */\n        if (prev == entry)\n            FRAG_PREV_ASSIGN(f, f);\n    } else\n        FRAG_NEXT_ASSIGN(prev, f);\n    if (FRAG_NEXT(f) == NULL) {\n        if (area == NULL) {\n            DEBUG_DECLARE(bool ok =)\n                /* need to know area for area->frags */\n                lookup_addr(&data->areas, FRAG_PC(entry), &area);\n            ASSERT(ok);\n        }\n        if (area->custom.frags == f) {\n            ASSERT(FRAG_PREV(area->custom.frags) == f);\n        } else {\n            ASSERT(FRAG_PREV(area->custom.frags) == entry);\n            FRAG_PREV_ASSIGN(area->custom.frags, f);\n        }\n    } else {\n        prev = FRAG_NEXT(f);\n        FRAG_PREV_ASSIGN(prev, f);\n    }\n\n    ASSERT(area_contains_frag_pc(area, entry));\n\n    prev = FRAG_ALSO(entry);\n    nonpersistent_heap_free(MULTI_ALLOC_DC(dcontext, entry->flags), entry,\n                            sizeof(multi_entry_t) HEAPACCT(ACCT_VMAREA_MULTI));\n    entry = prev;\n\n    DOSTATS({\n        if (entry != NULL)\n            STATS_INC(num_bb_also_vmarea);\n    });\n\n    /* now put backpointers in */\n    while (entry != NULL) {\n        ASSERT(FRAG_MULTI_INIT(entry));\n        ASSERT(FRAG_FRAG(entry) == (fragment_t *) f->tag); /* for this frag */\n        DOLOG(4, LOG_VMAREAS, { print_entry(dcontext, entry, \"\\talso \"); });\n        FRAG_FRAG_ASSIGN(entry, f);\n        /* remove the init flag now that the real fragment_t is in the f field\n         * The vector lock protects this non-atomic flag change.\n         */\n        entry->flags &= ~FRAG_IS_EXTRA_VMAREA_INIT;\n        entry = FRAG_ALSO(entry);\n    }\n\n    DOLOG(6, LOG_VMAREAS, { print_frag_arealist(dcontext, f); });\n    DOLOG(7, LOG_VMAREAS, { print_fraglists(dcontext); });\n\n    /* can't release lock once done w/ prev/next values since alsos can\n     * be changed as well by vm_area_clean_fraglist()!\n     */\n    SHARED_VECTOR_RWLOCK(&data->areas, write, unlock);\n}\n\nvoid\nacquire_vm_areas_lock(dcontext_t *dcontext, uint flags)\n{\n    thread_data_t *data = GET_DATA(dcontext, flags);\n    SHARED_VECTOR_RWLOCK(&data->areas, write, lock);\n}\n\nbool\nacquire_vm_areas_lock_if_not_already(dcontext_t *dcontext, uint flags)\n{\n    thread_data_t *data = GET_DATA(dcontext, flags);\n    return writelock_if_not_already(&data->areas);\n}\n\nvoid\nrelease_vm_areas_lock(dcontext_t *dcontext, uint flags)\n{\n    thread_data_t *data = GET_DATA(dcontext, flags);\n    SHARED_VECTOR_RWLOCK(&data->areas, write, unlock);\n}\n\n#ifdef DEBUG\n/* i#942: Check that each also_vmarea entry in a multi-area fragment is in its\n * own vmarea.  If a fragment is on a vmarea fragment list twice, we can end up\n * deleting that fragment twice while flushing.\n */\nstatic bool\nfrag_also_list_areas_unique(dcontext_t *dcontext, thread_data_t *tgt_data,\n                            void **vmlist)\n{\n    fragment_t *entry;\n    fragment_t *already;\n    vm_area_t *entry_area;\n    vm_area_t *already_area;\n    bool ok;\n    for (entry = (fragment_t *) *vmlist; entry != NULL;\n         entry = FRAG_ALSO(entry)) {\n        ASSERT(FRAG_MULTI(entry));\n        ok = lookup_addr(&tgt_data->areas, FRAG_PC(entry), &entry_area);\n        ASSERT(ok);\n        /* Iterate the previous also entries and make sure they don't have the\n         * same vmarea.\n         * XXX: This is O(n^2) in the also list length, but these lists are\n         * short and the O(n) impl would require a hashtable.\n         */\n        for (already = (fragment_t *) *vmlist; already != entry;\n             already = FRAG_ALSO(already)) {\n            ASSERT(FRAG_MULTI(already));\n            ok = lookup_addr(&tgt_data->areas, FRAG_PC(already), &already_area);\n            ASSERT(ok);\n            if (entry_area == already_area)\n                return false;\n        }\n    }\n    return true;\n}\n\n/* i#942: Check that the per-thread list of executed areas doesn't cross any\n * executable_area boundaries.  If this happens, we start adding fragments to the\n * wrong vmarea fragment lists.  This check should be roughly O(n log n) in the\n * number of exec areas, so not too slow to run at the assertion check level.\n */\nstatic void\nexec_area_bounds_match(dcontext_t *dcontext, thread_data_t *data)\n{\n    vm_area_vector_t *v = &data->areas;\n    int i;\n    read_lock(&executable_areas->lock);\n    for (i = 0; i < v->length; i++) {\n        vm_area_t *thread_area = &v->buf[i];\n        vm_area_t *exec_area;\n        bool ok = lookup_addr(executable_areas, thread_area->start, &exec_area);\n        ASSERT(ok);\n        /* It's OK if thread areas are more fragmented than executable_areas.\n         */\n        if (!(thread_area->start >= exec_area->start &&\n              thread_area->end <= exec_area->end)) {\n            DOLOG(1, LOG_VMAREAS, {\n                LOG(THREAD, LOG_VMAREAS, 1,\n                    \"%s: bounds mismatch on %s vmvector\\n\", __FUNCTION__,\n                    (TEST(VECTOR_SHARED, v->flags) ? \"shared\" : \"private\"));\n                print_vm_area(v, thread_area, THREAD, \"thread area: \");\n                print_vm_area(v, exec_area, THREAD, \"exec area: \");\n                LOG(THREAD, 1, LOG_VMAREAS, \"executable_areas:\\n\");\n                print_vm_areas(executable_areas, THREAD);\n                LOG(THREAD, 1, LOG_VMAREAS, \"thread areas:\\n\");\n                print_vm_areas(v, THREAD);\n                ASSERT(false && \"vmvector does not match exec area bounds\");\n            });\n        }\n    }\n    read_unlock(&executable_areas->lock);\n}\n#endif /* DEBUG */\n\n/* Creates a list of also entries for each vmarea touched by f and prepends it\n * to vmlist.\n *\n * Case 8419: this routine will fail and return false if f is marked as\n * FRAG_WAS_DELETED, since that means f's also entries have been deleted!\n * Caller can make an atomic no-fail region by holding f's vm area lock\n * and the change_linking_lock and passing true for have_locks.\n */\nbool\nvm_area_add_to_list(dcontext_t *dcontext, app_pc tag, void **vmlist,\n                    uint list_flags, fragment_t *f, bool have_locks)\n{\n    thread_data_t *src_data = GET_DATA(dcontext, f->flags);\n    thread_data_t *tgt_data = GET_DATA(dcontext, list_flags);\n    vm_area_t *area = NULL;\n    bool ok;\n    fragment_t *prev = (fragment_t *) *vmlist;\n    fragment_t *already;\n    fragment_t *entry = f;\n    bool success = true;\n    bool lock;\n    if (!have_locks)\n        SHARED_FLAGS_RECURSIVE_LOCK(f->flags, acquire, change_linking_lock);\n    else {\n        ASSERT((!TEST(VECTOR_SHARED, tgt_data->areas.flags) &&\n                !TEST(VECTOR_SHARED, src_data->areas.flags)) ||\n               self_owns_recursive_lock(&change_linking_lock));\n    }\n    /* support caller already owning write lock */\n    lock = writelock_if_not_already(&src_data->areas);\n    if (src_data != tgt_data) {\n        /* we assume only one of the two is shared, or that they are both the same,\n         * and we thus grab only one lock in this routine:\n         * otherwise we need to do more work to avoid deadlocks here!\n         */\n        ASSERT(!TEST(VECTOR_SHARED, tgt_data->areas.flags) ||\n               !TEST(VECTOR_SHARED, src_data->areas.flags));\n        if (TEST(VECTOR_SHARED, tgt_data->areas.flags)) {\n            ASSERT(!lock);\n            lock = writelock_if_not_already(&tgt_data->areas);\n        }\n    }\n    ASSERT((lock && !have_locks) || (!lock && have_locks) ||\n           (!TEST(VECTOR_SHARED, tgt_data->areas.flags) &&\n            !TEST(VECTOR_SHARED, src_data->areas.flags)));\n    DOCHECK(CHKLVL_ASSERTS, {\n        LOG(THREAD, 1, LOG_VMAREAS, \"checking src_data\\n\");\n        exec_area_bounds_match(dcontext, src_data);\n        LOG(THREAD, 1, LOG_VMAREAS, \"checking tgt_data\\n\");\n        exec_area_bounds_match(dcontext, tgt_data);\n    });\n    /* If deleted, the also field is invalid and we cannot handle that! */\n    if (TEST(FRAG_WAS_DELETED, f->flags)) {\n        success = false;\n        goto vm_area_add_to_list_done;\n    }\n    /* vmlist has to point to front, so must walk every time to find end */\n    while (prev != NULL && FRAG_ALSO(prev) != NULL)\n        prev = FRAG_ALSO(prev);\n    /* walk f's areas */\n    while (entry != NULL) {\n        /* see if each of f's areas is already on trace's list */\n        ok = lookup_addr(&src_data->areas, FRAG_PC(entry), &area);\n        ASSERT(ok);\n        ok = false; /* whether found existing entry in area or not */\n        for (already = (fragment_t *) *vmlist; already != NULL;\n             already = FRAG_ALSO(already)) {\n            ASSERT(FRAG_MULTI(already));\n            if (FRAG_PC(already) >= area->start && FRAG_PC(already) < area->end) {\n                ok = true;\n                break;\n            }\n        }\n        if (!ok) {\n            /* found new area that trace is on */\n            /* src may be shared bb, its area may not be on tgt list (e.g., private trace) */\n            if (src_data != tgt_data) { /* else, have area already */\n                vm_area_t *tgt_area = NULL;\n                if (lookup_addr(&tgt_data->areas, FRAG_PC(entry), &tgt_area)) {\n                    /* check target area for existing entry */\n                    for (already = (fragment_t *) *vmlist; already != NULL;\n                         already = FRAG_ALSO(already)) {\n                        ASSERT(FRAG_MULTI(already));\n                        if (FRAG_PC(already) >= tgt_area->start &&\n                            FRAG_PC(already) < tgt_area->end) {\n                            ok = true;\n                            break;\n                        }\n                    }\n                    if (ok)\n                        break;\n                } else {\n                    add_vm_area(&tgt_data->areas, area->start, area->end, area->vm_flags,\n                                area->frag_flags, NULL _IF_DEBUG(area->comment));\n                    ok = lookup_addr(&tgt_data->areas, FRAG_PC(entry), &tgt_area);\n                    ASSERT(ok);\n                    /* modified vector, must clear last_area */\n                    tgt_data->last_area = NULL;\n                    DOLOG(2, LOG_VMAREAS, {\n                        print_vm_area(&tgt_data->areas, tgt_area, THREAD,\n                                      \"new vm area for thread: \");\n                    });\n                    DOLOG(5, LOG_VMAREAS, { print_vm_areas(&tgt_data->areas, THREAD); });\n                }\n                area = tgt_area;\n            }\n            ASSERT(area != NULL);\n            prev = prepend_fraglist(MULTI_ALLOC_DC(dcontext, list_flags),\n                                    area, FRAG_PC(entry), tag, prev);\n            if (*vmlist == NULL) {\n                /* write back first */\n                *vmlist = (void *) prev;\n            }\n        }\n        entry = FRAG_ALSO(entry);\n    }\n    ASSERT_MESSAGE(CHKLVL_DEFAULT, \"fragment also list has duplicate entries\",\n                   frag_also_list_areas_unique(dcontext, tgt_data, vmlist));\n    DOLOG(6, LOG_VMAREAS, { print_frag_arealist(dcontext, (fragment_t *) *vmlist); });\n    DOLOG(7, LOG_VMAREAS, { print_fraglists(dcontext); });\n vm_area_add_to_list_done:\n    if (lock) {\n        if (src_data != tgt_data)\n            SHARED_VECTOR_RWLOCK(&tgt_data->areas, write, unlock);\n        SHARED_VECTOR_RWLOCK(&src_data->areas, write, unlock);\n    }\n    if (!have_locks)\n        SHARED_FLAGS_RECURSIVE_LOCK(f->flags, release, change_linking_lock);\n    return success;\n}\n\n/* Frees storage for any multi-entries in the list (NOT for any fragment_t).\n * FIXME: this is now used on bb abort, where we may want to remove a vmarea\n * that was added only for a unreadable region (if decode fault will have been\n * added already)!  Yet we don't know whether any coarse fragments in area,\n * etc., so we go ahead and leave there: cached in last_area will lead to decode\n * fault rather than explicit detection in check_thread_vm_area but that's ok.\n * If we do want to remove should share code between this routine and\n * remove_shared_vmlist().\n */\nvoid\nvm_area_destroy_list(dcontext_t *dcontext, void *vmlist)\n{\n    if (vmlist != NULL)\n        vm_area_remove_fragment(dcontext, (fragment_t *)vmlist);\n}\n\nbool\nvm_list_overlaps(dcontext_t *dcontext, void *vmlist, app_pc start, app_pc end)\n{\n    vm_area_vector_t *v = GET_VECTOR(dcontext, ((fragment_t *)vmlist)->flags);\n    fragment_t *entry;\n    bool ok;\n    vm_area_t *area;\n    bool result = false;\n    LOG(THREAD, LOG_VMAREAS, 4, \"vm_list_overlaps \"PFX\" vs \"PFX\"-\"PFX\"\\n\",\n        vmlist, start, end);\n    /* don't assert if can't find anything -- see usage in handle_modified_code() */\n    if (v == NULL)\n        return false;\n    SHARED_VECTOR_RWLOCK(v, read, lock);\n    for (entry = vmlist; entry != NULL; entry = FRAG_ALSO(entry)) {\n        ok = lookup_addr(v, FRAG_PC(entry), &area);\n        if (!ok)\n            break;\n        if (start < area->end && end > area->start) {\n            result = true;\n            break;\n        }\n    }\n    SHARED_VECTOR_RWLOCK(v, read, unlock);\n    return result;\n}\n\n/* Removes an entry from the fraglist of area.\n * If area is NULL, looks it up based on dcontext->vm_areas_field->areas,\n * or the shared areas, depending on entry.\n * That lookup may need to be synchronized: this routine checks if the\n * caller holds the write lock before grabbing it.\n * If entry is a multi_entry_t, frees its heap\n * DOES NOT update the also chain!\n */\nstatic void\nremove_fraglist_entry(dcontext_t *dcontext, fragment_t *entry, vm_area_t *area)\n{\n    thread_data_t *data = GET_DATA(dcontext, entry->flags);\n    fragment_t *prev;\n    vm_area_vector_t *vector = &data->areas;\n    /* need write lock since may modify area->frags */\n    bool lock = writelock_if_not_already(vector);\n    /* entry is only in shared vector if still live -- if not\n     * we shouldn't get here\n     */\n    ASSERT(!TEST(VECTOR_SHARED, vector->flags) || !TEST(FRAG_WAS_DELETED, entry->flags));\n    ASSERT(area_contains_frag_pc(area, entry));\n\n    prev = FRAG_PREV(entry);\n    if (FRAG_NEXT(prev) == NULL || FRAG_NEXT(entry) == NULL) {\n        /* need to know area */\n        DEBUG_DECLARE(bool ok =)\n            lookup_addr(vector, FRAG_PC(entry), &area);\n        ASSERT(ok);\n        ASSERT(area != NULL);\n    }\n\n    /* remember: prev wraps around, next does not */\n    if (FRAG_NEXT(prev) == NULL) {\n        ASSERT(area->custom.frags == entry);\n        area->custom.frags = FRAG_NEXT(entry);\n    } else {\n        FRAG_NEXT_ASSIGN(prev, FRAG_NEXT(entry));\n    }\n    if (FRAG_NEXT(entry) == NULL) {\n        if (area->custom.frags != NULL) {\n            ASSERT(FRAG_PREV(area->custom.frags) == entry);\n            FRAG_PREV_ASSIGN(area->custom.frags, FRAG_PREV(entry));\n        }\n    } else {\n        fragment_t *next = FRAG_NEXT(entry);\n        FRAG_PREV_ASSIGN(next, FRAG_PREV(entry));\n    }\n    /* next MUST be NULL-ed for fragment_remove_shared_no_flush() */\n    FRAG_NEXT_ASSIGN(entry, NULL);\n    DODEBUG({\n        FRAG_PREV_ASSIGN(entry, NULL);\n        FRAG_ALSO_ASSIGN(entry, NULL);\n    });\n    if (FRAG_MULTI(entry)) {\n        nonpersistent_heap_free(MULTI_ALLOC_DC(dcontext, entry->flags), entry,\n                                sizeof(multi_entry_t) HEAPACCT(ACCT_VMAREA_MULTI));\n    }\n    if (lock)\n        SHARED_VECTOR_RWLOCK(vector, write, unlock);\n}\n\n#ifdef DEBUG\n/* For every multi_entry_t fragment in the fraglist, make sure that neither the\n * real fragment nor any of the other also entries are in the same fraglist.\n * This should only ever happen after a merger, at which point we call\n * vm_area_clean_fraglist() to fix it.  Any other occurrence is a bug.\n */\nstatic void\nvm_area_check_clean_fraglist(vm_area_t *area)\n{\n    fragment_t *entry;\n    for (entry = area->custom.frags; entry != NULL; entry = FRAG_NEXT(entry)) {\n        /* All entries and fragments should be from this area. */\n        ASSERT(area_contains_frag_pc(area, entry));\n        if (FRAG_MULTI(entry)) {\n            fragment_t *f = FRAG_FRAG(entry);\n            /* Ideally we'd take FRAG_ALSO(f) to start also iteration, but that\n             * pointer isn't valid during bb building.\n             */\n            fragment_t *also = FRAG_ALSO(entry);\n            ASSERT(f != FRAG_NEXT(entry));\n            /* Iterate the also list.  All elements should be outside the\n             * current area, or they should be the multi_entry_t that we're\n             * currently looking at.\n             */\n            while (also != NULL) {\n                ASSERT(FRAG_MULTI(also));\n                ASSERT(also == entry || !area_contains_frag_pc(area, also));\n                also = FRAG_ALSO(also);\n            }\n            /* This is a multi area entry, so the real fragment shouldn't start\n             * in this area and therefore shouldn't be on this list.\n             */\n            ASSERT(FRAG_MULTI_INIT(entry) ||\n                   !(f->tag >= area->start && f->tag < area->end));\n        }\n    }\n}\n#endif /* DEBUG */\n\n/* Removes redundant also entries in area's frags list\n * (viz., those also entries that are now in same area as frag)\n * Meant to be called after merging areas\n */\nstatic void\nvm_area_clean_fraglist(dcontext_t *dcontext, vm_area_t *area)\n{\n    fragment_t *entry, *next, *f;\n    fragment_t *also, *also_prev, *also_next;\n    LOG(THREAD, LOG_VMAREAS, 4,\n        \"vm_area_clean_fraglist for \"PFX\"-\"PFX\"\\n\", area->start, area->end);\n    DOLOG(6, LOG_VMAREAS, { print_fraglist(dcontext, area, \"before cleaning \"); });\n    /* FIXME: would like to assert we hold write lock but only have area ptr */\n    for (entry = area->custom.frags; entry != NULL; entry = next) {\n        next = FRAG_NEXT(entry); /* might delete entry */\n        /* Strategy: look at each multi, see if its fragment_t is here or if the next\n         * multi in also chain is here.\n         * This cleaning doesn't happen very often so this shouldn't be perf critical.\n         */\n        if (FRAG_MULTI(entry)) {\n            f = FRAG_FRAG(entry);\n            ASSERT(f != next);\n            /* Remove later also entries first */\n            also = FRAG_ALSO(entry);\n            also_prev = entry;\n            while (also != NULL) {\n                app_pc pc = FRAG_PC(also);\n                also_next = FRAG_ALSO(also);\n                if (pc >= area->start && pc < area->end) {\n                    ASSERT(FRAG_FRAG(also) == f);\n                    DOLOG(5, LOG_VMAREAS, { print_entry(dcontext, also, \"\\tremoving \"); });\n                    /* we have to remove from also chain ourselves */\n                    FRAG_ALSO_ASSIGN(also_prev, also_next);\n                    /* now remove from area frags list */\n                    remove_fraglist_entry(dcontext, also, area);\n                } else\n                    also_prev = also;\n                also = also_next;\n            }\n            /* fragment_t itself is always in area of its tag */\n            if (!FRAG_MULTI_INIT(entry) && f->tag >= area->start && f->tag < area->end) {\n                /* Remove this multi entry */\n                DOLOG(5, LOG_VMAREAS, { print_entry(dcontext, entry, \"\\tremoving \"); });\n                /* we have to remove from also chain ourselves */\n                for (also_prev = f; FRAG_ALSO(also_prev) != entry; also_prev = FRAG_ALSO(also_prev))\n                    ;\n                FRAG_ALSO_ASSIGN(also_prev, FRAG_ALSO(entry));\n                /* now remove from area frags list */\n                remove_fraglist_entry(dcontext, entry, area);\n            }\n        }\n    }\n    DOCHECK(CHKLVL_DEFAULT, {\n        vm_area_check_clean_fraglist(area);\n    });\n    DOLOG(6, LOG_VMAREAS, { print_fraglist(dcontext, area, \"after cleaning \"); });\n}\n\nvoid\nvm_area_remove_fragment(dcontext_t *dcontext, fragment_t *f)\n{\n    fragment_t *entry, *next, *match;\n    /* must grab lock across whole thing since alsos can be changed\n     * by vm_area_clean_fraglist()\n     */\n    vm_area_vector_t *vector = &(GET_DATA(dcontext, f->flags))->areas;\n    bool multi = FRAG_MULTI(f);\n    bool lock = writelock_if_not_already(vector);\n\n    if (!multi) {\n        LOG(THREAD, LOG_VMAREAS, 4,\n            \"vm_area_remove_fragment: F%d tag=\"PFX\"\\n\", f->id, f->tag);\n        match = f;\n    } else {\n        /* we do get called for multi-entries from vm_area_destroy_list */\n        LOG(THREAD, LOG_VMAREAS, 4,\n            \"vm_area_remove_fragment: entry \"PFX\"\\n\", f);\n        match = FRAG_FRAG(f);\n    }\n    ASSERT(FRAG_PREV(f) != NULL); /* prev wraps around, should never be null */\n\n    entry = f;\n    while (entry != NULL) {\n        DOLOG(5, LOG_VMAREAS, { print_entry(dcontext, entry, \"\\tremoving \"); });\n        /* from vm_area_destroy_list we can end up deleting a multi-init */\n        ASSERT(FRAG_FRAG(entry) == match);\n        next = FRAG_ALSO(entry);\n        remove_fraglist_entry(dcontext, entry, NULL);\n        entry = next;\n    }\n    if (!multi) /* else f may have been freed */\n        FRAG_ALSO_ASSIGN(f, NULL);\n\n    DOLOG(7, LOG_VMAREAS, { print_fraglists(dcontext); });\n\n    /* f may no longer exist if it is FRAG_MULTI */\n    if (lock)\n        SHARED_VECTOR_RWLOCK(vector, write, unlock);\n}\n\n/* adds the fragment list chained by next_vmarea starting at f to a new\n * pending deletion entry\n */\nstatic void\nadd_to_pending_list(dcontext_t *dcontext, fragment_t *f,\n                    uint refcount, uint flushtime\n                    _IF_DEBUG(app_pc start) _IF_DEBUG(app_pc end))\n{\n    pending_delete_t *pend;\n    ASSERT_OWN_MUTEX(true, &shared_delete_lock);\n    pend = HEAP_TYPE_ALLOC(GLOBAL_DCONTEXT, pending_delete_t,\n                           ACCT_VMAREAS, PROTECTED);\n    DODEBUG({\n        pend->start = start;\n        pend->end = end;\n    });\n    pend->frags = f;\n    if (DYNAMO_OPTION(shared_deletion)) {\n        /* Set up ref count and timestamp for delayed deletion */\n        pend->ref_count = refcount;\n        pend->flushtime_deleted = flushtime;\n        LOG(GLOBAL, LOG_VMAREAS, 2,\n            \"deleted area ref count=%d timestamp=%u start=\"PFX\" end=\"PFX\"\\n\",\n            pend->ref_count, pend->flushtime_deleted, start, end);\n    }\n    /* add to front of list */\n    pend->next = todelete->shared_delete;\n    todelete->shared_delete = pend;\n    todelete->shared_delete_count++;\n    if (pend->next == NULL) {\n        ASSERT(todelete->shared_delete_tail == NULL);\n        todelete->shared_delete_tail = pend;\n    }\n\n    if (DYNAMO_OPTION(reset_every_nth_pending) > 0 &&\n        DYNAMO_OPTION(reset_every_nth_pending) == todelete->shared_delete_count) {\n        /* if too many pending entries are piling up, suspend all threads\n         * in order to free them immediately.\n         * we can get here multiple times before we actually do the reset\n         * (can dec and then re-inc shared_delete_count),\n         * but that's not a problem, except we have to move our stats inc\n         * into the reset routine itself.\n         */\n        schedule_reset(RESET_PENDING_DELETION/*NYI: currently this is ignored and we\n                                              * do a full reset*/);\n    }\n\n    STATS_INC(num_shared_flush_regions);\n    LOG(GLOBAL, LOG_VMAREAS, 3,\n        \"Pending list after adding deleted vm area:\\n\");\n    DOLOG(3, LOG_VMAREAS, { print_pending_list(GLOBAL); });\n}\n\n#if defined(DEBUG) && defined(INTERNAL)\nstatic void\nprint_lazy_deletion_list(dcontext_t *dcontext, const char *msg)\n{\n    uint i = 0;\n    fragment_t *f;\n    ASSERT_OWN_MUTEX(true, &lazy_delete_lock);\n    LOG(THREAD, LOG_VMAREAS, 1, \"%s\", msg);\n    for (f = todelete->lazy_delete_list; f != NULL; f = f->next_vmarea) {\n        LOG(THREAD, LOG_VMAREAS, 1, \"\\t%d: F%d (\"PFX\")\\n\", i, f->id, f->tag);\n        i++;\n    }\n}\n#endif\n\n#ifdef DEBUG\nstatic void\ncheck_lazy_deletion_list_consistency()\n{\n    uint i =0;\n    fragment_t *f;\n    ASSERT_OWN_MUTEX(true, &lazy_delete_lock);\n    for (f = todelete->lazy_delete_list; f != NULL; f = f->next_vmarea) {\n        i++;\n    }\n    ASSERT(i == todelete->lazy_delete_count);\n}\n#endif\n\nbool\nremove_from_lazy_deletion_list(dcontext_t *dcontext, fragment_t *remove)\n{\n    fragment_t *f, *prev_f = NULL;\n    mutex_lock(&lazy_delete_lock);\n    /* FIXME: start using prev_vmarea?!? (case 7165) */\n    for (f = todelete->lazy_delete_list; f != NULL; prev_f = f, f = f->next_vmarea) {\n        if (f == remove) {\n            if (prev_f == NULL)\n                todelete->lazy_delete_list = f->next_vmarea;\n            else\n                prev_f->next_vmarea = f->next_vmarea;\n            if (f == todelete->lazy_delete_tail)\n                todelete->lazy_delete_tail = prev_f;\n            todelete->lazy_delete_count--;\n            mutex_unlock(&lazy_delete_lock);\n            return true;\n        }\n    }\n    mutex_unlock(&lazy_delete_lock);\n    return false;\n}\n\n/* Moves all lazy list entries into a real pending deletion entry.\n * Can only be called when !couldbelinking.\n */\nstatic void\nmove_lazy_list_to_pending_delete(dcontext_t *dcontext)\n{\n    ASSERT_OWN_NO_LOCKS();\n    ASSERT(is_self_couldbelinking());\n    /* to properly set up ref count we MUST get a flushtime synched with a\n     * thread count (otherwise we may have too many threads decrementing\n     * the ref count, or vice versa, causing either premature or\n     * never-occurring freeing), so we must grab thread_initexit_lock,\n     * meaning we must be nolinking, meaning the caller must accept loss\n     * of locals.\n     * FIXME: should switch to a flag-triggered addition in dispatch\n     * to avoid this nolinking trouble.\n     */\n    enter_nolinking(dcontext, NULL, false/*not a cache transition*/);\n    mutex_lock(&thread_initexit_lock);\n    /* to ensure no deletion queue checks happen in the middle of our update */\n    mutex_lock(&shared_cache_flush_lock);\n    mutex_lock(&shared_delete_lock);\n    mutex_lock(&lazy_delete_lock);\n    if (todelete->move_pending) {\n        /* it's possible for remove_from_lazy_deletion_list to drop the count */\n#ifdef X86\n        DODEBUG({\n            fragment_t *f; /* Raise SIGILL if a deleted fragment gets executed again */\n            for (f = todelete->lazy_delete_list; f != NULL; f = f->next_vmarea) {\n                *(ushort *) f->start_pc = RAW_OPCODE_SIGILL;\n            }\n        });\n#endif\n        DODEBUG({\n            if (todelete->lazy_delete_count <=\n                DYNAMO_OPTION(lazy_deletion_max_pending)) {\n                SYSLOG_INTERNAL_WARNING_ONCE(\"lazy_delete_count dropped below \"\n                                             \"threshold before move to pending\");\n            }\n        });\n        LOG(THREAD, LOG_VMAREAS, 3, \"moving lazy list to a pending deletion entry\\n\");\n        STATS_INC(num_lazy_del_to_pending);\n        STATS_ADD(num_lazy_del_frags_to_pending, todelete->lazy_delete_count);\n        /* ensure all threads in ref count will actually check the queue */\n        increment_global_flushtime();\n        add_to_pending_list(dcontext, todelete->lazy_delete_list,\n                            /* we do count this thread, as we aren't checking the\n                             * pending list here or inc-ing our flushtime\n                             */\n                            get_num_threads(), flushtime_global\n                            _IF_DEBUG(NULL) _IF_DEBUG(NULL));\n        todelete->lazy_delete_list = NULL;\n        todelete->lazy_delete_tail = NULL;\n        todelete->lazy_delete_count = 0;\n        todelete->move_pending = false;\n    } else /* should not happen */\n        ASSERT(false && \"race in move_lazy_list_to_pending_delete\");\n    DODEBUG({ check_lazy_deletion_list_consistency(); });\n    mutex_unlock(&lazy_delete_lock);\n    mutex_unlock(&shared_delete_lock);\n    mutex_unlock(&shared_cache_flush_lock);\n    mutex_unlock(&thread_initexit_lock);\n    enter_couldbelinking(dcontext, NULL, false/*not a cache transition*/);\n}\n\n/* adds the list of fragments beginning with f and chained by {next,prev}_vmarea\n * to a new pending-lazy-deletion entry.\n * This routine may become nolinking, meaning that fragments may be freed\n * before this routine returns, so the caller should invalidate all pointers.\n * It also means that no locks may be held by the caller!\n */\nvoid\nadd_to_lazy_deletion_list(dcontext_t *dcontext, fragment_t *f)\n{\n    /* rather than allocate memory for a pending operation to save memory,\n     * we re-use f->incoming_stubs's slot (via a union), which is no longer needed\n     * (caller should have already called incoming_remove_fragment()), to store our\n     * timestamp, and next_vmarea to chain.\n     */\n    fragment_t *tail, *prev = NULL;\n    uint flushtime;\n    bool perform_move = false;\n    ASSERT_OWN_NO_LOCKS();\n    ASSERT(is_self_couldbelinking());\n    mutex_lock(&shared_cache_flush_lock); /* for consistent flushtime */\n    mutex_lock(&lazy_delete_lock);\n    /* We need a flushtime as we are compared to shared deletion pending\n     * entries, but we don't need to inc flushtime_global.  We need a value\n     * larger than any thread has already signed off on, and thus larger than\n     * the current flushtime_global.  We hold shared_cache_flush_lock to ensure\n     * our flushtime retains that property until the lazy list is updated.\n     *\n     * (Optimization to allow lazy adds to proceed concurrently with deletion\n     * list checks: don't grab the shared_cache_flush_lock.  Since we're\n     * couldbelinking, the flusher won't inc flushtime until we're done here,\n     * and the lazy lock prevents other lazy adders from incing flushtime global\n     * for a shift to pending deletion list (in code below).  Then non-flusher\n     * must hold lazy lock in general to inc flushtime.).\n     */\n    ASSERT(flushtime_global < UINT_MAX);\n    /* currently we reset if flushtime hits a threshold -- in which case we\n     * may never reach this flushtime, but the reset if we hit threshold again,\n     * moving lazy entries to pending delete (below), and -reset_every_nth_pending\n     * combined should ensure we delete these fragments\n     */\n    flushtime = flushtime_global + 1;\n    /* we support adding a string of fragments at once\n     * FIXME: if a string is common, move to a data structure w/ a\n     * single timestamp for a group of fragments -- though lazy_deletion_max_pending\n     * sort of does that for us.\n     */\n    /* must append to keep the list reverse-sorted by flushtime */\n    if (todelete->lazy_delete_list == NULL) {\n        ASSERT(todelete->lazy_delete_tail == NULL);\n        todelete->lazy_delete_list = f;\n    } else {\n        ASSERT(todelete->lazy_delete_tail->next_vmarea == NULL);\n        todelete->lazy_delete_tail->next_vmarea = f;\n    }\n    for (tail = f; tail != NULL; prev = tail, tail = tail->next_vmarea) {\n        ASSERT(tail->also.also_vmarea == NULL);\n        ASSERT(TEST(FRAG_SHARED, tail->flags));\n        tail->also.flushtime = flushtime;\n        todelete->lazy_delete_count++;\n    }\n    todelete->lazy_delete_tail = prev;\n    ASSERT(todelete->lazy_delete_tail != NULL);\n    LOG(THREAD, LOG_VMAREAS, 3, \"adding F%d to lazy deletion list @ timestamp %u\\n\",\n        f->id, flushtime);\n    STATS_INC(num_lazy_deletion_appends);\n    DOLOG(5, LOG_VMAREAS, {\n        print_lazy_deletion_list(dcontext,\n                                 \"Lazy deletion list after adding deleted fragment:\\n\");\n    });\n    DODEBUG({ check_lazy_deletion_list_consistency(); });\n    /* case 9115: ensure only one thread calls move_lazy_list_to_pending_delete,\n     * to reduce thread_initexit_lock contention and subsequent synch_with_all_threads\n     * performance issues\n     */\n    if (!todelete->move_pending &&\n        todelete->lazy_delete_count > DYNAMO_OPTION(lazy_deletion_max_pending)) {\n        perform_move = true;\n        todelete->move_pending = true;\n    }\n    mutex_unlock(&lazy_delete_lock);\n    mutex_unlock(&shared_cache_flush_lock);\n    if (perform_move) {\n        /* hit threshold -- move to real pending deletion entry */\n        /* had to release lazy_delete_lock and re-grab for proper rank order */\n        move_lazy_list_to_pending_delete(dcontext);\n    }\n}\n\n/* frees all fragments on the lazy list with flushtimes less than flushtime\n */\nstatic void\ncheck_lazy_deletion_list(dcontext_t *dcontext, uint flushtime)\n{\n    fragment_t *f, *next_f;\n    mutex_lock(&lazy_delete_lock);\n    LOG(THREAD, LOG_VMAREAS, 3,\n        \"checking lazy list @ timestamp %u\\n\", flushtime);\n    for (f = todelete->lazy_delete_list; f != NULL; f = next_f) {\n        next_f = f->next_vmarea; /* may be freed so cache now */\n        LOG(THREAD, LOG_VMAREAS, 4,\n            \"\\tf->id %u vs %u\\n\", f->id, f->also.flushtime, flushtime);\n        if (f->also.flushtime <= flushtime) {\n            /* it is safe to free! */\n            LOG(THREAD, LOG_VMAREAS, 3,\n                \"freeing F%d on lazy deletion list @ timestamp %u\\n\",\n                f->id, flushtime);\n            DOSTATS({\n                if (dcontext == GLOBAL_DCONTEXT) /* at exit */\n                    STATS_INC(num_lazy_deletion_frees_atexit);\n                else\n                    STATS_INC(num_lazy_deletion_frees);\n            });\n            /* FIXME: separate stats for frees at exit time */\n            ASSERT(TEST(FRAG_SHARED, f->flags));\n            /* we assume we're freeing the entire head of the list */\n            todelete->lazy_delete_count--;\n            todelete->lazy_delete_list = next_f;\n            if (f == todelete->lazy_delete_tail) {\n                ASSERT(todelete->lazy_delete_list == NULL);\n                todelete->lazy_delete_tail = NULL;\n            }\n#ifdef X86\n            DODEBUG({ /* Raise SIGILL if a deleted fragment gets executed again */\n                *(ushort *) f->start_pc = RAW_OPCODE_SIGILL;\n            });\n#endif\n            fragment_delete(dcontext, f,\n                            FRAGDEL_NO_OUTPUT | FRAGDEL_NO_UNLINK |\n                            FRAGDEL_NO_HTABLE | FRAGDEL_NO_VMAREA);\n        } else {\n            /* the lazy list is appended to and thus reverse-sorted, so\n             * we can stop now as the oldest items are at the front\n             */\n            break;\n        }\n    }\n    DOLOG(5, LOG_VMAREAS, {\n        print_lazy_deletion_list(dcontext,\n                                 \"Lazy deletion list after freeing fragments:\\n\");\n    });\n    DODEBUG({ check_lazy_deletion_list_consistency(); });\n    mutex_unlock(&lazy_delete_lock);\n}\n\n/* Prepares a list of shared fragments for deletion..\n * Caller should have already called vm_area_remove_fragment() on\n * each and chained them together via next_vmarea.\n * Caller must hold the shared_cache_flush_lock.\n * Returns the number of fragments unlinked\n */\nint\nunlink_fragments_for_deletion(dcontext_t *dcontext, fragment_t *list,\n                              int pending_delete_threads)\n{\n    fragment_t *f, *next;\n    uint num = 0;\n    /* only applies to lists of shared fragments -- we check the head now */\n    ASSERT(TEST(FRAG_SHARED, list->flags));\n    /* for shared_deletion we have to protect this whole walk w/ a lock so\n     * that the flushtime_global value remains higher than any thread's\n     * flushtime.\n     */\n    ASSERT_OWN_MUTEX(DYNAMO_OPTION(shared_deletion), &shared_cache_flush_lock);\n\n    acquire_recursive_lock(&change_linking_lock);\n    for (f = list; f != NULL; f = next) {\n        ASSERT(!FRAG_MULTI(f));\n        next = f->next_vmarea;\n        if (SHARED_IB_TARGETS()) {\n            /* Invalidate shared targets from all threads' ibl tables\n             * (if private) or from shared ibl tables.  Right now this\n             * routine is only called mid-flush so it's safe to do\n             * this here.\n             */\n            flush_invalidate_ibl_shared_target(dcontext, f);\n        }\n        fragment_unlink_for_deletion(dcontext, f);\n        num++;\n    }\n    release_recursive_lock(&change_linking_lock);\n\n    mutex_lock(&shared_delete_lock);\n    /* add area's fragments as a new entry in the pending deletion list */\n    add_to_pending_list(dcontext, list,\n                        pending_delete_threads, flushtime_global\n                        _IF_DEBUG(NULL) _IF_DEBUG(NULL));\n    mutex_unlock(&shared_delete_lock);\n    STATS_ADD(list_entries_unlinked_for_deletion, num);\n    return num;\n}\n\n/* returns the number of fragments unlinked */\nint\nvm_area_unlink_fragments(dcontext_t *dcontext, app_pc start, app_pc end,\n                         int pending_delete_threads\n                         _IF_DGCDIAG(app_pc written_pc))\n{\n    /* dcontext is for another thread, so don't use THREAD to log.  Cache the\n     * logfile instead of repeatedly calling THREAD_GET.\n     */\n    LOG_DECLARE(file_t thread_log = get_thread_private_logfile();)\n    thread_data_t *data = GET_DATA(dcontext, 0);\n    fragment_t *entry, *next;\n    int num = 0, i;\n    if (data == shared_data) {\n        /* we also need to add to the deletion list */\n        mutex_lock(&shared_delete_lock);\n\n        acquire_recursive_lock(&change_linking_lock);\n\n        /* we do not need the bb building lock, only the vm lock and\n         * the fragment hashtable write lock, which is grabbed by fragment_remove\n         */\n        SHARED_VECTOR_RWLOCK(&data->areas, write, lock);\n\n        /* clear shared last_area now, don't want a new bb in flushed area\n         * thought to be ok b/c of a last_area hit\n         */\n        shared_data->last_area = NULL;\n\n        /* for shared_deletion we have to protect this whole walk w/ a lock so\n         * that the flushtime_global value remains higher than any thread's\n         * flushtime.\n         */\n        ASSERT_OWN_MUTEX(DYNAMO_OPTION(shared_deletion), &shared_cache_flush_lock);\n    }\n\n    LOG(thread_log, LOG_FRAGMENT|LOG_VMAREAS, 2,\n        \"vm_area_unlink_fragments \"PFX\"..\"PFX\"\\n\", start, end);\n\n    /* walk backwards to avoid O(n^2)\n     * FIXME case 9819: could use executable_area_overlap_bounds() to avoid linear walk\n     */\n    for (i = data->areas.length - 1; i >= 0; i--) {\n        /* look for overlap */\n        if (start < data->areas.buf[i].end && end > data->areas.buf[i].start) {\n            LOG(thread_log, LOG_FRAGMENT|LOG_VMAREAS, 2,\n                \"\\tmarking region \"PFX\"..\"PFX\" for deletion & unlinking all its frags\\n\",\n                data->areas.buf[i].start, data->areas.buf[i].end);\n            data->areas.buf[i].vm_flags |= VM_DELETE_ME;\n            if (data->areas.buf[i].start < start ||\n                data->areas.buf[i].end > end) {\n                /* FIXME: best to only delete within asked-for flush area\n                 * however, checking every fragment's bounds is way too expensive\n                 * (surprisingly).  we've gone through several different schemes,\n                 * including keeping a min_page and max_page in fragment_t, or\n                 * various multi-page flags, to make checking every fragment faster,\n                 * but keeping vm area lists is the most efficient.\n                 * HOWEVER, deleting outside the flush bounds can cause problems\n                 * if the caller holds fragment_t pointers and expects them not\n                 * to be flushed (e.g., a faulting write on a read-only code region).\n                 */\n                LOG(thread_log, LOG_FRAGMENT|LOG_VMAREAS, 2,\n                    \"\\tWARNING: region \"PFX\"..\"PFX\" is larger than \"\n                    \"flush area \"PFX\"..\"PFX\"\\n\",\n                    data->areas.buf[i].start, data->areas.buf[i].end,\n                    start, end);\n            }\n            /* i#942: We can't flush a fragment list with multiple also entries\n             * from the same fragment on it, or our iteration gets derailed.\n             */\n            DOCHECK(CHKLVL_DEFAULT, {\n                vm_area_check_clean_fraglist(&data->areas.buf[i]);\n            });\n            ASSERT(!TEST(FRAG_COARSE_GRAIN, data->areas.buf[i].frag_flags));\n            for (entry = data->areas.buf[i].custom.frags; entry != NULL; entry = next) {\n                fragment_t *f = FRAG_FRAG(entry);\n                next = FRAG_NEXT(entry);\n                ASSERT(f != next &&\n                       \"i#942: changing f's fraglist derails iteration\");\n                /* case 9381: this shouldn't happen but we handle it to avoid crash */\n                if (FRAG_MULTI_INIT(entry)) {\n                    ASSERT(false && \"stale multi-init entry on frags list\");\n                    /* stale init entry, just remove it */\n                    vm_area_remove_fragment(dcontext, entry);\n                    continue;\n                }\n                /* case 9118: call fragment_unlink_for_deletion() even if fragment\n                 * is already unlinked\n                 */\n                if (!TEST(FRAG_WAS_DELETED, f->flags) || data == shared_data) {\n                    LOG(thread_log, LOG_FRAGMENT|LOG_VMAREAS, 5,\n                        \"\\tunlinking \"PFX\"%s F%d(\"PFX\")\\n\",\n                        entry, FRAG_MULTI(entry) ? \" multi\": \"\", FRAG_ID(entry),\n                        FRAG_PC(entry));\n                    /* need to remove also entries from other vm lists\n                     * thread-private doesn't have to do this b/c only unlinking,\n                     * so ok if encounter an also in same flush, except we\n                     * now do incoming_remove_fragment() for thread-private for\n                     * use of fragment_t.incoming_stubs as a union.  so we\n                     * do this for all fragments.\n                     */\n                    if (FRAG_ALSO(entry) != NULL || FRAG_MULTI(entry)) {\n                        if (FRAG_MULTI(entry)) {\n                            vm_area_remove_fragment(dcontext, f);\n                            /* move to this area's frags list so will get\n                             * transferred to deletion list if shared, or\n                             * freed from this marked-vmarea if private\n                             */\n                            prepend_entry_to_fraglist(&data->areas.buf[i], f);\n                        } else {\n                            /* entry is the fragment, remove all its alsos */\n                            vm_area_remove_fragment(dcontext, FRAG_ALSO(entry));\n                        }\n                        FRAG_ALSO_ASSIGN(f, NULL);\n                    }\n                    if (data == shared_data && SHARED_IB_TARGETS()) {\n                        /* Invalidate shared targets from all threads' ibl\n                         * tables (if private) or from shared ibl tables\n                         */\n                        flush_invalidate_ibl_shared_target(dcontext, f);\n                    }\n                    fragment_unlink_for_deletion(dcontext, f);\n#ifdef DGC_DIAGNOSTICS\n                    /* try to find out exactly which fragment contained written_pc */\n                    if (written_pc != NULL) {\n                        app_pc bb;\n                        DOLOG(2, LOG_VMAREAS, {\n                            LOG(thread_log, LOG_VMAREAS, 1, \"Flushing F%d \"PFX\":\\n\",\n                                FRAG_ID(entry), FRAG_PC(entry));\n                            disassemble_fragment(dcontext, entry, false);\n                            LOG(thread_log, LOG_VMAREAS, 1, \"First app bb for frag:\\n\");\n                            disassemble_app_bb(dcontext, FRAG_PC(entry), thread_log);\n                        });\n                        if (fragment_overlaps(dcontext, entry, written_pc,\n                                              written_pc+1, false, NULL, &bb)) {\n                            LOG(thread_log, LOG_VMAREAS, 1,\n                                \"Write target is actually inside app bb @\"PFX\":\\n\",\n                                written_pc);\n                            disassemble_app_bb(dcontext, bb, thread_log);\n                        }\n                    }\n#endif\n                    num++;\n                } else {\n                    LOG(thread_log, LOG_FRAGMENT|LOG_VMAREAS, 5,\n                        \"\\tnot unlinking \"PFX\"%s F%d(\"PFX\") (already unlinked)\\n\",\n                        entry, FRAG_MULTI(entry) ? \" multi\": \"\", FRAG_ID(entry),\n                        FRAG_PC(entry));\n                }\n                /* let recreate_fragment_ilist() know that this fragment\n                 * is pending deletion and might no longer match the app's\n                 * state. note that if we called fragment_unlink_for_deletion()\n                 * then we already set this flag above. */\n                f->flags |= FRAG_WAS_DELETED;\n            }\n            DOLOG(6, LOG_VMAREAS, {\n                print_fraglist(dcontext, &data->areas.buf[i], \"Fragments after unlinking\\n\");\n            });\n            if (data == shared_data) {\n                if (data->areas.buf[i].custom.frags != NULL) {\n                    /* add area's fragments as a new entry in the pending deletion list */\n                    add_to_pending_list(dcontext, data->areas.buf[i].custom.frags,\n                                        pending_delete_threads, flushtime_global\n                                        _IF_DEBUG(data->areas.buf[i].start)\n                                        _IF_DEBUG(data->areas.buf[i].end));\n                    /* frags are moved over completely */\n                    data->areas.buf[i].custom.frags = NULL;\n                    STATS_INC(num_shared_flush_regions);\n                }\n\n                /* ASSUMPTION: remove_vm_area, given exact bounds, simply shifts later\n                 * areas down in vector!\n                 */\n                LOG(thread_log, LOG_VMAREAS, 3, \"Before removing vm area:\\n\");\n                DOLOG(3, LOG_VMAREAS, { print_vm_areas(&data->areas, thread_log); });\n                LOG(thread_log, LOG_VMAREAS, 2, \"Removing shared vm area \"PFX\"-\"PFX\"\\n\",\n                    data->areas.buf[i].start, data->areas.buf[i].end);\n                remove_vm_area(&data->areas, data->areas.buf[i].start,\n                               data->areas.buf[i].end, false);\n                LOG(thread_log, LOG_VMAREAS, 3, \"After removing vm area:\\n\");\n                DOLOG(3, LOG_VMAREAS, { print_vm_areas(&data->areas, thread_log); });\n            }\n        }\n    }\n\n    if (data == shared_data) {\n        SHARED_VECTOR_RWLOCK(&data->areas, write, unlock);\n        release_recursive_lock(&change_linking_lock);\n        mutex_unlock(&shared_delete_lock);\n    }\n\n    LOG(thread_log, LOG_FRAGMENT|LOG_VMAREAS, 2, \"  Unlinked %d frags\\n\", num);\n    return num;\n}\n\n/* removes incoming links for all private fragments in the dcontext\n * thread that contain 'pc'\n */\nvoid\nvm_area_unlink_incoming(dcontext_t *dcontext, app_pc pc)\n{\n    int i;\n    thread_data_t *data;\n\n    ASSERT(dcontext != GLOBAL_DCONTEXT);\n    data = GET_DATA(dcontext, 0);\n\n    for (i = data->areas.length - 1; i >= 0; i--) {\n        if (pc >= data->areas.buf[i].start &&\n            pc <  data->areas.buf[i].end) {\n\n            fragment_t *entry;\n            for (entry = data->areas.buf[i].custom.frags;\n                 entry != NULL; entry = FRAG_NEXT(entry)) {\n                fragment_t *f = FRAG_FRAG(entry);\n                ASSERT(!TEST(FRAG_SHARED, f->flags));\n\n                /* Note that we aren't unlinking or ibl-invalidating\n                 * (i.e., making unreachable) any fragments in other\n                 * threads containing pc.\n                 */\n                if ((f->flags & FRAG_LINKED_INCOMING) != 0)\n                    unlink_fragment_incoming(dcontext, f);\n                fragment_remove_from_ibt_tables(dcontext, f, false);\n            }\n        }\n    }\n}\n\n/* Decrements ref counts for thread-shared pending-deletion fragments,\n * and deletes those whose count has reached 0.\n * If dcontext==GLOBAL_DCONTEXT, does NOT check the ref counts and assumes it's\n * safe to free EVERYTHING.\n * Returns false iff was_I_flushed has been flushed (not necessarily\n * fully freed yet though, but may be at any time after this call\n * returns, so caller should drop its ref to it).\n */\nbool\nvm_area_check_shared_pending(dcontext_t *dcontext, fragment_t *was_I_flushed)\n{\n    pending_delete_t *pend;\n    pending_delete_t *pend_prev = NULL;\n    pending_delete_t *pend_nxt;\n    /* a local list used to arrange in reverse order of flushtime */\n    pending_delete_t *tofree = NULL;\n    fragment_t *entry, *next;\n    int num = 0;\n    DEBUG_DECLARE(int i = 0;)\n    bool not_flushed = true;\n    ASSERT(DYNAMO_OPTION(shared_deletion) || dynamo_exited);\n    /* must pass in real dcontext, unless exiting or resetting */\n    ASSERT(dcontext != GLOBAL_DCONTEXT || dynamo_exited || dynamo_resetting);\n\n    LOG(THREAD, LOG_FRAGMENT|LOG_VMAREAS, 2,\n        \"thread \"TIDFMT\" (flushtime %d) walking pending deletion list (was_I_flushed==F%d)\\n\",\n        get_thread_id(), dcontext == GLOBAL_DCONTEXT ? flushtime_global :\n        get_flushtime_last_update(dcontext),\n        (was_I_flushed==NULL) ? -1 : was_I_flushed->id);\n    STATS_INC(num_shared_flush_walks);\n\n    /* synch w/ anyone incrementing flushtime_global and using its\n     * value when adding to the shared deletion list (currently flushers\n     * and lazy list transfers).\n     */\n    mutex_lock(&shared_cache_flush_lock);\n\n    /* check if was_I_flushed has been flushed, prior to dec ref count and\n     * allowing anyone to be fully freed\n     */\n    if (was_I_flushed != NULL &&\n        TESTALL(FRAG_SHARED|FRAG_WAS_DELETED, was_I_flushed->flags)) {\n        not_flushed = false;\n        if (was_I_flushed == dcontext->last_fragment)\n            last_exit_deleted(dcontext);\n    }\n    /* we can hit check points before we re-enter the cache, so we cannot\n     * rely on the enter_couldbelinking of exiting the cache for invalidating\n     * last_fragment -- we must check here as well (case 7453) (and case 7666,\n     * where a non-null was_I_flushed prevented this check from executing).\n     */\n    if (dcontext != GLOBAL_DCONTEXT && dcontext->last_fragment != NULL &&\n        TESTALL(FRAG_SHARED|FRAG_WAS_DELETED, dcontext->last_fragment->flags)) {\n        last_exit_deleted(dcontext);\n    }\n\n    mutex_lock(&shared_delete_lock);\n    for (pend = todelete->shared_delete; pend != NULL; pend = pend_nxt) {\n        bool delete_area = false;\n        pend_nxt = pend->next;\n        LOG(THREAD, LOG_FRAGMENT|LOG_VMAREAS, 2,\n            \"  Considering #%d: \"PFX\"..\"PFX\" flushtime %d\\n\",\n            i, pend->start, pend->end, pend->flushtime_deleted);\n        if (dcontext == GLOBAL_DCONTEXT) {\n            /* indication that it's safe to free everything */\n            delete_area = true;\n            if (dynamo_exited)\n                STATS_INC(num_shared_flush_atexit);\n            else\n                STATS_INC(num_shared_flush_atreset);\n        } else if (get_flushtime_last_update(dcontext) < pend->flushtime_deleted) {\n            ASSERT(pend->ref_count > 0);\n            pend->ref_count--;\n            STATS_INC(num_shared_flush_refdec);\n            LOG(THREAD, LOG_FRAGMENT|LOG_VMAREAS, 2,\n                \"\\tdec => ref_count is now %d, flushtime diff is %d\\n\",\n                pend->ref_count, flushtime_global - pend->flushtime_deleted);\n            delete_area = (pend->ref_count == 0);\n            DODEBUG({\n                if (INTERNAL_OPTION(detect_dangling_fcache) && delete_area) {\n                    /* don't actually free fragments until exit so we can catch any\n                     * lingering links or ibt entries\n                     */\n                    delete_area = false;\n                    for (entry = pend->frags; entry != NULL; entry = FRAG_NEXT(entry)) {\n                        /* we do have to notify caller of flushing held ptrs */\n                        if (FRAG_FRAG(entry) == was_I_flushed)\n                            ASSERT(!not_flushed); /* should have been caught up top */\n                        /* catch any links or ibt entries allowing access to deleted\n                         * fragments by filling w/ int3 instead of reusing the cache\n                         * space.  this will show up as a pc translation assert,\n                         * typically.\n                         */\n                        /* should only get fragment_t here */\n                        ASSERT(!FRAG_MULTI(entry));\n                        LOG(THREAD, LOG_FRAGMENT|LOG_VMAREAS, 4,\n                            \"\\tfilling F%d \"PFX\"-\"PFX\" with 0x%x\\n\",\n                            entry->id, entry->start_pc, entry->start_pc+entry->size,\n                            DEBUGGER_INTERRUPT_BYTE);\n                        memset(entry->start_pc, DEBUGGER_INTERRUPT_BYTE, entry->size);\n                    }\n                }\n            });\n            DOSTATS({\n                if (delete_area)\n                    STATS_INC(num_shared_flush_refzero);\n            });\n        } else {\n            /* optimization: since we always pre-pend, can skip all the rest, as\n             * they are guaranteed to have been ok-ed by us already\n             */\n            LOG(THREAD, LOG_FRAGMENT|LOG_VMAREAS, 2,\n                \"\\t(aborting now since rest have already been ok-ed)\\n\");\n            break;\n        }\n\n        if (delete_area) {\n            /* we want to delete in increasing order of flushtime so that\n             * fcache unit flushing will not occur before all lazily deleted\n             * fragments in a unit are freed\n             */\n            if (pend_prev == NULL)\n                todelete->shared_delete = pend->next;\n            else\n                pend_prev->next = pend->next;\n            if (pend == todelete->shared_delete_tail) {\n                ASSERT(pend->next == NULL);\n                todelete->shared_delete_tail = pend_prev;\n            }\n            pend->next = tofree;\n            tofree = pend;\n        } else\n            pend_prev = pend;\n        DODEBUG({ i++; });\n    }\n\n    for (pend = tofree; pend != NULL; pend = pend_nxt) {\n        pend_nxt = pend->next;\n\n        /* we now know that any objects unlinked at or before this entry's\n         * timestamp are safe to be freed (although not all earlier objects have\n         * yet been freed, so containers cannot necessarily be freed: case 8242).\n         * free these before this entry's fragments as they are older\n         * (fcache unit flushing relies on this order).\n         */\n        check_lazy_deletion_list(dcontext, pend->flushtime_deleted);\n\n        STATS_TRACK_MAX(num_shared_flush_maxdiff,\n                        flushtime_global - pend->flushtime_deleted);\n        DOSTATS({\n            /* metric: # times flushtime diff is > #threads */\n            if (flushtime_global - pend->flushtime_deleted > (uint) get_num_threads())\n                STATS_INC(num_shared_flush_diffthreads);\n        });\n        LOG(THREAD, LOG_FRAGMENT|LOG_VMAREAS, 2,\n            \"\\tdeleting all fragments in region \"PFX\"..\"PFX\" flushtime %u\\n\",\n            pend->start, pend->end, pend->flushtime_deleted);\n        ASSERT(pend->frags != NULL);\n        for (entry = pend->frags; entry != NULL; entry = next) {\n            next = FRAG_NEXT(entry);\n            LOG(THREAD, LOG_FRAGMENT|LOG_VMAREAS, 5,\n                \"\\tremoving \"PFX\"%s F%d(\"PFX\")\\n\",\n                entry, FRAG_MULTI(entry) ? \" multi\": \"\", FRAG_ID(entry), FRAG_PC(entry));\n            if (FRAG_FRAG(entry) == was_I_flushed)\n                ASSERT(!not_flushed); /* should have been caught up top */\n            /* vm_area_unlink_fragments should have removed all multis/alsos */\n            ASSERT(!FRAG_MULTI(entry));\n            /* FRAG_ALSO is used by lazy list so it may not be NULL */\n            ASSERT(TEST(FRAG_WAS_DELETED, FRAG_FRAG(entry)->flags));\n            /* do NOT call vm_area_remove_fragment, as it will freak out trying\n             * to look up the area this fragment is in\n             */\n            fragment_delete(dcontext, FRAG_FRAG(entry),\n                            FRAGDEL_NO_OUTPUT | FRAGDEL_NO_UNLINK |\n                            FRAGDEL_NO_HTABLE | FRAGDEL_NO_VMAREA);\n            STATS_INC(num_fragments_deleted_consistency);\n            num++;\n        }\n\n        ASSERT(todelete->shared_delete_count > 0);\n        todelete->shared_delete_count--;\n        HEAP_TYPE_FREE(GLOBAL_DCONTEXT, pend, pending_delete_t,\n                       ACCT_VMAREAS, PROTECTED);\n    }\n\n    if (tofree != NULL) { /* if we freed something (careful: tofree is dangling) */\n        /* case 8242: due to -syscalls_synch_flush, a later entry can\n         * reach refcount 0 before an earlier entry, so we cannot free\n         * units until all earlier entries have been freed.\n         */\n        if (todelete->shared_delete_tail == NULL)\n            fcache_free_pending_units(dcontext, flushtime_global);\n        else {\n            fcache_free_pending_units(dcontext,\n                                      todelete->shared_delete_tail->flushtime_deleted\n                                      - 1);\n        }\n    }\n\n    if (dcontext == GLOBAL_DCONTEXT) { /* need to free everything */\n        check_lazy_deletion_list(dcontext, flushtime_global+1);\n        fcache_free_pending_units(dcontext, flushtime_global+1);\n        /* reset_every_nth_pending relies on this */\n        ASSERT(todelete->shared_delete_count == 0);\n    }\n    mutex_unlock(&shared_delete_lock);\n    STATS_TRACK_MAX(num_shared_flush_maxpending, i);\n\n    /* last_area cleared in vm_area_unlink_fragments */\n    LOG(THREAD, LOG_FRAGMENT|LOG_VMAREAS, 2,\n        \"thread \"TIDFMT\" done walking pending list @flushtime %d\\n\",\n        get_thread_id(), flushtime_global);\n    if (dcontext != GLOBAL_DCONTEXT) {\n        /* update thread timestamp */\n        set_flushtime_last_update(dcontext, flushtime_global);\n    }\n    mutex_unlock(&shared_cache_flush_lock);\n\n    LOG(THREAD, LOG_FRAGMENT|LOG_VMAREAS, 2, \"  Flushed %d frags\\n\", num);\n    return not_flushed;\n}\n\n/* Deletes all pending-delete thread-private vm areas belonging to dcontext.\n * Returns false iff was_I_flushed ends up being deleted.\n */\nbool\nvm_area_flush_fragments(dcontext_t *dcontext, fragment_t *was_I_flushed)\n{\n    thread_data_t *data = GET_DATA(dcontext, 0);\n    vm_area_vector_t *v = &data->areas;\n    fragment_t *entry, *next;\n    int i, num = 0;\n    bool not_flushed = true;\n    /* should call vm_area_check_shared_pending for shared flushing */\n    ASSERT(data != shared_data);\n\n    LOG(THREAD, LOG_FRAGMENT|LOG_VMAREAS, 2, \"vm_area_flush_fragments\\n\");\n    /* walk backwards to avoid O(n^2) */\n    for (i = v->length - 1; i >= 0; i--) {\n        LOG(THREAD, LOG_FRAGMENT|LOG_VMAREAS, 2,\n            \"  Considering %d == \"PFX\"..\"PFX\"\\n\", i,\n            v->buf[i].start, v->buf[i].end);\n        if (TEST(VM_DELETE_ME, v->buf[i].vm_flags)) {\n            LOG(THREAD, LOG_FRAGMENT|LOG_VMAREAS, 2,\n                \"\\tdeleting all fragments in region \"PFX\"..\"PFX\"\\n\",\n                v->buf[i].start, v->buf[i].end);\n            for (entry = v->buf[i].custom.frags; entry != NULL; entry = next) {\n                next = FRAG_NEXT(entry);\n                LOG(THREAD, LOG_FRAGMENT|LOG_VMAREAS, 5,\n                    \"\\tremoving \"PFX\"%s F%d(\"PFX\")\\n\",\n                    entry, FRAG_MULTI(entry) ? \" multi\": \"\", FRAG_ID(entry), FRAG_PC(entry));\n                if (FRAG_FRAG(entry) == was_I_flushed) {\n                    not_flushed = false;\n                    if (was_I_flushed == dcontext->last_fragment)\n                        last_exit_deleted(dcontext);\n                }\n                ASSERT(TEST(FRAG_WAS_DELETED, FRAG_FRAG(entry)->flags));\n                ASSERT(FRAG_ALSO_DEL_OK(entry) == NULL);\n                fragment_delete(dcontext, FRAG_FRAG(entry),\n                                /* We used to leave link, vmarea, and htable removal\n                                 * until here for private fragments, but for case\n                                 * 3559 we wanted link removal at unlink time, and\n                                 * the 3 of them must go together, so we now do all 3\n                                 * at unlink time just like for shared fragments.\n                                 */\n                                FRAGDEL_NO_OUTPUT | FRAGDEL_NO_UNLINK |\n                                FRAGDEL_NO_HTABLE | FRAGDEL_NO_VMAREA);\n                STATS_INC(num_fragments_deleted_consistency);\n                num++;\n            }\n            v->buf[i].custom.frags = NULL;\n            /* could just remove flush region...but we flushed entire vm region\n             * ASSUMPTION: remove_vm_area, given exact bounds, simply shifts later\n             * areas down in vector!\n             */\n            LOG(THREAD, LOG_VMAREAS, 3, \"Before removing vm area:\\n\");\n            DOLOG(3, LOG_VMAREAS, { print_vm_areas(v, THREAD); });\n            remove_vm_area(v, v->buf[i].start, v->buf[i].end, false);\n            LOG(THREAD, LOG_VMAREAS, 3, \"After removing vm area:\\n\");\n            DOLOG(3, LOG_VMAREAS, { print_vm_areas(v, THREAD); });\n        }\n    }\n\n#ifdef WINDOWS\n    /* The relink needs a real thread dcontext, so don't pass a GLOBAL_DCONTEXT\n     * in. This can occur when flushing shared fragments. Functionally, this is\n     * fine since only private fragments are routed thru shared syscall, and\n     * flush requests for such fragments are provided with a real thread\n     * context.\n     */\n    if (DYNAMO_OPTION(shared_syscalls) && dcontext != GLOBAL_DCONTEXT &&\n        !IS_SHARED_SYSCALL_THREAD_SHARED) {\n        /* re-link shared syscall */\n        link_shared_syscall(dcontext);\n    }\n#endif\n\n    /* i#849: re-link private xfer */\n    if (dcontext != GLOBAL_DCONTEXT && special_ibl_xfer_is_thread_private())\n        link_special_ibl_xfer(dcontext);\n\n    data->last_area = NULL;\n\n    DOSTATS({\n        if (num == 0)\n            STATS_INC(num_flushq_actually_empty);\n    });\n    LOG(THREAD, LOG_FRAGMENT|LOG_VMAREAS, 2, \"  Flushed %d frags\\n\", num);\n    DOLOG(7, LOG_VMAREAS, {\n        SHARED_VECTOR_RWLOCK(&data->areas, read, lock);\n        print_fraglists(dcontext);\n        SHARED_VECTOR_RWLOCK(&data->areas, read, unlock);\n    });\n\n    return not_flushed;\n}\n\n/* Flushes all units grouped with info.\n * Caller must hold change_linking_lock, read lock hotp_get_lock(), and\n * executable_areas lock.\n */\nstatic void\nvm_area_flush_coarse_unit(dcontext_t *dcontext, coarse_info_t *info_in,\n                          vm_area_t *area, bool all_synched, bool entire)\n{\n    coarse_info_t *info = info_in, *next_info;\n    ASSERT(info != NULL);\n    ASSERT_OWN_RECURSIVE_LOCK(true, &change_linking_lock);\n#ifdef HOT_PATCHING_INTERFACE\n    ASSERT_OWN_READWRITE_LOCK(DYNAMO_OPTION(hot_patching), hotp_get_lock());\n#endif\n    ASSERT(READ_LOCK_HELD(&executable_areas->lock));\n    /* Need a real dcontext for persisting rac */\n    if (dcontext == GLOBAL_DCONTEXT)\n        dcontext = get_thread_private_dcontext();\n    if (DYNAMO_OPTION(coarse_freeze_at_unload)) {\n        /* we do not try to freeze if we've failed to suspend the world */\n        if (all_synched) {\n            /* in-place builds a separate unit anyway so no savings that way */\n            vm_area_coarse_region_freeze(dcontext, info, area, false/*!in place*/);\n            STATS_INC(persist_unload_try);\n        } else {\n            SYSLOG_INTERNAL_WARNING_ONCE(\"not freezing due to synch failure\");\n            STATS_INC(persist_unload_suspend_failure);\n        }\n    }\n    while (info != NULL) { /* loop over primary and secondary unit */\n        next_info = info->non_frozen;\n        ASSERT(info->frozen || info->non_frozen == NULL);\n        if (!entire && TEST(PERSCACHE_CODE_INVALID, info->flags)) {\n            /* Do not reset yet as it may become valid again.\n             * Assumption: if !entire, we will leave this info there.\n             */\n            /* Should only mark invalid if no or empty secondary unit */\n            ASSERT(next_info == NULL || next_info->cache == NULL);\n            break;\n        }\n        DOSTATS({\n            if (info->persisted) {\n                STATS_INC(flush_persisted_units);\n                if (os_module_get_flag(info->base_pc, MODULE_BEING_UNLOADED))\n                    STATS_INC(flush_persisted_unload);\n            }\n            STATS_INC(flush_coarse_units);\n        });\n        coarse_unit_reset_free(dcontext, info, false/*no locks*/, true/*unlink*/,\n                               true/*give up primary*/);\n        /* We only want one non-frozen unit per region; we keep the 1st unit */\n        if (info != info_in) {\n            coarse_unit_free(GLOBAL_DCONTEXT, info);\n            info = NULL;\n        } else\n            coarse_unit_mark_in_use(info); /* still in-use if re-used */\n        /* The remaining info itself is freed from exec list in remove_vm_area,\n         * though may remain if only part of this region is removed\n         * and will be lazily re-initialized if we execute from there again.\n         * FIXME: case 8640: better to remove it all here?\n         */\n        info = next_info;\n        ASSERT(info == NULL || !info->frozen);\n    }\n}\n\n/* Assumes that all threads are suspended at safe synch points.\n * Flushes fragments in the region [start, end) in the vmarea\n * list for del_dcontext.\n * If dcontext == del_dcontext == GLOBAL_DCONTEXT,\n *   removes shared fine fragments and coarse units in the region.\n * If dcontext == thread and del_dcontext == GLOBAL_DCONTEXT,\n *   removes any ibl table entries for shared fragments in the region.\n *   WARNING: this routine will not remove coarse ibl entries!\n * Else (both dcontexts are the local thread's), deletes private fragments\n *   in the region.\n * FIXME: share code w/ vm_area_unlink_fragments() and vm_area_flush_fragments()!\n * all_synched is ignored unless dcontext == GLOBAL_DCONTEXT\n */\nvoid\nvm_area_allsynch_flush_fragments(dcontext_t *dcontext, dcontext_t *del_dcontext,\n                                 app_pc start, app_pc end, bool exec_invalid,\n                                 bool all_synched)\n{\n    thread_data_t *data = GET_DATA(del_dcontext, 0);\n    vm_area_vector_t *v = &data->areas;\n    fragment_t *entry, *next;\n    int i;\n    bool remove_shared_vm_area = true;\n    DEBUG_DECLARE(int num_fine = 0;)\n    DEBUG_DECLARE(int num_coarse = 0;)\n\n    LOG(THREAD, LOG_FRAGMENT|LOG_VMAREAS, 2,\n        \"vm_area_allsynch_flush_fragments \"PFX\" \"PFX\"\\n\",\n        dcontext, del_dcontext);\n    ASSERT(OWN_MUTEX(&all_threads_synch_lock) && OWN_MUTEX(&thread_initexit_lock));\n    ASSERT(is_self_allsynch_flushing());\n\n    /* change_linking_lock is higher ranked than shared_vm_areas lock and is\n     * acquired for fragment_delete()'s unlinking as well as fcache removal to\n     * add to free list, so we must grab it up front.\n     * coarse_unit_persist and coarse_unit_freeze also require it to be held.\n     */\n    acquire_recursive_lock(&change_linking_lock);\n\n    if (dcontext == GLOBAL_DCONTEXT && del_dcontext == GLOBAL_DCONTEXT) {\n        /* We can't add persisted units to shared vector at load time due to\n         * lock rank orders, so we normally add on first access -- but we can\n         * flush before any access, so we must walk exec areas here.\n         * While we're at it we do our coarse unit freeing here, so don't have\n         * to do lookups in exec areas while walking shared vmarea vector below.\n         */\n#ifdef HOT_PATCHING_INTERFACE\n        if (DYNAMO_OPTION(hot_patching))\n            read_lock(hotp_get_lock()); /* case 9970: rank hotp < exec_areas */\n#endif\n        read_lock(&executable_areas->lock); /* no need to write */\n        for (i = 0; i < executable_areas->length; i++) {\n            if (TEST(FRAG_COARSE_GRAIN, executable_areas->buf[i].frag_flags) &&\n                start < executable_areas->buf[i].end &&\n                end > executable_areas->buf[i].start) {\n                coarse_info_t *coarse =\n                    (coarse_info_t *) executable_areas->buf[i].custom.client;\n                bool do_flush = (coarse != NULL);\n#ifdef HOT_PATCHING_INTERFACE\n                /* Case 9995: do not flush for 1-byte (mostly hotp) regions that are\n                 * still valid execution regions and that are recorded as not being\n                 * present in persistent caches.\n                 */\n                if (do_flush && !exec_invalid &&\n                    start + 1 == end && coarse->hotp_ppoint_vec != NULL) {\n                    app_pc modbase = get_module_base(coarse->base_pc);\n                    ASSERT(modbase <= start);\n                    /* Only persisted units store vec, though we could store for\n                     * frozen but not persisted if we had frequent nudges throwing\n                     * them out. */\n                    ASSERT(coarse->persisted);\n                    if (hotp_ppoint_on_list((app_rva_t)(start - modbase),\n                                            coarse->hotp_ppoint_vec,\n                                            coarse->hotp_ppoint_vec_num)) {\n                        do_flush = false;\n                        STATS_INC(perscache_hotp_flush_avoided);\n                        remove_shared_vm_area = false;\n                    }\n                }\n#endif\n                if (do_flush) {\n                    vm_area_flush_coarse_unit(dcontext, coarse,\n                                              &executable_areas->buf[i], all_synched,\n                                              start <= executable_areas->buf[i].start &&\n                                              end >= executable_areas->buf[i].end);\n                    DODEBUG({ num_coarse++; });\n                    if (TEST(VM_ADD_TO_SHARED_DATA, executable_areas->buf[i].vm_flags)) {\n                        LOG(THREAD, LOG_FRAGMENT|LOG_VMAREAS, 2,\n                            \"\\tdeleting coarse unit not yet in shared vector \"\n                            PFX\"..\"PFX\"\\n\",\n                            executable_areas->buf[i].start,\n                            executable_areas->buf[i].end);\n                        /* This flag is only relevant for persisted units, so we clear it\n                         * here since this same coarse_info_t may be re-used\n                         */\n                        executable_areas->buf[i].vm_flags &= ~VM_ADD_TO_SHARED_DATA;\n                    }\n                }\n            }\n        }\n        read_unlock(&executable_areas->lock);\n#ifdef HOT_PATCHING_INTERFACE\n        if (DYNAMO_OPTION(hot_patching))\n            read_unlock(hotp_get_lock());\n#endif\n    }\n\n    SHARED_VECTOR_RWLOCK(v, write, lock);\n    /* walk backwards to avoid O(n^2)\n     * FIXME case 9819: could use executable_area_overlap_bounds() to avoid linear walk\n     */\n    for (i = v->length - 1; i >= 0; i--) {\n        if (start < v->buf[i].end && end > v->buf[i].start) {\n            if (v->buf[i].start < start ||\n                v->buf[i].end > end) {\n                /* see comments in vm_area_unlink_fragments() */\n                LOG(THREAD, LOG_FRAGMENT|LOG_VMAREAS, 2,\n                    \"\\tWARNING: region \"PFX\"..\"PFX\" is larger than flush area\"\n                    \" \"PFX\"..\"PFX\"\\n\",\n                    v->buf[i].start, v->buf[i].end, start, end);\n            }\n            LOG(THREAD, LOG_FRAGMENT|LOG_VMAREAS, 2,\n                \"\\tdeleting all fragments in region \"PFX\"..\"PFX\"\\n\",\n                v->buf[i].start, v->buf[i].end);\n            /* We flush coarse units in executable_areas walk down below */\n            /* We can have fine fragments here as well */\n            if (v->buf[i].custom.frags != NULL) {\n                for (entry = v->buf[i].custom.frags; entry != NULL; entry = next) {\n                    next = FRAG_NEXT(entry);\n                    if (dcontext == del_dcontext) {\n                        LOG(THREAD, LOG_FRAGMENT|LOG_VMAREAS, 5,\n                            \"\\tremoving \"PFX\"%s F%d(\"PFX\")\\n\",\n                            entry, FRAG_MULTI(entry) ? \" multi\": \"\", FRAG_ID(entry),\n                            FRAG_PC(entry));\n                        if (SHARED_IBT_TABLES_ENABLED()) {\n                            /* fragment_remove() won't remove from shared ibt tables,\n                             * b/c assuming we didn't do the synch for it, so we\n                             * have to explicitly remove\n                             */\n                            fragment_remove_from_ibt_tables(dcontext, FRAG_FRAG(entry),\n                                                            true/*rm from shared*/);\n                        }\n                        fragment_delete(dcontext, FRAG_FRAG(entry), FRAGDEL_ALL);\n                        STATS_INC(num_fragments_deleted_consistency);\n                        DODEBUG({ num_fine++; });\n                    } else {\n                        ASSERT(dcontext != GLOBAL_DCONTEXT &&\n                               del_dcontext == GLOBAL_DCONTEXT);\n                        fragment_remove_from_ibt_tables(dcontext, FRAG_FRAG(entry),\n                                                        false/*shouldn't be in shared*/);\n                    }\n                }\n                if (dcontext == del_dcontext)\n                    v->buf[i].custom.frags = NULL;\n            }\n            if (dcontext == del_dcontext && remove_shared_vm_area) {\n                /* could just remove flush region...but we flushed entire vm region\n                 * ASSUMPTION: remove_vm_area, given exact bounds, simply shifts later\n                 * areas down in vector!\n                 */\n                LOG(THREAD, LOG_VMAREAS, 3, \"Before removing vm area:\\n\");\n                DOLOG(3, LOG_VMAREAS, { print_vm_areas(v, THREAD); });\n                remove_vm_area(v, v->buf[i].start, v->buf[i].end, false);\n                LOG(THREAD, LOG_VMAREAS, 3, \"After removing vm area:\\n\");\n                DOLOG(3, LOG_VMAREAS, { print_vm_areas(v, THREAD); });\n            } else {\n                ASSERT(dcontext != del_dcontext ||\n                       /* should only not flush for special hotp case 9995 */\n                       start + 1 == end);\n            }\n        }\n    }\n\n    if (dcontext == del_dcontext)\n        data->last_area = NULL;\n    SHARED_VECTOR_RWLOCK(v, write, unlock);\n    release_recursive_lock(&change_linking_lock);\n\n    LOG(THREAD, LOG_FRAGMENT|LOG_VMAREAS, 2,\n        \"  Flushed %d fine frags & %d coarse units\\n\", num_fine, num_coarse);\n    DOLOG(7, LOG_VMAREAS, {\n        SHARED_VECTOR_RWLOCK(v, read, lock);\n        print_fraglists(dcontext);\n        SHARED_VECTOR_RWLOCK(v, read, unlock);\n    });\n}\n\n/* Deletes all coarse units */\nvoid\nvm_area_coarse_units_reset_free()\n{\n    vm_area_vector_t *v = executable_areas;\n    int i;\n    ASSERT(DYNAMO_OPTION(coarse_units));\n    LOG(GLOBAL, LOG_FRAGMENT|LOG_VMAREAS, 2, \"vm_area_coarse_units_reset_free\\n\");\n    ASSERT(dynamo_exited || dynamo_resetting);\n    DOLOG(1, LOG_VMAREAS, {\n        LOG(GLOBAL, LOG_VMAREAS, 1, \"\\nexecutable_areas before reset:\\n\");\n        print_executable_areas(GLOBAL);\n    });\n    /* We would grab executable_areas_lock but coarse_unit_reset_free() grabs\n     * change_linking_lock and coarse_info_lock, both of higher rank.  We could\n     * grab change_linking_lock first here and raise executable_areas_lock above\n     * coarse_info_lock's rank, but executable_areas_lock can be acquired during\n     * coarse_unit_unlink after special_heap_lock -- so the best solution is to\n     * not grab executable_areas_lock here and rely on reset synch.\n     */\n    for (i = 0; i < v->length; i++) {\n        if (TEST(FRAG_COARSE_GRAIN, v->buf[i].frag_flags)) {\n            coarse_info_t *info_start = (coarse_info_t *) v->buf[i].custom.client;\n            coarse_info_t *info = info_start, *next_info;\n            ASSERT(info != NULL);\n            while (info != NULL) { /* loop over primary and secondary unit */\n                next_info = info->non_frozen;\n                ASSERT(info->frozen || info->non_frozen == NULL);\n                LOG(GLOBAL, LOG_FRAGMENT|LOG_VMAREAS, 2,\n                    \"\\tdeleting all fragments in region \"PFX\"..\"PFX\"\\n\",\n                    v->buf[i].start, v->buf[i].end);\n                coarse_unit_reset_free(GLOBAL_DCONTEXT, info, false/*no locks*/,\n                                       true/*unlink*/, true/*give up primary*/);\n                /* We only want one non-frozen unit per region; we keep the 1st one */\n                if (info != info_start) {\n                    coarse_unit_free(GLOBAL_DCONTEXT, info);\n                    info = NULL;\n                } else\n                    coarse_unit_mark_in_use(info); /* still in-use if re-used */\n                /* The start info itself is freed in remove_vm_area, if exiting */\n                /* XXX i#1051: should re-load persisted caches after reset */\n                info = next_info;\n                ASSERT(info == NULL || !info->frozen);\n            }\n        }\n    }\n}\n\n/* Returns true if info && info->non_frozen meet the size requirements\n * for persisting.\n */\nstatic bool\ncoarse_region_should_persist(dcontext_t *dcontext, coarse_info_t *info)\n{\n    bool cache_large_enough = false;\n    size_t cache_size = 0;\n    /* Must hold lock to get size but ok for size to change afterward;\n     * normal usage has all threads synched */\n    if (!info->persisted) {\n        mutex_lock(&info->lock);\n        cache_size += coarse_frozen_cache_size(dcontext, info);\n        mutex_unlock(&info->lock);\n    }\n    if (info->non_frozen != NULL) {\n        mutex_lock(&info->non_frozen->lock);\n        cache_size += coarse_frozen_cache_size(dcontext, info->non_frozen);\n        mutex_unlock(&info->non_frozen->lock);\n    }\n    LOG(THREAD, LOG_FRAGMENT|LOG_VMAREAS, 2,\n        \"\\tconsidering persisting coarse unit %s with cache size %d\\n\",\n        info->module, cache_size);\n    /* case 10107: check for disk space before freezing, if persisting.\n     * A crude estimate is all we need up front (we'll do a precise check at file\n     * write time): estimate that hashtables, stubs, etc. double cache size.\n     */\n    if (!coarse_unit_check_persist_space(INVALID_FILE, cache_size * 2)) {\n        LOG(THREAD, LOG_FRAGMENT|LOG_VMAREAS, 2,\n            \"\\tnot enough disk space for %s\\n\", info->module);\n        STATS_INC(coarse_units_persist_nospace);\n        return false;\n    }\n    cache_large_enough =\n        (cache_size > DYNAMO_OPTION(coarse_freeze_min_size) ||\n         (info->persisted &&\n          /* FIXME: should use append size if merging only w/ disk as well */\n          cache_size > DYNAMO_OPTION(coarse_freeze_append_size)));\n#if defined(RETURN_AFTER_CALL) || defined(RCT_IND_BRANCH)\n    /* Real cost is in pages touched while walking reloc, which is\n     * typically 80% of module.\n     */\n    if (rct_module_live_entries(dcontext, info->base_pc, RCT_RCT)\n        > DYNAMO_OPTION(coarse_freeze_rct_min)) {\n        DOSTATS({\n            if (!cache_large_enough)\n                STATS_INC(persist_code_small);\n        });\n        LOG(THREAD, LOG_FRAGMENT|LOG_VMAREAS, 2,\n            \"\\tRCT entries are over threshold so persisting %s\\n\", info->module);\n        return true;\n    }\n#endif /* defined(RETURN_AFTER_CALL) || defined(RCT_IND_BRANCH) */\n    DOSTATS({\n        if (!cache_large_enough) {\n            LOG(THREAD, LOG_FRAGMENT|LOG_VMAREAS, 2,\n                \"\\tnot persisting %s since too small\\n\", info->module);\n            STATS_INC(persist_too_small);\n        }\n    });\n    return cache_large_enough;\n}\n\n/* FIXME case 9975: we should provide separate control over persistence\n * (today we assume !in_place==persist) so we can persist and use in_place\n * rather than having to wait until next run to get the benefit.\n */\n/* FIXME: if we map in a newly persisted unit we need to set\n * VM_PERSISTED_CACHE, but we only care about it in executable_areas.\n */\n/* Caller must hold change_linking_lock, read lock hotp_get_lock(), and\n * either executable_areas lock or dynamo_all_threads_synched.\n */\nstatic void\nvm_area_coarse_region_freeze(dcontext_t *dcontext, coarse_info_t *info,\n                             vm_area_t *area, bool in_place)\n{\n    coarse_info_t *frozen_info = NULL; /* the already-frozen info */\n    coarse_info_t *unfrozen_info = NULL; /* the un-frozen info */\n    if (!DYNAMO_OPTION(coarse_enable_freeze) || RUNNING_WITHOUT_CODE_CACHE())\n        return;\n    ASSERT(!RUNNING_WITHOUT_CODE_CACHE());\n    ASSERT(info != NULL);\n    ASSERT_OWN_RECURSIVE_LOCK(true, &change_linking_lock);\n#ifdef HOT_PATCHING_INTERFACE\n    ASSERT_OWN_READWRITE_LOCK(DYNAMO_OPTION(hot_patching), hotp_get_lock());\n#endif\n    ASSERT(READ_LOCK_HELD(&executable_areas->lock) || dynamo_all_threads_synched);\n    /* Note that freezing in place will call mark_executable_area_coarse_frozen and\n     * add a new unit, so next_info should not be traversed after freezing.\n     */\n    if (info->frozen) {\n        frozen_info = info;\n        unfrozen_info = info->non_frozen;\n    } else {\n        unfrozen_info = info;\n        ASSERT(info->non_frozen == NULL);\n    }\n    if (unfrozen_info != NULL &&\n        unfrozen_info->cache != NULL /*skip empty units*/ &&\n        !TEST(PERSCACHE_CODE_INVALID, unfrozen_info->flags) &&\n         /* we only freeze a unit in presence of a frozen unit if we're merging\n          * (we don't support side-by-side frozen units) */\n        (DYNAMO_OPTION(coarse_freeze_merge) || frozen_info == NULL)) {\n        if (in_place || coarse_region_should_persist(dcontext, info)) {\n            coarse_info_t *frozen;\n            coarse_info_t *premerge;\n            LOG(THREAD, LOG_FRAGMENT|LOG_VMAREAS, 2,\n                \"\\tfreezing coarse unit for region \"PFX\"..\"PFX\" %s\\n\",\n                info->base_pc, info->end_pc, info->module);\n            if (frozen_info != NULL && in_place) {\n                /* We're freezing unfrozen_info, merging frozen_info into it, and\n                 * then deleting frozen_info, so we need to replace it with just\n                 * unfrozen_info (soon to be frozen); we do it this way since\n                 * mark_executable_area_coarse_frozen assumes being-frozen info is\n                 * the 1st info.\n                 */\n                area->custom.client = (void *) unfrozen_info;\n            }\n            frozen = coarse_unit_freeze(dcontext, unfrozen_info, in_place);\n            ASSERT(frozen != NULL && frozen->frozen);\n            /* mark_executable_area_coarse_frozen creates new non_frozen for in_place */\n            ASSERT(!in_place || frozen->non_frozen != NULL);\n            premerge = frozen;\n            if (frozen_info != NULL) {\n                ASSERT(DYNAMO_OPTION(coarse_freeze_merge));\n                /* case 9701: more efficient to merge while freezing, but\n                 * this way we share code w/ offline merger\n                 */\n                /* I would put most-likely-larger unit as first source since more\n                 * efficient to merge into, but we need frozen first in case\n                 * we are in_place.\n                 */\n                frozen = coarse_unit_merge(dcontext, frozen, frozen_info, in_place);\n                ASSERT(frozen != NULL);\n                ASSERT(!in_place || frozen->non_frozen != NULL);\n                if (frozen == NULL && in_place) {\n                    /* Shouldn't happen w/ online units; if it does we end up\n                     * tossing frozen_info w/o merging it\n                     */\n                    frozen = premerge;\n                }\n                /* for !in_place we free premerge after persisting, so clients don't\n                 * get deletion events that remove data from hashtables too early\n                 * (xref https://github.com/DynamoRIO/drmemory/issues/869)\n                 */\n                if (in_place) {\n                    coarse_unit_reset_free(dcontext, frozen_info, false/*no locks*/,\n                                           true/*need to unlink*/,\n                                           false/*keep primary*/);\n                    coarse_unit_free(dcontext, frozen_info);\n                    frozen_info = NULL;\n                }\n            }\n            if (!in_place && frozen != NULL) {\n                coarse_unit_persist(dcontext, frozen);\n                coarse_unit_reset_free(dcontext, frozen, false/*no locks*/,\n                                       false/*already unlinked*/,\n                                       false/*not in use anyway*/);\n                coarse_unit_free(dcontext, frozen);\n                frozen = NULL;\n            } else\n                ASSERT(frozen == unfrozen_info);\n            if (frozen_info != NULL && !in_place && premerge != NULL) {\n                /* see comment above: delayed until after persist */\n                coarse_unit_reset_free(dcontext, premerge, false/*no locks*/,\n                                       false/*already unlinked*/,\n                                       false/*not in use anyway*/);\n                ASSERT(frozen != premerge);\n                coarse_unit_free(dcontext, premerge);\n                premerge = NULL;\n            }\n        }\n    } else if (frozen_info != NULL && frozen_info->cache != NULL &&\n               !in_place && !frozen_info->persisted) {\n        ASSERT(!TEST(PERSCACHE_CODE_INVALID, frozen_info->flags));\n        if (coarse_region_should_persist(dcontext, frozen_info))\n            coarse_unit_persist(dcontext, frozen_info);\n    }\n}\n\n/* FIXME: could create iterator and move this and vm_area_coarse_units_reset_free()\n * into callers\n * If !in_place this routine freezes (if not already) and persists.\n */\nvoid\nvm_area_coarse_units_freeze(bool in_place)\n{\n    vm_area_vector_t *v = executable_areas;\n    int i;\n    dcontext_t *dcontext = get_thread_private_dcontext();\n    if (!DYNAMO_OPTION(coarse_units) || !DYNAMO_OPTION(coarse_enable_freeze) ||\n        RUNNING_WITHOUT_CODE_CACHE())\n        return;\n    ASSERT(!RUNNING_WITHOUT_CODE_CACHE());\n    ASSERT(dcontext != NULL);\n    LOG(THREAD, LOG_FRAGMENT|LOG_VMAREAS, 2, \"vm_area_coarse_units_freeze\\n\");\n    ASSERT(dynamo_all_threads_synched);\n    acquire_recursive_lock(&change_linking_lock);\n#ifdef HOT_PATCHING_INTERFACE\n    if (DYNAMO_OPTION(hot_patching))\n        read_lock(hotp_get_lock());\n#endif\n    /* We would grab executable_areas_lock but coarse_unit_freeze() grabs\n     * change_linking_lock and coarse_info_lock, both of higher rank.  We could\n     * grab change_linking_lock first here and raise executable_areas_lock above\n     * coarse_info_lock's rank, but executable_areas_lock can be acquired during\n     * coarse_unit_unlink after special_heap_lock -- so the best solution is to\n     * not grab executable_areas_lock here and rely on all_threads_synched.\n     * Could make executable_areas_lock recursive and grab all locks here?\n     */\n    for (i = 0; i < v->length; i++) {\n        if (TEST(FRAG_COARSE_GRAIN, v->buf[i].frag_flags)) {\n            coarse_info_t *info = (coarse_info_t *) v->buf[i].custom.client;\n            ASSERT(info != NULL);\n            if (info != NULL)\n                vm_area_coarse_region_freeze(dcontext, info, &v->buf[i], in_place);\n        }\n    }\n#ifdef HOT_PATCHING_INTERFACE\n    if (DYNAMO_OPTION(hot_patching))\n        read_unlock(hotp_get_lock());\n#endif\n    release_recursive_lock(&change_linking_lock);\n}\n\n#if 0 /* not used */\n/* remove a thread's vm area */\nstatic bool\nremove_thread_vm_area(dcontext_t *dcontext, app_pc start, app_pc end)\n{\n    thread_data_t *data = GET_DATA(dcontext, 0);\n    bool ok;\n    LOG(THREAD, LOG_VMAREAS, 2, \"removing thread \"TIDFMT\" vm area: \"PFX\"-\"PFX\"\\n\",\n        dcontext->owning_thread, start, end);\n    /* no lock needed, this is thread-private */\n    ok = remove_vm_area(&data->areas, start, end, false);\n    /* due to re-sorting, areas move around...not worth trying to shift,\n     * just clear the cache area */\n    data->last_area = NULL;\n    return ok;\n}\n#endif\n\n/* returns true if the passed in area overlaps any thread executable areas */\nbool\nthread_vm_area_overlap(dcontext_t *dcontext, app_pc start, app_pc end)\n{\n    thread_data_t *data = GET_DATA(dcontext, 0);\n    bool res;\n    if (data == shared_data) {\n        ASSERT(!self_owns_write_lock(&shared_data->areas.lock));\n        SHARED_VECTOR_RWLOCK(&data->areas, write, lock);\n    }\n    res = vm_area_overlap(&data->areas, start, end);\n    if (data == shared_data) {\n        SHARED_VECTOR_RWLOCK(&data->areas, write, unlock);\n    }\n    return res;\n}\n\n/* Returns NULL if should re-execute the faulting write\n * Else returns the target pc for a new basic block -- caller should\n * return to dispatch rather than the code cache\n * If instr_cache_pc==NULL, assumes the cache is unavailable (due to reset).\n */\napp_pc\nhandle_modified_code(dcontext_t *dcontext, cache_pc instr_cache_pc,\n                     app_pc instr_app_pc, app_pc target, fragment_t *f)\n{\n    /* FIXME: for Linux, this is all happening inside signal handler...\n     * flushing could take a while, and signals are blocked the entire time!\n     */\n    app_pc base_pc, flush_start = NULL, next_pc;\n    app_pc instr_size_pc;\n    size_t size, flush_size = 0, instr_size;\n    uint opnd_size = 0;\n    uint prot;\n    overlap_info_t info = {0,/* init to 0 so info.overlap is false */};\n    app_pc bb_start = NULL;\n    app_pc bb_end = NULL;\n    app_pc bb_pstart = NULL, bb_pend = NULL; /* pages occupied by instr's bb */\n    vm_area_t *a = NULL;\n    fragment_t wrapper;\n    /* get the \"region\" size (don't use exec list, it merges regions),\n     * the os merges regions too, and we might have changed the protections\n     * on the region and caused it do so, so below we take the intersection\n     * with the enclosing executable_areas region if it exists */\n    bool ok = get_memory_info(target, &base_pc, &size, &prot);\n    if (f == NULL && instr_cache_pc != NULL)\n        f = fragment_pclookup(dcontext, instr_cache_pc, &wrapper);\n    /* FIXME: what if seg fault is b/c target is unreadable?  then should have\n     * app die, not us trigger assertion!\n     */\n    /* In the absence of reset, f MUST still be in the cache since we're still\n     * nolinking, and pclookup will find it even if it's no longer in htables.\n     * But, a reset can result in not having the fragment available at all.  In\n     * that case we just flush the whole region and hope that in the future\n     * we'll eventually identify the writer, but there's a possibility of no\n     * forward progress if another thread keeps flushing writing fragment\n     * (ro2sandbox_threshold would alleviate that).\n     */\n    DOLOG(1, LOG_VMAREAS, {\n        if (instr_cache_pc == NULL) {\n            LOG(THREAD, LOG_VMAREAS, 1,\n                \"WARNING: cache unavailable for processing code mod @ app pc \"PFX\"\\n\",\n                instr_app_pc);\n        } else if (f == NULL) {\n            LOG(THREAD, LOG_VMAREAS, 1,\n                \"WARNING: cannot find fragment @ writer pc \"PFX\" -- was deleted, \"\n                \"or native\\n\", instr_cache_pc);\n        }\n    });\n    ASSERT(ok);\n    SYSLOG_INTERNAL_WARNING_ONCE(\"writing to executable region.\");\n    STATS_INC(num_write_faults);\n    read_lock(&executable_areas->lock);\n    lookup_addr(executable_areas, (app_pc)target, &a);\n    if (a == NULL) {\n        LOG(THREAD, LOG_VMAREAS, 1,\n            \"\\tRegion for \"PFX\" not exec, probably data on same page\\n\", target);\n        DOLOG(2, LOG_VMAREAS, { print_vm_areas(executable_areas, THREAD); });\n    } else {\n        /* The os may have merged regions  because we made a region read\n         * only! (ref case 2803), thus we should take the intersection of\n         * the region on our list and the os region */\n        /* make sure to handle sub-page regions, pad to page boundary */\n        app_pc a_pstart = (app_pc)ALIGN_BACKWARD(a->start, PAGE_SIZE);\n        app_pc a_pend = (app_pc)ALIGN_FORWARD(a->end, PAGE_SIZE);\n        if (a_pstart > base_pc) {\n            size -= a_pstart - base_pc;\n            base_pc = a_pstart;\n        }\n        if (a_pend < base_pc + size) {\n            size = a_pend - base_pc;\n        }\n        LOG(THREAD, LOG_VMAREAS, 1,\n            \"WARNING: Exec \"PFX\"-\"PFX\" %s%s written @\"PFX\" by \"PFX\" == app \"PFX\"\\n\",\n            base_pc, base_pc+size,\n            ((a->vm_flags & VM_WRITABLE) != 0) ? \"W\" : \"\",\n            ((prot & MEMPROT_EXEC) != 0) ? \"E\" : \"\",\n            target, instr_cache_pc, instr_app_pc);\n    }\n    read_unlock(&executable_areas->lock);\n#ifdef DGC_DIAGNOSTICS\n    DOLOG(1, LOG_VMAREAS, {\n        /* it's hard to locate frag owning an app pc in the cache, so we wait until\n         * we flush and only check the flushed frags\n         */\n        char buf[MAXIMUM_SYMBOL_LENGTH];\n        print_symbolic_address(instr_app_pc, buf, sizeof(buf), false);\n        LOG(THREAD, LOG_VMAREAS, 1, \"code written by app pc \"PFX\" from bb %s:\\n\",\n            instr_app_pc, buf);\n        disassemble_app_bb(dcontext, instr_app_pc, THREAD);\n    });\n#endif\n    if (TEST(MEMPROT_WRITE, prot)) {\n        LOG(THREAD, LOG_VMAREAS, 1,\n            \"\\tWARNING: region now writable: assuming another thread already flushed it\\n\"\n            \"\\tgoing to flush again just to make sure\\n\");\n        /* we could just bail here, but could have no forward progress if repeated\n         * races between selfmod writer and out-of-region writer\n         */\n        STATS_INC(num_write_fault_races);\n    }\n\n    /* see if writer is inside our region\n     * need instr size and opnd size to check for page boundary overlaps!\n     * For reset when the cache is not present, we decode from the app code,\n     * though that's racy!  solution is to have reset store a copy of the app instr\n     * (FIXME case 7393).\n     */\n    instr_size_pc = (instr_cache_pc == NULL) ? instr_app_pc : instr_cache_pc;\n    next_pc = decode_memory_reference_size(dcontext, instr_size_pc, &opnd_size);\n    ASSERT(next_pc != NULL);\n    ASSERT(opnd_size != 0);\n    instr_size = next_pc - instr_size_pc;\n    /* FIXME case 7492: if write crosses page boundary, the reported faulting\n     * target for win32 will be in the middle of the instr's target (win32\n     * reports the first unwritable byte).  (On Linux we're fine as we calculate\n     * the target ourselves.)\n     */\n    if (target + opnd_size > base_pc + size) {\n        /* must expand to cover entire target, even if crosses OS regions */\n        app_pc t_pend = (app_pc)ALIGN_FORWARD(target + opnd_size, PAGE_SIZE);\n        size = t_pend - base_pc;\n    }\n    /* see if instr's bb is in region\n     * not good enough to only check instr!\n     * will end up in infinite loop if any part of bb overlaps the executable\n     * region removed!\n     * if f was deleted, we threw away its also info, so we have to do a full\n     * overlaps lookup.  f cannot have been removed completely since we\n     * count as being in the shared cache and could be inside f.\n     */\n    if (f != NULL &&\n         /* faster check up front if frag not deleted -- BUT, we are in\n          * a race w/ any flusher marking as deleted!\n          * so, we make vm_list_overlaps not assert on a not-there fragment,\n          * and only if it finds it and it's STILL not marked do we trust the\n          * return value.\n          */\n         (vm_list_overlaps(dcontext, (void *)f, base_pc, base_pc+size) ||\n          TEST(FRAG_WAS_DELETED, f->flags))) {\n        fragment_overlaps(dcontext, f, instr_app_pc, instr_app_pc+1,\n                          false /* fine-grain! */, &info, &bb_start);\n        /* if did fast check and it said overlap, slow check should too */\n        ASSERT(TEST(FRAG_WAS_DELETED, f->flags) || info.overlap);\n    }\n    if (info.overlap) {\n        /* instr_t may be in region, but could also be from a different region\n         * included in a trace.  Determine if instr bb overlaps with target\n         * region.\n         * Move to page boundaries, with inclusive end pages.\n         * We must look at entire bb containing instr, not just instr\n         * itself (can't isolate write from its bb -- will always\n         * enter from top of bb, even across direct cti)\n         */\n        ASSERT(info.overlap && bb_start != NULL);\n        if (info.contiguous)\n            bb_end = info.bb_end;\n        else {\n            /* FIXME: could be smart and have info include list of all pages,\n             * handle situations like start outside of region and jmp/call in,\n             * but this is going to be rare -- let's just take min and max of\n             * entire bb, even if that includes huge area (in which case we'll\n             * consider it self-modifying code, even if jumped over middle)\n             */\n            bb_start = info.min_pc;\n            bb_end = info.max_pc;\n            ASSERT(bb_start != NULL && bb_end != NULL);\n        }\n        bb_pstart = (app_pc) PAGE_START(bb_start);\n        bb_pend = (app_pc) PAGE_START(bb_end);\n        ASSERT(instr_app_pc >= bb_pstart &&\n               instr_app_pc+instr_size <= bb_pend+PAGE_SIZE);\n        ASSERT(f != NULL); /* else info.overlap should not be set */\n    }\n    /* Now we can check if source bb overlaps target region. */\n    if (info.overlap &&\n        base_pc < (bb_pend + PAGE_SIZE) &&\n        (base_pc + size) > bb_pstart) {\n        /* bb pages overlap target region -\n         * We want to split up region to keep instr exec but target writable.\n         * All pages touched by target will become writable.\n         * All pages in instr's bb must remain executable (can't isolate\n         * write from its bb -- will always enter from top of bb)\n         */\n        /* pages occupied by target */\n        app_pc tgt_pstart = (app_pc) PAGE_START(target);\n        app_pc tgt_pend = (app_pc) PAGE_START(target+opnd_size);\n\n        DOSTATS({\n            /* race condition case of another thread flushing 1st */\n            if (TEST(MEMPROT_WRITE, prot))\n                STATS_INC(num_write_fault_races_selfmod);\n        });\n\n        LOG(THREAD, LOG_VMAREAS, 2,\n            \"Write instr is inside F%d \"PFX\"\\n\", f->id, f->tag);\n\n        LOG(THREAD, LOG_VMAREAS, 1,\n            \"\\tinstr's bb src \"PFX\"-\"PFX\" overlaps target \"PFX\"-\"PFX\"\\n\",\n            bb_start, bb_end, target, target+opnd_size);\n\n        /* look for selfmod overlap */\n        if (bb_pstart <= tgt_pend && bb_pend >= tgt_pstart) {\n            vm_area_t *execarea;\n            app_pc nxt_on_page;\n            LOG(THREAD, LOG_VMAREAS, 1,\n                \"WARNING: self-modifying code: instr @\"PFX\" (in bb \"PFX\"-\"PFX\")\\n\"\n                \"\\twrote to \"PFX\"-\"PFX\"\\n\",\n                instr_app_pc, bb_start, bb_end, target, target+opnd_size);\n            SYSLOG_INTERNAL_WARNING_ONCE(\"self-modifying code.\");\n            /* can leave non-intersection part of instr pages as executable,\n             * no need to flush them\n             */\n            /* DGC_DIAGNOSTICS: have flusher pass target to\n             * vm_area_unlink_fragments to check if code was actually overwritten\n             */\n            flush_fragments_in_region_start(dcontext, (app_pc)tgt_pstart,\n                                            (tgt_pend+PAGE_SIZE-tgt_pstart),\n                                            false /* don't own initexit_lock */,\n                                            false /* keep futures */,\n                                            true /* exec invalid */,\n                                            false /* don't force synchall */\n                                            _IF_DGCDIAG(target));\n            /* flush_* grabbed exec areas lock for us, to make following sequence atomic */\n            /* need to change all exec areas on these pages to be selfmod */\n            for (ok = true, nxt_on_page = (app_pc) tgt_pstart;\n                 ok && nxt_on_page < (app_pc)tgt_pend + PAGE_SIZE; ) {\n                ok = binary_search(executable_areas, nxt_on_page, (app_pc)tgt_pend+PAGE_SIZE,\n                                   &execarea, NULL, true /* want 1st match! */);\n                if (ok) {\n                    nxt_on_page = execarea->end;\n                    if (TESTANY(FRAG_SELFMOD_SANDBOXED, execarea->frag_flags)) {\n                        /* not calling remove_vm_area so we have to vm_make_writable\n                         * FIXME: why do we have to do anything if already selfmod?\n                         */\n                        if (DR_MADE_READONLY(execarea->vm_flags))\n                            vm_make_writable(execarea->start, execarea->end - execarea->start);\n                        continue;\n                    }\n                    if (execarea->start < (app_pc)tgt_pstart ||\n                        execarea->end > (app_pc)tgt_pend + PAGE_SIZE) {\n                        /* this area sticks out from our target area, so we split it\n                         * by removing and then re-adding (as selfmod) the overlap portion\n                         */\n                        uint old_vmf = execarea->vm_flags;\n                        uint old_ff = execarea->frag_flags;\n                        app_pc old_start = (execarea->start < tgt_pstart) ?\n                            tgt_pstart : execarea->start;\n                        app_pc old_end = (execarea->end > tgt_pend + PAGE_SIZE) ?\n                            tgt_pend + PAGE_SIZE : execarea->end;\n                        LOG(GLOBAL, LOG_VMAREAS, 2,\n                            \"removing executable vm area to mark selfmod: \"PFX\"-\"PFX\"\\n\",\n                            old_start, old_end);\n                        remove_vm_area(executable_areas, old_start, old_end, true);\n                        /* now re-add */\n                        add_executable_vm_area(old_start, old_end,\n                                               old_vmf, old_ff | FRAG_SELFMOD_SANDBOXED,\n                                               true /*own lock */\n                                               _IF_DEBUG(\"selfmod replacement\"));\n                        STATS_INC(num_selfmod_vm_areas);\n                        /* this won't hurt our iteration since it's stateless except for\n                         * nxt_on_page\n                         */\n                    } else {\n                        LOG(THREAD, LOG_VMAREAS, 2, \"\\tmarking \"PFX\"-\"PFX\" as selfmod\\n\",\n                            execarea->start, execarea->end);\n                        execarea->frag_flags |= SANDBOX_FLAG();\n                        STATS_INC(num_selfmod_vm_areas);\n                        /* not calling remove_vm_area so we have to vm_make_writable */\n                        if (DR_MADE_READONLY(execarea->vm_flags))\n                            vm_make_writable(execarea->start, execarea->end - execarea->start);\n                    }\n                }\n            }\n            LOG(GLOBAL, LOG_VMAREAS, 3,\n                \"After marking all areas in \"PFX\"-\"PFX\" as selfmod:\\n\",\n                tgt_pstart, tgt_pend+PAGE_SIZE);\n            DOLOG(3, LOG_VMAREAS, { print_vm_areas(executable_areas, GLOBAL); });\n            flush_fragments_in_region_finish(dcontext,\n                                             false /*don't keep initexit_lock*/);\n            if (DYNAMO_OPTION(opt_jit) && !TEST(MEMPROT_WRITE, prot) &&\n                is_jit_managed_area((app_pc)tgt_pstart)) {\n                jitopt_clear_span((app_pc) tgt_pstart,\n                                             (app_pc) (tgt_pend+PAGE_SIZE-tgt_pstart));\n            }\n            /* must execute instr_app_pc next, even though that new bb will be\n             * useless afterward (will most likely re-enter from bb_start)\n             */\n            return instr_app_pc;\n        } else {\n            /* Not selfmod, but target and bb region may still overlap -\n             * heuristic: split the region up -- assume will keep writing\n             * to higher addresses and keep executing at higher addresses.\n             */\n            if (tgt_pend < bb_pstart) {\n                /* make all pages from tgt_pstart up to bb_pstart or\n                 * region end (which ever is first) non-exec */\n                /* FIXME - CHECK - should we really be starting at\n                 * base_pc instead? Not clear why we shouldn't start at\n                 * region start (like we would if we didn't have an\n                 * overlap). */\n                flush_start = tgt_pstart;\n                ASSERT(bb_pstart < (base_pc + size) &&\n                       bb_pstart > tgt_pstart);\n                flush_size = bb_pstart - tgt_pstart;\n            } else if (tgt_pstart > bb_pend) {\n                /* make all pages from tgt_pstart to end of region non-exec */\n                flush_start = tgt_pstart;\n                flush_size = (base_pc + size) - tgt_pstart;\n            } else {\n                /* should never get here -- all cases covered above */\n                ASSERT_NOT_REACHED();\n            }\n            LOG(THREAD, LOG_VMAREAS, 2,\n                \"splitting region up, flushing just \"PFX\"-\"PFX\"\\n\",\n                flush_start, flush_start+flush_size);\n        }\n    } else {\n        ASSERT(!info.overlap || (f != NULL && TEST(FRAG_IS_TRACE, f->flags)));\n        /* instr not in region, so move entire region off the executable list */\n        flush_start = base_pc;\n        flush_size = size;\n        LOG(THREAD, LOG_VMAREAS, 2, \"instr not in region, flushing entire \"PFX\"-\"PFX\"\\n\",\n            flush_start, flush_start+flush_size);\n    }\n\n    /* DGC_DIAGNOSTICS: have flusher pass target to\n     * vm_area_unlink_fragments to check if code was actually overwritten\n     */\n    flush_fragments_in_region_start(dcontext, flush_start, flush_size,\n                                    false /* don't own initexit_lock */,\n                                    false /* keep futures */,\n                                    true /* exec invalid */,\n                                    false /* don't force synchall */\n                                    _IF_DGCDIAG(target));\n    f = NULL; /* after the flush we don't know if it's safe to deref f */\n\n    if (DYNAMO_OPTION(ro2sandbox_threshold) > 0) {\n        /* add removed region to written list to track # of times this has happened\n         * actually, we only track by the written-to page\n         * FIXME case 8161: should we add more than just the page?\n         * we'll keep adding the whole region until it hits the ro2sandbox threshold,\n         * at which point we'll just add the page\n         */\n        ro_vs_sandbox_data_t *ro2s;\n        write_lock(&written_areas->lock);\n        /* use the add routine to lookup if present, add if not */\n        add_written_area(written_areas, target, (app_pc) PAGE_START(target),\n                         (app_pc) PAGE_START(target+opnd_size) + PAGE_SIZE, &a);\n        ASSERT(a != NULL);\n        ro2s = (ro_vs_sandbox_data_t *) a->custom.client;\n        ro2s->written_count++;\n        LOG(GLOBAL, LOG_VMAREAS, 2,\n            \"written area \"PFX\"-\"PFX\" now written %d X\\n\",\n            a->start, a->end, ro2s->written_count);\n        DOLOG(3, LOG_VMAREAS, {\n            LOG(GLOBAL, LOG_VMAREAS, 2, \"\\nwritten areas:\\n\");\n            print_vm_areas(written_areas, GLOBAL);\n        });\n        write_unlock(&written_areas->lock);\n    }\n\n    if (\n#ifdef PROGRAM_SHEPHERDING\n        !DYNAMO_OPTION(selfmod_futureexec) &&\n#endif\n        is_executable_area_on_all_selfmod_pages(target, target+opnd_size)) {\n        /* We can be in various races with another thread in handling write\n         * faults to this same region.  We check at the start of this routine,\n         * but in practice (case 7911) I've seen the race more often show up\n         * here, after the flush synch.  If another thread has already switched\n         * the target region to selfmod, then we shouldn't remove it from\n         * executable_areas here.  In fact if we were to remove it we would foil\n         * the selfmod->remove future optimizations (case 280) (once-only at\n         * NtFlush, selfmod when used to validate exec area, and remove\n         * overlapping futures w/ new selfmod exec area).\n         */\n        /* FIXME: is it worth checking this selfmod overlap in earlier places,\n         * like the start of this routine, or at the start of the flush synch,\n         * which could save some synch work and perhaps avoid the flush\n         * altogether?\n         */\n        STATS_INC(flush_selfmod_race_no_remove);\n        LOG(THREAD, LOG_VMAREAS, 2,\n            \"Target \"PFX\" is already selfmod, race, no reason to remove\\n\",\n            target);\n    } else {\n        /* flush_* grabbed exec areas lock for us, to make vm_make_writable,\n         * remove global vm area, and lookup an atomic sequence\n         */\n        LOG(GLOBAL, LOG_VMAREAS, 2,\n            \"removing executable vm area since written: \"PFX\"-\"PFX\"\\n\",\n            flush_start, flush_start+flush_size);\n        /* FIXME : are we removing regions that might not get re-added here?\n         * what about things that came from once only future or mem prot changes,\n         * the region removed here can be much larger then just the page written\n         */\n        /* FIXME (part of case 3744): should remove only non-selfmod regions here!\n         * Then can eliminate the if above.   Could pass filter flag to remove_vm_area,\n         * but better to just split code origins from consistency and not have\n         * sub-page regions on the consistency list (case 3744).\n         */\n        remove_vm_area(executable_areas, flush_start, flush_start+flush_size,\n                       true/*restore writability!*/);\n        LOG(THREAD, LOG_VMAREAS, 2,\n            \"Removed \"PFX\"-\"PFX\" from exec list, continuing @ write\\n\",\n            flush_start, flush_start+flush_size);\n    }\n    DOLOG(3, LOG_VMAREAS, {\n        thread_data_t *data = GET_DATA(dcontext, 0);\n        LOG(THREAD, LOG_VMAREAS, 2, \"\\nexecutable areas:\\n\");\n        print_vm_areas(executable_areas, THREAD);\n        LOG(THREAD, LOG_VMAREAS, 2, \"\\nthread areas:\\n\");\n        print_vm_areas(&data->areas, THREAD);\n    });\n\n    /* There is no good way to tell if we flushed f or not, so need to start\n     * interpreting at instr_app_pc. If f was a trace could overlap flushed\n     * region even if the src bb didn't and anyways flushing can end up\n     * flushing outside the requested region (entire vm_area_t). If we could tell\n     * we could return NULL instead (which is a special flag that says redo the\n     * write instead of going to dispatch) if f wasn't flushed.\n     * FIXME - Redoing the write would be more efficient then going back to\n     * dispatch and should be the common case. */\n    flush_fragments_in_region_finish(dcontext, false /*don't keep initexit_lock*/);\n    if (DYNAMO_OPTION(opt_jit) && !TEST(MEMPROT_WRITE, prot) &&\n        is_jit_managed_area(flush_start))\n        jitopt_clear_span(flush_start, flush_start+flush_size);\n    return instr_app_pc;\n}\n\n/* Returns the counter a selfmod fragment should execute for -sandbox2ro_threshold */\nuint *\nget_selfmod_exec_counter(app_pc tag)\n{\n    vm_area_t *area = NULL;\n    ro_vs_sandbox_data_t *ro2s;\n    uint *counter;\n    bool ok;\n    read_lock(&written_areas->lock);\n    ok = lookup_addr(written_areas, tag, &area);\n    if (!ok) {\n        read_unlock(&written_areas->lock);\n        read_lock(&executable_areas->lock);\n        write_lock(&written_areas->lock);\n        ok = lookup_addr(executable_areas, tag, &area);\n        ASSERT(ok && area != NULL);\n        /* FIXME: do this addition whenever add new exec area marked as\n         * selfmod?\n         * FIXME case 8161: add only add one page?  since never split written_areas?\n         * For now we add the whole region, reasoning that as a selfmod\n         * region it's probably not very big anyway.\n         * In Sun's JVM 1.4.2 we actually never get here b/c we always\n         * have an executable region already present before we make it selfmod,\n         * so we're only adding to written_areas when we get a write fault,\n         * at which point we only use the surrounding page.\n         */\n        STATS_INC(num_sandbox_before_ro);\n        add_written_area(written_areas, tag, area->start, area->end, &area);\n        ASSERT(area != NULL);\n        ro2s = (ro_vs_sandbox_data_t *) area->custom.client;\n        counter = &ro2s->selfmod_execs;\n        /* Inc of selfmod_execs from cache can have problems if it crosses a\n         * cache line, so we assert on the 32-bit alignment we should get from\n         * the heap.  add_written_area already asserts but we double-check here.\n         */\n        ASSERT(ALIGNED(counter, sizeof(uint)));\n        write_unlock(&written_areas->lock);\n        read_unlock(&executable_areas->lock);\n    } else {\n        ASSERT(ok && area != NULL);\n        ro2s = (ro_vs_sandbox_data_t *) area->custom.client;\n        counter = &ro2s->selfmod_execs;\n        read_unlock(&written_areas->lock);\n    }\n    /* ref to counter will be accessed in-cache w/o read lock but\n     * written_areas is never merged and counter won't be freed until\n     * exit time.\n     */\n    return counter;\n}\n\n/* Returns true if f has been flushed */\nbool\nvm_area_selfmod_check_clear_exec_count(dcontext_t *dcontext, fragment_t *f)\n{\n    ro_vs_sandbox_data_t *ro2s = NULL;\n    vm_area_t *exec_area = NULL, *written_area;\n    app_pc start, end;\n    bool ok;\n    bool convert_s2ro = true;\n    if (DYNAMO_OPTION(sandbox2ro_threshold) == 0)\n        return false;\n\n    /* NOTE - we could only grab the readlock here.  Even though we're going to\n     * write to selfmod_execs count, it's not really protected by the written_areas\n     * lock since we read and write to it from the cache.  Should change to read lock\n     * if contention ever becomes an issue.  Note that we would then have to later\n     * grab the write lock if we need to write to ro2s->written_count below. */\n    write_lock(&written_areas->lock);\n\n    ok = lookup_addr(written_areas, f->tag, &written_area);\n    if (ok) {\n        ro2s = (ro_vs_sandbox_data_t *) written_area->custom.client;\n    } else {\n        /* never had instrumentation */\n        write_unlock(&written_areas->lock);\n        return false;\n    }\n    if (ro2s->selfmod_execs < DYNAMO_OPTION(sandbox2ro_threshold)) {\n        /* must be a real fragment modification, reset the selfmod_execs count\n         * xref case 9908 */\n        LOG(THREAD, LOG_VMAREAS, 3,\n            \"Fragment \"PFX\" self-write -> \"PFX\"-\"PFX\" selfmod exec counter reset, old\"\n            \" count=%d\\n\",\n            f->tag, written_area->start, written_area->end, ro2s->selfmod_execs);\n        /* Write must be atomic since we access this field from the cache, an aligned\n         * 4 byte write is atomic on the architectures we support. */\n        ASSERT(sizeof(ro2s->selfmod_execs) == 4 && ALIGNED(&(ro2s->selfmod_execs), 4));\n        ro2s->selfmod_execs = 0;\n        write_unlock(&written_areas->lock);\n        return false;\n    }\n\n    LOG(THREAD, LOG_VMAREAS, 1,\n        \"Fragment \"PFX\" caused \"PFX\"-\"PFX\" to cross sandbox2ro threshold %d vs %d\\n\",\n        f->tag, written_area->start, written_area->end,\n        ro2s->selfmod_execs, DYNAMO_OPTION(sandbox2ro_threshold));\n    start = written_area->start;\n    end = written_area->end;\n    /* reset to avoid immediate re-trigger */\n    ro2s->selfmod_execs = 0;\n\n    if (is_on_stack(dcontext, f->tag, NULL)) {\n        /* Naturally we cannot make the stack ro.  We checked when we built f,\n         * but esp must now point elsewhere.  We go ahead and flush and assume\n         * that when we rebuild f we won't put the instrumentation in. */\n        convert_s2ro = false;\n        STATS_INC(num_sandbox2ro_onstack);\n        LOG(THREAD, LOG_VMAREAS, 1, \"Fragment \"PFX\" is on stack now!\\n\", f->tag);\n        ASSERT_CURIOSITY(false && \"on-stack selfmod bb w/ counter inc\");\n    }\n\n    if (convert_s2ro && DYNAMO_OPTION(ro2sandbox_threshold) > 0) {\n        /* We'll listen to -sandbox2ro_threshold even if a selfmod region\n         * didn't become that way via -ro2sandbox_threshold, to avoid perf\n         * problems w/ other code in the same region, and to take advantage of\n         * patterns of write at init time and then never selfmod again.\n         * FIXME: have a different threshold for regions made selfmod for actual\n         * self-writes versus -ro2sandbox_threshold regions?\n         * If there is a written_count, we reset it so it can trigger again.\n         * We reset here rather than when ro2sandbox_threshold is triggered as\n         * ro2sandbox only does a page at a time and if keeping a count for\n         * multiple pages doesn't want to clear that count too early.\n         */\n        LOG(THREAD, LOG_VMAREAS, 2,\n            \"re-setting written executable vm area: \"PFX\"-\"PFX\" written %d X\\n\",\n            written_area->start, written_area->end,\n            ro2s->written_count);\n        ro2s->written_count = 0;\n    }\n    DOLOG(3, LOG_VMAREAS, {\n        LOG(THREAD, LOG_VMAREAS, 2, \"\\nwritten areas:\\n\");\n        print_vm_areas(written_areas, THREAD);\n    });\n\n    write_unlock(&written_areas->lock);\n\n    /* Convert the selfmod region to a ro region.\n     * FIXME case 8161: should we flush and make ro the executable area,\n     * or the written area?  Written area may only be a page if made\n     * selfmod due to a code write, but then it should match the executable area\n     * in the common case, though written area may be larger if executable area\n     * is from a tiny NtFlush.  If we make a sub-piece of the executable area ro,\n     * the rest will remain selfmod and will eventually come here anyway.\n     */\n    flush_fragments_in_region_start(dcontext, start, end - start,\n                                    false /* don't own initexit_lock */,\n                                    false /* keep futures */,\n                                    true /* exec invalid */,\n                                    false /* don't force synchall */\n                                    _IF_DGCDIAG(NULL));\n    if (convert_s2ro) {\n        DODEBUG(ro2s->s2ro_xfers++;);\n        /* flush_* grabbed executable_areas lock for us */\n        ok = lookup_addr(executable_areas, f->tag, &exec_area);\n        if (ok) {\n            if (TEST(FRAG_SELFMOD_SANDBOXED, exec_area->frag_flags)) {\n                /* FIXME: if exec area is larger than flush area, it's\n                 * ok since marking fragments in a ro region as selfmod\n                 * is not a correctness problem.  Current flush impl, though,\n                 * will flush whole region.\n                 */\n                vm_area_t area_copy = *exec_area;  /* copy since we remove it */\n                exec_area = &area_copy;\n                LOG(THREAD, LOG_VMAREAS, 1,\n                    \"\\tconverting \"PFX\"-\"PFX\" from sandbox to ro\\n\",\n                    exec_area->start, exec_area->end);\n                exec_area->frag_flags &= ~FRAG_SELFMOD_SANDBOXED;\n                /* can't ASSERT(!TEST(VM_MADE_READONLY, area->vm_flags)) (case 7877) */\n                vm_make_unwritable(exec_area->start, exec_area->end - exec_area->start);\n                exec_area->vm_flags |= VM_MADE_READONLY;\n                /* i#942: Remove the sandboxed area and re-add it to merge it\n                 * back with any areas it used to be a part of.\n                 */\n                remove_vm_area(executable_areas, exec_area->start,\n                               exec_area->end, false /* !restore_prot */);\n                ok = add_executable_vm_area(exec_area->start, exec_area->end,\n                                            exec_area->vm_flags,\n                                            exec_area->frag_flags,\n                                            true /*own lock */\n                                            _IF_DEBUG(\"selfmod replacement\"));\n                ASSERT(ok);\n                /* Re-do the lookup in case of merger. */\n                ok = lookup_addr(executable_areas, f->tag, &exec_area);\n                ASSERT(ok);\n                LOG(THREAD, LOG_VMAREAS, 3,\n                    \"After marking \"PFX\"-\"PFX\" as NOT selfmod:\\n\",\n                    exec_area->start, exec_area->end);\n                DOLOG(3, LOG_VMAREAS, { print_vm_areas(executable_areas, THREAD); });\n                STATS_INC(num_sandbox2ro);\n            } else {\n                /* must be a race! */\n                LOG(THREAD, LOG_VMAREAS, 3,\n                    \"Area \"PFX\"-\"PFX\" is ALREADY not selfmod!\\n\",\n                    exec_area->start, exec_area->end);\n                STATS_INC(num_sandbox2ro_race);\n            }\n        } else {\n            /* must be a flushing race */\n            LOG(THREAD, LOG_VMAREAS, 3, \"Area \"PFX\"-\"PFX\" is no longer there!\\n\",\n                start, end);\n            STATS_INC(num_sandbox2ro_flush_race);\n        }\n    }\n\n    ASSERT(exec_area == NULL || /* never looked up */\n           (start < exec_area->end && end > exec_area->start));\n\n    flush_fragments_in_region_finish(dcontext,\n                                     false /*don't keep initexit_lock*/);\n    if (DYNAMO_OPTION(opt_jit) && is_jit_managed_area(start))\n        jitopt_clear_span(start, end);\n    return true;\n}\n\nvoid\nmark_unload_start(app_pc module_base, size_t module_size)\n{\n    /* in thin client mode we don't allocate this,\n     * but we do track unloads in -client mode\n     */\n    if (last_deallocated == NULL)\n        return;\n    ASSERT(DYNAMO_OPTION(unloaded_target_exception));\n    ASSERT_CURIOSITY(!last_deallocated->unload_in_progress);\n    /* we may have a race, or a thread killed during unload syscall,\n     * either way we just mark our last region on top of the old one\n     */\n    mutex_lock(&last_deallocated_lock);\n    last_deallocated->last_unload_base = module_base;\n    last_deallocated->last_unload_size = module_size;\n    last_deallocated->unload_in_progress = true;\n    mutex_unlock(&last_deallocated_lock);\n}\n\nvoid\nmark_unload_future_added(app_pc module_base, size_t size)\n{\n    /* case 9371: if a thread gets preempted before returning from\n     * unmapviewofsection and in the mean time another has a _future_ exec\n     * area allocated at the same place and executes from it, we should not\n     * throw exception mistakenly if the area would have been allowed\n     */\n    if (last_deallocated == NULL)\n        return;\n    ASSERT(DYNAMO_OPTION(unloaded_target_exception));\n\n    ASSERT_CURIOSITY(!last_deallocated->unload_in_progress && \"future while unload\");\n\n    /* FIXME: more preciselly we should only remove our intersection\n     * with the last module, otherwise don't need to, but it is never\n     * expected to happen, so not optimizing at all\n     */\n    last_deallocated->unload_in_progress = false;\n}\n\nvoid\nmark_unload_end(app_pc module_base)\n{\n    if (last_deallocated == NULL)\n        return;\n    ASSERT(DYNAMO_OPTION(unloaded_target_exception));\n\n    /* We're trying to avoid a spurious security violation while we\n     * are flushing our security policies, but before the address is\n     * actually fully unloaded.  So if we don't have an entry in our\n     * executable_areas or RAC or RCT policies then we should either\n     * find the address unreadable with query_virtual_memory(), or we\n     * should make sure that we find it as is_currently_unloaded_region().\n     */\n\n    /* The fact that we have reached this routine already guarantees\n     * that the memory was made unreadable (whether the memory is\n     * still unreadable is not guaranteed, see below).  Yet if we do\n     * checks in proper order is_currently_unloaded_region() _before_\n     * is_readable_without_exception(), as we do in the convenience\n     * routine is_unreadable_or_currently_unloaded_region(), we can\n     * get away without a barrier here.\n     */\n\n    /* FIXME: Otherwise we'd need a barrier, such that until a security\n     * policy reader is done, we cannot mark the module as unloaded,\n     * and if they start doing their check after this - then they\n     * should get a policy consistent with the memory already being\n     * unreadable.  (For example, we can synchronize with\n     * check_thread_vm_area() via\n     * {executable_areas_lock();executable_areas_unlock()} but since\n     * all other policies have sufficient information from unreadable\n     * memory, we're OK with a DLL being completely unloaded.\n     */\n\n    /* FIXME: note we may want to grab the appropriate policy locks so\n     * that we can thus delay our declaring we're no longer unloading\n     * a module until the policy processing is done, e.g. if one has\n     * started querying a security policy while we are unloading, we\n     * should preserve the marker until they are done.\n     * for .B we hold a writable executable_areas_lock(),\n     * watch out here if for case 9371 we want to also mark_unload_end()\n     * on any new allocations\n     * FIXME: the RCT policies however we don't hold a lock.\n     */\n\n    /* FIXME: case 9372 Note that we may still have a problem primarily if a DLL\n     * gets subsequently reloaded at the same location, (so we have\n     * lost our flag) so after a time in which we make our checks\n     * whether the target is unreadable, the new version will show up\n     * and may not yet be fully processed in postsys_MapViewOfSection\n     * (and even if it is, we may have already checked our\n     * policies). I assume this should be less frequent than the\n     * unload side (although it still shows up in our\n     * win32/reload-race.c).  At least not a problem if the DLL gets\n     * reloaded at a different address, like case 9121 or with -aslr 1\n     */\n\n    /* note grabbing this lock is only useful for the ASSERTs, setting\n     * the flag is atomic even without it.\n     * is_unreadable_or_currently_unloaded_region() when used in\n     * proper order doesn't need to synchronize with this lock either */\n    mutex_lock(&last_deallocated_lock);\n\n    /* note, we mark_unload_start on MEM_IMAGE but mark_unload_end on\n     * MEM_MAPPED as well.  Note base doesn't have to match as long as\n     * it is within the module */\n    ASSERT_CURIOSITY(!last_deallocated->unload_in_progress ||\n                     ((last_deallocated->last_unload_base <= module_base &&\n                       module_base <\n                       (last_deallocated->last_unload_base +\n                        last_deallocated->last_unload_size)) && \"race - multiple unmaps\"));\n    DOLOG(1, LOG_VMAREAS, {\n        /* there are a few cases where DLLs aren't unloaded by real\n         * base uxtheme.dll, but I haven't seen them */\n        ASSERT_CURIOSITY(!last_deallocated->unload_in_progress ||\n                         (last_deallocated->last_unload_base == module_base &&\n                         \"not base\"));\n    });\n\n    /* multiple racy unmaps can't be handled simultaneously anyways */\n    last_deallocated->unload_in_progress = false;\n    mutex_unlock(&last_deallocated_lock);\n}\n\nbool\nis_in_last_unloaded_region(app_pc pc)\n{\n    bool in_last = true;\n    if (last_deallocated == NULL)\n        return false;\n    ASSERT(DYNAMO_OPTION(unloaded_target_exception));\n\n    mutex_lock(&last_deallocated_lock);\n    /* if we are in such a tight race that we're no longer\n     * last_deallocated->unload_in_progress we can still use the\n     * already unloaded module\n     */\n    if ((pc < last_deallocated->last_unload_base) ||\n        (pc >= (last_deallocated->last_unload_base\n                + last_deallocated->last_unload_size)))\n        in_last = false;\n    mutex_unlock(&last_deallocated_lock);\n    return in_last;\n}\n\nstatic bool\nis_currently_unloaded_region(app_pc pc)\n{\n    if (last_deallocated == NULL)\n        return false;\n    ASSERT(DYNAMO_OPTION(unloaded_target_exception));\n\n    if (!last_deallocated->unload_in_progress)\n        return false;\n\n    return is_in_last_unloaded_region(pc);\n}\n\nbool\nis_unreadable_or_currently_unloaded_region(app_pc pc)\n{\n    /* we want one atomic query - so if we are before the completion\n     * of the UnMap system call we should be\n     * is_currently_unloaded_region(), but afterwards the address\n     * should be !is_readable_without_exception\n     */\n    /* order of execution is important - so that we don't have to grab\n     * a lock to synchronize with mark_unload_end().\n     */\n\n    if (is_currently_unloaded_region(pc)) {\n        STATS_INC(num_unloaded_race);\n        return true;\n    }\n    /* If we are not in a currently unloaded module then target is\n     * either not being unloaded or we are beyond system call.\n     */\n    if (!is_readable_without_exception(pc, 1)) {\n        return true;\n    }\n    return false;\n}\n\nvoid\nprint_last_deallocated(file_t outf)\n{\n    if (last_deallocated == NULL)\n        return;\n\n    ASSERT(DYNAMO_OPTION(unloaded_target_exception));\n    if (last_deallocated->last_unload_base == NULL) {\n        print_file(outf, \"never unloaded\\n\");\n        return;\n    }\n\n    print_file(outf, \"last unload: \"PFX\"-\"PFX\"%s\\n\",\n               last_deallocated->last_unload_base,\n               last_deallocated->last_unload_base +\n               last_deallocated->last_unload_size,\n               last_deallocated->unload_in_progress ? \" being unloaded\": \"\");\n}\n\n\n#ifdef PROGRAM_SHEPHERDING\n/* Note that rerouting an APC to this target should safely popup the arguments\n * and continue.\n *\n * Since ThreadProc and APCProc have the same signature, we handle a\n * remote thread in a similar way, instead of letting attack handling\n * decide its fate - which may be an exception instead of killing the\n * thread.\n *\n * FIXME: we're interpreting dynamorio.dll code here\n */\n/* FIXME clean up: safe_apc_or_thread_target, apc_thread_policy_helper and\n * aslr_report_violation should all be ifdef WINDOWS, and may be in a\n * different file\n */\n/* could do naked to get a single RET 4 emitted with no prologue */\nvoid\nAPC_API\nsafe_apc_or_thread_target(reg_t arg)\n{\n    /* NOTHING */\n}\n/* FIXME: case 9023: this is WRONG for NATIVE APCs!\n * kernel32!BaseDispatchAPC+0x33:\n * 7c82c13a c20c00           ret     0xc\n * FIXME: add safe_native_apc(PVOID context, PAPCFUNC func, reg_t arg)\n */\n\n/* a helper procedure for DYNAMO_OPTION(apc_policy) or DYNAMO_OPTION(thread_policy)\n *\n * FIXME: currently relevant only on WINDOWS\n */\nvoid\napc_thread_policy_helper(app_pc *apc_target_location, /* IN/OUT */\n                         security_option_t target_policy,\n                         apc_thread_type_t target_type)\n{\n    bool is_apc =\n        (target_type == APC_TARGET_NATIVE) ||\n        (target_type == APC_TARGET_WINDOWS);\n    /* if is_win32api we're evaluating the Win32 API targets of\n     * QueueUserAPC/CreateThreadEx, otherwise it is the native\n     * NtQueueApcThread/NtCreateThreadEx targets\n     */\n    bool is_win32api =\n        (target_type == THREAD_TARGET_WINDOWS) ||\n        (target_type == APC_TARGET_WINDOWS);\n\n    bool match = false;\n    /* FIXME: note taking the risk here of reading from either the\n     * word on the stack, or from a Cxt.  While the app would fail in\n     * either case this should be safer.  I don't want the extra\n     * is_readable_without_exception() here though.\n     */\n    app_pc injected_target = *apc_target_location;\n    uint injected_code = 0; /* first bytes of shellcode */\n\n    /* match PIC shellcode header, for example\n     * 0013004c 53               push    ebx\n     * 0013004d e800000000       call    00130052\n     */\n    enum {PIC_SHELLCODE_MATCH = 0x0000e853};\n\n    /* Now we quickly check a stipped down code origins policy instead\n     * of letting the bb builder do this.  ALTERNATIVE design: We could save\n     * the target and have this extra work done only after a code\n     * origins violations.  Then we would not modify application state\n     * unnecessarily.  The problem however is that we need to make\n     * sure we do that only _immediately_ after an APC.\n     */\n\n    /* using only executable area - assuming areas added by\n     * -executable_if_x are only added to futureexec_areas, so that\n     * this test can be done and acted upon independently of us\n     * running in NX compatibility\n     */\n    if (is_executable_address(injected_target)) {\n        return;         /* not a match */\n    }\n\n    if (safe_read(injected_target,\n                  sizeof(injected_code), &injected_code)) {\n        LOG(GLOBAL, LOG_ASYNCH, 2,\n            \"ASYNCH intercepted APC: APC pc=\"PFX\", APC code=\"PFX\" %s\\n\",\n            injected_target, injected_code,\n            injected_code == PIC_SHELLCODE_MATCH ? \"MATCH\" : \"\");\n    } else {\n        ASSERT_NOT_TESTED();\n    }\n\n    /* target is a non-executable area, but we may want to be more specific */\n    if (TEST(OPTION_CUSTOM, target_policy)) {\n        match = true;   /* no matter what is in the shellcode */\n    } else {\n        if (injected_code == PIC_SHELLCODE_MATCH)\n            match = true;\n    }\n\n    if (match) {\n        bool squashed = false;\n        char injected_threat_buf[MAXIMUM_VIOLATION_NAME_LENGTH]\n            = \"APCS.XXXX.B\";\n        const char *name = injected_threat_buf;\n\n        bool block = TEST(OPTION_BLOCK, target_policy);\n\n        /* we need the constructed name before deciding to really\n         * block, in case we exempt by ID */\n        if (TEST(OPTION_REPORT, target_policy)) {\n            /* mangle injected_code into a name */\n            if (injected_code == PIC_SHELLCODE_MATCH) {\n                /* keeping the well known hardcoded ones for VSE */\n                name = is_apc ? \"VVPP.3200.B\" : \"YCRP.3200.B\";\n            } else {\n                /* FIXME: nativs vs non-native could get a different prefix as well */\n                if (!is_apc) {\n                    const char *INJT = \"INJT\";\n                    /* (injected) shellcode thread */\n                    ASSERT_NOT_TESTED();\n                    /* gcc warns if we use the string \"INJT\" directly */\n                    strncpy(injected_threat_buf, INJT, 4);\n                }\n                fill_security_violation_target(injected_threat_buf,\n                                               (const byte*)&injected_code);\n            }\n\n            /* we allow -exempt_threat_list to override our action */\n            if (!IS_STRING_OPTION_EMPTY(exempt_threat_list)) {\n                if (is_exempt_threat_name(name)) {\n                    /* we want to ALLOW unconditionally so we don't\n                     * immediately get a regular .B violation after we\n                     * let it through the APC check\n                     */\n                    block = false;\n                }\n                /* FIXME: we don't have a good way to express allow\n                 * everyone except for the ones on this list while we\n                 * could say block = !block that doesn't match the\n                 * general meaning of exempt_threat_list\n                 */\n            }\n        }\n\n        if (block) {\n            /* always using custom attack handling */\n            /* We cannot let default attack handling take care\n             * of this because a main thread may get affected very early.\n             *\n             * It is also hard to reuse security_violation() call here\n             * (since we are not under dispatch()).  If we want to see a\n             * code origins failure, we can just disable this policy.\n             */\n            ASSERT(!TEST(OPTION_HANDLING, target_policy) && \"handling cannot be modified\");\n\n            SYSLOG_INTERNAL_WARNING(\"squashed %s %s at bad target pc=\"PFX\" %s\",\n                                    is_apc ? \"APC\" : \"thread\",\n                                    is_win32api ? \"win32\" : \"native\",\n                                    injected_target, name);\n\n            /* FIXME: case 9023 : should squash appropriately native\n             * vs non-native since the number of arguments may be\n             * different, hence stdcall RET size\n             */\n            *apc_target_location =\n                is_win32api ?\n                (app_pc)safe_apc_or_thread_target :\n                (app_pc)safe_apc_or_thread_target;\n\n            squashed = true;\n        } else {\n            /* allow */\n            app_pc base = (app_pc)PAGE_START(injected_target);\n            SYSLOG_INTERNAL_WARNING(\"allowing %s %s at bad target pc=\"PFX\" %s\",\n                                    is_apc ? \"APC\" : \"thread\",\n                                    is_win32api ? \"win32\" : \"native\",\n                                    injected_target, name);\n\n            /* FIXME: for HIGH mode, unfortunately the target code\n             * may be selfmod, so adding a hook-style policy is hard.\n             */\n            /* FIXME: It looks like in VirusScan (case 2871) they\n             * eventually free this memory, so not that bad hole.\n             * Although I haven't found how would they properly\n             * synchronize that entapi.dll is loaded. */\n\n            /* we can't safely determine a subpage region so adding whole page */\n            add_futureexec_vm_area(base, base + PAGE_SIZE,\n                                   false/*permanent*/\n                                   _IF_DEBUG(is_apc ? \"apc_helper\" : \"thread_policy\"));\n        }\n\n        if (TEST(OPTION_REPORT, target_policy)) {\n            /* report a violation adjusted for appropriate action */\n            /* FIXME: should come up with a new name for this\n             * violation otherwise it is pretty inconsistent to say\n             * running in detect mode and -B policies\n             */\n            /* note that we may not actually report if silent_block_threat_list */\n            security_violation_report(injected_target, APC_THREAD_SHELLCODE_VIOLATION,\n                                      name,\n                                      squashed ? ACTION_TERMINATE_THREAD :\n                                                 ACTION_CONTINUE);\n        }\n\n        DOSTATS({\n            if (is_apc)\n                STATS_INC(num_used_apc_policy);\n            else\n                STATS_INC(num_used_thread_policy);\n        });\n    }\n}\n\n/* a helper procedure for reporting ASLR violations */\nvoid\naslr_report_violation(app_pc execution_fault_pc,\n                      security_option_t handling_policy)\n{\n    STATS_INC(aslr_wouldbe_exec);\n\n    /* note OPTION_BLOCK has to be set since there is nothing we can\n     * do to not block the attack, there is no detect mode here, yet\n     * we let the original exception be passed.  For default\n     * applications where ASLR can be hit natively, the attack\n     * handling policy is to throw an exception.\n     */\n    ASSERT(TEST(OPTION_BLOCK, handling_policy));\n\n    /* FIXME: yet we should have a choice whether to override the\n     * exception that would normally be delivered to the application,\n     * with a -kill_thread or -kill_process in case the SEH chain is\n     * corrupt, and to allow the attack handling thresholds to take\n     * effect.\n     */\n    ASSERT(!TEST(OPTION_HANDLING, handling_policy));\n    /* FIXME: if using report security_violation() to provide attack\n     * handling decisions should make sure it prefers exceptions,\n     * FIXME: make sure not trying to release locks, FIXME: also clean\n     * kstats (currently hotp_only is already broken)\n     */\n\n    ASSERT(!TEST(OPTION_CUSTOM, handling_policy));\n\n    if (TEST(OPTION_REPORT, handling_policy)) {\n        /* report a violation, adjusted for appropriate action */\n        char aslr_threat_id[MAXIMUM_VIOLATION_NAME_LENGTH];\n\n        /* in -hotp_only mode cannot have the regular distinction\n         * between stack and heap targets (usually marked as .A and\n         * .B), instead marking all as the same .R violation.\n         */\n        security_violation_t aslr_violation_type = ASLR_TARGET_VIOLATION;\n\n        /* source cannot be obtained */\n        /* FIXME: case 8160 on possibly setting the source to something useful */\n\n        /* FIXME: target is currently unreadable, forensic and Threat\n         * ID generation will adjust to a likely current mapping to\n         * print its contents\n         */\n        dcontext_t *dcontext = get_thread_private_dcontext();\n\n        /* should be in hotp_only */\n        ASSERT(dcontext != NULL && dcontext->last_fragment != NULL &&\n               dcontext->last_fragment->tag == NULL);\n\n        /* note we clobber next_tag here, not bothering to preserve */\n        /* report_dcontext_info() uses next_tag for target (and\n         * preferred target) diagnostics */\n        dcontext->next_tag = execution_fault_pc;\n\n        /* if likely_target_pc is unreadable (and it should be)\n         * get_security_violation_name will use as target the contents\n         * of a likely would be target */\n        get_security_violation_name(dcontext,\n                                    execution_fault_pc,\n                                    aslr_threat_id, MAXIMUM_VIOLATION_NAME_LENGTH,\n                                    aslr_violation_type, NULL);\n        security_violation_report(execution_fault_pc,\n                                  aslr_violation_type,\n                                  aslr_threat_id,\n                                  ACTION_THROW_EXCEPTION);\n   }\n}\n#endif /* PROGRAM_SHEPHERDING */\n\n#ifdef STANDALONE_UNIT_TEST\n# define INT_TO_PC(x) ((app_pc)(ptr_uint_t)(x))\n\nstatic void\nprint_vector_msg(vm_area_vector_t *v, file_t f, const char *msg)\n{\n    print_file(f, \"%s:\\n\", msg);\n    print_vm_areas(v, f);\n}\n\nstatic void\ncheck_vec(vm_area_vector_t *v, int i, app_pc start, app_pc end,\n          uint vm_flags, uint frag_flags, void *data)\n{\n    ASSERT(i < v->length);\n    ASSERT(v->buf[i].start == start);\n    ASSERT(v->buf[i].end == end);\n    ASSERT(v->buf[i].vm_flags == vm_flags);\n    ASSERT(v->buf[i].frag_flags == frag_flags);\n    ASSERT(v->buf[i].custom.client == data);\n}\n\nvoid\nvmvector_tests()\n{\n    vm_area_vector_t v = {0, 0, 0, VECTOR_SHARED | VECTOR_NEVER_MERGE,\n                        INIT_READWRITE_LOCK(thread_vm_areas)};\n    bool res;\n    app_pc start = NULL, end = NULL;\n    print_file(STDERR, \"\\nvm_area_vector_t tests\\n\");\n    /* FIXME: not tested */\n    vmvector_add(&v, INT_TO_PC(0x100), INT_TO_PC(0x103), NULL);\n    vmvector_add(&v, INT_TO_PC(0x200), INT_TO_PC(0x203), NULL);\n    vmvector_print(&v, STDERR);\n#if 0 /* this raises no-merge assert: no mechanism to test that it fires though */\n    vmvector_add(&v, INT_TO_PC(0x202), INT_TO_PC(0x210), NULL); /* should complain */\n#endif\n    vmvector_add(&v, INT_TO_PC(0x203), INT_TO_PC(0x221), NULL);\n    vmvector_print(&v, STDERR);\n    check_vec(&v, 2, INT_TO_PC(0x203), INT_TO_PC(0x221), 0, 0, NULL);\n\n    res = vmvector_remove_containing_area(&v, INT_TO_PC(0x103), NULL, NULL); /* not in */\n    EXPECT(res, false);\n    check_vec(&v, 0, INT_TO_PC(0x100), INT_TO_PC(0x103), 0, 0, NULL);\n    res = vmvector_remove_containing_area(&v, INT_TO_PC(0x100), NULL, &end);\n    EXPECT(end, 0x103);\n    EXPECT(res, true);\n    vmvector_print(&v, STDERR);\n    check_vec(&v, 0, INT_TO_PC(0x200), INT_TO_PC(0x203), 0, 0, NULL);\n    res = vmvector_remove_containing_area(&v, INT_TO_PC(0x100), NULL, NULL); /* not in */\n    EXPECT(res, false);\n    vmvector_print(&v, STDERR);\n    res = vmvector_remove_containing_area(&v, INT_TO_PC(0x202), &start, NULL);\n    EXPECT(res, true);\n    EXPECT(start, 0x200);\n    vmvector_print(&v, STDERR);\n    res = vmvector_remove(&v, INT_TO_PC(0x20), INT_TO_PC(0x210)); /* truncation allowed? */\n    EXPECT(res, true);\n    vmvector_print(&v, STDERR);\n}\n\n/* initial vector tests\n * FIXME: should add a lot more, esp. wrt other flags -- these only\n * test no flags or interactions w/ selfmod flag\n */\nvoid\nunit_test_vmareas(void)\n{\n    vm_area_vector_t v = {0,0,0,false};\n    /* not needed yet: dcontext_t *dcontext = */\n    ASSIGN_INIT_READWRITE_LOCK_FREE(v.lock, thread_vm_areas);\n\n    /* TEST 1: merge a bunch of areas\n     */\n    add_vm_area(&v, INT_TO_PC(1), INT_TO_PC(3), 0, 0, NULL _IF_DEBUG(\"A\"));\n    add_vm_area(&v, INT_TO_PC(5), INT_TO_PC(7), 0, 0, NULL _IF_DEBUG(\"B\"));\n    add_vm_area(&v, INT_TO_PC(9), INT_TO_PC(11), 0, 0, NULL _IF_DEBUG(\"C\"));\n    print_vector_msg(&v, STDERR, \"after adding areas\");\n    check_vec(&v, 0, INT_TO_PC(1), INT_TO_PC(3), 0, 0, NULL);\n    check_vec(&v, 1, INT_TO_PC(5), INT_TO_PC(7), 0, 0, NULL);\n    check_vec(&v, 2, INT_TO_PC(9), INT_TO_PC(11), 0, 0, NULL);\n\n    add_vm_area(&v, INT_TO_PC(0), INT_TO_PC(12), 0, 0, NULL _IF_DEBUG(\"D\"));\n    print_vector_msg(&v, STDERR, \"after merging with D\");\n    check_vec(&v, 0, INT_TO_PC(0), INT_TO_PC(12), 0, 0, NULL);\n\n    /* clear for next test */\n    remove_vm_area(&v, INT_TO_PC(0), UNIVERSAL_REGION_END, false);\n    print_file(STDERR, \"\\n\");\n\n    /* TEST 2: add an area that covers several smaller ones, including one\n     * that cannot be merged\n     */\n    add_vm_area(&v, INT_TO_PC(1), INT_TO_PC(3), 0, 0, NULL _IF_DEBUG(\"A\"));\n    add_vm_area(&v, INT_TO_PC(5), INT_TO_PC(7), 0, FRAG_SELFMOD_SANDBOXED, NULL _IF_DEBUG(\"B\"));\n    add_vm_area(&v, INT_TO_PC(9), INT_TO_PC(11), 0, 0, NULL _IF_DEBUG(\"C\"));\n    print_vector_msg(&v, STDERR, \"after adding areas\");\n    check_vec(&v, 0, INT_TO_PC(1), INT_TO_PC(3), 0, 0, NULL);\n    check_vec(&v, 1, INT_TO_PC(5), INT_TO_PC(7), 0, FRAG_SELFMOD_SANDBOXED, NULL);\n    check_vec(&v, 2, INT_TO_PC(9), INT_TO_PC(11), 0, 0, NULL);\n\n    add_vm_area(&v, INT_TO_PC(2), INT_TO_PC(10), 0, 0, NULL _IF_DEBUG(\"D\"));\n    print_vector_msg(&v, STDERR, \"after merging with D\");\n    check_vec(&v, 0, INT_TO_PC(1), INT_TO_PC(5), 0, 0, NULL);\n    check_vec(&v, 1, INT_TO_PC(5), INT_TO_PC(7), 0, FRAG_SELFMOD_SANDBOXED, NULL);\n    check_vec(&v, 2, INT_TO_PC(7), INT_TO_PC(11), 0, 0, NULL);\n\n    remove_vm_area(&v, INT_TO_PC(6), INT_TO_PC(8), false);\n    print_vector_msg(&v, STDERR, \"after removing 6-8\");\n    check_vec(&v, 0, INT_TO_PC(1), INT_TO_PC(5), 0, 0, NULL);\n    check_vec(&v, 1, INT_TO_PC(5), INT_TO_PC(6), 0, FRAG_SELFMOD_SANDBOXED, NULL);\n    check_vec(&v, 2, INT_TO_PC(8), INT_TO_PC(11), 0, 0, NULL);\n\n    /* clear for next test */\n    remove_vm_area(&v, INT_TO_PC(0), UNIVERSAL_REGION_END, false);\n    print_file(STDERR, \"\\n\");\n\n    /* TEST 3: add an area that covers several smaller ones, including two\n     * that cannot be merged\n     */\n    add_vm_area(&v, INT_TO_PC(1), INT_TO_PC(3), 0, FRAG_SELFMOD_SANDBOXED, NULL _IF_DEBUG(\"A\"));\n    add_vm_area(&v, INT_TO_PC(5), INT_TO_PC(7), 0, FRAG_SELFMOD_SANDBOXED, NULL _IF_DEBUG(\"B\"));\n    add_vm_area(&v, INT_TO_PC(9), INT_TO_PC(11), 0, 0, NULL _IF_DEBUG(\"C\"));\n    print_vector_msg(&v, STDERR, \"after adding areas\");\n    check_vec(&v, 0, INT_TO_PC(1), INT_TO_PC(3), 0, FRAG_SELFMOD_SANDBOXED, NULL);\n    check_vec(&v, 1, INT_TO_PC(5), INT_TO_PC(7), 0, FRAG_SELFMOD_SANDBOXED, NULL);\n    check_vec(&v, 2, INT_TO_PC(9), INT_TO_PC(11), 0, 0, NULL);\n\n    add_vm_area(&v, INT_TO_PC(2), INT_TO_PC(12), 0, 0, NULL _IF_DEBUG(\"D\"));\n    print_vector_msg(&v, STDERR, \"after merging with D\");\n    check_vec(&v, 0, INT_TO_PC(1), INT_TO_PC(3), 0, FRAG_SELFMOD_SANDBOXED, NULL);\n    check_vec(&v, 1, INT_TO_PC(3), INT_TO_PC(5), 0, 0, NULL);\n    check_vec(&v, 2, INT_TO_PC(5), INT_TO_PC(7), 0, FRAG_SELFMOD_SANDBOXED, NULL);\n    check_vec(&v, 3, INT_TO_PC(7), INT_TO_PC(12), 0, 0, NULL);\n\n    remove_vm_area(&v, INT_TO_PC(2), INT_TO_PC(11), false);\n    print_vector_msg(&v, STDERR, \"after removing 2-11\");\n    check_vec(&v, 0, INT_TO_PC(1), INT_TO_PC(2), 0, FRAG_SELFMOD_SANDBOXED, NULL);\n    check_vec(&v, 1, INT_TO_PC(11), INT_TO_PC(12), 0, 0, NULL);\n\n    /* FIXME: would be nice to be able to test that an assert is generated...\n     * say, for this:\n     * add_vm_area(&v, INT_TO_PC(7), INT_TO_PC(12), 0, FRAG_SELFMOD_SANDBOXED, NULL _IF_DEBUG(\"E\"));\n     */\n\n    /* clear for next test */\n    remove_vm_area(&v, INT_TO_PC(0), UNIVERSAL_REGION_END, false);\n    print_file(STDERR, \"\\n\");\n\n    /* TEST 4: add an area completely inside one that cannot be merged\n     */\n    add_vm_area(&v, INT_TO_PC(1), INT_TO_PC(5), 0, FRAG_SELFMOD_SANDBOXED, NULL _IF_DEBUG(\"A\"));\n    print_vector_msg(&v, STDERR, \"after adding areas\");\n    check_vec(&v, 0, INT_TO_PC(1), INT_TO_PC(5), 0, FRAG_SELFMOD_SANDBOXED, NULL);\n\n    add_vm_area(&v, INT_TO_PC(3), INT_TO_PC(4), 0, 0, NULL _IF_DEBUG(\"B\"));\n    print_vector_msg(&v, STDERR, \"after merging with B\");\n    check_vec(&v, 0, INT_TO_PC(1), INT_TO_PC(5), 0, FRAG_SELFMOD_SANDBOXED, NULL);\n\n    /* clear for next test */\n    remove_vm_area(&v, INT_TO_PC(0), UNIVERSAL_REGION_END, false);\n    print_file(STDERR, \"\\n\");\n\n    /* TEST 5: Test merging adjacent areas.\n     */\n    add_vm_area(&v, INT_TO_PC(1), INT_TO_PC(2), 0, 0, NULL _IF_DEBUG(\"A\"));\n    add_vm_area(&v, INT_TO_PC(2), INT_TO_PC(3), 0, 0, NULL _IF_DEBUG(\"B\"));\n    add_vm_area(&v, INT_TO_PC(3), INT_TO_PC(4), 0, 0, NULL _IF_DEBUG(\"C\"));\n    print_vector_msg(&v, STDERR, \"do areas merge\");\n    check_vec(&v, 0, INT_TO_PC(1), INT_TO_PC(4), 0, 0, NULL);\n\n    remove_vm_area(&v, INT_TO_PC(1), INT_TO_PC(4), false);\n    add_vm_area(&v, INT_TO_PC(1), INT_TO_PC(2), 0, 0, NULL _IF_DEBUG(\"A\"));\n    add_vm_area(&v, INT_TO_PC(2), INT_TO_PC(3), 0, FRAG_SELFMOD_SANDBOXED, NULL\n                _IF_DEBUG(\"B\"));\n    add_vm_area(&v, INT_TO_PC(3), INT_TO_PC(4), 0, 0, NULL _IF_DEBUG(\"C\"));\n    print_vector_msg(&v, STDERR, \"do areas merge with flags\");\n    check_vec(&v, 0, INT_TO_PC(1), INT_TO_PC(2), 0, 0, NULL);\n    check_vec(&v, 1, INT_TO_PC(2), INT_TO_PC(3), 0, FRAG_SELFMOD_SANDBOXED, NULL);\n    check_vec(&v, 2, INT_TO_PC(3), INT_TO_PC(4), 0, 0, NULL);\n\n    vmvector_tests();\n}\n#endif  /* STANDALONE_UNIT_TEST */\n", "idx": 1, "id": 10598, "msg": "This is declared in the wrong block", "proj": "DynamoRIO-dynamorio", "lang": "c"}
{"patch": "@@ -150,12 +150,16 @@ public abstract class PrivacyApiGroupJsonRpcMethods extends ApiGroupJsonRpcMetho\n \n   private JsonRpcMethod createPrivacyMethod(\n       final PrivacyParameters privacyParameters, final JsonRpcMethod rpcMethod) {\n-    if (rpcMethod.getName().equals(RpcMethod.ETH_SEND_RAW_PRIVATE_TRANSACTION.getMethodName())) {\n+    final String methodName = rpcMethod.getName();\n+    if (methodName.equals(RpcMethod.ETH_SEND_RAW_PRIVATE_TRANSACTION.getMethodName())) {\n+      return rpcMethod;\n+    } else if (methodName.equals(RpcMethod.PRIV_DISTRIBUTE_RAW_TRANSACTION.getMethodName())\n+        && privacyParameters.getGoQuorumPrivacyParameters().isPresent()) {\n       return rpcMethod;\n     } else if (privacyParameters.isEnabled() && privacyParameters.isMultiTenancyEnabled()) {\n       return new MultiTenancyRpcMethodDecorator(rpcMethod);\n     } else if (!privacyParameters.isEnabled()) {\n-      return new DisabledPrivacyRpcMethod(rpcMethod.getName());\n+      return new DisabledPrivacyRpcMethod(methodName);\n     } else {\n       return rpcMethod;\n     }", "y": 1, "oldf": "/*\n * Copyright ConsenSys AG.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n * the License. You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n * an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n * specific language governing permissions and limitations under the License.\n *\n * SPDX-License-Identifier: Apache-2.0\n */\npackage org.hyperledger.besu.ethereum.api.jsonrpc.methods;\n\nimport org.hyperledger.besu.ethereum.api.jsonrpc.LatestNonceProvider;\nimport org.hyperledger.besu.ethereum.api.jsonrpc.RpcMethod;\nimport org.hyperledger.besu.ethereum.api.jsonrpc.internal.methods.JsonRpcMethod;\nimport org.hyperledger.besu.ethereum.api.jsonrpc.internal.privacy.methods.DisabledPrivacyRpcMethod;\nimport org.hyperledger.besu.ethereum.api.jsonrpc.internal.privacy.methods.EnclavePublicKeyProvider;\nimport org.hyperledger.besu.ethereum.api.jsonrpc.internal.privacy.methods.MultiTenancyRpcMethodDecorator;\nimport org.hyperledger.besu.ethereum.api.query.BlockchainQueries;\nimport org.hyperledger.besu.ethereum.api.query.PrivacyQueries;\nimport org.hyperledger.besu.ethereum.core.Address;\nimport org.hyperledger.besu.ethereum.core.PrivacyParameters;\nimport org.hyperledger.besu.ethereum.eth.transactions.PendingTransactions;\nimport org.hyperledger.besu.ethereum.eth.transactions.TransactionPool;\nimport org.hyperledger.besu.ethereum.mainnet.ProtocolSchedule;\nimport org.hyperledger.besu.ethereum.privacy.ChainHeadPrivateNonceProvider;\nimport org.hyperledger.besu.ethereum.privacy.DefaultPrivacyController;\nimport org.hyperledger.besu.ethereum.privacy.MultiTenancyPrivacyController;\nimport org.hyperledger.besu.ethereum.privacy.PrivacyController;\nimport org.hyperledger.besu.ethereum.privacy.PrivateNonceProvider;\nimport org.hyperledger.besu.ethereum.privacy.PrivateTransactionSimulator;\nimport org.hyperledger.besu.ethereum.privacy.markertransaction.FixedKeySigningPrivateMarkerTransactionFactory;\nimport org.hyperledger.besu.ethereum.privacy.markertransaction.PrivateMarkerTransactionFactory;\nimport org.hyperledger.besu.ethereum.privacy.markertransaction.RandomSigningPrivateMarkerTransactionFactory;\n\nimport java.math.BigInteger;\nimport java.util.Map;\nimport java.util.Optional;\nimport java.util.stream.Collectors;\n\npublic abstract class PrivacyApiGroupJsonRpcMethods extends ApiGroupJsonRpcMethods {\n\n  private final BlockchainQueries blockchainQueries;\n  private final ProtocolSchedule protocolSchedule;\n  private final TransactionPool transactionPool;\n  private final PrivacyParameters privacyParameters;\n  private final PrivateNonceProvider privateNonceProvider;\n  private final PrivacyQueries privacyQueries;\n\n  protected PrivacyApiGroupJsonRpcMethods(\n      final BlockchainQueries blockchainQueries,\n      final ProtocolSchedule protocolSchedule,\n      final TransactionPool transactionPool,\n      final PrivacyParameters privacyParameters) {\n    this.blockchainQueries = blockchainQueries;\n    this.protocolSchedule = protocolSchedule;\n    this.transactionPool = transactionPool;\n    this.privacyParameters = privacyParameters;\n\n    this.privateNonceProvider =\n        new ChainHeadPrivateNonceProvider(\n            blockchainQueries.getBlockchain(),\n            privacyParameters.getPrivateStateRootResolver(),\n            privacyParameters.getPrivateWorldStateArchive());\n\n    this.privacyQueries =\n        new PrivacyQueries(blockchainQueries, privacyParameters.getPrivateWorldStateReader());\n  }\n\n  public BlockchainQueries getBlockchainQueries() {\n    return blockchainQueries;\n  }\n\n  public ProtocolSchedule getProtocolSchedule() {\n    return protocolSchedule;\n  }\n\n  public TransactionPool getTransactionPool() {\n    return transactionPool;\n  }\n\n  public PrivacyParameters getPrivacyParameters() {\n    return privacyParameters;\n  }\n\n  @Override\n  protected Map<String, JsonRpcMethod> create() {\n    final PrivateMarkerTransactionFactory markerTransactionFactory =\n        createPrivateMarkerTransactionFactory(\n            privacyParameters, blockchainQueries, transactionPool.getPendingTransactions());\n    final EnclavePublicKeyProvider enclavePublicProvider =\n        EnclavePublicKeyProvider.build(privacyParameters);\n    final PrivacyController privacyController = createPrivacyController(markerTransactionFactory);\n    return create(privacyController, enclavePublicProvider).entrySet().stream()\n        .collect(\n            Collectors.toMap(\n                Map.Entry::getKey,\n                entry -> createPrivacyMethod(privacyParameters, entry.getValue())));\n  }\n\n  protected abstract Map<String, JsonRpcMethod> create(\n      final PrivacyController privacyController,\n      final EnclavePublicKeyProvider enclavePublicKeyProvider);\n\n  private PrivateMarkerTransactionFactory createPrivateMarkerTransactionFactory(\n      final PrivacyParameters privacyParameters,\n      final BlockchainQueries blockchainQueries,\n      final PendingTransactions pendingTransactions) {\n\n    final Address privateContractAddress =\n        Address.privacyPrecompiled(privacyParameters.getPrivacyAddress());\n\n    if (privacyParameters.getSigningKeyPair().isPresent()) {\n      return new FixedKeySigningPrivateMarkerTransactionFactory(\n          privateContractAddress,\n          new LatestNonceProvider(blockchainQueries, pendingTransactions),\n          privacyParameters.getSigningKeyPair().get());\n    }\n    return new RandomSigningPrivateMarkerTransactionFactory(privateContractAddress);\n  }\n\n  private PrivacyController createPrivacyController(\n      final PrivateMarkerTransactionFactory markerTransactionFactory) {\n    final Optional<BigInteger> chainId = protocolSchedule.getChainId();\n    final DefaultPrivacyController defaultPrivacyController =\n        new DefaultPrivacyController(\n            getBlockchainQueries().getBlockchain(),\n            privacyParameters,\n            chainId,\n            markerTransactionFactory,\n            createPrivateTransactionSimulator(),\n            privateNonceProvider,\n            privacyParameters.getPrivateWorldStateReader());\n    return privacyParameters.isMultiTenancyEnabled()\n        ? new MultiTenancyPrivacyController(\n            defaultPrivacyController,\n            chainId,\n            privacyParameters.getEnclave(),\n            privacyParameters.isOnchainPrivacyGroupsEnabled())\n        : defaultPrivacyController;\n  }\n\n  PrivacyQueries getPrivacyQueries() {\n    return privacyQueries;\n  }\n\n  private JsonRpcMethod createPrivacyMethod(\n      final PrivacyParameters privacyParameters, final JsonRpcMethod rpcMethod) {\n    if (rpcMethod.getName().equals(RpcMethod.ETH_SEND_RAW_PRIVATE_TRANSACTION.getMethodName())) {\n      return rpcMethod;\n    } else if (privacyParameters.isEnabled() && privacyParameters.isMultiTenancyEnabled()) {\n      return new MultiTenancyRpcMethodDecorator(rpcMethod);\n    } else if (!privacyParameters.isEnabled()) {\n      return new DisabledPrivacyRpcMethod(rpcMethod.getName());\n    } else {\n      return rpcMethod;\n    }\n  }\n\n  private PrivateTransactionSimulator createPrivateTransactionSimulator() {\n    return new PrivateTransactionSimulator(\n        getBlockchainQueries().getBlockchain(),\n        getBlockchainQueries().getWorldStateArchive(),\n        getProtocolSchedule(),\n        getPrivacyParameters());\n  }\n}\n", "idx": 1, "id": 24434, "msg": "can this be removed now?", "proj": "hyperledger-besu", "lang": "java"}
{"patch": "@@ -84,6 +84,19 @@ describe \"apply\" do\n         resources = result[0]['result']['report']['resource_statuses']\n         expect(resources).to include('Notify[hello world]')\n       end\n+\n+      it 'applies the deferred type' do\n+        result = run_cli_json(%w[plan run basic::defer] + config_flags)\n+        expect(result).not_to include('kind')\n+        expect(result[0]['status']).to eq('success')\n+        resources = result[0]['result']['report']['resource_statuses']\n+\n+        local_pid = resources['Notify[local pid]']['events'][0]['desired_value'][/(\\d+)/, 1]\n+        raise 'local pid was not found' if local_pid.nil?\n+        remote_pid = resources['Notify[remote pid]']['events'][0]['desired_value'][/(\\d+)/, 1]\n+        raise 'remote pid was not found' if remote_pid.nil?\n+        expect(local_pid).not_to eq(remote_pid)\n+      end\n     end\n   end\n end", "y": 1, "oldf": "# frozen_string_literal: true\n\nrequire 'spec_helper'\nrequire 'bolt_spec/conn'\nrequire 'bolt_spec/files'\nrequire 'bolt_spec/integration'\nrequire 'bolt_spec/run'\n\ndescribe \"apply\" do\n  include BoltSpec::Conn\n  include BoltSpec::Files\n  include BoltSpec::Integration\n  include BoltSpec::Run\n\n  let(:modulepath) { File.join(__dir__, '../fixtures/apply') }\n  let(:config_flags) { %W[--format json --nodes #{uri} --password #{password} --modulepath #{modulepath}] + tflags }\n\n  describe 'over ssh', ssh: true do\n    let(:uri) { conn_uri('ssh') }\n    let(:password) { conn_info('ssh')[:password] }\n    let(:tflags) { %W[--no-host-key-check --run-as root --sudo-password #{password}] }\n\n    def root_config\n      { 'modulepath' => File.join(__dir__, '../fixtures/apply'),\n        'ssh' => {\n          'run-as' => 'root',\n          'sudo-password' => conn_info('ssh')[:password],\n          'host-key-check' => false\n        } }\n    end\n\n    after(:all) do\n      # TODO: Extract into test helper if needed in more files\n      uri = conn_uri('ssh')\n      inventory_data = conn_inventory\n      config_data = root_config\n      uninstall = '/opt/puppetlabs/bin/puppet resource package puppet-agent ensure=absent'\n      run_command(uninstall, uri, config: config_data, inventory: inventory_data)\n    end\n\n    context \"when installing puppet\" do\n      before(:each) do\n        uninstall = '/opt/puppetlabs/bin/puppet resource package puppet-agent ensure=absent'\n        run_cli_json(%W[command run #{uninstall}] + config_flags)\n      end\n\n      it 'succeeds when run twice' do\n        result = run_cli_json(%w[plan run prep] + config_flags)\n        expect(result).not_to include('kind')\n        expect(result.count).to eq(1)\n        expect(result[0]['status']).to eq('success')\n        report = result[0]['result']['report']\n        expect(report['resource_statuses']).to include(\"Notify[Hello #{conn_info('ssh')[:host]}]\")\n\n        result = run_cli_json(%w[plan run prep] + config_flags)\n        expect(result.count).to eq(1)\n        expect(result[0]['status']).to eq('success')\n        report = result[0]['result']['report']\n        expect(report['resource_statuses']).to include(\"Notify[Hello #{conn_info('ssh')[:host]}]\")\n      end\n    end\n\n    context \"with a puppet_agent installed\" do\n      before(:all) do\n        # TODO: Extract into test helper if needed in more files\n        uri = conn_uri('ssh')\n        inventory_data = conn_inventory\n        config_data = root_config\n        run_task('puppet_agent::install', uri, config: config_data, inventory: inventory_data)\n      end\n\n      it 'errors when there are resource failures' do\n        result = run_cli_json(%w[plan run basic::failure] + config_flags, rescue_exec: true)\n        expect(result).to include('kind' => 'bolt/apply-failure')\n        error = result['details']['result_set'][0]['result']['_error']\n        expect(error['kind']).to eq('bolt/resource-failure')\n        expect(error['msg']).to match(/Resources failed to apply/)\n      end\n\n      it 'applies a notify' do\n        result = run_cli_json(%w[plan run basic::class] + config_flags)\n        expect(result).not_to include('kind')\n        expect(result[0]).to include('status' => 'success')\n        resources = result[0]['result']['report']['resource_statuses']\n        expect(resources).to include('Notify[hello world]')\n      end\n    end\n  end\nend\n", "idx": 1, "id": 9437, "msg": "`expect(resources['Notify[local pid]']['events'][0]['desired_value']).to match(/(\\d+)/)` seems clearer.", "proj": "puppetlabs-bolt", "lang": "rb"}
{"patch": "@@ -1,19 +1,3 @@\n-/*\n-Copyright 2018 The Kubernetes Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-*/\n-\n package resource\n \n import (", "y": 1, "oldf": "/*\nCopyright 2018 The Kubernetes Authors.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage resource\n\nimport (\n\t\"io/ioutil\"\n\n\tlog \"github.com/sirupsen/logrus\"\n\n\t\"k8s.io/client-go/rest\"\n\tconfigapi \"k8s.io/client-go/tools/clientcmd/api\"\n)\n\nconst (\n\ttokenFile = \"/var/run/secrets/kubernetes.io/serviceaccount/token\"\n)\n\n// GenerateClientConfigFromRESTConfig generates a new kubeconfig using a given rest.Config.\n// The rest.Config may come from in-cluster config (as in a pod) or an existing kubeconfig.\nfunc GenerateClientConfigFromRESTConfig(name string, restConfig *rest.Config) *configapi.Config {\n\tcfg := &configapi.Config{\n\t\tKind:           \"Config\",\n\t\tAPIVersion:     \"v1\",\n\t\tClusters:       map[string]*configapi.Cluster{},\n\t\tAuthInfos:      map[string]*configapi.AuthInfo{},\n\t\tContexts:       map[string]*configapi.Context{},\n\t\tCurrentContext: name,\n\t}\n\n\tcluster := &configapi.Cluster{\n\t\tServer:                   restConfig.Host,\n\t\tInsecureSkipTLSVerify:    restConfig.Insecure,\n\t\tCertificateAuthority:     restConfig.CAFile,\n\t\tCertificateAuthorityData: restConfig.CAData,\n\t}\n\n\tauthInfo := &configapi.AuthInfo{\n\t\tClientCertificate:     restConfig.CertFile,\n\t\tClientCertificateData: restConfig.CertData,\n\t\tClientKey:             restConfig.KeyFile,\n\t\tClientKeyData:         restConfig.KeyData,\n\t\tToken:                 restConfig.BearerToken,\n\t\tUsername:              restConfig.Username,\n\t\tPassword:              restConfig.Password,\n\t}\n\n\tif restConfig.WrapTransport != nil && len(restConfig.BearerToken) == 0 {\n\t\ttoken, err := ioutil.ReadFile(tokenFile)\n\t\tif err != nil {\n\t\t\tlog.WithError(err).Warning(\"empty bearer token and cannot read token file\")\n\t\t} else {\n\t\t\tauthInfo.Token = string(token)\n\t\t}\n\t}\n\n\tcontext := &configapi.Context{\n\t\tCluster:  name,\n\t\tAuthInfo: name,\n\t}\n\n\tcfg.Clusters[name] = cluster\n\tcfg.AuthInfos[name] = authInfo\n\tcfg.Contexts[name] = context\n\n\treturn cfg\n}\n", "idx": 1, "id": 6592, "msg": "Was this our code @csrwng", "proj": "openshift-hive", "lang": "go"}
{"patch": "@@ -257,6 +257,7 @@ public class TransactionPool implements BlockAddedObserver {\n               transaction.getGasLimit(), chainHeadBlockHeader.getGasLimit()));\n     }\n \n+    // TODO: this is where we would use the private state to do the validation against\n     return protocolContext\n         .getWorldStateArchive()\n         .get(chainHeadBlockHeader.getStateRoot())", "y": 1, "oldf": "/*\n * Copyright ConsenSys AG.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n * the License. You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n * an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n * specific language governing permissions and limitations under the License.\n *\n * SPDX-License-Identifier: Apache-2.0\n */\npackage org.hyperledger.besu.ethereum.eth.transactions;\n\nimport static java.util.Collections.singletonList;\nimport static org.apache.logging.log4j.LogManager.getLogger;\nimport static org.hyperledger.besu.ethereum.transaction.TransactionInvalidReason.CHAIN_HEAD_WORLD_STATE_NOT_AVAILABLE;\n\nimport org.hyperledger.besu.config.experimental.ExperimentalEIPs;\nimport org.hyperledger.besu.ethereum.ProtocolContext;\nimport org.hyperledger.besu.ethereum.chain.BlockAddedEvent;\nimport org.hyperledger.besu.ethereum.chain.BlockAddedObserver;\nimport org.hyperledger.besu.ethereum.chain.MutableBlockchain;\nimport org.hyperledger.besu.ethereum.core.Account;\nimport org.hyperledger.besu.ethereum.core.BlockHeader;\nimport org.hyperledger.besu.ethereum.core.Hash;\nimport org.hyperledger.besu.ethereum.core.Transaction;\nimport org.hyperledger.besu.ethereum.core.Wei;\nimport org.hyperledger.besu.ethereum.core.fees.BaseFee;\nimport org.hyperledger.besu.ethereum.core.fees.EIP1559;\nimport org.hyperledger.besu.ethereum.core.fees.TransactionPriceCalculator;\nimport org.hyperledger.besu.ethereum.eth.EthProtocol;\nimport org.hyperledger.besu.ethereum.eth.manager.EthContext;\nimport org.hyperledger.besu.ethereum.eth.manager.EthPeer;\nimport org.hyperledger.besu.ethereum.eth.sync.state.SyncState;\nimport org.hyperledger.besu.ethereum.eth.transactions.PendingTransactions.TransactionAddedStatus;\nimport org.hyperledger.besu.ethereum.mainnet.MainnetTransactionValidator;\nimport org.hyperledger.besu.ethereum.mainnet.ProtocolSchedule;\nimport org.hyperledger.besu.ethereum.mainnet.TransactionValidationParams;\nimport org.hyperledger.besu.ethereum.mainnet.ValidationResult;\nimport org.hyperledger.besu.ethereum.transaction.TransactionInvalidReason;\nimport org.hyperledger.besu.metrics.BesuMetricCategory;\nimport org.hyperledger.besu.plugin.services.MetricsSystem;\nimport org.hyperledger.besu.plugin.services.metrics.Counter;\nimport org.hyperledger.besu.plugin.services.metrics.LabelledMetric;\n\nimport java.util.Collection;\nimport java.util.HashSet;\nimport java.util.Optional;\nimport java.util.Set;\n\nimport org.apache.logging.log4j.Logger;\n\n/**\n * Maintains the set of pending transactions received from JSON-RPC or other nodes. Transactions are\n * removed automatically when they are included in a block on the canonical chain and re-added if a\n * re-org removes them from the canonical chain again.\n *\n * <p>This class is safe for use across multiple threads.\n */\npublic class TransactionPool implements BlockAddedObserver {\n\n  private static final Logger LOG = getLogger();\n\n  private static final long SYNC_TOLERANCE = 100L;\n  private static final String REMOTE = \"remote\";\n  private static final String LOCAL = \"local\";\n  private final PendingTransactions pendingTransactions;\n  private final ProtocolSchedule protocolSchedule;\n  private final ProtocolContext protocolContext;\n  private final TransactionBatchAddedListener transactionBatchAddedListener;\n  private final Optional<TransactionBatchAddedListener> pendingTransactionBatchAddedListener;\n  private final SyncState syncState;\n  private final Wei minTransactionGasPrice;\n  private final LabelledMetric<Counter> duplicateTransactionCounter;\n  private final PeerTransactionTracker peerTransactionTracker;\n  private final Optional<PeerPendingTransactionTracker> maybePeerPendingTransactionTracker;\n  private final Optional<EIP1559> eip1559;\n  private final TransactionPriceCalculator frontierPriceCalculator =\n      TransactionPriceCalculator.frontier();\n  private final TransactionPriceCalculator eip1559PriceCalculator =\n      TransactionPriceCalculator.eip1559();\n  private final TransactionPoolConfiguration configuration;\n\n  public TransactionPool(\n      final PendingTransactions pendingTransactions,\n      final ProtocolSchedule protocolSchedule,\n      final ProtocolContext protocolContext,\n      final TransactionBatchAddedListener transactionBatchAddedListener,\n      final Optional<TransactionBatchAddedListener> pendingTransactionBatchAddedListener,\n      final SyncState syncState,\n      final EthContext ethContext,\n      final PeerTransactionTracker peerTransactionTracker,\n      final Optional<PeerPendingTransactionTracker> maybePeerPendingTransactionTracker,\n      final Wei minTransactionGasPrice,\n      final MetricsSystem metricsSystem,\n      final Optional<EIP1559> eip1559,\n      final TransactionPoolConfiguration configuration) {\n    this.pendingTransactions = pendingTransactions;\n    this.protocolSchedule = protocolSchedule;\n    this.protocolContext = protocolContext;\n    this.transactionBatchAddedListener = transactionBatchAddedListener;\n    this.pendingTransactionBatchAddedListener = pendingTransactionBatchAddedListener;\n    this.syncState = syncState;\n    this.peerTransactionTracker = peerTransactionTracker;\n    this.maybePeerPendingTransactionTracker = maybePeerPendingTransactionTracker;\n    this.minTransactionGasPrice = minTransactionGasPrice;\n    this.eip1559 = eip1559;\n    this.configuration = configuration;\n\n    duplicateTransactionCounter =\n        metricsSystem.createLabelledCounter(\n            BesuMetricCategory.TRANSACTION_POOL,\n            \"transactions_duplicates_total\",\n            \"Total number of duplicate transactions received\",\n            \"source\");\n\n    ethContext.getEthPeers().subscribeConnect(this::handleConnect);\n  }\n\n  void handleConnect(final EthPeer peer) {\n    pendingTransactions\n        .getLocalTransactions()\n        .forEach(transaction -> peerTransactionTracker.addToPeerSendQueue(peer, transaction));\n\n    maybePeerPendingTransactionTracker\n        .filter(\n            peerPendingTransactionTracker ->\n                peerPendingTransactionTracker.isPeerSupported(peer, EthProtocol.ETH65))\n        .ifPresent(\n            peerPendingTransactionTracker ->\n                pendingTransactions\n                    .getNewPooledHashes()\n                    .forEach(hash -> peerPendingTransactionTracker.addToPeerSendQueue(peer, hash)));\n  }\n\n  public boolean addTransactionHash(final Hash transactionHash) {\n    return pendingTransactions.addTransactionHash(transactionHash);\n  }\n\n  public ValidationResult<TransactionInvalidReason> addLocalTransaction(\n      final Transaction transaction) {\n    if (transaction.isFrontierTransaction()\n        && (!ExperimentalEIPs.eip1559Enabled || this.eip1559.isEmpty())) {\n      final Wei transactionGasPrice = minTransactionGasPrice(transaction);\n      if (transactionGasPrice.compareTo(minTransactionGasPrice) < 0) {\n        return ValidationResult.invalid(TransactionInvalidReason.GAS_PRICE_TOO_LOW);\n      }\n      if (!configuration.getTxFeeCap().isZero()\n          && transactionGasPrice.compareTo(configuration.getTxFeeCap()) > 0) {\n        return ValidationResult.invalid(TransactionInvalidReason.TX_FEECAP_EXCEEDED);\n      }\n    }\n\n    final ValidationResult<TransactionInvalidReason> validationResult =\n        validateTransaction(transaction);\n    if (validationResult.isValid()) {\n      final TransactionAddedStatus transactionAddedStatus =\n          pendingTransactions.addLocalTransaction(transaction);\n      if (!transactionAddedStatus.equals(TransactionAddedStatus.ADDED)) {\n        duplicateTransactionCounter.labels(LOCAL).inc();\n        return ValidationResult.invalid(transactionAddedStatus.getInvalidReason().orElseThrow());\n      }\n      final Collection<Transaction> txs = singletonList(transaction);\n      transactionBatchAddedListener.onTransactionsAdded(txs);\n      pendingTransactionBatchAddedListener.ifPresent(it -> it.onTransactionsAdded(txs));\n    }\n\n    return validationResult;\n  }\n\n  public void addRemoteTransactions(final Collection<Transaction> transactions) {\n    if (!syncState.isInSync(SYNC_TOLERANCE)) {\n      return;\n    }\n    final Set<Transaction> addedTransactions = new HashSet<>();\n    for (final Transaction transaction : transactions) {\n      pendingTransactions.tryEvictTransactionHash(transaction.getHash());\n      if (pendingTransactions.containsTransaction(transaction.getHash())) {\n        // We already have this transaction, don't even validate it.\n        duplicateTransactionCounter.labels(REMOTE).inc();\n        continue;\n      }\n      final Wei transactionGasPrice = minTransactionGasPrice(transaction);\n      if (transactionGasPrice.compareTo(minTransactionGasPrice) < 0) {\n        continue;\n      }\n      final ValidationResult<TransactionInvalidReason> validationResult =\n          validateTransaction(transaction);\n      if (validationResult.isValid()) {\n        final boolean added = pendingTransactions.addRemoteTransaction(transaction);\n        if (added) {\n          addedTransactions.add(transaction);\n        } else {\n          duplicateTransactionCounter.labels(REMOTE).inc();\n        }\n      } else {\n        LOG.trace(\n            \"Validation failed ({}) for transaction {}. Discarding.\",\n            validationResult.getInvalidReason(),\n            transaction);\n      }\n    }\n    if (!addedTransactions.isEmpty()) {\n      transactionBatchAddedListener.onTransactionsAdded(addedTransactions);\n    }\n  }\n\n  public long subscribePendingTransactions(final PendingTransactionListener listener) {\n    return pendingTransactions.subscribePendingTransactions(listener);\n  }\n\n  public void unsubscribePendingTransactions(final long id) {\n    pendingTransactions.unsubscribePendingTransactions(id);\n  }\n\n  public long subscribeDroppedTransactions(final PendingTransactionDroppedListener listener) {\n    return pendingTransactions.subscribeDroppedTransactions(listener);\n  }\n\n  public void unsubscribeDroppedTransactions(final long id) {\n    pendingTransactions.unsubscribeDroppedTransactions(id);\n  }\n\n  @Override\n  public void onBlockAdded(final BlockAddedEvent event) {\n    event.getAddedTransactions().forEach(pendingTransactions::transactionAddedToBlock);\n    addRemoteTransactions(event.getRemovedTransactions());\n  }\n\n  private MainnetTransactionValidator getTransactionValidator() {\n    return protocolSchedule\n        .getByBlockNumber(protocolContext.getBlockchain().getChainHeadBlockNumber())\n        .getTransactionValidator();\n  }\n\n  public PendingTransactions getPendingTransactions() {\n    return pendingTransactions;\n  }\n\n  private ValidationResult<TransactionInvalidReason> validateTransaction(\n      final Transaction transaction) {\n    final BlockHeader chainHeadBlockHeader = getChainHeadBlockHeader();\n    final ValidationResult<TransactionInvalidReason> basicValidationResult =\n        getTransactionValidator().validate(transaction, chainHeadBlockHeader.getBaseFee());\n    if (!basicValidationResult.isValid()) {\n      return basicValidationResult;\n    }\n\n    if (transaction.getGasLimit() > chainHeadBlockHeader.getGasLimit()) {\n      return ValidationResult.invalid(\n          TransactionInvalidReason.EXCEEDS_BLOCK_GAS_LIMIT,\n          String.format(\n              \"Transaction gas limit of %s exceeds block gas limit of %s\",\n              transaction.getGasLimit(), chainHeadBlockHeader.getGasLimit()));\n    }\n\n    return protocolContext\n        .getWorldStateArchive()\n        .get(chainHeadBlockHeader.getStateRoot())\n        .map(\n            worldState -> {\n              final Account senderAccount = worldState.get(transaction.getSender());\n              return getTransactionValidator()\n                  .validateForSender(\n                      transaction, senderAccount, TransactionValidationParams.transactionPool());\n            })\n        .orElseGet(() -> ValidationResult.invalid(CHAIN_HEAD_WORLD_STATE_NOT_AVAILABLE));\n  }\n\n  public Optional<Transaction> getTransactionByHash(final Hash hash) {\n    return pendingTransactions.getTransactionByHash(hash);\n  }\n\n  private BlockHeader getChainHeadBlockHeader() {\n    final MutableBlockchain blockchain = protocolContext.getBlockchain();\n    return blockchain.getBlockHeader(blockchain.getChainHeadHash()).get();\n  }\n\n  public interface TransactionBatchAddedListener {\n\n    void onTransactionsAdded(Iterable<Transaction> transactions);\n  }\n\n  private Wei minTransactionGasPrice(final Transaction transaction) {\n    // EIP-1559 enablement guard block\n    if (!ExperimentalEIPs.eip1559Enabled || this.eip1559.isEmpty()) {\n      return frontierPriceCalculator.price(transaction, Optional.empty());\n    }\n\n    final BlockHeader chainHeadBlockHeader = getChainHeadBlockHeader();\n    // Compute transaction price using EIP-1559 rules if chain head is after fork\n    if (this.eip1559.get().isEIP1559(chainHeadBlockHeader.getNumber())) {\n      return BaseFee.minTransactionPriceInNextBlock(\n          transaction, eip1559PriceCalculator, chainHeadBlockHeader::getBaseFee);\n    } else { // Use frontier rules otherwise\n      return frontierPriceCalculator.price(transaction, Optional.empty());\n    }\n  }\n}\n", "idx": 1, "id": 23904, "msg": "This TODO isn't related to this change. We should remove it.", "proj": "hyperledger-besu", "lang": "java"}
