{"patch": "@@ -87,9 +87,9 @@ public class HiveTablesTest extends HiveTableBaseTest {\n \n   @Test(expected = CommitFailedException.class)\n   public void testFailure() throws TException {\n-    org.apache.iceberg.Table icebergTable = new HiveTables(hiveConf).load(DB_NAME, TABLE_NAME);\n-    final Table table = metastoreClient.getTable(DB_NAME, TABLE_NAME);\n-    final String dummyLocation = \"dummylocation\";\n+    Table icebergTable = tables.load(DB_NAME, TABLE_NAME);\n+    org.apache.hadoop.hive.metastore.api.Table table = metastoreClient.getTable(DB_NAME, TABLE_NAME);\n+    String dummyLocation = \"dummylocation\";\n     table.getParameters().put(METADATA_LOCATION_PROP, dummyLocation);\n     metastoreClient.alter_table(DB_NAME, TABLE_NAME, table);\n     icebergTable.updateSchema()", "y": 0, "oldf": "/*\n * Copyright 2017 Netflix, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.apache.iceberg.hive;\n\nimport com.google.common.util.concurrent.MoreExecutors;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.UUID;\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\nimport java.util.concurrent.ThreadPoolExecutor;\nimport java.util.concurrent.TimeUnit;\nimport java.util.stream.Collectors;\nimport org.apache.hadoop.hive.metastore.api.Table;\nimport org.apache.iceberg.DataFile;\nimport org.apache.iceberg.DataFiles;\nimport org.apache.iceberg.FileFormat;\nimport org.apache.iceberg.exceptions.CommitFailedException;\nimport org.apache.iceberg.types.Types;\nimport org.apache.iceberg.util.Tasks;\nimport org.apache.thrift.TException;\nimport org.junit.Assert;\nimport org.junit.Test;\n\nimport static org.apache.iceberg.BaseMetastoreTableOperations.ICEBERG_TABLE_TYPE_VALUE;\nimport static org.apache.iceberg.BaseMetastoreTableOperations.METADATA_LOCATION_PROP;\nimport static org.apache.iceberg.BaseMetastoreTableOperations.TABLE_TYPE_PROP;\n\npublic class HiveTablesTest extends HiveTableBaseTest {\n  @Test\n  public void testCreate() throws TException {\n    // Table should be created in hive metastore\n    final Table table = metastoreClient.getTable(DB_NAME, TABLE_NAME);\n\n    // check parameters are in expected state\n    final Map<String, String> parameters = table.getParameters();\n    Assert.assertNotNull(parameters);\n    Assert.assertTrue(ICEBERG_TABLE_TYPE_VALUE.equalsIgnoreCase(parameters.get(TABLE_TYPE_PROP)));\n    Assert.assertTrue(ICEBERG_TABLE_TYPE_VALUE.equalsIgnoreCase(table.getTableType()));\n\n    // Ensure the table is pointing to empty location\n    Assert.assertEquals(getTableLocation(TABLE_NAME) , table.getSd().getLocation());\n\n    // Ensure it is stored as unpartitioned table in hive.\n    Assert.assertEquals(0 , table.getPartitionKeysSize());\n\n    // Only 1 snapshotFile Should exist and no manifests should exist\n    Assert.assertEquals(1, metadataVersionFiles(TABLE_NAME).size());\n    Assert.assertEquals(0, manifestFiles(TABLE_NAME).size());\n\n    final org.apache.iceberg.Table icebergTable = new HiveTables(hiveConf).load(DB_NAME, TABLE_NAME);\n    // Iceberg schema should match the loaded table\n    Assert.assertEquals(schema.asStruct(), icebergTable.schema().asStruct());\n  }\n\n  @Test\n  public void testExistingTableUpdate() throws TException {\n    org.apache.iceberg.Table icebergTable = new HiveTables(hiveConf).load(DB_NAME, TABLE_NAME);\n    // add a column\n    icebergTable.updateSchema().addColumn(\"data\", Types.LongType.get()).commit();\n\n    icebergTable = new HiveTables(hiveConf).load(DB_NAME, TABLE_NAME);\n\n    // Only 2 snapshotFile Should exist and no manifests should exist\n    Assert.assertEquals(2, metadataVersionFiles(TABLE_NAME).size());\n    Assert.assertEquals(0, manifestFiles(TABLE_NAME).size());\n    Assert.assertEquals(altered.asStruct(), icebergTable.schema().asStruct());\n\n    final Table table = metastoreClient.getTable(DB_NAME, TABLE_NAME);\n    final List<String> hiveColumns = table.getSd().getCols().stream().map(f -> f.getName()).collect(Collectors.toList());\n    final List<String> icebergColumns = altered.columns().stream().map(f -> f.name()).collect(Collectors.toList());\n    Assert.assertEquals(icebergColumns, hiveColumns);\n  }\n\n  @Test(expected = CommitFailedException.class)\n  public void testFailure() throws TException {\n    org.apache.iceberg.Table icebergTable = new HiveTables(hiveConf).load(DB_NAME, TABLE_NAME);\n    final Table table = metastoreClient.getTable(DB_NAME, TABLE_NAME);\n    final String dummyLocation = \"dummylocation\";\n    table.getParameters().put(METADATA_LOCATION_PROP, dummyLocation);\n    metastoreClient.alter_table(DB_NAME, TABLE_NAME, table);\n    icebergTable.updateSchema()\n            .addColumn(\"data\", Types.LongType.get())\n            .commit();\n  }\n\n  @Test\n  public void testConcurrentFastAppends() {\n    HiveTables hiveTables = new HiveTables(hiveConf);\n    org.apache.iceberg.Table icebergTable = hiveTables.load(DB_NAME, TABLE_NAME);\n    org.apache.iceberg.Table anotherIcebergTable = hiveTables.load(DB_NAME, TABLE_NAME);\n\n    String fileName = UUID.randomUUID().toString();\n    DataFile file = DataFiles.builder(icebergTable.spec())\n      .withPath(FileFormat.PARQUET.addExtension(fileName))\n      .withRecordCount(2)\n      .withFileSizeInBytes(0)\n      .build();\n\n    ExecutorService executorService = MoreExecutors.getExitingExecutorService(\n      (ThreadPoolExecutor) Executors.newFixedThreadPool(2));\n\n    Tasks.foreach(icebergTable, anotherIcebergTable)\n      .stopOnFailure().throwFailureWhenFinished()\n      .executeWith(executorService)\n      .run(table -> {\n        for (int numCommittedFiles = 0; numCommittedFiles < 10; numCommittedFiles++) {\n          long commitStartTime = System.currentTimeMillis();\n          table.newFastAppend().appendFile(file).commit();\n          long commitEndTime = System.currentTimeMillis();\n          long commitDuration = commitEndTime - commitStartTime;\n          try {\n            TimeUnit.MILLISECONDS.sleep(200 - commitDuration);\n          } catch (InterruptedException e) {\n            throw new RuntimeException(e);\n          }\n        }\n      });\n\n    icebergTable.refresh();\n    Assert.assertEquals(20, icebergTable.currentSnapshot().manifests().size());\n  }\n}\n", "idx": 4, "id": 13319, "msg": "", "proj": "apache-iceberg", "lang": "java"}
{"patch": "@@ -22,10 +22,14 @@ type LocationCache struct {\n \tendpoints sync.Map\n \t// servicePods is a map, key is namespace/serviceName, value is []v1.Pod\n \tservicePods sync.Map\n+\t// persistentvolume is a map, key is namespace/persistentvolumeName, value is nodeName\n+\tpersistentvolumeNode sync.Map\n+\t// persistentvolumeclaim is a map, key is namespace/persistentvolumeclaimName, value is nodeName\n+\tpersistentvolumeclaimNode sync.Map\n }\n \n-// PodConfigMapsAndSecrets return configmaps and secrets used by pod\n-func (lc *LocationCache) PodConfigMapsAndSecrets(pod v1.Pod) (configMaps, secrets []string) {\n+// PodConfigMapsAndSecretsAndPersistentvolumeclaims return configmaps and secrets and  Persistentvolumeclaims  used by pod\n+func (lc *LocationCache) PodConfigMapsAndSecretsAndPersistentvolumeclaims(pod v1.Pod) (configMaps, secrets, persistentvolumeclaims []string) {\n \tfor _, v := range pod.Spec.Volumes {\n \t\tif v.ConfigMap != nil {\n \t\t\tconfigMaps = append(configMaps, v.ConfigMap.Name)", "y": 0, "oldf": "package manager\n\nimport (\n\t\"fmt\"\n\t\"reflect\"\n\t\"sync\"\n\n\t\"k8s.io/api/core/v1\"\n)\n\n// LocationCache cache the map of node, pod, configmap, secret\ntype LocationCache struct {\n\t// EdgeNodes is a map, key is nodeName, value is Status\n\tEdgeNodes sync.Map\n\t// configMapNode is a map, key is namespace/configMapName, value is nodeName\n\tconfigMapNode sync.Map\n\t// secretNode is a map, key is namespace/secretName, value is nodeName\n\tsecretNode sync.Map\n\t// services is a map, key is namespace/serviceName, value is v1.Service\n\tservices sync.Map\n\t// endpoints is a map, key is namespace/endpointsName, value is v1.endpoints\n\tendpoints sync.Map\n\t// servicePods is a map, key is namespace/serviceName, value is []v1.Pod\n\tservicePods sync.Map\n}\n\n// PodConfigMapsAndSecrets return configmaps and secrets used by pod\nfunc (lc *LocationCache) PodConfigMapsAndSecrets(pod v1.Pod) (configMaps, secrets []string) {\n\tfor _, v := range pod.Spec.Volumes {\n\t\tif v.ConfigMap != nil {\n\t\t\tconfigMaps = append(configMaps, v.ConfigMap.Name)\n\t\t}\n\t\tif v.Secret != nil {\n\t\t\tsecrets = append(secrets, v.Secret.SecretName)\n\t\t}\n\t}\n\t// used by envs\n\tfor _, s := range pod.Spec.Containers {\n\t\tfor _, ef := range s.EnvFrom {\n\t\t\tif ef.ConfigMapRef != nil {\n\t\t\t\tconfigMaps = append(configMaps, ef.ConfigMapRef.Name)\n\t\t\t}\n\t\t\tif ef.SecretRef != nil {\n\t\t\t\tsecrets = append(secrets, ef.SecretRef.Name)\n\t\t\t}\n\t\t}\n\t}\n\t// used by ImagePullSecrets\n\tfor _, s := range pod.Spec.ImagePullSecrets {\n\t\tsecrets = append(secrets, s.Name)\n\t}\n\treturn\n}\n\nfunc (lc *LocationCache) newNodes(oldNodes []string, node string) []string {\n\tfor _, n := range oldNodes {\n\t\tif n == node {\n\t\t\treturn oldNodes\n\t\t}\n\t}\n\treturn append(oldNodes, node)\n}\n\n// AddOrUpdatePod add pod to node, pod to configmap, configmap to pod, pod to secret, secret to pod relation\nfunc (lc *LocationCache) AddOrUpdatePod(pod v1.Pod) {\n\tconfigMaps, secrets := lc.PodConfigMapsAndSecrets(pod)\n\tfor _, c := range configMaps {\n\t\tconfigMapKey := fmt.Sprintf(\"%s/%s\", pod.Namespace, c)\n\t\t// update configMapPod\n\t\tvalue, ok := lc.configMapNode.Load(configMapKey)\n\t\tvar newNodes []string\n\t\tif ok {\n\t\t\tnodes, _ := value.([]string)\n\t\t\tnewNodes = lc.newNodes(nodes, pod.Spec.NodeName)\n\t\t} else {\n\t\t\tnewNodes = []string{pod.Spec.NodeName}\n\t\t}\n\t\tlc.configMapNode.Store(configMapKey, newNodes)\n\t}\n\n\tfor _, s := range secrets {\n\t\tsecretKey := fmt.Sprintf(\"%s/%s\", pod.Namespace, s)\n\t\t// update secretPod\n\t\tvalue, ok := lc.secretNode.Load(secretKey)\n\t\tvar newNodes []string\n\t\tif ok {\n\t\t\tnodes, _ := value.([]string)\n\t\t\tnewNodes = lc.newNodes(nodes, pod.Spec.NodeName)\n\t\t} else {\n\t\t\tnewNodes = []string{pod.Spec.NodeName}\n\t\t}\n\t\tlc.secretNode.Store(secretKey, newNodes)\n\t}\n}\n\n// ConfigMapNodes return all nodes which deploy pod on with configmap\nfunc (lc *LocationCache) ConfigMapNodes(namespace, name string) (nodes []string) {\n\tconfigMapKey := fmt.Sprintf(\"%s/%s\", namespace, name)\n\tvalue, ok := lc.configMapNode.Load(configMapKey)\n\tif ok {\n\t\tif nodes, ok := value.([]string); ok {\n\t\t\treturn nodes\n\t\t}\n\t}\n\treturn\n}\n\n// SecretNodes return all nodes which deploy pod on with secret\nfunc (lc *LocationCache) SecretNodes(namespace, name string) (nodes []string) {\n\tsecretKey := fmt.Sprintf(\"%s/%s\", namespace, name)\n\tvalue, ok := lc.secretNode.Load(secretKey)\n\tif ok {\n\t\tif nodes, ok := value.([]string); ok {\n\t\t\treturn nodes\n\t\t}\n\t}\n\treturn\n}\n\n//IsEdgeNode checks weather node is edge node or not\nfunc (lc *LocationCache) IsEdgeNode(nodeName string) bool {\n\t_, ok := lc.EdgeNodes.Load(nodeName)\n\treturn ok\n}\n\n//\nfunc (lc *LocationCache) GetNodeStatus(nodeName string) (string, bool) {\n\tvalue, ok := lc.EdgeNodes.Load(nodeName)\n\tstatus, ok := value.(string)\n\treturn status, ok\n}\n\n// UpdateEdgeNode is to maintain edge nodes name upto-date by querying kubernetes client\nfunc (lc *LocationCache) UpdateEdgeNode(nodeName string, status string) {\n\tlc.EdgeNodes.Store(nodeName, status)\n}\n\n// DeleteConfigMap from cache\nfunc (lc *LocationCache) DeleteConfigMap(namespace, name string) {\n\tlc.configMapNode.Delete(fmt.Sprintf(\"%s/%s\", namespace, name))\n}\n\n// DeleteSecret from cache\nfunc (lc *LocationCache) DeleteSecret(namespace, name string) {\n\tlc.secretNode.Delete(fmt.Sprintf(\"%s/%s\", namespace, name))\n}\n\n// DeleteNode from cache\nfunc (lc *LocationCache) DeleteNode(nodeName string) {\n\tlc.EdgeNodes.Delete(nodeName)\n}\n\n// AddOrUpdateService in cache\nfunc (lc *LocationCache) AddOrUpdateService(service v1.Service) {\n\tlc.services.Store(fmt.Sprintf(\"%s/%s\", service.Namespace, service.Name), service)\n}\n\n// DeleteService from cache\nfunc (lc *LocationCache) DeleteService(service v1.Service) {\n\tlc.services.Delete(fmt.Sprintf(\"%s/%s\", service.Namespace, service.Name))\n}\n\n// GetAllServices from cache\nfunc (lc *LocationCache) GetAllServices() []v1.Service {\n\tservices := []v1.Service{}\n\tlc.services.Range(func(key interface{}, value interface{}) bool {\n\t\tsvc, ok := value.(v1.Service)\n\t\tif ok {\n\t\t\tservices = append(services, svc)\n\t\t}\n\t\treturn true\n\t})\n\treturn services\n}\n\n// GetService from cache\nfunc (lc *LocationCache) GetService(name string) (v1.Service, bool) {\n\tvalue, ok := lc.services.Load(name)\n\tif !ok {\n\t\treturn v1.Service{}, ok\n\t}\n\tsvc, ok := value.(v1.Service)\n\treturn svc, ok\n}\n\n// AddOrUpdateServicePods in cache\nfunc (lc *LocationCache) AddOrUpdateServicePods(name string, value []v1.Pod) {\n\tlc.servicePods.Store(name, value)\n}\n\n// DeleteServicePods from cache\nfunc (lc *LocationCache) DeleteServicePods(endpoints v1.Endpoints) {\n\tlc.servicePods.Delete(fmt.Sprintf(\"%s/%s\", endpoints.Namespace, endpoints.Name))\n}\n\n// GetServicePods from cache\nfunc (lc *LocationCache) GetServicePods(name string) ([]v1.Pod, bool) {\n\tvalue, ok := lc.servicePods.Load(name)\n\tif !ok {\n\t\treturn []v1.Pod{}, ok\n\t}\n\tpods, ok := value.([]v1.Pod)\n\treturn pods, ok\n}\n\n// AddOrUpdateEndpoints in cache\nfunc (lc *LocationCache) AddOrUpdateEndpoints(endpoints v1.Endpoints) {\n\tlc.endpoints.Store(fmt.Sprintf(\"%s/%s\", endpoints.Namespace, endpoints.Name), endpoints)\n}\n\n// DeleteEndpoints in cache\nfunc (lc *LocationCache) DeleteEndpoints(endpoints v1.Endpoints) {\n\tlc.endpoints.Delete(fmt.Sprintf(\"%s/%s\", endpoints.Namespace, endpoints.Name))\n}\n\n// IsEndpointsUpdated checks if endpoints is actually updated\nfunc (lc *LocationCache) IsEndpointsUpdated(new v1.Endpoints) bool {\n\teps, ok := lc.endpoints.Load(fmt.Sprintf(\"%s/%s\", new.Namespace, new.Name))\n\tif !ok {\n\t\t// return true because the endpoint was not found in cache\n\t\treturn !ok\n\t}\n\told, ok := eps.(v1.Endpoints)\n\tif !ok {\n\t\treturn !ok\n\t}\n\told.ObjectMeta.ResourceVersion = new.ObjectMeta.ResourceVersion\n\told.ObjectMeta.Generation = new.ObjectMeta.Generation\n\told.ObjectMeta.Annotations = new.ObjectMeta.Annotations\n\t// return true if ObjectMeta or Subsets changed, else false\n\treturn !reflect.DeepEqual(old.ObjectMeta, new.ObjectMeta) || !reflect.DeepEqual(old.Subsets, new.Subsets)\n}\n\n// GetAllEndpoints from cache\nfunc (lc *LocationCache) GetAllEndpoints() []v1.Endpoints {\n\tendpoints := []v1.Endpoints{}\n\tlc.endpoints.Range(func(key interface{}, value interface{}) bool {\n\t\teps, ok := value.(v1.Endpoints)\n\t\tif ok {\n\t\t\tendpoints = append(endpoints, eps)\n\t\t}\n\t\treturn true\n\t})\n\treturn endpoints\n}\n", "idx": 1, "id": 17696, "msg": "", "proj": "kubeedge-kubeedge", "lang": "go"}
{"patch": "@@ -0,0 +1,43 @@\n+import * as C from '../../../i18n/constants';\n+\n+/**\n+ * The `ContextMenuHandler` class handles adding the context menu entries for the merged cells plugin.\n+ *\n+ * @class ContextMenu\n+ * @plugin MergeCells\n+ * @private\n+ */\n+class ContextMenuHandler {\n+  /**\n+   * `afterContextMenuDefaultOptions` hook callback.\n+   *\n+   * @private\n+   * @param {MergeCells} plugin The plugin instance.\n+   * @param {Object} defaultOptions The default context menu options.\n+   */\n+  addEntries(plugin, defaultOptions) {\n+    defaultOptions.items.push({name: '---------'});\n+    defaultOptions.items.push({\n+      key: 'mergeCells',\n+      name() {\n+        const sel = this.getSelected();\n+        const info = plugin.collectionContainer.get(sel[0], sel[1]);\n+\n+        if (info.row === sel[0] && info.col === sel[1] && info.row + info.rowspan - 1 === sel[2] && info.col + info.colspan - 1 === sel[3]) {\n+          return this.getTranslatedPhrase(C.CONTEXTMENU_ITEMS_UNMERGE_CELLS);\n+        }\n+        return this.getTranslatedPhrase(C.CONTEXTMENU_ITEMS_MERGE_CELLS);\n+\n+      },\n+      callback() {\n+        plugin.toggleMerge(this.getSelectedRange());\n+        this.render();\n+      },\n+      disabled() {\n+        return this.selection.selectedHeader.corner;\n+      },\n+    });\n+  }\n+}\n+\n+export default ContextMenuHandler;", "y": 1, "oldf": "", "idx": 1, "id": 14567, "msg": "Please clear the situation with enters.", "proj": "handsontable-handsontable", "lang": "js"}
{"patch": "@@ -0,0 +1,24 @@\n+// Licensed to the Software Freedom Conservancy (SFC) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The SFC licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.openqa.selenium.grid.data;\n+\n+public enum Status {\n+  UP,\n+  DRAINING,\n+  DOWN\n+}", "y": 1, "oldf": "", "idx": 1, "id": 18106, "msg": "`Status` is one of those words that has many usages. I guess this is more properly `Availability` or something similar.", "proj": "SeleniumHQ-selenium", "lang": "js"}
{"patch": "@@ -151,6 +151,27 @@ class TestCase(unittest.TestCase):\n     self.assertLess(fpd1, fpd2)\n     self.assertLess(fpd2, fpd3)\n \n+  def testVectorDescriptors(self):\n+    print(\"&\"*44)\n+    m = Chem.MolFromSmiles('CCCc1ccccc1')\n+    print(\"BCUT2D\")\n+    results = rdMolDescriptors.BCUT2D(m)\n+    names = [\"BCUT2D_%s\"%s for s in ('MWHI',\"MWLOW\",\"CHGHI\",\"CHGLO\",\n+                                     \"LOGPHI\",\"LOGPLOW\",\"MRHI\",\"MRLOW\")]\n+    for i,n in  enumerate(names):\n+      print(\"Searching for\", n)\n+      f = getattr(Descriptors, n)\n+      self.assertEqual(results[i], f(m))\n+\n+    print(\"AUTOCORR\")\n+    results = rdMolDescriptors.CalcAUTOCORR2D(m)\n+    names = [\"AUTOCORR2D_%s\"%str(i+1) for i in range(192)]\n+    for i,n in enumerate(names):\n+      print(\"Searching for\", n)\n+      f = getattr(Descriptors, n)\n+      self.assertEqual(results[i], f(m))\n+      \n+\n \n if __name__ == '__main__':\n   unittest.main()", "y": 1, "oldf": "#\n#  Copyright (C) 2007-2017 Greg Landrum\n#\n#   @@ All Rights Reserved @@\n#  This file is part of the RDKit.\n#  The contents are covered by the terms of the BSD license\n#  which is included in the file license.txt, found at the root\n#  of the RDKit source tree.\n#\n\"\"\" General descriptor testing code\n\n\"\"\"\n\n\nimport io\nimport os.path\nimport unittest\nimport doctest\n\nimport numpy as np\nfrom rdkit import Chem\nfrom rdkit import RDConfig\nfrom rdkit.Chem import AllChem\nfrom rdkit.Chem import Descriptors\nfrom rdkit.Chem import Lipinski\nfrom rdkit.Chem import rdMolDescriptors\nimport pickle\n\n\ndef load_tests(loader, tests, ignore):\n  \"\"\" Add the Doctests from the module \"\"\"\n  tests.addTests(doctest.DocTestSuite(Descriptors, optionflags=doctest.ELLIPSIS))\n  return tests\n\n\nclass TestCase(unittest.TestCase):\n\n  def testGithub1287(self):\n    smis = ('CCC',)\n    for smi in smis:\n      m = Chem.MolFromSmiles(smi)\n      self.assertTrue(m)\n      for nm, fn in Descriptors._descList:\n        try:\n          _ = fn(m)\n        except Exception:\n          import traceback\n          traceback.print_exc()\n          raise AssertionError('SMILES: %s; Descriptor: %s' % (smi, nm))\n\n  def testBadAtomHandling(self):\n    smis = ('CC[Pu]', 'CC[*]')\n    for smi in smis:\n      m = Chem.MolFromSmiles(smi)\n      self.assertTrue(m)\n      for nm, fn in Descriptors._descList:\n        try:\n          v = fn(m)\n        except RuntimeError:\n          # 3D descriptors fail since the mol has no conformers\n          pass\n        except Exception:\n          import traceback\n          traceback.print_exc()\n          raise AssertionError('SMILES: %s; Descriptor: %s' % (smi, nm))\n\n  def testMolFormula(self):\n    for (smiles, expected) in ((\"[NH4+]\", \"H4N+\"),\n                               (\"c1ccccc1\", \"C6H6\"),\n                               (\"C1CCCCC1\", \"C6H12\"),\n                               (\"c1ccccc1O\", \"C6H6O\"),\n                               (\"C1CCCCC1O\", \"C6H12O\"),\n                               (\"C1CCCCC1=O\", \"C6H10O\"),\n                               (\"N[Na]\", \"H2NNa\"),\n                               (\"[C-][C-]\", \"C2-2\"),\n                               (\"[H]\", \"H\"),\n                               (\"[H-1]\", \"H-\"),\n                               (\"[H-1]\", \"H-\"),\n                               (\"[CH2]\", \"CH2\"),\n                               (\"[He-2]\", \"He-2\"),\n                               (\"[U+3]\", \"U+3\"),):\n      mol = Chem.MolFromSmiles(smiles)\n      actual = AllChem.CalcMolFormula(mol)\n      self.assertEqual(actual, expected)\n\n  def testMQNDetails(self):\n    refFile = os.path.join(RDConfig.RDCodeDir, 'Chem', 'test_data', 'MQNs_regress.pkl')\n    refFile2 = os.path.join(RDConfig.RDCodeDir, 'Chem', 'test_data', 'MQNs_non_strict_regress.pkl')\n    # figure out which definition we are currently using\n    m = Chem.MolFromSmiles(\"CC(C)(C)c1cc(O)c(cc1O)C(C)(C)C\")\n    if Lipinski.NumRotatableBonds(m) == 2:\n      refFile = refFile2\n\n    with open(refFile, 'r') as intf:\n      buf = intf.read().replace('\\r\\n', '\\n').encode('utf-8')\n      intf.close()\n    with io.BytesIO(buf) as inf:\n      pkl = inf.read()\n    refData = pickle.loads(pkl, encoding='bytes')\n    fn = os.path.join(RDConfig.RDCodeDir, 'Chem', 'test_data', 'aromat_regress.txt')\n    ms = [x for x in Chem.SmilesMolSupplier(fn, delimiter='\\t')]\n    refData2 = []\n    for i, m in enumerate(ms):\n      mqns = rdMolDescriptors.MQNs_(m)\n      refData2.append((m, mqns))\n      if mqns != refData[i][1]:\n        indices = [(j, x, y) for j, x, y in zip(range(len(mqns)), mqns, refData[i][1]) if x != y]\n        print(i, Chem.MolToSmiles(m), indices)\n      self.assertEqual(mqns, refData[i][1])\n\n  def testMQN(self):\n    m = Chem.MolFromSmiles(\"CC(C)(C)c1cc(O)c(cc1O)C(C)(C)C\")\n    if Lipinski.NumRotatableBonds(m) == 2:\n      tgt = np.array(\n        [42917, 274, 870, 621, 135, 1582, 29, 3147, 5463, 6999, 470, 62588, 19055, 4424, 309, 24061,\n         17820, 1, 9303, 24146, 16076, 5560, 4262, 646, 746, 13725, 5430, 2629, 362, 24211, 15939,\n         292, 41, 20, 1852, 5642, 31, 9, 1, 2, 3060, 1750])\n    else:\n      tgt = np.array(\n        [42917, 274, 870, 621, 135, 1582, 29, 3147, 5463, 6999, 470, 62588, 19055, 4424, 309, 24061,\n         17820, 1, 8314, 24146, 16076, 5560, 4262, 646, 746, 13725, 5430, 2629, 362, 24211, 15939,\n         292, 41, 20, 1852, 5642, 31, 9, 1, 2, 3060, 1750])\n    fn = os.path.join(RDConfig.RDCodeDir, 'Chem', 'test_data', 'aromat_regress.txt')\n    ms = [x for x in Chem.SmilesMolSupplier(fn, delimiter='\\t')]\n    vs = np.zeros((42,), np.int32)\n    for m in ms:\n      vs += rdMolDescriptors.MQNs_(m)\n    self.assertFalse(False in (vs == tgt))\n\n  def test_FpDensityMorgan(self):\n    self.assertEqual(Descriptors.FpDensityMorgan1.version, '1.0.0')\n    self.assertEqual(Descriptors.FpDensityMorgan2.version, '1.0.0')\n    self.assertEqual(Descriptors.FpDensityMorgan3.version, '1.0.0')\n\n    m = Chem.MolFromSmiles('C')\n    self.assertAlmostEqual(Descriptors.FpDensityMorgan2(m), 1)\n    m = Chem.MolFromSmiles('CC')\n    self.assertAlmostEqual(Descriptors.FpDensityMorgan2(m), 1)\n    m = Chem.MolFromSmiles('CCC')\n    self.assertAlmostEqual(Descriptors.FpDensityMorgan2(m), 4.0 / 3)\n    m = Chem.MolFromSmiles('C' * 10)\n    self.assertAlmostEqual(Descriptors.FpDensityMorgan2(m), 8.0 / 10)\n    m = Chem.MolFromSmiles('C' * 100)\n    self.assertAlmostEqual(Descriptors.FpDensityMorgan2(m), 8.0 / 100)\n\n    m = Chem.MolFromSmiles('CCCc1ccccc1')\n    fpd1 = Descriptors.FpDensityMorgan1(m)\n    fpd2 = Descriptors.FpDensityMorgan2(m)\n    fpd3 = Descriptors.FpDensityMorgan3(m)\n    self.assertAlmostEqual(fpd1, 10.0 / 9)\n    self.assertLess(fpd1, fpd2)\n    self.assertLess(fpd2, fpd3)\n\n\nif __name__ == '__main__':\n  unittest.main()\n", "idx": 1, "id": 20952, "msg": "Probably don't need these debugging prints in the merged version", "proj": "rdkit-rdkit", "lang": "cpp"}
{"patch": "@@ -496,21 +496,25 @@ func processBind(fset *token.FileSet, info *types.Info, call *ast.CallExpr) (*If\n \t\treturn nil, fmt.Errorf(\"%v: call to Bind takes exactly two arguments\", fset.Position(call.Pos()))\n \t}\n \t// TODO(light): Verify that arguments are simple expressions.\n-\tiface := info.TypeOf(call.Args[0])\n-\tmethodSet, ok := iface.Underlying().(*types.Interface)\n+\tifaceArgType := info.TypeOf(call.Args[0])\n+\tifacePtr, ok := ifaceArgType.(*types.Pointer)\n \tif !ok {\n-\t\treturn nil, fmt.Errorf(\"%v: first argument to bind must be of interface type; found %s\", fset.Position(call.Pos()), types.TypeString(iface, nil))\n+\t\treturn nil, fmt.Errorf(\"%v: first argument to bind must be a pointer to an interface type; found %s\", fset.Position(call.Pos()), types.TypeString(ifaceArgType, nil))\n+\t}\n+\tmethodSet, ok := ifacePtr.Elem().Underlying().(*types.Interface)\n+\tif !ok {\n+\t\treturn nil, fmt.Errorf(\"%v: first argument to bind must be a pointer to an interface type; found %s\", fset.Position(call.Pos()), types.TypeString(ifaceArgType, nil))\n \t}\n \tprovided := info.TypeOf(call.Args[1])\n-\tif types.Identical(iface, provided) {\n+\tif types.Identical(ifacePtr.Elem(), provided) {\n \t\treturn nil, fmt.Errorf(\"%v: cannot bind interface to itself\", fset.Position(call.Pos()))\n \t}\n \tif !types.Implements(provided, methodSet) {\n-\t\treturn nil, fmt.Errorf(\"%v: %s does not implement %s\", fset.Position(call.Pos()), types.TypeString(provided, nil), types.TypeString(iface, nil))\n+\t\treturn nil, fmt.Errorf(\"%v: %s does not implement %s\", fset.Position(call.Pos()), types.TypeString(provided, nil), types.TypeString(ifaceArgType, nil))\n \t}\n \treturn &IfaceBinding{\n \t\tPos:      call.Pos(),\n-\t\tIface:    iface,\n+\t\tIface:    ifacePtr.Elem(),\n \t\tProvided: provided,\n \t}, nil\n }", "y": 1, "oldf": "// Copyright 2018 Google LLC\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     https://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage goose\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"go/ast\"\n\t\"go/build\"\n\t\"go/token\"\n\t\"go/types\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"golang.org/x/tools/go/ast/astutil\"\n\t\"golang.org/x/tools/go/loader\"\n)\n\n// A ProviderSet describes a set of providers.  The zero value is an empty\n// ProviderSet.\ntype ProviderSet struct {\n\t// Pos is the position of the call to goose.NewSet or goose.Build that\n\t// created the set.\n\tPos token.Pos\n\t// PkgPath is the import path of the package that declared this set.\n\tPkgPath string\n\t// Name is the variable name of the set, if it came from a package\n\t// variable.\n\tName string\n\n\tProviders []*Provider\n\tBindings  []*IfaceBinding\n\tValues    []*Value\n\tImports   []*ProviderSet\n}\n\n// An IfaceBinding declares that a type should be used to satisfy inputs\n// of the given interface type.\ntype IfaceBinding struct {\n\t// Iface is the interface type, which is what can be injected.\n\tIface types.Type\n\n\t// Provided is always a type that is assignable to Iface.\n\tProvided types.Type\n\n\t// Pos is the position where the binding was declared.\n\tPos token.Pos\n}\n\n// Provider records the signature of a provider. A provider is a\n// single Go object, either a function or a named struct type.\ntype Provider struct {\n\t// ImportPath is the package path that the Go object resides in.\n\tImportPath string\n\n\t// Name is the name of the Go object.\n\tName string\n\n\t// Pos is the source position of the func keyword or type spec\n\t// defining this provider.\n\tPos token.Pos\n\n\t// Args is the list of data dependencies this provider has.\n\tArgs []ProviderInput\n\n\t// IsStruct is true if this provider is a named struct type.\n\t// Otherwise it's a function.\n\tIsStruct bool\n\n\t// Fields lists the field names to populate. This will map 1:1 with\n\t// elements in Args.\n\tFields []string\n\n\t// Out is the type this provider produces.\n\tOut types.Type\n\n\t// HasCleanup reports whether the provider function returns a cleanup\n\t// function.  (Always false for structs.)\n\tHasCleanup bool\n\n\t// HasErr reports whether the provider function can return an error.\n\t// (Always false for structs.)\n\tHasErr bool\n}\n\n// ProviderInput describes an incoming edge in the provider graph.\ntype ProviderInput struct {\n\tType types.Type\n\n\t// TODO(light): Move field name into this struct.\n}\n\n// Value describes a value expression.\ntype Value struct {\n\t// Pos is the source position of the expression defining this value.\n\tPos token.Pos\n\n\t// Out is the type this value produces.\n\tOut types.Type\n\n\t// expr is the expression passed to goose.Value.\n\texpr ast.Expr\n\n\t// info is the type info for the expression.\n\tinfo *types.Info\n}\n\n// Load finds all the provider sets in the given packages, as well as\n// the provider sets' transitive dependencies.\nfunc Load(bctx *build.Context, wd string, pkgs []string) (*Info, error) {\n\t// TODO(light): Stop errors from printing to stderr.\n\tconf := &loader.Config{\n\t\tBuild:               bctx,\n\t\tCwd:                 wd,\n\t\tTypeCheckFuncBodies: func(string) bool { return false },\n\t}\n\tfor _, p := range pkgs {\n\t\tconf.Import(p)\n\t}\n\tprog, err := conf.Load()\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"load: %v\", err)\n\t}\n\tinfo := &Info{\n\t\tFset: prog.Fset,\n\t\tSets: make(map[ProviderSetID]*ProviderSet),\n\t}\n\toc := newObjectCache(prog)\n\tfor _, pkgInfo := range prog.InitialPackages() {\n\t\tscope := pkgInfo.Pkg.Scope()\n\t\tfor _, name := range scope.Names() {\n\t\t\titem, err := oc.get(scope.Lookup(name))\n\t\t\tif err != nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tpset, ok := item.(*ProviderSet)\n\t\t\tif !ok {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\t// pset.Name may not equal name, since it could be an alias to\n\t\t\t// another provider set.\n\t\t\tid := ProviderSetID{ImportPath: pset.PkgPath, VarName: name}\n\t\t\tinfo.Sets[id] = pset\n\t\t}\n\t}\n\treturn info, nil\n}\n\n// Info holds the result of Load.\ntype Info struct {\n\tFset *token.FileSet\n\n\t// Sets contains all the provider sets in the initial packages.\n\tSets map[ProviderSetID]*ProviderSet\n}\n\n// A ProviderSetID identifies a named provider set.\ntype ProviderSetID struct {\n\tImportPath string\n\tVarName    string\n}\n\n// String returns the ID as \"\"path/to/pkg\".Foo\".\nfunc (id ProviderSetID) String() string {\n\treturn strconv.Quote(id.ImportPath) + \".\" + id.VarName\n}\n\n// objectCache is a lazily evaluated mapping of objects to goose structures.\ntype objectCache struct {\n\tprog    *loader.Program\n\tobjects map[objRef]interface{} // *Provider, *ProviderSet, *IfaceBinding, or *Value\n}\n\ntype objRef struct {\n\timportPath string\n\tname       string\n}\n\nfunc newObjectCache(prog *loader.Program) *objectCache {\n\treturn &objectCache{\n\t\tprog:    prog,\n\t\tobjects: make(map[objRef]interface{}),\n\t}\n}\n\n// get converts a Go object into a goose structure. It may return a\n// *Provider, a structProviderPair, an *IfaceBinding, a *ProviderSet,\n// or a *Value.\nfunc (oc *objectCache) get(obj types.Object) (interface{}, error) {\n\tref := objRef{\n\t\timportPath: obj.Pkg().Path(),\n\t\tname:       obj.Name(),\n\t}\n\tif val, cached := oc.objects[ref]; cached {\n\t\tif val == nil {\n\t\t\treturn nil, fmt.Errorf(\"%v is not a provider or a provider set\", obj)\n\t\t}\n\t\treturn val, nil\n\t}\n\tswitch obj := obj.(type) {\n\tcase *types.Var:\n\t\tspec := oc.varDecl(obj)\n\t\tif len(spec.Values) == 0 {\n\t\t\treturn nil, fmt.Errorf(\"%v is not a provider or a provider set\", obj)\n\t\t}\n\t\tvar i int\n\t\tfor i = range spec.Names {\n\t\t\tif spec.Names[i].Name == obj.Name() {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\treturn oc.processExpr(oc.prog.Package(obj.Pkg().Path()), spec.Values[i])\n\tcase *types.Func:\n\t\tp, err := processFuncProvider(oc.prog.Fset, obj)\n\t\tif err != nil {\n\t\t\toc.objects[ref] = nil\n\t\t\treturn nil, err\n\t\t}\n\t\toc.objects[ref] = p\n\t\treturn p, nil\n\tdefault:\n\t\toc.objects[ref] = nil\n\t\treturn nil, fmt.Errorf(\"%v is not a provider or a provider set\", obj)\n\t}\n}\n\n// varDecl finds the declaration that defines the given variable.\nfunc (oc *objectCache) varDecl(obj *types.Var) *ast.ValueSpec {\n\t// TODO(light): Walk files to build object -> declaration mapping, if more performant.\n\t// Recommended by https://golang.org/s/types-tutorial\n\tpkg := oc.prog.Package(obj.Pkg().Path())\n\tpos := obj.Pos()\n\tfor _, f := range pkg.Files {\n\t\ttokenFile := oc.prog.Fset.File(f.Pos())\n\t\tif base := tokenFile.Base(); base <= int(pos) && int(pos) < base+tokenFile.Size() {\n\t\t\tpath, _ := astutil.PathEnclosingInterval(f, pos, pos)\n\t\t\tfor _, node := range path {\n\t\t\t\tif spec, ok := node.(*ast.ValueSpec); ok {\n\t\t\t\t\treturn spec\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}\n\n// processExpr converts an expression into a goose structure. It may\n// return a *Provider, a structProviderPair, an *IfaceBinding, a\n// *ProviderSet, or a *Value.\nfunc (oc *objectCache) processExpr(pkg *loader.PackageInfo, expr ast.Expr) (interface{}, error) {\n\texprPos := oc.prog.Fset.Position(expr.Pos())\n\texpr = astutil.Unparen(expr)\n\tif obj := qualifiedIdentObject(&pkg.Info, expr); obj != nil {\n\t\titem, err := oc.get(obj)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"%v: %v\", exprPos, err)\n\t\t}\n\t\treturn item, nil\n\t}\n\tif call, ok := expr.(*ast.CallExpr); ok {\n\t\tfnObj := qualifiedIdentObject(&pkg.Info, call.Fun)\n\t\tif fnObj == nil || !isGooseImport(fnObj.Pkg().Path()) {\n\t\t\treturn nil, fmt.Errorf(\"%v: unknown pattern\", exprPos)\n\t\t}\n\t\tswitch fnObj.Name() {\n\t\tcase \"NewSet\":\n\t\t\tpset, err := oc.processNewSet(pkg, call)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"%v: %v\", exprPos, err)\n\t\t\t}\n\t\t\treturn pset, nil\n\t\tcase \"Bind\":\n\t\t\tb, err := processBind(oc.prog.Fset, &pkg.Info, call)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"%v: %v\", exprPos, err)\n\t\t\t}\n\t\t\treturn b, nil\n\t\tcase \"Value\":\n\t\t\tv, err := processValue(oc.prog.Fset, &pkg.Info, call)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"%v: %v\", exprPos, err)\n\t\t\t}\n\t\t\treturn v, nil\n\t\tdefault:\n\t\t\treturn nil, fmt.Errorf(\"%v: unknown pattern\", exprPos)\n\t\t}\n\t}\n\tif tn := structArgType(&pkg.Info, expr); tn != nil {\n\t\tp, err := processStructProvider(oc.prog.Fset, tn)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"%v: %v\", exprPos, err)\n\t\t}\n\t\tptrp := new(Provider)\n\t\t*ptrp = *p\n\t\tptrp.Out = types.NewPointer(p.Out)\n\t\treturn structProviderPair{p, ptrp}, nil\n\t}\n\treturn nil, fmt.Errorf(\"%v: unknown pattern\", exprPos)\n}\n\ntype structProviderPair struct {\n\tprovider    *Provider\n\tptrProvider *Provider\n}\n\nfunc (oc *objectCache) processNewSet(pkg *loader.PackageInfo, call *ast.CallExpr) (*ProviderSet, error) {\n\t// Assumes that call.Fun is goose.NewSet or goose.Build.\n\n\tpset := &ProviderSet{\n\t\tPos:     call.Pos(),\n\t\tPkgPath: pkg.Pkg.Path(),\n\t}\n\tfor _, arg := range call.Args {\n\t\titem, err := oc.processExpr(pkg, arg)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tswitch item := item.(type) {\n\t\tcase *Provider:\n\t\t\tpset.Providers = append(pset.Providers, item)\n\t\tcase *ProviderSet:\n\t\t\tpset.Imports = append(pset.Imports, item)\n\t\tcase *IfaceBinding:\n\t\t\tpset.Bindings = append(pset.Bindings, item)\n\t\tcase structProviderPair:\n\t\t\tpset.Providers = append(pset.Providers, item.provider, item.ptrProvider)\n\t\tcase *Value:\n\t\t\tpset.Values = append(pset.Values, item)\n\t\tdefault:\n\t\t\tpanic(\"unknown item type\")\n\t\t}\n\t}\n\treturn pset, nil\n}\n\n// structArgType attempts to interpret an expression as a simple struct type.\n// It assumes any parentheses have been stripped.\nfunc structArgType(info *types.Info, expr ast.Expr) *types.TypeName {\n\tlit, ok := expr.(*ast.CompositeLit)\n\tif !ok {\n\t\treturn nil\n\t}\n\ttn, ok := qualifiedIdentObject(info, lit.Type).(*types.TypeName)\n\tif !ok {\n\t\treturn nil\n\t}\n\tif _, isStruct := tn.Type().Underlying().(*types.Struct); !isStruct {\n\t\treturn nil\n\t}\n\treturn tn\n}\n\n// qualifiedIdentObject finds the object for an identifier or a\n// qualified identifier, or nil if the object could not be found.\nfunc qualifiedIdentObject(info *types.Info, expr ast.Expr) types.Object {\n\tswitch expr := expr.(type) {\n\tcase *ast.Ident:\n\t\treturn info.ObjectOf(expr)\n\tcase *ast.SelectorExpr:\n\t\tpkgName, ok := expr.X.(*ast.Ident)\n\t\tif !ok {\n\t\t\treturn nil\n\t\t}\n\t\tif _, ok := info.ObjectOf(pkgName).(*types.PkgName); !ok {\n\t\t\treturn nil\n\t\t}\n\t\treturn info.ObjectOf(expr.Sel)\n\tdefault:\n\t\treturn nil\n\t}\n}\n\n// processFuncProvider creates a provider for a function declaration.\nfunc processFuncProvider(fset *token.FileSet, fn *types.Func) (*Provider, error) {\n\tsig := fn.Type().(*types.Signature)\n\tfpos := fn.Pos()\n\tproviderSig, err := funcOutput(sig)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"%v: wrong signature for provider %s: %v\", fset.Position(fpos), fn.Name(), err)\n\t}\n\tparams := sig.Params()\n\tprovider := &Provider{\n\t\tImportPath: fn.Pkg().Path(),\n\t\tName:       fn.Name(),\n\t\tPos:        fn.Pos(),\n\t\tArgs:       make([]ProviderInput, params.Len()),\n\t\tOut:        providerSig.out,\n\t\tHasCleanup: providerSig.cleanup,\n\t\tHasErr:     providerSig.err,\n\t}\n\tfor i := 0; i < params.Len(); i++ {\n\t\tprovider.Args[i] = ProviderInput{\n\t\t\tType: params.At(i).Type(),\n\t\t}\n\t\tfor j := 0; j < i; j++ {\n\t\t\tif types.Identical(provider.Args[i].Type, provider.Args[j].Type) {\n\t\t\t\treturn nil, fmt.Errorf(\"%v: provider has multiple parameters of type %s\", fset.Position(fpos), types.TypeString(provider.Args[j].Type, nil))\n\t\t\t}\n\t\t}\n\t}\n\treturn provider, nil\n}\n\ntype outputSignature struct {\n\tout     types.Type\n\tcleanup bool\n\terr     bool\n}\n\n// funcOutput validates an injector or provider function's return signature.\nfunc funcOutput(sig *types.Signature) (outputSignature, error) {\n\tresults := sig.Results()\n\tswitch results.Len() {\n\tcase 0:\n\t\treturn outputSignature{}, errors.New(\"no return values\")\n\tcase 1:\n\t\treturn outputSignature{out: results.At(0).Type()}, nil\n\tcase 2:\n\t\tout := results.At(0).Type()\n\t\tswitch t := results.At(1).Type(); {\n\t\tcase types.Identical(t, errorType):\n\t\t\treturn outputSignature{out: out, err: true}, nil\n\t\tcase types.Identical(t, cleanupType):\n\t\t\treturn outputSignature{out: out, cleanup: true}, nil\n\t\tdefault:\n\t\t\treturn outputSignature{}, fmt.Errorf(\"second return type is %s; must be error or func()\", types.TypeString(t, nil))\n\t\t}\n\tcase 3:\n\t\tif t := results.At(1).Type(); !types.Identical(t, cleanupType) {\n\t\t\treturn outputSignature{}, fmt.Errorf(\"second return type is %s; must be func()\", types.TypeString(t, nil))\n\t\t}\n\t\tif t := results.At(2).Type(); !types.Identical(t, errorType) {\n\t\t\treturn outputSignature{}, fmt.Errorf(\"third return type is %s; must be error\", types.TypeString(t, nil))\n\t\t}\n\t\treturn outputSignature{\n\t\t\tout:     results.At(0).Type(),\n\t\t\tcleanup: true,\n\t\t\terr:     true,\n\t\t}, nil\n\tdefault:\n\t\treturn outputSignature{}, errors.New(\"too many return values\")\n\t}\n}\n\n// processStructProvider creates a provider for a named struct type.\n// It only produces the non-pointer variant.\nfunc processStructProvider(fset *token.FileSet, typeName *types.TypeName) (*Provider, error) {\n\tout := typeName.Type()\n\tst, ok := out.Underlying().(*types.Struct)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"%v does not name a struct\", typeName)\n\t}\n\n\tpos := typeName.Pos()\n\tprovider := &Provider{\n\t\tImportPath: typeName.Pkg().Path(),\n\t\tName:       typeName.Name(),\n\t\tPos:        pos,\n\t\tArgs:       make([]ProviderInput, st.NumFields()),\n\t\tFields:     make([]string, st.NumFields()),\n\t\tIsStruct:   true,\n\t\tOut:        out,\n\t}\n\tfor i := 0; i < st.NumFields(); i++ {\n\t\tf := st.Field(i)\n\t\tprovider.Args[i] = ProviderInput{\n\t\t\tType: f.Type(),\n\t\t}\n\t\tprovider.Fields[i] = f.Name()\n\t\tfor j := 0; j < i; j++ {\n\t\t\tif types.Identical(provider.Args[i].Type, provider.Args[j].Type) {\n\t\t\t\treturn nil, fmt.Errorf(\"%v: provider struct has multiple fields of type %s\", fset.Position(pos), types.TypeString(provider.Args[j].Type, nil))\n\t\t\t}\n\t\t}\n\t}\n\treturn provider, nil\n}\n\n// processBind creates an interface binding from a goose.Bind call.\nfunc processBind(fset *token.FileSet, info *types.Info, call *ast.CallExpr) (*IfaceBinding, error) {\n\t// Assumes that call.Fun is goose.Bind.\n\n\tif len(call.Args) != 2 {\n\t\treturn nil, fmt.Errorf(\"%v: call to Bind takes exactly two arguments\", fset.Position(call.Pos()))\n\t}\n\t// TODO(light): Verify that arguments are simple expressions.\n\tiface := info.TypeOf(call.Args[0])\n\tmethodSet, ok := iface.Underlying().(*types.Interface)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"%v: first argument to bind must be of interface type; found %s\", fset.Position(call.Pos()), types.TypeString(iface, nil))\n\t}\n\tprovided := info.TypeOf(call.Args[1])\n\tif types.Identical(iface, provided) {\n\t\treturn nil, fmt.Errorf(\"%v: cannot bind interface to itself\", fset.Position(call.Pos()))\n\t}\n\tif !types.Implements(provided, methodSet) {\n\t\treturn nil, fmt.Errorf(\"%v: %s does not implement %s\", fset.Position(call.Pos()), types.TypeString(provided, nil), types.TypeString(iface, nil))\n\t}\n\treturn &IfaceBinding{\n\t\tPos:      call.Pos(),\n\t\tIface:    iface,\n\t\tProvided: provided,\n\t}, nil\n}\n\n// processValue creates a value from a goose.Value call.\nfunc processValue(fset *token.FileSet, info *types.Info, call *ast.CallExpr) (*Value, error) {\n\t// Assumes that call.Fun is goose.Value.\n\n\tif len(call.Args) != 1 {\n\t\treturn nil, fmt.Errorf(\"%v: call to Value takes exactly one argument\", fset.Position(call.Pos()))\n\t}\n\tok := true\n\tast.Inspect(call.Args[0], func(node ast.Node) bool {\n\t\tswitch node.(type) {\n\t\tcase nil, *ast.ArrayType, *ast.BasicLit, *ast.BinaryExpr, *ast.ChanType, *ast.CompositeLit, *ast.FuncType, *ast.Ident, *ast.IndexExpr, *ast.InterfaceType, *ast.KeyValueExpr, *ast.MapType, *ast.ParenExpr, *ast.SelectorExpr, *ast.SliceExpr, *ast.StarExpr, *ast.StructType, *ast.TypeAssertExpr:\n\t\t\t// Good!\n\t\tcase *ast.UnaryExpr:\n\t\t\texpr := node.(*ast.UnaryExpr)\n\t\t\tif expr.Op == token.ARROW {\n\t\t\t\tok = false\n\t\t\t\treturn false\n\t\t\t}\n\t\tcase *ast.CallExpr:\n\t\t\t// Only acceptable if it's a type conversion.\n\t\t\tcall := node.(*ast.CallExpr)\n\t\t\tif _, isFunc := info.TypeOf(call.Fun).(*types.Signature); isFunc {\n\t\t\t\tok = false\n\t\t\t\treturn false\n\t\t\t}\n\t\tdefault:\n\t\t\tok = false\n\t\t\treturn false\n\t\t}\n\t\treturn true\n\t})\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"%v: argument to Value is too complex\", fset.Position(call.Pos()))\n\t}\n\treturn &Value{\n\t\tPos:  call.Args[0].Pos(),\n\t\tOut:  info.TypeOf(call.Args[0]),\n\t\texpr: call.Args[0],\n\t\tinfo: info,\n\t}, nil\n}\n\n// isInjector checks whether a given function declaration is an\n// injector template, returning the goose.Build call. It returns nil if\n// the function is not an injector template.\nfunc isInjector(info *types.Info, fn *ast.FuncDecl) *ast.CallExpr {\n\tif fn.Body == nil {\n\t\treturn nil\n\t}\n\tvar only *ast.ExprStmt\n\tfor _, stmt := range fn.Body.List {\n\t\tswitch stmt := stmt.(type) {\n\t\tcase *ast.ExprStmt:\n\t\t\tif only != nil {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tonly = stmt\n\t\tcase *ast.EmptyStmt:\n\t\t\t// Do nothing.\n\t\tdefault:\n\t\t\treturn nil\n\t\t}\n\t}\n\tif only == nil {\n\t\treturn nil\n\t}\n\tpanicCall, ok := only.X.(*ast.CallExpr)\n\tif !ok {\n\t\treturn nil\n\t}\n\tpanicIdent, ok := panicCall.Fun.(*ast.Ident)\n\tif !ok {\n\t\treturn nil\n\t}\n\tif info.ObjectOf(panicIdent) != types.Universe.Lookup(\"panic\") {\n\t\treturn nil\n\t}\n\tif len(panicCall.Args) != 1 {\n\t\treturn nil\n\t}\n\tbuildCall, ok := panicCall.Args[0].(*ast.CallExpr)\n\tif !ok {\n\t\treturn nil\n\t}\n\tbuildObj := qualifiedIdentObject(info, buildCall.Fun)\n\tif !isGooseImport(buildObj.Pkg().Path()) || buildObj.Name() != \"Build\" {\n\t\treturn nil\n\t}\n\treturn buildCall\n}\n\nfunc isGooseImport(path string) bool {\n\t// TODO(light): This is depending on details of the current loader.\n\tconst vendorPart = \"vendor/\"\n\tif i := strings.LastIndex(path, vendorPart); i != -1 && (i == 0 || path[i-1] == '/') {\n\t\tpath = path[i+len(vendorPart):]\n\t}\n\treturn path == \"github.com/google/go-cloud/goose\"\n}\n\n// paramIndex returns the index of the parameter with the given name, or\n// -1 if no such parameter exists.\nfunc paramIndex(params *types.Tuple, name string) int {\n\tfor i := 0; i < params.Len(); i++ {\n\t\tif params.At(i).Name() == name {\n\t\t\treturn i\n\t\t}\n\t}\n\treturn -1\n}\n", "idx": 1, "id": 9723, "msg": "Two questions: 1) Should the underlying type be an interface? Why it is still a pointer to interface? 2) What's the difference between calling ifacePtr.Elem().Underlying() vs ifacePtr.Underlying()?", "proj": "google-go-cloud", "lang": "go"}
{"patch": "@@ -1468,6 +1468,7 @@ func (o *consumer) info() *ConsumerInfo {\n \t\tNumAckPending:  len(o.pending),\n \t\tNumRedelivered: len(o.rdc),\n \t\tNumPending:     o.adjustedPending(),\n+\t\tActive:         pa,\n \t\tCluster:        ci,\n \t}\n \t// If we are a pull mode consumer, report on number of waiting requests.", "y": 0, "oldf": "// Copyright 2019-2021 The NATS Authors\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n// http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage server\n\nimport (\n\t\"bytes\"\n\t\"encoding/binary\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"math/rand\"\n\t\"reflect\"\n\t\"sort\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\t\"github.com/nats-io/nuid\"\n\t\"golang.org/x/time/rate\"\n)\n\ntype ConsumerInfo struct {\n\tStream         string          `json:\"stream_name\"`\n\tName           string          `json:\"name\"`\n\tCreated        time.Time       `json:\"created\"`\n\tConfig         *ConsumerConfig `json:\"config,omitempty\"`\n\tDelivered      SequencePair    `json:\"delivered\"`\n\tAckFloor       SequencePair    `json:\"ack_floor\"`\n\tNumAckPending  int             `json:\"num_ack_pending\"`\n\tNumRedelivered int             `json:\"num_redelivered\"`\n\tNumWaiting     int             `json:\"num_waiting\"`\n\tNumPending     uint64          `json:\"num_pending\"`\n\tCluster        *ClusterInfo    `json:\"cluster,omitempty\"`\n}\n\ntype ConsumerConfig struct {\n\tDurable         string        `json:\"durable_name,omitempty\"`\n\tDescription     string        `json:\"description,omitempty\"`\n\tDeliverSubject  string        `json:\"deliver_subject,omitempty\"`\n\tDeliverPolicy   DeliverPolicy `json:\"deliver_policy\"`\n\tOptStartSeq     uint64        `json:\"opt_start_seq,omitempty\"`\n\tOptStartTime    *time.Time    `json:\"opt_start_time,omitempty\"`\n\tAckPolicy       AckPolicy     `json:\"ack_policy\"`\n\tAckWait         time.Duration `json:\"ack_wait,omitempty\"`\n\tMaxDeliver      int           `json:\"max_deliver,omitempty\"`\n\tFilterSubject   string        `json:\"filter_subject,omitempty\"`\n\tReplayPolicy    ReplayPolicy  `json:\"replay_policy\"`\n\tRateLimit       uint64        `json:\"rate_limit_bps,omitempty\"` // Bits per sec\n\tSampleFrequency string        `json:\"sample_freq,omitempty\"`\n\tMaxWaiting      int           `json:\"max_waiting,omitempty\"`\n\tMaxAckPending   int           `json:\"max_ack_pending,omitempty\"`\n\tHeartbeat       time.Duration `json:\"idle_heartbeat,omitempty\"`\n\tFlowControl     bool          `json:\"flow_control,omitempty\"`\n\n\t// Don't add to general clients.\n\tDirect bool `json:\"direct,omitempty\"`\n}\n\ntype CreateConsumerRequest struct {\n\tStream string         `json:\"stream_name\"`\n\tConfig ConsumerConfig `json:\"config\"`\n}\n\n// DeliverPolicy determines how the consumer should select the first message to deliver.\ntype DeliverPolicy int\n\nconst (\n\t// DeliverAll will be the default so can be omitted from the request.\n\tDeliverAll DeliverPolicy = iota\n\t// DeliverLast will start the consumer with the last sequence received.\n\tDeliverLast\n\t// DeliverNew will only deliver new messages that are sent after the consumer is created.\n\tDeliverNew\n\t// DeliverByStartSequence will look for a defined starting sequence to start.\n\tDeliverByStartSequence\n\t// DeliverByStartTime will select the first messsage with a timestamp >= to StartTime.\n\tDeliverByStartTime\n\t// DeliverLastPerSubject will start the consumer with the last message for all subjects received.\n\tDeliverLastPerSubject\n)\n\nfunc (dp DeliverPolicy) String() string {\n\tswitch dp {\n\tcase DeliverAll:\n\t\treturn \"all\"\n\tcase DeliverLast:\n\t\treturn \"last\"\n\tcase DeliverNew:\n\t\treturn \"new\"\n\tcase DeliverByStartSequence:\n\t\treturn \"by_start_sequence\"\n\tcase DeliverByStartTime:\n\t\treturn \"by_start_time\"\n\tcase DeliverLastPerSubject:\n\t\treturn \"last_per_subject\"\n\tdefault:\n\t\treturn \"undefined\"\n\t}\n}\n\n// AckPolicy determines how the consumer should acknowledge delivered messages.\ntype AckPolicy int\n\nconst (\n\t// AckNone requires no acks for delivered messages.\n\tAckNone AckPolicy = iota\n\t// AckAll when acking a sequence number, this implicitly acks all sequences below this one as well.\n\tAckAll\n\t// AckExplicit requires ack or nack for all messages.\n\tAckExplicit\n)\n\nfunc (a AckPolicy) String() string {\n\tswitch a {\n\tcase AckNone:\n\t\treturn \"none\"\n\tcase AckAll:\n\t\treturn \"all\"\n\tdefault:\n\t\treturn \"explicit\"\n\t}\n}\n\n// ReplayPolicy determines how the consumer should replay messages it already has queued in the stream.\ntype ReplayPolicy int\n\nconst (\n\t// ReplayInstant will replay messages as fast as possible.\n\tReplayInstant ReplayPolicy = iota\n\t// ReplayOriginal will maintain the same timing as the messages were received.\n\tReplayOriginal\n)\n\nfunc (r ReplayPolicy) String() string {\n\tswitch r {\n\tcase ReplayInstant:\n\t\treturn \"instant\"\n\tdefault:\n\t\treturn \"original\"\n\t}\n}\n\n// OK\nconst OK = \"+OK\"\n\n// Ack responses. Note that a nil or no payload is same as AckAck\nvar (\n\t// Ack\n\tAckAck = []byte(\"+ACK\") // nil or no payload to ack subject also means ACK\n\tAckOK  = []byte(OK)     // deprecated but +OK meant ack as well.\n\n\t// Nack\n\tAckNak = []byte(\"-NAK\")\n\t// Progress indicator\n\tAckProgress = []byte(\"+WPI\")\n\t// Ack + Deliver the next message(s).\n\tAckNext = []byte(\"+NXT\")\n\t// Terminate delivery of the message.\n\tAckTerm = []byte(\"+TERM\")\n)\n\n// Consumer is a jetstream consumer.\ntype consumer struct {\n\tmu                sync.RWMutex\n\tjs                *jetStream\n\tmset              *stream\n\tacc               *Account\n\tsrv               *Server\n\tclient            *client\n\tsysc              *client\n\tsid               int\n\tname              string\n\tstream            string\n\tsseq              uint64\n\tdseq              uint64\n\tadflr             uint64\n\tasflr             uint64\n\tsgap              uint64\n\tdsubj             string\n\tlss               *lastSeqSkipList\n\trlimit            *rate.Limiter\n\treqSub            *subscription\n\tackSub            *subscription\n\tackReplyT         string\n\tackSubj           string\n\tnextMsgSubj       string\n\tmaxp              int\n\tpblimit           int\n\tmaxpb             int\n\tpbytes            int\n\tfcsz              int\n\tfcid              string\n\tfcSub             *subscription\n\toutq              *jsOutQ\n\tpending           map[uint64]*Pending\n\tptmr              *time.Timer\n\trdq               []uint64\n\trdqi              map[uint64]struct{}\n\trdc               map[uint64]uint64\n\tmaxdc             uint64\n\twaiting           *waitQueue\n\tcfg               ConsumerConfig\n\tstore             ConsumerStore\n\tactive            bool\n\treplay            bool\n\tfilterWC          bool\n\tdtmr              *time.Timer\n\tgwdtmr            *time.Timer\n\tdthresh           time.Duration\n\tmch               chan struct{}\n\tqch               chan struct{}\n\tinch              chan bool\n\tsfreq             int32\n\tackEventT         string\n\tdeliveryExcEventT string\n\tcreated           time.Time\n\tclosed            bool\n\n\t// Clustered.\n\tca      *consumerAssignment\n\tnode    RaftNode\n\tinfoSub *subscription\n\tlqsent  time.Time\n\n\t// R>1 proposals\n\tpch   chan struct{}\n\tphead *proposal\n\tptail *proposal\n}\n\ntype proposal struct {\n\tdata []byte\n\tnext *proposal\n}\n\nconst (\n\t// JsAckWaitDefault is the default AckWait, only applicable on explicit ack policy consumers.\n\tJsAckWaitDefault = 30 * time.Second\n\t// JsDeleteWaitTimeDefault is the default amount of time we will wait for non-durable\n\t// consumers to be in an inactive state before deleting them.\n\tJsDeleteWaitTimeDefault = 5 * time.Second\n\t// JsFlowControlMaxPending specifies default pending bytes during flow control that can be\n\t// outstanding.\n\tJsFlowControlMaxPending = 1 * 1024 * 1024\n\t// JsDefaultMaxAckPending is set for consumers with explicit ack that do not set the max ack pending.\n\tJsDefaultMaxAckPending = 20_000\n)\n\nfunc (mset *stream) addConsumer(config *ConsumerConfig) (*consumer, error) {\n\treturn mset.addConsumerWithAssignment(config, _EMPTY_, nil)\n}\n\nfunc (mset *stream) addConsumerWithAssignment(config *ConsumerConfig, oname string, ca *consumerAssignment) (*consumer, error) {\n\tmset.mu.RLock()\n\ts, jsa := mset.srv, mset.jsa\n\tmset.mu.RUnlock()\n\n\t// If we do not have the consumer currently assigned to us in cluster mode we will proceed but warn.\n\t// This can happen on startup with restored state where on meta replay we still do not have\n\t// the assignment. Running in single server mode this always returns true.\n\tif oname != _EMPTY_ && !jsa.consumerAssigned(mset.name(), oname) {\n\t\ts.Debugf(\"Consumer %q > %q does not seem to be assigned to this server\", mset.name(), oname)\n\t}\n\n\tif config == nil {\n\t\treturn nil, NewJSConsumerConfigRequiredError()\n\t}\n\n\tif len(config.Description) > JSMaxDescriptionLen {\n\t\treturn nil, NewJSConsumerDescriptionTooLongError(JSMaxDescriptionLen)\n\t}\n\n\tvar err error\n\t// For now expect a literal subject if its not empty. Empty means work queue mode (pull mode).\n\tif config.DeliverSubject != _EMPTY_ {\n\t\tif !subjectIsLiteral(config.DeliverSubject) {\n\t\t\treturn nil, NewJSConsumerDeliverToWildcardsError()\n\t\t}\n\t\tif mset.deliveryFormsCycle(config.DeliverSubject) {\n\t\t\treturn nil, NewJSConsumerDeliverCycleError()\n\t\t}\n\t\tif config.MaxWaiting != 0 {\n\t\t\treturn nil, NewJSConsumerPushMaxWaitingError()\n\t\t}\n\t\tif config.MaxAckPending > 0 && config.AckPolicy == AckNone {\n\t\t\treturn nil, NewJSConsumerMaxPendingAckPolicyRequiredError()\n\t\t}\n\t\tif config.Heartbeat > 0 && config.Heartbeat < 100*time.Millisecond {\n\t\t\treturn nil, NewJSConsumerSmallHeartbeatError()\n\t\t}\n\t} else {\n\t\t// Pull mode / work queue mode require explicit ack.\n\t\tif config.AckPolicy != AckExplicit {\n\t\t\treturn nil, NewJSConsumerPullRequiresAckError()\n\t\t}\n\t\t// They are also required to be durable since otherwise we will not know when to\n\t\t// clean them up.\n\t\tif config.Durable == _EMPTY_ {\n\t\t\treturn nil, NewJSConsumerPullNotDurableError()\n\t\t}\n\t\tif config.RateLimit > 0 {\n\t\t\treturn nil, NewJSConsumerPullWithRateLimitError()\n\t\t}\n\t\tif config.MaxWaiting < 0 {\n\t\t\treturn nil, NewJSConsumerMaxWaitingNegativeError()\n\t\t}\n\t\t// Set to default if not specified.\n\t\tif config.MaxWaiting == 0 {\n\t\t\tconfig.MaxWaiting = JSWaitQueueDefaultMax\n\t\t}\n\t\tif config.Heartbeat > 0 {\n\t\t\treturn nil, NewJSConsumerHBRequiresPushError()\n\t\t}\n\t\tif config.FlowControl {\n\t\t\treturn nil, NewJSConsumerFCRequiresPushError()\n\t\t}\n\t}\n\n\t// Direct need to be non-mapped ephemerals.\n\tif config.Direct {\n\t\tif config.DeliverSubject == _EMPTY_ {\n\t\t\treturn nil, NewJSConsumerDirectRequiresPushError()\n\t\t}\n\t\tif isDurableConsumer(config) {\n\t\t\treturn nil, NewJSConsumerDirectRequiresEphemeralError()\n\t\t}\n\t\tif ca != nil {\n\t\t\treturn nil, NewJSConsumerOnMappedError()\n\t\t}\n\t}\n\n\t// Setup proper default for ack wait if we are in explicit ack mode.\n\tif config.AckWait == 0 && (config.AckPolicy == AckExplicit || config.AckPolicy == AckAll) {\n\t\tconfig.AckWait = JsAckWaitDefault\n\t}\n\t// Setup default of -1, meaning no limit for MaxDeliver.\n\tif config.MaxDeliver == 0 {\n\t\tconfig.MaxDeliver = -1\n\t}\n\t// Set proper default for max ack pending if we are ack explicit and none has been set.\n\tif (config.AckPolicy == AckExplicit || config.AckPolicy == AckAll) && config.MaxAckPending == 0 {\n\t\tconfig.MaxAckPending = JsDefaultMaxAckPending\n\t}\n\n\t// As best we can make sure the filtered subject is valid.\n\tif config.FilterSubject != _EMPTY_ {\n\t\tsubjects, hasExt := mset.allSubjects()\n\t\tif !validFilteredSubject(config.FilterSubject, subjects) && !hasExt {\n\t\t\treturn nil, NewJSConsumerFilterNotSubsetError()\n\t\t}\n\t}\n\n\t// Check on start position conflicts.\n\tswitch config.DeliverPolicy {\n\tcase DeliverAll:\n\t\tif config.OptStartSeq > 0 {\n\t\t\treturn nil, NewJSConsumerInvalidPolicyError(fmt.Errorf(\"consumer delivery policy is deliver all, but optional start sequence is also set\"))\n\t\t}\n\t\tif config.OptStartTime != nil {\n\t\t\treturn nil, NewJSConsumerInvalidPolicyError(fmt.Errorf(\"consumer delivery policy is deliver all, but optional start time is also set\"))\n\t\t}\n\tcase DeliverLast:\n\t\tif config.OptStartSeq > 0 {\n\t\t\treturn nil, NewJSConsumerInvalidPolicyError(fmt.Errorf(\"consumer delivery policy is deliver last, but optional start sequence is also set\"))\n\t\t}\n\t\tif config.OptStartTime != nil {\n\t\t\treturn nil, NewJSConsumerInvalidPolicyError(fmt.Errorf(\"consumer delivery policy is deliver last, but optional start time is also set\"))\n\t\t}\n\tcase DeliverLastPerSubject:\n\t\tif config.OptStartSeq > 0 {\n\t\t\treturn nil, NewJSConsumerInvalidPolicyError(fmt.Errorf(\"consumer delivery policy is deliver last per subject, but optional start sequence is also set\"))\n\t\t}\n\t\tif config.OptStartTime != nil {\n\t\t\treturn nil, NewJSConsumerInvalidPolicyError(fmt.Errorf(\"consumer delivery policy is deliver last per subject, but optional start time is also set\"))\n\t\t}\n\t\tbadConfig := config.FilterSubject == _EMPTY_\n\t\tif !badConfig {\n\t\t\tsubjects, ext := mset.allSubjects()\n\t\t\tif len(subjects) == 1 && !ext && subjects[0] == config.FilterSubject && subjectIsLiteral(subjects[0]) {\n\t\t\t\tbadConfig = true\n\t\t\t}\n\t\t}\n\t\tif badConfig {\n\t\t\treturn nil, NewJSConsumerInvalidPolicyError(fmt.Errorf(\"consumer delivery policy is deliver last per subject, but filter subject is not set\"))\n\t\t}\n\tcase DeliverNew:\n\t\tif config.OptStartSeq > 0 {\n\t\t\treturn nil, NewJSConsumerInvalidPolicyError(fmt.Errorf(\"consumer delivery policy is deliver new, but optional start sequence is also set\"))\n\t\t}\n\t\tif config.OptStartTime != nil {\n\t\t\treturn nil, NewJSConsumerInvalidPolicyError(fmt.Errorf(\"consumer delivery policy is deliver new, but optional start time is also set\"))\n\t\t}\n\tcase DeliverByStartSequence:\n\t\tif config.OptStartSeq == 0 {\n\t\t\treturn nil, NewJSConsumerInvalidPolicyError(fmt.Errorf(\"consumer delivery policy is deliver by start sequence, but optional start sequence is not set\"))\n\t\t}\n\t\tif config.OptStartTime != nil {\n\t\t\treturn nil, NewJSConsumerInvalidPolicyError(fmt.Errorf(\"consumer delivery policy is deliver by start sequence, but optional start time is also set\"))\n\t\t}\n\tcase DeliverByStartTime:\n\t\tif config.OptStartTime == nil {\n\t\t\treturn nil, NewJSConsumerInvalidPolicyError(fmt.Errorf(\"consumer delivery policy is deliver by start time, but optional start time is not set\"))\n\t\t}\n\t\tif config.OptStartSeq != 0 {\n\t\t\treturn nil, NewJSConsumerInvalidPolicyError(fmt.Errorf(\"consumer delivery policy is deliver by start time, but optional start sequence is also set\"))\n\t\t}\n\t}\n\n\tsampleFreq := 0\n\tif config.SampleFrequency != _EMPTY_ {\n\t\ts := strings.TrimSuffix(config.SampleFrequency, \"%\")\n\t\tsampleFreq, err = strconv.Atoi(s)\n\t\tif err != nil {\n\t\t\treturn nil, NewJSConsumerInvalidSamplingError(err)\n\t\t}\n\t}\n\n\t// Grab the client, account and server reference.\n\tc := mset.client\n\tif c == nil {\n\t\treturn nil, NewJSStreamInvalidError()\n\t}\n\tc.mu.Lock()\n\ts, a := c.srv, c.acc\n\tc.mu.Unlock()\n\n\t// Hold mset lock here.\n\tmset.mu.Lock()\n\tif mset.client == nil || mset.store == nil {\n\t\tmset.mu.Unlock()\n\t\treturn nil, errors.New(\"invalid stream\")\n\t}\n\n\t// If this one is durable and already exists, we let that be ok as long as the configs match.\n\tif isDurableConsumer(config) {\n\t\tif eo, ok := mset.consumers[config.Durable]; ok {\n\t\t\tmset.mu.Unlock()\n\t\t\tocfg := eo.config()\n\t\t\tif reflect.DeepEqual(&ocfg, config) {\n\t\t\t\treturn eo, nil\n\t\t\t} else {\n\t\t\t\t// If we are a push mode and not active and the only difference\n\t\t\t\t// is deliver subject then update and return.\n\t\t\t\tif configsEqualSansDelivery(ocfg, *config) && eo.hasNoLocalInterest() {\n\t\t\t\t\teo.updateDeliverSubject(config.DeliverSubject)\n\t\t\t\t\treturn eo, nil\n\t\t\t\t} else {\n\t\t\t\t\treturn nil, NewJSConsumerNameExistError()\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check for any limits, if the config for the consumer sets a limit we check against that\n\t// but if not we use the value from account limits, if account limits is more restrictive\n\t// than stream config we prefer the account limits to handle cases where account limits are\n\t// updated during the lifecycle of the stream\n\tmaxc := mset.cfg.MaxConsumers\n\tif maxc <= 0 || (mset.jsa.limits.MaxConsumers > 0 && mset.jsa.limits.MaxConsumers < maxc) {\n\t\tmaxc = mset.jsa.limits.MaxConsumers\n\t}\n\tif maxc > 0 && len(mset.consumers) >= maxc {\n\t\tmset.mu.Unlock()\n\t\treturn nil, NewJSMaximumConsumersLimitError()\n\t}\n\n\t// Check on stream type conflicts with WorkQueues.\n\tif mset.cfg.Retention == WorkQueuePolicy && !config.Direct {\n\t\t// Force explicit acks here.\n\t\tif config.AckPolicy != AckExplicit {\n\t\t\tmset.mu.Unlock()\n\t\t\treturn nil, NewJSConsumerWQRequiresExplicitAckError()\n\t\t}\n\n\t\tif len(mset.consumers) > 0 {\n\t\t\tif config.FilterSubject == _EMPTY_ {\n\t\t\t\tmset.mu.Unlock()\n\t\t\t\treturn nil, NewJSConsumerWQMultipleUnfilteredError()\n\t\t\t} else if !mset.partitionUnique(config.FilterSubject) {\n\t\t\t\t// We have a partition but it is not unique amongst the others.\n\t\t\t\tmset.mu.Unlock()\n\t\t\t\treturn nil, NewJSConsumerWQConsumerNotUniqueError()\n\t\t\t}\n\t\t}\n\t\tif config.DeliverPolicy != DeliverAll {\n\t\t\tmset.mu.Unlock()\n\t\t\treturn nil, NewJSConsumerWQConsumerNotDeliverAllError()\n\t\t}\n\t}\n\n\t// Set name, which will be durable name if set, otherwise we create one at random.\n\to := &consumer{\n\t\tmset:    mset,\n\t\tjs:      s.getJetStream(),\n\t\tacc:     a,\n\t\tsrv:     s,\n\t\tclient:  s.createInternalJetStreamClient(),\n\t\tsysc:    s.createInternalJetStreamClient(),\n\t\tcfg:     *config,\n\t\tdsubj:   config.DeliverSubject,\n\t\toutq:    mset.outq,\n\t\tactive:  true,\n\t\tqch:     make(chan struct{}),\n\t\tmch:     make(chan struct{}, 1),\n\t\tsfreq:   int32(sampleFreq),\n\t\tmaxdc:   uint64(config.MaxDeliver),\n\t\tmaxp:    config.MaxAckPending,\n\t\tcreated: time.Now().UTC(),\n\t}\n\n\t// Bind internal client to the user account.\n\to.client.registerWithAccount(a)\n\t// Bind to the system account.\n\to.sysc.registerWithAccount(s.SystemAccount())\n\n\tif isDurableConsumer(config) {\n\t\tif len(config.Durable) > JSMaxNameLen {\n\t\t\tmset.mu.Unlock()\n\t\t\to.deleteWithoutAdvisory()\n\t\t\treturn nil, NewJSConsumerNameTooLongError(JSMaxNameLen)\n\t\t}\n\t\to.name = config.Durable\n\t\tif o.isPullMode() {\n\t\t\to.waiting = newWaitQueue(config.MaxWaiting)\n\t\t}\n\t} else if oname != _EMPTY_ {\n\t\to.name = oname\n\t} else {\n\t\tfor {\n\t\t\to.name = createConsumerName()\n\t\t\tif _, ok := mset.consumers[o.name]; !ok {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check if we have a rate limit set.\n\tif config.RateLimit != 0 {\n\t\t// TODO(dlc) - Make sane values or error if not sane?\n\t\t// We are configured in bits per sec so adjust to bytes.\n\t\trl := rate.Limit(config.RateLimit / 8)\n\t\t// Burst should be set to maximum msg size for this account, etc.\n\t\tvar burst int\n\t\tif mset.cfg.MaxMsgSize > 0 {\n\t\t\tburst = int(mset.cfg.MaxMsgSize)\n\t\t} else if mset.jsa.account.limits.mpay > 0 {\n\t\t\tburst = int(mset.jsa.account.limits.mpay)\n\t\t} else {\n\t\t\ts := mset.jsa.account.srv\n\t\t\tburst = int(s.getOpts().MaxPayload)\n\t\t}\n\t\to.rlimit = rate.NewLimiter(rl, burst)\n\t}\n\n\t// Check if we have  filtered subject that is a wildcard.\n\tif config.FilterSubject != _EMPTY_ && subjectHasWildcard(config.FilterSubject) {\n\t\to.filterWC = true\n\t}\n\n\t// already under lock, mset.Name() would deadlock\n\to.stream = mset.cfg.Name\n\to.ackEventT = JSMetricConsumerAckPre + \".\" + o.stream + \".\" + o.name\n\to.deliveryExcEventT = JSAdvisoryConsumerMaxDeliveryExceedPre + \".\" + o.stream + \".\" + o.name\n\n\tif !isValidName(o.name) {\n\t\tmset.mu.Unlock()\n\t\to.deleteWithoutAdvisory()\n\t\treturn nil, NewJSConsumerBadDurableNameError()\n\t}\n\n\t// Select starting sequence number\n\to.selectStartingSeqNo()\n\n\tif !config.Direct {\n\t\tstore, err := mset.store.ConsumerStore(o.name, config)\n\t\tif err != nil {\n\t\t\tmset.mu.Unlock()\n\t\t\to.deleteWithoutAdvisory()\n\t\t\treturn nil, NewJSConsumerStoreFailedError(err)\n\t\t}\n\t\to.store = store\n\t}\n\n\t// Now register with mset and create the ack subscription.\n\t// Check if we already have this one registered.\n\tif eo, ok := mset.consumers[o.name]; ok {\n\t\tmset.mu.Unlock()\n\t\tif !o.isDurable() || !o.isPushMode() {\n\t\t\to.name = _EMPTY_ // Prevent removal since same name.\n\t\t\to.deleteWithoutAdvisory()\n\t\t\treturn nil, NewJSConsumerNameExistError()\n\t\t}\n\t\t// If we are here we have already registered this durable. If it is still active that is an error.\n\t\tif eo.isActive() {\n\t\t\to.name = _EMPTY_ // Prevent removal since same name.\n\t\t\to.deleteWithoutAdvisory()\n\t\t\treturn nil, NewJSConsumerExistingActiveError()\n\t\t}\n\t\t// Since we are here this means we have a potentially new durable so we should update here.\n\t\t// Check that configs are the same.\n\t\tif !configsEqualSansDelivery(o.cfg, eo.cfg) {\n\t\t\to.name = _EMPTY_ // Prevent removal since same name.\n\t\t\to.deleteWithoutAdvisory()\n\t\t\treturn nil, NewJSConsumerReplacementWithDifferentNameError()\n\t\t}\n\t\t// Once we are here we have a replacement push-based durable.\n\t\teo.updateDeliverSubject(o.cfg.DeliverSubject)\n\t\treturn eo, nil\n\t}\n\n\t// Set up the ack subscription for this consumer. Will use wildcard for all acks.\n\t// We will remember the template to generate replies with sequence numbers and use\n\t// that to scanf them back in.\n\tmn := mset.cfg.Name\n\tpre := fmt.Sprintf(jsAckT, mn, o.name)\n\to.ackReplyT = fmt.Sprintf(\"%s.%%d.%%d.%%d.%%d.%%d\", pre)\n\to.ackSubj = fmt.Sprintf(\"%s.*.*.*.*.*\", pre)\n\to.nextMsgSubj = fmt.Sprintf(JSApiRequestNextT, mn, o.name)\n\n\tif o.isPushMode() {\n\t\to.dthresh = JsDeleteWaitTimeDefault\n\t\tif !o.isDurable() {\n\t\t\t// Check if we are not durable that the delivery subject has interest.\n\t\t\t// Check in place here for interest. Will setup properly in setLeader.\n\t\t\tr := o.acc.sl.Match(o.cfg.DeliverSubject)\n\t\t\tif !o.hasDeliveryInterest(len(r.psubs)+len(r.qsubs) > 0) {\n\t\t\t\t// Let the interest come to us eventually, but setup delete timer.\n\t\t\t\to.updateDeliveryInterest(false)\n\t\t\t}\n\t\t}\n\t}\n\n\t// Set our ca.\n\tif ca != nil {\n\t\to.setConsumerAssignment(ca)\n\t}\n\n\tmset.setConsumer(o)\n\tmset.mu.Unlock()\n\n\tif config.Direct || (!s.JetStreamIsClustered() && s.standAloneMode()) {\n\t\to.setLeader(true)\n\t}\n\n\t// This is always true in single server mode.\n\tif o.isLeader() {\n\t\t// Send advisory.\n\t\tvar suppress bool\n\t\tif !s.standAloneMode() && ca == nil {\n\t\t\tsuppress = true\n\t\t} else if ca != nil {\n\t\t\tsuppress = ca.responded\n\t\t}\n\t\tif !suppress {\n\t\t\to.sendCreateAdvisory()\n\t\t}\n\t}\n\n\treturn o, nil\n}\n\nfunc (o *consumer) consumerAssignment() *consumerAssignment {\n\to.mu.RLock()\n\tdefer o.mu.RUnlock()\n\treturn o.ca\n}\n\nfunc (o *consumer) setConsumerAssignment(ca *consumerAssignment) {\n\to.mu.Lock()\n\tdefer o.mu.Unlock()\n\to.ca = ca\n\t// Set our node.\n\tif ca != nil {\n\t\to.node = ca.Group.node\n\t}\n}\n\n// Lock should be held.\nfunc (o *consumer) isLeader() bool {\n\tif o.node != nil {\n\t\treturn o.node.Leader()\n\t}\n\treturn true\n}\n\nfunc (o *consumer) setLeader(isLeader bool) {\n\to.mu.RLock()\n\tmset := o.mset\n\tisRunning := o.ackSub != nil\n\to.mu.RUnlock()\n\n\t// If we are here we have a change in leader status.\n\tif isLeader {\n\t\tif mset == nil || isRunning {\n\t\t\treturn\n\t\t}\n\n\t\tmset.mu.RLock()\n\t\ts, jsa, stream := mset.srv, mset.jsa, mset.cfg.Name\n\t\tmset.mu.RUnlock()\n\n\t\to.mu.Lock()\n\t\t// Restore our saved state. During non-leader status we just update our underlying store.\n\t\to.readStoredState()\n\n\t\t// Do info sub.\n\t\tif o.infoSub == nil && jsa != nil {\n\t\t\tisubj := fmt.Sprintf(clusterConsumerInfoT, jsa.acc(), stream, o.name)\n\t\t\t// Note below the way we subscribe here is so that we can send requests to ourselves.\n\t\t\to.infoSub, _ = s.systemSubscribe(isubj, _EMPTY_, false, o.sysc, o.handleClusterConsumerInfoRequest)\n\t\t}\n\n\t\tvar err error\n\t\tif o.ackSub, err = o.subscribeInternal(o.ackSubj, o.processAck); err != nil {\n\t\t\to.mu.Unlock()\n\t\t\to.deleteWithoutAdvisory()\n\t\t\treturn\n\t\t}\n\n\t\t// Setup the internal sub for next message requests regardless.\n\t\t// Will error if wrong mode to provide feedback to users.\n\t\tif o.reqSub, err = o.subscribeInternal(o.nextMsgSubj, o.processNextMsgReq); err != nil {\n\t\t\to.mu.Unlock()\n\t\t\to.deleteWithoutAdvisory()\n\t\t\treturn\n\t\t}\n\n\t\t// Check on flow control settings.\n\t\tif o.cfg.FlowControl {\n\t\t\to.setMaxPendingBytes(JsFlowControlMaxPending)\n\t\t\tfcsubj := fmt.Sprintf(jsFlowControl, stream, o.name)\n\t\t\tif o.fcSub, err = o.subscribeInternal(fcsubj, o.processFlowControl); err != nil {\n\t\t\t\to.mu.Unlock()\n\t\t\t\to.deleteWithoutAdvisory()\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\t// Setup initial pending and proper start sequence.\n\t\to.setInitialPendingAndStart()\n\n\t\t// If push mode, register for notifications on interest.\n\t\tif o.isPushMode() {\n\t\t\to.inch = make(chan bool, 8)\n\t\t\to.acc.sl.RegisterNotification(o.cfg.DeliverSubject, o.inch)\n\t\t\tif o.active = <-o.inch; !o.active {\n\t\t\t\t// Check gateways in case they are enabled.\n\t\t\t\tif s.gateway.enabled {\n\t\t\t\t\to.active = s.hasGatewayInterest(o.acc.Name, o.cfg.DeliverSubject)\n\t\t\t\t\tstopAndClearTimer(&o.gwdtmr)\n\t\t\t\t\to.gwdtmr = time.AfterFunc(time.Second, func() { o.watchGWinterest() })\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// If we are not in ReplayInstant mode mark us as in replay state until resolved.\n\t\tif o.cfg.ReplayPolicy != ReplayInstant {\n\t\t\to.replay = true\n\t\t}\n\n\t\t// Recreate quit channel.\n\t\to.qch = make(chan struct{})\n\t\tqch := o.qch\n\t\tnode := o.node\n\t\tif node != nil && o.pch == nil {\n\t\t\to.pch = make(chan struct{}, 1)\n\t\t}\n\t\to.mu.Unlock()\n\n\t\t// Now start up Go routine to deliver msgs.\n\t\tgo o.loopAndGatherMsgs(qch)\n\n\t\t// If we are R>1 spin up our proposal loop.\n\t\tif node != nil {\n\t\t\tgo o.loopAndForwardProposals(qch)\n\t\t}\n\n\t} else {\n\t\t// Shutdown the go routines and the subscriptions.\n\t\to.mu.Lock()\n\t\to.unsubscribe(o.ackSub)\n\t\to.unsubscribe(o.reqSub)\n\t\to.unsubscribe(o.fcSub)\n\t\to.ackSub = nil\n\t\to.reqSub = nil\n\t\to.fcSub = nil\n\t\tif o.infoSub != nil {\n\t\t\to.srv.sysUnsubscribe(o.infoSub)\n\t\t\to.infoSub = nil\n\t\t}\n\t\tif o.qch != nil {\n\t\t\tclose(o.qch)\n\t\t\to.qch = nil\n\t\t}\n\t\to.mu.Unlock()\n\t}\n}\n\nfunc (o *consumer) handleClusterConsumerInfoRequest(sub *subscription, c *client, _ *Account, subject, reply string, msg []byte) {\n\to.mu.RLock()\n\tsysc := o.sysc\n\to.mu.RUnlock()\n\tsysc.sendInternalMsg(reply, _EMPTY_, nil, o.info())\n}\n\n// Lock should be held.\nfunc (o *consumer) subscribeInternal(subject string, cb msgHandler) (*subscription, error) {\n\tc := o.client\n\tif c == nil {\n\t\treturn nil, fmt.Errorf(\"invalid consumer\")\n\t}\n\tif !c.srv.eventsEnabled() {\n\t\treturn nil, ErrNoSysAccount\n\t}\n\tif cb == nil {\n\t\treturn nil, fmt.Errorf(\"undefined message handler\")\n\t}\n\n\to.sid++\n\n\t// Now create the subscription\n\treturn c.processSub([]byte(subject), nil, []byte(strconv.Itoa(o.sid)), cb, false)\n}\n\n// Unsubscribe from our subscription.\n// Lock should be held.\nfunc (o *consumer) unsubscribe(sub *subscription) {\n\tif sub == nil || o.client == nil {\n\t\treturn\n\t}\n\to.client.processUnsub(sub.sid)\n}\n\n// We need to make sure we protect access to the outq.\n// Do all advisory sends here.\nfunc (o *consumer) sendAdvisory(subj string, msg []byte) {\n\to.outq.sendMsg(subj, msg)\n}\n\nfunc (o *consumer) sendDeleteAdvisoryLocked() {\n\te := JSConsumerActionAdvisory{\n\t\tTypedEvent: TypedEvent{\n\t\t\tType: JSConsumerActionAdvisoryType,\n\t\t\tID:   nuid.Next(),\n\t\t\tTime: time.Now().UTC(),\n\t\t},\n\t\tStream:   o.stream,\n\t\tConsumer: o.name,\n\t\tAction:   DeleteEvent,\n\t\tDomain:   o.srv.getOpts().JetStreamDomain,\n\t}\n\n\tj, err := json.Marshal(e)\n\tif err != nil {\n\t\treturn\n\t}\n\n\tsubj := JSAdvisoryConsumerDeletedPre + \".\" + o.stream + \".\" + o.name\n\to.sendAdvisory(subj, j)\n}\n\nfunc (o *consumer) sendCreateAdvisory() {\n\to.mu.Lock()\n\tdefer o.mu.Unlock()\n\n\te := JSConsumerActionAdvisory{\n\t\tTypedEvent: TypedEvent{\n\t\t\tType: JSConsumerActionAdvisoryType,\n\t\t\tID:   nuid.Next(),\n\t\t\tTime: time.Now().UTC(),\n\t\t},\n\t\tStream:   o.stream,\n\t\tConsumer: o.name,\n\t\tAction:   CreateEvent,\n\t\tDomain:   o.srv.getOpts().JetStreamDomain,\n\t}\n\n\tj, err := json.Marshal(e)\n\tif err != nil {\n\t\treturn\n\t}\n\n\tsubj := JSAdvisoryConsumerCreatedPre + \".\" + o.stream + \".\" + o.name\n\to.sendAdvisory(subj, j)\n}\n\n// Created returns created time.\nfunc (o *consumer) createdTime() time.Time {\n\to.mu.Lock()\n\tcreated := o.created\n\to.mu.Unlock()\n\treturn created\n}\n\n// Internal to allow creation time to be restored.\nfunc (o *consumer) setCreatedTime(created time.Time) {\n\to.mu.Lock()\n\to.created = created\n\to.mu.Unlock()\n}\n\n// This will check for extended interest in a subject. If we have local interest we just return\n// that, but in the absence of local interest and presence of gateways or service imports we need\n// to check those as well.\nfunc (o *consumer) hasDeliveryInterest(localInterest bool) bool {\n\to.mu.Lock()\n\tmset := o.mset\n\tif mset == nil {\n\t\to.mu.Unlock()\n\t\treturn false\n\t}\n\tacc := o.acc\n\tdeliver := o.cfg.DeliverSubject\n\to.mu.Unlock()\n\n\tif localInterest {\n\t\treturn true\n\t}\n\n\t// If we are here check gateways.\n\tif s := acc.srv; s != nil && s.hasGatewayInterest(acc.Name, deliver) {\n\t\treturn true\n\t}\n\treturn false\n}\n\nfunc (s *Server) hasGatewayInterest(account, subject string) bool {\n\tgw := s.gateway\n\tif !gw.enabled {\n\t\treturn false\n\t}\n\tgw.RLock()\n\tdefer gw.RUnlock()\n\tfor _, gwc := range gw.outo {\n\t\tpsi, qr := gwc.gatewayInterest(account, subject)\n\t\tif psi || qr != nil {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\n// This processes an update to the local interest for a deliver subject.\nfunc (o *consumer) updateDeliveryInterest(localInterest bool) bool {\n\tinterest := o.hasDeliveryInterest(localInterest)\n\n\to.mu.Lock()\n\tdefer o.mu.Unlock()\n\n\tmset := o.mset\n\tif mset == nil || o.isPullMode() {\n\t\treturn false\n\t}\n\n\tif interest && !o.active {\n\t\to.signalNewMessages()\n\t}\n\to.active = interest\n\n\t// If the delete timer has already been set do not clear here and return.\n\tif o.dtmr != nil && !o.isDurable() && !interest {\n\t\treturn true\n\t}\n\n\t// Stop and clear the delete timer always.\n\tstopAndClearTimer(&o.dtmr)\n\n\t// If we do not have interest anymore and we are not durable start\n\t// a timer to delete us. We wait for a bit in case of server reconnect.\n\tif !o.isDurable() && !interest {\n\t\to.dtmr = time.AfterFunc(o.dthresh, func() { o.deleteNotActive() })\n\t\treturn true\n\t}\n\treturn false\n}\n\nfunc (o *consumer) deleteNotActive() {\n\t// Need to check again if there is not an interest now that the timer fires.\n\tif !o.hasNoLocalInterest() {\n\t\treturn\n\t}\n\to.mu.RLock()\n\tif o.mset == nil {\n\t\to.mu.RUnlock()\n\t\treturn\n\t}\n\ts, js := o.mset.srv, o.mset.srv.js\n\tacc, stream, name := o.acc.Name, o.stream, o.name\n\to.mu.RUnlock()\n\n\t// If we are clustered, check if we still have this consumer assigned.\n\t// If we do forward a proposal to delete ourselves to the metacontroller leader.\n\tif s.JetStreamIsClustered() {\n\t\tjs.mu.RLock()\n\t\tca := js.consumerAssignment(acc, stream, name)\n\t\tcc := js.cluster\n\t\tjs.mu.RUnlock()\n\t\tif ca != nil && cc != nil {\n\t\t\tcca := *ca\n\t\t\tcca.Reply = _EMPTY_\n\t\t\tmeta, removeEntry := cc.meta, encodeDeleteConsumerAssignment(&cca)\n\t\t\tmeta.ForwardProposal(removeEntry)\n\n\t\t\t// Check to make sure we went away.\n\t\t\t// Don't think this needs to be a monitored go routine.\n\t\t\tgo func() {\n\t\t\t\tticker := time.NewTicker(time.Second)\n\t\t\t\tdefer ticker.Stop()\n\t\t\t\tfor range ticker.C {\n\t\t\t\t\tjs.mu.RLock()\n\t\t\t\t\tca := js.consumerAssignment(acc, stream, name)\n\t\t\t\t\tjs.mu.RUnlock()\n\t\t\t\t\tif ca != nil {\n\t\t\t\t\t\ts.Warnf(\"Consumer assignment not cleaned up, retrying\")\n\t\t\t\t\t\tmeta.ForwardProposal(removeEntry)\n\t\t\t\t\t} else {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t}\n\n\t// We will delete here regardless.\n\to.delete()\n}\n\nfunc (o *consumer) watchGWinterest() {\n\tpa := o.isActive()\n\t// If there is no local interest...\n\tif o.hasNoLocalInterest() {\n\t\to.updateDeliveryInterest(false)\n\t\tif !pa && o.isActive() {\n\t\t\to.signalNewMessages()\n\t\t}\n\t}\n\n\t// We want this to always be running so we can also pick up on interest returning.\n\to.mu.Lock()\n\tif o.gwdtmr != nil {\n\t\to.gwdtmr.Reset(time.Second)\n\t} else {\n\t\tstopAndClearTimer(&o.gwdtmr)\n\t\to.gwdtmr = time.AfterFunc(time.Second, func() { o.watchGWinterest() })\n\t}\n\to.mu.Unlock()\n}\n\n// Config returns the consumer's configuration.\nfunc (o *consumer) config() ConsumerConfig {\n\to.mu.Lock()\n\tdefer o.mu.Unlock()\n\treturn o.cfg\n}\n\n// Force expiration of all pending.\n// Lock should be held.\nfunc (o *consumer) forceExpirePending() {\n\tvar expired []uint64\n\tfor seq := range o.pending {\n\t\tif !o.onRedeliverQueue(seq) {\n\t\t\texpired = append(expired, seq)\n\t\t}\n\t}\n\tif len(expired) > 0 {\n\t\tsort.Slice(expired, func(i, j int) bool { return expired[i] < expired[j] })\n\t\to.addToRedeliverQueue(expired...)\n\t\t// Now we should update the timestamp here since we are redelivering.\n\t\t// We will use an incrementing time to preserve order for any other redelivery.\n\t\toff := time.Now().UnixNano() - o.pending[expired[0]].Timestamp\n\t\tfor _, seq := range expired {\n\t\t\tif p, ok := o.pending[seq]; ok && p != nil {\n\t\t\t\tp.Timestamp += off\n\t\t\t}\n\t\t}\n\t\to.ptmr.Reset(o.ackWait(0))\n\t}\n\to.signalNewMessages()\n}\n\n// This is a config change for the delivery subject for a\n// push based consumer.\nfunc (o *consumer) updateDeliverSubject(newDeliver string) {\n\t// Update the config and the dsubj\n\to.mu.Lock()\n\tdefer o.mu.Unlock()\n\n\tif o.closed || o.isPullMode() || o.cfg.DeliverSubject == newDeliver {\n\t\treturn\n\t}\n\n\t// Force redeliver of all pending on change of delivery subject.\n\tif len(o.pending) > 0 {\n\t\to.forceExpirePending()\n\t}\n\n\to.acc.sl.ClearNotification(o.dsubj, o.inch)\n\to.dsubj, o.cfg.DeliverSubject = newDeliver, newDeliver\n\t// When we register new one it will deliver to update state loop.\n\to.acc.sl.RegisterNotification(newDeliver, o.inch)\n}\n\n// Check that configs are equal but allow delivery subjects to be different.\nfunc configsEqualSansDelivery(a, b ConsumerConfig) bool {\n\t// These were copied in so can set Delivery here.\n\ta.DeliverSubject, b.DeliverSubject = _EMPTY_, _EMPTY_\n\treturn a == b\n}\n\n// Helper to send a reply to an ack.\nfunc (o *consumer) sendAckReply(subj string) {\n\to.mu.Lock()\n\tdefer o.mu.Unlock()\n\to.sendAdvisory(subj, nil)\n}\n\n// Process a message for the ack reply subject delivered with a message.\nfunc (o *consumer) processAck(_ *subscription, c *client, acc *Account, subject, reply string, rmsg []byte) {\n\t_, msg := c.msgParts(rmsg)\n\tsseq, dseq, dc := ackReplyInfo(subject)\n\n\tskipAckReply := sseq == 0\n\n\tswitch {\n\tcase len(msg) == 0, bytes.Equal(msg, AckAck), bytes.Equal(msg, AckOK):\n\t\to.processAckMsg(sseq, dseq, dc, true)\n\tcase bytes.HasPrefix(msg, AckNext):\n\t\to.processAckMsg(sseq, dseq, dc, true)\n\t\t// processNextMsgReq can be invoked from an internal subscription or from here.\n\t\t// Therefore, it has to call msgParts(), so we can't simply pass msg[len(AckNext):]\n\t\t// with current c.pa.hdr because it would cause a panic.  We will save the current\n\t\t// c.pa.hdr value and disable headers before calling processNextMsgReq and then\n\t\t// restore so that we don't mess with the calling stack in case it is used\n\t\t// somewhere else.\n\t\tphdr := c.pa.hdr\n\t\tc.pa.hdr = -1\n\t\to.processNextMsgReq(nil, c, acc, subject, reply, msg[len(AckNext):])\n\t\tc.pa.hdr = phdr\n\t\tskipAckReply = true\n\tcase bytes.Equal(msg, AckNak):\n\t\to.processNak(sseq, dseq)\n\tcase bytes.Equal(msg, AckProgress):\n\t\to.progressUpdate(sseq)\n\tcase bytes.Equal(msg, AckTerm):\n\t\to.processTerm(sseq, dseq, dc)\n\t}\n\n\t// Ack the ack if requested.\n\tif len(reply) > 0 && !skipAckReply {\n\t\to.sendAckReply(reply)\n\t}\n}\n\n// Used to process a working update to delay redelivery.\nfunc (o *consumer) progressUpdate(seq uint64) {\n\to.mu.Lock()\n\tif len(o.pending) > 0 {\n\t\tif p, ok := o.pending[seq]; ok {\n\t\t\tp.Timestamp = time.Now().UnixNano()\n\t\t\t// Update store system.\n\t\t\to.updateDelivered(p.Sequence, seq, 1, p.Timestamp)\n\t\t}\n\t}\n\to.mu.Unlock()\n}\n\n// Lock should be held.\nfunc (o *consumer) updateSkipped() {\n\t// Clustered mode and R>1 only.\n\tif o.node == nil || !o.isLeader() {\n\t\treturn\n\t}\n\tvar b [1 + 8]byte\n\tb[0] = byte(updateSkipOp)\n\tvar le = binary.LittleEndian\n\tle.PutUint64(b[1:], o.sseq)\n\to.propose(b[:])\n}\n\nfunc (o *consumer) loopAndForwardProposals(qch chan struct{}) {\n\to.mu.RLock()\n\tnode, pch := o.node, o.pch\n\to.mu.RUnlock()\n\n\tif node == nil || pch == nil {\n\t\treturn\n\t}\n\n\tforwardProposals := func() {\n\t\to.mu.Lock()\n\t\tproposal := o.phead\n\t\to.phead, o.ptail = nil, nil\n\t\to.mu.Unlock()\n\t\t// 256k max for now per batch.\n\t\tconst maxBatch = 256 * 1024\n\t\tvar entries []*Entry\n\t\tfor sz := 0; proposal != nil; proposal = proposal.next {\n\t\t\tentries = append(entries, &Entry{EntryNormal, proposal.data})\n\t\t\tsz += len(proposal.data)\n\t\t\tif sz > maxBatch {\n\t\t\t\tnode.ProposeDirect(entries)\n\t\t\t\tsz, entries = 0, entries[:0]\n\t\t\t}\n\t\t}\n\t\tif len(entries) > 0 {\n\t\t\tnode.ProposeDirect(entries)\n\t\t}\n\t}\n\n\t// In case we have anything pending on entry.\n\tforwardProposals()\n\n\tfor {\n\t\tselect {\n\t\tcase <-qch:\n\t\t\tforwardProposals()\n\t\t\treturn\n\t\tcase <-pch:\n\t\t\tforwardProposals()\n\t\t}\n\t}\n}\n\n// Lock should be held.\nfunc (o *consumer) propose(entry []byte) {\n\tvar notify bool\n\tp := &proposal{data: entry}\n\tif o.phead == nil {\n\t\to.phead = p\n\t\tnotify = true\n\t} else {\n\t\to.ptail.next = p\n\t}\n\to.ptail = p\n\n\t// Kick our looper routine if needed.\n\tif notify {\n\t\tselect {\n\t\tcase o.pch <- struct{}{}:\n\t\tdefault:\n\t\t}\n\t}\n}\n\n// Lock should be held.\nfunc (o *consumer) updateDelivered(dseq, sseq, dc uint64, ts int64) {\n\t// Clustered mode and R>1.\n\tif o.node != nil {\n\t\t// Inline for now, use variable compression.\n\t\tvar b [4*binary.MaxVarintLen64 + 1]byte\n\t\tb[0] = byte(updateDeliveredOp)\n\t\tn := 1\n\t\tn += binary.PutUvarint(b[n:], dseq)\n\t\tn += binary.PutUvarint(b[n:], sseq)\n\t\tn += binary.PutUvarint(b[n:], dc)\n\t\tn += binary.PutVarint(b[n:], ts)\n\t\to.propose(b[:n])\n\t}\n\tif o.store != nil {\n\t\t// Update local state always.\n\t\to.store.UpdateDelivered(dseq, sseq, dc, ts)\n\t}\n}\n\n// Lock should be held.\nfunc (o *consumer) updateAcks(dseq, sseq uint64) {\n\tif o.node != nil {\n\t\t// Inline for now, use variable compression.\n\t\tvar b [2*binary.MaxVarintLen64 + 1]byte\n\t\tb[0] = byte(updateAcksOp)\n\t\tn := 1\n\t\tn += binary.PutUvarint(b[n:], dseq)\n\t\tn += binary.PutUvarint(b[n:], sseq)\n\t\to.propose(b[:n])\n\t} else if o.store != nil {\n\t\to.store.UpdateAcks(dseq, sseq)\n\t}\n}\n\n// Process a NAK.\nfunc (o *consumer) processNak(sseq, dseq uint64) {\n\to.mu.Lock()\n\tdefer o.mu.Unlock()\n\n\t// Check for out of range.\n\tif dseq <= o.adflr || dseq > o.dseq {\n\t\treturn\n\t}\n\t// If we are explicit ack make sure this is still on our pending list.\n\tif len(o.pending) > 0 {\n\t\tif _, ok := o.pending[sseq]; !ok {\n\t\t\treturn\n\t\t}\n\t}\n\t// If already queued up also ignore.\n\tif !o.onRedeliverQueue(sseq) {\n\t\to.addToRedeliverQueue(sseq)\n\t}\n\n\to.signalNewMessages()\n}\n\n// Process a TERM\nfunc (o *consumer) processTerm(sseq, dseq, dc uint64) {\n\t// Treat like an ack to suppress redelivery.\n\to.processAckMsg(sseq, dseq, dc, false)\n\n\to.mu.Lock()\n\tdefer o.mu.Unlock()\n\n\t// Deliver an advisory\n\te := JSConsumerDeliveryTerminatedAdvisory{\n\t\tTypedEvent: TypedEvent{\n\t\t\tType: JSConsumerDeliveryTerminatedAdvisoryType,\n\t\t\tID:   nuid.Next(),\n\t\t\tTime: time.Now().UTC(),\n\t\t},\n\t\tStream:      o.stream,\n\t\tConsumer:    o.name,\n\t\tConsumerSeq: dseq,\n\t\tStreamSeq:   sseq,\n\t\tDeliveries:  dc,\n\t\tDomain:      o.srv.getOpts().JetStreamDomain,\n\t}\n\n\tj, err := json.Marshal(e)\n\tif err != nil {\n\t\treturn\n\t}\n\n\tsubj := JSAdvisoryConsumerMsgTerminatedPre + \".\" + o.stream + \".\" + o.name\n\to.sendAdvisory(subj, j)\n}\n\n// Introduce a small delay in when timer fires to check pending.\n// Allows bursts to be treated in same time frame.\nconst ackWaitDelay = time.Millisecond\n\n// ackWait returns how long to wait to fire the pending timer.\nfunc (o *consumer) ackWait(next time.Duration) time.Duration {\n\tif next > 0 {\n\t\treturn next + ackWaitDelay\n\t}\n\treturn o.cfg.AckWait + ackWaitDelay\n}\n\n// This will restore the state from disk.\nfunc (o *consumer) readStoredState() error {\n\tif o.store == nil {\n\t\treturn nil\n\t}\n\tstate, err := o.store.State()\n\tif err == nil && state != nil {\n\t\to.applyState(state)\n\t}\n\treturn err\n}\n\n// Apply the consumer stored state.\nfunc (o *consumer) applyState(state *ConsumerState) {\n\tif state == nil {\n\t\treturn\n\t}\n\n\to.dseq = state.Delivered.Consumer + 1\n\to.sseq = state.Delivered.Stream + 1\n\to.adflr = state.AckFloor.Consumer\n\to.asflr = state.AckFloor.Stream\n\to.pending = state.Pending\n\to.rdc = state.Redelivered\n\n\t// Setup tracking timer if we have restored pending.\n\tif len(o.pending) > 0 && o.ptmr == nil {\n\t\to.ptmr = time.AfterFunc(o.ackWait(0), o.checkPending)\n\t}\n}\n\nfunc (o *consumer) readStoreState() *ConsumerState {\n\to.mu.RLock()\n\tdefer o.mu.RUnlock()\n\tif o.store == nil {\n\t\treturn nil\n\t}\n\tstate, _ := o.store.State()\n\treturn state\n}\n\n// Sets our store state from another source. Used in clustered mode on snapshot restore.\nfunc (o *consumer) setStoreState(state *ConsumerState) error {\n\tif state == nil || o.store == nil {\n\t\treturn nil\n\t}\n\to.applyState(state)\n\treturn o.store.Update(state)\n}\n\n// Update our state to the store.\nfunc (o *consumer) writeStoreState() error {\n\to.mu.Lock()\n\tdefer o.mu.Unlock()\n\n\tif o.store == nil {\n\t\treturn nil\n\t}\n\n\tstate := ConsumerState{\n\t\tDelivered: SequencePair{\n\t\t\tConsumer: o.dseq - 1,\n\t\t\tStream:   o.sseq - 1,\n\t\t},\n\t\tAckFloor: SequencePair{\n\t\t\tConsumer: o.adflr,\n\t\t\tStream:   o.asflr,\n\t\t},\n\t\tPending:     o.pending,\n\t\tRedelivered: o.rdc,\n\t}\n\treturn o.store.Update(&state)\n}\n\n// Info returns our current consumer state.\nfunc (o *consumer) info() *ConsumerInfo {\n\to.mu.RLock()\n\tmset := o.mset\n\tif mset == nil || mset.srv == nil {\n\t\to.mu.RUnlock()\n\t\treturn nil\n\t}\n\tjs := o.js\n\to.mu.RUnlock()\n\n\tif js == nil {\n\t\treturn nil\n\t}\n\n\tci := js.clusterInfo(o.raftGroup())\n\n\to.mu.RLock()\n\tdefer o.mu.RUnlock()\n\n\tcfg := o.cfg\n\tinfo := &ConsumerInfo{\n\t\tStream:  o.stream,\n\t\tName:    o.name,\n\t\tCreated: o.created,\n\t\tConfig:  &cfg,\n\t\tDelivered: SequencePair{\n\t\t\tConsumer: o.dseq - 1,\n\t\t\tStream:   o.sseq - 1,\n\t\t},\n\t\tAckFloor: SequencePair{\n\t\t\tConsumer: o.adflr,\n\t\t\tStream:   o.asflr,\n\t\t},\n\t\tNumAckPending:  len(o.pending),\n\t\tNumRedelivered: len(o.rdc),\n\t\tNumPending:     o.adjustedPending(),\n\t\tCluster:        ci,\n\t}\n\t// If we are a pull mode consumer, report on number of waiting requests.\n\tif o.isPullMode() {\n\t\tinfo.NumWaiting = o.waiting.len()\n\t}\n\treturn info\n}\n\n// Will signal us that new messages are available. Will break out of waiting.\nfunc (o *consumer) signalNewMessages() {\n\t// Kick our new message channel\n\tselect {\n\tcase o.mch <- struct{}{}:\n\tdefault:\n\t}\n}\n\n// shouldSample lets us know if we are sampling metrics on acks.\nfunc (o *consumer) shouldSample() bool {\n\tswitch {\n\tcase o.sfreq <= 0:\n\t\treturn false\n\tcase o.sfreq >= 100:\n\t\treturn true\n\t}\n\n\t// TODO(ripienaar) this is a tad slow so we need to rethink here, however this will only\n\t// hit for those with sampling enabled and its not the default\n\treturn rand.Int31n(100) <= o.sfreq\n}\n\nfunc (o *consumer) sampleAck(sseq, dseq, dc uint64) {\n\tif !o.shouldSample() {\n\t\treturn\n\t}\n\n\tnow := time.Now().UTC()\n\tunow := now.UnixNano()\n\n\te := JSConsumerAckMetric{\n\t\tTypedEvent: TypedEvent{\n\t\t\tType: JSConsumerAckMetricType,\n\t\t\tID:   nuid.Next(),\n\t\t\tTime: now,\n\t\t},\n\t\tStream:      o.stream,\n\t\tConsumer:    o.name,\n\t\tConsumerSeq: dseq,\n\t\tStreamSeq:   sseq,\n\t\tDelay:       unow - o.pending[sseq].Timestamp,\n\t\tDeliveries:  dc,\n\t\tDomain:      o.srv.getOpts().JetStreamDomain,\n\t}\n\n\tj, err := json.Marshal(e)\n\tif err != nil {\n\t\treturn\n\t}\n\n\to.sendAdvisory(o.ackEventT, j)\n}\n\nfunc (o *consumer) processAckMsg(sseq, dseq, dc uint64, doSample bool) {\n\to.mu.Lock()\n\tvar sagap uint64\n\tvar needSignal bool\n\n\tswitch o.cfg.AckPolicy {\n\tcase AckExplicit:\n\t\tif p, ok := o.pending[sseq]; ok {\n\t\t\tif doSample {\n\t\t\t\to.sampleAck(sseq, dseq, dc)\n\t\t\t}\n\t\t\tif o.maxp > 0 && len(o.pending) >= o.maxp {\n\t\t\t\tneedSignal = true\n\t\t\t}\n\t\t\tdelete(o.pending, sseq)\n\t\t\t// Use the original deliver sequence from our pending record.\n\t\t\tdseq = p.Sequence\n\t\t}\n\t\tif len(o.pending) == 0 {\n\t\t\to.adflr, o.asflr = o.dseq-1, o.sseq-1\n\t\t} else if dseq == o.adflr+1 {\n\t\t\to.adflr, o.asflr = dseq, sseq\n\t\t\tfor ss := sseq + 1; ss < o.sseq; ss++ {\n\t\t\t\tif p, ok := o.pending[ss]; ok {\n\t\t\t\t\tif p.Sequence > 0 {\n\t\t\t\t\t\to.adflr, o.asflr = p.Sequence-1, ss-1\n\t\t\t\t\t}\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t// We do these regardless.\n\t\tdelete(o.rdc, sseq)\n\t\to.removeFromRedeliverQueue(sseq)\n\tcase AckAll:\n\t\t// no-op\n\t\tif dseq <= o.adflr || sseq <= o.asflr {\n\t\t\to.mu.Unlock()\n\t\t\treturn\n\t\t}\n\t\tif o.maxp > 0 && len(o.pending) >= o.maxp {\n\t\t\tneedSignal = true\n\t\t}\n\t\tsagap = sseq - o.asflr\n\t\to.adflr, o.asflr = dseq, sseq\n\t\tfor seq := sseq; seq > sseq-sagap; seq-- {\n\t\t\tdelete(o.pending, seq)\n\t\t\tdelete(o.rdc, seq)\n\t\t\to.removeFromRedeliverQueue(seq)\n\t\t}\n\tcase AckNone:\n\t\t// FIXME(dlc) - This is error but do we care?\n\t\to.mu.Unlock()\n\t\treturn\n\t}\n\n\t// Update underlying store.\n\to.updateAcks(dseq, sseq)\n\n\tmset := o.mset\n\tclustered := o.node != nil\n\to.mu.Unlock()\n\n\t// Let the owning stream know if we are interest or workqueue retention based.\n\t// If this consumer is clustered this will be handled by processReplicatedAck\n\t// after the ack has propagated.\n\tif !clustered && mset != nil && mset.cfg.Retention != LimitsPolicy {\n\t\tif sagap > 1 {\n\t\t\t// FIXME(dlc) - This is very inefficient, will need to fix.\n\t\t\tfor seq := sseq; seq > sseq-sagap; seq-- {\n\t\t\t\tmset.ackMsg(o, seq)\n\t\t\t}\n\t\t} else {\n\t\t\tmset.ackMsg(o, sseq)\n\t\t}\n\t}\n\n\t// If we had max ack pending set and were at limit we need to unblock folks.\n\tif needSignal {\n\t\to.signalNewMessages()\n\t}\n}\n\n// Determine if this is a truly filtered consumer. Modern clients will place filtered subjects\n// even if the stream only has a single non-wildcard subject designation.\n// Read lock should be held.\nfunc (o *consumer) isFiltered() bool {\n\tif o.cfg.FilterSubject == _EMPTY_ {\n\t\treturn false\n\t}\n\t// If we are here we want to check if the filtered subject is\n\t// a direct match for our only listed subject.\n\tmset := o.mset\n\tif mset == nil {\n\t\treturn true\n\t}\n\tif len(mset.cfg.Subjects) > 1 {\n\t\treturn true\n\t}\n\treturn o.cfg.FilterSubject != mset.cfg.Subjects[0]\n}\n\n// Check if we need an ack for this store seq.\n// This is called for interest based retention streams to remove messages.\nfunc (o *consumer) needAck(sseq uint64) bool {\n\tvar needAck bool\n\tvar asflr, osseq uint64\n\tvar pending map[uint64]*Pending\n\to.mu.RLock()\n\tif o.isLeader() {\n\t\tasflr, osseq = o.asflr, o.sseq\n\t\tpending = o.pending\n\t} else {\n\t\tif o.store == nil {\n\t\t\to.mu.RUnlock()\n\t\t\treturn false\n\t\t}\n\t\tstate, err := o.store.State()\n\t\tif err != nil || state == nil {\n\t\t\t// Fall back to what we track internally for now.\n\t\t\tneedAck := sseq > o.asflr && !o.isFiltered()\n\t\t\to.mu.RUnlock()\n\t\t\treturn needAck\n\t\t}\n\t\tasflr, osseq = state.AckFloor.Stream, o.sseq\n\t\tpending = state.Pending\n\t}\n\tswitch o.cfg.AckPolicy {\n\tcase AckNone, AckAll:\n\t\tneedAck = sseq > asflr\n\tcase AckExplicit:\n\t\tif sseq > asflr {\n\t\t\t// Generally this means we need an ack, but just double check pending acks.\n\t\t\tneedAck = true\n\t\t\tif sseq < osseq {\n\t\t\t\tif len(pending) == 0 {\n\t\t\t\t\tneedAck = false\n\t\t\t\t} else {\n\t\t\t\t\t_, needAck = pending[sseq]\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\to.mu.RUnlock()\n\treturn needAck\n}\n\n// Helper for the next message requests.\nfunc nextReqFromMsg(msg []byte) (time.Time, int, bool, error) {\n\treq := bytes.TrimSpace(msg)\n\n\tswitch {\n\tcase len(req) == 0:\n\t\treturn time.Time{}, 1, false, nil\n\n\tcase req[0] == '{':\n\t\tvar cr JSApiConsumerGetNextRequest\n\t\tif err := json.Unmarshal(req, &cr); err != nil {\n\t\t\treturn time.Time{}, -1, false, err\n\t\t}\n\t\tif cr.Expires == time.Duration(0) {\n\t\t\treturn time.Time{}, cr.Batch, cr.NoWait, nil\n\t\t}\n\t\treturn time.Now().Add(cr.Expires), cr.Batch, cr.NoWait, nil\n\tdefault:\n\t\tif n, err := strconv.Atoi(string(req)); err == nil {\n\t\t\treturn time.Time{}, n, false, nil\n\t\t}\n\t}\n\n\treturn time.Time{}, 1, false, nil\n}\n\n// Represents a request that is on the internal waiting queue\ntype waitingRequest struct {\n\tclient  *client\n\treply   string\n\tn       int // For batching\n\texpires time.Time\n\tnoWait  bool\n}\n\n// waiting queue for requests that are waiting for new messages to arrive.\ntype waitQueue struct {\n\trp, wp int\n\treqs   []*waitingRequest\n}\n\n// Create a new ring buffer with at most max items.\nfunc newWaitQueue(max int) *waitQueue {\n\treturn &waitQueue{rp: -1, reqs: make([]*waitingRequest, max)}\n}\n\nvar (\n\terrWaitQueueFull = errors.New(\"wait queue is full\")\n\terrWaitQueueNil  = errors.New(\"wait queue is nil\")\n)\n\n// Adds in a new request.\nfunc (wq *waitQueue) add(req *waitingRequest) error {\n\tif wq == nil {\n\t\treturn errWaitQueueNil\n\t}\n\tif wq.isFull() {\n\t\treturn errWaitQueueFull\n\t}\n\twq.reqs[wq.wp] = req\n\t// TODO(dlc) - Could make pow2 and get rid of mod.\n\twq.wp = (wq.wp + 1) % cap(wq.reqs)\n\n\t// Adjust read pointer if we were empty.\n\tif wq.rp < 0 {\n\t\twq.rp = 0\n\t}\n\n\treturn nil\n}\n\nfunc (wq *waitQueue) isFull() bool {\n\treturn wq.rp == wq.wp\n}\n\nfunc (wq *waitQueue) len() int {\n\tif wq == nil || wq.rp < 0 {\n\t\treturn 0\n\t}\n\tif wq.rp < wq.wp {\n\t\treturn wq.wp - wq.rp\n\t}\n\treturn cap(wq.reqs) - wq.rp + wq.wp\n}\n\n// Peek will return the next request waiting or nil if empty.\nfunc (wq *waitQueue) peek() *waitingRequest {\n\tif wq == nil {\n\t\treturn nil\n\t}\n\tvar wr *waitingRequest\n\tif wq.rp >= 0 {\n\t\twr = wq.reqs[wq.rp]\n\t}\n\treturn wr\n}\n\n// pop will return the next request and move the read cursor.\nfunc (wq *waitQueue) pop() *waitingRequest {\n\twr := wq.peek()\n\tif wr != nil {\n\t\twr.n--\n\t\tif wr.n <= 0 {\n\t\t\twq.reqs[wq.rp] = nil\n\t\t\twq.rp = (wq.rp + 1) % cap(wq.reqs)\n\t\t\t// Check if we are empty.\n\t\t\tif wq.rp == wq.wp {\n\t\t\t\twq.rp, wq.wp = -1, 0\n\t\t\t}\n\t\t}\n\t}\n\treturn wr\n}\n\n// processNextMsgReq will process a request for the next message available. A nil message payload means deliver\n// a single message. If the payload is a formal request or a number parseable with Atoi(), then we will send a\n// batch of messages without requiring another request to this endpoint, or an ACK.\nfunc (o *consumer) processNextMsgReq(_ *subscription, c *client, _ *Account, _, reply string, msg []byte) {\n\t_, msg = c.msgParts(msg)\n\n\to.mu.Lock()\n\tdefer o.mu.Unlock()\n\n\ts, mset, js := o.srv, o.mset, o.js\n\tif mset == nil {\n\t\treturn\n\t}\n\n\tsendErr := func(status int, description string) {\n\t\thdr := []byte(fmt.Sprintf(\"NATS/1.0 %d %s\\r\\n\\r\\n\", status, description))\n\t\to.outq.send(&jsPubMsg{reply, _EMPTY_, _EMPTY_, hdr, nil, nil, 0, nil})\n\t}\n\n\tif o.isPushMode() {\n\t\tsendErr(409, \"Consumer is push based\")\n\t\treturn\n\t}\n\n\tif o.waiting.isFull() {\n\t\t// Try to expire some of the requests.\n\t\tif expired := o.expireWaiting(); expired == 0 {\n\t\t\t// Force expiration if needed.\n\t\t\to.forceExpireFirstWaiting()\n\t\t}\n\t}\n\n\t// Check payload here to see if they sent in batch size or a formal request.\n\texpires, batchSize, noWait, err := nextReqFromMsg(msg)\n\tif err != nil {\n\t\tsendErr(400, fmt.Sprintf(\"Bad Request - %v\", err))\n\t\treturn\n\t}\n\n\tif o.maxp > 0 && batchSize > o.maxp {\n\t\tsendErr(409, \"Exceeded MaxAckPending\")\n\t\treturn\n\t}\n\n\t// In case we have to queue up this request.\n\twr := waitingRequest{client: c, reply: reply, n: batchSize, noWait: noWait, expires: expires}\n\n\t// If we are in replay mode, defer to processReplay for delivery.\n\tif o.replay {\n\t\to.waiting.add(&wr)\n\t\to.signalNewMessages()\n\t\treturn\n\t}\n\n\tsendBatch := func(wr *waitingRequest) {\n\t\tfor i, batchSize := 0, wr.n; i < batchSize; i++ {\n\t\t\t// See if we have more messages available.\n\t\t\tif subj, hdr, msg, seq, dc, ts, err := o.getNextMsg(); err == nil {\n\t\t\t\to.deliverMsg(reply, subj, hdr, msg, seq, dc, ts)\n\t\t\t\t// Need to discount this from the total n for the request.\n\t\t\t\twr.n--\n\t\t\t} else {\n\t\t\t\tif wr.noWait {\n\t\t\t\t\tswitch err {\n\t\t\t\t\tcase errMaxAckPending:\n\t\t\t\t\t\tsendErr(409, \"Exceeded MaxAckPending\")\n\t\t\t\t\tdefault:\n\t\t\t\t\t\tsendErr(404, \"No Messages\")\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\to.waiting.add(wr)\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n\n\t// If this is direct from a client can proceed inline.\n\tif c.kind == CLIENT {\n\t\tsendBatch(&wr)\n\t} else {\n\t\t// Check for API outstanding requests.\n\t\tif apiOut := atomic.AddInt64(&js.apiCalls, 1); apiOut > 1024 {\n\t\t\tatomic.AddInt64(&js.apiCalls, -1)\n\t\t\to.mu.Unlock()\n\t\t\tsendErr(503, \"JetStream API limit exceeded\")\n\t\t\ts.Warnf(\"JetStream API limit exceeded: %d calls outstanding\", apiOut)\n\t\t\treturn\n\t\t}\n\n\t\t// Dispatch the API call to its own Go routine.\n\t\tgo func() {\n\t\t\to.mu.Lock()\n\t\t\tsendBatch(&wr)\n\t\t\to.mu.Unlock()\n\t\t\tatomic.AddInt64(&js.apiCalls, -1)\n\t\t}()\n\t}\n}\n\n// Increase the delivery count for this message.\n// ONLY used on redelivery semantics.\n// Lock should be held.\nfunc (o *consumer) incDeliveryCount(sseq uint64) uint64 {\n\tif o.rdc == nil {\n\t\to.rdc = make(map[uint64]uint64)\n\t}\n\to.rdc[sseq] += 1\n\treturn o.rdc[sseq] + 1\n}\n\n// send a delivery exceeded advisory.\nfunc (o *consumer) notifyDeliveryExceeded(sseq, dc uint64) {\n\te := JSConsumerDeliveryExceededAdvisory{\n\t\tTypedEvent: TypedEvent{\n\t\t\tType: JSConsumerDeliveryExceededAdvisoryType,\n\t\t\tID:   nuid.Next(),\n\t\t\tTime: time.Now().UTC(),\n\t\t},\n\t\tStream:     o.stream,\n\t\tConsumer:   o.name,\n\t\tStreamSeq:  sseq,\n\t\tDeliveries: dc,\n\t\tDomain:     o.srv.getOpts().JetStreamDomain,\n\t}\n\n\tj, err := json.Marshal(e)\n\tif err != nil {\n\t\treturn\n\t}\n\n\to.sendAdvisory(o.deliveryExcEventT, j)\n}\n\n// Check to see if the candidate subject matches a filter if its present.\n// Lock should be held.\nfunc (o *consumer) isFilteredMatch(subj string) bool {\n\t// No filter is automatic match.\n\tif o.cfg.FilterSubject == _EMPTY_ {\n\t\treturn true\n\t}\n\tif !o.filterWC {\n\t\treturn subj == o.cfg.FilterSubject\n\t}\n\t// If we are here we have a wildcard filter subject.\n\t// TODO(dlc) at speed might be better to just do a sublist with L2 and/or possibly L1.\n\treturn subjectIsSubsetMatch(subj, o.cfg.FilterSubject)\n}\n\nvar (\n\terrMaxAckPending = errors.New(\"max ack pending reached\")\n\terrBadConsumer   = errors.New(\"consumer not valid\")\n\terrNoInterest    = errors.New(\"consumer requires interest for delivery subject when ephemeral\")\n)\n\n// Get next available message from underlying store.\n// Is partition aware and redeliver aware.\n// Lock should be held.\nfunc (o *consumer) getNextMsg() (subj string, hdr, msg []byte, seq uint64, dc uint64, ts int64, err error) {\n\tif o.mset == nil || o.mset.store == nil {\n\t\treturn _EMPTY_, nil, nil, 0, 0, 0, errBadConsumer\n\t}\n\tfor {\n\t\tseq, dc := o.sseq, uint64(1)\n\t\tif o.hasSkipListPending() {\n\t\t\tseq = o.lss.seqs[0]\n\t\t\tif len(o.lss.seqs) == 1 {\n\t\t\t\to.sseq = o.lss.resume\n\t\t\t\to.lss = nil\n\t\t\t\to.updateSkipped()\n\t\t\t} else {\n\t\t\t\to.lss.seqs = o.lss.seqs[1:]\n\t\t\t}\n\t\t} else if o.hasRedeliveries() {\n\t\t\tseq = o.getNextToRedeliver()\n\t\t\tdc = o.incDeliveryCount(seq)\n\t\t\tif o.maxdc > 0 && dc > o.maxdc {\n\t\t\t\t// Only send once\n\t\t\t\tif dc == o.maxdc+1 {\n\t\t\t\t\to.notifyDeliveryExceeded(seq, dc-1)\n\t\t\t\t}\n\t\t\t\t// Make sure to remove from pending.\n\t\t\t\tdelete(o.pending, seq)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t} else if o.maxp > 0 && len(o.pending) >= o.maxp {\n\t\t\t// maxp only set when ack policy != AckNone and user set MaxAckPending\n\t\t\t// Stall if we have hit max pending.\n\t\t\treturn _EMPTY_, nil, nil, 0, 0, 0, errMaxAckPending\n\t\t}\n\n\t\tsubj, hdr, msg, ts, err := o.mset.store.LoadMsg(seq)\n\t\tif err == nil {\n\t\t\tif dc == 1 { // First delivery.\n\t\t\t\to.sseq++\n\t\t\t\tif o.cfg.FilterSubject != _EMPTY_ && !o.isFilteredMatch(subj) {\n\t\t\t\t\to.updateSkipped()\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\t\t\t// We have the msg here.\n\t\t\treturn subj, hdr, msg, seq, dc, ts, nil\n\t\t}\n\t\t// We got an error here. If this is an EOF we will return, otherwise\n\t\t// we can continue looking.\n\t\tif err == ErrStoreEOF || err == ErrStoreClosed {\n\t\t\treturn _EMPTY_, nil, nil, 0, 0, 0, err\n\t\t}\n\t\t// Skip since its probably deleted or expired.\n\t\to.sseq++\n\t}\n}\n\n// forceExpireFirstWaiting will force expire the first waiting.\n// Lock should be held.\nfunc (o *consumer) forceExpireFirstWaiting() *waitingRequest {\n\t// FIXME(dlc) - Should we do advisory here as well?\n\twr := o.waiting.pop()\n\tif wr == nil {\n\t\treturn wr\n\t}\n\t// If we are expiring this and we think there is still interest, alert.\n\tif rr := o.acc.sl.Match(wr.reply); len(rr.psubs)+len(rr.qsubs) > 0 && o.mset != nil {\n\t\t// We still appear to have interest, so send alert as courtesy.\n\t\thdr := []byte(\"NATS/1.0 408 Request Timeout\\r\\n\\r\\n\")\n\t\to.outq.send(&jsPubMsg{wr.reply, _EMPTY_, _EMPTY_, hdr, nil, nil, 0, nil})\n\t}\n\treturn wr\n}\n\n// Will check for expiration and lack of interest on waiting requests.\nfunc (o *consumer) expireWaiting() int {\n\tvar expired int\n\tnow := time.Now()\n\tfor wr := o.waiting.peek(); wr != nil; wr = o.waiting.peek() {\n\t\tif !wr.expires.IsZero() && now.After(wr.expires) {\n\t\t\to.forceExpireFirstWaiting()\n\t\t\texpired++\n\t\t\tcontinue\n\t\t}\n\t\ts, acc := o.acc.srv, o.acc\n\t\trr := acc.sl.Match(wr.reply)\n\t\tif len(rr.psubs)+len(rr.qsubs) > 0 {\n\t\t\tbreak\n\t\t}\n\t\t// If we are here check on gateways.\n\t\tif s != nil && s.hasGatewayInterest(acc.Name, wr.reply) {\n\t\t\tbreak\n\t\t}\n\t\t// No more interest so go ahead and remove this one from our list.\n\t\to.forceExpireFirstWaiting()\n\t\texpired++\n\t}\n\treturn expired\n}\n\n// Will check to make sure those waiting still have registered interest.\nfunc (o *consumer) checkWaitingForInterest() bool {\n\to.expireWaiting()\n\treturn o.waiting.len() > 0\n}\n\n// Lock should be held.\nfunc (o *consumer) hbTimer() (time.Duration, *time.Timer) {\n\tif o.cfg.Heartbeat == 0 {\n\t\treturn 0, nil\n\t}\n\treturn o.cfg.Heartbeat, time.NewTimer(o.cfg.Heartbeat)\n}\n\nfunc (o *consumer) loopAndGatherMsgs(qch chan struct{}) {\n\t// On startup check to see if we are in a a reply situation where replay policy is not instant.\n\tvar (\n\t\tlts  int64 // last time stamp seen, used for replay.\n\t\tlseq uint64\n\t)\n\n\to.mu.Lock()\n\ts := o.srv\n\tif o.replay {\n\t\t// consumer is closed when mset is set to nil.\n\t\tif o.mset == nil {\n\t\t\to.mu.Unlock()\n\t\t\treturn\n\t\t}\n\t\tlseq = o.mset.state().LastSeq\n\t}\n\t// For idle heartbeat support.\n\tvar hbc <-chan time.Time\n\thbd, hb := o.hbTimer()\n\tif hb != nil {\n\t\thbc = hb.C\n\t}\n\t// Interest changes.\n\tinch := o.inch\n\to.mu.Unlock()\n\n\t// Deliver all the msgs we have now, once done or on a condition, we wait for new ones.\n\tfor {\n\t\tvar (\n\t\t\tseq, dc     uint64\n\t\t\tsubj, dsubj string\n\t\t\thdr         []byte\n\t\t\tmsg         []byte\n\t\t\terr         error\n\t\t\tts          int64\n\t\t\tdelay       time.Duration\n\t\t)\n\n\t\to.mu.Lock()\n\t\t// consumer is closed when mset is set to nil.\n\t\tif o.mset == nil {\n\t\t\to.mu.Unlock()\n\t\t\treturn\n\t\t}\n\n\t\t// If we are in push mode and not active or under flowcontrol let's stop sending.\n\t\tif o.isPushMode() {\n\t\t\tif !o.active {\n\t\t\t\tgoto waitForMsgs\n\t\t\t}\n\t\t\t// Flowcontrol.\n\t\t\tif o.maxpb > 0 && o.pbytes > o.maxpb {\n\t\t\t\tgoto waitForMsgs\n\t\t\t}\n\t\t}\n\n\t\t// If we are in pull mode and no one is waiting already break and wait.\n\t\tif o.isPullMode() && !o.checkWaitingForInterest() {\n\t\t\tgoto waitForMsgs\n\t\t}\n\n\t\tsubj, hdr, msg, seq, dc, ts, err = o.getNextMsg()\n\n\t\t// On error either wait or return.\n\t\tif err != nil {\n\t\t\tif err == ErrStoreMsgNotFound || err == ErrStoreEOF || err == errMaxAckPending {\n\t\t\t\tgoto waitForMsgs\n\t\t\t} else {\n\t\t\t\to.mu.Unlock()\n\t\t\t\ts.Errorf(\"Received an error looking up message for consumer: %v\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\tif wr := o.waiting.pop(); wr != nil {\n\t\t\tdsubj = wr.reply\n\t\t} else {\n\t\t\tdsubj = o.dsubj\n\t\t}\n\n\t\t// If we are in a replay scenario and have not caught up check if we need to delay here.\n\t\tif o.replay && lts > 0 {\n\t\t\tif delay = time.Duration(ts - lts); delay > time.Millisecond {\n\t\t\t\to.mu.Unlock()\n\t\t\t\tselect {\n\t\t\t\tcase <-qch:\n\t\t\t\t\treturn\n\t\t\t\tcase <-time.After(delay):\n\t\t\t\t}\n\t\t\t\to.mu.Lock()\n\t\t\t}\n\t\t}\n\n\t\t// Track this regardless.\n\t\tlts = ts\n\n\t\t// If we have a rate limit set make sure we check that here.\n\t\tif o.rlimit != nil {\n\t\t\tnow := time.Now()\n\t\t\tr := o.rlimit.ReserveN(now, len(msg)+len(hdr)+len(subj)+len(dsubj)+len(o.ackReplyT))\n\t\t\tdelay := r.DelayFrom(now)\n\t\t\tif delay > 0 {\n\t\t\t\to.mu.Unlock()\n\t\t\t\tselect {\n\t\t\t\tcase <-qch:\n\t\t\t\t\treturn\n\t\t\t\tcase <-time.After(delay):\n\t\t\t\t}\n\t\t\t\to.mu.Lock()\n\t\t\t}\n\t\t}\n\n\t\t// Do actual delivery.\n\t\to.deliverMsg(dsubj, subj, hdr, msg, seq, dc, ts)\n\n\t\t// Reset our idle heartbeat timer if set.\n\t\tif hb != nil {\n\t\t\thb.Reset(hbd)\n\t\t}\n\n\t\to.mu.Unlock()\n\t\tcontinue\n\n\twaitForMsgs:\n\t\t// If we were in a replay state check to see if we are caught up. If so clear.\n\t\tif o.replay && o.sseq > lseq {\n\t\t\to.replay = false\n\t\t}\n\n\t\t// We will wait here for new messages to arrive.\n\t\tmch, outq, odsubj, sseq, dseq := o.mch, o.outq, o.cfg.DeliverSubject, o.sseq-1, o.dseq-1\n\t\to.mu.Unlock()\n\n\t\tselect {\n\t\tcase interest := <-inch:\n\t\t\t// inch can be nil on pull-based, but then this will\n\t\t\t// just block and not fire.\n\t\t\to.updateDeliveryInterest(interest)\n\t\tcase <-qch:\n\t\t\treturn\n\t\tcase <-mch:\n\t\t\t// Messages are waiting.\n\t\tcase <-hbc:\n\t\t\tif o.isActive() {\n\t\t\t\tconst t = \"NATS/1.0 100 Idle Heartbeat\\r\\n%s: %d\\r\\n%s: %d\\r\\n\\r\\n\"\n\t\t\t\thdr := []byte(fmt.Sprintf(t, JSLastConsumerSeq, dseq, JSLastStreamSeq, sseq))\n\t\t\t\tif fcp := o.fcID(); fcp != _EMPTY_ {\n\t\t\t\t\t// Add in that we are stalled on flow control here.\n\t\t\t\t\taddOn := []byte(fmt.Sprintf(\"%s: %s\\r\\n\\r\\n\", JSConsumerStalled, fcp))\n\t\t\t\t\thdr = append(hdr[:len(hdr)-LEN_CR_LF], []byte(addOn)...)\n\t\t\t\t}\n\t\t\t\toutq.send(&jsPubMsg{odsubj, _EMPTY_, _EMPTY_, hdr, nil, nil, 0, nil})\n\t\t\t}\n\t\t\t// Reset our idle heartbeat timer.\n\t\t\thb.Reset(hbd)\n\t\t}\n\t}\n}\n\nfunc (o *consumer) ackReply(sseq, dseq, dc uint64, ts int64, pending uint64) string {\n\treturn fmt.Sprintf(o.ackReplyT, dc, sseq, dseq, ts, pending)\n}\n\n// Used mostly for testing. Sets max pending bytes for flow control setups.\nfunc (o *consumer) setMaxPendingBytes(limit int) {\n\to.pblimit = limit\n\to.maxpb = limit / 16\n\tif o.maxpb == 0 {\n\t\to.maxpb = 1\n\t}\n}\n\n// We have the case where a consumer can become greedy and pick up a messages before the stream has incremented our pending(sgap).\n// Instead of trying to slow things down and synchronize we will allow this to wrap and go negative (biggest uint64) for a short time.\n// This functions checks for that and returns 0.\n// Lock should be held.\nfunc (o *consumer) adjustedPending() uint64 {\n\tif o.sgap&(1<<63) != 0 {\n\t\treturn 0\n\t}\n\treturn o.sgap\n}\n\n// Deliver a msg to the consumer.\n// Lock should be held and o.mset validated to be non-nil.\nfunc (o *consumer) deliverMsg(dsubj, subj string, hdr, msg []byte, seq, dc uint64, ts int64) {\n\tif o.mset == nil {\n\t\treturn\n\t}\n\t// Update pending on first attempt. This can go upside down for a short bit, that is ok.\n\t// See adjustedPending().\n\tif dc == 1 {\n\t\to.sgap--\n\t}\n\n\tdseq := o.dseq\n\to.dseq++\n\n\tpmsg := &jsPubMsg{dsubj, subj, o.ackReply(seq, dseq, dc, ts, o.adjustedPending()), hdr, msg, o, seq, nil}\n\tif o.maxpb > 0 {\n\t\to.pbytes += pmsg.size()\n\t}\n\n\tmset := o.mset\n\tap := o.cfg.AckPolicy\n\n\t// Send message.\n\to.outq.send(pmsg)\n\n\t// If we are ack none and mset is interest only we should make sure stream removes interest.\n\tif ap == AckNone && mset.cfg.Retention != LimitsPolicy && mset.amch != nil {\n\t\tmset.amch <- seq\n\t}\n\n\tif ap == AckExplicit || ap == AckAll {\n\t\to.trackPending(seq, dseq)\n\t} else if ap == AckNone {\n\t\to.adflr = dseq\n\t\to.asflr = seq\n\t}\n\n\t// Flow control.\n\tif o.maxpb > 0 && o.needFlowControl() {\n\t\to.sendFlowControl()\n\t}\n\n\t// FIXME(dlc) - Capture errors?\n\to.updateDelivered(dseq, seq, dc, ts)\n}\n\nfunc (o *consumer) needFlowControl() bool {\n\tif o.maxpb == 0 {\n\t\treturn false\n\t}\n\t// Decide whether to send a flow control message which we will need the user to respond.\n\t// We send when we are over 50% of our current window limit.\n\tif o.fcid == _EMPTY_ && o.pbytes > o.maxpb/2 {\n\t\treturn true\n\t}\n\treturn false\n}\n\nfunc (o *consumer) processFlowControl(_ *subscription, c *client, _ *Account, subj, _ string, _ []byte) {\n\to.mu.Lock()\n\tdefer o.mu.Unlock()\n\n\t// Ignore if not the latest we have sent out.\n\tif subj != o.fcid {\n\t\treturn\n\t}\n\n\t// For slow starts and ramping up.\n\tif o.maxpb < o.pblimit {\n\t\to.maxpb *= 2\n\t\tif o.maxpb > o.pblimit {\n\t\t\to.maxpb = o.pblimit\n\t\t}\n\t}\n\n\t// Update accounting.\n\to.pbytes -= o.fcsz\n\tif o.pbytes < 0 {\n\t\to.pbytes = 0\n\t}\n\to.fcid, o.fcsz = _EMPTY_, 0\n\n\to.signalNewMessages()\n}\n\n// Lock should be held.\nfunc (o *consumer) fcReply() string {\n\tvar sb strings.Builder\n\tsb.WriteString(jsFlowControlPre)\n\tsb.WriteString(o.stream)\n\tsb.WriteByte(btsep)\n\tsb.WriteString(o.name)\n\tsb.WriteByte(btsep)\n\tvar b [4]byte\n\trn := rand.Int63()\n\tfor i, l := 0, rn; i < len(b); i++ {\n\t\tb[i] = digits[l%base]\n\t\tl /= base\n\t}\n\tsb.Write(b[:])\n\treturn sb.String()\n}\n\nfunc (o *consumer) fcID() string {\n\to.mu.RLock()\n\tdefer o.mu.RUnlock()\n\treturn o.fcid\n}\n\n// sendFlowControl will send a flow control packet to the consumer.\n// Lock should be held.\nfunc (o *consumer) sendFlowControl() {\n\tif !o.isPushMode() {\n\t\treturn\n\t}\n\tsubj, rply := o.cfg.DeliverSubject, o.fcReply()\n\to.fcsz, o.fcid = o.pbytes, rply\n\thdr := []byte(\"NATS/1.0 100 FlowControl Request\\r\\n\\r\\n\")\n\to.outq.send(&jsPubMsg{subj, _EMPTY_, rply, hdr, nil, nil, 0, nil})\n}\n\n// Tracks our outstanding pending acks. Only applicable to AckExplicit mode.\n// Lock should be held.\nfunc (o *consumer) trackPending(sseq, dseq uint64) {\n\tif o.pending == nil {\n\t\to.pending = make(map[uint64]*Pending)\n\t}\n\tif o.ptmr == nil {\n\t\to.ptmr = time.AfterFunc(o.ackWait(0), o.checkPending)\n\t}\n\tif p, ok := o.pending[sseq]; ok {\n\t\tp.Timestamp = time.Now().UnixNano()\n\t} else {\n\t\to.pending[sseq] = &Pending{dseq, time.Now().UnixNano()}\n\t}\n}\n\n// didNotDeliver is called when a delivery for a consumer message failed.\n// Depending on our state, we will process the failure.\nfunc (o *consumer) didNotDeliver(seq uint64) {\n\to.mu.Lock()\n\tmset := o.mset\n\tif mset == nil {\n\t\to.mu.Unlock()\n\t\treturn\n\t}\n\tvar checkDeliveryInterest bool\n\tif o.isPushMode() {\n\t\to.active = false\n\t\tcheckDeliveryInterest = true\n\t} else if o.pending != nil {\n\t\t// pull mode and we have pending.\n\t\tif _, ok := o.pending[seq]; ok {\n\t\t\t// We found this messsage on pending, we need\n\t\t\t// to queue it up for immediate redelivery since\n\t\t\t// we know it was not delivered.\n\t\t\tif !o.onRedeliverQueue(seq) {\n\t\t\t\to.addToRedeliverQueue(seq)\n\t\t\t\to.signalNewMessages()\n\t\t\t}\n\t\t}\n\t}\n\to.mu.Unlock()\n\n\t// If we do not have interest update that here.\n\tif checkDeliveryInterest && o.hasNoLocalInterest() {\n\t\to.updateDeliveryInterest(false)\n\t}\n}\n\n// Lock should be held.\nfunc (o *consumer) addToRedeliverQueue(seqs ...uint64) {\n\tif o.rdqi == nil {\n\t\to.rdqi = make(map[uint64]struct{})\n\t}\n\to.rdq = append(o.rdq, seqs...)\n\tfor _, seq := range seqs {\n\t\to.rdqi[seq] = struct{}{}\n\t}\n}\n\n// Lock should be held.\nfunc (o *consumer) hasRedeliveries() bool {\n\treturn len(o.rdq) > 0\n}\n\nfunc (o *consumer) getNextToRedeliver() uint64 {\n\tif len(o.rdq) == 0 {\n\t\treturn 0\n\t}\n\tseq := o.rdq[0]\n\tif len(o.rdq) == 1 {\n\t\to.rdq, o.rdqi = nil, nil\n\t} else {\n\t\to.rdq = append(o.rdq[:0], o.rdq[1:]...)\n\t\tdelete(o.rdqi, seq)\n\t}\n\treturn seq\n}\n\n// This checks if we already have this sequence queued for redelivery.\n// FIXME(dlc) - This is O(n) but should be fast with small redeliver size.\n// Lock should be held.\nfunc (o *consumer) onRedeliverQueue(seq uint64) bool {\n\tif o.rdqi == nil {\n\t\treturn false\n\t}\n\t_, ok := o.rdqi[seq]\n\treturn ok\n}\n\n// Remove a sequence from the redelivery queue.\n// Lock should be held.\nfunc (o *consumer) removeFromRedeliverQueue(seq uint64) bool {\n\tif !o.onRedeliverQueue(seq) {\n\t\treturn false\n\t}\n\tfor i, rseq := range o.rdq {\n\t\tif rseq == seq {\n\t\t\tif len(o.rdq) == 1 {\n\t\t\t\to.rdq, o.rdqi = nil, nil\n\t\t\t} else {\n\t\t\t\to.rdq = append(o.rdq[:i], o.rdq[i+1:]...)\n\t\t\t\tdelete(o.rdqi, seq)\n\t\t\t}\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\n// Checks the pending messages.\nfunc (o *consumer) checkPending() {\n\to.mu.Lock()\n\tdefer o.mu.Unlock()\n\n\tmset := o.mset\n\tif mset == nil {\n\t\treturn\n\t}\n\tttl := int64(o.cfg.AckWait)\n\tnext := int64(o.ackWait(0))\n\tnow := time.Now().UnixNano()\n\n\t// Since we can update timestamps, we have to review all pending.\n\t// We may want to unlock here or warn if list is big.\n\tvar expired []uint64\n\tfor seq, p := range o.pending {\n\t\telapsed := now - p.Timestamp\n\t\tif elapsed >= ttl {\n\t\t\tif !o.onRedeliverQueue(seq) {\n\t\t\t\texpired = append(expired, seq)\n\t\t\t\to.signalNewMessages()\n\t\t\t}\n\t\t} else if ttl-elapsed < next {\n\t\t\t// Update when we should fire next.\n\t\t\tnext = ttl - elapsed\n\t\t}\n\t}\n\n\tif len(expired) > 0 {\n\t\t// We need to sort.\n\t\tsort.Slice(expired, func(i, j int) bool { return expired[i] < expired[j] })\n\t\to.addToRedeliverQueue(expired...)\n\t\t// Now we should update the timestamp here since we are redelivering.\n\t\t// We will use an incrementing time to preserve order for any other redelivery.\n\t\toff := now - o.pending[expired[0]].Timestamp\n\t\tfor _, seq := range expired {\n\t\t\tif p, ok := o.pending[seq]; ok {\n\t\t\t\tp.Timestamp += off\n\t\t\t}\n\t\t}\n\t}\n\n\tif len(o.pending) > 0 {\n\t\to.ptmr.Reset(o.ackWait(time.Duration(next)))\n\t} else {\n\t\to.ptmr.Stop()\n\t\to.ptmr = nil\n\t}\n}\n\n// SeqFromReply will extract a sequence number from a reply subject.\nfunc (o *consumer) seqFromReply(reply string) uint64 {\n\t_, dseq, _ := ackReplyInfo(reply)\n\treturn dseq\n}\n\n// StreamSeqFromReply will extract the stream sequence from the reply subject.\nfunc (o *consumer) streamSeqFromReply(reply string) uint64 {\n\tsseq, _, _ := ackReplyInfo(reply)\n\treturn sseq\n}\n\n// Quick parser for positive numbers in ack reply encoding.\nfunc parseAckReplyNum(d string) (n int64) {\n\tif len(d) == 0 {\n\t\treturn -1\n\t}\n\tfor _, dec := range d {\n\t\tif dec < asciiZero || dec > asciiNine {\n\t\t\treturn -1\n\t\t}\n\t\tn = n*10 + (int64(dec) - asciiZero)\n\t}\n\treturn n\n}\n\nconst expectedNumReplyTokens = 9\n\n// Grab encoded information in the reply subject for a delivered message.\nfunc replyInfo(subject string) (sseq, dseq, dc uint64, ts int64, pending uint64) {\n\ttsa := [expectedNumReplyTokens]string{}\n\tstart, tokens := 0, tsa[:0]\n\tfor i := 0; i < len(subject); i++ {\n\t\tif subject[i] == btsep {\n\t\t\ttokens = append(tokens, subject[start:i])\n\t\t\tstart = i + 1\n\t\t}\n\t}\n\ttokens = append(tokens, subject[start:])\n\tif len(tokens) != expectedNumReplyTokens || tokens[0] != \"$JS\" || tokens[1] != \"ACK\" {\n\t\treturn 0, 0, 0, 0, 0\n\t}\n\t// TODO(dlc) - Should we error if we do not match consumer name?\n\t// stream is tokens[2], consumer is 3.\n\tdc = uint64(parseAckReplyNum(tokens[4]))\n\tsseq, dseq = uint64(parseAckReplyNum(tokens[5])), uint64(parseAckReplyNum(tokens[6]))\n\tts = parseAckReplyNum(tokens[7])\n\tpending = uint64(parseAckReplyNum(tokens[8]))\n\n\treturn sseq, dseq, dc, ts, pending\n}\n\nfunc ackReplyInfo(subject string) (sseq, dseq, dc uint64) {\n\ttsa := [expectedNumReplyTokens]string{}\n\tstart, tokens := 0, tsa[:0]\n\tfor i := 0; i < len(subject); i++ {\n\t\tif subject[i] == btsep {\n\t\t\ttokens = append(tokens, subject[start:i])\n\t\t\tstart = i + 1\n\t\t}\n\t}\n\ttokens = append(tokens, subject[start:])\n\tif len(tokens) != expectedNumReplyTokens || tokens[0] != \"$JS\" || tokens[1] != \"ACK\" {\n\t\treturn 0, 0, 0\n\t}\n\tdc = uint64(parseAckReplyNum(tokens[4]))\n\tsseq, dseq = uint64(parseAckReplyNum(tokens[5])), uint64(parseAckReplyNum(tokens[6]))\n\n\treturn sseq, dseq, dc\n}\n\n// NextSeq returns the next delivered sequence number for this consumer.\nfunc (o *consumer) nextSeq() uint64 {\n\to.mu.RLock()\n\tdseq := o.dseq\n\to.mu.RUnlock()\n\treturn dseq\n}\n\n// Used to hold skip list when deliver policy is last per subject.\ntype lastSeqSkipList struct {\n\tresume uint64\n\tseqs   []uint64\n}\n\n// Will create a skip list for us from a store's subjects state.\nfunc createLastSeqSkipList(mss map[string]SimpleState) []uint64 {\n\tseqs := make([]uint64, 0, len(mss))\n\tfor _, ss := range mss {\n\t\tseqs = append(seqs, ss.Last)\n\t}\n\tsort.Slice(seqs, func(i, j int) bool { return seqs[i] < seqs[j] })\n\treturn seqs\n}\n\n// Let's us know we have a skip list, which is for deliver last per subject and we are just starting.\n// Lock should be held.\nfunc (o *consumer) hasSkipListPending() bool {\n\treturn o.lss != nil && len(o.lss.seqs) > 0\n}\n\n// Will select the starting sequence.\nfunc (o *consumer) selectStartingSeqNo() {\n\tif o.mset == nil || o.mset.store == nil {\n\t\to.sseq = 1\n\t} else {\n\t\tstats := o.mset.store.State()\n\t\tif o.cfg.OptStartSeq == 0 {\n\t\t\tif o.cfg.DeliverPolicy == DeliverAll {\n\t\t\t\to.sseq = stats.FirstSeq\n\t\t\t} else if o.cfg.DeliverPolicy == DeliverLast {\n\t\t\t\to.sseq = stats.LastSeq\n\t\t\t\t// If we are partitioned here this will be properly set when we become leader.\n\t\t\t\tif o.cfg.FilterSubject != _EMPTY_ {\n\t\t\t\t\tss := o.mset.store.FilteredState(1, o.cfg.FilterSubject)\n\t\t\t\t\to.sseq = ss.Last\n\t\t\t\t}\n\t\t\t} else if o.cfg.DeliverPolicy == DeliverLastPerSubject {\n\t\t\t\tif mss := o.mset.store.SubjectsState(o.cfg.FilterSubject); len(mss) > 0 {\n\t\t\t\t\to.lss = &lastSeqSkipList{\n\t\t\t\t\t\tresume: stats.LastSeq,\n\t\t\t\t\t\tseqs:   createLastSeqSkipList(mss),\n\t\t\t\t\t}\n\t\t\t\t\to.sseq = o.lss.seqs[0]\n\t\t\t\t} else {\n\t\t\t\t\t// If no mapping info just set to last.\n\t\t\t\t\to.sseq = stats.LastSeq\n\t\t\t\t}\n\t\t\t} else if o.cfg.OptStartTime != nil {\n\t\t\t\t// If we are here we are time based.\n\t\t\t\t// TODO(dlc) - Once clustered can't rely on this.\n\t\t\t\to.sseq = o.mset.store.GetSeqFromTime(*o.cfg.OptStartTime)\n\t\t\t} else {\n\t\t\t\to.sseq = stats.LastSeq + 1\n\t\t\t}\n\t\t} else {\n\t\t\to.sseq = o.cfg.OptStartSeq\n\t\t}\n\n\t\tif stats.FirstSeq == 0 {\n\t\t\to.sseq = 1\n\t\t} else if o.sseq < stats.FirstSeq {\n\t\t\to.sseq = stats.FirstSeq\n\t\t} else if o.sseq > stats.LastSeq {\n\t\t\to.sseq = stats.LastSeq + 1\n\t\t}\n\t}\n\n\t// Always set delivery sequence to 1.\n\to.dseq = 1\n\t// Set ack delivery floor to delivery-1\n\to.adflr = o.dseq - 1\n\t// Set ack store floor to store-1\n\to.asflr = o.sseq - 1\n}\n\n// Test whether a config represents a durable subscriber.\nfunc isDurableConsumer(config *ConsumerConfig) bool {\n\treturn config != nil && config.Durable != _EMPTY_\n}\n\nfunc (o *consumer) isDurable() bool {\n\treturn o.cfg.Durable != _EMPTY_\n}\n\n// Are we in push mode, delivery subject, etc.\nfunc (o *consumer) isPushMode() bool {\n\treturn o.cfg.DeliverSubject != _EMPTY_\n}\n\nfunc (o *consumer) isPullMode() bool {\n\treturn o.cfg.DeliverSubject == _EMPTY_\n}\n\n// Name returns the name of this consumer.\nfunc (o *consumer) String() string {\n\to.mu.RLock()\n\tn := o.name\n\to.mu.RUnlock()\n\treturn n\n}\n\nfunc createConsumerName() string {\n\treturn string(getHash(nuid.Next()))\n}\n\n// deleteConsumer will delete the consumer from this stream.\nfunc (mset *stream) deleteConsumer(o *consumer) error {\n\treturn o.delete()\n}\n\nfunc (o *consumer) streamName() string {\n\to.mu.RLock()\n\tmset := o.mset\n\to.mu.RUnlock()\n\tif mset != nil {\n\t\treturn mset.name()\n\t}\n\treturn _EMPTY_\n}\n\n// Active indicates if this consumer is still active.\nfunc (o *consumer) isActive() bool {\n\to.mu.RLock()\n\tactive := o.active && o.mset != nil\n\to.mu.RUnlock()\n\treturn active\n}\n\n// hasNoLocalInterest return true if we have no local interest.\nfunc (o *consumer) hasNoLocalInterest() bool {\n\to.mu.RLock()\n\trr := o.acc.sl.Match(o.cfg.DeliverSubject)\n\to.mu.RUnlock()\n\treturn len(rr.psubs)+len(rr.qsubs) == 0\n}\n\n// This is when the underlying stream has been purged.\n// sseq is the new first seq for the stream after purge.\nfunc (o *consumer) purge(sseq uint64) {\n\t// Do not update our state unless we know we are the leader.\n\tif sseq == 0 || !o.isLeader() {\n\t\treturn\n\t}\n\n\to.mu.Lock()\n\to.sseq = sseq\n\to.asflr = sseq - 1\n\to.adflr = o.dseq - 1\n\to.sgap = 0\n\to.pending = nil\n\n\t// We need to remove all those being queued for redelivery under o.rdq\n\tif len(o.rdq) > 0 {\n\t\trdq := o.rdq\n\t\to.rdq, o.rdqi = nil, nil\n\t\tfor _, sseq := range rdq {\n\t\t\tif sseq >= o.sseq {\n\t\t\t\to.addToRedeliverQueue(sseq)\n\t\t\t}\n\t\t}\n\t}\n\to.mu.Unlock()\n\n\to.writeStoreState()\n}\n\nfunc stopAndClearTimer(tp **time.Timer) {\n\tif *tp == nil {\n\t\treturn\n\t}\n\t// Will get drained in normal course, do not try to\n\t// drain here.\n\t(*tp).Stop()\n\t*tp = nil\n}\n\n// Stop will shutdown  the consumer for the associated stream.\nfunc (o *consumer) stop() error {\n\treturn o.stopWithFlags(false, false, true, false)\n}\n\nfunc (o *consumer) deleteWithoutAdvisory() error {\n\treturn o.stopWithFlags(true, false, true, false)\n}\n\n// Delete will delete the consumer for the associated stream and send advisories.\nfunc (o *consumer) delete() error {\n\treturn o.stopWithFlags(true, false, true, true)\n}\n\nfunc (o *consumer) stopWithFlags(dflag, sdflag, doSignal, advisory bool) error {\n\to.mu.Lock()\n\tif o.closed {\n\t\to.mu.Unlock()\n\t\treturn nil\n\t}\n\to.closed = true\n\n\tif dflag && advisory && o.isLeader() {\n\t\to.sendDeleteAdvisoryLocked()\n\t}\n\n\tif o.qch != nil {\n\t\tclose(o.qch)\n\t\to.qch = nil\n\t}\n\n\ta := o.acc\n\tstore := o.store\n\tmset := o.mset\n\to.mset = nil\n\to.active = false\n\to.unsubscribe(o.ackSub)\n\to.unsubscribe(o.reqSub)\n\to.unsubscribe(o.fcSub)\n\to.ackSub = nil\n\to.reqSub = nil\n\to.fcSub = nil\n\tif o.infoSub != nil {\n\t\to.srv.sysUnsubscribe(o.infoSub)\n\t\to.infoSub = nil\n\t}\n\tc := o.client\n\to.client = nil\n\tsysc := o.sysc\n\to.sysc = nil\n\tstopAndClearTimer(&o.ptmr)\n\tstopAndClearTimer(&o.dtmr)\n\tstopAndClearTimer(&o.gwdtmr)\n\tdelivery := o.cfg.DeliverSubject\n\to.waiting = nil\n\t// Break us out of the readLoop.\n\tif doSignal {\n\t\to.signalNewMessages()\n\t}\n\tn := o.node\n\to.mu.Unlock()\n\n\tif c != nil {\n\t\tc.closeConnection(ClientClosed)\n\t}\n\tif sysc != nil {\n\t\tsysc.closeConnection(ClientClosed)\n\t}\n\n\tif delivery != _EMPTY_ {\n\t\ta.sl.ClearNotification(delivery, o.inch)\n\t}\n\n\tmset.mu.Lock()\n\tmset.removeConsumer(o)\n\trp := mset.cfg.Retention\n\tmset.mu.Unlock()\n\n\t// We need to optionally remove all messages since we are interest based retention.\n\t// We will do this consistently on all replicas. Note that if in clustered mode the\n\t// non-leader consumers will need to restore state first.\n\tif dflag && rp == InterestPolicy {\n\t\tstop := mset.lastSeq()\n\t\to.mu.Lock()\n\t\tif !o.isLeader() {\n\t\t\to.readStoredState()\n\t\t}\n\t\tstart := o.asflr\n\t\to.mu.Unlock()\n\n\t\tvar rmseqs []uint64\n\t\tmset.mu.RLock()\n\t\tfor seq := start; seq <= stop; seq++ {\n\t\t\tif !mset.checkInterest(seq, o) {\n\t\t\t\trmseqs = append(rmseqs, seq)\n\t\t\t}\n\t\t}\n\t\tmset.mu.RUnlock()\n\n\t\tfor _, seq := range rmseqs {\n\t\t\tmset.store.RemoveMsg(seq)\n\t\t}\n\t}\n\n\t// Cluster cleanup.\n\tif n != nil {\n\t\tif dflag {\n\t\t\tn.Delete()\n\t\t} else {\n\t\t\tn.Stop()\n\t\t}\n\t}\n\n\t// Clean up our store.\n\tvar err error\n\tif store != nil {\n\t\tif dflag {\n\t\t\tif sdflag {\n\t\t\t\terr = store.StreamDelete()\n\t\t\t} else {\n\t\t\t\terr = store.Delete()\n\t\t\t}\n\t\t} else {\n\t\t\terr = store.Stop()\n\t\t}\n\t}\n\n\treturn err\n}\n\n// Check that we do not form a cycle by delivering to a delivery subject\n// that is part of the interest group.\nfunc (mset *stream) deliveryFormsCycle(deliverySubject string) bool {\n\tmset.mu.RLock()\n\tdefer mset.mu.RUnlock()\n\n\tfor _, subject := range mset.cfg.Subjects {\n\t\tif subjectIsSubsetMatch(deliverySubject, subject) {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\n// Check that the filtered subject is valid given a set of stream subjects.\nfunc validFilteredSubject(filteredSubject string, subjects []string) bool {\n\tif !IsValidSubject(filteredSubject) {\n\t\treturn false\n\t}\n\thasWC := subjectHasWildcard(filteredSubject)\n\n\tfor _, subject := range subjects {\n\t\tif subjectIsSubsetMatch(filteredSubject, subject) {\n\t\t\treturn true\n\t\t}\n\t\t// If we have a wildcard as the filtered subject check to see if we are\n\t\t// a wider scope but do match a subject.\n\t\tif hasWC && subjectIsSubsetMatch(subject, filteredSubject) {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\n// SetInActiveDeleteThreshold sets the delete threshold for how long to wait\n// before deleting an inactive ephemeral consumer.\nfunc (o *consumer) setInActiveDeleteThreshold(dthresh time.Duration) error {\n\to.mu.Lock()\n\tdefer o.mu.Unlock()\n\n\tif o.isPullMode() {\n\t\treturn fmt.Errorf(\"consumer is not push-based\")\n\t}\n\tif o.isDurable() {\n\t\treturn fmt.Errorf(\"consumer is not durable\")\n\t}\n\tdeleteWasRunning := o.dtmr != nil\n\tstopAndClearTimer(&o.dtmr)\n\to.dthresh = dthresh\n\tif deleteWasRunning {\n\t\to.dtmr = time.AfterFunc(o.dthresh, func() { o.deleteNotActive() })\n\t}\n\treturn nil\n}\n\n// switchToEphemeral is called on startup when recovering ephemerals.\nfunc (o *consumer) switchToEphemeral() {\n\to.mu.Lock()\n\to.cfg.Durable = _EMPTY_\n\tstore, ok := o.store.(*consumerFileStore)\n\trr := o.acc.sl.Match(o.cfg.DeliverSubject)\n\to.mu.Unlock()\n\n\t// Update interest\n\to.updateDeliveryInterest(len(rr.psubs)+len(rr.qsubs) > 0)\n\t// Write out new config\n\tif ok {\n\t\tstore.updateConfig(o.cfg)\n\t}\n}\n\n// RequestNextMsgSubject returns the subject to request the next message when in pull or worker mode.\n// Returns empty otherwise.\nfunc (o *consumer) requestNextMsgSubject() string {\n\treturn o.nextMsgSubj\n}\n\n// Will set the initial pending and start sequence.\n// mset lock should be held.\nfunc (o *consumer) setInitialPendingAndStart() {\n\tmset := o.mset\n\tif mset == nil || mset.store == nil {\n\t\treturn\n\t}\n\n\t// notFiltered means we want all messages.\n\tnotFiltered := o.cfg.FilterSubject == _EMPTY_\n\tif !notFiltered {\n\t\t// Check to see if we directly match the configured stream.\n\t\t// Many clients will always send a filtered subject.\n\t\tcfg := &mset.cfg\n\t\tif len(cfg.Subjects) == 1 && cfg.Subjects[0] == o.cfg.FilterSubject {\n\t\t\tnotFiltered = true\n\t\t}\n\t}\n\n\tif notFiltered {\n\t\tstate := mset.store.State()\n\t\tif state.Msgs > 0 {\n\t\t\to.sgap = state.Msgs - (o.sseq - state.FirstSeq)\n\t\t}\n\t} else {\n\t\t// Here we are filtered.\n\t\tdp := o.cfg.DeliverPolicy\n\t\tif dp == DeliverLastPerSubject && o.hasSkipListPending() && o.sseq < o.lss.resume {\n\t\t\tss := mset.store.FilteredState(o.lss.resume+1, o.cfg.FilterSubject)\n\t\t\to.sseq = o.lss.seqs[0]\n\t\t\to.sgap = ss.Msgs + uint64(len(o.lss.seqs))\n\t\t} else if ss := mset.store.FilteredState(o.sseq, o.cfg.FilterSubject); ss.Msgs > 0 {\n\t\t\to.sgap = ss.Msgs\n\t\t\t// See if we should update our starting sequence.\n\t\t\tif dp == DeliverLast || dp == DeliverLastPerSubject {\n\t\t\t\to.sseq = ss.Last\n\t\t\t} else if dp == DeliverNew {\n\t\t\t\to.sseq = ss.Last + 1\n\t\t\t} else {\n\t\t\t\t// DeliverAll, DeliverByStartSequence, DeliverByStartTime\n\t\t\t\to.sseq = ss.First\n\t\t\t}\n\t\t\t// Cleanup lss when we take over in clustered mode.\n\t\t\tif dp == DeliverLastPerSubject && o.hasSkipListPending() && o.sseq >= o.lss.resume {\n\t\t\t\to.lss = nil\n\t\t\t}\n\t\t}\n\t\to.updateSkipped()\n\t}\n}\n\nfunc (o *consumer) decStreamPending(sseq uint64, subj string) {\n\to.mu.Lock()\n\t// Ignore if we have already seen this one.\n\tif sseq >= o.sseq && o.sgap > 0 && o.isFilteredMatch(subj) {\n\t\to.sgap--\n\t}\n\t// Check if this message was pending.\n\tp, wasPending := o.pending[sseq]\n\tvar rdc uint64 = 1\n\tif o.rdc != nil {\n\t\trdc = o.rdc[sseq]\n\t}\n\to.mu.Unlock()\n\n\t// If it was pending process it like an ack.\n\t// TODO(dlc) - we could do a term here instead with a reason to generate the advisory.\n\tif wasPending {\n\t\to.processAckMsg(sseq, p.Sequence, rdc, false)\n\t}\n}\n\nfunc (o *consumer) account() *Account {\n\to.mu.RLock()\n\ta := o.acc\n\to.mu.RUnlock()\n\treturn a\n}\n", "idx": 9, "id": 13838, "msg": "", "proj": "nats-io-nats-server", "lang": "go"}
{"patch": "@@ -350,7 +350,6 @@ public abstract class Node implements Cloneable, HasParentNode<Node>, Visitable\n     @Override\n     public Node setParentNode(Node parentNode) {\n         observers.forEach(o -> o.parentChange(this, this.parentNode, parentNode));\n-\n         // remove from old parent, if any\n         if (this.parentNode != null) {\n             this.parentNode.childNodes.remove(this);", "y": 0, "oldf": "/*\n * Copyright (C) 2007-2010 J\u00falio Vilmar Gesser.\n * Copyright (C) 2011, 2013-2016 The JavaParser Team.\n *\n * This file is part of JavaParser.\n *\n * JavaParser can be used either under the terms of\n * a) the GNU Lesser General Public License as published by\n *     the Free Software Foundation, either version 3 of the License, or\n *     (at your option) any later version.\n * b) the terms of the Apache License\n *\n * You should have received a copy of both licenses in LICENCE.LGPL and\n * LICENCE.APACHE. Please refer to those files for details.\n *\n * JavaParser is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU Lesser General Public License for more details.\n */\n\npackage com.github.javaparser.ast;\n\nimport com.github.javaparser.HasParentNode;\nimport com.github.javaparser.Position;\nimport com.github.javaparser.Range;\nimport com.github.javaparser.ast.comments.BlockComment;\nimport com.github.javaparser.ast.comments.Comment;\nimport com.github.javaparser.ast.comments.JavadocComment;\nimport com.github.javaparser.ast.comments.LineComment;\nimport com.github.javaparser.ast.observer.AstObserver;\nimport com.github.javaparser.ast.observer.ObservableProperty;\nimport com.github.javaparser.ast.observer.PropagatingAstObserver;\nimport com.github.javaparser.ast.visitor.CloneVisitor;\nimport com.github.javaparser.ast.visitor.EqualsVisitor;\nimport com.github.javaparser.ast.visitor.HashCodeVisitor;\nimport com.github.javaparser.ast.visitor.Visitable;\nimport com.github.javaparser.printer.PrettyPrinter;\nimport com.github.javaparser.printer.PrettyPrinterConfiguration;\n\nimport java.lang.reflect.InvocationTargetException;\nimport java.lang.reflect.Method;\nimport java.lang.reflect.ParameterizedType;\nimport java.lang.reflect.Type;\nimport java.util.*;\n\nimport static java.util.Collections.unmodifiableList;\n\n/**\n * Base class for all nodes of the abstract syntax tree.\n * <h2>Construction</h2>\n * <p>The tree is built by instantiating the required nodes, then adding them to other nodes.\n * If it is the parser who is building the tree, it will use the largest constructor,\n * the one with \"range\" as the first parameter.\n * If you want to manually instantiate nodes, we suggest to...\n * <ul>\n * <li>use a convenience method, like \"addStatement(...)\", or if none are available...</li>\n * <li>use a convenient constructor, like ClassOrInterfaceType(String name), or if none are available...</li>\n * <li>use the default constructor.</li>\n * <li>Alternatively, use one of the JavaParser.parse(snippet) methods.</li>\n * </ul>\n * ... and use the various methods on the node to initialize it further, if needed.\n * <h2>Parent/child</h2>\n * <p>The parent node field is managed automatically and can be seen as read only.\n * Note that there is only one parent,\n * and trying to use the same node in two places will lead to unexpected behaviour.\n * It is advised to clone() a node before moving it around.\n * <h2>Comments</h2>\n * <p>Each Node can have one associated comment which describes it and\n * a number of \"orphan comments\" which it contains but are not specifically\n * associated to any child.\n * <h2>Positions</h2>\n * <p>When the parser creates nodes, it sets their source code position in the \"range\" field.\n * When you manually instantiate nodes, their range is not set.\n * The top left character is position 1, 1.\n * Note that since this is an <i>abstract</i> syntax tree,\n * it leaves out a lot of text from the original source file,\n * like where braces or comma's are exactly.\n * Therefore there is no position information on everything in the original source file.\n * <h2>Observers</h2>\n * <p>It is possible to add observers to the the tree.\n * Any change in the tree is sent as an event to any observers watching.\n * <h2>Visitors</h2>\n * <p>The most comfortable way of working with an abstract syntax tree is using visitors.\n * You can use one of the visitors in the visitor package, or extend one of them.\n * A visitor can be \"run\" by calling accept on a node:\n * <pre>node.accept(visitor, argument);</pre>\n * where argument is an object of your choice (often simply null.)\n *\n * @author Julio Vilmar Gesser\n */\n// Use <Node> to prevent Node from becoming generic.\npublic abstract class Node implements Cloneable, HasParentNode<Node>, Visitable {\n    /**\n     * Different registration mode for observers on nodes.\n     */\n    public enum ObserverRegistrationMode {\n\n        /**\n         * Notify exclusively for changes happening on this node alone.\n         */\n        JUST_THIS_NODE,\n\n        /**\n         * Notify for changes happening on this node and all its descendants existing at the moment in\n         * which the observer was registered. Nodes attached later will not be observed.\n         */\n        THIS_NODE_AND_EXISTING_DESCENDANTS,\n\n        /**\n         * Notify for changes happening on this node and all its descendants. The descendants existing at the moment in\n         * which the observer was registered will be observed immediately. As new nodes are attached later they are\n         * automatically registered to be observed.\n         */\n        SELF_PROPAGATING\n    }\n\n    /**\n     * This can be used to sort nodes on position.\n     */\n    public static Comparator<Node> NODE_BY_BEGIN_POSITION = (a, b) -> {\n        if (a.getRange().isPresent() && b.getRange().isPresent()) {\n            return a.getRange().get().begin.compareTo(b.getRange().get().begin);\n        }\n        if (a.getRange().isPresent() || b.getRange().isPresent()) {\n            if (a.getRange().isPresent()) {\n                return 1;\n            }\n            return -1;\n        }\n        return 0;\n\n    };\n\n    private static final PrettyPrinter toStringPrinter = new PrettyPrinter(new PrettyPrinterConfiguration());\n    protected static final PrettyPrinterConfiguration prettyPrinterNoCommentsConfiguration = new PrettyPrinterConfiguration().setPrintComments(false);\n\n    private Range range;\n\n    private Node parentNode;\n\n    private List<Node> childNodes = new LinkedList<>();\n    private List<Comment> orphanComments = new LinkedList<>();\n\n    private IdentityHashMap<DataKey<?>, Object> data = null;\n\n    private Comment comment;\n\n    private List<AstObserver> observers = new ArrayList<>();\n\n    public Node(Range range) {\n        this.range = range;\n    }\n\n    /**\n     * This is a comment associated with this node.\n     *\n     * @return comment property\n     */\n    public final Optional<Comment> getComment() {\n        return Optional.ofNullable(comment);\n    }\n\n    /**\n     * The begin position of this node in the source file.\n     */\n    public Optional<Position> getBegin() {\n        if (range == null) {\n            return Optional.empty();\n        }\n        return Optional.of(range.begin);\n    }\n\n    /**\n     * The end position of this node in the source file.\n     */\n    public Optional<Position> getEnd() {\n        if (range == null) {\n            return Optional.empty();\n        }\n        return Optional.of(range.end);\n    }\n\n    /**\n     * @return the range of characters in the source code that this node covers.\n     */\n    public Optional<Range> getRange() {\n        return Optional.ofNullable(range);\n    }\n\n    /**\n     * @param range the range of characters in the source code that this node covers. null can be used to indicate that\n     * no range information is known, or that it is not of interest.\n     */\n    public Node setRange(Range range) {\n        notifyPropertyChange(ObservableProperty.RANGE, this.range, range);\n        this.range = range;\n        return this;\n    }\n\n    /**\n     * Use this to store additional information to this node.\n     *\n     * @param comment to be set\n     */\n    public final Node setComment(final Comment comment) {\n        if (comment != null && (this instanceof Comment)) {\n            throw new RuntimeException(\"A comment can not be commented\");\n        }\n        notifyPropertyChange(ObservableProperty.COMMENT, this.comment, comment);\n        if (this.comment != null) {\n            this.comment.setCommentedNode(null);\n        }\n        this.comment = comment;\n        if (comment != null) {\n            this.comment.setCommentedNode(this);\n        }\n        return this;\n    }\n\n    /**\n     * Use this to store additional information to this node.\n     *\n     * @param comment to be set\n     */\n    public final Node setLineComment(String comment) {\n        return setComment(new LineComment(comment));\n    }\n\n    /**\n     * Use this to store additional information to this node.\n     *\n     * @param comment to be set\n     */\n    public final Node setBlockComment(String comment) {\n        return setComment(new BlockComment(comment));\n    }\n\n    /**\n     * Return the String representation of this node.\n     *\n     * @return the String representation of this node\n     */\n    @Override\n    public final String toString() {\n        return toStringPrinter.print(this);\n    }\n\n    public final String toString(PrettyPrinterConfiguration prettyPrinterConfiguration) {\n        return new PrettyPrinter(prettyPrinterConfiguration).print(this);\n    }\n\n    @Override\n    public final int hashCode() {\n        return HashCodeVisitor.hashCode(this);\n    }\n\n    @Override\n    public boolean equals(final Object obj) {\n        if (obj == null || !(obj instanceof Node)) {\n            return false;\n        }\n        return EqualsVisitor.equals(this, (Node) obj);\n    }\n\n    @Override\n    public Node clone() {\n        return (Node) accept(new CloneVisitor(), null);\n    }\n\n    @Override\n    public Optional<Node> getParentNode() {\n        return Optional.ofNullable(parentNode);\n    }\n\n    /**\n     * Contains all nodes that have this node set as their parent.\n     * You can add nodes to it by setting a node's parent to this node.\n     * You can remove nodes from it by setting a child node's parent to something other than this node.\n     *\n     * @return all nodes that have this node as their parent.\n     */\n    public List<Node> getChildNodes() {\n        return unmodifiableList(childNodes);\n    }\n\n    public <N extends Node> boolean containsWithin(N other) {\n        if (getRange().isPresent() && other.getRange().isPresent()) {\n            return range.contains(other.getRange().get());\n        }\n        return false;\n    }\n\n    public void addOrphanComment(Comment comment) {\n        orphanComments.add(comment);\n        comment.setParentNode(this);\n    }\n\n    public boolean removeOrphanComment(Comment comment) {\n        boolean removed = orphanComments.remove(comment);\n        if (removed) {\n            comment.setParentNode(null);\n        }\n        return removed;\n    }\n\n    /**\n     * This is a list of Comment which are inside the node and are not associated\n     * with any meaningful AST Node.\n     * <p>\n     * For example, comments at the end of methods (immediately before the parenthesis)\n     * or at the end of CompilationUnit are orphan comments.\n     * <p>\n     * When more than one comment preceeds a statement, the one immediately preceding it\n     * it is associated with the statements, while the others are orphans.\n     * <p>\n     * Changes to this list are not persisted.\n     *\n     * @return all comments that cannot be attributed to a concept\n     */\n    public List<Comment> getOrphanComments() {\n        return new LinkedList<>(orphanComments);\n    }\n\n    /**\n     * This is the list of Comment which are contained in the Node either because\n     * they are properly associated to one of its children or because they are floating\n     * around inside the Node\n     *\n     * @return all Comments within the node as a list\n     */\n    public List<Comment> getAllContainedComments() {\n        List<Comment> comments = new LinkedList<>();\n        comments.addAll(getOrphanComments());\n\n        for (Node child : getChildNodes()) {\n            child.getComment().ifPresent(comments::add);\n            comments.addAll(child.getAllContainedComments());\n        }\n\n        return comments;\n    }\n\n    /**\n     * Assign a new parent to this node, removing it\n     * from the list of children of the previous parent, if any.\n     *\n     * @param parentNode node to be set as parent\n     */\n    @Override\n    public Node setParentNode(Node parentNode) {\n        observers.forEach(o -> o.parentChange(this, this.parentNode, parentNode));\n\n        // remove from old parent, if any\n        if (this.parentNode != null) {\n            this.parentNode.childNodes.remove(this);\n        }\n        this.parentNode = parentNode;\n        // add to new parent, if any\n        if (this.parentNode != null) {\n            this.parentNode.childNodes.add(this);\n        }\n        return this;\n    }\n\n    public static final int ABSOLUTE_BEGIN_LINE = -1;\n    public static final int ABSOLUTE_END_LINE = -2;\n\n    @Deprecated\n    public boolean isPositionedAfter(Position position) {\n        if (range == null) {\n            return false;\n        }\n        return range.isAfter(position);\n    }\n\n    @Deprecated\n    public boolean isPositionedBefore(Position position) {\n        if (range == null) {\n            return true;\n        }\n        return range.isBefore(position);\n    }\n\n    @Deprecated\n    public boolean hasComment() {\n        return comment != null;\n    }\n\n    public void tryAddImportToParentCompilationUnit(Class<?> clazz) {\n        getAncestorOfType(CompilationUnit.class).ifPresent(p -> p.addImport(clazz));\n    }\n\n    /**\n     * Recursively finds all nodes of a certain type.\n     *\n     * @param clazz the type of node to find.\n     */\n    public <N extends Node> List<N> getNodesByType(Class<N> clazz) {\n        List<N> nodes = new ArrayList<>();\n        for (Node child : getChildNodes()) {\n            if (clazz.isInstance(child)) {\n                nodes.add(clazz.cast(child));\n            }\n            nodes.addAll(child.getNodesByType(clazz));\n        }\n        return nodes;\n    }\n\n    /**\n     * Gets data for this component using the given key.\n     *\n     * @param <M> The type of the data.\n     * @param key The key for the data\n     * @return The data or null of no data was found for the given key\n     * @see DataKey\n     */\n    @SuppressWarnings(\"unchecked\")\n    public <M> M getData(final DataKey<M> key) {\n        if (data == null) {\n            return null;\n        }\n        return (M) data.get(key);\n    }\n\n    /**\n     * Sets data for this component using the given key.\n     * For information on creating DataKey, see {@link DataKey}.\n     *\n     * @param <M> The type of data\n     * @param key The singleton key for the data\n     * @param object The data object\n     * @see DataKey\n     */\n    public <M> void setData(DataKey<M> key, M object) {\n        if (data == null) {\n            data = new IdentityHashMap<>();\n        }\n        data.put(key, object);\n    }\n\n    /**\n     * Try to remove this node from the parent\n     *\n     * @return true if removed, false otherwise\n     * @throws RuntimeException if it fails in an unexpected way\n     */\n    public boolean remove() {\n        Node parentNode = this.parentNode;\n        if (parentNode == null) {\n            return false;\n        }\n        boolean removed = false;\n        Class<?> parentClass = parentNode.getClass();\n\n        // we are going to look to remove the node either by checking if it is part of a NodeList\n        // of if there is an explicit setter for it\n\n        for (Method method : parentClass.getMethods()) {\n            if (!removed && !java.lang.reflect.Modifier.isStatic(method.getModifiers())) {\n                // looking for methods returning a NodeList\n                if (method.getParameterCount() == 0 && NodeList.class.isAssignableFrom(method.getReturnType())) {\n                    try {\n                        NodeList result = (NodeList) method.invoke(parentNode);\n                        removed = result.remove(this);\n                    } catch (IllegalAccessException | InvocationTargetException e) {\n                        // nothing to do here\n                    }\n                } else if ((method.getReturnType().isAssignableFrom(this.getClass()) || isOptionalAssignableFrom(method.getGenericReturnType(), this.getClass()))\n                        && method.getParameterCount() == 0\n                        && method.getName().startsWith(\"get\")) {\n                    final Class<?> setterParamType = isOptionalAssignableFrom(method.getGenericReturnType(), this.getClass()) ?\n                            getOptionalParameterType(method.getGenericReturnType()) : method.getReturnType();\n                    // ok, we found a potential getter. Before invoking let's check there is a corresponding setter,\n                    // otherwise there is no point\n                    String setterName = \"set\" + method.getName().substring(\"get\".length());\n                    Optional<Method> optSetter = Arrays.stream(parentClass.getMethods())\n                            .filter(m -> m.getName().equals(setterName))\n                            .filter(m -> !java.lang.reflect.Modifier.isStatic(m.getModifiers()))\n                            .filter(m -> m.getParameterCount() == 1)\n                            .filter(m -> m.getParameterTypes()[0].equals(setterParamType))\n                            .findFirst();\n                    if (optSetter.isPresent()) {\n                        try {\n                            Object resultRaw = method.invoke(parentNode);\n                            Node result;\n                            if (isOptionalAssignableFrom(method.getGenericReturnType(), this.getClass())) {\n                                Optional optionalResultRaw = (Optional) resultRaw;\n                                if (optionalResultRaw.isPresent()) {\n                                    Object o = optionalResultRaw.get();\n                                    if (Node.class.isAssignableFrom(o.getClass())) {\n                                        result = (Node) o;\n                                    } else continue;\n                                } else continue;\n                            } else {\n                                result = (Node) resultRaw;\n                            }\n                            if (this == result) {\n                                optSetter.get().invoke(parentNode, (Object) null);\n                                removed = true;\n                            }\n                        } catch (IllegalAccessException | InvocationTargetException e) {\n                            // nothing to do here\n                        }\n                    }\n                }\n            }\n        }\n        return removed;\n    }\n\n    @Override\n    public Node getParentNodeForChildren() {\n        return this;\n    }\n\n    protected void setAsParentNodeOf(NodeList<? extends Node> list) {\n        if (list != null) {\n            list.setParentNode(getParentNodeForChildren());\n        }\n    }\n\n    protected <P> void notifyPropertyChange(ObservableProperty property, P oldValue, P newValue) {\n        this.observers.forEach(o -> o.propertyChange(this, property, oldValue, newValue));\n    }\n\n    @Override\n    public void unregister(AstObserver observer) {\n        this.observers.remove(observer);\n    }\n\n    @Override\n    public void register(AstObserver observer) {\n        this.observers.add(observer);\n    }\n\n    /**\n     * Register a new observer for the given node. Depending on the mode specified also descendants, existing\n     * and new, could be observed. For more details see <i>ObserverRegistrationMode</i>.\n     */\n    public void register(AstObserver observer, ObserverRegistrationMode mode) {\n        if (mode == null) {\n            throw new IllegalArgumentException(\"Mode should be not null\");\n        }\n        switch (mode) {\n            case JUST_THIS_NODE:\n                register(observer);\n                break;\n            case THIS_NODE_AND_EXISTING_DESCENDANTS:\n                registerForSubtree(observer);\n                break;\n            case SELF_PROPAGATING:\n                registerForSubtree(PropagatingAstObserver.transformInPropagatingObserver(observer));\n                break;\n            default:\n                throw new UnsupportedOperationException(\"This mode is not supported: \" + mode);\n        }\n    }\n\n    /**\n     * Register the observer for the current node and all the contained node and nodelists, recursively.\n     */\n    public void registerForSubtree(AstObserver observer) {\n        register(observer);\n        this.getChildNodes().forEach(c -> c.registerForSubtree(observer));\n        this.getNodeLists().forEach(nl -> nl.register(observer));\n    }\n\n    @Override\n    public boolean isRegistered(AstObserver observer) {\n        return this.observers.contains(observer);\n    }\n\n    /**\n     * The list of NodeLists owned by this node.\n     */\n    public List<NodeList<?>> getNodeLists() {\n        return Collections.emptyList();\n    }\n\n    private boolean isOptionalAssignableFrom(Type type, Class<?> clazz) {\n        return internalGetOptionalParameterType(type).isPresent();\n    }\n\n    private Class getOptionalParameterType(Type type) {\n        Optional<Class> res = internalGetOptionalParameterType(type);\n        if (res.isPresent()) {\n            return res.get();\n        } else {\n            throw new IllegalArgumentException(\"This type is not an Optional \" + type);\n        }\n    }\n\n    private Optional<Class> internalGetOptionalParameterType(Type type) {\n        if (!(type instanceof ParameterizedType)) {\n            return Optional.empty();\n        }\n        ParameterizedType parameterizedType = (ParameterizedType) type;\n        if (!(parameterizedType.getRawType() instanceof Class)) {\n            return Optional.empty();\n        }\n        Class rawType = (Class) parameterizedType.getRawType();\n        if (!(rawType.equals(Optional.class))) {\n            return Optional.empty();\n        }\n        if (!(parameterizedType.getActualTypeArguments()[0] instanceof Class)) {\n            return Optional.empty();\n        }\n        Class parameterType = (Class) parameterizedType.getActualTypeArguments()[0];\n        return Optional.of(parameterType);\n    }\n}\n", "idx": 8, "id": 10526, "msg": "", "proj": "javaparser-javaparser", "lang": "java"}
{"patch": "@@ -529,10 +529,12 @@ func testMDOpsGetRangeSuccess(t *testing.T, fromStart bool) {\n \t\tverifyMDForPrivate(config, rmds)\n \t}\n \n-\tconfig.mockMdserv.EXPECT().GetRange(ctx, rmdses[0].MD.TlfID(), NullBranchID, Merged, start,\n-\t\tstop).Return(rmdses, nil)\n-\tfor _, e := range extras {\n-\t\texpectGetKeyBundles(ctx, config, e)\n+\tmdServer := makeKeyBundleMDServer(config.MDServer())\n+\tconfig.SetMDServer(mdServer)\n+\n+\tmdServer.nextGetRange = rmdses\n+\tfor i, e := range extras {\n+\t\tmdServer.processRMDSes(rmdses[i], e)\n \t}\n \n \t// Do this first since rmdses is consumed.", "y": 0, "oldf": "// Copyright 2016 Keybase Inc. All rights reserved.\n// Use of this source code is governed by a BSD\n// license that can be found in the LICENSE file.\n\npackage libkbfs\n\nimport (\n\t\"errors\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/golang/mock/gomock\"\n\t\"github.com/keybase/client/go/libkb\"\n\t\"github.com/keybase/kbfs/kbfscodec\"\n\t\"github.com/keybase/kbfs/kbfscrypto\"\n\t\"github.com/keybase/kbfs/kbfshash\"\n\t\"github.com/keybase/kbfs/tlf\"\n\t\"github.com/stretchr/testify/require\"\n\t\"golang.org/x/net/context\"\n)\n\ntype shimCrypto struct {\n\tCrypto\n\tpure cryptoPure\n\tkey  kbfscrypto.SigningKey\n}\n\nfunc (c shimCrypto) MakeMdID(md BareRootMetadata) (MdID, error) {\n\treturn c.pure.MakeMdID(md)\n}\n\nfunc (c shimCrypto) Sign(\n\tctx context.Context, data []byte) (kbfscrypto.SignatureInfo, error) {\n\treturn c.key.Sign(data), nil\n}\n\nfunc (c shimCrypto) Verify(\n\tmsg []byte, sigInfo kbfscrypto.SignatureInfo) (err error) {\n\treturn kbfscrypto.Verify(msg, sigInfo)\n}\n\nfunc injectShimCrypto(config Config) {\n\tsigningKey := kbfscrypto.MakeFakeSigningKeyOrBust(\"test key\")\n\tcrypto := shimCrypto{\n\t\tconfig.Crypto(),\n\t\tMakeCryptoCommon(kbfscodec.NewMsgpack()),\n\t\tsigningKey,\n\t}\n\tconfig.SetCrypto(crypto)\n}\n\nfunc mdOpsInit(t *testing.T) (mockCtrl *gomock.Controller,\n\tconfig *ConfigMock, ctx context.Context) {\n\tctr := NewSafeTestReporter(t)\n\tmockCtrl = gomock.NewController(ctr)\n\tconfig = NewConfigMock(mockCtrl, ctr)\n\tmdops := NewMDOpsStandard(config)\n\tconfig.SetMDOps(mdops)\n\tconfig.SetCodec(kbfscodec.NewMsgpack())\n\tconfig.mockMdserv.EXPECT().OffsetFromServerTime().\n\t\tReturn(time.Duration(0), true).AnyTimes()\n\th1, _ := kbfshash.DefaultHash([]byte{1})\n\th2, _ := kbfshash.DefaultHash([]byte{2})\n\tconfig.mockCrypto.EXPECT().MakeTLFWriterKeyBundleID(gomock.Any()).\n\t\tReturn(TLFWriterKeyBundleID{h1}, nil).AnyTimes()\n\tconfig.mockCrypto.EXPECT().MakeTLFReaderKeyBundleID(gomock.Any()).\n\t\tReturn(TLFReaderKeyBundleID{h2}, nil).AnyTimes()\n\tinjectShimCrypto(config)\n\tinterposeDaemonKBPKI(config, \"alice\", \"bob\", \"charlie\")\n\tctx = context.Background()\n\treturn\n}\n\nfunc mdOpsShutdown(mockCtrl *gomock.Controller, config *ConfigMock) {\n\tconfig.ctr.CheckForFailures()\n\tmockCtrl.Finish()\n}\n\nfunc addFakeRMDData(t *testing.T,\n\tcodec kbfscodec.Codec, crypto cryptoPure, rmd *RootMetadata,\n\th *TlfHandle) {\n\trmd.SetRevision(MetadataRevision(1))\n\tpmd := PrivateMetadata{}\n\t// TODO: Will have to change this for private folders if we\n\t// un-mock out those tests.\n\tbuf, err := codec.Encode(pmd)\n\trequire.NoError(t, err)\n\trmd.SetSerializedPrivateMetadata(buf)\n\trmd.SetLastModifyingWriter(h.FirstResolvedWriter())\n\trmd.SetLastModifyingUser(h.FirstResolvedWriter())\n\tif !h.IsPublic() {\n\t\trmd.fakeInitialRekey(codec, crypto)\n\t}\n}\n\nfunc newRMDS(t *testing.T, config Config, h *TlfHandle) (\n\t*RootMetadataSigned, ExtraMetadata) {\n\tid := tlf.FakeID(1, h.IsPublic())\n\n\trmd, err := makeInitialRootMetadata(defaultClientMetadataVer, id, h)\n\trequire.NoError(t, err)\n\n\taddFakeRMDData(t, config.Codec(), config.Crypto(), rmd, h)\n\tctx := context.Background()\n\n\t// Encode and sign writer metadata.\n\terr = rmd.bareMd.SignWriterMetadataInternally(ctx, config.Codec(), config.Crypto())\n\trequire.NoError(t, err)\n\n\trmds, err := SignBareRootMetadata(\n\t\tctx, config.Codec(), config.Crypto(), config.Crypto(),\n\t\trmd.bareMd, time.Now())\n\trequire.NoError(t, err)\n\treturn rmds, rmd.extra\n}\n\nfunc verifyMDForPublic(config *ConfigMock, rmds *RootMetadataSigned,\n\tverifyErr, hasVerifyingKeyErr error) {\n\tif verifyErr != nil {\n\t\treturn\n\t}\n\tconfig.mockKbpki.EXPECT().HasVerifyingKey(gomock.Any(), gomock.Any(),\n\t\tgomock.Any(), gomock.Any()).AnyTimes().Return(hasVerifyingKeyErr)\n\n\tif hasVerifyingKeyErr != nil {\n\t\treturn\n\t}\n}\n\nfunc verifyMDForPrivateHelper(\n\tconfig *ConfigMock, rmds *RootMetadataSigned, minTimes, maxTimes int) {\n\tmdCopy, err := rmds.MD.DeepCopy(config.Codec())\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tfakeRMD := RootMetadata{\n\t\tbareMd: mdCopy,\n\t}\n\texpectGetTLFCryptKeyForMDDecryptionAtMostOnce(config, &fakeRMD)\n\tvar pmd PrivateMetadata\n\tconfig.mockCrypto.EXPECT().DecryptPrivateMetadata(\n\t\tgomock.Any(), kbfscrypto.TLFCryptKey{}).\n\t\tMinTimes(minTimes).MaxTimes(maxTimes).Return(pmd, nil)\n\n\tif rmds.MD.IsFinal() {\n\t\tconfig.mockKbpki.EXPECT().HasUnverifiedVerifyingKey(gomock.Any(), gomock.Any(),\n\t\t\tgomock.Any()).AnyTimes().Return(nil)\n\t} else {\n\t\tconfig.mockKbpki.EXPECT().HasVerifyingKey(gomock.Any(), gomock.Any(),\n\t\t\tgomock.Any(), gomock.Any()).AnyTimes().Return(nil)\n\t}\n\n\tconfig.mockCrypto.EXPECT().Verify(gomock.Any(), rmds.SigInfo).\n\t\tMinTimes(minTimes).MaxTimes(maxTimes).Return(nil)\n\tconfig.mockCrypto.EXPECT().\n\t\tVerify(gomock.Any(), rmds.GetWriterMetadataSigInfo()).\n\t\tMinTimes(minTimes).MaxTimes(maxTimes).Return(nil)\n}\n\nfunc verifyMDForPrivate(\n\tconfig *ConfigMock, rmds *RootMetadataSigned) {\n\tverifyMDForPrivateHelper(config, rmds, 1, 1)\n}\n\nfunc putMDForPrivate(config *ConfigMock, rmd *RootMetadata) {\n\texpectGetTLFCryptKeyForEncryption(config, rmd)\n\tconfig.mockCrypto.EXPECT().EncryptPrivateMetadata(\n\t\trmd.data, kbfscrypto.TLFCryptKey{}).Return(\n\t\tEncryptedPrivateMetadata{}, nil)\n\tconfig.mockBsplit.EXPECT().ShouldEmbedBlockChanges(gomock.Any()).\n\t\tReturn(true)\n\tconfig.mockMdserv.EXPECT().Put(gomock.Any(), gomock.Any(), gomock.Any()).Return(nil)\n}\n\nfunc TestMDOpsGetForHandlePublicSuccess(t *testing.T) {\n\tmockCtrl, config, ctx := mdOpsInit(t)\n\tdefer mdOpsShutdown(mockCtrl, config)\n\n\th := parseTlfHandleOrBust(t, config, \"alice,bob\", true)\n\trmds, _ := newRMDS(t, config, h)\n\n\tverifyMDForPublic(config, rmds, nil, nil)\n\n\tconfig.mockMdserv.EXPECT().GetForHandle(ctx, h.ToBareHandleOrBust(), Merged).Return(tlf.NullID, rmds, nil)\n\n\t// Do this first, since rmds is consumed.\n\texpectedMD := rmds.MD\n\t_, rmd2, err := config.MDOps().GetForHandle(ctx, h, Merged)\n\trequire.NoError(t, err)\n\trequire.Equal(t, expectedMD, rmd2.bareMd)\n}\n\nfunc expectGetKeyBundles(ctx context.Context, config *ConfigMock, extra ExtraMetadata) {\n\tif extraV3, ok := extra.(*ExtraMetadataV3); ok {\n\t\tconfig.mockMdserv.EXPECT().GetKeyBundles(\n\t\t\tctx, gomock.Any(), gomock.Any(), gomock.Any()).\n\t\t\tReturn(extraV3.wkb, extraV3.rkb, nil)\n\t}\n}\n\nfunc TestMDOpsGetForHandlePrivateSuccess(t *testing.T) {\n\tmockCtrl, config, ctx := mdOpsInit(t)\n\tdefer mdOpsShutdown(mockCtrl, config)\n\n\th := parseTlfHandleOrBust(t, config, \"alice,bob\", false)\n\trmds, extra := newRMDS(t, config, h)\n\n\tverifyMDForPrivate(config, rmds)\n\n\tconfig.mockMdserv.EXPECT().GetForHandle(ctx, h.ToBareHandleOrBust(), Merged).Return(tlf.NullID, rmds, nil)\n\texpectGetKeyBundles(ctx, config, extra)\n\n\t// Do this first, since rmds is consumed.\n\texpectedMD := rmds.MD\n\t_, rmd2, err := config.MDOps().GetForHandle(ctx, h, Merged)\n\trequire.NoError(t, err)\n\trequire.Equal(t, expectedMD, rmd2.bareMd)\n}\n\nfunc TestMDOpsGetForUnresolvedHandlePublicSuccess(t *testing.T) {\n\tmockCtrl, config, ctx := mdOpsInit(t)\n\tdefer mdOpsShutdown(mockCtrl, config)\n\n\th := parseTlfHandleOrBust(t, config, \"alice,bob\", true)\n\trmds, _ := newRMDS(t, config, h)\n\n\t// Do this before setting tlfHandle to nil.\n\tverifyMDForPublic(config, rmds, nil, nil)\n\n\thUnresolved, err := ParseTlfHandle(ctx, config.KBPKI(),\n\t\t\"alice,bob@twitter\", true)\n\trequire.NoError(t, err)\n\n\tconfig.mockMdserv.EXPECT().GetForHandle(ctx, hUnresolved.ToBareHandleOrBust(), Merged).Return(tlf.NullID, rmds, nil).Times(2)\n\n\t// First time should fail.\n\t_, _, err = config.MDOps().GetForHandle(ctx, hUnresolved, Merged)\n\tif _, ok := err.(MDMismatchError); !ok {\n\t\tt.Errorf(\"Got unexpected error on bad handle check test: %v\", err)\n\t}\n\n\tdaemon := config.KeybaseService().(*KeybaseDaemonLocal)\n\tdaemon.addNewAssertionForTestOrBust(\"bob\", \"bob@twitter\")\n\n\t// Second time should succeed.\n\tif _, _, err := config.MDOps().GetForHandle(ctx, hUnresolved, Merged); err != nil {\n\t\tt.Errorf(\"Got error on get: %v\", err)\n\t}\n}\n\nfunc TestMDOpsGetForUnresolvedMdHandlePublicSuccess(t *testing.T) {\n\tmockCtrl, config, ctx := mdOpsInit(t)\n\tdefer mdOpsShutdown(mockCtrl, config)\n\n\tmdHandle1, err := ParseTlfHandle(ctx, config.KBPKI(),\n\t\t\"alice,dave@twitter\", true)\n\trequire.NoError(t, err)\n\n\tmdHandle2, err := ParseTlfHandle(ctx, config.KBPKI(),\n\t\t\"alice,bob,charlie\", true)\n\trequire.NoError(t, err)\n\n\tmdHandle3, err := ParseTlfHandle(ctx, config.KBPKI(),\n\t\t\"alice,bob@twitter,charlie@twitter\", true)\n\trequire.NoError(t, err)\n\n\trmds1, _ := newRMDS(t, config, mdHandle1)\n\n\trmds2, _ := newRMDS(t, config, mdHandle2)\n\n\trmds3, _ := newRMDS(t, config, mdHandle3)\n\n\t// Do this before setting tlfHandles to nil.\n\tverifyMDForPublic(config, rmds2, nil, nil)\n\tverifyMDForPublic(config, rmds3, nil, nil)\n\n\th, err := ParseTlfHandle(\n\t\tctx, config.KBPKI(), \"alice,bob,charlie@twitter\", true)\n\trequire.NoError(t, err)\n\n\tconfig.mockMdserv.EXPECT().GetForHandle(ctx, h.ToBareHandleOrBust(), Merged).Return(tlf.NullID, rmds1, nil)\n\n\t// First time should fail.\n\t_, _, err = config.MDOps().GetForHandle(ctx, h, Merged)\n\tif _, ok := err.(MDMismatchError); !ok {\n\t\tt.Errorf(\"Got unexpected error on bad handle check test: %v\", err)\n\t}\n\n\tdaemon := config.KeybaseService().(*KeybaseDaemonLocal)\n\tdaemon.addNewAssertionForTestOrBust(\"bob\", \"bob@twitter\")\n\tdaemon.addNewAssertionForTestOrBust(\"charlie\", \"charlie@twitter\")\n\n\tconfig.mockMdserv.EXPECT().GetForHandle(ctx, h.ToBareHandleOrBust(), Merged).Return(tlf.NullID, rmds2, nil)\n\n\t// Second and time should succeed.\n\tif _, _, err := config.MDOps().GetForHandle(ctx, h, Merged); err != nil {\n\t\tt.Errorf(\"Got error on get: %v\", err)\n\t}\n\n\tconfig.mockMdserv.EXPECT().GetForHandle(ctx, h.ToBareHandleOrBust(), Merged).Return(tlf.NullID, rmds3, nil)\n\n\tif _, _, err := config.MDOps().GetForHandle(ctx, h, Merged); err != nil {\n\t\tt.Errorf(\"Got error on get: %v\", err)\n\t}\n}\n\nfunc TestMDOpsGetForUnresolvedHandlePublicFailure(t *testing.T) {\n\tmockCtrl, config, ctx := mdOpsInit(t)\n\tdefer mdOpsShutdown(mockCtrl, config)\n\n\th := parseTlfHandleOrBust(t, config, \"alice,bob\", true)\n\trmds, _ := newRMDS(t, config, h)\n\n\thUnresolved, err := ParseTlfHandle(ctx, config.KBPKI(),\n\t\t\"alice,bob@github,bob@twitter\", true)\n\trequire.NoError(t, err)\n\n\tdaemon := config.KeybaseService().(*KeybaseDaemonLocal)\n\tdaemon.addNewAssertionForTestOrBust(\"bob\", \"bob@twitter\")\n\n\tconfig.mockMdserv.EXPECT().GetForHandle(ctx, hUnresolved.ToBareHandleOrBust(), Merged).Return(tlf.NullID, rmds, nil)\n\n\t// Should still fail.\n\t_, _, err = config.MDOps().GetForHandle(ctx, hUnresolved, Merged)\n\tif _, ok := err.(MDMismatchError); !ok {\n\t\tt.Errorf(\"Got unexpected error on bad handle check test: %v\", err)\n\t}\n}\n\nfunc TestMDOpsGetForHandlePublicFailFindKey(t *testing.T) {\n\tmockCtrl, config, ctx := mdOpsInit(t)\n\tdefer mdOpsShutdown(mockCtrl, config)\n\n\th := parseTlfHandleOrBust(t, config, \"alice,bob\", true)\n\trmds, _ := newRMDS(t, config, h)\n\n\t// Do this before setting tlfHandle to nil.\n\tverifyMDForPublic(config, rmds, nil, KeyNotFoundError{})\n\n\tconfig.mockMdserv.EXPECT().GetForHandle(ctx, h.ToBareHandleOrBust(), Merged).Return(tlf.NullID, rmds, nil)\n\n\t_, _, err := config.MDOps().GetForHandle(ctx, h, Merged)\n\tif _, ok := err.(UnverifiableTlfUpdateError); !ok {\n\t\tt.Errorf(\"Got unexpected error on get: %v\", err)\n\t}\n}\n\ntype failVerifyCrypto struct {\n\tCrypto\n\terr error\n}\n\nfunc (c failVerifyCrypto) Verify(msg []byte, sigInfo kbfscrypto.SignatureInfo) error {\n\treturn c.err\n}\n\nfunc TestMDOpsGetForHandlePublicFailVerify(t *testing.T) {\n\tmockCtrl, config, ctx := mdOpsInit(t)\n\tdefer mdOpsShutdown(mockCtrl, config)\n\n\th := parseTlfHandleOrBust(t, config, \"alice,bob\", true)\n\trmds, _ := newRMDS(t, config, h)\n\n\t// Do this before setting tlfHandle to nil.\n\texpectedErr := libkb.VerificationError{}\n\tverifyMDForPublic(config, rmds, expectedErr, nil)\n\n\tconfig.SetCrypto(failVerifyCrypto{config.Crypto(), expectedErr})\n\n\tconfig.mockMdserv.EXPECT().GetForHandle(ctx, h.ToBareHandleOrBust(), Merged).Return(tlf.NullID, rmds, nil)\n\n\t_, _, err := config.MDOps().GetForHandle(ctx, h, Merged)\n\trequire.IsType(t, MDMismatchError{}, err)\n}\n\nfunc TestMDOpsGetForHandleFailGet(t *testing.T) {\n\tmockCtrl, config, ctx := mdOpsInit(t)\n\tdefer mdOpsShutdown(mockCtrl, config)\n\n\th := parseTlfHandleOrBust(t, config, \"alice,bob\", false)\n\n\terr := errors.New(\"Fake fail\")\n\n\t// only the get happens, no verify needed with a blank sig\n\tconfig.mockMdserv.EXPECT().GetForHandle(ctx, h.ToBareHandleOrBust(), Merged).Return(tlf.NullID, nil, err)\n\n\tif _, _, err2 := config.MDOps().GetForHandle(ctx, h, Merged); err2 != err {\n\t\tt.Errorf(\"Got bad error on get: %v\", err2)\n\t}\n}\n\nfunc TestMDOpsGetForHandleFailHandleCheck(t *testing.T) {\n\tmockCtrl, config, ctx := mdOpsInit(t)\n\tdefer mdOpsShutdown(mockCtrl, config)\n\n\th := parseTlfHandleOrBust(t, config, \"alice,bob\", false)\n\trmds, extra := newRMDS(t, config, h)\n\n\t// Make a different handle.\n\totherH := parseTlfHandleOrBust(t, config, \"alice\", false)\n\tconfig.mockMdserv.EXPECT().GetForHandle(ctx, otherH.ToBareHandleOrBust(), Merged).Return(tlf.NullID, rmds, nil)\n\texpectGetKeyBundles(ctx, config, extra)\n\n\t_, _, err := config.MDOps().GetForHandle(ctx, otherH, Merged)\n\tif _, ok := err.(MDMismatchError); !ok {\n\t\tt.Errorf(\"Got unexpected error on bad handle check test: %v\", err)\n\t}\n}\n\nfunc TestMDOpsGetSuccess(t *testing.T) {\n\tmockCtrl, config, ctx := mdOpsInit(t)\n\tdefer mdOpsShutdown(mockCtrl, config)\n\n\th := parseTlfHandleOrBust(t, config, \"alice,bob\", false)\n\trmds, extra := newRMDS(t, config, h)\n\n\t// Do this before setting tlfHandle to nil.\n\tverifyMDForPrivate(config, rmds)\n\n\tconfig.mockMdserv.EXPECT().GetForTLF(ctx, rmds.MD.TlfID(), NullBranchID, Merged).Return(rmds, nil)\n\texpectGetKeyBundles(ctx, config, extra)\n\n\t// Do this first, since rmds is consumed.\n\texpectedMD := rmds.MD\n\trmd2, err := config.MDOps().GetForTLF(ctx, rmds.MD.TlfID())\n\trequire.NoError(t, err)\n\trequire.Equal(t, expectedMD, rmd2.bareMd)\n}\n\nfunc TestMDOpsGetBlankSigFailure(t *testing.T) {\n\tmockCtrl, config, ctx := mdOpsInit(t)\n\tdefer mdOpsShutdown(mockCtrl, config)\n\n\th := parseTlfHandleOrBust(t, config, \"alice,bob\", false)\n\trmds, extra := newRMDS(t, config, h)\n\trmds.SigInfo = kbfscrypto.SignatureInfo{}\n\n\t// only the get happens, no verify needed with a blank sig\n\tconfig.mockMdserv.EXPECT().GetForTLF(ctx, rmds.MD.TlfID(), NullBranchID, Merged).Return(rmds, nil)\n\texpectGetKeyBundles(ctx, config, extra)\n\n\tif _, err := config.MDOps().GetForTLF(ctx, rmds.MD.TlfID()); err == nil {\n\t\tt.Error(\"Got no error on get\")\n\t}\n}\n\nfunc TestMDOpsGetFailGet(t *testing.T) {\n\tmockCtrl, config, ctx := mdOpsInit(t)\n\tdefer mdOpsShutdown(mockCtrl, config)\n\n\tid := tlf.FakeID(1, true)\n\terr := errors.New(\"Fake fail\")\n\n\t// only the get happens, no verify needed with a blank sig\n\tconfig.mockMdserv.EXPECT().GetForTLF(ctx, id, NullBranchID, Merged).Return(nil, err)\n\n\tif _, err2 := config.MDOps().GetForTLF(ctx, id); err2 != err {\n\t\tt.Errorf(\"Got bad error on get: %v\", err2)\n\t}\n}\n\nfunc TestMDOpsGetFailIdCheck(t *testing.T) {\n\tmockCtrl, config, ctx := mdOpsInit(t)\n\tdefer mdOpsShutdown(mockCtrl, config)\n\n\th := parseTlfHandleOrBust(t, config, \"alice,bob\", false)\n\trmds, extra := newRMDS(t, config, h)\n\n\tid2 := tlf.FakeID(2, true)\n\n\tconfig.mockMdserv.EXPECT().GetForTLF(ctx, id2, NullBranchID, Merged).Return(rmds, nil)\n\texpectGetKeyBundles(ctx, config, extra)\n\n\tif _, err := config.MDOps().GetForTLF(ctx, id2); err == nil {\n\t\tt.Errorf(\"Got no error on bad id check test\")\n\t} else if _, ok := err.(MDMismatchError); !ok {\n\t\tt.Errorf(\"Got unexpected error on bad id check test: %v\", err)\n\t}\n}\n\nfunc makeRMDSRange(t *testing.T, config Config,\n\tstart MetadataRevision, count int, prevID MdID) (\n\trmdses []*RootMetadataSigned, extras []ExtraMetadata) {\n\tid := tlf.FakeID(1, false)\n\th := parseTlfHandleOrBust(t, config, \"alice,bob\", false)\n\tfor i := 0; i < count; i++ {\n\t\trmd, err := makeInitialRootMetadata(defaultClientMetadataVer, id, h)\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\n\t\taddFakeRMDData(t, config.Codec(), config.Crypto(), rmd, h)\n\t\trmd.SetPrevRoot(prevID)\n\t\trmd.SetRevision(start + MetadataRevision(i))\n\n\t\tctx := context.Background()\n\n\t\t// Encode and sign writer metadata.\n\t\terr = rmd.bareMd.SignWriterMetadataInternally(ctx, config.Codec(), config.Crypto())\n\t\trequire.NoError(t, err)\n\n\t\trmds, err := SignBareRootMetadata(\n\t\t\tctx, config.Codec(), config.Crypto(), config.Crypto(),\n\t\t\trmd.bareMd, time.Now())\n\t\trequire.NoError(t, err)\n\t\tcurrID, err := config.Crypto().MakeMdID(rmds.MD)\n\t\trequire.NoError(t, err)\n\t\tprevID = currID\n\t\trmdses = append(rmdses, rmds)\n\t\textras = append(extras, rmd.extra)\n\t}\n\treturn rmdses, extras\n}\n\nfunc testMDOpsGetRangeSuccess(t *testing.T, fromStart bool) {\n\tmockCtrl, config, ctx := mdOpsInit(t)\n\tdefer mdOpsShutdown(mockCtrl, config)\n\n\trmdses, extras := makeRMDSRange(t, config, 100, 5, fakeMdID(1))\n\n\tstart := MetadataRevision(100)\n\tstop := start + MetadataRevision(len(rmdses))\n\tif fromStart {\n\t\tstart = 0\n\t}\n\n\tfor _, rmds := range rmdses {\n\t\tverifyMDForPrivate(config, rmds)\n\t}\n\n\tconfig.mockMdserv.EXPECT().GetRange(ctx, rmdses[0].MD.TlfID(), NullBranchID, Merged, start,\n\t\tstop).Return(rmdses, nil)\n\tfor _, e := range extras {\n\t\texpectGetKeyBundles(ctx, config, e)\n\t}\n\n\t// Do this first since rmdses is consumed.\n\texpectedMDs := make([]BareRootMetadata, len(rmdses))\n\tfor i, rmds := range rmdses {\n\t\texpectedMDs[i] = rmds.MD\n\t}\n\trmds, err := config.MDOps().GetRange(ctx, rmdses[0].MD.TlfID(), start, stop)\n\trequire.NoError(t, err)\n\trequire.Equal(t, len(rmdses), len(rmds))\n\tfor i := 0; i < len(rmdses); i++ {\n\t\trequire.Equal(t, expectedMDs[i], rmds[i].bareMd)\n\t}\n}\n\nfunc TestMDOpsGetRangeSuccess(t *testing.T) {\n\ttestMDOpsGetRangeSuccess(t, false)\n}\n\nfunc TestMDOpsGetRangeFromStartSuccess(t *testing.T) {\n\ttestMDOpsGetRangeSuccess(t, true)\n}\n\nfunc TestMDOpsGetRangeFailBadPrevRoot(t *testing.T) {\n\tmockCtrl, config, ctx := mdOpsInit(t)\n\tdefer mdOpsShutdown(mockCtrl, config)\n\n\trmdses, extras := makeRMDSRange(t, config, 100, 5, fakeMdID(1))\n\n\trmdses[2].MD.(MutableBareRootMetadata).SetPrevRoot(fakeMdID(1))\n\n\tstart := MetadataRevision(100)\n\tstop := start + MetadataRevision(len(rmdses))\n\n\t// Verification is parallelized, so we have to expect at most one\n\t// verification for each rmds.\n\tfor _, rmds := range rmdses {\n\t\tverifyMDForPrivateHelper(config, rmds, 0, 1)\n\t}\n\n\tconfig.mockMdserv.EXPECT().GetRange(ctx, rmdses[0].MD.TlfID(), NullBranchID, Merged, start,\n\t\tstop).Return(rmdses, nil)\n\tfor _, e := range extras {\n\t\texpectGetKeyBundles(ctx, config, e)\n\t}\n\n\t_, err := config.MDOps().GetRange(ctx, rmdses[0].MD.TlfID(), start, stop)\n\trequire.IsType(t, MDMismatchError{}, err)\n}\n\ntype fakeMDServerPut struct {\n\tMDServer\n\n\tlastRmdsLock sync.Mutex\n\tlastRmds     *RootMetadataSigned\n}\n\nfunc (s *fakeMDServerPut) Put(ctx context.Context, rmds *RootMetadataSigned,\n\t_ ExtraMetadata) error {\n\ts.lastRmdsLock.Lock()\n\tdefer s.lastRmdsLock.Unlock()\n\ts.lastRmds = rmds\n\treturn nil\n}\n\nfunc (s *fakeMDServerPut) getLastRmds() *RootMetadataSigned {\n\ts.lastRmdsLock.Lock()\n\tdefer s.lastRmdsLock.Unlock()\n\treturn s.lastRmds\n}\n\nfunc (s *fakeMDServerPut) Shutdown() {}\n\nfunc validatePutPublicRMDS(\n\tctx context.Context, t *testing.T, config Config,\n\tinputRmd BareRootMetadata, rmds *RootMetadataSigned) {\n\t// TODO: Handle private RMDS, too.\n\n\t// Verify LastModifying* fields.\n\t_, me, err := config.KBPKI().GetCurrentUserInfo(ctx)\n\trequire.NoError(t, err)\n\trequire.Equal(t, me, rmds.MD.LastModifyingWriter())\n\trequire.Equal(t, me, rmds.MD.GetLastModifyingUser())\n\n\t// Verify signature of WriterMetadata.\n\tbuf, err := rmds.MD.GetSerializedWriterMetadata(config.Codec())\n\trequire.NoError(t, err)\n\terr = config.Crypto().Verify(buf, rmds.GetWriterMetadataSigInfo())\n\trequire.NoError(t, err)\n\n\t// Verify encoded PrivateMetadata.\n\tvar data PrivateMetadata\n\terr = config.Codec().Decode(rmds.MD.GetSerializedPrivateMetadata(), &data)\n\trequire.NoError(t, err)\n\n\t// Verify signature of RootMetadata.\n\tbuf, err = config.Codec().Encode(rmds.MD)\n\trequire.NoError(t, err)\n\terr = config.Crypto().Verify(buf, rmds.SigInfo)\n\trequire.NoError(t, err)\n\n\t// MDv3 TODO: This should become a BareRootMetadataV3.\n\tvar expectedRmd BareRootMetadataV2\n\terr = kbfscodec.Update(config.Codec(), &expectedRmd, inputRmd)\n\trequire.NoError(t, err)\n\n\t// Overwrite written fields.\n\texpectedRmd.SetLastModifyingWriter(rmds.MD.LastModifyingWriter())\n\texpectedRmd.SetLastModifyingUser(rmds.MD.GetLastModifyingUser())\n\texpectedRmd.WriterMetadataSigInfo = rmds.MD.(*BareRootMetadataV2).WriterMetadataSigInfo\n\texpectedRmd.SetSerializedPrivateMetadata(rmds.MD.GetSerializedPrivateMetadata())\n\n\trequire.Equal(t, &expectedRmd, rmds.MD)\n}\n\nfunc TestMDOpsPutPublicSuccess(t *testing.T) {\n\tconfig := MakeTestConfigOrBust(t, \"alice\", \"bob\")\n\tdefer CheckConfigAndShutdown(t, config)\n\n\tconfig.MDServer().Shutdown()\n\tvar mdServer fakeMDServerPut\n\tconfig.SetMDServer(&mdServer)\n\n\tid := tlf.FakeID(1, true)\n\th := parseTlfHandleOrBust(t, config, \"alice,bob\", true)\n\n\trmd, err := makeInitialRootMetadata(config.MetadataVersion(), id, h)\n\trequire.NoError(t, err)\n\trmd.data = makeFakePrivateMetadataFuture(t).toCurrent()\n\trmd.tlfHandle = h\n\n\tctx := context.Background()\n\t_, err = config.MDOps().Put(ctx, rmd)\n\n\trmds := mdServer.getLastRmds()\n\tvalidatePutPublicRMDS(ctx, t, config, rmd.bareMd, rmds)\n}\n\nfunc TestMDOpsPutPrivateSuccess(t *testing.T) {\n\tmockCtrl, config, ctx := mdOpsInit(t)\n\tdefer mdOpsShutdown(mockCtrl, config)\n\n\tconfig.SetCodec(kbfscodec.NewMsgpack())\n\n\tid := tlf.FakeID(1, false)\n\th := parseTlfHandleOrBust(t, config, \"alice,bob\", false)\n\trmd, err := makeInitialRootMetadata(defaultClientMetadataVer, id, h)\n\trequire.NoError(t, err)\n\taddFakeRMDData(t, config.Codec(), config.Crypto(), rmd, h)\n\n\tputMDForPrivate(config, rmd)\n\n\tif _, err := config.MDOps().Put(ctx, rmd); err != nil {\n\t\tt.Errorf(\"Got error on put: %v\", err)\n\t}\n}\n\ntype failEncodeCodec struct {\n\tkbfscodec.Codec\n\terr error\n}\n\nfunc (c failEncodeCodec) Encode(obj interface{}) ([]byte, error) {\n\treturn nil, c.err\n}\n\nfunc TestMDOpsPutFailEncode(t *testing.T) {\n\tmockCtrl, config, ctx := mdOpsInit(t)\n\tdefer mdOpsShutdown(mockCtrl, config)\n\n\tid := tlf.FakeID(1, false)\n\th := parseTlfHandleOrBust(t, config, \"alice,bob\", false)\n\trmd, err := makeInitialRootMetadata(config.MetadataVersion(), id, h)\n\trequire.NoError(t, err)\n\n\texpectGetTLFCryptKeyForEncryption(config, rmd)\n\tconfig.mockCrypto.EXPECT().EncryptPrivateMetadata(\n\t\trmd.data, kbfscrypto.TLFCryptKey{}).Return(\n\t\tEncryptedPrivateMetadata{}, nil)\n\tconfig.mockBsplit.EXPECT().ShouldEmbedBlockChanges(gomock.Any()).\n\t\tReturn(true)\n\n\terr = errors.New(\"Fake fail\")\n\tconfig.SetCodec(failEncodeCodec{config.Codec(), err})\n\n\tif _, err2 := config.MDOps().Put(ctx, rmd); err2 != err {\n\t\tt.Errorf(\"Got bad error on put: %v\", err2)\n\t}\n}\n\nfunc TestMDOpsGetRangeFailFinal(t *testing.T) {\n\tmockCtrl, config, ctx := mdOpsInit(t)\n\tdefer mdOpsShutdown(mockCtrl, config)\n\n\trmdses, extras := makeRMDSRange(t, config, 100, 5, fakeMdID(1))\n\trmdses[2].MD.(MutableBareRootMetadata).SetFinalBit()\n\trmdses[2].MD.(MutableBareRootMetadata).SetPrevRoot(rmdses[1].MD.GetPrevRoot())\n\n\tstart := MetadataRevision(100)\n\tstop := start + MetadataRevision(len(rmdses))\n\n\t// Verification is parallelized, so we have to expect at most one\n\t// verification for each rmds.\n\tfor _, rmds := range rmdses {\n\t\tverifyMDForPrivateHelper(config, rmds, 0, 1)\n\t}\n\n\tconfig.mockMdserv.EXPECT().GetRange(\n\t\tctx, rmdses[0].MD.TlfID(), NullBranchID, Merged, start, stop).Return(\n\t\trmdses, nil)\n\tfor _, e := range extras {\n\t\texpectGetKeyBundles(ctx, config, e)\n\t}\n\t_, err := config.MDOps().GetRange(ctx, rmdses[0].MD.TlfID(), start, stop)\n\trequire.IsType(t, MDMismatchError{}, err)\n}\n", "idx": 19, "id": 14826, "msg": "", "proj": "keybase-kbfs", "lang": "go"}
{"patch": "@@ -400,7 +400,7 @@ class StackChangeSet(Stack):\n \n def create_stack(req_params):\n     state = CloudFormationRegion.get()\n-    template_deployer.prepare_template_body(req_params)\n+    template_deployer.prepare_template_body(req_params)  # TODO: avoid mutating req_params directly\n     template = template_preparer.parse_template(req_params[\"TemplateBody\"])\n     stack_name = template[\"StackName\"] = req_params.get(\"StackName\")\n     stack = Stack(req_params, template)", "y": 0, "oldf": "import json\nimport logging\nimport traceback\n\nimport xmltodict\nfrom flask import Flask, request\nfrom requests.models import Response\n\nfrom localstack.services.generic_proxy import RegionBackend\nfrom localstack.utils.aws import aws_responses, aws_stack\nfrom localstack.utils.aws.aws_responses import (\n    extract_url_encoded_param_list,\n    flask_error_response_xml,\n    requests_response_xml,\n    requests_to_flask_response,\n)\nfrom localstack.utils.cloudformation import template_deployer, template_preparer\nfrom localstack.utils.common import (\n    clone,\n    clone_safe,\n    long_uid,\n    parse_request_data,\n    recurse_object,\n    select_attributes,\n    short_uid,\n    timestamp_millis,\n)\n\nAPP_NAME = \"cloudformation_api\"\napp = Flask(APP_NAME)\n\nLOG = logging.getLogger(__name__)\n\nXMLNS_CF = \"http://cloudformation.amazonaws.com/doc/2010-05-15/\"\n\n\nclass CloudFormationRegion(RegionBackend):\n    def __init__(self):\n        # maps stack ID to stack details\n        self.stacks = {}\n        # maps stack set ID to stack set details\n        self.stack_sets = {}\n\n    @property\n    def exports(self):\n        exports = []\n        output_keys = {}\n        for stack_id, stack in self.stacks.items():\n            for output in stack.outputs:\n                export_name = output.get(\"ExportName\")\n                if not export_name:\n                    continue\n                if export_name in output_keys:\n                    # TODO: raise exception on stack creation in case of duplicate exports\n                    LOG.warning(\n                        \"Found duplicate export name %s in stacks: %s %s\"\n                        % (export_name, output_keys[export_name], stack.stack_id)\n                    )\n                entry = {\n                    \"ExportingStackId\": stack.stack_id,\n                    \"Name\": export_name,\n                    \"Value\": output[\"OutputValue\"],\n                }\n                exports.append(entry)\n                output_keys[export_name] = stack.stack_id\n        return exports\n\n\nclass StackSet(object):\n    \"\"\"A stack set contains multiple stack instances.\"\"\"\n\n    def __init__(self, metadata={}):\n        self.metadata = metadata\n        # list of stack instances\n        self.stack_instances = []\n        # maps operation ID to stack set operation details\n        self.operations = {}\n\n    @property\n    def stack_set_name(self):\n        return self.metadata.get(\"StackSetName\")\n\n\nclass StackInstance(object):\n    \"\"\"A stack instance belongs to a stack set and is specific to a region / account ID.\"\"\"\n\n    def __init__(self, metadata={}):\n        self.metadata = metadata\n        # reference to the deployed stack belonging to this stack instance\n        self.stack = None\n\n\nclass Stack(object):\n    def __init__(self, metadata=None, template={}):\n        self.metadata = metadata or {}\n        self.template = template or {}\n        self._template_raw = clone_safe(self.template)\n        self.template_original = clone_safe(self.template)\n        # initialize resources\n        for resource_id, resource in self.template_resources.items():\n            resource[\"LogicalResourceId\"] = self.template_original[\"Resources\"][resource_id][\n                \"LogicalResourceId\"\n            ] = (resource.get(\"LogicalResourceId\") or resource_id)\n        # initialize stack template attributes\n        self.template[\"StackId\"] = self.metadata[\"StackId\"] = self.metadata.get(\n            \"StackId\"\n        ) or aws_stack.cloudformation_stack_arn(self.stack_name, short_uid())\n        self.template[\"Parameters\"] = self.template.get(\"Parameters\") or {}\n        self.template[\"Outputs\"] = self.template.get(\"Outputs\") or {}\n        # initialize metadata\n        self.metadata[\"Parameters\"] = self.metadata.get(\"Parameters\") or []\n        self.metadata[\"StackStatus\"] = \"CREATE_IN_PROGRESS\"\n        self.metadata[\"CreationTime\"] = self.metadata.get(\"CreationTime\") or timestamp_millis()\n        # maps resource id to resource state\n        self.resource_states = {}\n        # maps resource id to moto resource class instance (TODO: remove in the future)\n        self.moto_resource_statuses = {}\n        # list of stack events\n        self.events = []\n        # list of stack change sets\n        self.change_sets = []\n        # initialize parameters\n        for i in range(1, 100):\n            key = \"Parameters.member.%s.ParameterKey\" % i\n            value = \"Parameters.member.%s.ParameterValue\" % i\n            key = self.metadata.get(key)\n            value = self.metadata.get(value)\n            if not key:\n                break\n            self.metadata[\"Parameters\"].append({\"ParameterKey\": key, \"ParameterValue\": value})\n\n    def describe_details(self):\n        attrs = [\n            \"StackId\",\n            \"StackName\",\n            \"Description\",\n            \"StackStatusReason\",\n            \"StackStatus\",\n            \"Capabilities\",\n            \"ParentId\",\n            \"RootId\",\n            \"RoleARN\",\n            \"CreationTime\",\n            \"DeletionTime\",\n            \"LastUpdatedTime\",\n            \"ChangeSetId\",\n        ]\n        result = select_attributes(self.metadata, attrs)\n        result[\"Tags\"] = self.tags\n        result[\"Outputs\"] = self.outputs\n        result[\"Parameters\"] = self.stack_parameters()\n        for attr in [\"Capabilities\", \"Tags\", \"Outputs\", \"Parameters\"]:\n            result[attr] = result.get(attr, [])\n        return result\n\n    def set_stack_status(self, status):\n        self.metadata[\"StackStatus\"] = status\n        self.metadata[\"StackStatusReason\"] = \"Deployment %s\" % (\n            \"failed\" if \"FAILED\" in status else \"succeeded\"\n        )\n        self.add_stack_event(self.stack_name, self.stack_id, status)\n\n    def add_stack_event(self, resource_id, physical_res_id, status):\n        event = {\n            \"EventId\": long_uid(),\n            \"Timestamp\": timestamp_millis(),\n            \"StackId\": self.stack_id,\n            \"StackName\": self.stack_name,\n            \"LogicalResourceId\": resource_id,\n            \"PhysicalResourceId\": physical_res_id,\n            \"ResourceStatus\": status,\n            \"ResourceType\": \"AWS::CloudFormation::Stack\",\n        }\n        self.events.insert(0, event)\n\n    def set_resource_status(self, resource_id, status, physical_res_id=None):\n        resource = self.resources[resource_id]\n        state = self.resource_states[resource_id] = self.resource_states.get(resource_id) or {}\n        attr_defaults = (\n            (\"LogicalResourceId\", resource_id),\n            (\"PhysicalResourceId\", physical_res_id),\n        )\n        for res in [resource, state]:\n            for attr, default in attr_defaults:\n                res[attr] = res.get(attr) or default\n        state[\"PreviousResourceStatus\"] = state.get(\"ResourceStatus\")\n        state[\"ResourceStatus\"] = status\n        state[\"StackName\"] = state.get(\"StackName\") or self.stack_name\n        state[\"StackId\"] = state.get(\"StackId\") or self.stack_id\n        state[\"ResourceType\"] = state.get(\"ResourceType\") or self.resources[resource_id].get(\"Type\")\n        state[\"LastUpdatedTimestamp\"] = timestamp_millis()\n        self.add_stack_event(resource_id, physical_res_id, status)\n\n    def resource_status(self, resource_id):\n        result = self._lookup(self.resource_states, resource_id)\n        return result\n\n    @property\n    def stack_name(self):\n        return self.metadata[\"StackName\"]\n\n    @property\n    def stack_id(self):\n        return self.metadata[\"StackId\"]\n\n    @property\n    def resources(self):\n        \"\"\"Return dict of resources, parameters, conditions, and other stack metadata.\"\"\"\n\n        def add_params(defaults=True):\n            for param in self.stack_parameters(defaults=defaults):\n                if param[\"ParameterKey\"] not in result:\n                    props = {\"Value\": param[\"ParameterValue\"]}\n                    result[param[\"ParameterKey\"]] = {\n                        \"Type\": \"Parameter\",\n                        \"LogicalResourceId\": param[\"ParameterKey\"],\n                        \"Properties\": props,\n                    }\n\n        result = dict(self.template_resources)\n\n        add_params(defaults=False)\n\n        for name, value in self.conditions.items():\n            if name not in result:\n                result[name] = {\n                    \"Type\": \"Parameter\",\n                    \"LogicalResourceId\": name,\n                    \"Properties\": {\"Value\": value},\n                }\n        for name, value in self.mappings.items():\n            if name not in result:\n                result[name] = {\n                    \"Type\": \"Parameter\",\n                    \"LogicalResourceId\": name,\n                    \"Properties\": {\"Value\": value},\n                }\n\n        add_params(defaults=True)\n\n        return result\n\n    @property\n    def template_resources(self):\n        return self.template[\"Resources\"]\n\n    @property\n    def tags(self):\n        return aws_responses.extract_tags(self.metadata)\n\n    @property\n    def imports(self):\n        def _collect(o, **kwargs):\n            if isinstance(o, dict):\n                import_val = o.get(\"Fn::ImportValue\")\n                if import_val:\n                    result.add(import_val)\n            return o\n\n        result = set()\n        recurse_object(self.resources, _collect)\n        return result\n\n    @property\n    def outputs(self):\n        result = []\n        # first, fetch the outputs of nested child stacks\n        for stack in self.nested_stacks:\n            result.extend(stack.outputs)\n        # now, fetch the outputs of this stack\n        for k, details in self.template.get(\"Outputs\", {}).items():\n            value = None\n            try:\n                template_deployer.resolve_refs_recursively(self.stack_name, details, self.resources)\n                value = details[\"Value\"]\n            except Exception as e:\n                LOG.debug(\"Unable to resolve references in stack outputs: %s - %s\" % (details, e))\n            exports = details.get(\"Export\") or {}\n            export = exports.get(\"Name\")\n            export = template_deployer.resolve_refs_recursively(\n                self.stack_name, export, self.resources\n            )\n            description = details.get(\"Description\")\n            entry = {\n                \"OutputKey\": k,\n                \"OutputValue\": value,\n                \"Description\": description,\n                \"ExportName\": export,\n            }\n            result.append(entry)\n        return result\n\n    def stack_parameters(self, defaults=True):\n        result = {}\n        # add default template parameter values\n        if defaults:\n            for key, value in self.template_parameters.items():\n                result[key] = {\n                    \"ParameterKey\": key,\n                    \"ParameterValue\": value.get(\"Default\"),\n                }\n        # add stack parameters\n        result.update({p[\"ParameterKey\"]: p for p in self.metadata[\"Parameters\"]})\n        # add parameters of change sets\n        for change_set in self.change_sets:\n            result.update({p[\"ParameterKey\"]: p for p in change_set.metadata[\"Parameters\"]})\n        result = list(result.values())\n        return result\n\n    @property\n    def template_parameters(self):\n        return self.template[\"Parameters\"]\n\n    @property\n    def conditions(self):\n        return self.template.get(\"Conditions\", {})\n\n    @property\n    def mappings(self):\n        return self.template.get(\"Mappings\", {})\n\n    @property\n    def exports_map(self):\n        result = {}\n        for export in CloudFormationRegion.get().exports:\n            result[export[\"Name\"]] = export\n        return result\n\n    @property\n    def nested_stacks(self):\n        \"\"\"Return a list of nested stacks that have been deployed by this stack.\"\"\"\n        result = [\n            r for r in self.template_resources.values() if r[\"Type\"] == \"AWS::CloudFormation::Stack\"\n        ]\n        result = [find_stack(r[\"Properties\"].get(\"StackName\")) for r in result]\n        result = [r for r in result if r]\n        return result\n\n    @property\n    def status(self):\n        return self.metadata[\"StackStatus\"]\n\n    @property\n    def resource_types(self):\n        return [r.get(\"Type\") for r in self.template_resources.values()]\n\n    def resource(self, resource_id):\n        return self._lookup(self.resources, resource_id)\n\n    def _lookup(self, resource_map, resource_id):\n        resource = resource_map.get(resource_id)\n        if not resource:\n            raise Exception(\n                'Unable to find details for resource \"%s\" in stack \"%s\"'\n                % (resource_id, self.stack_name)\n            )\n        return resource\n\n    def copy(self):\n        return Stack(metadata=dict(self.metadata), template=dict(self.template))\n\n\nclass StackChangeSet(Stack):\n    def __init__(self, params={}, template={}):\n        super(StackChangeSet, self).__init__(params, template)\n        name = self.metadata[\"ChangeSetName\"]\n        if not self.metadata.get(\"ChangeSetId\"):\n            self.metadata[\"ChangeSetId\"] = aws_stack.cf_change_set_arn(\n                name, change_set_id=short_uid()\n            )\n\n        stack = self.stack = find_stack(self.metadata[\"StackName\"])\n        self.metadata[\"StackId\"] = stack.stack_id\n        self.metadata[\"Status\"] = \"CREATE_PENDING\"\n\n    @property\n    def change_set_id(self):\n        return self.metadata[\"ChangeSetId\"]\n\n    @property\n    def change_set_name(self):\n        return self.metadata[\"ChangeSetName\"]\n\n    @property\n    def resources(self):\n        result = dict(self.stack.resources)\n        result.update(self.resources)\n        return result\n\n    @property\n    def changes(self):\n        result = self.metadata[\"Changes\"] = self.metadata.get(\"Changes\", [])\n        return result\n\n\n# --------------\n# API ENDPOINTS\n# --------------\n\n\ndef create_stack(req_params):\n    state = CloudFormationRegion.get()\n    template_deployer.prepare_template_body(req_params)\n    template = template_preparer.parse_template(req_params[\"TemplateBody\"])\n    stack_name = template[\"StackName\"] = req_params.get(\"StackName\")\n    stack = Stack(req_params, template)\n\n    # find existing stack with same name, and remove it if this stack is in DELETED state\n    existing = ([s for s in state.stacks.values() if s.stack_name == stack_name] or [None])[0]\n    if existing:\n        if \"DELETE\" not in existing.status:\n            return error_response(\n                'Stack named \"%s\" already exists with status \"%s\"' % (stack_name, existing.status),\n                code=400,\n                code_string=\"ValidationError\",\n            )\n        state.stacks.pop(existing.stack_id)\n\n    state.stacks[stack.stack_id] = stack\n    LOG.debug(\n        'Creating stack \"%s\" with %s resources ...'\n        % (stack.stack_name, len(stack.template_resources))\n    )\n    deployer = template_deployer.TemplateDeployer(stack)\n    try:\n        deployer.deploy_stack()\n    except Exception as e:\n        stack.set_stack_status(\"CREATE_FAILED\")\n        msg = 'Unable to create stack \"%s\": %s' % (stack.stack_name, e)\n        LOG.debug(\"%s %s\" % (msg, traceback.format_exc()))\n        return error_response(msg, code=400, code_string=\"ValidationError\")\n    result = {\"StackId\": stack.stack_id}\n    return result\n\n\ndef create_stack_set(req_params):\n    state = CloudFormationRegion.get()\n    stack_set = StackSet(req_params)\n    stack_set_id = short_uid()\n    stack_set.metadata[\"StackSetId\"] = stack_set_id\n    state.stack_sets[stack_set_id] = stack_set\n    result = {\"StackSetId\": stack_set_id}\n    return result\n\n\ndef create_stack_instances(req_params):\n    state = CloudFormationRegion.get()\n    set_name = req_params.get(\"StackSetName\")\n    stack_set = [sset for sset in state.stack_sets.values() if sset.stack_set_name == set_name]\n    if not stack_set:\n        return not_found_error('Stack set named \"%s\" does not exist' % set_name)\n    stack_set = stack_set[0]\n    op_id = req_params.get(\"OperationId\") or short_uid()\n    sset_meta = stack_set.metadata\n    accounts = extract_url_encoded_param_list(req_params, \"Accounts.member.%s\")\n    accounts = accounts or extract_url_encoded_param_list(\n        req_params, \"DeploymentTargets.Accounts.member.%s\"\n    )\n    regions = extract_url_encoded_param_list(req_params, \"Regions.member.%s\")\n    stacks_to_await = []\n    for account in accounts:\n        for region in regions:\n            # deploy new stack\n            LOG.debug('Deploying instance for stack set \"%s\" in region \"%s\"' % (set_name, region))\n            cf_client = aws_stack.connect_to_service(\"cloudformation\", region_name=region)\n            kwargs = select_attributes(sset_meta, \"TemplateBody\") or select_attributes(\n                sset_meta, \"TemplateURL\"\n            )\n            stack_name = \"sset-%s-%s\" % (set_name, account)\n            result = cf_client.create_stack(StackName=stack_name, **kwargs)\n            stacks_to_await.append((stack_name, region))\n            # store stack instance\n            instance = {\n                \"StackSetId\": sset_meta[\"StackSetId\"],\n                \"OperationId\": op_id,\n                \"Account\": account,\n                \"Region\": region,\n                \"StackId\": result[\"StackId\"],\n                \"Status\": \"CURRENT\",\n                \"StackInstanceStatus\": {\"DetailedStatus\": \"SUCCEEDED\"},\n            }\n            instance = StackInstance(instance)\n            stack_set.stack_instances.append(instance)\n    # wait for completion of stack\n    for stack in stacks_to_await:\n        aws_stack.await_stack_completion(stack[0], region_name=stack[1])\n    # record operation\n    operation = {\n        \"OperationId\": op_id,\n        \"StackSetId\": stack_set.metadata[\"StackSetId\"],\n        \"Action\": \"CREATE\",\n        \"Status\": \"SUCCEEDED\",\n    }\n    stack_set.operations[op_id] = operation\n    result = {\"OperationId\": op_id}\n    return result\n\n\ndef delete_stack(req_params):\n    stack_name = req_params.get(\"StackName\")\n    stack = find_stack(stack_name)\n    deployer = template_deployer.TemplateDeployer(stack)\n    deployer.delete_stack()\n    return {}\n\n\ndef delete_stack_set(req_params):\n    state = CloudFormationRegion.get()\n    set_name = req_params.get(\"StackSetName\")\n    stack_set = [sset for sset in state.stack_sets.values() if sset.stack_set_name == set_name]\n    if not stack_set:\n        return not_found_error('Stack set named \"%s\" does not exist' % set_name)\n    for instance in stack_set[0].stack_instances:\n        deployer = template_deployer.TemplateDeployer(instance.stack)\n        deployer.delete_stack()\n    return {}\n\n\ndef update_stack(req_params):\n    stack_name = req_params.get(\"StackName\")\n    stack = find_stack(stack_name)\n    if not stack:\n        return not_found_error('Unable to update non-existing stack \"%s\"' % stack_name)\n    template_preparer.prepare_template_body(req_params)\n    template = template_preparer.parse_template(req_params[\"TemplateBody\"])\n    new_stack = Stack(req_params, template)\n    deployer = template_deployer.TemplateDeployer(stack)\n    try:\n        deployer.update_stack(new_stack)\n    except Exception as e:\n        stack.set_stack_status(\"UPDATE_FAILED\")\n        msg = 'Unable to update stack \"%s\": %s' % (stack_name, e)\n        LOG.debug(\"%s %s\" % (msg, traceback.format_exc()))\n        return error_response(msg, code=400, code_string=\"ValidationError\")\n    result = {\"StackId\": stack.stack_id}\n    return result\n\n\ndef update_stack_set(req_params):\n    state = CloudFormationRegion.get()\n    set_name = req_params.get(\"StackSetName\")\n    stack_set = [sset for sset in state.stack_sets.values() if sset.stack_set_name == set_name]\n    if not stack_set:\n        return not_found_error('Stack set named \"%s\" does not exist' % set_name)\n    stack_set = stack_set[0]\n    stack_set.metadata.update(req_params)\n    op_id = req_params.get(\"OperationId\") or short_uid()\n    operation = {\n        \"OperationId\": op_id,\n        \"StackSetId\": stack_set.metadata[\"StackSetId\"],\n        \"Action\": \"UPDATE\",\n        \"Status\": \"SUCCEEDED\",\n    }\n    stack_set.operations[op_id] = operation\n    return {\"OperationId\": op_id}\n\n\ndef describe_stacks(req_params):\n    state = CloudFormationRegion.get()\n    stack_name = req_params.get(\"StackName\")\n    stack_list = list(state.stacks.values())\n    stacks = [\n        s.describe_details() for s in stack_list if stack_name in [None, s.stack_name, s.stack_id]\n    ]\n    if stack_name and not stacks:\n        return error_response(\n            \"Stack with id %s does not exist\" % stack_name,\n            code=400,\n            code_string=\"ValidationError\",\n        )\n    result = {\"Stacks\": stacks}\n    return result\n\n\ndef list_stacks(req_params):\n    state = CloudFormationRegion.get()\n\n    stack_status_filters = _get_status_filter_members(req_params)\n\n    stacks = [\n        s.describe_details()\n        for s in state.stacks.values()\n        if not stack_status_filters or s.status in stack_status_filters\n    ]\n\n    attrs = [\n        \"StackId\",\n        \"StackName\",\n        \"TemplateDescription\",\n        \"CreationTime\",\n        \"LastUpdatedTime\",\n        \"DeletionTime\",\n        \"StackStatus\",\n        \"StackStatusReason\",\n        \"ParentId\",\n        \"RootId\",\n        \"DriftInformation\",\n    ]\n    stacks = [select_attributes(stack, attrs) for stack in stacks]\n    result = {\"StackSummaries\": stacks}\n    return result\n\n\ndef describe_stack_resource(req_params):\n    stack_name = req_params.get(\"StackName\")\n    resource_id = req_params.get(\"LogicalResourceId\")\n    stack = find_stack(stack_name)\n    if not stack:\n        return stack_not_found_error(stack_name)\n    details = stack.resource_status(resource_id)\n    result = {\"StackResourceDetail\": details}\n    return result\n\n\ndef describe_stack_resources(req_params):\n    stack_name = req_params.get(\"StackName\")\n    resource_id = req_params.get(\"LogicalResourceId\")\n    phys_resource_id = req_params.get(\"PhysicalResourceId\")\n    if phys_resource_id and stack_name:\n        return error_response(\"Cannot specify both StackName and PhysicalResourceId\", code=400)\n    # TODO: filter stack by PhysicalResourceId!\n    stack = find_stack(stack_name)\n    if not stack:\n        return stack_not_found_error(stack_name)\n    statuses = [\n        stack.resource_status(res_id)\n        for res_id, _ in stack.resource_states.items()\n        if resource_id in [res_id, None]\n    ]\n    return {\"StackResources\": statuses}\n\n\ndef list_stack_resources(req_params):\n    result = describe_stack_resources(req_params)\n    if not isinstance(result, dict):\n        return result\n    result = {\"StackResourceSummaries\": result.pop(\"StackResources\")}\n    return result\n\n\ndef list_stack_instances(req_params):\n    state = CloudFormationRegion.get()\n    set_name = req_params.get(\"StackSetName\")\n    stack_set = [sset for sset in state.stack_sets.values() if sset.stack_set_name == set_name]\n    if not stack_set:\n        return not_found_error('Stack set named \"%s\" does not exist' % set_name)\n    stack_set = stack_set[0]\n    result = [inst.metadata for inst in stack_set.stack_instances]\n    result = {\"Summaries\": result}\n    return result\n\n\ndef create_change_set(req_params):\n    stack_name = req_params.get(\"StackName\")\n    template_deployer.prepare_template_body(req_params)\n    template = template_preparer.parse_template(req_params.pop(\"TemplateBody\"))\n    template[\"StackName\"] = stack_name\n    template[\"ChangeSetName\"] = req_params.get(\"ChangeSetName\")\n    stack = existing = find_stack(stack_name)\n    if not existing:\n        # automatically create (empty) stack if none exists yet\n        state = CloudFormationRegion.get()\n        empty_stack_template = dict(template)\n        empty_stack_template[\"Resources\"] = {}\n        req_params_copy = clone_stack_params(req_params)\n        stack = Stack(req_params_copy, empty_stack_template)\n        state.stacks[stack.stack_id] = stack\n        stack.set_stack_status(\"CREATE_COMPLETE\")\n    change_set = StackChangeSet(req_params, template)\n    deployer = template_deployer.TemplateDeployer(stack)\n    deployer.construct_changes(\n        stack,\n        change_set,\n        change_set_id=change_set.change_set_id,\n        append_to_changeset=True,\n    )\n    stack.change_sets.append(change_set)\n    change_set.metadata[\"Status\"] = \"CREATE_COMPLETE\"\n    change_set.metadata[\"ExecutionStatus\"] = \"AVAILABLE\"\n    change_set.metadata[\"StatusReason\"] = \"Changeset created\"\n    return {\"StackId\": change_set.stack_id, \"Id\": change_set.change_set_id}\n\n\ndef execute_change_set(req_params):\n    stack_name = req_params.get(\"StackName\")\n    cs_name = req_params.get(\"ChangeSetName\")\n    change_set = find_change_set(cs_name, stack_name=stack_name)\n    if not change_set:\n        return not_found_error(\n            'Unable to find change set \"%s\" for stack \"%s\"' % (cs_name, stack_name)\n        )\n    LOG.debug(\n        'Executing change set \"%s\" for stack \"%s\" with %s resources ...'\n        % (cs_name, stack_name, len(change_set.template_resources))\n    )\n    deployer = template_deployer.TemplateDeployer(change_set.stack)\n    deployer.apply_change_set(change_set)\n    change_set.stack.metadata[\"ChangeSetId\"] = change_set.change_set_id\n    return {}\n\n\ndef list_change_sets(req_params):\n    stack_name = req_params.get(\"StackName\")\n    stack = find_stack(stack_name)\n    if not stack:\n        return not_found_error('Unable to find stack \"%s\"' % stack_name)\n    result = [cs.metadata for cs in stack.change_sets]\n    result = {\"Summaries\": result}\n    return result\n\n\ndef list_stack_sets(req_params):\n    state = CloudFormationRegion.get()\n    result = [sset.metadata for sset in state.stack_sets.values()]\n    result = {\"Summaries\": result}\n    return result\n\n\ndef describe_change_set(req_params):\n    stack_name = req_params.get(\"StackName\")\n    cs_name = req_params.get(\"ChangeSetName\")\n    change_set = find_change_set(cs_name, stack_name=stack_name)\n    if not change_set:\n        return not_found_error(\n            'Unable to find change set \"%s\" for stack \"%s\"' % (cs_name, stack_name)\n        )\n    return change_set.metadata\n\n\ndef describe_stack_set(req_params):\n    state = CloudFormationRegion.get()\n    set_name = req_params.get(\"StackSetName\")\n    result = [\n        sset.metadata for sset in state.stack_sets.values() if sset.stack_set_name == set_name\n    ]\n    if not result:\n        return not_found_error('Unable to find stack set \"%s\"' % set_name)\n    result = {\"StackSet\": result[0]}\n    return result\n\n\ndef describe_stack_set_operation(req_params):\n    state = CloudFormationRegion.get()\n    set_name = req_params.get(\"StackSetName\")\n    stack_set = [sset for sset in state.stack_sets.values() if sset.stack_set_name == set_name]\n    if not stack_set:\n        return not_found_error('Unable to find stack set \"%s\"' % set_name)\n    stack_set = stack_set[0]\n    op_id = req_params.get(\"OperationId\")\n    result = stack_set.operations.get(op_id)\n    if not result:\n        LOG.debug(\n            'Unable to find operation ID \"%s\" for stack set \"%s\" in list: %s'\n            % (op_id, set_name, list(stack_set.operations.keys()))\n        )\n        return not_found_error(\n            'Unable to find operation ID \"%s\" for stack set \"%s\"' % (op_id, set_name)\n        )\n    result = {\"StackSetOperation\": result}\n    return result\n\n\ndef list_exports(req_params):\n    state = CloudFormationRegion.get()\n    result = {\"Exports\": state.exports}\n    return result\n\n\ndef list_imports(req_params):\n    state = CloudFormationRegion.get()\n    export_name = req_params.get(\"ExportName\")\n    importing_stack_names = []\n    for stack in state.stacks.values():\n        if export_name in stack.imports:\n            importing_stack_names.append(stack.stack_name)\n    result = {\"Imports\": importing_stack_names}\n    return result\n\n\ndef validate_template(req_params):\n    try:\n        result = template_preparer.validate_template(req_params)\n        result = \"<tmp>%s</tmp>\" % result\n        result = xmltodict.parse(result)[\"tmp\"]\n        return result\n    except Exception as err:\n        return error_response(\"Template Validation Error: %s\" % err)\n\n\ndef describe_stack_events(req_params):\n    stack_name = req_params.get(\"StackName\")\n    state = CloudFormationRegion.get()\n    events = []\n    for stack_id, stack in state.stacks.items():\n        if stack_name in [None, stack.stack_name, stack.stack_id]:\n            events.extend(stack.events)\n    return {\"StackEvents\": events}\n\n\ndef delete_change_set(req_params):\n    stack_name = req_params.get(\"StackName\")\n    cs_name = req_params.get(\"ChangeSetName\")\n    change_set = find_change_set(cs_name, stack_name=stack_name)\n    if not change_set:\n        return not_found_error(\n            'Unable to find change set \"%s\" for stack \"%s\"' % (cs_name, stack_name)\n        )\n    change_set.stack.change_sets = [\n        cs for cs in change_set.stack.change_sets if cs.change_set_name != cs_name\n    ]\n    return {}\n\n\ndef get_template(req_params):\n    stack_name = req_params.get(\"StackName\")\n    cs_name = req_params.get(\"ChangeSetName\")\n    stack = find_stack(stack_name)\n    if cs_name:\n        stack = find_change_set(stack_name, cs_name)\n    if not stack:\n        return stack_not_found_error(stack_name)\n    result = {\"TemplateBody\": json.dumps(stack._template_raw)}\n    return result\n\n\ndef get_template_summary(req_params):\n    stack_name = req_params.get(\"StackName\")\n    stack = None\n    if stack_name:\n        stack = find_stack(stack_name)\n        if not stack:\n            return stack_not_found_error(stack_name)\n    else:\n        template_deployer.prepare_template_body(req_params)\n        template = template_preparer.parse_template(req_params[\"TemplateBody\"])\n        req_params[\"StackName\"] = \"tmp-stack\"\n        stack = Stack(req_params, template)\n    result = stack.describe_details()\n    id_summaries = {}\n    for resource_id, resource in stack.template_resources.items():\n        res_type = resource[\"Type\"]\n        id_summaries[res_type] = id_summaries.get(res_type) or []\n        id_summaries[res_type].append(resource_id)\n    result[\"ResourceTypes\"] = list(id_summaries.keys())\n    result[\"ResourceIdentifierSummaries\"] = [\n        {\"ResourceType\": key, \"LogicalResourceIds\": values} for key, values in id_summaries.items()\n    ]\n    return result\n\n\n# -----------------\n# MAIN ENTRY POINT\n# -----------------\n\n\n@app.route(\"/\", methods=[\"POST\"])\ndef handle_request():\n    data = request.get_data()\n    req_params = parse_request_data(request.method, request.path, data)\n    action = req_params.get(\"Action\", \"\")\n\n    func = ENDPOINTS.get(action)\n    if not func:\n        return \"\", 404\n    result = func(req_params)\n\n    result = _response(action, result)\n    return result\n\n\nENDPOINTS = {\n    \"CreateChangeSet\": create_change_set,\n    \"CreateStack\": create_stack,\n    \"CreateStackInstances\": create_stack_instances,\n    \"CreateStackSet\": create_stack_set,\n    \"DeleteChangeSet\": delete_change_set,\n    \"DeleteStack\": delete_stack,\n    \"DeleteStackSet\": delete_stack_set,\n    \"DescribeChangeSet\": describe_change_set,\n    \"DescribeStackEvents\": describe_stack_events,\n    \"DescribeStackResource\": describe_stack_resource,\n    \"DescribeStackResources\": describe_stack_resources,\n    \"DescribeStacks\": describe_stacks,\n    \"DescribeStackSet\": describe_stack_set,\n    \"DescribeStackSetOperation\": describe_stack_set_operation,\n    \"ExecuteChangeSet\": execute_change_set,\n    \"GetTemplate\": get_template,\n    \"GetTemplateSummary\": get_template_summary,\n    \"ListChangeSets\": list_change_sets,\n    \"ListExports\": list_exports,\n    \"ListImports\": list_imports,\n    \"ListStackInstances\": list_stack_instances,\n    \"ListStacks\": list_stacks,\n    \"ListStackResources\": list_stack_resources,\n    \"ListStackSets\": list_stack_sets,\n    \"UpdateStack\": update_stack,\n    \"UpdateStackSet\": update_stack_set,\n    \"ValidateTemplate\": validate_template,\n}\n\n\n# ---------------\n# UTIL FUNCTIONS\n# ---------------\n\n\ndef error_response(*args, **kwargs):\n    kwargs[\"xmlns\"] = kwargs.get(\"xmlns\") or XMLNS_CF\n    return flask_error_response_xml(*args, **kwargs)\n\n\ndef not_found_error(message):\n    return error_response(message, code=404, code_string=\"ResourceNotFoundException\")\n\n\ndef stack_not_found_error(stack_name):\n    return not_found_error('Unable to find stack named \"%s\"' % stack_name)\n\n\ndef clone_stack_params(stack_params):\n    try:\n        return clone(stack_params)\n    except Exception as e:\n        LOG.info(\"Unable to clone stack parameters: %s\" % e)\n        return stack_params\n\n\ndef find_stack(stack_name):\n    state = CloudFormationRegion.get()\n    return (\n        [s for s in state.stacks.values() if stack_name in [s.stack_name, s.stack_id]] or [None]\n    )[0]\n\n\ndef find_change_set(cs_name, stack_name=None):\n    state = CloudFormationRegion.get()\n    stack = find_stack(stack_name)\n    stacks = [stack] if stack else state.stacks.values()\n    result = [\n        cs\n        for s in stacks\n        for cs in s.change_sets\n        if cs_name in [cs.change_set_id, cs.change_set_name]\n    ]\n    return (result or [None])[0]\n\n\ndef _response(action, result):\n    if isinstance(result, (dict, str)):\n        result = requests_response_xml(action, result, xmlns=XMLNS_CF)\n    if isinstance(result, Response):\n        result = requests_to_flask_response(result)\n    return result\n\n\ndef serve(port, quiet=True):\n    from localstack.services import generic_proxy  # moved here to fix circular import errors\n\n    return generic_proxy.serve_flask_app(app=app, port=port)\n\n\ndef _get_status_filter_members(req_params):\n    \"\"\"\n    Creates a set of status from the requests parameters\n\n    The API request params specify two parameters of the endpoint:\n       - NextToken: Token for next page\n       - StackStatusFilter.member.N: Status to use as a filter (it conforms a list)\n\n    StackStatusFilter.member.N abstracts the list of status in the request, and it is sent\n    as different parameters, as the N suggests.\n\n    Docs:\n         https://docs.aws.amazon.com/AWSCloudFormation/latest/APIReference/API_ListStacks.html\n\n    Returns:\n        set: set of status to filter upon\n    \"\"\"\n    return {\n        value for param, value in req_params.items() if param.startswith(\"StackStatusFilter.member\")\n    }\n", "idx": 7, "id": 12930, "msg": "", "proj": "localstack-localstack", "lang": "py"}
{"patch": "@@ -136,17 +136,18 @@ class AutoRowSize extends BasePlugin {\n       return;\n     }\n \n+    this.rowHeightsMap = new ValueMap();\n+    this.rowIndexMapper.registerMap(ROW_WIDTHS_MAP_NAME, this.rowHeightsMap);\n+\n     this.setSamplingOptions();\n \n     this.addHook('afterLoadData', () => this.onAfterLoadData());\n     this.addHook('beforeChange', changes => this.onBeforeChange(changes));\n-    this.addHook('beforeColumnMove', () => this.recalculateAllRowsHeight());\n     this.addHook('beforeColumnResize', () => this.recalculateAllRowsHeight());\n-    this.addHook('beforeColumnSort', () => this.clearCache());\n     this.addHook('beforeRender', force => this.onBeforeRender(force));\n-    this.addHook('beforeRowMove', (rowStart, rowEnd) => this.onBeforeRowMove(rowStart, rowEnd));\n     this.addHook('modifyRowHeight', (height, row) => this.getRowHeight(row, height));\n     this.addHook('modifyColumnHeaderHeight', () => this.getColumnHeaderHeight());\n+\n     super.enablePlugin();\n   }\n ", "y": 0, "oldf": "import BasePlugin from './../_base';\nimport { arrayEach, arrayFilter } from './../../helpers/array';\nimport { cancelAnimationFrame, requestAnimationFrame } from './../../helpers/feature';\nimport { isVisible } from './../../helpers/dom/element';\nimport GhostTable from './../../utils/ghostTable';\nimport { isObject, hasOwnProperty } from './../../helpers/object';\nimport { valueAccordingPercent, rangeEach } from './../../helpers/number';\nimport { registerPlugin } from './../../plugins';\nimport SamplesGenerator from './../../utils/samplesGenerator';\nimport { isPercentValue } from './../../helpers/string';\n\n/**\n * @plugin AutoRowSize\n *\n * @description\n * This plugin allows to set row heights based on their highest cells.\n *\n * By default, the plugin is declared as `undefined`, which makes it disabled (same as if it was declared as `false`).\n * Enabling this plugin may decrease the overall table performance, as it needs to calculate the heights of all cells to\n * resize the rows accordingly.\n * If you experience problems with the performance, try turning this feature off and declaring the row heights manually.\n *\n * Row height calculations are divided into sync and async part. Each of this parts has their own advantages and\n * disadvantages. Synchronous calculations are faster but they block the browser UI, while the slower asynchronous\n * operations don't block the browser UI.\n *\n * To configure the sync/async distribution, you can pass an absolute value (number of columns) or a percentage value to a config object:\n * ```js\n * // as a number (300 columns in sync, rest async)\n * autoRowSize: {syncLimit: 300},\n *\n * // as a string (percent)\n * autoRowSize: {syncLimit: '40%'},\n *\n * // allow sample duplication\n * autoRowSize: {syncLimit: '40%', allowSampleDuplicates: true},\n * ```\n *\n * You can also use the `allowSampleDuplicates` option to allow sampling duplicate values when calculating the row\n * height. __Note__, that this might have a negative impact on performance.\n *\n * To configure this plugin see {@link Options#autoRowSize}.\n *\n * @example\n *\n * ```js\n * const hot = new Handsontable(document.getElementById('example'), {\n *   date: getData(),\n *   autoRowSize: true\n * });\n * // Access to plugin instance:\n * const plugin = hot.getPlugin('autoRowSize');\n *\n * plugin.getRowHeight(4);\n *\n * if (plugin.isEnabled()) {\n *   // code...\n * }\n * ```\n */\nclass AutoRowSize extends BasePlugin {\n  static get CALCULATION_STEP() {\n    return 50;\n  }\n\n  static get SYNC_CALCULATION_LIMIT() {\n    return 500;\n  }\n\n  constructor(hotInstance) {\n    super(hotInstance);\n    /**\n     * Cached rows heights.\n     *\n     * @type {Number[]}\n     */\n    this.heights = [];\n    /**\n     * Instance of {@link GhostTable} for rows and columns size calculations.\n     *\n     * @private\n     * @type {GhostTable}\n     */\n    this.ghostTable = new GhostTable(this.hot);\n    /**\n     * Instance of {@link SamplesGenerator} for generating samples necessary for rows height calculations.\n     *\n     * @private\n     * @type {SamplesGenerator}\n     */\n    this.samplesGenerator = new SamplesGenerator((row, col) => {\n      let cellValue;\n\n      if (row >= 0) {\n        cellValue = this.hot.getDataAtCell(row, col);\n\n      } else if (row === -1) {\n        cellValue = this.hot.getColHeader(col);\n      }\n\n      return { value: cellValue };\n    });\n    /**\n     * `true` if only the first calculation was performed.\n     *\n     * @private\n     * @type {Boolean}\n     */\n    this.firstCalculation = true;\n    /**\n     * `true` if the size calculation is in progress.\n     *\n     * @type {Boolean}\n     */\n    this.inProgress = false;\n\n    // moved to constructor to allow auto-sizing the rows when the plugin is disabled\n    this.addHook('beforeRowResize', (row, size, isDblClick) => this.onBeforeRowResize(row, size, isDblClick));\n  }\n\n  /**\n   * Checks if the plugin is enabled in the handsontable settings. This method is executed in {@link Hooks#beforeInit}\n   * hook and if it returns `true` than the {@link AutoRowSize#enablePlugin} method is called.\n   *\n   * @returns {Boolean}\n   */\n  isEnabled() {\n    return this.hot.getSettings().autoRowSize === true || isObject(this.hot.getSettings().autoRowSize);\n  }\n\n  /**\n   * Enables the plugin functionality for this Handsontable instance.\n   */\n  enablePlugin() {\n    if (this.enabled) {\n      return;\n    }\n\n    this.setSamplingOptions();\n\n    this.addHook('afterLoadData', () => this.onAfterLoadData());\n    this.addHook('beforeChange', changes => this.onBeforeChange(changes));\n    this.addHook('beforeColumnMove', () => this.recalculateAllRowsHeight());\n    this.addHook('beforeColumnResize', () => this.recalculateAllRowsHeight());\n    this.addHook('beforeColumnSort', () => this.clearCache());\n    this.addHook('beforeRender', force => this.onBeforeRender(force));\n    this.addHook('beforeRowMove', (rowStart, rowEnd) => this.onBeforeRowMove(rowStart, rowEnd));\n    this.addHook('modifyRowHeight', (height, row) => this.getRowHeight(row, height));\n    this.addHook('modifyColumnHeaderHeight', () => this.getColumnHeaderHeight());\n    super.enablePlugin();\n  }\n\n  /**\n   * Disables the plugin functionality for this Handsontable instance.\n   */\n  disablePlugin() {\n    super.disablePlugin();\n  }\n\n  /**\n   * Calculate a given rows height.\n   *\n   * @param {Number|Object} rowRange Row index or an object with `from` and `to` indexes as a range.\n   * @param {Number|Object} colRange Column index or an object with `from` and `to` indexes as a range.\n   * @param {Boolean} [force=false] If `true` the calculation will be processed regardless of whether the width exists in the cache.\n   */\n  calculateRowsHeight(rowRange = { from: 0, to: this.hot.countRows() - 1 }, colRange = { from: 0, to: this.hot.countCols() - 1 }, force = false) {\n    const rowsRange = typeof rowRange === 'number' ? { from: rowRange, to: rowRange } : rowRange;\n    const columnsRange = typeof colRange === 'number' ? { from: colRange, to: colRange } : colRange;\n\n    if (this.hot.getColHeader(0) !== null) {\n      const samples = this.samplesGenerator.generateRowSamples(-1, columnsRange);\n\n      this.ghostTable.addColumnHeadersRow(samples.get(-1));\n    }\n\n    rangeEach(rowsRange.from, rowsRange.to, (row) => {\n      // For rows we must calculate row height even when user had set height value manually.\n      // We can shrink column but cannot shrink rows!\n      if (force || this.heights[row] === void 0) {\n        const samples = this.samplesGenerator.generateRowSamples(row, columnsRange);\n\n        arrayEach(samples, ([rowIndex, sample]) => this.ghostTable.addRow(rowIndex, sample));\n      }\n    });\n    if (this.ghostTable.rows.length) {\n      this.ghostTable.getHeights((row, height) => {\n        this.heights[row] = height;\n      });\n      this.ghostTable.clean();\n    }\n  }\n\n  /**\n   * Calculate all rows heights. The calculated row will be cached in the {@link AutoRowSize#heights} property.\n   * To retrieve height for specyfied row use {@link AutoRowSize#getRowHeight} method.\n   *\n   * @param {Object|Number} rowRange Row index or an object with `from` and `to` properties which define row range.\n   */\n  calculateAllRowsHeight(colRange = { from: 0, to: this.hot.countCols() - 1 }) {\n    let current = 0;\n    const length = this.hot.countRows() - 1;\n    let timer = null;\n\n    this.inProgress = true;\n\n    const loop = () => {\n      // When hot was destroyed after calculating finished cancel frame\n      if (!this.hot) {\n        cancelAnimationFrame(timer);\n        this.inProgress = false;\n\n        return;\n      }\n      this.calculateRowsHeight({ from: current, to: Math.min(current + AutoRowSize.CALCULATION_STEP, length) }, colRange);\n      current = current + AutoRowSize.CALCULATION_STEP + 1;\n\n      if (current < length) {\n        timer = requestAnimationFrame(loop);\n      } else {\n        cancelAnimationFrame(timer);\n        this.inProgress = false;\n\n        // @TODO Should call once per render cycle, currently fired separately in different plugins\n        this.hot.view.wt.wtOverlays.adjustElementsSize(true);\n        // tmp\n        if (this.hot.view.wt.wtOverlays.leftOverlay.needFullRender) {\n          this.hot.view.wt.wtOverlays.leftOverlay.clone.draw();\n        }\n      }\n    };\n\n    const syncLimit = this.getSyncCalculationLimit();\n\n    // sync\n    if (this.firstCalculation && syncLimit >= 0) {\n      this.calculateRowsHeight({ from: 0, to: syncLimit }, colRange);\n      this.firstCalculation = false;\n      current = syncLimit + 1;\n    }\n    // async\n    if (current < length) {\n      loop();\n    } else {\n      this.inProgress = false;\n      this.hot.view.wt.wtOverlays.adjustElementsSize(false);\n    }\n  }\n\n  /**\n   * Sets the sampling options.\n   *\n   * @private\n   */\n  setSamplingOptions() {\n    const setting = this.hot.getSettings().autoRowSize;\n    const samplingRatio = setting && hasOwnProperty(setting, 'samplingRatio') ? this.hot.getSettings().autoRowSize.samplingRatio : void 0;\n    const allowSampleDuplicates = setting && hasOwnProperty(setting, 'allowSampleDuplicates') ? this.hot.getSettings().autoRowSize.allowSampleDuplicates : void 0;\n\n    if (samplingRatio && !isNaN(samplingRatio)) {\n      this.samplesGenerator.setSampleCount(parseInt(samplingRatio, 10));\n    }\n\n    if (allowSampleDuplicates) {\n      this.samplesGenerator.setAllowDuplicates(allowSampleDuplicates);\n    }\n  }\n\n  /**\n   * Recalculates all rows height (overwrite cache values).\n   */\n  recalculateAllRowsHeight() {\n    if (isVisible(this.hot.view.wt.wtTable.TABLE)) {\n      this.clearCache();\n      this.calculateAllRowsHeight();\n    }\n  }\n\n  /**\n   * Gets value which tells how many rows should be calculated synchronously (rest of the rows will be calculated\n   * asynchronously). The limit is calculated based on `syncLimit` set to autoRowSize option (see {@link Options#autoRowSize}).\n   *\n   * @returns {Number}\n   */\n  getSyncCalculationLimit() {\n    /* eslint-disable no-bitwise */\n    let limit = AutoRowSize.SYNC_CALCULATION_LIMIT;\n    const rowsLimit = this.hot.countRows() - 1;\n\n    if (isObject(this.hot.getSettings().autoRowSize)) {\n      limit = this.hot.getSettings().autoRowSize.syncLimit;\n\n      if (isPercentValue(limit)) {\n        limit = valueAccordingPercent(rowsLimit, limit);\n      } else {\n        // Force to Number\n        limit >>= 0;\n      }\n    }\n\n    return Math.min(limit, rowsLimit);\n  }\n\n  /**\n   * Gets the calculated row height.\n   *\n   * @param {Number} row Visual row index.\n   * @param {Number} [defaultHeight] Default row height. It will be picked up if no calculated height found.\n   * @returns {Number}\n   */\n  getRowHeight(row, defaultHeight = void 0) {\n    let height = defaultHeight;\n\n    if (this.heights[row] !== void 0 && this.heights[row] > (defaultHeight || 0)) {\n      height = this.heights[row];\n    }\n\n    return height;\n  }\n\n  /**\n   * Get the calculated column header height.\n   *\n   * @returns {Number|undefined}\n   */\n  getColumnHeaderHeight() {\n    return this.heights[-1];\n  }\n\n  /**\n   * Get the first visible row.\n   *\n   * @returns {Number|null} Returns row index, -1 if table is not rendered or null if there are no rows to base the the calculations on.\n   */\n  getFirstVisibleRow() {\n    const wot = this.hot.view.wt;\n\n    if (wot.wtViewport.rowsVisibleCalculator) {\n      return wot.wtTable.getFirstVisibleRow();\n    }\n    if (wot.wtViewport.rowsRenderCalculator) {\n      return wot.wtTable.getFirstRenderedRow();\n    }\n\n    return -1;\n  }\n\n  /**\n   * Gets the last visible row.\n   *\n   * @returns {Number} Returns row index or -1 if table is not rendered.\n   */\n  getLastVisibleRow() {\n    const wot = this.hot.view.wt;\n\n    if (wot.wtViewport.rowsVisibleCalculator) {\n      return wot.wtTable.getLastVisibleRow();\n    }\n    if (wot.wtViewport.rowsRenderCalculator) {\n      return wot.wtTable.getLastRenderedRow();\n    }\n\n    return -1;\n  }\n\n  /**\n   * Clears cached heights.\n   */\n  clearCache() {\n    this.heights.length = 0;\n    this.heights[-1] = void 0;\n  }\n\n  /**\n   * Clears cache by range.\n   *\n   * @param {Object|Number} range Row index or an object with `from` and `to` properties which define row range.\n   */\n  clearCacheByRange(range) {\n    const { from, to } = typeof range === 'number' ? { from: range, to: range } : range;\n\n    rangeEach(Math.min(from, to), Math.max(from, to), (row) => {\n      this.heights[row] = void 0;\n    });\n  }\n\n  /**\n   * Checks if all heights were calculated. If not then return `true` (need recalculate).\n   *\n   * @returns {Boolean}\n   */\n  isNeedRecalculate() {\n    return !!arrayFilter(this.heights, item => (item === void 0)).length;\n  }\n\n  /**\n   * On before render listener.\n   *\n   * @private\n   */\n  onBeforeRender() {\n    const force = this.hot.renderCall;\n    const fixedRowsBottom = this.hot.getSettings().fixedRowsBottom;\n    const firstVisibleRow = this.getFirstVisibleRow();\n    const lastVisibleRow = this.getLastVisibleRow();\n\n    if (firstVisibleRow === null || lastVisibleRow === null) {\n      return;\n    }\n\n    this.calculateRowsHeight({ from: firstVisibleRow, to: lastVisibleRow }, void 0, force);\n\n    // Calculate rows height synchronously for bottom overlay\n    if (fixedRowsBottom) {\n      const totalRows = this.hot.countRows() - 1;\n      this.calculateRowsHeight({ from: totalRows - fixedRowsBottom, to: totalRows });\n    }\n\n    if (this.isNeedRecalculate() && !this.inProgress) {\n      this.calculateAllRowsHeight();\n    }\n  }\n\n  /**\n   * On before row move listener.\n   *\n   * @private\n   * @param {Number} from Row index where was grabbed.\n   * @param {Number} to Destination row index.\n   */\n  onBeforeRowMove(from, to) {\n    this.clearCacheByRange({ from, to });\n    this.calculateAllRowsHeight();\n  }\n\n  /**\n   * On before row resize listener.\n   *\n   * @private\n   * @param {Number} row\n   * @param {Number} size\n   * @param {Boolean} isDblClick\n   * @returns {Number}\n   */\n  onBeforeRowResize(row, size, isDblClick) {\n    let newSize = size;\n\n    if (isDblClick) {\n      this.calculateRowsHeight(row, void 0, true);\n\n      newSize = this.getRowHeight(row);\n    }\n\n    return newSize;\n  }\n\n  /**\n   * On after load data listener.\n   *\n   * @private\n   */\n  onAfterLoadData() {\n    if (this.hot.view) {\n      this.recalculateAllRowsHeight();\n    } else {\n      // first load - initialization\n      setTimeout(() => {\n        if (this.hot) {\n          this.recalculateAllRowsHeight();\n        }\n      }, 0);\n    }\n  }\n\n  /**\n   * On before change listener.\n   *\n   * @private\n   * @param {Array} changes\n   */\n  onBeforeChange(changes) {\n    let range = null;\n\n    if (changes.length === 1) {\n      range = changes[0][0];\n    } else if (changes.length > 1) {\n      range = {\n        from: changes[0][0],\n        to: changes[changes.length - 1][0],\n      };\n    }\n    if (range !== null) {\n      this.clearCacheByRange(range);\n    }\n  }\n\n  /**\n   * Destroys the plugin instance.\n   */\n  destroy() {\n    this.ghostTable.clean();\n    super.destroy();\n  }\n}\n\nregisterPlugin('autoRowSize', AutoRowSize);\n\nexport default AutoRowSize;\n", "idx": 3, "id": 15650, "msg": "", "proj": "handsontable-handsontable", "lang": "js"}
{"patch": "@@ -36,6 +36,8 @@ const isValidNumericID = function( input ) {\n /**\n  * Checks if the given account ID appears to be a valid Analyics account.\n  *\n+ * @since 1.8.0\n+ *\n  * @param {(string|number)} accountID Account ID to test.\n  * @return {boolean} Whether or not the given account ID is valid.\n  */", "y": 0, "oldf": "/**\n * Validation utilities.\n *\n * Site Kit by Google, Copyright 2020 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Internal dependencies\n */\nimport { ACCOUNT_CREATE, PROPERTY_CREATE, PROFILE_CREATE } from '../datastore/constants';\n\n/**\n * Checks the given value to see if it is a positive integer.\n *\n * @param {*} input Value to check.\n * @return {boolean} Validity.\n */\nconst isValidNumericID = function( input ) {\n\tconst id = parseInt( input, 10 ) || 0;\n\n\treturn id > 0;\n};\n\n/**\n * Checks if the given account ID appears to be a valid Analyics account.\n *\n * @param {(string|number)} accountID Account ID to test.\n * @return {boolean} Whether or not the given account ID is valid.\n */\nexport { isValidNumericID as isValidAccountID };\n\n/**\n * Checks if the given value is a valid selection for an Account.\n *\n * @param {?string} value Selected value\n * @return {boolean} True if valid, otherwise false.\n */\nexport function isValidAccountSelection( value ) {\n\tif ( value === ACCOUNT_CREATE ) {\n\t\treturn true;\n\t}\n\n\treturn isValidNumericID( value );\n}\n\n/**\n * Checks whether the given property ID appears to be valid.\n *\n * @param {*} propertyID Property ID to check.\n * @return {boolean} Whether or not the given property ID is valid.\n */\nexport function isValidPropertyID( propertyID ) {\n\treturn typeof propertyID === 'string' && propertyID.match( /^UA-\\d+-\\d+$/ );\n}\n\n/**\n * Checks if the given value is a valid selection for a Property.\n *\n * @param {?string} value Selected value\n * @return {boolean} True if valid, otherwise false.\n */\nexport function isValidPropertySelection( value ) {\n\tif ( value === PROPERTY_CREATE ) {\n\t\treturn true;\n\t}\n\n\treturn isValidPropertyID( value );\n}\n\n/**\n * Checks if the given profile ID appears to be valid.\n *\n * @param {(string|number)} accountID Account ID to test.\n * @return {boolean} Whether or not the given account ID is valid.\n */\nexport { isValidNumericID as isValidProfileID };\n\n/**\n * Checks if the given value is a valid selection for a Profile.\n *\n * @param {?string} value Selected value\n * @return {boolean} True if valid, otherwise false.\n */\nexport function isValidProfileSelection( value ) {\n\tif ( value === PROFILE_CREATE ) {\n\t\treturn true;\n\t}\n\n\treturn isValidNumericID( value );\n}\n\n/**\n * Checks if the given profile name appears to be valid.\n *\n * @since 1.11.0\n *\n * @param {string} value Profile name to test\n * @return {boolean} True if valid, otherwise false.\n */\nexport function isValidProfileName( value ) {\n\treturn typeof value === 'string' && value.trim().length > 0;\n}\n\n/**\n * Checks if the given internal web property ID appears to be valid.\n *\n * @param {(string|number)} accountID Account ID to test.\n * @return {boolean} Whether or not the given account ID is valid.\n */\nexport { isValidNumericID as isValidInternalWebPropertyID };\n", "idx": 2, "id": 32161, "msg": "", "proj": "google-site-kit-wp", "lang": "js"}
{"patch": "@@ -222,16 +222,9 @@ func (w *watcher) modifyFiles(ctx context.Context, event *config.EventWatcherEve\n \t\tif err != nil {\n \t\t\treturn nil, fmt.Errorf(\"failed to get value at %s in %s: %w\", r.YAMLField, r.File, err)\n \t\t}\n-\t\tvar value string\n-\t\tswitch vv := v.(type) {\n-\t\tcase string:\n-\t\t\tvalue = vv\n-\t\tcase int:\n-\t\t\tvalue = strconv.Itoa(vv)\n-\t\tcase float64:\n-\t\t\tvalue = strconv.FormatFloat(vv, 'f', -1, 64)\n-\t\tdefault:\n-\t\t\treturn nil, fmt.Errorf(\"unknown type of value is defined at %s in %s\", r.YAMLField, r.File)\n+\t\tvalue, err := convertStr(v)\n+\t\tif err != nil {\n+\t\t\treturn nil, fmt.Errorf(\"a value of unknown type (%v) is defined at %s in %s\", err, r.YAMLField, r.File)\n \t\t}\n \t\tif latestEvent.Data == value {\n \t\t\t// Already up-to-date.", "y": 0, "oldf": "// Copyright 2021 The PipeCD Authors.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n// Package eventwatcher provides facilities to update config files when new\n// event found. It can be done by periodically comparing the latest value user\n// registered and the value in the files placed at Git repositories.\npackage eventwatcher\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strconv\"\n\t\"sync\"\n\t\"time\"\n\n\t\"go.uber.org/zap\"\n\n\t\"github.com/pipe-cd/pipe/pkg/config\"\n\t\"github.com/pipe-cd/pipe/pkg/git\"\n\t\"github.com/pipe-cd/pipe/pkg/model\"\n\t\"github.com/pipe-cd/pipe/pkg/yamlprocessor\"\n)\n\nconst (\n\t// The latest value and Event name are supposed.\n\tdefaultCommitMessageFormat = \"Replace values with %q set by Event %q\"\n\tdefaultCheckInterval       = 5 * time.Minute\n)\n\ntype Watcher interface {\n\tRun(context.Context) error\n}\n\ntype eventGetter interface {\n\tGetLatest(ctx context.Context, name string, labels map[string]string) (*model.Event, bool)\n}\n\ntype gitClient interface {\n\tClone(ctx context.Context, repoID, remote, branch, destination string) (git.Repo, error)\n}\n\ntype commit struct {\n\tchanges map[string][]byte\n\tmessage string\n}\n\ntype watcher struct {\n\tconfig      *config.PipedSpec\n\teventGetter eventGetter\n\tgitClient   gitClient\n\tlogger      *zap.Logger\n\twg          sync.WaitGroup\n}\n\nfunc NewWatcher(cfg *config.PipedSpec, eventGetter eventGetter, gitClient gitClient, logger *zap.Logger) Watcher {\n\treturn &watcher{\n\t\tconfig:      cfg,\n\t\teventGetter: eventGetter,\n\t\tgitClient:   gitClient,\n\t\tlogger:      logger.Named(\"event-watcher\"),\n\t}\n}\n\n// Run spawns goroutines for each git repository. They periodically fetch the latest Event\n// from the control-plane to compare the value with one in the git repository.\nfunc (w *watcher) Run(ctx context.Context) error {\n\tw.logger.Info(\"start running event watcher\")\n\n\tfor _, repoCfg := range w.config.Repositories {\n\t\trepo, err := w.gitClient.Clone(ctx, repoCfg.RepoID, repoCfg.Remote, repoCfg.Branch, \"\")\n\t\tif err != nil {\n\t\t\tw.logger.Error(\"failed to clone repository\",\n\t\t\t\tzap.String(\"repo-id\", repoCfg.RepoID),\n\t\t\t\tzap.Error(err),\n\t\t\t)\n\t\t\treturn fmt.Errorf(\"failed to clone repository %s: %w\", repoCfg.RepoID, err)\n\t\t}\n\t\tdefer os.RemoveAll(repo.GetPath())\n\n\t\tw.wg.Add(1)\n\t\tgo w.run(ctx, repo, &repoCfg)\n\t}\n\n\tw.wg.Wait()\n\treturn nil\n}\n\n// run works against a single git repo. It periodically compares the value in the given\n// git repository and one in the control-plane. And then pushes those with differences.\nfunc (w *watcher) run(ctx context.Context, repo git.Repo, repoCfg *config.PipedRepository) {\n\tdefer w.wg.Done()\n\n\tvar (\n\t\tcommitMsg                  string\n\t\tincludedCfgs, excludedCfgs []string\n\t)\n\t// Use user-defined settings if there is.\n\tfor _, r := range w.config.EventWatcher.GitRepos {\n\t\tif r.RepoID != repoCfg.RepoID {\n\t\t\tcontinue\n\t\t}\n\t\tcommitMsg = r.CommitMessage\n\t\tincludedCfgs = r.Includes\n\t\texcludedCfgs = r.Excludes\n\t\tbreak\n\t}\n\tcheckInterval := time.Duration(w.config.EventWatcher.CheckInterval)\n\tif checkInterval == 0 {\n\t\tcheckInterval = defaultCheckInterval\n\t}\n\n\tticker := time.NewTicker(checkInterval)\n\tdefer ticker.Stop()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn\n\t\tcase <-ticker.C:\n\t\t\terr := repo.Pull(ctx, repo.GetClonedBranch())\n\t\t\tif err != nil {\n\t\t\t\tw.logger.Error(\"failed to perform git pull\",\n\t\t\t\t\tzap.String(\"repo-id\", repoCfg.RepoID),\n\t\t\t\t\tzap.String(\"branch\", repo.GetClonedBranch()),\n\t\t\t\t\tzap.Error(err),\n\t\t\t\t)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tcfg, err := config.LoadEventWatcher(repo.GetPath(), includedCfgs, excludedCfgs)\n\t\t\tif errors.Is(err, config.ErrNotFound) {\n\t\t\t\tw.logger.Info(\"configuration file for Event Watcher not found\",\n\t\t\t\t\tzap.String(\"repo-id\", repoCfg.RepoID),\n\t\t\t\t\tzap.Error(err),\n\t\t\t\t)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\tw.logger.Error(\"failed to load configuration file for Event Watcher\",\n\t\t\t\t\tzap.String(\"repo-id\", repoCfg.RepoID),\n\t\t\t\t\tzap.Error(err),\n\t\t\t\t)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif err := w.updateValues(ctx, repo, cfg.Events, commitMsg); err != nil {\n\t\t\t\tw.logger.Error(\"failed to update the values\",\n\t\t\t\t\tzap.String(\"repo-id\", repoCfg.RepoID),\n\t\t\t\t\tzap.Error(err),\n\t\t\t\t)\n\t\t\t}\n\t\t}\n\t}\n}\n\n// updateValues inspects all Event-definition and pushes the changes to git repo if there is.\nfunc (w *watcher) updateValues(ctx context.Context, repo git.Repo, events []config.EventWatcherEvent, commitMsg string) error {\n\t// Copy the repo to another directory to avoid pull failure in the future.\n\ttmpDir, err := ioutil.TempDir(\"\", \"event-watcher\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to create a new temporary directory: %w\", err)\n\t}\n\tdefer os.RemoveAll(tmpDir)\n\ttmpRepo, err := repo.Copy(filepath.Join(tmpDir, \"tmp-repo\"))\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to copy the repository to the temporary directory: %w\", err)\n\t}\n\n\tcommits := make([]*commit, 0)\n\tfor _, e := range events {\n\t\tc, err := w.modifyFiles(ctx, &e, tmpRepo, commitMsg)\n\t\tif err != nil {\n\t\t\tw.logger.Error(\"failed to check outdated value\", zap.Error(err))\n\t\t\tcontinue\n\t\t}\n\t\tif c != nil {\n\t\t\tcommits = append(commits, c)\n\t\t}\n\t}\n\tif len(commits) == 0 {\n\t\treturn nil\n\t}\n\n\tw.logger.Info(fmt.Sprintf(\"there are %d outdated values\", len(commits)))\n\tfor _, c := range commits {\n\t\tif err := tmpRepo.CommitChanges(ctx, tmpRepo.GetClonedBranch(), c.message, false, c.changes); err != nil {\n\t\t\treturn fmt.Errorf(\"failed to perform git commit: %w\", err)\n\t\t}\n\t}\n\treturn tmpRepo.Push(ctx, tmpRepo.GetClonedBranch())\n}\n\n// modifyFiles modifies files defined in a given Event if any deviation exists between the value in\n// the git repository and one in the control-plane. And gives back a change contents.\nfunc (w *watcher) modifyFiles(ctx context.Context, event *config.EventWatcherEvent, repo git.Repo, commitMsg string) (*commit, error) {\n\tlatestEvent, ok := w.eventGetter.GetLatest(ctx, event.Name, event.Labels)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"failed to get the latest Event with the name %q\", event.Name)\n\t}\n\n\t// Determine files to be changed.\n\tchanges := make(map[string][]byte, 0)\n\tfor _, r := range event.Replacements {\n\t\tpath := filepath.Join(repo.GetPath(), r.File)\n\t\tyml, err := ioutil.ReadFile(path)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to read file: %w\", err)\n\t\t}\n\t\tv, err := yamlprocessor.GetValue(yml, r.YAMLField)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to get value at %s in %s: %w\", r.YAMLField, r.File, err)\n\t\t}\n\t\tvar value string\n\t\tswitch vv := v.(type) {\n\t\tcase string:\n\t\t\tvalue = vv\n\t\tcase int:\n\t\t\tvalue = strconv.Itoa(vv)\n\t\tcase float64:\n\t\t\tvalue = strconv.FormatFloat(vv, 'f', -1, 64)\n\t\tdefault:\n\t\t\treturn nil, fmt.Errorf(\"unknown type of value is defined at %s in %s\", r.YAMLField, r.File)\n\t\t}\n\t\tif latestEvent.Data == value {\n\t\t\t// Already up-to-date.\n\t\t\tcontinue\n\t\t}\n\t\t// Modify the local file and put it into the change list.\n\t\tnewYml, err := yamlprocessor.ReplaceValue(yml, r.YAMLField, latestEvent.Data)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to replace value at %s with %s: %w\", r.YAMLField, latestEvent.Data, err)\n\t\t}\n\t\tif err := ioutil.WriteFile(path, newYml, os.ModePerm); err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to write file: %w\", err)\n\t\t}\n\t\tchanges[r.File] = newYml\n\t}\n\n\tif len(changes) == 0 {\n\t\treturn nil, nil\n\t}\n\n\tif commitMsg == \"\" {\n\t\tcommitMsg = fmt.Sprintf(defaultCommitMessageFormat, latestEvent.Data, event.Name)\n\t}\n\treturn &commit{\n\t\tchanges: changes,\n\t\tmessage: commitMsg,\n\t}, nil\n}\n", "idx": 1, "id": 13783, "msg": "", "proj": "pipe-cd-pipe", "lang": "go"}
{"patch": "@@ -63,7 +63,7 @@ class BitmapArrayEncoderTest(unittest.TestCase):\n \n   def testEncodeArray(self):\n     \"\"\"Send bitmap as array of indicies\"\"\"\n-    e = self._encoder(self.n, self.w, self.name)\n+    e = self._encoder(self.n, self.w, name=self.name)\n     bitmap = [2,7,15,18,23]\n     out = e.encode(bitmap)\n     assert out.sum() == len(bitmap)*self.w", "y": 0, "oldf": "#!/usr/bin/env python\n# ----------------------------------------------------------------------\n# Numenta Platform for Intelligent Computing (NuPIC)\n# Copyright (C) 2013, Numenta, Inc.  Unless you have purchased from\n# Numenta, Inc. a separate commercial license for this software code, the\n# following terms and conditions apply:\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License version 3 as\n# published by the Free Software Foundation.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n# See the GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see http://www.gnu.org/licenses.\n#\n# http://numenta.org/licenses/\n# ----------------------------------------------------------------------\n\n\"\"\"Unit tests for BitmapArray Encoder.\"\"\"\n\nCL_VERBOSITY = 0\n\nimport cPickle as pickle\nimport unittest2 as unittest\n\nimport numpy\n\nfrom nupic.encoders.bitmaparray import BitmapArrayEncoder\n\n\n\nclass BitmapArrayEncoderTest(unittest.TestCase):\n  \"\"\"Unit tests for BitmapArrayEncoder class.\"\"\"\n\n\n  def setUp(self):\n    self.n = 25\n    self.w = 1\n    self.name = \"foo\"\n    self._encoder = BitmapArrayEncoder\n\n\n  def testInitialization(self):\n    e = self._encoder(self.n, self.w, self.name)\n    self.assertEqual(type(e), self._encoder)\n\n\n  def testEncodeString(self):\n    \"\"\"Send array as csv string.\"\"\"\n    e = self._encoder(self.n, self.w, self.name)\n    bitmap = \"2,7,15,18,23\"\n    out = e.encode(bitmap)\n    assert out.sum() == len(bitmap.split(','))*self.w\n\n    x = e.decode(out)\n    assert isinstance(x[0], dict)\n    assert self.name in x[0]\n\n\n  def testEncodeArray(self):\n    \"\"\"Send bitmap as array of indicies\"\"\"\n    e = self._encoder(self.n, self.w, self.name)\n    bitmap = [2,7,15,18,23]\n    out = e.encode(bitmap)\n    assert out.sum() == len(bitmap)*self.w\n\n    x = e.decode(out)\n    assert isinstance(x[0], dict)\n    assert self.name in x[0]\n\n\n  def testClosenessScores(self):\n    \"\"\"Compare two bitmaps for closeness\"\"\"\n    e = self._encoder(self.n, self.w, self.name)\n\n    \"\"\"Identical => 1\"\"\"\n    bitmap1 = [2,7,15,18,23]\n    bitmap2 = [2,7,15,18,23]\n    out1 = e.encode(bitmap1)\n    out2 = e.encode(bitmap2)\n    c = e.closenessScores(out1, out2)\n    assert c[0] == 1.0\n\n    \"\"\"No overlap => 0\"\"\"\n    bitmap1 = [2,7,15,18,23]\n    bitmap2 = [3,9,14,19,24]\n    out1 = e.encode(bitmap1)\n    out2 = e.encode(bitmap2)\n    c = e.closenessScores(out1, out2)\n    assert c[0] == 0.0\n\n    \"\"\"Similar => 4 of 5 match\"\"\"\n    bitmap1 = [2,7,15,18,23]\n    bitmap2 = [2,7,17,18,23]\n    out1 = e.encode(bitmap1)\n    out2 = e.encode(bitmap2)\n    c = e.closenessScores(out1, out2)\n    assert c[0] == 0.8\n\n    \"\"\"Little => 1 of 5 match\"\"\"\n    bitmap1 = [2,7,15,18,23]\n    bitmap2 = [3,7,17,19,24]\n    out1 = e.encode(bitmap1)\n    out2 = e.encode(bitmap2)\n    c = e.closenessScores(out1, out2)\n    assert c[0] == 0.2\n\n    \"\"\"Extra active bit => off by 1 of 5\"\"\"\n    bitmap1 = [2,7,15,18,23]\n    bitmap2 = [2,7,11,15,18,23]\n    out1 = e.encode(bitmap1)\n    out2 = e.encode(bitmap2)\n    c = e.closenessScores(out1, out2)\n    assert c[0] == 0.8\n\n    \"\"\"Missing active bit => off by 1 of 5\"\"\"\n    bitmap1 = [2,7,15,18,23]\n    bitmap2 = [2,7,18,23]\n    out1 = e.encode(bitmap1)\n    out2 = e.encode(bitmap2)\n    c = e.closenessScores(out1, out2)\n    assert c[0] == 0.8\n\n\n  def testRobustness(self):\n    \"\"\"Encode bitmaps with robustness (w) set\"\"\"\n    self.w = 3\n    self.n = self.n * self.w\n    self.testEncodeString()\n    self.testEncodeArray()\n    self.testClosenessScores()\n\n\n\nif __name__ == '__main__':\n  unittest.main()\n", "idx": 2, "id": 12956, "msg": "", "proj": "numenta-nupic", "lang": "py"}
{"patch": "@@ -24,8 +24,8 @@ public class TableCodecTest {\n         // TODO: enable when support Timestamp\n         // .addColumn(\"c3\", DateTimeType.DATETIME)\n         // .addColumn(\"c4\", TimestampType.TIMESTAMP)\n-        .addColumn(\"c5\", StringType.VARCHAR)\n-        .addColumn(\"c6\", StringType.VARCHAR)\n+        .addColumn(\"c5\", StringType.VARCHAR255)\n+        .addColumn(\"c6\", StringType.VARCHAR255)\n         // .appendIndex(\"testIndex\", ImmutableList.of(\"c1\", \"c2\"), false)\n         .build();\n   }", "y": 1, "oldf": "package com.pingcap.tikv.codec;\n\nimport static org.junit.Assert.*;\n\nimport com.pingcap.tikv.meta.MetaUtils;\nimport com.pingcap.tikv.meta.TiTableInfo;\nimport com.pingcap.tikv.row.Row;\nimport com.pingcap.tikv.types.IntegerType;\nimport com.pingcap.tikv.types.StringType;\nimport java.util.ArrayList;\nimport java.util.List;\nimport org.joda.time.DateTime;\nimport org.junit.Before;\nimport org.junit.Rule;\nimport org.junit.Test;\nimport org.junit.rules.ExpectedException;\n\npublic class TableCodecTest {\n  private static TiTableInfo createTable() {\n    return new MetaUtils.TableBuilder()\n        .name(\"testTable\")\n        .addColumn(\"c1\", IntegerType.INT, true)\n        .addColumn(\"c2\", IntegerType.BIGINT)\n        // TODO: enable when support Timestamp\n        // .addColumn(\"c3\", DateTimeType.DATETIME)\n        // .addColumn(\"c4\", TimestampType.TIMESTAMP)\n        .addColumn(\"c5\", StringType.VARCHAR)\n        .addColumn(\"c6\", StringType.VARCHAR)\n        // .appendIndex(\"testIndex\", ImmutableList.of(\"c1\", \"c2\"), false)\n        .build();\n  }\n\n  private Object[] values;\n  private TiTableInfo tblInfo = createTable();\n\n  private void makeValues() {\n    List<Object> values = new ArrayList<>();\n    values.add(1L);\n    values.add(1L);\n    DateTime dateTime = DateTime.parse(\"1995-10-10\");\n    // values.add(new Timestamp(dateTime.getMillis()));\n    // values.add(new Timestamp(dateTime.getMillis()));\n    values.add(\"abc\");\n    values.add(\"\u4e2d\");\n    this.values = values.toArray();\n  }\n\n  @Before\n  public void setUp() {\n    makeValues();\n  }\n\n  @Rule public ExpectedException expectedEx = ExpectedException.none();\n\n  @Test\n  public void testRowCodecThrowException() {\n    try {\n      TableCodec.encodeRow(\n          tblInfo.getColumns(), new Object[] {values[0], values[1]}, tblInfo.isPkHandle());\n      expectedEx.expect(IllegalAccessException.class);\n      expectedEx.expectMessage(\"encodeRow error: data and columnID count not match 6 vs 2\");\n    } catch (IllegalAccessException ignored) {\n    }\n  }\n\n  @Test\n  public void testEmptyValues() {\n    try {\n      byte[] bytes = TableCodec.encodeRow(new ArrayList<>(), new Object[] {}, false);\n      assertEquals(1, bytes.length);\n      assertEquals(Codec.NULL_FLAG, bytes[0]);\n    } catch (IllegalAccessException ignored) {\n    }\n  }\n\n  @Test\n  public void testRowCodec() {\n    // multiple test was added since encodeRow refuse its cdo\n    for (int i = 0; i < 4; i++) {\n      try {\n        byte[] bytes = TableCodec.encodeRow(tblInfo.getColumns(), values, tblInfo.isPkHandle());\n        // testing the correctness via decodeRow\n        Row row = TableCodec.decodeRow(bytes, tblInfo.getColumns());\n        for (int j = 0; j < tblInfo.getColumns().size(); j++) {\n          assertEquals(row.get(j, null), values[j]);\n        }\n      } catch (IllegalAccessException ignored) {\n      }\n    }\n  }\n}\n", "idx": 1, "id": 10106, "msg": "We may change the signature of `addColumn` as the following, .addColumn(\"c5\", StringType.VARCHAR, 235) where 235 specifying the length.", "proj": "pingcap-tispark", "lang": "java"}
{"patch": "@@ -284,6 +284,9 @@ gboolean\n _ostree_sysroot_ensure_writable (OstreeSysroot      *self,\n                                  GError            **error)\n {\n+  if (self->root_is_ostree_live)\n+    return glnx_throw (error, \"sysroot does not support persistent changes\");\n+\n   /* Do nothing if no mount namespace is in use */\n   if (!self->mount_namespace_in_use)\n     return TRUE;", "y": 1, "oldf": "/*\n * Copyright (C) 2013 Colin Walters <walters@verbum.org>\n *\n * SPDX-License-Identifier: LGPL-2.0+\n *\n * This library is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2 of the License, or (at your option) any later version.\n *\n * This library is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with this library; if not, write to the\n * Free Software Foundation, Inc., 59 Temple Place - Suite 330,\n * Boston, MA 02111-1307, USA.\n */\n\n#include \"config.h\"\n\n#include \"otutil.h\"\n#include <sys/file.h>\n#include <sys/mount.h>\n#include <err.h>\n#include <sys/wait.h>\n\n#include \"ostree.h\"\n#include \"ostree-core-private.h\"\n#include \"ostree-repo-private.h\"\n#include \"ostree-sepolicy-private.h\"\n#include \"ostree-sysroot-private.h\"\n#include \"ostree-deployment-private.h\"\n#include \"ostree-bootloader-uboot.h\"\n#include \"ostree-bootloader-syslinux.h\"\n#include \"ostree-bootloader-grub2.h\"\n\n/**\n * SECTION:ostree-sysroot\n * @title: Root partition mount point\n * @short_description: Manage physical root filesystem\n *\n * A #OstreeSysroot object represents a physical root filesystem,\n * which in particular should contain a toplevel /ostree directory.\n * Inside this directory is an #OstreeRepo in /ostree/repo, plus a set\n * of deployments in /ostree/deploy.\n *\n * This class is not by default safe against concurrent use by threads\n * or external processes.  You can use ostree_sysroot_lock() to\n * perform locking externally.\n */\ntypedef struct {\n  GObjectClass parent_class;\n\n  /* Signals */\n  void (*journal_msg) (OstreeSysroot *sysroot,\n                       const char    *msg);\n} OstreeSysrootClass;\n\nenum {\n  JOURNAL_MSG_SIGNAL,\n  LAST_SIGNAL,\n};\nstatic guint signals[LAST_SIGNAL] = { 0 };\n\nenum {\n  PROP_0,\n\n  PROP_PATH\n};\n\nG_DEFINE_TYPE (OstreeSysroot, ostree_sysroot, G_TYPE_OBJECT)\n\nstatic void\nostree_sysroot_finalize (GObject *object)\n{\n  OstreeSysroot *self = OSTREE_SYSROOT (object);\n\n  g_clear_object (&self->path);\n  g_clear_object (&self->repo);\n  g_clear_pointer (&self->deployments, g_ptr_array_unref);\n  g_clear_object (&self->booted_deployment);\n  g_clear_object (&self->staged_deployment);\n  g_clear_pointer (&self->staged_deployment_data, (GDestroyNotify)g_variant_unref);\n\n  glnx_release_lock_file (&self->lock);\n\n  ostree_sysroot_unload (self);\n\n  G_OBJECT_CLASS (ostree_sysroot_parent_class)->finalize (object);\n}\n\nstatic void\nostree_sysroot_set_property(GObject         *object,\n                            guint            prop_id,\n                            const GValue    *value,\n                            GParamSpec      *pspec)\n{\n  OstreeSysroot *self = OSTREE_SYSROOT (object);\n\n  switch (prop_id)\n    {\n    case PROP_PATH:\n      self->path = g_value_dup_object (value);\n      break;\n    default:\n      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);\n      break;\n    }\n}\n\nstatic void\nostree_sysroot_get_property(GObject         *object,\n                            guint            prop_id,\n                            GValue          *value,\n                            GParamSpec      *pspec)\n{\n  OstreeSysroot *self = OSTREE_SYSROOT (object);\n\n  switch (prop_id)\n    {\n    case PROP_PATH:\n      g_value_set_object (value, self->path);\n      break;\n    default:\n      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);\n      break;\n    }\n}\n\nstatic void\nostree_sysroot_constructed (GObject *object)\n{\n  OstreeSysroot *self = OSTREE_SYSROOT (object);\n\n  /* Ensure the system root path is set. */\n  if (self->path == NULL)\n    self->path = g_object_ref (_ostree_get_default_sysroot_path ());\n\n  G_OBJECT_CLASS (ostree_sysroot_parent_class)->constructed (object);\n}\n\nstatic void\nostree_sysroot_class_init (OstreeSysrootClass *klass)\n{\n  GObjectClass *object_class = G_OBJECT_CLASS (klass);\n\n  object_class->constructed = ostree_sysroot_constructed;\n  object_class->get_property = ostree_sysroot_get_property;\n  object_class->set_property = ostree_sysroot_set_property;\n  object_class->finalize = ostree_sysroot_finalize;\n\n  g_object_class_install_property (object_class,\n                                   PROP_PATH,\n                                   g_param_spec_object (\"path\",\n                                                        \"\",\n                                                        \"\",\n                                                        G_TYPE_FILE,\n                                                        G_PARAM_READWRITE | G_PARAM_CONSTRUCT_ONLY));\n\n  /**\n   * OstreeSysroot::journal-msg:\n   * @self: Self\n   * @msg: Human-readable string (should not contain newlines)\n   *\n   * libostree will log to the journal various events, such as the /etc merge\n   * status, and transaction completion. Connect to this signal to also\n   * synchronously receive the text for those messages. This is intended to be\n   * used by command line tools which link to libostree as a library.\n   *\n   * Currently, the structured data is only available via the systemd journal.\n   *\n   * Since: 2017.10\n   */\n  signals[JOURNAL_MSG_SIGNAL] =\n    g_signal_new (\"journal-msg\",\n                  G_OBJECT_CLASS_TYPE (object_class),\n                  G_SIGNAL_RUN_LAST,\n                  G_STRUCT_OFFSET (OstreeSysrootClass, journal_msg),\n                  NULL, NULL, NULL, G_TYPE_NONE, 1, G_TYPE_STRING);\n}\n\nstatic void\nostree_sysroot_init (OstreeSysroot *self)\n{\n  const GDebugKey keys[] = {\n    { \"mutable-deployments\", OSTREE_SYSROOT_DEBUG_MUTABLE_DEPLOYMENTS },\n    { \"test-fifreeze\", OSTREE_SYSROOT_DEBUG_TEST_FIFREEZE },\n    { \"no-xattrs\", OSTREE_SYSROOT_DEBUG_NO_XATTRS },\n    { \"test-staged-path\", OSTREE_SYSROOT_DEBUG_TEST_STAGED_PATH },\n  };\n\n  self->debug_flags = g_parse_debug_string (g_getenv (\"OSTREE_SYSROOT_DEBUG\"),\n                                            keys, G_N_ELEMENTS (keys));\n\n  self->sysroot_fd = -1;\n}\n\n/**\n * ostree_sysroot_new:\n * @path: (allow-none): Path to a system root directory, or %NULL to use the\n *   current visible root file system\n *\n * Create a new #OstreeSysroot object for the sysroot at @path. If @path is %NULL,\n * the current visible root file system is used, equivalent to\n * ostree_sysroot_new_default().\n *\n * Returns: (transfer full): An accessor object for an system root located at @path\n */\nOstreeSysroot*\nostree_sysroot_new (GFile *path)\n{\n  return g_object_new (OSTREE_TYPE_SYSROOT, \"path\", path, NULL);\n}\n\n/**\n * ostree_sysroot_new_default:\n *\n * Returns: (transfer full): An accessor for the current visible root / filesystem\n */\nOstreeSysroot*\nostree_sysroot_new_default (void)\n{\n  return ostree_sysroot_new (NULL);\n}\n\n/**\n * ostree_sysroot_set_mount_namespace_in_use:\n *\n * If this function is invoked, then libostree will assume that\n * a private Linux mount namespace has been created by the process.\n * The primary use case for this is to have e.g. /sysroot mounted\n * read-only by default.\n *\n * If this function has been called, then when a function which requires\n * writable access is invoked, libostree will automatically remount as writable\n * any mount points on which it operates.  This currently is just `/sysroot` and\n * `/boot`.\n *\n * If you invoke this function, it must be before ostree_sysroot_load(); it may\n * be invoked before or after ostree_sysroot_initialize().\n *\n * Since: 2020.1\n */\nvoid\nostree_sysroot_set_mount_namespace_in_use (OstreeSysroot  *self)\n{\n  /* Must be before we're loaded, as otherwise we'd have to close/reopen all our\n     fds, e.g. the repo */\n  g_return_if_fail (self->loadstate < OSTREE_SYSROOT_LOAD_STATE_LOADED);\n  self->mount_namespace_in_use = TRUE;\n}\n\n/**\n * ostree_sysroot_get_path:\n * @self:\n *\n * Returns: (transfer none): Path to rootfs\n */\nGFile *\nostree_sysroot_get_path (OstreeSysroot  *self)\n{\n  return self->path;\n}\n\n/* Open a directory file descriptor for the sysroot if we haven't yet */\nstatic gboolean\nensure_sysroot_fd (OstreeSysroot          *self,\n                   GError                **error)\n{\n  if (self->sysroot_fd == -1)\n    {\n      if (!glnx_opendirat (AT_FDCWD, gs_file_get_path_cached (self->path), TRUE,\n                           &self->sysroot_fd, error))\n        return FALSE;\n    }\n  return TRUE;\n}\n\n/* Remount /sysroot read-write if necessary */\ngboolean\n_ostree_sysroot_ensure_writable (OstreeSysroot      *self,\n                                 GError            **error)\n{\n  /* Do nothing if no mount namespace is in use */\n  if (!self->mount_namespace_in_use)\n    return TRUE;\n\n  /* If a mount namespace is in use, ensure we're initialized */\n  if (!ostree_sysroot_initialize (self, error))\n    return FALSE;\n\n  /* If we aren't operating on a booted system, then we don't\n   * do anything with mounts.\n   */\n  if (!self->root_is_ostree_booted)\n    return TRUE;\n\n  /* Check if /sysroot is a read-only mountpoint */\n  struct statvfs stvfsbuf;\n  if (statvfs (\"/sysroot\", &stvfsbuf) < 0)\n    return glnx_throw_errno_prefix (error, \"fstatvfs(/sysroot)\");\n  if ((stvfsbuf.f_flag & ST_RDONLY) == 0)\n    return TRUE;\n\n  /* OK, let's remount writable. */\n  if (mount (\"/sysroot\", \"/sysroot\", NULL, MS_REMOUNT | MS_RELATIME, \"\") < 0)\n    return glnx_throw_errno_prefix (error, \"Remounting /sysroot read-write\");\n\n  /* Reopen our fd */\n  glnx_close_fd (&self->sysroot_fd);\n  if (!ensure_sysroot_fd (self, error))\n    return FALSE;\n\n  return TRUE;\n}\n\n/**\n * ostree_sysroot_get_fd:\n * @self: Sysroot\n *\n * Access a file descriptor that refers to the root directory of this sysroot.\n * ostree_sysroot_initialize() (or ostree_sysroot_load()) must have been invoked\n * prior to calling this function.\n *\n * Returns: A file descriptor valid for the lifetime of @self\n */\nint\nostree_sysroot_get_fd (OstreeSysroot *self)\n{\n  g_return_val_if_fail (self->sysroot_fd != -1, -1);\n  return self->sysroot_fd;\n}\n\n/**\n * ostree_sysroot_is_booted:\n * @self: Sysroot\n *\n * Can only be invoked after `ostree_sysroot_initialize()`.\n * \n * Returns: %TRUE iff the sysroot points to a booted deployment\n * Since: 2020.1\n */\ngboolean\nostree_sysroot_is_booted (OstreeSysroot *self)\n{\n  g_return_val_if_fail (self->loadstate >= OSTREE_SYSROOT_LOAD_STATE_INIT, FALSE);\n  return self->root_is_ostree_booted;\n}\n\ngboolean\n_ostree_sysroot_bump_mtime (OstreeSysroot *self,\n                            GError       **error)\n{\n  /* Allow other systems to monitor for changes */\n  if (utimensat (self->sysroot_fd, \"ostree/deploy\", NULL, 0) < 0)\n    {\n      glnx_set_prefix_error_from_errno (error, \"%s\", \"futimens\");\n      return FALSE;\n    }\n  return TRUE;\n}\n\n/**\n * ostree_sysroot_unload:\n * @self: Sysroot\n *\n * Release any resources such as file descriptors referring to the\n * root directory of this sysroot.  Normally, those resources are\n * cleared by finalization, but in garbage collected languages that\n * may not be predictable.\n *\n * This undoes the effect of `ostree_sysroot_load()`.\n */\nvoid\nostree_sysroot_unload (OstreeSysroot  *self)\n{\n  glnx_close_fd (&self->sysroot_fd);\n}\n\n/**\n * ostree_sysroot_ensure_initialized:\n * @self: Sysroot\n * @cancellable: Cancellable\n * @error: Error\n *\n * Ensure that @self is set up as a valid rootfs, by creating\n * /ostree/repo, among other things.\n */\ngboolean\nostree_sysroot_ensure_initialized (OstreeSysroot  *self,\n                                   GCancellable   *cancellable,\n                                   GError        **error)\n{\n  if (!ensure_sysroot_fd (self, error))\n    return FALSE;\n\n  if (!glnx_shutil_mkdir_p_at (self->sysroot_fd, \"ostree/repo\", 0755,\n                               cancellable, error))\n    return FALSE;\n\n  if (!glnx_shutil_mkdir_p_at (self->sysroot_fd, \"ostree/deploy\", 0755,\n                               cancellable, error))\n    return FALSE;\n\n  g_autoptr(OstreeRepo) repo =\n    ostree_repo_create_at (self->sysroot_fd, \"ostree/repo\",\n                           OSTREE_REPO_MODE_BARE, NULL,\n                           cancellable, error);\n  if (!repo)\n    return FALSE;\n  return TRUE;\n}\n\nvoid\n_ostree_sysroot_emit_journal_msg (OstreeSysroot  *self,\n                                  const char     *msg)\n{\n  g_signal_emit (self, signals[JOURNAL_MSG_SIGNAL], 0, msg);\n}\n\ngboolean\n_ostree_sysroot_parse_deploy_path_name (const char *name,\n                                        char      **out_csum,\n                                        int        *out_serial,\n                                        GError    **error)\n{\n\n  static gsize regex_initialized;\n  static GRegex *regex;\n  if (g_once_init_enter (&regex_initialized))\n    {\n      regex = g_regex_new (\"^([0-9a-f]+)\\\\.([0-9]+)$\", 0, 0, NULL);\n      g_assert (regex);\n      g_once_init_leave (&regex_initialized, 1);\n    }\n\n  g_autoptr(GMatchInfo) match = NULL;\n  if (!g_regex_match (regex, name, 0, &match))\n    return glnx_throw (error, \"Invalid deploy name '%s', expected CHECKSUM.TREESERIAL\", name);\n\n  g_autofree char *serial_str = g_match_info_fetch (match, 2);\n  *out_csum = g_match_info_fetch (match, 1);\n  *out_serial = (int)g_ascii_strtoll (serial_str, NULL, 10);\n  return TRUE;\n}\n\ngboolean\n_ostree_sysroot_read_current_subbootversion (OstreeSysroot *self,\n                                             int            bootversion,\n                                             int           *out_subbootversion,\n                                             GCancellable  *cancellable,\n                                             GError       **error)\n{\n  if (!ensure_sysroot_fd (self, error))\n    return FALSE;\n\n  g_autofree char *ostree_bootdir_name = g_strdup_printf (\"ostree/boot.%d\", bootversion);\n  struct stat stbuf;\n  if (!glnx_fstatat_allow_noent (self->sysroot_fd, ostree_bootdir_name, &stbuf, AT_SYMLINK_NOFOLLOW, error))\n    return FALSE;\n  if (errno == ENOENT)\n    {\n      *out_subbootversion = 0;\n    }\n  else\n    {\n      g_autofree char *current_subbootdir_name =\n        glnx_readlinkat_malloc (self->sysroot_fd, ostree_bootdir_name,\n                                cancellable, error);\n      if (!current_subbootdir_name)\n        return FALSE;\n\n      if (g_str_has_suffix (current_subbootdir_name, \".0\"))\n        *out_subbootversion = 0;\n      else if (g_str_has_suffix (current_subbootdir_name, \".1\"))\n        *out_subbootversion = 1;\n      else\n        return glnx_throw (error, \"Invalid target '%s' in %s\",\n                           current_subbootdir_name, ostree_bootdir_name);\n    }\n\n  return TRUE;\n}\n\nstatic gint\ncompare_boot_loader_configs (OstreeBootconfigParser     *a,\n                             OstreeBootconfigParser     *b)\n{\n  const char *a_version = ostree_bootconfig_parser_get (a, \"version\");\n  const char *b_version = ostree_bootconfig_parser_get (b, \"version\");\n\n  if (a_version && b_version)\n    {\n      int r = strverscmp (a_version, b_version);\n      /* Reverse */\n      return -r;\n    }\n  else if (a_version)\n    return -1;\n  else\n    return 1;\n}\n\nstatic int\ncompare_loader_configs_for_sorting (gconstpointer  a_pp,\n                                    gconstpointer  b_pp)\n{\n  OstreeBootconfigParser *a = *((OstreeBootconfigParser**)a_pp);\n  OstreeBootconfigParser *b = *((OstreeBootconfigParser**)b_pp);\n\n  return compare_boot_loader_configs (a, b);\n}\n\ngboolean\n_ostree_sysroot_read_boot_loader_configs (OstreeSysroot *self,\n                                          int            bootversion,\n                                          GPtrArray    **out_loader_configs,\n                                          GCancellable  *cancellable,\n                                          GError       **error)\n{\n  if (!ensure_sysroot_fd (self, error))\n    return FALSE;\n\n  g_autoptr(GPtrArray) ret_loader_configs =\n    g_ptr_array_new_with_free_func ((GDestroyNotify)g_object_unref);\n\n  g_autofree char *entries_path = g_strdup_printf (\"boot/loader.%d/entries\", bootversion);\n  gboolean entries_exists;\n  g_auto(GLnxDirFdIterator) dfd_iter = { 0, };\n  if (!ot_dfd_iter_init_allow_noent (self->sysroot_fd, entries_path,\n                                     &dfd_iter, &entries_exists, error))\n    return FALSE;\n  if (!entries_exists)\n    {\n      /* Note early return */\n      *out_loader_configs = g_steal_pointer (&ret_loader_configs);\n      return TRUE;\n    }\n\n  while (TRUE)\n    {\n      struct dirent *dent;\n      struct stat stbuf;\n\n      if (!glnx_dirfd_iterator_next_dent (&dfd_iter, &dent, cancellable, error))\n        return FALSE;\n      if (dent == NULL)\n        break;\n\n      if (!glnx_fstatat (dfd_iter.fd, dent->d_name, &stbuf, 0, error))\n        return FALSE;\n\n      if (g_str_has_prefix (dent->d_name, \"ostree-\") &&\n          g_str_has_suffix (dent->d_name, \".conf\") &&\n          S_ISREG (stbuf.st_mode))\n        {\n          g_autoptr(OstreeBootconfigParser) config = ostree_bootconfig_parser_new ();\n\n          if (!ostree_bootconfig_parser_parse_at (config, dfd_iter.fd, dent->d_name, cancellable, error))\n            return glnx_prefix_error (error, \"Parsing %s\", dent->d_name);\n\n          g_ptr_array_add (ret_loader_configs, g_object_ref (config));\n        }\n    }\n\n  /* Callers expect us to give them a sorted array */\n  g_ptr_array_sort (ret_loader_configs, compare_loader_configs_for_sorting);\n  ot_transfer_out_value(out_loader_configs, &ret_loader_configs);\n  return TRUE;\n}\n\nstatic gboolean\nread_current_bootversion (OstreeSysroot *self,\n                          int           *out_bootversion,\n                          GCancellable  *cancellable,\n                          GError       **error)\n{\n  int ret_bootversion;\n  struct stat stbuf;\n\n  if (!glnx_fstatat_allow_noent (self->sysroot_fd, \"boot/loader\", &stbuf, AT_SYMLINK_NOFOLLOW, error))\n    return FALSE;\n  if (errno == ENOENT)\n    {\n      ret_bootversion = 0;\n    }\n  else\n    {\n      if (!S_ISLNK (stbuf.st_mode))\n        return glnx_throw (error, \"Not a symbolic link: boot/loader\");\n\n      g_autofree char *target =\n        glnx_readlinkat_malloc (self->sysroot_fd, \"boot/loader\", cancellable, error);\n      if (!target)\n        return FALSE;\n      if (g_strcmp0 (target, \"loader.0\") == 0)\n        ret_bootversion = 0;\n      else if (g_strcmp0 (target, \"loader.1\") == 0)\n        ret_bootversion = 1;\n      else\n        return glnx_throw (error, \"Invalid target '%s' in boot/loader\", target);\n    }\n\n  *out_bootversion = ret_bootversion;\n  return TRUE;\n}\n\nstatic gboolean\nload_origin (OstreeSysroot   *self,\n             OstreeDeployment *deployment,\n             GCancellable    *cancellable,\n             GError         **error)\n{\n  g_autofree char *origin_path = ostree_deployment_get_origin_relpath (deployment);\n\n  glnx_autofd int fd = -1;\n  if (!ot_openat_ignore_enoent (self->sysroot_fd, origin_path, &fd, error))\n    return FALSE;\n  if (fd >= 0)\n    {\n      g_autofree char *origin_contents =\n        glnx_fd_readall_utf8 (fd, NULL, cancellable, error);\n      if (!origin_contents)\n        return FALSE;\n\n      g_autoptr(GKeyFile) origin = g_key_file_new ();\n      if (!g_key_file_load_from_data (origin, origin_contents, -1, 0, error))\n        return glnx_prefix_error (error, \"Parsing %s\", origin_path);\n\n      ostree_deployment_set_origin (deployment, origin);\n    }\n\n  return TRUE;\n}\n\nstatic gboolean\nparse_bootlink (const char    *bootlink,\n                int           *out_entry_bootversion,\n                char         **out_osname,\n                char         **out_bootcsum,\n                int           *out_treebootserial,\n                GError       **error)\n{\n  static gsize regex_initialized;\n  static GRegex *regex;\n  if (g_once_init_enter (&regex_initialized))\n    {\n      regex = g_regex_new (\"^/ostree/boot.([01])/([^/]+)/([^/]+)/([0-9]+)$\", 0, 0, NULL);\n      g_assert (regex);\n      g_once_init_leave (&regex_initialized, 1);\n    }\n\n  g_autoptr(GMatchInfo) match = NULL;\n  if (!g_regex_match (regex, bootlink, 0, &match))\n    return glnx_throw (error, \"Invalid ostree= argument '%s', expected ostree=/ostree/boot.BOOTVERSION/OSNAME/BOOTCSUM/TREESERIAL\", bootlink);\n\n  g_autofree char *bootversion_str = g_match_info_fetch (match, 1);\n  g_autofree char *treebootserial_str = g_match_info_fetch (match, 4);\n  *out_entry_bootversion = (int)g_ascii_strtoll (bootversion_str, NULL, 10);\n  *out_osname = g_match_info_fetch (match, 2);\n  *out_bootcsum = g_match_info_fetch (match, 3);\n  *out_treebootserial = (int)g_ascii_strtoll (treebootserial_str, NULL, 10);\n  return TRUE;\n}\n\nchar *\n_ostree_sysroot_get_runstate_path (OstreeDeployment *deployment, const char *key)\n{\n  return g_strdup_printf (\"%s%s.%d/%s\",\n                          _OSTREE_SYSROOT_DEPLOYMENT_RUNSTATE_DIR,\n                          ostree_deployment_get_csum (deployment),\n                          ostree_deployment_get_deployserial (deployment),\n                          key);\n}\n\nstatic gboolean\nparse_deployment (OstreeSysroot       *self,\n                  const char          *boot_link,\n                  OstreeDeployment   **out_deployment,\n                  GCancellable        *cancellable,\n                  GError             **error)\n{\n  if (!ensure_sysroot_fd (self, error))\n    return FALSE;\n\n  int entry_boot_version;\n  g_autofree char *osname = NULL;\n  g_autofree char *bootcsum = NULL;\n  int treebootserial = -1;\n  if (!parse_bootlink (boot_link, &entry_boot_version,\n                       &osname, &bootcsum, &treebootserial,\n                       error))\n    return FALSE;\n\n  g_autofree char *errprefix =\n    g_strdup_printf (\"Parsing deployment %i in stateroot '%s'\", treebootserial, osname);\n  GLNX_AUTO_PREFIX_ERROR(errprefix, error);\n\n  const char *relative_boot_link = boot_link;\n  if (*relative_boot_link == '/')\n    relative_boot_link++;\n\n  g_autofree char *treebootserial_target =\n    glnx_readlinkat_malloc (self->sysroot_fd, relative_boot_link,\n                            cancellable, error);\n  if (!treebootserial_target)\n    return FALSE;\n\n  const char *deploy_basename = glnx_basename (treebootserial_target);\n  g_autofree char *treecsum = NULL;\n  int deployserial = -1;\n  if (!_ostree_sysroot_parse_deploy_path_name (deploy_basename,\n                                               &treecsum, &deployserial, error))\n    return FALSE;\n\n  glnx_autofd int deployment_dfd = -1;\n  if (!glnx_opendirat (self->sysroot_fd, relative_boot_link, TRUE,\n                       &deployment_dfd, error))\n    return FALSE;\n\n  /* See if this is the booted deployment */\n  const gboolean looking_for_booted_deployment =\n    (self->root_is_ostree_booted && !self->booted_deployment);\n  gboolean is_booted_deployment = FALSE;\n  if (looking_for_booted_deployment)\n    {\n      struct stat stbuf;\n      if (!glnx_fstat (deployment_dfd, &stbuf, error))\n        return FALSE;\n      /* A bit ugly, we're assigning to a sysroot-owned variable from deep in\n       * this parsing code. But eh, if something fails the sysroot state can't\n       * be relied on anyways.\n       */\n      is_booted_deployment = (stbuf.st_dev == self->root_device &&\n                              stbuf.st_ino == self->root_inode);\n    }\n\n  g_autoptr(OstreeDeployment) ret_deployment\n    = ostree_deployment_new (-1, osname, treecsum, deployserial,\n                             bootcsum, treebootserial);\n  if (!load_origin (self, ret_deployment, cancellable, error))\n    return FALSE;\n\n  ret_deployment->unlocked = OSTREE_DEPLOYMENT_UNLOCKED_NONE;\n  g_autofree char *unlocked_development_path =\n    _ostree_sysroot_get_runstate_path (ret_deployment, _OSTREE_SYSROOT_DEPLOYMENT_RUNSTATE_FLAG_DEVELOPMENT);\n  struct stat stbuf;\n  if (lstat (unlocked_development_path, &stbuf) == 0)\n    ret_deployment->unlocked = OSTREE_DEPLOYMENT_UNLOCKED_DEVELOPMENT;\n  else\n    {\n      GKeyFile *origin = ostree_deployment_get_origin (ret_deployment);\n      g_autofree char *existing_unlocked_state = origin ?\n        g_key_file_get_string (origin, \"origin\", \"unlocked\", NULL) : NULL;\n\n      if (g_strcmp0 (existing_unlocked_state, \"hotfix\") == 0)\n        {\n          ret_deployment->unlocked = OSTREE_DEPLOYMENT_UNLOCKED_HOTFIX;\n        }\n      /* TODO: warn on unknown unlock types? */\n    }\n\n  g_debug (\"Deployment %s.%d unlocked=%d\", treecsum, deployserial, ret_deployment->unlocked);\n\n  if (is_booted_deployment)\n    self->booted_deployment = g_object_ref (ret_deployment);\n  if (out_deployment)\n    *out_deployment = g_steal_pointer (&ret_deployment);\n  return TRUE;\n}\n\n/* Given a bootloader config, return the value part of the ostree= kernel\n * argument.\n */\nstatic char *\nget_ostree_kernel_arg_from_config (OstreeBootconfigParser  *config)\n{\n  const char *options = ostree_bootconfig_parser_get (config, \"options\");\n  if (!options)\n    return NULL;\n\n  g_auto(GStrv) opts = g_strsplit (options, \" \", -1);\n  for (char **iter = opts; *iter; iter++)\n    {\n      const char *opt = *iter;\n      if (g_str_has_prefix (opt, \"ostree=\"))\n        return g_strdup (opt + strlen (\"ostree=\"));\n    }\n\n  return NULL;\n}\n\nstatic gboolean\nlist_deployments_process_one_boot_entry (OstreeSysroot               *self,\n                                         OstreeBootconfigParser      *config,\n                                         GPtrArray                   *inout_deployments,\n                                         GCancellable                *cancellable,\n                                         GError                     **error)\n{\n  g_autofree char *ostree_arg = get_ostree_kernel_arg_from_config (config);\n  if (ostree_arg == NULL)\n    return glnx_throw (error, \"No ostree= kernel argument found\");\n\n  g_autoptr(OstreeDeployment) deployment = NULL;\n  if (!parse_deployment (self, ostree_arg, &deployment,\n                         cancellable, error))\n    return FALSE;\n\n  ostree_deployment_set_bootconfig (deployment, config);\n\n  g_ptr_array_add (inout_deployments, g_object_ref (deployment));\n  return TRUE;\n}\n\nstatic gint\ncompare_deployments_by_boot_loader_version_reversed (gconstpointer     a_pp,\n                                                     gconstpointer     b_pp)\n{\n  OstreeDeployment *a = *((OstreeDeployment**)a_pp);\n  OstreeDeployment *b = *((OstreeDeployment**)b_pp);\n  OstreeBootconfigParser *a_bootconfig = ostree_deployment_get_bootconfig (a);\n  OstreeBootconfigParser *b_bootconfig = ostree_deployment_get_bootconfig (b);\n\n  /* Staged deployments are always first */\n  if (ostree_deployment_is_staged (a))\n    {\n      g_assert (!ostree_deployment_is_staged (b));\n      return -1;\n    }\n  else if (ostree_deployment_is_staged (b))\n    return 1;\n\n  return compare_boot_loader_configs (a_bootconfig, b_bootconfig);\n}\n\n/**\n * ostree_sysroot_load:\n * @self: Sysroot\n * @cancellable: Cancellable\n * @error: Error\n *\n * Load deployment list, bootversion, and subbootversion from the\n * rootfs @self.\n */\ngboolean\nostree_sysroot_load (OstreeSysroot  *self,\n                     GCancellable   *cancellable,\n                     GError        **error)\n{\n  return ostree_sysroot_load_if_changed (self, NULL, cancellable, error);\n}\n\nstatic gboolean\nensure_repo (OstreeSysroot  *self,\n             GError        **error)\n{\n  if (self->repo != NULL)\n    return TRUE;\n  if (!ensure_sysroot_fd (self, error))\n    return FALSE;\n  self->repo = ostree_repo_open_at (self->sysroot_fd, \"ostree/repo\", NULL, error);\n  if (!self->repo)\n    return FALSE;\n\n  /* Flag it as having been created via ostree_sysroot_get_repo(), and hold a\n   * weak ref for the remote-add handling.\n   */\n  g_weak_ref_init (&self->repo->sysroot, self);\n  self->repo->sysroot_kind = OSTREE_REPO_SYSROOT_KIND_VIA_SYSROOT;\n\n  /* Reload the repo config in case any defaults depend on knowing if this is\n   * a system repo.\n   */\n  if (!ostree_repo_reload_config (self->repo, NULL, error))\n    return FALSE;\n\n  return TRUE;\n}\n\n/**\n * ostree_sysroot_initialize:\n * @self: sysroot\n *\n * Subset of ostree_sysroot_load(); performs basic initialization. Notably, one\n * can invoke `ostree_sysroot_get_fd()` after calling this function.\n *\n * It is not necessary to call this function if ostree_sysroot_load() is\n * invoked.\n *\n * Since: 2020.1\n */\ngboolean\nostree_sysroot_initialize (OstreeSysroot  *self,\n                           GError        **error)\n{\n  if (!ensure_sysroot_fd (self, error))\n    return FALSE;\n\n  if (self->loadstate < OSTREE_SYSROOT_LOAD_STATE_INIT)\n    {\n      /* Gather some global state; first if we have the global ostree-booted flag;\n       * we'll use it to sanity check that we found a booted deployment for example.\n       * Second, we also find out whether sysroot == /.\n       */\n      if (!glnx_fstatat_allow_noent (AT_FDCWD, \"/run/ostree-booted\", NULL, 0, error))\n        return FALSE;\n      const gboolean ostree_booted = (errno == 0);\n\n      { struct stat root_stbuf;\n        if (!glnx_fstatat (AT_FDCWD, \"/\", &root_stbuf, 0, error))\n          return FALSE;\n        self->root_device = root_stbuf.st_dev;\n        self->root_inode = root_stbuf.st_ino;\n      }\n\n      struct stat self_stbuf;\n      if (!glnx_fstatat (AT_FDCWD, gs_file_get_path_cached (self->path), &self_stbuf, 0, error))\n        return FALSE;\n\n      const gboolean root_is_sysroot =\n        (self->root_device == self_stbuf.st_dev &&\n         self->root_inode == self_stbuf.st_ino);\n\n      self->root_is_ostree_booted = (ostree_booted && root_is_sysroot);\n      self->loadstate = OSTREE_SYSROOT_LOAD_STATE_INIT;\n    }\n\n  return TRUE;\n}\n\n/* Reload the staged deployment from the file in /run */\ngboolean\n_ostree_sysroot_reload_staged (OstreeSysroot *self,\n                               GError       **error)\n{\n  GLNX_AUTO_PREFIX_ERROR (\"Loading staged deployment\", error);\n  if (!self->root_is_ostree_booted)\n    return TRUE; /* Note early return */\n\n  g_assert (self->booted_deployment);\n\n  g_clear_object (&self->staged_deployment);\n  g_clear_pointer (&self->staged_deployment_data, (GDestroyNotify)g_variant_unref);\n\n  /* Read the staged state from disk */\n  glnx_autofd int fd = -1;\n  if (!ot_openat_ignore_enoent (AT_FDCWD, _OSTREE_SYSROOT_RUNSTATE_STAGED, &fd, error))\n    return FALSE;\n  if (fd != -1)\n    {\n      g_autoptr(GBytes) contents = ot_fd_readall_or_mmap (fd, 0, error);\n      if (!contents)\n        return FALSE;\n      g_autoptr(GVariant) staged_deployment_data =\n        g_variant_new_from_bytes ((GVariantType*)\"a{sv}\", contents, TRUE);\n      g_autoptr(GVariantDict) staged_deployment_dict =\n        g_variant_dict_new (staged_deployment_data);\n\n      /* Parse it */\n      g_autoptr(GVariant) target = NULL;\n      g_autofree char **kargs = NULL;\n      g_variant_dict_lookup (staged_deployment_dict, \"target\", \"@a{sv}\", &target);\n      g_variant_dict_lookup (staged_deployment_dict, \"kargs\", \"^a&s\", &kargs);\n      if (target)\n        {\n          g_autoptr(OstreeDeployment) staged =\n            _ostree_sysroot_deserialize_deployment_from_variant (target, error);\n          if (!staged)\n            return FALSE;\n\n          _ostree_deployment_set_bootconfig_from_kargs (staged, kargs);\n          if (!load_origin (self, staged, NULL, error))\n            return FALSE;\n\n          self->staged_deployment = g_steal_pointer (&staged);\n          self->staged_deployment_data = g_steal_pointer (&staged_deployment_data);\n          /* We set this flag for ostree_deployment_is_staged() because that API\n           * doesn't have access to the sysroot, which currently has the\n           * canonical \"staged_deployment\" reference.\n           */\n          self->staged_deployment->staged = TRUE;\n        }\n    }\n\n  return TRUE;\n}\n\n/**\n * ostree_sysroot_load_if_changed:\n * @self: #OstreeSysroot\n * @out_changed: (out caller-allocates):\n * @cancellable: Cancellable\n * @error: Error\n *\n * Since: 2016.4\n */\ngboolean\nostree_sysroot_load_if_changed (OstreeSysroot  *self,\n                                gboolean       *out_changed,\n                                GCancellable   *cancellable,\n                                GError        **error)\n{\n  if (!ostree_sysroot_initialize (self, error))\n    return FALSE;\n\n  /* Here we also lazily initialize the repository.  We didn't do this\n   * previous to v2017.6, but we do now to support the error-free\n   * ostree_sysroot_repo() API.\n   */\n  if (!ensure_repo (self, error))\n    return FALSE;\n\n  int bootversion = 0;\n  if (!read_current_bootversion (self, &bootversion, cancellable, error))\n    return FALSE;\n\n  int subbootversion = 0;\n  if (!_ostree_sysroot_read_current_subbootversion (self, bootversion, &subbootversion,\n                                                    cancellable, error))\n    return FALSE;\n\n  struct stat stbuf;\n  if (!glnx_fstatat (self->sysroot_fd, \"ostree/deploy\", &stbuf, 0, error))\n    return FALSE;\n\n  if (out_changed)\n    {\n      if (self->loaded_ts.tv_sec == stbuf.st_mtim.tv_sec &&\n          self->loaded_ts.tv_nsec == stbuf.st_mtim.tv_nsec)\n        {\n          *out_changed = FALSE;\n          /* Note early return */\n          return TRUE;\n        }\n    }\n\n  g_clear_pointer (&self->deployments, g_ptr_array_unref);\n  g_clear_object (&self->booted_deployment);\n  g_clear_object (&self->staged_deployment);\n  self->bootversion = -1;\n  self->subbootversion = -1;\n\n  g_autoptr(GPtrArray) boot_loader_configs = NULL;\n  if (!_ostree_sysroot_read_boot_loader_configs (self, bootversion, &boot_loader_configs,\n                                                 cancellable, error))\n    return FALSE;\n\n  g_autoptr(GPtrArray) deployments = g_ptr_array_new_with_free_func ((GDestroyNotify)g_object_unref);\n\n  g_assert (boot_loader_configs); /* Pacify static analysis */\n  for (guint i = 0; i < boot_loader_configs->len; i++)\n    {\n      OstreeBootconfigParser *config = boot_loader_configs->pdata[i];\n\n      /* Note this also sets self->booted_deployment */\n      if (!list_deployments_process_one_boot_entry (self, config, deployments,\n                                                    cancellable, error))\n        {\n          g_clear_object (&self->booted_deployment);\n          return FALSE;\n        }\n    }\n\n  if (self->root_is_ostree_booted && !self->booted_deployment)\n    {\n      if (!glnx_fstatat_allow_noent (self->sysroot_fd, \"boot/loader\", NULL, AT_SYMLINK_NOFOLLOW, error))\n        return FALSE;\n      if (errno == ENOENT)\n        {\n          return glnx_throw (error, \"Unexpected state: /run/ostree-booted found, but no /boot/loader directory\");\n        }\n      else\n        {\n          return glnx_throw (error, \"Unexpected state: /run/ostree-booted found and in / sysroot, but bootloader entry not found\");\n        }\n     }\n\n  if (!_ostree_sysroot_reload_staged (self, error))\n    return FALSE;\n\n  /* Ensure the entires are sorted */\n  g_ptr_array_sort (deployments, compare_deployments_by_boot_loader_version_reversed);\n\n  /* Staged shows up first */\n  if (self->staged_deployment)\n    g_ptr_array_insert (deployments, 0, g_object_ref (self->staged_deployment));\n\n  /* And then set their index variables */\n  for (guint i = 0; i < deployments->len; i++)\n    {\n      OstreeDeployment *deployment = deployments->pdata[i];\n      ostree_deployment_set_index (deployment, i);\n    }\n\n  /* Determine whether we're \"physical\" or not, the first time we load deployments */\n  if (self->loadstate < OSTREE_SYSROOT_LOAD_STATE_LOADED)\n    {\n      /* If we have a booted deployment, the sysroot is / and we're definitely\n       * not physical.\n       */\n      if (self->booted_deployment)\n        self->is_physical = FALSE;  /* (the default, but explicit for clarity) */\n      /* Otherwise - check for /sysroot which should only exist in a deployment,\n       * not in ${sysroot} (a metavariable for the real physical root).\n       */\n      else\n        {\n          if (!glnx_fstatat_allow_noent (self->sysroot_fd, \"sysroot\", &stbuf, 0, error))\n            return FALSE;\n          if (errno == ENOENT)\n            self->is_physical = TRUE;\n        }\n      /* Otherwise, the default is FALSE */\n\n      self->loadstate = OSTREE_SYSROOT_LOAD_STATE_LOADED;\n    }\n\n  self->bootversion = bootversion;\n  self->subbootversion = subbootversion;\n  self->deployments = deployments;\n  deployments = NULL; /* Transfer ownership */\n  self->loaded_ts = stbuf.st_mtim;\n\n  if (out_changed)\n    *out_changed = TRUE;\n  return TRUE;\n}\n\nint\nostree_sysroot_get_bootversion (OstreeSysroot   *self)\n{\n  return self->bootversion;\n}\n\nint\nostree_sysroot_get_subbootversion (OstreeSysroot   *self)\n{\n  return self->subbootversion;\n}\n\n/**\n * ostree_sysroot_get_booted_deployment:\n * @self: Sysroot\n *\n * Returns: (transfer none): The currently booted deployment, or %NULL if none\n */\nOstreeDeployment *\nostree_sysroot_get_booted_deployment (OstreeSysroot       *self)\n{\n  g_return_val_if_fail (self->loadstate == OSTREE_SYSROOT_LOAD_STATE_LOADED, NULL);\n\n  return self->booted_deployment;\n}\n\n/**\n * ostree_sysroot_get_staged_deployment:\n * @self: Sysroot\n *\n * Returns: (transfer none): The currently staged deployment, or %NULL if none\n *\n * Since: 2018.5\n */\nOstreeDeployment *\nostree_sysroot_get_staged_deployment (OstreeSysroot       *self)\n{\n  g_return_val_if_fail (self->loadstate == OSTREE_SYSROOT_LOAD_STATE_LOADED, NULL);\n\n  return self->staged_deployment;\n}\n\n/**\n * ostree_sysroot_get_deployments:\n * @self: Sysroot\n *\n * Returns: (element-type OstreeDeployment) (transfer container): Ordered list of deployments\n */\nGPtrArray *\nostree_sysroot_get_deployments (OstreeSysroot  *self)\n{\n  g_return_val_if_fail (self->loadstate == OSTREE_SYSROOT_LOAD_STATE_LOADED, NULL);\n\n  GPtrArray *copy = g_ptr_array_new_with_free_func ((GDestroyNotify)g_object_unref);\n  for (guint i = 0; i < self->deployments->len; i++)\n    g_ptr_array_add (copy, g_object_ref (self->deployments->pdata[i]));\n  return copy;\n}\n\n/**\n * ostree_sysroot_get_deployment_dirpath:\n * @self: Repo\n * @deployment: A deployment\n *\n * Note this function only returns a *relative* path - if you want\n * to access, it, you must either use fd-relative api such as openat(),\n * or concatenate it with the full ostree_sysroot_get_path().\n *\n * Returns: (transfer full): Path to deployment root directory, relative to sysroot\n */\nchar *\nostree_sysroot_get_deployment_dirpath (OstreeSysroot    *self,\n                                       OstreeDeployment *deployment)\n{\n  return g_strdup_printf (\"ostree/deploy/%s/deploy/%s.%d\",\n                          ostree_deployment_get_osname (deployment),\n                          ostree_deployment_get_csum (deployment),\n                          ostree_deployment_get_deployserial (deployment));\n}\n\n/**\n * ostree_sysroot_get_deployment_directory:\n * @self: Sysroot\n * @deployment: A deployment\n *\n * Returns: (transfer full): Path to deployment root directory\n */\nGFile *\nostree_sysroot_get_deployment_directory (OstreeSysroot    *self,\n                                         OstreeDeployment *deployment)\n{\n  g_autofree char *dirpath = ostree_sysroot_get_deployment_dirpath (self, deployment);\n  return g_file_resolve_relative_path (self->path, dirpath);\n}\n\n/**\n * ostree_sysroot_get_deployment_origin_path:\n * @deployment_path: A deployment path\n *\n * Returns: (transfer full): Path to deployment origin file\n */\nGFile *\nostree_sysroot_get_deployment_origin_path (GFile   *deployment_path)\n{\n  g_autoptr(GFile) deployment_parent = g_file_get_parent (deployment_path);\n  return ot_gfile_resolve_path_printf (deployment_parent,\n                                       \"%s.origin\",\n                                       gs_file_get_path_cached (deployment_path));\n}\n\n/**\n * ostree_sysroot_get_repo:\n * @self: Sysroot\n * @out_repo: (out) (transfer full) (optional): Repository in sysroot @self\n * @cancellable: Cancellable\n * @error: Error\n *\n * Retrieve the OSTree repository in sysroot @self. The repo is guaranteed to be open\n * (see ostree_repo_open()).\n *\n * Returns: %TRUE on success, %FALSE otherwise\n */\ngboolean\nostree_sysroot_get_repo (OstreeSysroot         *self,\n                         OstreeRepo   **out_repo,\n                         GCancellable  *cancellable,\n                         GError       **error)\n{\n  if (!ensure_repo (self, error))\n    return FALSE;\n  if (out_repo != NULL)\n    *out_repo = g_object_ref (self->repo);\n  return TRUE;\n}\n\n/**\n * ostree_sysroot_repo:\n * @self: Sysroot\n *\n * This function is a variant of ostree_sysroot_get_repo() that cannot fail, and\n * returns a cached repository. Can only be called after ostree_sysroot_initialize()\n * or ostree_sysroot_load() has been invoked successfully.\n *\n * Returns: (transfer none): The OSTree repository in sysroot @self.\n *\n * Since: 2017.7\n */\nOstreeRepo *\nostree_sysroot_repo (OstreeSysroot *self)\n{\n  g_return_val_if_fail (self->loadstate >= OSTREE_SYSROOT_LOAD_STATE_LOADED, NULL);\n  g_assert (self->repo);\n  return self->repo;\n}\n\n/**\n * ostree_sysroot_query_bootloader:\n * @sysroot: Sysroot\n * @out_bootloader: (out) (transfer full) (allow-none): Return location for bootloader, may be %NULL\n * @cancellable: Cancellable\n * @error: Error\n */\ngboolean\n_ostree_sysroot_query_bootloader (OstreeSysroot     *sysroot,\n                                  OstreeBootloader **out_bootloader,\n                                  GCancellable      *cancellable,\n                                  GError           **error)\n{\n  gboolean is_active;\n  g_autoptr(OstreeBootloader) ret_loader =\n    (OstreeBootloader*)_ostree_bootloader_syslinux_new (sysroot);\n  if (!_ostree_bootloader_query (ret_loader, &is_active,\n                                 cancellable, error))\n    return FALSE;\n\n  if (!is_active)\n    {\n      g_object_unref (ret_loader);\n      ret_loader = (OstreeBootloader*)_ostree_bootloader_grub2_new (sysroot);\n      if (!_ostree_bootloader_query (ret_loader, &is_active,\n                                     cancellable, error))\n        return FALSE;\n    }\n  if (!is_active)\n    {\n      g_object_unref (ret_loader);\n      ret_loader = (OstreeBootloader*)_ostree_bootloader_uboot_new (sysroot);\n      if (!_ostree_bootloader_query (ret_loader, &is_active, cancellable, error))\n        return FALSE;\n    }\n  if (!is_active)\n    g_clear_object (&ret_loader);\n\n  ot_transfer_out_value(out_bootloader, &ret_loader);\n  return TRUE;\n}\n\nchar *\n_ostree_sysroot_join_lines (GPtrArray  *lines)\n{\n  GString *buf = g_string_new (\"\");\n  gboolean prev_was_empty = FALSE;\n\n  for (guint i = 0; i < lines->len; i++)\n    {\n      const char *line = lines->pdata[i];\n      /* Special bit to remove extraneous empty lines */\n      if (*line == '\\0')\n        {\n          if (prev_was_empty || i == 0)\n            continue;\n          else\n            prev_was_empty = TRUE;\n        }\n      g_string_append (buf, line);\n      g_string_append_c (buf, '\\n');\n    }\n  return g_string_free (buf, FALSE);\n}\n\n/**\n * ostree_sysroot_query_deployments_for:\n * @self: Sysroot\n * @osname: (allow-none): \"stateroot\" name\n * @out_pending: (out) (allow-none) (transfer full): The pending deployment\n * @out_rollback: (out) (allow-none) (transfer full): The rollback deployment\n *\n * Find the pending and rollback deployments for @osname. Pass %NULL for @osname\n * to use the booted deployment's osname. By default, pending deployment is the\n * first deployment in the order that matches @osname, and @rollback will be the\n * next one after the booted deployment, or the deployment after the pending if\n * we're not looking at the booted deployment.\n *\n * Since: 2017.7\n */\nvoid\nostree_sysroot_query_deployments_for (OstreeSysroot     *self,\n                                      const char        *osname,\n                                      OstreeDeployment  **out_pending,\n                                      OstreeDeployment  **out_rollback)\n{\n  g_return_if_fail (osname != NULL || self->booted_deployment != NULL);\n  g_autoptr(OstreeDeployment) ret_pending = NULL;\n  g_autoptr(OstreeDeployment) ret_rollback = NULL;\n\n  if (osname == NULL)\n    osname = ostree_deployment_get_osname (self->booted_deployment);\n\n  gboolean found_booted = FALSE;\n  for (guint i = 0; i < self->deployments->len; i++)\n    {\n      OstreeDeployment *deployment = self->deployments->pdata[i];\n\n      /* Ignore deployments not for this osname */\n      if (strcmp (ostree_deployment_get_osname (deployment), osname) != 0)\n          continue;\n\n      /* Is this deployment booted?  If so, note we're past the booted */\n      if (self->booted_deployment != NULL &&\n          ostree_deployment_equal (deployment, self->booted_deployment))\n        {\n          found_booted = TRUE;\n          continue;\n        }\n\n      if (!found_booted && !ret_pending)\n        ret_pending = g_object_ref (deployment);\n      else if (found_booted && !ret_rollback)\n        ret_rollback = g_object_ref (deployment);\n    }\n  if (out_pending)\n    *out_pending = g_steal_pointer (&ret_pending);\n  if (out_rollback)\n    *out_rollback = g_steal_pointer (&ret_rollback);\n}\n\n\n/**\n * ostree_sysroot_get_merge_deployment:\n * @self: Sysroot\n * @osname: (allow-none): Operating system group\n *\n * Find the deployment to use as a configuration merge source; this is\n * the first one in the current deployment list which matches osname.\n *\n * Returns: (transfer full): Configuration merge deployment\n */\nOstreeDeployment *\nostree_sysroot_get_merge_deployment (OstreeSysroot     *self,\n                                     const char        *osname)\n{\n  g_return_val_if_fail (osname != NULL || self->booted_deployment != NULL, NULL);\n\n  if (osname == NULL)\n    osname = ostree_deployment_get_osname (self->booted_deployment);\n\n  /* If we're booted into the OS into which we're deploying, then\n   * merge the currently *booted* configuration, rather than the most\n   * recently deployed.\n   */\n  if (self->booted_deployment &&\n      g_strcmp0 (ostree_deployment_get_osname (self->booted_deployment), osname) == 0)\n      return g_object_ref (self->booted_deployment);\n  else\n    {\n      g_autoptr(OstreeDeployment) pending = NULL;\n      ostree_sysroot_query_deployments_for (self, osname, &pending, NULL);\n      return g_steal_pointer (&pending);\n    }\n}\n\n/**\n * ostree_sysroot_origin_new_from_refspec:\n * @self: Sysroot\n * @refspec: A refspec\n *\n * Returns: (transfer full): A new config file which sets @refspec as an origin\n */\nGKeyFile *\nostree_sysroot_origin_new_from_refspec (OstreeSysroot  *self,\n                                        const char     *refspec)\n{\n  GKeyFile *ret = g_key_file_new ();\n  g_key_file_set_string (ret, \"origin\", \"refspec\", refspec);\n  return ret;\n}\n\n/**\n * ostree_sysroot_lock:\n * @self: Self\n * @error: Error\n *\n * Acquire an exclusive multi-process write lock for @self.  This call\n * blocks until the lock has been acquired.  The lock is not\n * reentrant.\n *\n * Release the lock with ostree_sysroot_unlock().  The lock will also\n * be released if @self is deallocated.\n */\ngboolean\nostree_sysroot_lock (OstreeSysroot     *self,\n                     GError           **error)\n{\n  if (!ensure_sysroot_fd (self, error))\n    return FALSE;\n\n  if (!_ostree_sysroot_ensure_writable (self, error))\n    return FALSE;\n\n  return glnx_make_lock_file (self->sysroot_fd, OSTREE_SYSROOT_LOCKFILE,\n                              LOCK_EX, &self->lock, error);\n}\n\n/**\n * ostree_sysroot_try_lock:\n * @self: Self\n * @out_acquired: (out): Whether or not the lock has been acquired\n * @error: Error\n *\n * Try to acquire an exclusive multi-process write lock for @self.  If\n * another process holds the lock, this function will return\n * immediately, setting @out_acquired to %FALSE, and returning %TRUE\n * (and no error).\n *\n * Release the lock with ostree_sysroot_unlock().  The lock will also\n * be released if @self is deallocated.\n */\ngboolean\nostree_sysroot_try_lock (OstreeSysroot         *self,\n                         gboolean              *out_acquired,\n                         GError               **error)\n{\n  if (!ensure_sysroot_fd (self, error))\n    return FALSE;\n\n  if (!_ostree_sysroot_ensure_writable (self, error))\n    return FALSE;\n\n  /* Note use of LOCK_NB */\n  g_autoptr(GError) local_error = NULL;\n  if (!glnx_make_lock_file (self->sysroot_fd, OSTREE_SYSROOT_LOCKFILE,\n                            LOCK_EX | LOCK_NB, &self->lock, &local_error))\n    {\n      if (g_error_matches (local_error, G_IO_ERROR, G_IO_ERROR_WOULD_BLOCK))\n        {\n          *out_acquired = FALSE;\n        }\n      else\n        {\n          g_propagate_error (error, g_steal_pointer (&local_error));\n          return FALSE;\n        }\n    }\n  else\n    {\n      *out_acquired = TRUE;\n    }\n\n  return TRUE;\n}\n\n/**\n * ostree_sysroot_unlock:\n * @self: Self\n *\n * Clear the lock previously acquired with ostree_sysroot_lock().  It\n * is safe to call this function if the lock has not been previously\n * acquired.\n */\nvoid\nostree_sysroot_unlock (OstreeSysroot  *self)\n{\n  glnx_release_lock_file (&self->lock);\n}\n\nstatic void\nlock_in_thread (GTask            *task,\n                gpointer          source,\n                gpointer          task_data,\n                GCancellable     *cancellable)\n{\n  GError *local_error = NULL;\n  OstreeSysroot *self = source;\n\n  if (!ostree_sysroot_lock (self, &local_error))\n    goto out;\n\n  if (g_cancellable_set_error_if_cancelled (cancellable, &local_error))\n    ostree_sysroot_unlock (self);\n\n out:\n  if (local_error)\n    g_task_return_error (task, local_error);\n  else\n    g_task_return_boolean (task, TRUE);\n}\n\n/**\n * ostree_sysroot_lock_async:\n * @self: Self\n * @cancellable: Cancellable\n * @callback: Callback\n * @user_data: User data\n *\n * An asynchronous version of ostree_sysroot_lock().\n */\nvoid\nostree_sysroot_lock_async (OstreeSysroot         *self,\n                           GCancellable          *cancellable,\n                           GAsyncReadyCallback    callback,\n                           gpointer               user_data)\n{\n  g_autoptr(GTask) task = g_task_new (self, cancellable, callback, user_data);\n  g_task_run_in_thread (task, lock_in_thread);\n}\n\n/**\n * ostree_sysroot_lock_finish:\n * @self: Self\n * @result: Result\n * @error: Error\n *\n * Call when ostree_sysroot_lock_async() is ready.\n */\ngboolean\nostree_sysroot_lock_finish (OstreeSysroot         *self,\n                            GAsyncResult          *result,\n                            GError               **error)\n{\n  g_return_val_if_fail (g_task_is_valid (result, self), FALSE);\n  return g_task_propagate_boolean ((GTask*)result, error);\n}\n\n/**\n * ostree_sysroot_init_osname:\n * @self: Sysroot\n * @osname: Name group of operating system checkouts\n * @cancellable: Cancellable\n * @error: Error\n *\n * Initialize the directory structure for an \"osname\", which is a\n * group of operating system deployments, with a shared `/var`.  One\n * is required for generating a deployment.\n *\n * Since: 2016.4\n */\ngboolean\nostree_sysroot_init_osname (OstreeSysroot       *self,\n                            const char          *osname,\n                            GCancellable        *cancellable,\n                            GError             **error)\n{\n  if (!_ostree_sysroot_ensure_writable (self, error))\n    return FALSE;\n\n  const char *deploydir = glnx_strjoina (\"ostree/deploy/\", osname);\n  if (mkdirat (self->sysroot_fd, deploydir, 0777) < 0)\n    return glnx_throw_errno_prefix (error, \"Creating %s\", deploydir);\n\n  glnx_autofd int dfd = -1;\n  if (!glnx_opendirat (self->sysroot_fd, deploydir, TRUE, &dfd, error))\n    return FALSE;\n\n  if (mkdirat (dfd, \"var\", 0777) < 0)\n    return glnx_throw_errno_prefix (error, \"Creating %s\", \"var\");\n\n  /* This is a bit of a legacy hack...but we have to keep it around\n   * now.  We're ensuring core subdirectories of /var exist.\n   */\n  if (mkdirat (dfd, \"var/tmp\", 0777) < 0)\n    return glnx_throw_errno_prefix (error, \"Creating %s\", \"var/tmp\");\n\n  if (fchmodat (dfd, \"var/tmp\", 01777, 0) < 0)\n    return glnx_throw_errno_prefix (error, \"fchmod %s\", \"var/tmp\");\n\n  if (mkdirat (dfd, \"var/lib\", 0777) < 0)\n    return glnx_throw_errno_prefix (error, \"Creating %s\", \"var/tmp\");\n\n  /* This needs to be available and properly labeled early during the boot\n   * process (before tmpfiles.d kicks in), so that journald can flush logs from\n   * the first boot there. https://bugzilla.redhat.com/show_bug.cgi?id=1265295\n   * */\n  if (mkdirat (dfd, \"var/log\", 0755) < 0)\n    return glnx_throw_errno_prefix (error, \"Creating %s\", \"var/log\");\n\n  if (symlinkat (\"../run\", dfd, \"var/run\") < 0)\n    return glnx_throw_errno_prefix (error, \"Symlinking %s\", \"var/run\");\n\n  if (symlinkat (\"../run/lock\", dfd, \"var/lock\") < 0)\n    return glnx_throw_errno_prefix (error, \"Symlinking %s\", \"var/lock\");\n\n  if (!_ostree_sysroot_bump_mtime (self, error))\n    return FALSE;\n\n  return TRUE;\n}\n\n/**\n * ostree_sysroot_simple_write_deployment:\n * @sysroot: Sysroot\n * @osname: (allow-none): OS name\n * @new_deployment: Prepend this deployment to the list\n * @merge_deployment: (allow-none): Use this deployment for configuration merge\n * @flags: Flags controlling behavior\n * @cancellable: Cancellable\n * @error: Error\n *\n * Prepend @new_deployment to the list of deployments, commit, and\n * cleanup.  By default, all other deployments for the given @osname\n * except the merge deployment and the booted deployment will be\n * garbage collected.\n *\n * If %OSTREE_SYSROOT_SIMPLE_WRITE_DEPLOYMENT_FLAGS_RETAIN is\n * specified, then all current deployments will be kept.\n *\n * If %OSTREE_SYSROOT_SIMPLE_WRITE_DEPLOYMENT_FLAGS_RETAIN_PENDING is\n * specified, then pending deployments will be kept.\n *\n * If %OSTREE_SYSROOT_SIMPLE_WRITE_DEPLOYMENT_FLAGS_RETAIN_ROLLBACK is\n * specified, then rollback deployments will be kept.\n *\n * If %OSTREE_SYSROOT_SIMPLE_WRITE_DEPLOYMENT_FLAGS_NOT_DEFAULT is\n * specified, then instead of prepending, the new deployment will be\n * added right after the booted or merge deployment, instead of first.\n *\n * If %OSTREE_SYSROOT_SIMPLE_WRITE_DEPLOYMENT_FLAGS_NO_CLEAN is\n * specified, then no cleanup will be performed after adding the\n * deployment. Make sure to call ostree_sysroot_cleanup() sometime\n * later, instead.\n */\ngboolean\nostree_sysroot_simple_write_deployment (OstreeSysroot      *sysroot,\n                                        const char         *osname,\n                                        OstreeDeployment   *new_deployment,\n                                        OstreeDeployment   *merge_deployment,\n                                        OstreeSysrootSimpleWriteDeploymentFlags flags,\n                                        GCancellable       *cancellable,\n                                        GError            **error)\n{\n  const gboolean postclean =\n    (flags & OSTREE_SYSROOT_SIMPLE_WRITE_DEPLOYMENT_FLAGS_NO_CLEAN) == 0;\n  const gboolean make_default =\n    !((flags & OSTREE_SYSROOT_SIMPLE_WRITE_DEPLOYMENT_FLAGS_NOT_DEFAULT) > 0);\n  const gboolean retain_pending =\n    (flags & OSTREE_SYSROOT_SIMPLE_WRITE_DEPLOYMENT_FLAGS_RETAIN_PENDING) > 0;\n  const gboolean retain_rollback =\n    (flags & OSTREE_SYSROOT_SIMPLE_WRITE_DEPLOYMENT_FLAGS_RETAIN_ROLLBACK) > 0;\n  gboolean retain =\n    (flags & OSTREE_SYSROOT_SIMPLE_WRITE_DEPLOYMENT_FLAGS_RETAIN) > 0;\n\n  g_autoptr(GPtrArray) deployments = ostree_sysroot_get_deployments (sysroot);\n  OstreeDeployment *booted_deployment = ostree_sysroot_get_booted_deployment (sysroot);\n\n  if (osname == NULL && booted_deployment)\n    osname = ostree_deployment_get_osname (booted_deployment);\n\n  gboolean added_new = FALSE;\n  g_autoptr(GPtrArray) new_deployments = g_ptr_array_new_with_free_func (g_object_unref);\n  if (make_default)\n    {\n      g_ptr_array_add (new_deployments, g_object_ref (new_deployment));\n      added_new = TRUE;\n    }\n\n  /* without a booted and a merge deployment, retain_pending/rollback become meaningless;\n   * let's just retain all deployments in that case */\n  if (!booted_deployment && !merge_deployment && (retain_pending || retain_rollback))\n    retain = TRUE;\n\n  /* tracks when we come across the booted deployment */\n  gboolean before_booted = TRUE;\n  gboolean before_merge = TRUE;\n  for (guint i = 0; i < deployments->len; i++)\n    {\n      OstreeDeployment *deployment = deployments->pdata[i];\n      const gboolean osname_matches =\n        (osname == NULL || g_str_equal (ostree_deployment_get_osname (deployment), osname));\n      const gboolean is_booted = ostree_deployment_equal (deployment, booted_deployment);\n      const gboolean is_merge = ostree_deployment_equal (deployment, merge_deployment);\n\n      if (is_booted)\n        before_booted = FALSE;\n      if (is_merge)\n        before_merge = FALSE;\n\n      /* use the booted deployment as the \"crossover\" point between pending and rollback\n       * deployments, fall back on merge deployment */\n      const gboolean passed_crossover = booted_deployment ? !before_booted : !before_merge;\n\n      /* Retain deployment if:\n       *   - we're explicitly asked to, or\n       *   - it's pinned\n       *   - the deployment is for another osname, or\n       *   - we're keeping pending deployments and this is a pending deployment, or\n       *   - this is the merge or boot deployment, or\n       *   - we're keeping rollback deployments and this is a rollback deployment\n       */\n      if (retain\n          || ostree_deployment_is_pinned (deployment)\n          || !osname_matches\n          || (retain_pending && !passed_crossover)\n          || (is_booted || is_merge)\n          || (retain_rollback && passed_crossover))\n        g_ptr_array_add (new_deployments, g_object_ref (deployment));\n\n      /* add right after booted/merge deployment */\n      if (!added_new && passed_crossover)\n        {\n          g_ptr_array_add (new_deployments, g_object_ref (new_deployment));\n          added_new = TRUE;\n        }\n    }\n\n  /* add it last if no crossover defined (or it's the first deployment in the sysroot) */\n  if (!added_new)\n    g_ptr_array_add (new_deployments, g_object_ref (new_deployment));\n\n  OstreeSysrootWriteDeploymentsOpts write_opts = { .do_postclean = postclean };\n  if (!ostree_sysroot_write_deployments_with_options (sysroot, new_deployments, &write_opts,\n                                                      cancellable, error))\n    return FALSE;\n\n  return TRUE;\n}\n\n/* Deploy a copy of @target_deployment */\nstatic gboolean\nclone_deployment (OstreeSysroot  *sysroot,\n                  OstreeDeployment *target_deployment,\n                  OstreeDeployment *merge_deployment,\n                  GCancellable *cancellable,\n                  GError **error)\n{\n  /* Ensure we have a clean slate */\n  if (!ostree_sysroot_prepare_cleanup (sysroot, cancellable, error))\n    return glnx_prefix_error (error, \"Performing initial cleanup\");\n\n  /* Copy the bootloader config options */\n  OstreeBootconfigParser *bootconfig = ostree_deployment_get_bootconfig (merge_deployment);\n  g_auto(GStrv) previous_args = g_strsplit (ostree_bootconfig_parser_get (bootconfig, \"options\"), \" \", -1);\n  g_autoptr(OstreeKernelArgs) kargs = ostree_kernel_args_new ();\n  ostree_kernel_args_append_argv (kargs, previous_args);\n\n  /* Deploy the copy */\n  g_autoptr(OstreeDeployment) new_deployment = NULL;\n  g_auto(GStrv) kargs_strv = ostree_kernel_args_to_strv (kargs);\n  if (!ostree_sysroot_deploy_tree (sysroot,\n                                   ostree_deployment_get_osname (target_deployment),\n                                   ostree_deployment_get_csum (target_deployment),\n                                   ostree_deployment_get_origin (target_deployment),\n                                   merge_deployment, kargs_strv, &new_deployment,\n                                   cancellable, error))\n    return FALSE;\n\n  /* Hotfixes push the deployment as rollback target, so it shouldn't\n   * be the default.\n   */\n  if (!ostree_sysroot_simple_write_deployment (sysroot, ostree_deployment_get_osname (target_deployment),\n                                               new_deployment, merge_deployment,\n                                               OSTREE_SYSROOT_SIMPLE_WRITE_DEPLOYMENT_FLAGS_NOT_DEFAULT,\n                                               cancellable, error))\n    return FALSE;\n\n  return TRUE;\n}\n\n/* Do `mkdir()` followed by `chmod()` immediately afterwards to ensure `umask()` isn't\n * masking permissions where we don't want it to. Thus we avoid calling `umask()`, which\n * would affect the whole process. */\nstatic gboolean mkdir_unmasked (int                   dfd,\n                                const char           *path,\n                                int                   mode,\n                                GCancellable         *cancellable,\n                                GError              **error)\n{\n  if (!glnx_shutil_mkdir_p_at (dfd, path, mode, cancellable, error))\n    return FALSE;\n  if (fchmodat (dfd, path, mode, 0) < 0)\n    return glnx_throw_errno_prefix (error, \"chmod(%s)\", path);\n  return TRUE;\n}\n\n/**\n * ostree_sysroot_deployment_unlock:\n * @self: Sysroot\n * @deployment: Deployment\n * @unlocked_state: Transition to this unlocked state\n * @cancellable: Cancellable\n * @error: Error\n *\n * Configure the target deployment @deployment such that it\n * is writable.  There are multiple modes, essentially differing\n * in whether or not any changes persist across reboot.\n *\n * The `OSTREE_DEPLOYMENT_UNLOCKED_HOTFIX` state is persistent\n * across reboots.\n *\n * Since: 2016.4\n */\ngboolean\nostree_sysroot_deployment_unlock (OstreeSysroot     *self,\n                                  OstreeDeployment  *deployment,\n                                  OstreeDeploymentUnlockedState unlocked_state,\n                                  GCancellable      *cancellable,\n                                  GError           **error)\n{\n  /* This function cannot re-lock */\n  g_return_val_if_fail (unlocked_state != OSTREE_DEPLOYMENT_UNLOCKED_NONE, FALSE);\n\n  OstreeDeploymentUnlockedState current_unlocked = ostree_deployment_get_unlocked (deployment);\n  if (current_unlocked != OSTREE_DEPLOYMENT_UNLOCKED_NONE)\n    return glnx_throw (error, \"Deployment is already in unlocked state: %s\",\n                       ostree_deployment_unlocked_state_to_string (current_unlocked));\n\n  g_autoptr(OstreeDeployment) merge_deployment =\n    ostree_sysroot_get_merge_deployment (self, ostree_deployment_get_osname (deployment));\n  if (!merge_deployment)\n    return glnx_throw (error, \"No previous deployment to duplicate\");\n\n  /* For hotfixes, we push a rollback target */\n  if (unlocked_state == OSTREE_DEPLOYMENT_UNLOCKED_HOTFIX)\n    {\n      if (!clone_deployment (self, deployment, merge_deployment, cancellable, error))\n        return FALSE;\n    }\n\n  /* Crack it open */\n  if (!ostree_sysroot_deployment_set_mutable (self, deployment, TRUE,\n                                              cancellable, error))\n    return FALSE;\n\n  g_autofree char *deployment_path = ostree_sysroot_get_deployment_dirpath (self, deployment);\n  glnx_autofd int deployment_dfd = -1;\n  if (!glnx_opendirat (self->sysroot_fd, deployment_path, TRUE, &deployment_dfd, error))\n    return FALSE;\n\n  g_autoptr(OstreeSePolicy) sepolicy = ostree_sepolicy_new_at (deployment_dfd, cancellable, error);\n  if (!sepolicy)\n    return FALSE;\n\n  /* we want our /usr overlay to have the same permission bits as the one we'll shadow */\n  mode_t usr_mode;\n  { struct stat stbuf;\n    if (!glnx_fstatat (deployment_dfd, \"usr\", &stbuf, 0, error))\n      return FALSE;\n    usr_mode = stbuf.st_mode;\n  }\n\n  const char *ovl_options = NULL;\n  static const char hotfix_ovl_options[] = \"lowerdir=usr,upperdir=.usr-ovl-upper,workdir=.usr-ovl-work\";\n  switch (unlocked_state)\n    {\n    case OSTREE_DEPLOYMENT_UNLOCKED_NONE:\n      g_assert_not_reached ();\n      break;\n    case OSTREE_DEPLOYMENT_UNLOCKED_HOTFIX:\n      {\n        /* Create the overlayfs directories in the deployment root\n         * directly for hotfixes.  The ostree-prepare-root.c helper\n         * is also set up to detect and mount these.\n         */\n        if (!mkdir_unmasked (deployment_dfd, \".usr-ovl-upper\", usr_mode, cancellable, error))\n          return FALSE;\n        if (!mkdir_unmasked (deployment_dfd, \".usr-ovl-work\", usr_mode, cancellable, error))\n          return FALSE;\n        ovl_options = hotfix_ovl_options;\n      }\n      break;\n    case OSTREE_DEPLOYMENT_UNLOCKED_DEVELOPMENT:\n      {\n        /* We're just doing transient development/hacking?  Okay,\n         * stick the overlayfs bits in /var/tmp.\n         */\n        char *development_ovldir = strdupa (\"/var/tmp/ostree-unlock-ovl.XXXXXX\");\n        const char *development_ovl_upper;\n        const char *development_ovl_work;\n\n        /* Ensure that the directory is created with the same label as `/usr` */\n        { g_auto(OstreeSepolicyFsCreatecon) con = { 0, };\n\n          if (!_ostree_sepolicy_preparefscreatecon (&con, sepolicy,\n                                                    \"/usr\", usr_mode, error))\n            return FALSE;\n\n          if (g_mkdtemp_full (development_ovldir, 0755) == NULL)\n            return glnx_throw_errno_prefix (error, \"mkdtemp\");\n        }\n\n        development_ovl_upper = glnx_strjoina (development_ovldir, \"/upper\");\n        if (!mkdir_unmasked (AT_FDCWD, development_ovl_upper, usr_mode, cancellable, error))\n          return FALSE;\n        development_ovl_work = glnx_strjoina (development_ovldir, \"/work\");\n        if (!mkdir_unmasked (AT_FDCWD, development_ovl_work, usr_mode, cancellable, error))\n          return FALSE;\n        ovl_options = glnx_strjoina (\"lowerdir=usr,upperdir=\", development_ovl_upper,\n                                     \",workdir=\", development_ovl_work);\n      }\n    }\n\n  g_assert (ovl_options != NULL);\n\n  /* Here we run `mount()` in a fork()ed child because we need to use\n   * `chdir()` in order to have the mount path options to overlayfs not\n   * look ugly.\n   *\n   * We can't `chdir()` inside a shared library since there may be\n   * threads, etc.\n   */\n  {\n    pid_t mount_child = fork ();\n    if (mount_child < 0)\n      return glnx_throw_errno_prefix (error, \"fork\");\n    else if (mount_child == 0)\n      {\n        /* Child process. Do NOT use any GLib API here; it's not generally fork() safe.\n         *\n         * TODO: report errors across a pipe (or use the journal?) rather than\n         * spewing to stderr.\n         */\n        if (fchdir (deployment_dfd) < 0)\n          err (1, \"fchdir\");\n        if (mount (\"overlay\", \"/usr\", \"overlay\", 0, ovl_options) < 0)\n          err (1, \"mount\");\n        exit (EXIT_SUCCESS);\n      }\n    else\n      {\n        /* Parent */\n        int estatus;\n\n        if (TEMP_FAILURE_RETRY (waitpid (mount_child, &estatus, 0)) < 0)\n          return glnx_throw_errno_prefix (error, \"waitpid() on mount helper\");\n        if (!g_spawn_check_exit_status (estatus, error))\n          return glnx_prefix_error (error, \"Failed overlayfs mount\");\n      }\n  }\n\n  g_autoptr(OstreeDeployment) deployment_clone = ostree_deployment_clone (deployment);\n  GKeyFile *origin_clone = ostree_deployment_get_origin (deployment_clone);\n\n  /* Now, write out the flag saying what we did */\n  switch (unlocked_state)\n    {\n    case OSTREE_DEPLOYMENT_UNLOCKED_NONE:\n      g_assert_not_reached ();\n      break;\n    case OSTREE_DEPLOYMENT_UNLOCKED_HOTFIX:\n      g_key_file_set_string (origin_clone, \"origin\", \"unlocked\",\n                             ostree_deployment_unlocked_state_to_string (unlocked_state));\n      if (!ostree_sysroot_write_origin_file (self, deployment, origin_clone,\n                                             cancellable, error))\n        return FALSE;\n      break;\n    case OSTREE_DEPLOYMENT_UNLOCKED_DEVELOPMENT:\n      {\n        g_autofree char *devpath =\n          _ostree_sysroot_get_runstate_path (deployment, _OSTREE_SYSROOT_DEPLOYMENT_RUNSTATE_FLAG_DEVELOPMENT);\n        g_autofree char *devpath_parent = dirname (g_strdup (devpath));\n\n        if (!glnx_shutil_mkdir_p_at (AT_FDCWD, devpath_parent, 0755, cancellable, error))\n          return FALSE;\n\n        if (!g_file_set_contents (devpath, \"\", 0, error))\n          return FALSE;\n      }\n    }\n\n  /* For hotfixes we already pushed a rollback which will bump the\n   * mtime, but we need to bump it again so that clients get the state\n   * change for this deployment.  For development we need to do this\n   * regardless.\n   */\n  if (!_ostree_sysroot_bump_mtime (self, error))\n    return FALSE;\n\n  return TRUE;\n}\n\n/**\n * ostree_sysroot_deployment_set_pinned:\n * @self: Sysroot\n * @deployment: A deployment\n * @is_pinned: Whether or not deployment will be automatically GC'd\n * @error: Error\n *\n * By default, deployments may be subject to garbage collection. Typical uses of\n * libostree only retain at most 2 deployments. If @is_pinned is `TRUE`, a\n * metadata bit will be set causing libostree to avoid automatic GC of the\n * deployment. However, this is really an \"advisory\" note; it's still possible\n * for e.g. older versions of libostree unaware of pinning to GC the deployment.\n *\n * This function does nothing and returns successfully if the deployment\n * is already in the desired pinning state.  It is an error to try to pin\n * the staged deployment (as it's not in the bootloader entries).\n *\n * Since: 2018.3\n */\ngboolean\nostree_sysroot_deployment_set_pinned (OstreeSysroot     *self,\n                                      OstreeDeployment  *deployment,\n                                      gboolean           is_pinned,\n                                      GError           **error)\n{\n  const gboolean current_pin = ostree_deployment_is_pinned (deployment);\n  if (is_pinned == current_pin)\n    return TRUE;\n\n  if (ostree_deployment_is_staged (deployment))\n    return glnx_throw (error, \"Cannot pin staged deployment\");\n\n  g_autoptr(OstreeDeployment) deployment_clone = ostree_deployment_clone (deployment);\n  GKeyFile *origin_clone = ostree_deployment_get_origin (deployment_clone);\n\n  if (is_pinned)\n    g_key_file_set_boolean (origin_clone, OSTREE_ORIGIN_TRANSIENT_GROUP, \"pinned\", TRUE);\n  else\n    g_key_file_remove_key (origin_clone, OSTREE_ORIGIN_TRANSIENT_GROUP, \"pinned\", NULL);\n\n  if (!ostree_sysroot_write_origin_file (self, deployment, origin_clone, NULL, error))\n    return FALSE;\n\n  return TRUE;\n}\n", "idx": 1, "id": 17763, "msg": "Minor: how about prefixing with `found /run/ostree-live`?", "proj": "ostreedev-ostree", "lang": "c"}
{"patch": "@@ -144,6 +144,7 @@ FactoryGirl.define do\n     name 'Test User'\n     association :purchaseable, factory: :product\n     variant 'individual'\n+    billing_email 'billing@example.com'\n \n     trait :free do\n       paid_price 0", "y": 1, "oldf": "FactoryGirl.define do\n  sequence :code do |n|\n    \"code#{n}\"\n  end\n\n  sequence :email do |n|\n    \"user#{n}@example.com\"\n  end\n\n  sequence :name do |n|\n    \"name #{n}\"\n  end\n\n  sequence :title do |n|\n    \"title #{n}\"\n  end\n\n  sequence :external_url do |n|\n    \"http://robots.thoughtbot.com/#{n}\"\n  end\n\n  sequence :tumblr_user_name do |n|\n    \"user#{n}\"\n  end\n\n  factory :alternate do\n    ignore do\n      key 'online_workshop'\n      offering { build(:workshop) }\n    end\n\n    initialize_with { new(key, offering) }\n  end\n\n  factory :announcement do\n    association :announceable, factory: :book_product\n    ends_at { Time.now.tomorrow }\n    message 'Foo: http://example.com'\n  end\n\n  factory :article do\n    body_html 'article body'\n    published_on Date.today\n    title\n\n    factory :tumblr_article do\n      external_url\n    end\n  end\n\n  factory :classification do\n    association :classifiable, factory: :article\n    topic\n  end\n\n  factory :coupon do\n    amount 10\n    code\n    discount_type 'percentage'\n\n    factory :one_time_coupon do\n      one_time_use_only true\n    end\n  end\n\n  factory :workshop do\n    description 'Solve 8-Queens over and over again'\n    maximum_students 12\n    name { generate(:name) }\n    individual_price '500'\n    company_price '10000'\n    short_description 'Solve 8-Queens'\n    start_at '9:00'\n    stop_at '17:00'\n\n    factory :private_workshop do\n      active false\n    end\n\n    factory :in_person_workshop do\n      online false\n    end\n\n    factory :online_workshop do\n      online true\n    end\n  end\n\n  factory :download\n\n  factory :follow_up do\n    email\n    workshop\n  end\n\n  factory :question do\n    answer 'Not much, bro.'\n    question \"What's up, buddy?\"\n    workshop\n  end\n\n  factory :product, traits: [:active] do\n    trait :active do\n      active true\n    end\n\n    trait :inactive do\n      active false\n    end\n\n    company_price 50\n    fulfillment_method 'fetch'\n    individual_price 15\n    name { generate(:name) }\n    sku 'TEST'\n    product_type 'test'\n\n    factory :book_product do\n      product_type 'book'\n    end\n\n    factory :github_book_product do\n      product_type 'book'\n      github_team 9999\n      fulfillment_method 'github'\n      github_url 'http://github.com/thoughtbot/book-repo'\n    end\n\n    factory :video_product do\n      product_type 'video'\n    end\n\n    factory :workshop_product do\n      product_type 'workshop'\n    end\n\n    factory :subscribeable_product do\n      product_type 'subscription'\n    end\n  end\n\n  factory :purchase, aliases: [:individual_purchase] do\n    email 'joe@example.com'\n    name 'Test User'\n    association :purchaseable, factory: :product\n    variant 'individual'\n\n    trait :free do\n      paid_price 0\n      payment_method 'free'\n    end\n\n    factory :paid_purchase do\n      paid true\n    end\n\n    factory :unpaid_purchase do\n      paid false\n\n      after(:create) do |purchase|\n        purchase.paid = false\n        purchase.save!\n      end\n    end\n\n    factory :stripe_purchase do\n      payment_method 'stripe'\n    end\n\n    factory :free_purchase, traits: [:free]\n\n    factory :section_purchase do\n      association :purchaseable, factory: :section\n\n      factory :in_person_section_purchase do\n        association :purchaseable, factory: :in_person_section\n      end\n\n      factory :online_section_purchase do\n        association :purchaseable, factory: :online_section\n      end\n    end\n\n    factory :book_purchase do\n      association :purchaseable, factory: :book_product\n    end\n\n    factory :video_purchase do\n      association :purchaseable, factory: :video_product\n    end\n\n    factory :subscription_purchase do\n      association :purchaseable, factory: :subscribeable_product\n    end\n  end\n\n  factory :section_teacher do\n    section\n    teacher\n  end\n\n  factory :section_without_teacher, class: Section do\n    association :workshop\n    starts_on { 1.day.from_now.to_date }\n    ends_on   { 2.days.from_now.to_date }\n    start_at    '9:00'\n    stop_at     '17:00'\n    address     '41 Winter St'\n\n    factory :section do\n      after(:build) do |s|\n        s.teachers << build(:teacher)\n      end\n\n      factory :future_section do\n        starts_on { 2.days.from_now.to_date }\n        ends_on   { 4.days.from_now.to_date }\n      end\n\n      factory :past_section do\n        starts_on { 6.days.ago.to_date }\n        ends_on   { 4.days.ago.to_date }\n      end\n\n      factory :in_person_section do\n        association :workshop, factory: :in_person_workshop\n      end\n\n      factory :online_section do\n        association :workshop, factory: :online_workshop\n      end\n    end\n  end\n\n  factory :teacher do\n    email 'bmadison@example.com'\n    name 'Billy Madison'\n  end\n\n  factory :topic do\n    keywords 'clean, clear, precise'\n    name\n    summary 'short yet descriptive'\n  end\n\n  factory :user do\n    email\n    first_name 'Dan'\n    last_name 'Deacon'\n    password 'password'\n\n    factory :admin do\n      admin true\n    end\n\n    trait :with_subscription do\n      github_username 'github_user_1'\n      stripe_customer 'cus12345'\n\n      after :create do |instance|\n        create(:subscription, user: instance)\n      end\n    end\n  end\n\n  factory :subscription do\n    user\n  end\n\n  factory :video do\n    association :watchable, factory: :product\n    wistia_id '1194803'\n  end\n\n  factory :event do\n    association :workshop\n    title 'Office Hours'\n    time '1pm Eastern'\n  end\n\n  factory :episode do\n    title 'Episode Title'\n    file_size 1000\n    duration 2000\n    file 'http://gr-podcast.s3.amazonaws.com/thoughtbot-020.mp3'\n    description 'A really great episode'\n    published_on { 1.day.ago }\n\n    factory :future_episode do\n      published_on { 1.day.from_now }\n    end\n  end\nend\n", "idx": 1, "id": 7336, "msg": "In general, we shouldn't set values in a factory that are not _required_ for the functioning of the class (ie. for validations to pass) I think this would be better if you moved it into the test so that it was clear in the test that you were testing a different billing email.", "proj": "thoughtbot-upcase", "lang": "rb"}
{"patch": "@@ -611,16 +611,7 @@ void CoreChecks::GpuPostCallRecordPipelineCreations(const uint32_t count, const\n         for (uint32_t stage = 0; stage < stageCount; ++stage) {\n             if (pipeline_state->active_slots.find(gpu_validation_state->desc_set_bind_index) !=\n                 pipeline_state->active_slots.end()) {\n-                if (bind_point == VK_PIPELINE_BIND_POINT_GRAPHICS) {\n-                    DispatchDestroyShaderModule(device, pGraphicsCreateInfos->pStages[stage].module, pAllocator);\n-                } else if (bind_point == VK_PIPELINE_BIND_POINT_COMPUTE) {\n-                    assert(stage == 0);\n-                    DispatchDestroyShaderModule(device, pComputeCreateInfos->stage.module, pAllocator);\n-                } else if (bind_point == VK_PIPELINE_BIND_POINT_RAY_TRACING_NV) {\n-                    DispatchDestroyShaderModule(device, pRayTracingCreateInfos->pStages[stage].module, pAllocator);\n-                } else {\n-                    assert(false);\n-                }\n+                DispatchDestroyShaderModule(device, Accessor::GetShaderModule(pCreateInfos[pipeline], stage), pAllocator);\n             }\n \n             const SHADER_MODULE_STATE *shader_state = nullptr;", "y": 0, "oldf": "/* Copyright (c) 2018-2019 The Khronos Group Inc.\n * Copyright (c) 2018-2019 Valve Corporation\n * Copyright (c) 2018-2019 LunarG, Inc.\n * Copyright (C) 2018-2019 Google Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n */\n\n// Allow use of STL min and max functions in Windows\n#define NOMINMAX\n\n#include \"chassis.h\"\n#include \"core_validation.h\"\n// This define indicates to build the VMA routines themselves\n#define VMA_IMPLEMENTATION\n// This define indicates that we will supply Vulkan function pointers at initialization\n#define VMA_STATIC_VULKAN_FUNCTIONS 0\n#include \"gpu_validation.h\"\n#include \"shader_validation.h\"\n#include \"spirv-tools/libspirv.h\"\n#include \"spirv-tools/optimizer.hpp\"\n#include \"spirv-tools/instrument.hpp\"\n#include <SPIRV/spirv.hpp>\n#include <algorithm>\n#include <regex>\n\n// This is the number of bindings in the debug descriptor set.\nstatic const uint32_t kNumBindingsInSet = 2;\n\nstatic const VkShaderStageFlags kShaderStageAllRayTracing =\n    VK_SHADER_STAGE_ANY_HIT_BIT_NV | VK_SHADER_STAGE_CALLABLE_BIT_NV | VK_SHADER_STAGE_CLOSEST_HIT_BIT_NV |\n    VK_SHADER_STAGE_INTERSECTION_BIT_NV | VK_SHADER_STAGE_MISS_BIT_NV | VK_SHADER_STAGE_RAYGEN_BIT_NV;\n\n// Implementation for Descriptor Set Manager class\nGpuDescriptorSetManager::GpuDescriptorSetManager(CoreChecks *dev_data) { dev_data_ = dev_data; }\n\nGpuDescriptorSetManager::~GpuDescriptorSetManager() {\n    for (auto &pool : desc_pool_map_) {\n        DispatchDestroyDescriptorPool(dev_data_->device, pool.first, NULL);\n    }\n    desc_pool_map_.clear();\n}\n\nVkResult GpuDescriptorSetManager::GetDescriptorSets(uint32_t count, VkDescriptorPool *pool,\n                                                    std::vector<VkDescriptorSet> *desc_sets) {\n    const uint32_t default_pool_size = kItemsPerChunk;\n    VkResult result = VK_SUCCESS;\n    VkDescriptorPool pool_to_use = VK_NULL_HANDLE;\n\n    if (0 == count) {\n        return result;\n    }\n    desc_sets->clear();\n    desc_sets->resize(count);\n\n    for (auto &pool : desc_pool_map_) {\n        if (pool.second.used + count < pool.second.size) {\n            pool_to_use = pool.first;\n            break;\n        }\n    }\n    if (VK_NULL_HANDLE == pool_to_use) {\n        uint32_t pool_count = default_pool_size;\n        if (count > default_pool_size) {\n            pool_count = count;\n        }\n        const VkDescriptorPoolSize size_counts = {\n            VK_DESCRIPTOR_TYPE_STORAGE_BUFFER,\n            pool_count * kNumBindingsInSet,\n        };\n        VkDescriptorPoolCreateInfo desc_pool_info = {};\n        desc_pool_info.sType = VK_STRUCTURE_TYPE_DESCRIPTOR_POOL_CREATE_INFO;\n        desc_pool_info.pNext = NULL;\n        desc_pool_info.flags = VK_DESCRIPTOR_POOL_CREATE_FREE_DESCRIPTOR_SET_BIT;\n        desc_pool_info.maxSets = pool_count;\n        desc_pool_info.poolSizeCount = 1;\n        desc_pool_info.pPoolSizes = &size_counts;\n        result = DispatchCreateDescriptorPool(dev_data_->device, &desc_pool_info, NULL, &pool_to_use);\n        assert(result == VK_SUCCESS);\n        if (result != VK_SUCCESS) {\n            return result;\n        }\n        desc_pool_map_[pool_to_use].size = desc_pool_info.maxSets;\n        desc_pool_map_[pool_to_use].used = 0;\n    }\n    std::vector<VkDescriptorSetLayout> desc_layouts(count, dev_data_->gpu_validation_state->debug_desc_layout);\n\n    VkDescriptorSetAllocateInfo alloc_info = {VK_STRUCTURE_TYPE_DESCRIPTOR_SET_ALLOCATE_INFO, NULL, pool_to_use, count,\n                                              desc_layouts.data()};\n\n    result = DispatchAllocateDescriptorSets(dev_data_->device, &alloc_info, desc_sets->data());\n    assert(result == VK_SUCCESS);\n    if (result != VK_SUCCESS) {\n        return result;\n    }\n    *pool = pool_to_use;\n    desc_pool_map_[pool_to_use].used += count;\n    return result;\n}\n\nvoid GpuDescriptorSetManager::PutBackDescriptorSet(VkDescriptorPool desc_pool, VkDescriptorSet desc_set) {\n    auto iter = desc_pool_map_.find(desc_pool);\n    if (iter != desc_pool_map_.end()) {\n        VkResult result = DispatchFreeDescriptorSets(dev_data_->device, desc_pool, 1, &desc_set);\n        assert(result == VK_SUCCESS);\n        if (result != VK_SUCCESS) {\n            return;\n        }\n        desc_pool_map_[desc_pool].used--;\n        if (0 == desc_pool_map_[desc_pool].used) {\n            DispatchDestroyDescriptorPool(dev_data_->device, desc_pool, NULL);\n            desc_pool_map_.erase(desc_pool);\n        }\n    }\n    return;\n}\n\n// Trampolines to make VMA call Dispatch for Vulkan calls\nstatic VKAPI_ATTR void VKAPI_CALL gpuVkGetPhysicalDeviceProperties(VkPhysicalDevice physicalDevice,\n                                                                   VkPhysicalDeviceProperties *pProperties) {\n    DispatchGetPhysicalDeviceProperties(physicalDevice, pProperties);\n}\nstatic VKAPI_ATTR void VKAPI_CALL gpuVkGetPhysicalDeviceMemoryProperties(VkPhysicalDevice physicalDevice,\n                                                                         VkPhysicalDeviceMemoryProperties *pMemoryProperties) {\n    DispatchGetPhysicalDeviceMemoryProperties(physicalDevice, pMemoryProperties);\n}\nstatic VKAPI_ATTR VkResult VKAPI_CALL gpuVkAllocateMemory(VkDevice device, const VkMemoryAllocateInfo *pAllocateInfo,\n                                                          const VkAllocationCallbacks *pAllocator, VkDeviceMemory *pMemory) {\n    return DispatchAllocateMemory(device, pAllocateInfo, pAllocator, pMemory);\n}\nstatic VKAPI_ATTR void VKAPI_CALL gpuVkFreeMemory(VkDevice device, VkDeviceMemory memory, const VkAllocationCallbacks *pAllocator) {\n    DispatchFreeMemory(device, memory, pAllocator);\n}\nstatic VKAPI_ATTR VkResult VKAPI_CALL gpuVkMapMemory(VkDevice device, VkDeviceMemory memory, VkDeviceSize offset, VkDeviceSize size,\n                                                     VkMemoryMapFlags flags, void **ppData) {\n    return DispatchMapMemory(device, memory, offset, size, flags, ppData);\n}\nstatic VKAPI_ATTR void VKAPI_CALL gpuVkUnmapMemory(VkDevice device, VkDeviceMemory memory) { DispatchUnmapMemory(device, memory); }\nstatic VKAPI_ATTR VkResult VKAPI_CALL gpuVkFlushMappedMemoryRanges(VkDevice device, uint32_t memoryRangeCount,\n                                                                   const VkMappedMemoryRange *pMemoryRanges) {\n    return DispatchFlushMappedMemoryRanges(device, memoryRangeCount, pMemoryRanges);\n}\nstatic VKAPI_ATTR VkResult VKAPI_CALL gpuVkInvalidateMappedMemoryRanges(VkDevice device, uint32_t memoryRangeCount,\n                                                                        const VkMappedMemoryRange *pMemoryRanges) {\n    return DispatchInvalidateMappedMemoryRanges(device, memoryRangeCount, pMemoryRanges);\n}\nstatic VKAPI_ATTR VkResult VKAPI_CALL gpuVkBindBufferMemory(VkDevice device, VkBuffer buffer, VkDeviceMemory memory,\n                                                            VkDeviceSize memoryOffset) {\n    return DispatchBindBufferMemory(device, buffer, memory, memoryOffset);\n}\nstatic VKAPI_ATTR VkResult VKAPI_CALL gpuVkBindImageMemory(VkDevice device, VkImage image, VkDeviceMemory memory,\n                                                           VkDeviceSize memoryOffset) {\n    return DispatchBindImageMemory(device, image, memory, memoryOffset);\n}\nstatic VKAPI_ATTR void VKAPI_CALL gpuVkGetBufferMemoryRequirements(VkDevice device, VkBuffer buffer,\n                                                                   VkMemoryRequirements *pMemoryRequirements) {\n    DispatchGetBufferMemoryRequirements(device, buffer, pMemoryRequirements);\n}\nstatic VKAPI_ATTR void VKAPI_CALL gpuVkGetImageMemoryRequirements(VkDevice device, VkImage image,\n                                                                  VkMemoryRequirements *pMemoryRequirements) {\n    DispatchGetImageMemoryRequirements(device, image, pMemoryRequirements);\n}\nstatic VKAPI_ATTR VkResult VKAPI_CALL gpuVkCreateBuffer(VkDevice device, const VkBufferCreateInfo *pCreateInfo,\n                                                        const VkAllocationCallbacks *pAllocator, VkBuffer *pBuffer) {\n    return DispatchCreateBuffer(device, pCreateInfo, pAllocator, pBuffer);\n}\nstatic VKAPI_ATTR void VKAPI_CALL gpuVkDestroyBuffer(VkDevice device, VkBuffer buffer, const VkAllocationCallbacks *pAllocator) {\n    return DispatchDestroyBuffer(device, buffer, pAllocator);\n}\nstatic VKAPI_ATTR VkResult VKAPI_CALL gpuVkCreateImage(VkDevice device, const VkImageCreateInfo *pCreateInfo,\n                                                       const VkAllocationCallbacks *pAllocator, VkImage *pImage) {\n    return DispatchCreateImage(device, pCreateInfo, pAllocator, pImage);\n}\nstatic VKAPI_ATTR void VKAPI_CALL gpuVkDestroyImage(VkDevice device, VkImage image, const VkAllocationCallbacks *pAllocator) {\n    DispatchDestroyImage(device, image, pAllocator);\n}\nstatic VKAPI_ATTR void VKAPI_CALL gpuVkCmdCopyBuffer(VkCommandBuffer commandBuffer, VkBuffer srcBuffer, VkBuffer dstBuffer,\n                                                     uint32_t regionCount, const VkBufferCopy *pRegions) {\n    DispatchCmdCopyBuffer(commandBuffer, srcBuffer, dstBuffer, regionCount, pRegions);\n}\n\nVkResult CoreChecks::GpuInitializeVma() {\n    VmaVulkanFunctions functions;\n    VmaAllocatorCreateInfo allocatorInfo = {};\n    allocatorInfo.device = device;\n    ValidationObject *device_object = GetLayerDataPtr(get_dispatch_key(allocatorInfo.device), layer_data_map);\n    ValidationObject *validation_data = GetValidationObject(device_object->object_dispatch, LayerObjectTypeCoreValidation);\n    CoreChecks *core_checks = static_cast<CoreChecks *>(validation_data);\n    allocatorInfo.physicalDevice = core_checks->physical_device;\n\n    functions.vkGetPhysicalDeviceProperties = (PFN_vkGetPhysicalDeviceProperties)gpuVkGetPhysicalDeviceProperties;\n    functions.vkGetPhysicalDeviceMemoryProperties = (PFN_vkGetPhysicalDeviceMemoryProperties)gpuVkGetPhysicalDeviceMemoryProperties;\n    functions.vkAllocateMemory = (PFN_vkAllocateMemory)gpuVkAllocateMemory;\n    functions.vkFreeMemory = (PFN_vkFreeMemory)gpuVkFreeMemory;\n    functions.vkMapMemory = (PFN_vkMapMemory)gpuVkMapMemory;\n    functions.vkUnmapMemory = (PFN_vkUnmapMemory)gpuVkUnmapMemory;\n    functions.vkFlushMappedMemoryRanges = (PFN_vkFlushMappedMemoryRanges)gpuVkFlushMappedMemoryRanges;\n    functions.vkInvalidateMappedMemoryRanges = (PFN_vkInvalidateMappedMemoryRanges)gpuVkInvalidateMappedMemoryRanges;\n    functions.vkBindBufferMemory = (PFN_vkBindBufferMemory)gpuVkBindBufferMemory;\n    functions.vkBindImageMemory = (PFN_vkBindImageMemory)gpuVkBindImageMemory;\n    functions.vkGetBufferMemoryRequirements = (PFN_vkGetBufferMemoryRequirements)gpuVkGetBufferMemoryRequirements;\n    functions.vkGetImageMemoryRequirements = (PFN_vkGetImageMemoryRequirements)gpuVkGetImageMemoryRequirements;\n    functions.vkCreateBuffer = (PFN_vkCreateBuffer)gpuVkCreateBuffer;\n    functions.vkDestroyBuffer = (PFN_vkDestroyBuffer)gpuVkDestroyBuffer;\n    functions.vkCreateImage = (PFN_vkCreateImage)gpuVkCreateImage;\n    functions.vkDestroyImage = (PFN_vkDestroyImage)gpuVkDestroyImage;\n    functions.vkCmdCopyBuffer = (PFN_vkCmdCopyBuffer)gpuVkCmdCopyBuffer;\n    allocatorInfo.pVulkanFunctions = &functions;\n\n    return vmaCreateAllocator(&allocatorInfo, &gpu_validation_state->vmaAllocator);\n}\n\n// Convenience function for reporting problems with setting up GPU Validation.\nvoid CoreChecks::ReportSetupProblem(VkDebugReportObjectTypeEXT object_type, uint64_t object_handle,\n                                    const char *const specific_message) {\n    log_msg(report_data, VK_DEBUG_REPORT_ERROR_BIT_EXT, object_type, object_handle, \"UNASSIGNED-GPU-Assisted Validation Error. \",\n            \"Detail: (%s)\", specific_message);\n}\n\n// Turn on necessary device features.\nvoid CoreChecks::GpuPreCallRecordCreateDevice(VkPhysicalDevice gpu, std::unique_ptr<safe_VkDeviceCreateInfo> &create_info,\n                                              VkPhysicalDeviceFeatures *supported_features) {\n    if (supported_features->fragmentStoresAndAtomics || supported_features->vertexPipelineStoresAndAtomics) {\n        VkPhysicalDeviceFeatures new_features = {};\n        if (create_info->pEnabledFeatures) {\n            new_features = *create_info->pEnabledFeatures;\n        }\n        new_features.fragmentStoresAndAtomics = supported_features->fragmentStoresAndAtomics;\n        new_features.vertexPipelineStoresAndAtomics = supported_features->vertexPipelineStoresAndAtomics;\n        delete create_info->pEnabledFeatures;\n        create_info->pEnabledFeatures = new VkPhysicalDeviceFeatures(new_features);\n    }\n}\n\n// Perform initializations that can be done at Create Device time.\nvoid CoreChecks::GpuPostCallRecordCreateDevice(const CHECK_ENABLED *enables, const VkDeviceCreateInfo *pCreateInfo) {\n    // Set instance-level enables in device-enable data structure if using legacy settings\n    enabled.gpu_validation = enables->gpu_validation;\n    enabled.gpu_validation_reserve_binding_slot = enables->gpu_validation_reserve_binding_slot;\n\n    gpu_validation_state = std::unique_ptr<GpuValidationState>(new GpuValidationState);\n    gpu_validation_state->reserve_binding_slot = enables->gpu_validation_reserve_binding_slot;\n\n    if (phys_dev_props.apiVersion < VK_API_VERSION_1_1) {\n        ReportSetupProblem(VK_DEBUG_REPORT_OBJECT_TYPE_DEVICE_EXT, HandleToUint64(device),\n                           \"GPU-Assisted validation requires Vulkan 1.1 or later.  GPU-Assisted Validation disabled.\");\n        gpu_validation_state->aborted = true;\n        return;\n    }\n\n    // If api version 1.1 or later, SetDeviceLoaderData will be in the loader\n    auto chain_info = get_chain_info(pCreateInfo, VK_LOADER_DATA_CALLBACK);\n    assert(chain_info->u.pfnSetDeviceLoaderData);\n    gpu_validation_state->vkSetDeviceLoaderData = chain_info->u.pfnSetDeviceLoaderData;\n\n    // Some devices have extremely high limits here, so set a reasonable max because we have to pad\n    // the pipeline layout with dummy descriptor set layouts.\n    gpu_validation_state->adjusted_max_desc_sets = phys_dev_props.limits.maxBoundDescriptorSets;\n    gpu_validation_state->adjusted_max_desc_sets = std::min(33U, gpu_validation_state->adjusted_max_desc_sets);\n\n    // We can't do anything if there is only one.\n    // Device probably not a legit Vulkan device, since there should be at least 4. Protect ourselves.\n    if (gpu_validation_state->adjusted_max_desc_sets == 1) {\n        ReportSetupProblem(VK_DEBUG_REPORT_OBJECT_TYPE_DEVICE_EXT, HandleToUint64(device),\n                           \"Device can bind only a single descriptor set.  GPU-Assisted Validation disabled.\");\n        gpu_validation_state->aborted = true;\n        return;\n    }\n    gpu_validation_state->desc_set_bind_index = gpu_validation_state->adjusted_max_desc_sets - 1;\n    log_msg(report_data, VK_DEBUG_REPORT_INFORMATION_BIT_EXT, VK_DEBUG_REPORT_OBJECT_TYPE_DEVICE_EXT, HandleToUint64(device),\n            \"UNASSIGNED-GPU-Assisted Validation. \", \"Shaders using descriptor set at index %d. \",\n            gpu_validation_state->desc_set_bind_index);\n\n    gpu_validation_state->output_buffer_size = sizeof(uint32_t) * (spvtools::kInstMaxOutCnt + 1);\n    VkResult result = GpuInitializeVma();\n    assert(result == VK_SUCCESS);\n    std::unique_ptr<GpuDescriptorSetManager> desc_set_manager(new GpuDescriptorSetManager(this));\n\n    // The descriptor indexing checks require only the first \"output\" binding.\n    const VkDescriptorSetLayoutBinding debug_desc_layout_bindings[kNumBindingsInSet] = {\n        {\n            0,  // output\n            VK_DESCRIPTOR_TYPE_STORAGE_BUFFER,\n            1,\n            VK_SHADER_STAGE_ALL_GRAPHICS | VK_SHADER_STAGE_COMPUTE_BIT | kShaderStageAllRayTracing,\n            NULL,\n        },\n        {\n            1,  // input\n            VK_DESCRIPTOR_TYPE_STORAGE_BUFFER,\n            1,\n            VK_SHADER_STAGE_ALL_GRAPHICS | VK_SHADER_STAGE_COMPUTE_BIT | kShaderStageAllRayTracing,\n            NULL,\n        },\n    };\n\n    const VkDescriptorSetLayoutCreateInfo debug_desc_layout_info = {VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_CREATE_INFO, NULL, 0,\n                                                                    kNumBindingsInSet, debug_desc_layout_bindings};\n\n    const VkDescriptorSetLayoutCreateInfo dummy_desc_layout_info = {VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_CREATE_INFO, NULL, 0, 0,\n                                                                    NULL};\n\n    result = DispatchCreateDescriptorSetLayout(device, &debug_desc_layout_info, NULL, &gpu_validation_state->debug_desc_layout);\n\n    // This is a layout used to \"pad\" a pipeline layout to fill in any gaps to the selected bind index.\n    VkResult result2 =\n        DispatchCreateDescriptorSetLayout(device, &dummy_desc_layout_info, NULL, &gpu_validation_state->dummy_desc_layout);\n    assert((result == VK_SUCCESS) && (result2 == VK_SUCCESS));\n    if ((result != VK_SUCCESS) || (result2 != VK_SUCCESS)) {\n        ReportSetupProblem(VK_DEBUG_REPORT_OBJECT_TYPE_DEVICE_EXT, HandleToUint64(device),\n                           \"Unable to create descriptor set layout.  GPU-Assisted Validation disabled.\");\n        if (result == VK_SUCCESS) {\n            DispatchDestroyDescriptorSetLayout(device, gpu_validation_state->debug_desc_layout, NULL);\n        }\n        if (result2 == VK_SUCCESS) {\n            DispatchDestroyDescriptorSetLayout(device, gpu_validation_state->dummy_desc_layout, NULL);\n        }\n        gpu_validation_state->debug_desc_layout = VK_NULL_HANDLE;\n        gpu_validation_state->dummy_desc_layout = VK_NULL_HANDLE;\n        gpu_validation_state->aborted = true;\n        return;\n    }\n    gpu_validation_state->desc_set_manager = std::move(desc_set_manager);\n}\n\n// Clean up device-related resources\nvoid CoreChecks::GpuPreCallRecordDestroyDevice() {\n    for (auto &queue_barrier_command_info_kv : gpu_validation_state->queue_barrier_command_infos) {\n        GpuQueueBarrierCommandInfo &queue_barrier_command_info = queue_barrier_command_info_kv.second;\n\n        DispatchFreeCommandBuffers(device, queue_barrier_command_info.barrier_command_pool, 1,\n                                   &queue_barrier_command_info.barrier_command_buffer);\n        queue_barrier_command_info.barrier_command_buffer = VK_NULL_HANDLE;\n\n        DispatchDestroyCommandPool(device, queue_barrier_command_info.barrier_command_pool, NULL);\n        queue_barrier_command_info.barrier_command_pool = VK_NULL_HANDLE;\n    }\n    gpu_validation_state->queue_barrier_command_infos.clear();\n    if (gpu_validation_state->debug_desc_layout) {\n        DispatchDestroyDescriptorSetLayout(device, gpu_validation_state->debug_desc_layout, NULL);\n        gpu_validation_state->debug_desc_layout = VK_NULL_HANDLE;\n    }\n    if (gpu_validation_state->dummy_desc_layout) {\n        DispatchDestroyDescriptorSetLayout(device, gpu_validation_state->dummy_desc_layout, NULL);\n        gpu_validation_state->dummy_desc_layout = VK_NULL_HANDLE;\n    }\n    gpu_validation_state->desc_set_manager.reset();\n    if (gpu_validation_state->vmaAllocator) {\n        vmaDestroyAllocator(gpu_validation_state->vmaAllocator);\n    }\n}\n\n// Modify the pipeline layout to include our debug descriptor set and any needed padding with the dummy descriptor set.\nbool CoreChecks::GpuPreCallCreatePipelineLayout(const VkPipelineLayoutCreateInfo *pCreateInfo,\n                                                const VkAllocationCallbacks *pAllocator, VkPipelineLayout *pPipelineLayout,\n                                                std::vector<VkDescriptorSetLayout> *new_layouts,\n                                                VkPipelineLayoutCreateInfo *modified_create_info) {\n    if (gpu_validation_state->aborted) {\n        return false;\n    }\n\n    if (modified_create_info->setLayoutCount >= gpu_validation_state->adjusted_max_desc_sets) {\n        std::ostringstream strm;\n        strm << \"Pipeline Layout conflict with validation's descriptor set at slot \" << gpu_validation_state->desc_set_bind_index\n             << \". \"\n             << \"Application has too many descriptor sets in the pipeline layout to continue with gpu validation. \"\n             << \"Validation is not modifying the pipeline layout. \"\n             << \"Instrumented shaders are replaced with non-instrumented shaders.\";\n        ReportSetupProblem(VK_DEBUG_REPORT_OBJECT_TYPE_DEVICE_EXT, HandleToUint64(device), strm.str().c_str());\n    } else {\n        // Modify the pipeline layout by:\n        // 1. Copying the caller's descriptor set desc_layouts\n        // 2. Fill in dummy descriptor layouts up to the max binding\n        // 3. Fill in with the debug descriptor layout at the max binding slot\n        new_layouts->reserve(gpu_validation_state->adjusted_max_desc_sets);\n        new_layouts->insert(new_layouts->end(), &pCreateInfo->pSetLayouts[0],\n                            &pCreateInfo->pSetLayouts[pCreateInfo->setLayoutCount]);\n        for (uint32_t i = pCreateInfo->setLayoutCount; i < gpu_validation_state->adjusted_max_desc_sets - 1; ++i) {\n            new_layouts->push_back(gpu_validation_state->dummy_desc_layout);\n        }\n        new_layouts->push_back(gpu_validation_state->debug_desc_layout);\n        modified_create_info->pSetLayouts = new_layouts->data();\n        modified_create_info->setLayoutCount = gpu_validation_state->adjusted_max_desc_sets;\n    }\n    return true;\n}\n\n// Clean up GPU validation after the CreatePipelineLayout call is made\nvoid CoreChecks::GpuPostCallCreatePipelineLayout(VkResult result) {\n    // Clean up GPU validation\n    if (result != VK_SUCCESS) {\n        ReportSetupProblem(VK_DEBUG_REPORT_OBJECT_TYPE_DEVICE_EXT, HandleToUint64(device),\n                           \"Unable to create pipeline layout.  Device could become unstable.\");\n        gpu_validation_state->aborted = true;\n    }\n}\n\n// Free the device memory and descriptor set associated with a command buffer.\nvoid CoreChecks::GpuResetCommandBuffer(const VkCommandBuffer commandBuffer) {\n    if (gpu_validation_state->aborted) {\n        return;\n    }\n    auto gpu_buffer_list = gpu_validation_state->GetGpuBufferInfo(commandBuffer);\n    for (auto buffer_info : gpu_buffer_list) {\n        vmaDestroyBuffer(gpu_validation_state->vmaAllocator, buffer_info.output_mem_block.buffer,\n                         buffer_info.output_mem_block.allocation);\n        if (buffer_info.input_mem_block.buffer) {\n            vmaDestroyBuffer(gpu_validation_state->vmaAllocator, buffer_info.input_mem_block.buffer,\n                             buffer_info.input_mem_block.allocation);\n        }\n        if (buffer_info.desc_set != VK_NULL_HANDLE) {\n            gpu_validation_state->desc_set_manager->PutBackDescriptorSet(buffer_info.desc_pool, buffer_info.desc_set);\n        }\n    }\n    gpu_validation_state->command_buffer_map.erase(commandBuffer);\n}\n\n// Just gives a warning about a possible deadlock.\nvoid CoreChecks::GpuPreCallValidateCmdWaitEvents(VkPipelineStageFlags sourceStageMask) {\n    if (sourceStageMask & VK_PIPELINE_STAGE_HOST_BIT) {\n        ReportSetupProblem(VK_DEBUG_REPORT_OBJECT_TYPE_DEVICE_EXT, HandleToUint64(device),\n                           \"CmdWaitEvents recorded with VK_PIPELINE_STAGE_HOST_BIT set. \"\n                           \"GPU_Assisted validation waits on queue completion. \"\n                           \"This wait could block the host's signaling of this event, resulting in deadlock.\");\n    }\n}\n\nstd::vector<safe_VkGraphicsPipelineCreateInfo> CoreChecks::GpuPreCallRecordCreateGraphicsPipelines(\n    VkPipelineCache pipelineCache, uint32_t count, const VkGraphicsPipelineCreateInfo *pCreateInfos,\n    const VkAllocationCallbacks *pAllocator, VkPipeline *pPipelines, std::vector<std::unique_ptr<PIPELINE_STATE>> &pipe_state) {\n    std::vector<safe_VkGraphicsPipelineCreateInfo> new_pipeline_create_infos;\n    GpuPreCallRecordPipelineCreations(count, pCreateInfos, nullptr, nullptr, pAllocator, pPipelines, pipe_state,\n                                      &new_pipeline_create_infos, nullptr, nullptr, VK_PIPELINE_BIND_POINT_GRAPHICS);\n    return new_pipeline_create_infos;\n}\nstd::vector<safe_VkComputePipelineCreateInfo> CoreChecks::GpuPreCallRecordCreateComputePipelines(\n    VkPipelineCache pipelineCache, uint32_t count, const VkComputePipelineCreateInfo *pCreateInfos,\n    const VkAllocationCallbacks *pAllocator, VkPipeline *pPipelines, std::vector<std::unique_ptr<PIPELINE_STATE>> &pipe_state) {\n    std::vector<safe_VkComputePipelineCreateInfo> new_pipeline_create_infos;\n    GpuPreCallRecordPipelineCreations(count, nullptr, pCreateInfos, nullptr, pAllocator, pPipelines, pipe_state, nullptr,\n                                      &new_pipeline_create_infos, nullptr, VK_PIPELINE_BIND_POINT_COMPUTE);\n    return new_pipeline_create_infos;\n}\nstd::vector<safe_VkRayTracingPipelineCreateInfoNV> CoreChecks::GpuPreCallRecordCreateRayTracingPipelinesNV(\n    VkPipelineCache pipelineCache, uint32_t count, const VkRayTracingPipelineCreateInfoNV *pCreateInfos,\n    const VkAllocationCallbacks *pAllocator, VkPipeline *pPipelines, std::vector<std::unique_ptr<PIPELINE_STATE>> &pipe_state) {\n    std::vector<safe_VkRayTracingPipelineCreateInfoNV> new_pipeline_create_infos;\n    GpuPreCallRecordPipelineCreations(count, nullptr, nullptr, pCreateInfos, pAllocator, pPipelines, pipe_state, nullptr, nullptr,\n                                      &new_pipeline_create_infos, VK_PIPELINE_BIND_POINT_RAY_TRACING_NV);\n    return new_pipeline_create_infos;\n}\n\n// Examine the pipelines to see if they use the debug descriptor set binding index.\n// If any do, create new non-instrumented shader modules and use them to replace the instrumented\n// shaders in the pipeline.  Return the (possibly) modified create infos to the caller.\nvoid CoreChecks::GpuPreCallRecordPipelineCreations(\n    uint32_t count, const VkGraphicsPipelineCreateInfo *pGraphicsCreateInfos,\n    const VkComputePipelineCreateInfo *pComputeCreateInfos, const VkRayTracingPipelineCreateInfoNV *pRayTracingCreateInfos,\n    const VkAllocationCallbacks *pAllocator, VkPipeline *pPipelines, std::vector<std::unique_ptr<PIPELINE_STATE>> &pipe_state,\n    std::vector<safe_VkGraphicsPipelineCreateInfo> *new_graphics_pipeline_create_infos,\n    std::vector<safe_VkComputePipelineCreateInfo> *new_compute_pipeline_create_infos,\n    std::vector<safe_VkRayTracingPipelineCreateInfoNV> *new_ray_tracing_pipeline_create_infos,\n    const VkPipelineBindPoint bind_point) {\n    if (bind_point != VK_PIPELINE_BIND_POINT_GRAPHICS && bind_point != VK_PIPELINE_BIND_POINT_COMPUTE &&\n        bind_point != VK_PIPELINE_BIND_POINT_RAY_TRACING_NV) {\n        return;\n    }\n\n    // Walk through all the pipelines, make a copy of each and flag each pipeline that contains a shader that uses the debug\n    // descriptor set index.\n    for (uint32_t pipeline = 0; pipeline < count; ++pipeline) {\n        uint32_t stageCount = 0;\n        if (bind_point == VK_PIPELINE_BIND_POINT_GRAPHICS) {\n            stageCount = pGraphicsCreateInfos[pipeline].stageCount;\n        } else if (bind_point == VK_PIPELINE_BIND_POINT_COMPUTE) {\n            stageCount = 1;\n        } else if (bind_point == VK_PIPELINE_BIND_POINT_RAY_TRACING_NV) {\n            stageCount = pRayTracingCreateInfos[pipeline].stageCount;\n        } else {\n            assert(false);\n        }\n\n        if (bind_point == VK_PIPELINE_BIND_POINT_GRAPHICS) {\n            new_graphics_pipeline_create_infos->push_back(pipe_state[pipeline]->graphicsPipelineCI);\n        } else if (bind_point == VK_PIPELINE_BIND_POINT_COMPUTE) {\n            new_compute_pipeline_create_infos->push_back(pipe_state[pipeline]->computePipelineCI);\n        } else if (bind_point == VK_PIPELINE_BIND_POINT_RAY_TRACING_NV) {\n            new_ray_tracing_pipeline_create_infos->push_back(pipe_state[pipeline]->raytracingPipelineCI);\n        } else {\n            assert(false);\n        }\n\n        bool replace_shaders = false;\n        if (pipe_state[pipeline]->active_slots.find(gpu_validation_state->desc_set_bind_index) !=\n            pipe_state[pipeline]->active_slots.end()) {\n            replace_shaders = true;\n        }\n        // If the app requests all available sets, the pipeline layout was not modified at pipeline layout creation and the already\n        // instrumented shaders need to be replaced with uninstrumented shaders\n        if (pipe_state[pipeline]->pipeline_layout.set_layouts.size() >= gpu_validation_state->adjusted_max_desc_sets) {\n            replace_shaders = true;\n        }\n\n        if (replace_shaders) {\n            for (uint32_t stage = 0; stage < stageCount; ++stage) {\n                const SHADER_MODULE_STATE *shader = nullptr;\n                if (bind_point == VK_PIPELINE_BIND_POINT_GRAPHICS) {\n                    shader = GetShaderModuleState(pGraphicsCreateInfos[pipeline].pStages[stage].module);\n                } else if (bind_point == VK_PIPELINE_BIND_POINT_COMPUTE) {\n                    shader = GetShaderModuleState(pComputeCreateInfos[pipeline].stage.module);\n                } else if (bind_point == VK_PIPELINE_BIND_POINT_RAY_TRACING_NV) {\n                    shader = GetShaderModuleState(pRayTracingCreateInfos[pipeline].pStages[stage].module);\n                } else {\n                    assert(false);\n                }\n\n                VkShaderModuleCreateInfo create_info = {};\n                VkShaderModule shader_module;\n                create_info.sType = VK_STRUCTURE_TYPE_SHADER_MODULE_CREATE_INFO;\n                create_info.pCode = shader->words.data();\n                create_info.codeSize = shader->words.size() * sizeof(uint32_t);\n                VkResult result = DispatchCreateShaderModule(device, &create_info, pAllocator, &shader_module);\n                if (result == VK_SUCCESS) {\n                    if (bind_point == VK_PIPELINE_BIND_POINT_GRAPHICS) {\n                        new_graphics_pipeline_create_infos[pipeline].data()->pStages[stage].module = shader_module;\n                    } else if (bind_point == VK_PIPELINE_BIND_POINT_COMPUTE) {\n                        new_compute_pipeline_create_infos[pipeline].data()->stage.module = shader_module;\n                    } else if (bind_point == VK_PIPELINE_BIND_POINT_RAY_TRACING_NV) {\n                        new_ray_tracing_pipeline_create_infos[pipeline].data()->pStages[stage].module = shader_module;\n                    } else {\n                        assert(false);\n                    }\n                } else {\n                    uint64_t moduleHandle = 0;\n                    if (bind_point == VK_PIPELINE_BIND_POINT_GRAPHICS) {\n                        moduleHandle = HandleToUint64(pGraphicsCreateInfos[pipeline].pStages[stage].module);\n                    } else if (bind_point == VK_PIPELINE_BIND_POINT_COMPUTE) {\n                        moduleHandle = HandleToUint64(pComputeCreateInfos[pipeline].stage.module);\n                    } else if (bind_point == VK_PIPELINE_BIND_POINT_RAY_TRACING_NV) {\n                        moduleHandle = HandleToUint64(pRayTracingCreateInfos[pipeline].pStages[stage].module);\n                    } else {\n                        assert(false);\n                    }\n                    ReportSetupProblem(VK_DEBUG_REPORT_OBJECT_TYPE_SHADER_MODULE_EXT, moduleHandle,\n                                       \"Unable to replace instrumented shader with non-instrumented one.  \"\n                                       \"Device could become unstable.\");\n                }\n            }\n        }\n    }\n}\n\nvoid CoreChecks::GpuPostCallRecordCreateGraphicsPipelines(const uint32_t count, const VkGraphicsPipelineCreateInfo *pCreateInfos,\n                                                          const VkAllocationCallbacks *pAllocator, VkPipeline *pPipelines) {\n    GpuPostCallRecordPipelineCreations(count, pCreateInfos, nullptr, nullptr, pAllocator, pPipelines,\n                                       VK_PIPELINE_BIND_POINT_GRAPHICS);\n}\nvoid CoreChecks::GpuPostCallRecordCreateComputePipelines(const uint32_t count, const VkComputePipelineCreateInfo *pCreateInfos,\n                                                         const VkAllocationCallbacks *pAllocator, VkPipeline *pPipelines) {\n    GpuPostCallRecordPipelineCreations(count, nullptr, pCreateInfos, nullptr, pAllocator, pPipelines,\n                                       VK_PIPELINE_BIND_POINT_COMPUTE);\n}\nvoid CoreChecks::GpuPostCallRecordCreateRayTracingPipelinesNV(const uint32_t count,\n                                                              const VkRayTracingPipelineCreateInfoNV *pCreateInfos,\n                                                              const VkAllocationCallbacks *pAllocator, VkPipeline *pPipelines) {\n    GpuPostCallRecordPipelineCreations(count, nullptr, nullptr, pCreateInfos, pAllocator, pPipelines,\n                                       VK_PIPELINE_BIND_POINT_RAY_TRACING_NV);\n}\n\n// For every pipeline:\n// - For every shader in a pipeline:\n//   - If the shader had to be replaced in PreCallRecord (because the pipeline is using the debug desc set index):\n//     - Destroy it since it has been bound into the pipeline by now.  This is our only chance to delete it.\n//   - Track the shader in the shader_map\n//   - Save the shader binary if it contains debug code\nvoid CoreChecks::GpuPostCallRecordPipelineCreations(const uint32_t count, const VkGraphicsPipelineCreateInfo *pGraphicsCreateInfos,\n                                                    const VkComputePipelineCreateInfo *pComputeCreateInfos,\n                                                    const VkRayTracingPipelineCreateInfoNV *pRayTracingCreateInfos,\n                                                    const VkAllocationCallbacks *pAllocator, VkPipeline *pPipelines,\n                                                    const VkPipelineBindPoint bind_point) {\n    if (bind_point != VK_PIPELINE_BIND_POINT_GRAPHICS && bind_point != VK_PIPELINE_BIND_POINT_COMPUTE &&\n        bind_point != VK_PIPELINE_BIND_POINT_RAY_TRACING_NV) {\n        return;\n    }\n    for (uint32_t pipeline = 0; pipeline < count; ++pipeline) {\n        auto pipeline_state = GetPipelineState(pPipelines[pipeline]);\n        if (nullptr == pipeline_state) continue;\n\n        uint32_t stageCount = 0;\n        if (bind_point == VK_PIPELINE_BIND_POINT_GRAPHICS) {\n            stageCount = pipeline_state->graphicsPipelineCI.stageCount;\n        } else if (bind_point == VK_PIPELINE_BIND_POINT_COMPUTE) {\n            stageCount = 1;\n        } else if (bind_point == VK_PIPELINE_BIND_POINT_RAY_TRACING_NV) {\n            stageCount = pipeline_state->raytracingPipelineCI.stageCount;\n        } else {\n            assert(false);\n        }\n\n        for (uint32_t stage = 0; stage < stageCount; ++stage) {\n            if (pipeline_state->active_slots.find(gpu_validation_state->desc_set_bind_index) !=\n                pipeline_state->active_slots.end()) {\n                if (bind_point == VK_PIPELINE_BIND_POINT_GRAPHICS) {\n                    DispatchDestroyShaderModule(device, pGraphicsCreateInfos->pStages[stage].module, pAllocator);\n                } else if (bind_point == VK_PIPELINE_BIND_POINT_COMPUTE) {\n                    assert(stage == 0);\n                    DispatchDestroyShaderModule(device, pComputeCreateInfos->stage.module, pAllocator);\n                } else if (bind_point == VK_PIPELINE_BIND_POINT_RAY_TRACING_NV) {\n                    DispatchDestroyShaderModule(device, pRayTracingCreateInfos->pStages[stage].module, pAllocator);\n                } else {\n                    assert(false);\n                }\n            }\n\n            const SHADER_MODULE_STATE *shader_state = nullptr;\n            if (bind_point == VK_PIPELINE_BIND_POINT_GRAPHICS) {\n                shader_state = GetShaderModuleState(pipeline_state->graphicsPipelineCI.pStages[stage].module);\n            } else if (bind_point == VK_PIPELINE_BIND_POINT_COMPUTE) {\n                assert(stage == 0);\n                shader_state = GetShaderModuleState(pipeline_state->computePipelineCI.stage.module);\n            } else if (bind_point == VK_PIPELINE_BIND_POINT_RAY_TRACING_NV) {\n                shader_state = GetShaderModuleState(pipeline_state->raytracingPipelineCI.pStages[stage].module);\n            } else {\n                assert(false);\n            }\n\n            std::vector<unsigned int> code;\n            // Save the shader binary if debug info is present.\n            // The core_validation ShaderModule tracker saves the binary too, but discards it when the ShaderModule\n            // is destroyed.  Applications may destroy ShaderModules after they are placed in a pipeline and before\n            // the pipeline is used, so we have to keep another copy.\n            if (shader_state && shader_state->has_valid_spirv) {  // really checking for presense of SPIR-V code.\n                for (auto insn : *shader_state) {\n                    if (insn.opcode() == spv::OpLine) {\n                        code = shader_state->words;\n                        break;\n                    }\n                }\n            }\n            gpu_validation_state->shader_map[shader_state->gpu_validation_shader_id].pipeline = pipeline_state->pipeline;\n            // Be careful to use the originally bound (instrumented) shader here, even if PreCallRecord had to back it\n            // out with a non-instrumented shader.  The non-instrumented shader (found in pCreateInfo) was destroyed above.\n            VkShaderModule shader_module = VK_NULL_HANDLE;\n            if (bind_point == VK_PIPELINE_BIND_POINT_GRAPHICS) {\n                shader_module = pipeline_state->graphicsPipelineCI.pStages[stage].module;\n            } else if (bind_point == VK_PIPELINE_BIND_POINT_COMPUTE) {\n                assert(stage == 0);\n                shader_module = pipeline_state->computePipelineCI.stage.module;\n            } else if (bind_point == VK_PIPELINE_BIND_POINT_RAY_TRACING_NV) {\n                shader_module = pipeline_state->raytracingPipelineCI.pStages[stage].module;\n            } else {\n                assert(false);\n            }\n            gpu_validation_state->shader_map[shader_state->gpu_validation_shader_id].shader_module = shader_module;\n            gpu_validation_state->shader_map[shader_state->gpu_validation_shader_id].pgm = std::move(code);\n        }\n    }\n}\n\n// Remove all the shader trackers associated with this destroyed pipeline.\nvoid CoreChecks::GpuPreCallRecordDestroyPipeline(const VkPipeline pipeline) {\n    for (auto it = gpu_validation_state->shader_map.begin(); it != gpu_validation_state->shader_map.end();) {\n        if (it->second.pipeline == pipeline) {\n            it = gpu_validation_state->shader_map.erase(it);\n        } else {\n            ++it;\n        }\n    }\n}\n\n// Call the SPIR-V Optimizer to run the instrumentation pass on the shader.\nbool CoreChecks::GpuInstrumentShader(const VkShaderModuleCreateInfo *pCreateInfo, std::vector<unsigned int> &new_pgm,\n                                     uint32_t *unique_shader_id) {\n    if (gpu_validation_state->aborted) return false;\n    if (pCreateInfo->pCode[0] != spv::MagicNumber) return false;\n\n    // Load original shader SPIR-V\n    uint32_t num_words = static_cast<uint32_t>(pCreateInfo->codeSize / 4);\n    new_pgm.clear();\n    new_pgm.reserve(num_words);\n    new_pgm.insert(new_pgm.end(), &pCreateInfo->pCode[0], &pCreateInfo->pCode[num_words]);\n\n    // Call the optimizer to instrument the shader.\n    // Use the unique_shader_module_id as a shader ID so we can look up its handle later in the shader_map.\n    // If descriptor indexing is enabled, enable length checks and updated descriptor checks\n    const bool descriptor_indexing = device_extensions.vk_ext_descriptor_indexing;\n    using namespace spvtools;\n    spv_target_env target_env = SPV_ENV_VULKAN_1_1;\n    Optimizer optimizer(target_env);\n    optimizer.RegisterPass(CreateInstBindlessCheckPass(gpu_validation_state->desc_set_bind_index,\n                                                       gpu_validation_state->unique_shader_module_id, descriptor_indexing,\n                                                       descriptor_indexing));\n    optimizer.RegisterPass(CreateAggressiveDCEPass());\n    bool pass = optimizer.Run(new_pgm.data(), new_pgm.size(), &new_pgm);\n    if (!pass) {\n        ReportSetupProblem(VK_DEBUG_REPORT_OBJECT_TYPE_SHADER_MODULE_EXT, VK_NULL_HANDLE,\n                           \"Failure to instrument shader.  Proceeding with non-instrumented shader.\");\n    }\n    *unique_shader_id = gpu_validation_state->unique_shader_module_id++;\n    return pass;\n}\n\n// Create the instrumented shader data to provide to the driver.\nbool CoreChecks::GpuPreCallCreateShaderModule(const VkShaderModuleCreateInfo *pCreateInfo, const VkAllocationCallbacks *pAllocator,\n                                              VkShaderModule *pShaderModule, uint32_t *unique_shader_id,\n                                              VkShaderModuleCreateInfo *instrumented_create_info,\n                                              std::vector<unsigned int> *instrumented_pgm) {\n    bool pass = GpuInstrumentShader(pCreateInfo, *instrumented_pgm, unique_shader_id);\n    if (pass) {\n        instrumented_create_info->pCode = instrumented_pgm->data();\n        instrumented_create_info->codeSize = instrumented_pgm->size() * sizeof(unsigned int);\n    }\n    return pass;\n}\n\n// Generate the stage-specific part of the message.\nstatic void GenerateStageMessage(const uint32_t *debug_record, std::string &msg) {\n    using namespace spvtools;\n    std::ostringstream strm;\n    switch (debug_record[kInstCommonOutStageIdx]) {\n        case spv::ExecutionModelVertex: {\n            strm << \"Stage = Vertex. Vertex Index = \" << debug_record[kInstVertOutVertexIndex]\n                 << \" Instance Index = \" << debug_record[kInstVertOutInstanceIndex] << \". \";\n        } break;\n        case spv::ExecutionModelTessellationControl: {\n            strm << \"Stage = Tessellation Control.  Invocation ID = \" << debug_record[kInstTessOutInvocationId] << \". \";\n        } break;\n        case spv::ExecutionModelTessellationEvaluation: {\n            strm << \"Stage = Tessellation Eval.  Invocation ID = \" << debug_record[kInstTessOutInvocationId] << \". \";\n        } break;\n        case spv::ExecutionModelGeometry: {\n            strm << \"Stage = Geometry.  Primitive ID = \" << debug_record[kInstGeomOutPrimitiveId]\n                 << \" Invocation ID = \" << debug_record[kInstGeomOutInvocationId] << \". \";\n        } break;\n        case spv::ExecutionModelFragment: {\n            strm << \"Stage = Fragment.  Fragment coord (x,y) = (\"\n                 << *reinterpret_cast<const float *>(&debug_record[kInstFragOutFragCoordX]) << \", \"\n                 << *reinterpret_cast<const float *>(&debug_record[kInstFragOutFragCoordY]) << \"). \";\n        } break;\n        case spv::ExecutionModelGLCompute: {\n            strm << \"Stage = Compute.  Global invocation ID = \" << debug_record[kInstCompOutGlobalInvocationId] << \". \";\n        } break;\n        case spv::ExecutionModelRayGenerationNV: {\n            strm << \"Stage = Ray Generation.  Global Launch ID (x,y,z) = (\" << debug_record[kInstRayTracingOutLaunchIdX] << \", \"\n                 << debug_record[kInstRayTracingOutLaunchIdY] << \", \" << debug_record[kInstRayTracingOutLaunchIdZ] << \"). \";\n        } break;\n        case spv::ExecutionModelIntersectionNV: {\n            strm << \"Stage = Intersection.  Global Launch ID (x,y,z) = (\" << debug_record[kInstRayTracingOutLaunchIdX] << \", \"\n                 << debug_record[kInstRayTracingOutLaunchIdY] << \", \" << debug_record[kInstRayTracingOutLaunchIdZ] << \"). \";\n        } break;\n        case spv::ExecutionModelAnyHitNV: {\n            strm << \"Stage = Any Hit.  Global Launch ID (x,y,z) = (\" << debug_record[kInstRayTracingOutLaunchIdX] << \", \"\n                 << debug_record[kInstRayTracingOutLaunchIdY] << \", \" << debug_record[kInstRayTracingOutLaunchIdZ] << \"). \";\n        } break;\n        case spv::ExecutionModelClosestHitNV: {\n            strm << \"Stage = Closest Hit.  Global Launch ID (x,y,z) = (\" << debug_record[kInstRayTracingOutLaunchIdX] << \", \"\n                 << debug_record[kInstRayTracingOutLaunchIdY] << \", \" << debug_record[kInstRayTracingOutLaunchIdZ] << \"). \";\n        } break;\n        case spv::ExecutionModelMissNV: {\n            strm << \"Stage = Miss.  Global Launch ID (x,y,z) = (\" << debug_record[kInstRayTracingOutLaunchIdX] << \", \"\n                 << debug_record[kInstRayTracingOutLaunchIdY] << \", \" << debug_record[kInstRayTracingOutLaunchIdZ] << \"). \";\n        } break;\n        case spv::ExecutionModelCallableNV: {\n            strm << \"Stage = Callable.  Global Launch ID (x,y,z) = (\" << debug_record[kInstRayTracingOutLaunchIdX] << \", \"\n                 << debug_record[kInstRayTracingOutLaunchIdY] << \", \" << debug_record[kInstRayTracingOutLaunchIdZ] << \"). \";\n        } break;\n        default: {\n            strm << \"Internal Error (unexpected stage = \" << debug_record[kInstCommonOutStageIdx] << \"). \";\n            assert(false);\n        } break;\n    }\n    msg = strm.str();\n}\n\n// Generate the part of the message describing the violation.\nstatic void GenerateValidationMessage(const uint32_t *debug_record, std::string &msg, std::string &vuid_msg) {\n    using namespace spvtools;\n    std::ostringstream strm;\n    switch (debug_record[kInstValidationOutError]) {\n        case 0: {\n            strm << \"Index of \" << debug_record[kInstBindlessOutDescIndex] << \" used to index descriptor array of length \"\n                 << debug_record[kInstBindlessOutDescBound] << \". \";\n            vuid_msg = \"UNASSIGNED-Descriptor index out of bounds\";\n        } break;\n        case 1: {\n            strm << \"Descriptor index \" << debug_record[kInstBindlessOutDescIndex] << \" is uninitialized. \";\n            vuid_msg = \"UNASSIGNED-Descriptor uninitialized\";\n        } break;\n        default: {\n            strm << \"Internal Error (unexpected error type = \" << debug_record[kInstValidationOutError] << \"). \";\n            vuid_msg = \"UNASSIGNED-Internal Error\";\n            assert(false);\n        } break;\n    }\n    msg = strm.str();\n}\n\nstatic std::string LookupDebugUtilsName(const debug_report_data *report_data, const uint64_t object) {\n    auto object_label = report_data->DebugReportGetUtilsObjectName(object);\n    if (object_label != \"\") {\n        object_label = \"(\" + object_label + \")\";\n    }\n    return object_label;\n}\n\n// Generate message from the common portion of the debug report record.\nstatic void GenerateCommonMessage(const debug_report_data *report_data, const CMD_BUFFER_STATE *cb_node,\n                                  const uint32_t *debug_record, const VkShaderModule shader_module_handle,\n                                  const VkPipeline pipeline_handle, const VkPipelineBindPoint pipeline_bind_point,\n                                  const uint32_t operation_index, std::string &msg) {\n    using namespace spvtools;\n    std::ostringstream strm;\n    if (shader_module_handle == VK_NULL_HANDLE) {\n        strm << std::hex << std::showbase << \"Internal Error: Unable to locate information for shader used in command buffer \"\n             << LookupDebugUtilsName(report_data, HandleToUint64(cb_node->commandBuffer)) << \"(\"\n             << HandleToUint64(cb_node->commandBuffer) << \"). \";\n        assert(true);\n    } else {\n        strm << std::hex << std::showbase << \"Command buffer \"\n             << LookupDebugUtilsName(report_data, HandleToUint64(cb_node->commandBuffer)) << \"(\"\n             << HandleToUint64(cb_node->commandBuffer) << \"). \";\n        if (pipeline_bind_point == VK_PIPELINE_BIND_POINT_GRAPHICS) {\n            strm << \"Draw \";\n        } else if (pipeline_bind_point == VK_PIPELINE_BIND_POINT_COMPUTE) {\n            strm << \"Compute \";\n        } else if (pipeline_bind_point == VK_PIPELINE_BIND_POINT_RAY_TRACING_NV) {\n            strm << \"Ray Trace \";\n        } else {\n            assert(false);\n            strm << \"Unknown Pipeline Operation \";\n        }\n        strm << \"Index \" << operation_index << \". \"\n             << \"Pipeline \" << LookupDebugUtilsName(report_data, HandleToUint64(pipeline_handle)) << \"(\"\n             << HandleToUint64(pipeline_handle) << \"). \"\n             << \"Shader Module \" << LookupDebugUtilsName(report_data, HandleToUint64(shader_module_handle)) << \"(\"\n             << HandleToUint64(shader_module_handle) << \"). \";\n    }\n    strm << std::dec << std::noshowbase;\n    strm << \"Shader Instruction Index = \" << debug_record[kInstCommonOutInstructionIdx] << \". \";\n    msg = strm.str();\n}\n\n// Read the contents of the SPIR-V OpSource instruction and any following continuation instructions.\n// Split the single string into a vector of strings, one for each line, for easier processing.\nstatic void ReadOpSource(const SHADER_MODULE_STATE &shader, const uint32_t reported_file_id,\n                         std::vector<std::string> &opsource_lines) {\n    for (auto insn : shader) {\n        if ((insn.opcode() == spv::OpSource) && (insn.len() >= 5) && (insn.word(3) == reported_file_id)) {\n            std::istringstream in_stream;\n            std::string cur_line;\n            in_stream.str((char *)&insn.word(4));\n            while (std::getline(in_stream, cur_line)) {\n                opsource_lines.push_back(cur_line);\n            }\n            while ((++insn).opcode() == spv::OpSourceContinued) {\n                in_stream.str((char *)&insn.word(1));\n                while (std::getline(in_stream, cur_line)) {\n                    opsource_lines.push_back(cur_line);\n                }\n            }\n            break;\n        }\n    }\n}\n\n// The task here is to search the OpSource content to find the #line directive with the\n// line number that is closest to, but still prior to the reported error line number and\n// still within the reported filename.\n// From this known position in the OpSource content we can add the difference between\n// the #line line number and the reported error line number to determine the location\n// in the OpSource content of the reported error line.\n//\n// Considerations:\n// - Look only at #line directives that specify the reported_filename since\n//   the reported error line number refers to its location in the reported filename.\n// - If a #line directive does not have a filename, the file is the reported filename, or\n//   the filename found in a prior #line directive.  (This is C-preprocessor behavior)\n// - It is possible (e.g., inlining) for blocks of code to get shuffled out of their\n//   original order and the #line directives are used to keep the numbering correct.  This\n//   is why we need to examine the entire contents of the source, instead of leaving early\n//   when finding a #line line number larger than the reported error line number.\n//\n\n// GCC 4.8 has a problem with std::regex that is fixed in GCC 4.9.  Provide fallback code for 4.8\n#define GCC_VERSION (__GNUC__ * 10000 + __GNUC_MINOR__ * 100 + __GNUC_PATCHLEVEL__)\n\n#if defined(__GNUC__) && GCC_VERSION < 40900\nstatic bool GetLineAndFilename(const std::string string, uint32_t *linenumber, std::string &filename) {\n    // # line <linenumber> \"<filename>\" or\n    // #line <linenumber> \"<filename>\"\n    std::vector<std::string> tokens;\n    std::stringstream stream(string);\n    std::string temp;\n    uint32_t line_index = 0;\n\n    while (stream >> temp) tokens.push_back(temp);\n    auto size = tokens.size();\n    if (size > 1) {\n        if (tokens[0] == \"#\" && tokens[1] == \"line\") {\n            line_index = 2;\n        } else if (tokens[0] == \"#line\") {\n            line_index = 1;\n        }\n    }\n    if (0 == line_index) return false;\n    *linenumber = std::stoul(tokens[line_index]);\n    uint32_t filename_index = line_index + 1;\n    // Remove enclosing double quotes around filename\n    if (size > filename_index) filename = tokens[filename_index].substr(1, tokens[filename_index].size() - 2);\n    return true;\n}\n#else\nstatic bool GetLineAndFilename(const std::string string, uint32_t *linenumber, std::string &filename) {\n    static const std::regex line_regex(  // matches #line directives\n        \"^\"                              // beginning of line\n        \"\\\\s*\"                           // optional whitespace\n        \"#\"                              // required text\n        \"\\\\s*\"                           // optional whitespace\n        \"line\"                           // required text\n        \"\\\\s+\"                           // required whitespace\n        \"([0-9]+)\"                       // required first capture - line number\n        \"(\\\\s+)?\"                        // optional second capture - whitespace\n        \"(\\\".+\\\")?\"                      // optional third capture - quoted filename with at least one char inside\n        \".*\");                           // rest of line (needed when using std::regex_match since the entire line is tested)\n\n    std::smatch captures;\n\n    bool found_line = std::regex_match(string, captures, line_regex);\n    if (!found_line) return false;\n\n    // filename is optional and considered found only if the whitespace and the filename are captured\n    if (captures[2].matched && captures[3].matched) {\n        // Remove enclosing double quotes.  The regex guarantees the quotes and at least one char.\n        filename = captures[3].str().substr(1, captures[3].str().size() - 2);\n    }\n    *linenumber = std::stoul(captures[1]);\n    return true;\n}\n#endif  // GCC_VERSION\n\n// Extract the filename, line number, and column number from the correct OpLine and build a message string from it.\n// Scan the source (from OpSource) to find the line of source at the reported line number and place it in another message string.\nstatic void GenerateSourceMessages(const std::vector<unsigned int> &pgm, const uint32_t *debug_record, std::string &filename_msg,\n                                   std::string &source_msg) {\n    using namespace spvtools;\n    std::ostringstream filename_stream;\n    std::ostringstream source_stream;\n    SHADER_MODULE_STATE shader;\n    shader.words = pgm;\n    // Find the OpLine just before the failing instruction indicated by the debug info.\n    // SPIR-V can only be iterated in the forward direction due to its opcode/length encoding.\n    uint32_t instruction_index = 0;\n    uint32_t reported_file_id = 0;\n    uint32_t reported_line_number = 0;\n    uint32_t reported_column_number = 0;\n    if (shader.words.size() > 0) {\n        for (auto insn : shader) {\n            if (insn.opcode() == spv::OpLine) {\n                reported_file_id = insn.word(1);\n                reported_line_number = insn.word(2);\n                reported_column_number = insn.word(3);\n            }\n            if (instruction_index == debug_record[kInstCommonOutInstructionIdx]) {\n                break;\n            }\n            instruction_index++;\n        }\n    }\n    // Create message with file information obtained from the OpString pointed to by the discovered OpLine.\n    std::string reported_filename;\n    if (reported_file_id == 0) {\n        filename_stream\n            << \"Unable to find SPIR-V OpLine for source information.  Build shader with debug info to get source information.\";\n    } else {\n        bool found_opstring = false;\n        for (auto insn : shader) {\n            if ((insn.opcode() == spv::OpString) && (insn.len() >= 3) && (insn.word(1) == reported_file_id)) {\n                found_opstring = true;\n                reported_filename = (char *)&insn.word(2);\n                if (reported_filename.empty()) {\n                    filename_stream << \"Shader validation error occurred at line \" << reported_line_number;\n                } else {\n                    filename_stream << \"Shader validation error occurred in file: \" << reported_filename << \" at line \"\n                                    << reported_line_number;\n                }\n                if (reported_column_number > 0) {\n                    filename_stream << \", column \" << reported_column_number;\n                }\n                filename_stream << \".\";\n                break;\n            }\n        }\n        if (!found_opstring) {\n            filename_stream << \"Unable to find SPIR-V OpString for file id \" << reported_file_id << \" from OpLine instruction.\";\n        }\n    }\n    filename_msg = filename_stream.str();\n\n    // Create message to display source code line containing error.\n    if ((reported_file_id != 0)) {\n        // Read the source code and split it up into separate lines.\n        std::vector<std::string> opsource_lines;\n        ReadOpSource(shader, reported_file_id, opsource_lines);\n        // Find the line in the OpSource content that corresponds to the reported error file and line.\n        if (!opsource_lines.empty()) {\n            uint32_t saved_line_number = 0;\n            std::string current_filename = reported_filename;  // current \"preprocessor\" filename state.\n            std::vector<std::string>::size_type saved_opsource_offset = 0;\n            bool found_best_line = false;\n            for (auto it = opsource_lines.begin(); it != opsource_lines.end(); ++it) {\n                uint32_t parsed_line_number;\n                std::string parsed_filename;\n                bool found_line = GetLineAndFilename(*it, &parsed_line_number, parsed_filename);\n                if (!found_line) continue;\n\n                bool found_filename = parsed_filename.size() > 0;\n                if (found_filename) {\n                    current_filename = parsed_filename;\n                }\n                if ((!found_filename) || (current_filename == reported_filename)) {\n                    // Update the candidate best line directive, if the current one is prior and closer to the reported line\n                    if (reported_line_number >= parsed_line_number) {\n                        if (!found_best_line ||\n                            (reported_line_number - parsed_line_number <= reported_line_number - saved_line_number)) {\n                            saved_line_number = parsed_line_number;\n                            saved_opsource_offset = std::distance(opsource_lines.begin(), it);\n                            found_best_line = true;\n                        }\n                    }\n                }\n            }\n            if (found_best_line) {\n                assert(reported_line_number >= saved_line_number);\n                std::vector<std::string>::size_type opsource_index =\n                    (reported_line_number - saved_line_number) + 1 + saved_opsource_offset;\n                if (opsource_index < opsource_lines.size()) {\n                    source_stream << \"\\n\" << reported_line_number << \": \" << opsource_lines[opsource_index].c_str();\n                } else {\n                    source_stream << \"Internal error: calculated source line of \" << opsource_index << \" for source size of \"\n                                  << opsource_lines.size() << \" lines.\";\n                }\n            } else {\n                source_stream << \"Unable to find suitable #line directive in SPIR-V OpSource.\";\n            }\n        } else {\n            source_stream << \"Unable to find SPIR-V OpSource.\";\n        }\n    }\n    source_msg = source_stream.str();\n}\n\n// Pull together all the information from the debug record to build the error message strings,\n// and then assemble them into a single message string.\n// Retrieve the shader program referenced by the unique shader ID provided in the debug record.\n// We had to keep a copy of the shader program with the same lifecycle as the pipeline to make\n// sure it is available when the pipeline is submitted.  (The ShaderModule tracking object also\n// keeps a copy, but it can be destroyed after the pipeline is created and before it is submitted.)\n//\nvoid CoreChecks::AnalyzeAndReportError(CMD_BUFFER_STATE *cb_node, VkQueue queue, VkPipelineBindPoint pipeline_bind_point,\n                                       uint32_t operation_index, uint32_t *const debug_output_buffer) {\n    using namespace spvtools;\n    const uint32_t total_words = debug_output_buffer[0];\n    // A zero here means that the shader instrumentation didn't write anything.\n    // If you have nothing to say, don't say it here.\n    if (0 == total_words) {\n        return;\n    }\n    // The first word in the debug output buffer is the number of words that would have\n    // been written by the shader instrumentation, if there was enough room in the buffer we provided.\n    // The number of words actually written by the shaders is determined by the size of the buffer\n    // we provide via the descriptor.  So, we process only the number of words that can fit in the\n    // buffer.\n    // Each \"report\" written by the shader instrumentation is considered a \"record\".  This function\n    // is hard-coded to process only one record because it expects the buffer to be large enough to\n    // hold only one record.  If there is a desire to process more than one record, this function needs\n    // to be modified to loop over records and the buffer size increased.\n    std::string validation_message;\n    std::string stage_message;\n    std::string common_message;\n    std::string filename_message;\n    std::string source_message;\n    std::string vuid_msg;\n    VkShaderModule shader_module_handle = VK_NULL_HANDLE;\n    VkPipeline pipeline_handle = VK_NULL_HANDLE;\n    std::vector<unsigned int> pgm;\n    // The first record starts at this offset after the total_words.\n    const uint32_t *debug_record = &debug_output_buffer[kDebugOutputDataOffset];\n    // Lookup the VkShaderModule handle and SPIR-V code used to create the shader, using the unique shader ID value returned\n    // by the instrumented shader.\n    auto it = gpu_validation_state->shader_map.find(debug_record[kInstCommonOutShaderId]);\n    if (it != gpu_validation_state->shader_map.end()) {\n        shader_module_handle = it->second.shader_module;\n        pipeline_handle = it->second.pipeline;\n        pgm = it->second.pgm;\n    }\n    GenerateValidationMessage(debug_record, validation_message, vuid_msg);\n    GenerateStageMessage(debug_record, stage_message);\n    GenerateCommonMessage(report_data, cb_node, debug_record, shader_module_handle, pipeline_handle, pipeline_bind_point,\n                          operation_index, common_message);\n    GenerateSourceMessages(pgm, debug_record, filename_message, source_message);\n    log_msg(report_data, VK_DEBUG_REPORT_ERROR_BIT_EXT, VK_DEBUG_REPORT_OBJECT_TYPE_QUEUE_EXT, HandleToUint64(queue),\n            vuid_msg.c_str(), \"%s %s %s %s%s\", validation_message.c_str(), common_message.c_str(), stage_message.c_str(),\n            filename_message.c_str(), source_message.c_str());\n    // The debug record at word kInstCommonOutSize is the number of words in the record\n    // written by the shader.  Clear the entire record plus the total_words word at the start.\n    const uint32_t words_to_clear = 1 + std::min(debug_record[kInstCommonOutSize], (uint32_t)kInstMaxOutCnt);\n    memset(debug_output_buffer, 0, sizeof(uint32_t) * words_to_clear);\n}\n\n// For the given command buffer, map its debug data buffers and read their contents for analysis.\nvoid CoreChecks::ProcessInstrumentationBuffer(VkQueue queue, CMD_BUFFER_STATE *cb_node) {\n    auto gpu_buffer_list = gpu_validation_state->GetGpuBufferInfo(cb_node->commandBuffer);\n    if (cb_node && (cb_node->hasDrawCmd || cb_node->hasTraceRaysCmd) && gpu_buffer_list.size() > 0) {\n        VkResult result;\n        char *pData;\n        uint32_t draw_index = 0;\n        uint32_t compute_index = 0;\n        uint32_t ray_trace_index = 0;\n\n        for (auto &buffer_info : gpu_buffer_list) {\n            result = vmaMapMemory(gpu_validation_state->vmaAllocator, buffer_info.output_mem_block.allocation, (void **)&pData);\n            // Analyze debug output buffer\n            if (result == VK_SUCCESS) {\n                uint32_t operation_index = 0;\n                if (buffer_info.pipeline_bind_point == VK_PIPELINE_BIND_POINT_GRAPHICS) {\n                    operation_index = draw_index;\n                } else if (buffer_info.pipeline_bind_point == VK_PIPELINE_BIND_POINT_COMPUTE) {\n                    operation_index = compute_index;\n                } else if (buffer_info.pipeline_bind_point == VK_PIPELINE_BIND_POINT_RAY_TRACING_NV) {\n                    operation_index = ray_trace_index;\n                } else {\n                    assert(false);\n                }\n\n                AnalyzeAndReportError(cb_node, queue, buffer_info.pipeline_bind_point, operation_index, (uint32_t *)pData);\n                vmaUnmapMemory(gpu_validation_state->vmaAllocator, buffer_info.output_mem_block.allocation);\n            }\n\n            if (buffer_info.pipeline_bind_point == VK_PIPELINE_BIND_POINT_GRAPHICS) {\n                draw_index++;\n            } else if (buffer_info.pipeline_bind_point == VK_PIPELINE_BIND_POINT_COMPUTE) {\n                compute_index++;\n            } else if (buffer_info.pipeline_bind_point == VK_PIPELINE_BIND_POINT_RAY_TRACING_NV) {\n                ray_trace_index++;\n            } else {\n                assert(false);\n            }\n        }\n    }\n}\n\n// For the given command buffer, map its debug data buffers and update the status of any update after bind descriptors\nvoid CoreChecks::UpdateInstrumentationBuffer(CMD_BUFFER_STATE *cb_node) {\n    auto gpu_buffer_list = gpu_validation_state->GetGpuBufferInfo(cb_node->commandBuffer);\n    uint32_t *pData;\n    for (auto &buffer_info : gpu_buffer_list) {\n        if (buffer_info.input_mem_block.update_at_submit.size() > 0) {\n            VkResult result =\n                vmaMapMemory(gpu_validation_state->vmaAllocator, buffer_info.input_mem_block.allocation, (void **)&pData);\n            if (result == VK_SUCCESS) {\n                for (auto update : buffer_info.input_mem_block.update_at_submit) {\n                    if (update.second->updated) pData[update.first] = 1;\n                }\n                vmaUnmapMemory(gpu_validation_state->vmaAllocator, buffer_info.input_mem_block.allocation);\n            }\n        }\n    }\n}\n\n// Submit a memory barrier on graphics queues.\n// Lazy-create and record the needed command buffer.\nvoid CoreChecks::SubmitBarrier(VkQueue queue) {\n    auto queue_barrier_command_info_it =\n        gpu_validation_state->queue_barrier_command_infos.emplace(queue, GpuQueueBarrierCommandInfo{});\n    if (queue_barrier_command_info_it.second) {\n        GpuQueueBarrierCommandInfo &quere_barrier_command_info = queue_barrier_command_info_it.first->second;\n\n        uint32_t queue_family_index = 0;\n\n        auto queue_state_it = queueMap.find(queue);\n        if (queue_state_it != queueMap.end()) {\n            queue_family_index = queue_state_it->second.queueFamilyIndex;\n        }\n\n        VkResult result = VK_SUCCESS;\n\n        VkCommandPoolCreateInfo pool_create_info = {};\n        pool_create_info.sType = VK_STRUCTURE_TYPE_COMMAND_POOL_CREATE_INFO;\n        pool_create_info.queueFamilyIndex = queue_family_index;\n        result = DispatchCreateCommandPool(device, &pool_create_info, nullptr, &quere_barrier_command_info.barrier_command_pool);\n        if (result != VK_SUCCESS) {\n            ReportSetupProblem(VK_DEBUG_REPORT_OBJECT_TYPE_DEVICE_EXT, HandleToUint64(device),\n                               \"Unable to create command pool for barrier CB.\");\n            quere_barrier_command_info.barrier_command_pool = VK_NULL_HANDLE;\n            return;\n        }\n\n        VkCommandBufferAllocateInfo buffer_alloc_info = {};\n        buffer_alloc_info.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_ALLOCATE_INFO;\n        buffer_alloc_info.commandPool = quere_barrier_command_info.barrier_command_pool;\n        buffer_alloc_info.commandBufferCount = 1;\n        buffer_alloc_info.level = VK_COMMAND_BUFFER_LEVEL_PRIMARY;\n        result = DispatchAllocateCommandBuffers(device, &buffer_alloc_info, &quere_barrier_command_info.barrier_command_buffer);\n        if (result != VK_SUCCESS) {\n            ReportSetupProblem(VK_DEBUG_REPORT_OBJECT_TYPE_DEVICE_EXT, HandleToUint64(device),\n                               \"Unable to create barrier command buffer.\");\n            DispatchDestroyCommandPool(device, quere_barrier_command_info.barrier_command_pool, nullptr);\n            quere_barrier_command_info.barrier_command_pool = VK_NULL_HANDLE;\n            quere_barrier_command_info.barrier_command_buffer = VK_NULL_HANDLE;\n            return;\n        }\n\n        // Hook up command buffer dispatch\n        gpu_validation_state->vkSetDeviceLoaderData(device, quere_barrier_command_info.barrier_command_buffer);\n\n        // Record a global memory barrier to force availability of device memory operations to the host domain.\n        VkCommandBufferBeginInfo command_buffer_begin_info = {};\n        command_buffer_begin_info.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_BEGIN_INFO;\n        result = DispatchBeginCommandBuffer(quere_barrier_command_info.barrier_command_buffer, &command_buffer_begin_info);\n        if (result == VK_SUCCESS) {\n            VkMemoryBarrier memory_barrier = {};\n            memory_barrier.sType = VK_STRUCTURE_TYPE_MEMORY_BARRIER;\n            memory_barrier.srcAccessMask = VK_ACCESS_MEMORY_WRITE_BIT;\n            memory_barrier.dstAccessMask = VK_ACCESS_HOST_READ_BIT;\n\n            DispatchCmdPipelineBarrier(quere_barrier_command_info.barrier_command_buffer, VK_PIPELINE_STAGE_ALL_COMMANDS_BIT,\n                                       VK_PIPELINE_STAGE_HOST_BIT, 0, 1, &memory_barrier, 0, nullptr, 0, nullptr);\n            DispatchEndCommandBuffer(quere_barrier_command_info.barrier_command_buffer);\n        }\n    }\n\n    GpuQueueBarrierCommandInfo &quere_barrier_command_info = queue_barrier_command_info_it.first->second;\n    if (quere_barrier_command_info.barrier_command_buffer != VK_NULL_HANDLE) {\n        VkSubmitInfo submit_info = {};\n        submit_info.sType = VK_STRUCTURE_TYPE_SUBMIT_INFO;\n        submit_info.commandBufferCount = 1;\n        submit_info.pCommandBuffers = &quere_barrier_command_info.barrier_command_buffer;\n        DispatchQueueSubmit(queue, 1, &submit_info, VK_NULL_HANDLE);\n    }\n}\n\nvoid CoreChecks::GpuPreCallRecordQueueSubmit(VkQueue queue, uint32_t submitCount, const VkSubmitInfo *pSubmits, VkFence fence) {\n    for (uint32_t submit_idx = 0; submit_idx < submitCount; submit_idx++) {\n        const VkSubmitInfo *submit = &pSubmits[submit_idx];\n        for (uint32_t i = 0; i < submit->commandBufferCount; i++) {\n            auto cb_node = GetCBState(submit->pCommandBuffers[i]);\n            UpdateInstrumentationBuffer(cb_node);\n            for (auto secondaryCmdBuffer : cb_node->linkedCommandBuffers) {\n                UpdateInstrumentationBuffer(secondaryCmdBuffer);\n            }\n        }\n    }\n}\n\n// Issue a memory barrier to make GPU-written data available to host.\n// Wait for the queue to complete execution.\n// Check the debug buffers for all the command buffers that were submitted.\nvoid CoreChecks::GpuPostCallQueueSubmit(VkQueue queue, uint32_t submitCount, const VkSubmitInfo *pSubmits, VkFence fence) {\n    if (gpu_validation_state->aborted) return;\n\n    SubmitBarrier(queue);\n\n    DispatchQueueWaitIdle(queue);\n\n    for (uint32_t submit_idx = 0; submit_idx < submitCount; submit_idx++) {\n        const VkSubmitInfo *submit = &pSubmits[submit_idx];\n        for (uint32_t i = 0; i < submit->commandBufferCount; i++) {\n            auto cb_node = GetCBState(submit->pCommandBuffers[i]);\n            ProcessInstrumentationBuffer(queue, cb_node);\n            for (auto secondaryCmdBuffer : cb_node->linkedCommandBuffers) {\n                ProcessInstrumentationBuffer(queue, secondaryCmdBuffer);\n            }\n        }\n    }\n}\n\nvoid CoreChecks::GpuAllocateValidationResources(const VkCommandBuffer cmd_buffer, const VkPipelineBindPoint bind_point) {\n    if (bind_point != VK_PIPELINE_BIND_POINT_GRAPHICS && bind_point != VK_PIPELINE_BIND_POINT_COMPUTE &&\n        bind_point != VK_PIPELINE_BIND_POINT_RAY_TRACING_NV) {\n        return;\n    }\n    VkResult result;\n\n    if (!(enabled.gpu_validation)) return;\n\n    if (gpu_validation_state->aborted) return;\n\n    std::vector<VkDescriptorSet> desc_sets;\n    VkDescriptorPool desc_pool = VK_NULL_HANDLE;\n    result = gpu_validation_state->desc_set_manager->GetDescriptorSets(1, &desc_pool, &desc_sets);\n    assert(result == VK_SUCCESS);\n    if (result != VK_SUCCESS) {\n        ReportSetupProblem(VK_DEBUG_REPORT_OBJECT_TYPE_DEVICE_EXT, HandleToUint64(device),\n                           \"Unable to allocate descriptor sets.  Device could become unstable.\");\n        gpu_validation_state->aborted = true;\n        return;\n    }\n\n    VkDescriptorBufferInfo output_desc_buffer_info = {};\n    output_desc_buffer_info.range = gpu_validation_state->output_buffer_size;\n\n    auto cb_node = GetCBState(cmd_buffer);\n    if (!cb_node) {\n        ReportSetupProblem(VK_DEBUG_REPORT_OBJECT_TYPE_DEVICE_EXT, HandleToUint64(device), \"Unrecognized command buffer\");\n        gpu_validation_state->aborted = true;\n        return;\n    }\n\n    // Allocate memory for the output block that the gpu will use to return any error information\n    GpuDeviceMemoryBlock output_block = {};\n    VkBufferCreateInfo bufferInfo = {VK_STRUCTURE_TYPE_BUFFER_CREATE_INFO};\n    bufferInfo.size = gpu_validation_state->output_buffer_size;\n    bufferInfo.usage = VK_BUFFER_USAGE_STORAGE_BUFFER_BIT;\n    VmaAllocationCreateInfo allocInfo = {};\n    allocInfo.usage = VMA_MEMORY_USAGE_GPU_TO_CPU;\n    result = vmaCreateBuffer(gpu_validation_state->vmaAllocator, &bufferInfo, &allocInfo, &output_block.buffer,\n                             &output_block.allocation, nullptr);\n    if (result != VK_SUCCESS) {\n        ReportSetupProblem(VK_DEBUG_REPORT_OBJECT_TYPE_DEVICE_EXT, HandleToUint64(device),\n                           \"Unable to allocate device memory.  Device could become unstable.\");\n        gpu_validation_state->aborted = true;\n        return;\n    }\n\n    // Clear the output block to zeros so that only error information from the gpu will be present\n    uint32_t *pData;\n    result = vmaMapMemory(gpu_validation_state->vmaAllocator, output_block.allocation, (void **)&pData);\n    if (result == VK_SUCCESS) {\n        memset(pData, 0, gpu_validation_state->output_buffer_size);\n        vmaUnmapMemory(gpu_validation_state->vmaAllocator, output_block.allocation);\n    }\n\n    GpuDeviceMemoryBlock input_block = {};\n    VkWriteDescriptorSet desc_writes[2] = {};\n    uint32_t desc_count = 1;\n    auto const &state = cb_node->lastBound[bind_point];\n    uint32_t number_of_sets = (uint32_t)state.boundDescriptorSets.size();\n\n    // Figure out how much memory we need for the input block based on how many sets and bindings there are\n    // and how big each of the bindings is\n    if (number_of_sets > 0 && device_extensions.vk_ext_descriptor_indexing) {\n        uint32_t descriptor_count = 0;  // Number of descriptors, including all array elements\n        uint32_t binding_count = 0;     // Number of bindings based on the max binding number used\n        for (auto desc : state.boundDescriptorSets) {\n            auto bindings = desc->GetLayout()->GetSortedBindingSet();\n            if (bindings.size() > 0) {\n                binding_count += desc->GetLayout()->GetMaxBinding() + 1;\n                for (auto binding : bindings) {\n                    if (binding == desc->GetLayout()->GetMaxBinding() && desc->IsVariableDescriptorCount(binding)) {\n                        descriptor_count += desc->GetVariableDescriptorCount();\n                    } else {\n                        descriptor_count += desc->GetDescriptorCountFromBinding(binding);\n                    }\n                }\n            }\n        }\n\n        // Note that the size of the input buffer is dependent on the maximum binding number, which\n        // can be very large.  This is because for (set = s, binding = b, index = i), the validation\n        // code is going to dereference Input[ i + Input[ b + Input[ s + Input[ Input[0] ] ] ] ] to\n        // see if descriptors have been written. In gpu_validation.md, we note this and advise\n        // using densely packed bindings as a best practice when using gpu-av with descriptor indexing\n        uint32_t words_needed = 1 + (number_of_sets * 2) + (binding_count * 2) + descriptor_count;\n        allocInfo.usage = VMA_MEMORY_USAGE_CPU_TO_GPU;\n        bufferInfo.size = words_needed * 4;\n        result = vmaCreateBuffer(gpu_validation_state->vmaAllocator, &bufferInfo, &allocInfo, &input_block.buffer,\n                                 &input_block.allocation, nullptr);\n        if (result != VK_SUCCESS) {\n            ReportSetupProblem(VK_DEBUG_REPORT_OBJECT_TYPE_DEVICE_EXT, HandleToUint64(device),\n                               \"Unable to allocate device memory.  Device could become unstable.\");\n            gpu_validation_state->aborted = true;\n            return;\n        }\n\n        // Populate input buffer first with the sizes of every descriptor in every set, then with whether\n        // each element of each descriptor has been written or not.  See gpu_validation.md for a more thourough\n        // outline of the input buffer format\n        result = vmaMapMemory(gpu_validation_state->vmaAllocator, input_block.allocation, (void **)&pData);\n        memset(pData, 0, static_cast<size_t>(bufferInfo.size));\n        // Pointer to a sets array that points into the sizes array\n        uint32_t *sets_to_sizes = pData + 1;\n        // Pointer to the sizes array that contains the array size of the descriptor at each binding\n        uint32_t *sizes = sets_to_sizes + number_of_sets;\n        // Pointer to another sets array that points into the bindings array that points into the written array\n        uint32_t *sets_to_bindings = sizes + binding_count;\n        // Pointer to the bindings array that points at the start of the writes in the writes array for each binding\n        uint32_t *bindings_to_written = sets_to_bindings + number_of_sets;\n        // Index of the next entry in the written array to be updated\n        uint32_t written_index = 1 + (number_of_sets * 2) + (binding_count * 2);\n        uint32_t bindCounter = number_of_sets + 1;\n        // Index of the start of the sets_to_bindings array\n        pData[0] = number_of_sets + binding_count + 1;\n\n        for (auto desc : state.boundDescriptorSets) {\n            auto layout = desc->GetLayout();\n            auto bindings = layout->GetSortedBindingSet();\n            if (bindings.size() > 0) {\n                // For each set, fill in index of its bindings sizes in the sizes array\n                *sets_to_sizes++ = bindCounter;\n                // For each set, fill in the index of its bindings in the bindings_to_written array\n                *sets_to_bindings++ = bindCounter + number_of_sets + binding_count;\n                for (auto binding : bindings) {\n                    // For each binding, fill in its size in the sizes array\n                    if (binding == layout->GetMaxBinding() && desc->IsVariableDescriptorCount(binding)) {\n                        sizes[binding] = desc->GetVariableDescriptorCount();\n                    } else {\n                        sizes[binding] = desc->GetDescriptorCountFromBinding(binding);\n                    }\n                    // Fill in the starting index for this binding in the written array in the bindings_to_written array\n                    bindings_to_written[binding] = written_index;\n\n                    auto index_range = desc->GetGlobalIndexRangeFromBinding(binding, true);\n                    // For each array element in the binding, update the written array with whether it has been written\n                    for (uint32_t i = index_range.start; i < index_range.end; ++i) {\n                        auto *descriptor = desc->GetDescriptorFromGlobalIndex(i);\n                        if (descriptor->updated) {\n                            pData[written_index] = 1;\n                        } else if (desc->IsUpdateAfterBind(binding)) {\n                            // If it hasn't been written now and it's update after bind, put it in a list to check at QueueSubmit\n                            input_block.update_at_submit[written_index] = descriptor;\n                        }\n                        written_index++;\n                    }\n                }\n                auto last = desc->GetLayout()->GetMaxBinding();\n                bindings_to_written += last + 1;\n                bindCounter += last + 1;\n                sizes += last + 1;\n            } else {\n                *sets_to_sizes++ = 0;\n                *sets_to_bindings++ = 0;\n            }\n        }\n        vmaUnmapMemory(gpu_validation_state->vmaAllocator, input_block.allocation);\n\n        VkDescriptorBufferInfo input_desc_buffer_info = {};\n        input_desc_buffer_info.range = (words_needed * 4);\n        input_desc_buffer_info.buffer = input_block.buffer;\n        input_desc_buffer_info.offset = 0;\n\n        desc_writes[1].sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET;\n        desc_writes[1].dstBinding = 1;\n        desc_writes[1].descriptorCount = 1;\n        desc_writes[1].descriptorType = VK_DESCRIPTOR_TYPE_STORAGE_BUFFER;\n        desc_writes[1].pBufferInfo = &input_desc_buffer_info;\n        desc_writes[1].dstSet = desc_sets[0];\n\n        desc_count = 2;\n    }\n\n    // Write the descriptor\n    output_desc_buffer_info.buffer = output_block.buffer;\n    output_desc_buffer_info.offset = 0;\n\n    desc_writes[0].sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET;\n    desc_writes[0].descriptorCount = 1;\n    desc_writes[0].descriptorType = VK_DESCRIPTOR_TYPE_STORAGE_BUFFER;\n    desc_writes[0].pBufferInfo = &output_desc_buffer_info;\n    desc_writes[0].dstSet = desc_sets[0];\n    DispatchUpdateDescriptorSets(device, desc_count, desc_writes, 0, NULL);\n\n    auto iter = cb_node->lastBound.find(bind_point);  // find() allows read-only access to cb_state\n    if (iter != cb_node->lastBound.end()) {\n        auto pipeline_state = iter->second.pipeline_state;\n        if (pipeline_state && (pipeline_state->pipeline_layout.set_layouts.size() <= gpu_validation_state->desc_set_bind_index)) {\n            DispatchCmdBindDescriptorSets(cmd_buffer, bind_point, pipeline_state->pipeline_layout.layout,\n                                          gpu_validation_state->desc_set_bind_index, 1, desc_sets.data(), 0, nullptr);\n        }\n        // Record buffer and memory info in CB state tracking\n        gpu_validation_state->GetGpuBufferInfo(cmd_buffer)\n            .emplace_back(output_block, input_block, desc_sets[0], desc_pool, bind_point);\n    } else {\n        ReportSetupProblem(VK_DEBUG_REPORT_OBJECT_TYPE_DEVICE_EXT, HandleToUint64(device), \"Unable to find pipeline state\");\n        vmaDestroyBuffer(gpu_validation_state->vmaAllocator, input_block.buffer, input_block.allocation);\n        vmaDestroyBuffer(gpu_validation_state->vmaAllocator, output_block.buffer, output_block.allocation);\n        gpu_validation_state->aborted = true;\n        return;\n    }\n}\n", "idx": 7, "id": 11424, "msg": "", "proj": "KhronosGroup-Vulkan-ValidationLayers", "lang": "cpp"}
{"patch": "@@ -308,8 +308,12 @@ std::string PrimaryExpression::toString() const {\n         case VAR_INT64:\n             snprintf(buf, sizeof(buf), \"%ld\", boost::get<int64_t>(operand_));\n             break;\n-        case VAR_DOUBLE:\n-            return std::to_string(boost::get<double>(operand_));\n+        case VAR_DOUBLE: {\n+            int digits10 = std::numeric_limits<double>::digits10;\n+            const char *fmt = folly::sformat(\"%.{}lf\", digits10).c_str();\n+            snprintf(buf, sizeof(buf), fmt, boost::get<double>(operand_));\n+            break;\n+        }\n         case VAR_BOOL:\n             snprintf(buf, sizeof(buf), \"%s\", boost::get<bool>(operand_) ? \"true\" : \"false\");\n             break;", "y": 1, "oldf": "/* Copyright (c) 2018 vesoft inc. All rights reserved.\n *\n *\n * This source code is licensed under Apache 2.0 License,\n * attached with Common Clause Condition 1.0, found in the LICENSES directory.\n */\n\n#include \"base/Base.h\"\n#include \"base/Cord.h\"\n#include \"filter/Expressions.h\"\n#include \"filter/FunctionManager.h\"\n\n\n#define THROW_IF_NO_SPACE(POS, END, REQUIRE)                                        \\\n    do {                                                                            \\\n        if ((POS) + (REQUIRE) > (END)) {                                            \\\n            throw Status::Error(\"Not enough space left, left: %lu bytes, \"          \\\n                                \"require: %lu bytes, at: %s:%d\", (END) - (POS),     \\\n                                (REQUIRE), __FILE__, __LINE__);                     \\\n        }                                                                           \\\n    } while (false)\n\nnamespace nebula {\n\nnamespace {\nconstexpr char INPUT_REF[] = \"$-\";\nconstexpr char VAR_REF[] = \"$\";\nconstexpr char SRC_REF[] = \"$^\";\nconstexpr char DST_REF[] = \"$$\";\n}   // namespace\n\nvoid Expression::print(const VariantType &value) {\n    switch (value.which()) {\n        case 0:\n            fprintf(stderr, \"%ld\\n\", asInt(value));\n            break;\n        case 1:\n            fprintf(stderr, \"%lf\\n\", asDouble(value));\n            break;\n        case 2:\n            fprintf(stderr, \"%d\\n\", asBool(value));\n            break;\n        case 3:\n            fprintf(stderr, \"%s\\n\", asString(value).c_str());\n            break;\n    }\n}\n\n\nstd::unique_ptr<Expression> Expression::makeExpr(uint8_t kind) {\n    switch (intToKind(kind)) {\n        case kPrimary:\n            return std::make_unique<PrimaryExpression>();\n        case kFunctionCall:\n            return std::make_unique<FunctionCallExpression>();\n        case kUnary:\n            return std::make_unique<UnaryExpression>();\n        case kTypeCasting:\n            return std::make_unique<TypeCastingExpression>();\n        case kUUID:\n            return std::make_unique<UUIDExpression>();\n        case kArithmetic:\n            return std::make_unique<ArithmeticExpression>();\n        case kRelational:\n            return std::make_unique<RelationalExpression>();\n        case kLogical:\n            return std::make_unique<LogicalExpression>();\n        case kSourceProp:\n            return std::make_unique<SourcePropertyExpression>();\n        case kEdgeRank:\n            return std::make_unique<EdgeRankExpression>();\n        case kEdgeDstId:\n            return std::make_unique<EdgeDstIdExpression>();\n        case kEdgeSrcId:\n            return std::make_unique<EdgeSrcIdExpression>();\n        case kEdgeType:\n            return std::make_unique<EdgeTypeExpression>();\n        case kAliasProp:\n            return std::make_unique<AliasPropertyExpression>();\n        case kVariableProp:\n            return std::make_unique<VariablePropertyExpression>();\n        case kDestProp:\n            return std::make_unique<DestPropertyExpression>();\n        case kInputProp:\n            return std::make_unique<InputPropertyExpression>();\n        default:\n            throw Status::Error(\"Illegal expression kind: %u\", kind);\n    }\n}\n\n\n// static\nstd::string Expression::encode(Expression *expr) noexcept {\n    Cord cord(1024);\n    expr->encode(cord);\n    return cord.str();\n}\n\n\n// static\nStatusOr<std::unique_ptr<Expression>>\nExpression::decode(folly::StringPiece buffer) noexcept {\n    auto *pos = buffer.data();\n    auto *end = pos + buffer.size();\n    try {\n        THROW_IF_NO_SPACE(pos, end, 1UL);\n        auto expr = makeExpr(*reinterpret_cast<const uint8_t*>(pos++));\n        pos = expr->decode(pos, end);\n        if (pos != end) {\n            return Status::Error(\"Buffer not consumed up, end: %p, used upto: %p\", end, pos);\n        }\n        return std::move(expr);\n    } catch (const Status &status) {\n        return status;\n    }\n}\n\nstd::string AliasPropertyExpression::toString() const {\n    std::string buf;\n    buf.reserve(64);\n    if (ref_ != nullptr) {\n        buf += *ref_;\n    }\n    if (*ref_ != \"\" && *ref_ != VAR_REF) {\n        buf += \".\";\n    }\n    if (alias_ != nullptr) {\n        buf += *alias_;\n    }\n    if (*alias_ != \"\") {\n        buf += \".\";\n    }\n    if (prop_ != nullptr) {\n        buf += *prop_;\n    }\n    return buf;\n}\n\nOptVariantType AliasPropertyExpression::eval(Getters &getters) const {\n    return getters.getAliasProp(*alias_, *prop_);\n}\n\nStatus AliasPropertyExpression::prepare() {\n    context_->addAliasProp(*alias_, *prop_);\n    return Status::OK();\n}\n\nvoid AliasPropertyExpression::encode(Cord &cord) const {\n    cord << kindToInt(kind());\n    cord << static_cast<uint16_t>(ref_->size());\n    cord << *ref_;\n    cord << static_cast<uint16_t>(alias_->size());\n    cord << *alias_;\n    cord << static_cast<uint16_t>(prop_->size());\n    cord << *prop_;\n}\n\nconst char* AliasPropertyExpression::decode(const char *pos, const char *end) {\n    {\n        THROW_IF_NO_SPACE(pos, end, 2UL);\n        auto size = *reinterpret_cast<const uint16_t*>(pos);\n        pos += 2;\n\n        THROW_IF_NO_SPACE(pos, end, static_cast<uint64_t>(size));\n        ref_ = std::make_unique<std::string>(pos, size);\n        pos += size;\n    }\n    {\n        THROW_IF_NO_SPACE(pos, end, 2UL);\n        auto size = *reinterpret_cast<const uint16_t*>(pos);\n        pos += 2;\n\n        THROW_IF_NO_SPACE(pos, end, static_cast<uint64_t>(size));\n        alias_ = std::make_unique<std::string>(pos, size);\n        pos += size;\n    }\n    {\n        THROW_IF_NO_SPACE(pos, end, 2UL);\n        auto size = *reinterpret_cast<const uint16_t*>(pos);\n        pos += 2;\n\n        THROW_IF_NO_SPACE(pos, end, static_cast<uint64_t>(size));\n        prop_ = std::make_unique<std::string>(pos, size);\n        pos += size;\n    }\n\n    return pos;\n}\n\nInputPropertyExpression::InputPropertyExpression(std::string *prop) {\n    kind_ = kInputProp;\n    ref_.reset(new std::string(INPUT_REF));\n    alias_.reset(new std::string(\"\"));\n    prop_.reset(prop);\n}\n\nStatus InputPropertyExpression::prepare() {\n    context_->addInputProp(*prop_);\n    return Status::OK();\n}\n\n\nOptVariantType InputPropertyExpression::eval(Getters &getters) const {\n    return getters.getInputProp(*prop_);\n}\n\n\nDestPropertyExpression::DestPropertyExpression(std::string *tag, std::string *prop) {\n    kind_ = kDestProp;\n    ref_.reset(new std::string(DST_REF));\n    alias_.reset(tag);\n    prop_.reset(prop);\n}\n\nOptVariantType DestPropertyExpression::eval(Getters &getters) const {\n    return getters.getDstTagProp(*alias_, *prop_);\n}\n\n\nStatus DestPropertyExpression::prepare() {\n    context_->addDstTagProp(*alias_, *prop_);\n    return Status::OK();\n}\n\n\nVariablePropertyExpression::VariablePropertyExpression(std::string *var, std::string *prop) {\n    kind_ = kVariableProp;\n    ref_.reset(new std::string(VAR_REF));\n    alias_.reset(var);\n    prop_.reset(prop);\n}\n\nOptVariantType VariablePropertyExpression::eval(Getters &getters) const {\n    return getters.getVariableProp(*prop_);\n}\n\nStatus VariablePropertyExpression::prepare() {\n    context_->addVariableProp(*alias_, *prop_);\n    return Status::OK();\n}\n\n\nOptVariantType EdgeTypeExpression::eval(Getters &getters) const {\n    UNUSED(getters);\n    return *alias_;\n}\n\nStatus EdgeTypeExpression::prepare() {\n    context_->addAliasProp(*alias_, *prop_);\n    return Status::OK();\n}\n\n\nOptVariantType EdgeSrcIdExpression::eval(Getters &getters) const {\n    return getters.getAliasProp(*alias_, *prop_);\n}\n\n\nStatus EdgeSrcIdExpression::prepare() {\n    context_->addAliasProp(*alias_, *prop_);\n    return Status::OK();\n}\n\n\nOptVariantType EdgeDstIdExpression::eval(Getters &getters) const {\n    return getters.getAliasProp(*alias_, *prop_);\n}\n\n\nStatus EdgeDstIdExpression::prepare() {\n    context_->addAliasProp(*alias_, *prop_);\n    return Status::OK();\n}\n\n\nOptVariantType EdgeRankExpression::eval(Getters &getters) const {\n    return getters.getAliasProp(*alias_, *prop_);\n}\n\n\nStatus EdgeRankExpression::prepare() {\n    context_->addAliasProp(*alias_, *prop_);\n    return Status::OK();\n}\n\n\nSourcePropertyExpression::SourcePropertyExpression(std::string *tag, std::string *prop) {\n    kind_ = kSourceProp;\n    ref_.reset(new std::string(SRC_REF));\n    alias_.reset(tag);\n    prop_.reset(prop);\n}\n\nOptVariantType SourcePropertyExpression::eval(Getters &getters) const {\n    return getters.getSrcTagProp(*alias_, *prop_);\n}\n\n\nStatus SourcePropertyExpression::prepare() {\n    context_->addSrcTagProp(*alias_, *prop_);\n    return Status::OK();\n}\n\n\nstd::string PrimaryExpression::toString() const {\n    char buf[1024];\n    switch (operand_.which()) {\n        case VAR_INT64:\n            snprintf(buf, sizeof(buf), \"%ld\", boost::get<int64_t>(operand_));\n            break;\n        case VAR_DOUBLE:\n            return std::to_string(boost::get<double>(operand_));\n        case VAR_BOOL:\n            snprintf(buf, sizeof(buf), \"%s\", boost::get<bool>(operand_) ? \"true\" : \"false\");\n            break;\n        case VAR_STR:\n            return boost::get<std::string>(operand_);\n    }\n    return buf;\n}\n\nOptVariantType PrimaryExpression::eval(Getters &getters) const {\n    UNUSED(getters);\n    switch (operand_.which()) {\n        case VAR_INT64:\n            return boost::get<int64_t>(operand_);\n            break;\n        case VAR_DOUBLE:\n            return boost::get<double>(operand_);\n            break;\n        case VAR_BOOL:\n            return boost::get<bool>(operand_);\n            break;\n        case VAR_STR:\n            return boost::get<std::string>(operand_);\n    }\n\n    return OptVariantType(Status::Error(\"Unknown type\"));\n}\n\nStatus PrimaryExpression::prepare() {\n    return Status::OK();\n}\n\n\nvoid PrimaryExpression::encode(Cord &cord) const {\n    cord << kindToInt(kind());\n    uint8_t which = operand_.which();\n    cord << which;\n    switch (which) {\n        case VAR_INT64:\n            cord << boost::get<int64_t>(operand_);\n            break;\n        case VAR_DOUBLE:\n            cord << boost::get<double>(operand_);\n            break;\n        case VAR_BOOL:\n            cord << static_cast<uint8_t>(boost::get<bool>(operand_));\n            break;\n        case VAR_STR: {\n            auto &str = boost::get<std::string>(operand_);\n            cord << static_cast<uint16_t>(str.size());\n            cord << str;\n            break;\n        }\n        default:\n            DCHECK(false);\n    }\n}\n\n\nconst char* PrimaryExpression::decode(const char *pos, const char *end) {\n    THROW_IF_NO_SPACE(pos, end, 1UL);\n    auto which = *reinterpret_cast<const uint8_t*>(pos++);\n    switch (which) {\n        case VAR_INT64:\n            THROW_IF_NO_SPACE(pos, end, 8UL);\n            operand_ = *reinterpret_cast<const int64_t*>(pos);\n            pos += 8;\n            break;\n        case VAR_DOUBLE:\n            THROW_IF_NO_SPACE(pos, end, 8UL);\n            operand_ = *reinterpret_cast<const double*>(pos);\n            pos += 8;\n            break;\n        case VAR_BOOL:\n            THROW_IF_NO_SPACE(pos, end, 1UL);\n            operand_ = *reinterpret_cast<const bool*>(pos++);\n            break;\n        case VAR_STR: {\n            THROW_IF_NO_SPACE(pos, end, 2UL);\n            auto size = *reinterpret_cast<const uint16_t*>(pos);\n            pos += 2;\n            THROW_IF_NO_SPACE(pos, end, static_cast<uint64_t>(size));\n            operand_ = std::string(pos, size);\n            pos += size;\n            break;\n        }\n        default:\n            throw Status::Error(\"Unknown variant type\");\n    }\n    return pos;\n}\n\n\nstd::string FunctionCallExpression::toString() const {\n    std::string buf;\n    buf.reserve(256);\n    buf += *name_;\n    buf += \"(\";\n    for (auto &arg : args_) {\n        buf += arg->toString();\n        buf += \",\";\n    }\n    if (!args_.empty()) {\n        buf.resize(buf.size() - 1);\n    }\n    buf += \")\";\n    return buf;\n}\n\nOptVariantType FunctionCallExpression::eval(Getters &getters) const {\n    std::vector<VariantType> args;\n\n    for (auto it = args_.cbegin(); it != args_.cend(); ++it) {\n        auto result = (*it)->eval(getters);\n        if (!result.ok()) {\n            return result;\n        }\n        args.emplace_back(std::move(result.value()));\n    }\n\n    // TODO(simon.liu)\n    auto r = function_(args);\n    return OptVariantType(r);\n}\n\nStatus FunctionCallExpression::prepare() {\n    auto result = FunctionManager::get(*name_, args_.size());\n    if (!result.ok()) {\n        return std::move(result).status();\n    }\n\n    function_ = std::move(result).value();\n\n    auto status = Status::OK();\n    for (auto &arg : args_) {\n        status = arg->prepare();\n        if (!status.ok()) {\n            break;\n        }\n    }\n    return status;\n}\n\n\nvoid FunctionCallExpression::encode(Cord &cord) const {\n    cord << kindToInt(kind());\n\n    cord << static_cast<uint16_t>(name_->size());\n    cord << *name_;\n\n    cord << static_cast<uint16_t>(args_.size());\n    for (auto &arg : args_) {\n        arg->encode(cord);\n    }\n}\n\n\nconst char* FunctionCallExpression::decode(const char *pos, const char *end) {\n    THROW_IF_NO_SPACE(pos, end, 2UL);\n    auto size = *reinterpret_cast<const uint16_t*>(pos);\n    pos += 2;\n\n    THROW_IF_NO_SPACE(pos, end, static_cast<uint64_t>(size));\n    name_ = std::make_unique<std::string>(pos, size);\n    pos += size;\n\n    auto count = *reinterpret_cast<const uint16_t*>(pos);\n    pos += 2;\n\n    args_.reserve(count);\n    for (auto i = 0u; i < count; i++) {\n        THROW_IF_NO_SPACE(pos, end, 1UL);\n        auto arg = makeExpr(*reinterpret_cast<const uint8_t*>(pos++));\n        pos = arg->decode(pos, end);\n        args_.emplace_back(std::move(arg));\n    }\n    return pos;\n}\n\nstd::string UUIDExpression::toString() const {\n    return folly::stringPrintf(\"uuid(%s)\", field_->c_str());\n}\n\nOptVariantType UUIDExpression::eval(Getters &getters) const {\n    UNUSED(getters);\n     auto client = context_->storageClient();\n     auto space = context_->space();\n     auto uuidResult = client->getUUID(space, *field_).get();\n     if (!uuidResult.ok()) {\n        LOG(ERROR) << \"Get UUID failed for \" << toString() << \", status \" << uuidResult.status();\n        return OptVariantType(Status::Error(\"Get UUID Failed\"));\n     }\n     auto v = std::move(uuidResult).value();\n     for (auto& rc : v.get_result().get_failed_codes()) {\n        LOG(ERROR) << \"Get UUID failed, error \" << static_cast<int32_t>(rc.get_code())\n                   << \", part \" << rc.get_part_id() << \", str id \" << toString();\n        return OptVariantType(Status::Error(\"Get UUID Failed\"));\n     }\n     VLOG(3) << \"Get UUID from \" << *field_ << \" to \" << v.get_id();\n     return v.get_id();\n}\n\nStatus UUIDExpression::prepare() {\n    return Status::OK();\n}\n\nstd::string UnaryExpression::toString() const {\n    std::string buf;\n    buf.reserve(256);\n    switch (op_) {\n        case PLUS:\n            buf += '+';\n            break;\n        case NEGATE:\n            buf += '-';\n            break;\n        case NOT:\n            buf += '!';\n            break;\n    }\n    buf += '(';\n    buf.append(operand_->toString());\n    buf += ')';\n    return buf;\n}\n\nOptVariantType UnaryExpression::eval(Getters &getters) const {\n    auto value = operand_->eval(getters);\n    if (value.ok()) {\n        if (op_ == PLUS) {\n            return value;\n        } else if (op_ == NEGATE) {\n            if (isInt(value.value())) {\n                return OptVariantType(-asInt(value.value()));\n            } else if (isDouble(value.value())) {\n                return OptVariantType(-asDouble(value.value()));\n            }\n        } else {\n            return OptVariantType(!asBool(value.value()));\n        }\n    }\n\n    return OptVariantType(Status::Error(folly::sformat(\n        \"attempt to perform unary arithmetic on a {}\", value.value().type().name())));\n}\n\nStatus UnaryExpression::prepare() {\n    return operand_->prepare();\n}\n\n\nvoid UnaryExpression::encode(Cord &cord) const {\n    cord << kindToInt(kind());\n    cord << static_cast<uint8_t>(op_);\n    operand_->encode(cord);\n}\n\n\nconst char* UnaryExpression::decode(const char *pos, const char *end) {\n    THROW_IF_NO_SPACE(pos, end, 2UL);\n    op_ = *reinterpret_cast<const Operator*>(pos++);\n    DCHECK(op_ == PLUS || op_ == NEGATE || op_ == NOT);\n\n    operand_ = makeExpr(*reinterpret_cast<const uint8_t*>(pos++));\n    return operand_->decode(pos, end);\n}\n\n\nstd::string columnTypeToString(ColumnType type) {\n    switch (type) {\n        case ColumnType::INT:\n            return \"int\";\n        case ColumnType::STRING:\n            return \"string\";\n        case ColumnType::DOUBLE:\n            return \"double\";\n        case ColumnType::BIGINT:\n            return \"bigint\";\n        case ColumnType::BOOL:\n            return \"bool\";\n        case ColumnType::TIMESTAMP:\n            return  \"timestamp\";\n        default:\n            return \"unknown\";\n    }\n}\n\n\nstd::string TypeCastingExpression::toString() const {\n    std::string buf;\n    buf.reserve(256);\n\n    buf += \"(\";\n    buf += columnTypeToString(type_);\n    buf += \")\";\n    buf += operand_->toString();\n\n    return buf;\n}\n\n\nOptVariantType TypeCastingExpression::eval(Getters &getters) const {\n    auto result = operand_->eval(getters);\n    if (!result.ok()) {\n        return result;\n    }\n\n    switch (type_) {\n        case ColumnType::INT:\n        case ColumnType::TIMESTAMP:\n            return Expression::toInt(result.value());\n        case ColumnType::STRING:\n            return Expression::toString(result.value());\n        case ColumnType::DOUBLE:\n            return Expression::toDouble(result.value());\n        case ColumnType::BOOL:\n            return Expression::toBool(result.value());\n        case ColumnType::BIGINT:\n            return Status::Error(\"Type bigint not supported yet\");\n    }\n    LOG(FATAL) << \"casting to unknown type: \" << static_cast<int>(type_);\n}\n\n\nStatus TypeCastingExpression::prepare() {\n    return operand_->prepare();\n}\n\n\nvoid TypeCastingExpression::encode(Cord &) const {\n}\n\n\nstd::string ArithmeticExpression::toString() const {\n    std::string buf;\n    buf.reserve(256);\n    buf += '(';\n    buf.append(left_->toString());\n    switch (op_) {\n        case ADD:\n            buf += '+';\n            break;\n        case SUB:\n            buf += '-';\n            break;\n        case MUL:\n            buf += '*';\n            break;\n        case DIV:\n            buf += '/';\n            break;\n        case MOD:\n            buf += '%';\n            break;\n        case XOR:\n            buf += '^';\n            break;\n    }\n    buf.append(right_->toString());\n    buf += ')';\n    return buf;\n}\n\nOptVariantType ArithmeticExpression::eval(Getters &getters) const {\n    auto left = left_->eval(getters);\n    auto right = right_->eval(getters);\n    if (!left.ok()) {\n        return left;\n    }\n\n    if (!right.ok()) {\n        return right;\n    }\n\n    auto l = left.value();\n    auto r = right.value();\n\n    switch (op_) {\n        case ADD:\n            if (isArithmetic(l) && isArithmetic(r)) {\n                if (isDouble(l) || isDouble(r)) {\n                    return OptVariantType(asDouble(l) + asDouble(r));\n                }\n                return OptVariantType(asInt(l) + asInt(r));\n            }\n\n            if (isString(l) && isString(r)) {\n                return OptVariantType(asString(l) + asString(r));\n            }\n            break;\n        case SUB:\n            if (isArithmetic(l) && isArithmetic(r)) {\n                if (isDouble(l) || isDouble(r)) {\n                    return OptVariantType(asDouble(l) - asDouble(r));\n                }\n                return OptVariantType(asInt(l) - asInt(r));\n            }\n            break;\n        case MUL:\n            if (isArithmetic(l) && isArithmetic(r)) {\n                if (isDouble(l) || isDouble(r)) {\n                    return OptVariantType(asDouble(l) * asDouble(r));\n                }\n                return OptVariantType(asInt(l) * asInt(r));\n            }\n            break;\n        case DIV:\n            if (isArithmetic(l) && isArithmetic(r)) {\n                if (isDouble(l) || isDouble(r)) {\n                    return OptVariantType(asDouble(l) / asDouble(r));\n                }\n                return OptVariantType(asInt(l) / asInt(r));\n            }\n            break;\n        case MOD:\n            if (isArithmetic(l) && isArithmetic(r)) {\n                if (isDouble(l) || isDouble(r)) {\n                    return fmod(asDouble(l), asDouble(r));\n                }\n                return OptVariantType(asInt(l) % asInt(r));\n            }\n            break;\n        case XOR:\n            if (isArithmetic(l) && isArithmetic(r)) {\n                if (isDouble(l) || isDouble(r)) {\n                    return (static_cast<int64_t>(std::round(asDouble(l)))\n                                ^ static_cast<int64_t>(std::round(asDouble(r))));\n                }\n                return OptVariantType(asInt(l) ^ asInt(r));\n            }\n            break;\n        default:\n            DCHECK(false);\n    }\n\n    return OptVariantType(Status::Error(folly::sformat(\n        \"attempt to perform arithmetic on {} with {}\", l.type().name(), r.type().name())));\n}\n\nStatus ArithmeticExpression::prepare() {\n    auto status = left_->prepare();\n    if (!status.ok()) {\n        return status;\n    }\n    status = right_->prepare();\n    if (!status.ok()) {\n        return status;\n    }\n    return Status::OK();\n}\n\n\nvoid ArithmeticExpression::encode(Cord &cord) const {\n    cord << kindToInt(kind());\n    cord << static_cast<uint8_t>(op_);\n    left_->encode(cord);\n    right_->encode(cord);\n}\n\n\nconst char* ArithmeticExpression::decode(const char *pos, const char *end) {\n    THROW_IF_NO_SPACE(pos, end, 2UL);\n    op_ = *reinterpret_cast<const Operator*>(pos++);\n    DCHECK(op_ == ADD || op_ == SUB || op_ == MUL || op_ == DIV || op_ == MOD);\n\n    left_ = makeExpr(*reinterpret_cast<const uint8_t*>(pos++));\n    pos = left_->decode(pos, end);\n\n    THROW_IF_NO_SPACE(pos, end, 1UL);\n    right_ = makeExpr(*reinterpret_cast<const uint8_t*>(pos++));\n    return right_->decode(pos, end);\n}\n\n\nstd::string RelationalExpression::toString() const {\n    std::string buf;\n    buf.reserve(256);\n    buf += '(';\n    buf.append(left_->toString());\n    switch (op_) {\n        case LT:\n            buf += '<';\n            break;\n        case LE:\n            buf += \"<=\";\n            break;\n        case GT:\n            buf += '>';\n            break;\n        case GE:\n            buf += \">=\";\n            break;\n        case EQ:\n            buf += \"==\";\n            break;\n        case NE:\n            buf += \"!=\";\n            break;\n    }\n    buf.append(right_->toString());\n    buf += ')';\n    return buf;\n}\n\nOptVariantType RelationalExpression::eval(Getters &getters) const {\n    auto left = left_->eval(getters);\n    auto right = right_->eval(getters);\n\n    if (!left.ok()) {\n        return left;\n    }\n\n    if (!right.ok()) {\n        return right;\n    }\n\n    auto l = left.value();\n    auto r = right.value();\n    if (l.which() != r.which()) {\n        auto s = implicitCasting(l, r);\n        if (!s.ok()) {\n            return s;\n        }\n    }\n\n    switch (op_) {\n        case LT:\n            return OptVariantType(l < r);\n        case LE:\n            return OptVariantType(l <= r);\n        case GT:\n            return OptVariantType(l > r);\n        case GE:\n            return OptVariantType(l >= r);\n        case EQ:\n            if (isArithmetic(l) && isArithmetic(r)) {\n                if (isDouble(l) || isDouble(r)) {\n                    return OptVariantType(\n                        almostEqual(asDouble(l), asDouble(r)));\n                }\n            }\n            return OptVariantType(l == r);\n        case NE:\n            if (isArithmetic(l) && isArithmetic(r)) {\n                if (isDouble(l) || isDouble(r)) {\n                    return OptVariantType(\n                        !almostEqual(asDouble(l), asDouble(r)));\n                }\n            }\n            return OptVariantType(l != r);\n    }\n\n    return OptVariantType(Status::Error(\"Wrong operator\"));\n}\n\nStatus RelationalExpression::implicitCasting(VariantType &lhs, VariantType &rhs) const {\n    // Rule: bool -> int64_t -> double\n    if (lhs.which() == VAR_STR || rhs.which() == VAR_STR) {\n        return Status::Error(\"A string type can not be compared with a non-string type.\");\n    } else if (lhs.which() == VAR_DOUBLE || rhs.which() == VAR_DOUBLE) {\n        lhs = toDouble(lhs);\n        rhs = toDouble(rhs);\n    } else if (lhs.which() == VAR_INT64 || rhs.which() == VAR_INT64) {\n        lhs = toInt(lhs);\n        rhs = toInt(rhs);\n    } else if (lhs.which() == VAR_BOOL || rhs.which() == VAR_BOOL) {\n        // No need do cast here.\n    } else {\n        // If the variant type is expanded, we should update the rule.\n        LOG(FATAL) << \"Unknown type: \" << lhs.which() << \", \" << rhs.which();\n    }\n\n    return Status::OK();\n}\n\nStatus RelationalExpression::prepare() {\n    auto status = left_->prepare();\n    if (!status.ok()) {\n        return status;\n    }\n    status = right_->prepare();\n    if (!status.ok()) {\n        return status;\n    }\n    return Status::OK();\n}\n\n\nvoid RelationalExpression::encode(Cord &cord) const {\n    cord << kindToInt(kind());\n    cord << static_cast<uint8_t>(op_);\n    left_->encode(cord);\n    right_->encode(cord);\n}\n\n\nconst char* RelationalExpression::decode(const char *pos, const char *end) {\n    THROW_IF_NO_SPACE(pos, end, 2UL);\n    op_ = *reinterpret_cast<const Operator*>(pos++);\n    DCHECK(op_ == LT || op_ == LE || op_ == GT || op_ == GE || op_ == EQ || op_ == NE);\n\n    left_ = makeExpr(*reinterpret_cast<const uint8_t*>(pos++));\n    pos = left_->decode(pos, end);\n\n    THROW_IF_NO_SPACE(pos, end, 1UL);\n    right_ = makeExpr(*reinterpret_cast<const uint8_t*>(pos++));\n    return right_->decode(pos, end);\n}\n\n\nstd::string LogicalExpression::toString() const {\n    std::string buf;\n    buf.reserve(256);\n    buf += '(';\n    buf.append(left_->toString());\n    switch (op_) {\n        case AND:\n            buf += \"&&\";\n            break;\n        case OR:\n            buf += \"||\";\n            break;\n        case XOR:\n            buf += \"XOR\";\n            break;\n    }\n    buf.append(right_->toString());\n    buf += ')';\n    return buf;\n}\n\nOptVariantType LogicalExpression::eval(Getters &getters) const {\n    auto left = left_->eval(getters);\n    auto right = right_->eval(getters);\n\n    if (!left.ok()) {\n        return left;\n    }\n\n    if (!right.ok()) {\n        return right;\n    }\n\n    if (op_ == AND) {\n        if (!asBool(left.value())) {\n            return OptVariantType(false);\n        }\n        return OptVariantType(asBool(right.value()));\n    } else if (op_ == OR) {\n        if (asBool(left.value())) {\n            return OptVariantType(true);\n        }\n        return OptVariantType(asBool(right.value()));\n    } else {\n        if (asBool(left.value()) == asBool(right.value())) {\n            return OptVariantType(false);\n        }\n        return OptVariantType(true);\n    }\n}\n\nStatus LogicalExpression::prepare() {\n    auto status = left_->prepare();\n    if (!status.ok()) {\n        return status;\n    }\n    status = right_->prepare();\n    return Status::OK();\n}\n\nvoid LogicalExpression::encode(Cord &cord) const {\n    cord << kindToInt(kind());\n    cord << static_cast<uint8_t>(op_);\n    left_->encode(cord);\n    right_->encode(cord);\n}\n\n\nconst char* LogicalExpression::decode(const char *pos, const char *end) {\n    THROW_IF_NO_SPACE(pos, end, 2UL);\n    op_ = *reinterpret_cast<const Operator*>(pos++);\n    DCHECK(op_ == AND || op_ == OR || op_ == XOR);\n\n    left_ = makeExpr(*reinterpret_cast<const uint8_t*>(pos++));\n    pos = left_->decode(pos, end);\n\n    THROW_IF_NO_SPACE(pos, end, 1UL);\n    right_ = makeExpr(*reinterpret_cast<const uint8_t*>(pos++));\n    return right_->decode(pos, end);\n}\n\n\n#undef THROW_IF_NO_SPACE\n\n}   // namespace nebula\n", "idx": 1, "id": 27451, "msg": "`fmt` will be a dangling pointer here.", "proj": "vesoft-inc-nebula", "lang": "cpp"}
{"patch": "@@ -541,6 +541,8 @@ public class Access extends AbstractApiBean {\n     /*\n      * GET method for retrieving various auxiliary files associated with \n      * a tabular datafile.\n+     *\n+     * TODO: Consider removing \"metadata\" from the path.\n      */\n     \n     @Path(\"datafile/{fileId}/metadata/{formatTag}/{formatVersion}\")", "y": 0, "oldf": "/*\n * To change this license header, choose License Headers in Project Properties.\n * To change this template file, choose Tools | Templates\n * and open the template in the editor.\n */\n\npackage edu.harvard.iq.dataverse.api;\n\nimport edu.harvard.iq.dataverse.AuxiliaryFile;\nimport edu.harvard.iq.dataverse.AuxiliaryFileServiceBean;\nimport edu.harvard.iq.dataverse.DataCitation;\nimport edu.harvard.iq.dataverse.DataFile;\nimport edu.harvard.iq.dataverse.FileMetadata;\nimport edu.harvard.iq.dataverse.DataFileServiceBean;\nimport edu.harvard.iq.dataverse.Dataset;\nimport edu.harvard.iq.dataverse.DatasetVersion;\nimport edu.harvard.iq.dataverse.DatasetVersionServiceBean;\nimport edu.harvard.iq.dataverse.DatasetServiceBean;\nimport edu.harvard.iq.dataverse.Dataverse;\nimport edu.harvard.iq.dataverse.DataverseRequestServiceBean;\nimport edu.harvard.iq.dataverse.DataverseRoleServiceBean;\nimport edu.harvard.iq.dataverse.DataverseServiceBean;\nimport edu.harvard.iq.dataverse.DataverseSession;\nimport edu.harvard.iq.dataverse.DataverseTheme;\nimport edu.harvard.iq.dataverse.FileDownloadServiceBean;\nimport edu.harvard.iq.dataverse.GuestbookResponse;\nimport edu.harvard.iq.dataverse.GuestbookResponseServiceBean;\nimport edu.harvard.iq.dataverse.PermissionServiceBean;\nimport edu.harvard.iq.dataverse.PermissionsWrapper;\nimport edu.harvard.iq.dataverse.RoleAssignment;\nimport edu.harvard.iq.dataverse.UserNotification;\nimport edu.harvard.iq.dataverse.UserNotificationServiceBean;\nimport static edu.harvard.iq.dataverse.api.AbstractApiBean.error;\nimport static edu.harvard.iq.dataverse.api.Datasets.handleVersion;\nimport edu.harvard.iq.dataverse.authorization.DataverseRole;\nimport edu.harvard.iq.dataverse.authorization.Permission;\nimport edu.harvard.iq.dataverse.authorization.RoleAssignee;\nimport edu.harvard.iq.dataverse.authorization.users.AuthenticatedUser;\nimport edu.harvard.iq.dataverse.authorization.users.PrivateUrlUser;\nimport edu.harvard.iq.dataverse.authorization.users.GuestUser;\nimport edu.harvard.iq.dataverse.authorization.users.User;\nimport edu.harvard.iq.dataverse.dataaccess.DataAccess;\nimport edu.harvard.iq.dataverse.dataaccess.DataAccessRequest;\nimport edu.harvard.iq.dataverse.dataaccess.StorageIO;\nimport edu.harvard.iq.dataverse.dataaccess.DataFileZipper;\nimport edu.harvard.iq.dataverse.dataaccess.OptionalAccessService;\nimport edu.harvard.iq.dataverse.dataaccess.ImageThumbConverter;\nimport edu.harvard.iq.dataverse.datavariable.DataVariable;\nimport edu.harvard.iq.dataverse.datavariable.VariableServiceBean;\nimport edu.harvard.iq.dataverse.engine.command.Command;\nimport edu.harvard.iq.dataverse.engine.command.DataverseRequest;\nimport edu.harvard.iq.dataverse.engine.command.exception.CommandException;\nimport edu.harvard.iq.dataverse.engine.command.impl.AssignRoleCommand;\nimport edu.harvard.iq.dataverse.engine.command.impl.GetDatasetCommand;\nimport edu.harvard.iq.dataverse.engine.command.impl.GetDraftDatasetVersionCommand;\nimport edu.harvard.iq.dataverse.engine.command.impl.GetLatestAccessibleDatasetVersionCommand;\nimport edu.harvard.iq.dataverse.engine.command.impl.GetLatestPublishedDatasetVersionCommand;\nimport edu.harvard.iq.dataverse.engine.command.impl.GetSpecificPublishedDatasetVersionCommand;\nimport edu.harvard.iq.dataverse.engine.command.impl.RequestAccessCommand;\nimport edu.harvard.iq.dataverse.engine.command.impl.RevokeRoleCommand;\nimport edu.harvard.iq.dataverse.engine.command.impl.UpdateDatasetVersionCommand;\nimport edu.harvard.iq.dataverse.export.DDIExportServiceBean;\nimport edu.harvard.iq.dataverse.makedatacount.MakeDataCountLoggingServiceBean;\nimport edu.harvard.iq.dataverse.makedatacount.MakeDataCountLoggingServiceBean.MakeDataCountEntry;\nimport edu.harvard.iq.dataverse.settings.SettingsServiceBean;\nimport edu.harvard.iq.dataverse.util.BundleUtil;\nimport edu.harvard.iq.dataverse.util.FileUtil;\nimport edu.harvard.iq.dataverse.util.StringUtil;\nimport edu.harvard.iq.dataverse.util.SystemConfig;\nimport edu.harvard.iq.dataverse.util.json.JsonPrinter;\n\nimport java.util.logging.Logger;\nimport javax.ejb.EJB;\nimport java.io.InputStream;\nimport java.io.ByteArrayOutputStream;\nimport java.io.File;\nimport java.io.FileInputStream;\nimport java.io.IOException;\nimport java.io.OutputStream;\nimport java.sql.Timestamp;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.Date;\nimport java.util.List;\nimport java.util.Properties;\nimport java.util.logging.Level;\nimport javax.inject.Inject;\nimport javax.json.Json;\nimport java.net.URI;\nimport javax.json.JsonArrayBuilder;\nimport javax.persistence.TypedQuery;\n\nimport javax.ws.rs.GET;\nimport javax.ws.rs.Path;\nimport javax.ws.rs.PathParam;\nimport javax.ws.rs.Produces;\n\nimport javax.ws.rs.core.Context;\nimport javax.ws.rs.core.HttpHeaders;\nimport javax.ws.rs.core.UriInfo;\n\n\nimport javax.servlet.http.HttpServletResponse;\nimport javax.ws.rs.BadRequestException;\nimport javax.ws.rs.Consumes;\nimport javax.ws.rs.DELETE;\nimport javax.ws.rs.ForbiddenException;\nimport javax.ws.rs.NotFoundException;\nimport javax.ws.rs.POST;\nimport javax.ws.rs.PUT;\nimport javax.ws.rs.QueryParam;\nimport javax.ws.rs.ServiceUnavailableException;\nimport javax.ws.rs.WebApplicationException;\nimport javax.ws.rs.core.Response;\nimport static javax.ws.rs.core.Response.Status.BAD_REQUEST;\nimport javax.ws.rs.core.StreamingOutput;\nimport static edu.harvard.iq.dataverse.util.json.JsonPrinter.json;\nimport java.net.URISyntaxException;\nimport javax.ws.rs.RedirectionException;\nimport javax.ws.rs.core.MediaType;\nimport static javax.ws.rs.core.Response.Status.FORBIDDEN;\nimport org.glassfish.jersey.media.multipart.FormDataBodyPart;\nimport org.glassfish.jersey.media.multipart.FormDataContentDisposition;\nimport org.glassfish.jersey.media.multipart.FormDataParam;\n\n/*\n    Custom API exceptions [NOT YET IMPLEMENTED]\nimport edu.harvard.iq.dataverse.api.exceptions.NotFoundException;\nimport edu.harvard.iq.dataverse.api.exceptions.ServiceUnavailableException;\nimport edu.harvard.iq.dataverse.api.exceptions.PermissionDeniedException;\nimport edu.harvard.iq.dataverse.api.exceptions.AuthorizationRequiredException;\n*/\n\n/**\n *\n * @author Leonid Andreev\n * \n * The data (file) access API is based on the DVN access API v.1.0 (that came \n * with the v.3.* of the DVN app) and extended for DVN 4.0 to include some\n * extra fancy functionality, such as subsetting individual columns in tabular\n * data files and more.\n */\n\n@Path(\"access\")\npublic class Access extends AbstractApiBean {\n    private static final Logger logger = Logger.getLogger(Access.class.getCanonicalName());\n        \n    @EJB\n    DataFileServiceBean dataFileService;\n    @EJB \n    DatasetServiceBean datasetService; \n    @EJB\n    DatasetVersionServiceBean versionService;\n    @EJB\n    DataverseServiceBean dataverseService; \n    @EJB\n    VariableServiceBean variableService;\n    @EJB\n    SettingsServiceBean settingsService;\n    @EJB\n    SystemConfig systemConfig;\n    @EJB\n    DDIExportServiceBean ddiExportService;\n    @EJB\n    PermissionServiceBean permissionService;\n    @Inject\n    DataverseSession session;\n    @Inject\n    DataverseRequestServiceBean dvRequestService;\n    @EJB\n    GuestbookResponseServiceBean guestbookResponseService;\n    @EJB\n    DataverseRoleServiceBean roleService;\n    @EJB\n    UserNotificationServiceBean userNotificationService;\n    @EJB\n    FileDownloadServiceBean fileDownloadService; \n    @EJB\n    AuxiliaryFileServiceBean auxiliaryFileService;\n    @Inject\n    PermissionsWrapper permissionsWrapper;\n    @Inject\n    MakeDataCountLoggingServiceBean mdcLogService;\n    \n    \n    private static final String API_KEY_HEADER = \"X-Dataverse-key\";    \n    \n    //@EJB\n    \n    // TODO: \n    // versions? -- L.A. 4.0 beta 10\n    @Path(\"datafile/bundle/{fileId}\")\n    @GET\n    @Produces({\"application/zip\"})\n    public BundleDownloadInstance datafileBundle(@PathParam(\"fileId\") String fileId, @QueryParam(\"fileMetadataId\") Long fileMetadataId,@QueryParam(\"gbrecs\") boolean gbrecs, @QueryParam(\"key\") String apiToken, @Context UriInfo uriInfo, @Context HttpHeaders headers, @Context HttpServletResponse response) /*throws NotFoundException, ServiceUnavailableException, PermissionDeniedException, AuthorizationRequiredException*/ {\n \n\n        GuestbookResponse gbr = null;\n        \n        DataFile df = findDataFileOrDieWrapper(fileId);\n        \n        if (apiToken == null || apiToken.equals(\"\")) {\n            apiToken = headers.getHeaderString(API_KEY_HEADER);\n        }\n        \n        // This will throw a ForbiddenException if access isn't authorized: \n        checkAuthorization(df, apiToken);\n        \n        if (gbrecs != true && df.isReleased()){\n            // Write Guestbook record if not done previously and file is released\n            User apiTokenUser = findAPITokenUser(apiToken);\n            gbr = guestbookResponseService.initAPIGuestbookResponse(df.getOwner(), df, session, apiTokenUser);\n            guestbookResponseService.save(gbr);\n            MakeDataCountEntry entry = new MakeDataCountEntry(uriInfo, headers, dvRequestService, df);                                        \n            mdcLogService.logEntry(entry);\n        }\n        \n        DownloadInfo dInfo = new DownloadInfo(df);\n        BundleDownloadInstance downloadInstance = new BundleDownloadInstance(dInfo);\n\n        FileMetadata fileMetadata = null;\n\n        if (fileMetadataId == null) {\n            fileMetadata = df.getFileMetadata();\n        } else {\n            fileMetadata = dataFileService.findFileMetadata(fileMetadataId);\n        }\n        \n        downloadInstance.setFileCitationEndNote(new DataCitation(fileMetadata).toEndNoteString());\n        downloadInstance.setFileCitationRIS(new DataCitation(fileMetadata).toRISString());\n        downloadInstance.setFileCitationBibtex(new DataCitation(fileMetadata).toBibtexString());\n\n        ByteArrayOutputStream outStream = null;\n        outStream = new ByteArrayOutputStream();\n        Long dfId = df.getId();\n        try {\n            ddiExportService.exportDataFile(\n                    dfId,\n                    outStream,\n                    null,\n                    null,\n                    fileMetadataId);\n\n            downloadInstance.setFileDDIXML(outStream.toString());\n\n        } catch (Exception ex) {\n            // if we can't generate the DDI, it's ok; \n            // we'll just generate the bundle without it. \n        }\n        \n        return downloadInstance;       \n    \n    }\n    \n    //Added a wrapper method since the original method throws a wrapped response \n    //the access methods return files instead of responses so we convert to a WebApplicationException\n    \n    private DataFile findDataFileOrDieWrapper(String fileId){\n        \n        DataFile df = null;\n        \n        try {\n            df = findDataFileOrDie(fileId);\n        } catch (WrappedResponse ex) {\n            logger.warning(\"Access: datafile service could not locate a DataFile object for id \"+fileId+\"!\");\n            logger.warning(ex.getWrappedMessageWhenJson());\n            throw new NotFoundException();\n        }\n         return df;\n    }\n        \n            \n    @Path(\"datafile/{fileId:.+}\")\n    @GET\n    @Produces({\"application/xml\"})\n    public DownloadInstance datafile(@PathParam(\"fileId\") String fileId, @QueryParam(\"gbrecs\") boolean gbrecs, @QueryParam(\"key\") String apiToken, @Context UriInfo uriInfo, @Context HttpHeaders headers, @Context HttpServletResponse response) /*throws NotFoundException, ServiceUnavailableException, PermissionDeniedException, AuthorizationRequiredException*/ {\n        \n        // check first if there's a trailing slash, and chop it: \n        while (fileId.lastIndexOf('/') == fileId.length() - 1) {\n            fileId = fileId.substring(0, fileId.length() - 1);\n        }\n            \n        if (fileId.indexOf('/') > -1) {\n            // This is for embedding folder names into the Access API URLs;\n            // something like /api/access/datafile/folder/subfolder/1234\n            // instead of the normal /api/access/datafile/1234 notation. \n            // this is supported only for recreating folders during recursive downloads - \n            // i.e. they are embedded into the URL for the remote client like wget,\n            // but can be safely ignored here.\n            fileId = fileId.substring(fileId.lastIndexOf('/') + 1);\n        }\n                \n        DataFile df = findDataFileOrDieWrapper(fileId);\n        GuestbookResponse gbr = null;\n        \n        if (df.isHarvested()) {\n            String errorMessage = \"Datafile \" + fileId + \" is a harvested file that cannot be accessed in this Dataverse\";\n            throw new NotFoundException(errorMessage);\n            // (nobody should ever be using this API on a harvested DataFile)!\n        }\n        \n        if (apiToken == null || apiToken.equals(\"\")) {\n            apiToken = headers.getHeaderString(API_KEY_HEADER);\n        }\n         \n        if (gbrecs != true && df.isReleased()){\n            // Write Guestbook record if not done previously and file is released\n            User apiTokenUser = findAPITokenUser(apiToken);\n            gbr = guestbookResponseService.initAPIGuestbookResponse(df.getOwner(), df, session, apiTokenUser);\n        }\n               \n        // This will throw a ForbiddenException if access isn't authorized: \n        checkAuthorization(df, apiToken);\n        \n        DownloadInfo dInfo = new DownloadInfo(df);\n\n        logger.fine(\"checking if thumbnails are supported on this file.\");\n        if (FileUtil.isThumbnailSupported(df)) {\n            dInfo.addServiceAvailable(new OptionalAccessService(\"thumbnail\", \"image/png\", \"imageThumb=true\", \"Image Thumbnail (64x64)\"));\n        }\n\n        if (df.isTabularData()) {\n            String originalMimeType = df.getDataTable().getOriginalFileFormat();\n            dInfo.addServiceAvailable(new OptionalAccessService(\"original\", originalMimeType, \"format=original\",\"Saved original (\" + originalMimeType + \")\"));\n            dInfo.addServiceAvailable(new OptionalAccessService(\"tabular\", \"text/tab-separated-values\", \"format=tab\", \"Tabular file in native format\"));\n            dInfo.addServiceAvailable(new OptionalAccessService(\"R\", \"application/x-rlang-transport\", \"format=RData\", \"Data in R format\"));\n            dInfo.addServiceAvailable(new OptionalAccessService(\"preprocessed\", \"application/json\", \"format=prep\", \"Preprocessed data in JSON\"));\n            dInfo.addServiceAvailable(new OptionalAccessService(\"subset\", \"text/tab-separated-values\", \"variables=&lt;LIST&gt;\", \"Column-wise Subsetting\"));\n        }\n        DownloadInstance downloadInstance = new DownloadInstance(dInfo);\n        downloadInstance.setRequestUriInfo(uriInfo);\n        downloadInstance.setRequestHttpHeaders(headers);\n        \n        if (gbr != null){\n            downloadInstance.setGbr(gbr);\n            downloadInstance.setDataverseRequestService(dvRequestService);\n            downloadInstance.setCommand(engineSvc);\n        }\n        boolean serviceRequested = false;\n        boolean serviceFound = false;\n\n        for (String key : uriInfo.getQueryParameters().keySet()) {\n            String value = uriInfo.getQueryParameters().getFirst(key);\n            logger.fine(\"is download service supported? key=\" + key + \", value=\" + value);\n            // The loop goes through all query params (e.g. including key, gbrecs, persistentId, etc. )\n            // So we need to identify when a service is being called and then let checkIfServiceSupportedAndSetConverter see if the required one exists\n            if (key.equals(\"imageThumb\") || key.equals(\"format\") || key.equals(\"variables\") || key.equals(\"noVarHeader\")) {\n                serviceRequested = true;\n                //In the dataset file table context a user is allowed to select original as the format\n                //for download\n                // if the dataset has tabular files - it should not be applied to instances \n                // where the file selected is not tabular see #6972\n                if(\"format\".equals(key) && \"original\".equals(value) && !df.isTabularData()) {\n                    serviceRequested = false;\n                    break;\n                }\n                //Only need to check if this key is associated with a service\n                if (downloadInstance.checkIfServiceSupportedAndSetConverter(key, value)) {\n                    // this automatically sets the conversion parameters in\n                    // the download instance to key and value;\n                    // TODO: I should probably set these explicitly instead.\n                    logger.fine(\"yes!\");\n\n                    if (downloadInstance.getConversionParam().equals(\"subset\")) {\n                        String subsetParam = downloadInstance.getConversionParamValue();\n                        String variableIdParams[] = subsetParam.split(\",\");\n                        if (variableIdParams != null && variableIdParams.length > 0) {\n                            logger.fine(variableIdParams.length + \" tokens;\");\n                            for (int i = 0; i < variableIdParams.length; i++) {\n                                logger.fine(\"token: \" + variableIdParams[i]);\n                                String token = variableIdParams[i].replaceFirst(\"^v\", \"\");\n                                Long variableId = null;\n                                try {\n                                    variableId = new Long(token);\n                                } catch (NumberFormatException nfe) {\n                                    variableId = null;\n                                }\n                                if (variableId != null) {\n                                    logger.fine(\"attempting to look up variable id \" + variableId);\n                                    if (variableService != null) {\n                                        DataVariable variable = variableService.find(variableId);\n                                        if (variable != null) {\n                                            if (downloadInstance.getExtraArguments() == null) {\n                                                downloadInstance.setExtraArguments(new ArrayList<Object>());\n                                            }\n                                            logger.fine(\"putting variable id \" + variable.getId() + \" on the parameters list of the download instance.\");\n                                            downloadInstance.getExtraArguments().add(variable);\n\n                                            // if (!variable.getDataTable().getDataFile().getId().equals(sf.getId())) {\n                                            // variableList.add(variable);\n                                            // }\n                                        }\n                                    } else {\n                                        logger.fine(\"variable service is null.\");\n                                    }\n                                }\n                            }\n                        }\n                    }\n\n                    logger.fine(\"downloadInstance: \" + downloadInstance.getConversionParam() + \",\" + downloadInstance.getConversionParamValue());\n                    serviceFound = true;\n                    break;\n                }\n            } else {\n                \n            }\n        }\n        if (serviceRequested && !serviceFound) {\n            // Service not supported/bad arguments, etc.:\n            // One could return\n            // a ServiceNotAvailableException. However, since the returns are all files of\n            // some sort, it seems reasonable, and more standard, to just return\n            // a NotFoundException.\n            throw new NotFoundException(\"datafile access error: requested optional service (image scaling, format conversion, etc.) is not supported on this datafile.\");\n        } // Else - the file itself was requested or we have the info needed to invoke the service and get the derived info\n        logger.fine(\"Returning download instance\");\n        /* \n         * Provide some browser-friendly headers: (?)\n         */\n        return downloadInstance;\n    }\n    \n    \n    /* \n     * Variants of the Access API calls for retrieving datafile-level \n     * Metadata.\n    */\n    \n    \n    // Metadata format defaults to DDI:\n    @Path(\"datafile/{fileId}/metadata\")\n    @GET\n    @Produces({\"text/xml\"})\n    public String tabularDatafileMetadata(@PathParam(\"fileId\") String fileId, @QueryParam(\"fileMetadataId\") Long fileMetadataId, @QueryParam(\"exclude\") String exclude, @QueryParam(\"include\") String include, @Context HttpHeaders header, @Context HttpServletResponse response) throws NotFoundException, ServiceUnavailableException /*, PermissionDeniedException, AuthorizationRequiredException*/ {\n        return tabularDatafileMetadataDDI(fileId, fileMetadataId, exclude, include, header, response);\n    }\n    \n    /* \n     * This has been moved here, under /api/access, from the /api/meta hierarchy\n     * which we are going to retire.\n     */\n    @Path(\"datafile/{fileId}/metadata/ddi\")\n    @GET\n    @Produces({\"text/xml\"})\n    public String tabularDatafileMetadataDDI(@PathParam(\"fileId\") String fileId,  @QueryParam(\"fileMetadataId\") Long fileMetadataId, @QueryParam(\"exclude\") String exclude, @QueryParam(\"include\") String include, @Context HttpHeaders header, @Context HttpServletResponse response) throws NotFoundException, ServiceUnavailableException /*, PermissionDeniedException, AuthorizationRequiredException*/ {\n        String retValue = \"\";\n\n        DataFile dataFile = null; \n\n        \n        dataFile = findDataFileOrDieWrapper(fileId);\n        \n        if (!dataFile.isTabularData()) { \n           throw new BadRequestException(\"tabular data required\");\n        }\n        \n        if (dataFile.isRestricted()) {\n            boolean hasPermissionToDownloadFile = false;\n            DataverseRequest dataverseRequest;\n            try {\n                dataverseRequest = createDataverseRequest(findUserOrDie());\n            } catch (WrappedResponse ex) {\n                throw new BadRequestException(\"cannot find user\");\n            }\n            if (dataverseRequest != null && dataverseRequest.getUser() instanceof GuestUser) {\n                // We must be in the UI. Try to get a non-GuestUser from the session.\n                dataverseRequest = dvRequestService.getDataverseRequest();\n            }\n            hasPermissionToDownloadFile = permissionService.requestOn(dataverseRequest, dataFile).has(Permission.DownloadFile);\n            if (!hasPermissionToDownloadFile) {\n                throw new BadRequestException(\"no permission to download file\");\n            }\n        }\n\n        response.setHeader(\"Content-disposition\", \"attachment; filename=\\\"dataverse_files.zip\\\"\");\n\n        FileMetadata fm = null;\n        if (fileMetadataId == null) {\n            fm = dataFile.getFileMetadata();\n        } else {\n            fm = dataFileService.findFileMetadata(fileMetadataId);\n        }\n\n        String fileName = fm.getLabel().replaceAll(\"\\\\.tab$\", \"-ddi.xml\");\n\n        response.setHeader(\"Content-disposition\", \"attachment; filename=\\\"\"+fileName+\"\\\"\");\n        response.setHeader(\"Content-Type\", \"application/xml; name=\\\"\"+fileName+\"\\\"\");\n        \n        ByteArrayOutputStream outStream = null;\n        outStream = new ByteArrayOutputStream();\n        Long dataFileId = dataFile.getId();\n        try {\n            ddiExportService.exportDataFile(\n                    dataFileId,\n                    outStream,\n                    exclude,\n                    include,\n                    fileMetadataId);\n\n            retValue = outStream.toString();\n\n        } catch (Exception e) {\n            // For whatever reason we've failed to generate a partial \n            // metadata record requested. \n            // We return Service Unavailable.\n            throw new ServiceUnavailableException();\n        }\n\n        return retValue;\n    }\n    \n    @Path(\"variable/{varId}/metadata/ddi\")\n    @GET\n    @Produces({ \"application/xml\" })\n\n    public String dataVariableMetadataDDI(@PathParam(\"varId\") Long varId, @QueryParam(\"fileMetadataId\") Long fileMetadataId, @QueryParam(\"exclude\") String exclude, @QueryParam(\"include\") String include, @Context HttpHeaders header, @Context HttpServletResponse response) /*throws NotFoundException, ServiceUnavailableException, PermissionDeniedException, AuthorizationRequiredException*/ {\n        String retValue = \"\";\n        \n        ByteArrayOutputStream outStream = null;\n        try {\n            outStream = new ByteArrayOutputStream();\n\n            ddiExportService.exportDataVariable(\n                    varId,\n                    outStream,\n                    exclude,\n                    include,\n                    fileMetadataId);\n        } catch (Exception e) {\n            // For whatever reason we've failed to generate a partial \n            // metadata record requested. We simply return an empty string.\n            return retValue;\n        }\n\n        retValue = outStream.toString();\n        \n        return retValue; \n    }\n    \n    /*\n     * GET method for retrieving various auxiliary files associated with \n     * a tabular datafile.\n     */\n    \n    @Path(\"datafile/{fileId}/metadata/{formatTag}/{formatVersion}\")\n    @GET    \n    public DownloadInstance tabularDatafileMetadataAux(@PathParam(\"fileId\") String fileId,\n            @PathParam(\"formatTag\") String formatTag,\n            @PathParam(\"formatVersion\") String formatVersion,\n            @QueryParam(\"key\") String apiToken, \n            @Context UriInfo uriInfo, \n            @Context HttpHeaders headers, \n            @Context HttpServletResponse response) throws ServiceUnavailableException {\n    \n        DataFile df = findDataFileOrDieWrapper(fileId);\n        \n        if (apiToken == null || apiToken.equals(\"\")) {\n            apiToken = headers.getHeaderString(API_KEY_HEADER);\n        }\n        \n        DownloadInfo dInfo = new DownloadInfo(df);\n        boolean publiclyAvailable = false; \n\n        if (!df.isTabularData()) {\n            throw new BadRequestException(\"tabular data required\");\n        } \n        \n        DownloadInstance downloadInstance;\n        AuxiliaryFile auxFile = null;\n        \n        // formatTag=preprocessed is handled as a special case. \n        // This is (as of now) the only aux. tabular metadata format that Dataverse\n        // can generate (and cache) itself. (All the other formats served have \n        // to be deposited first, by the @POST version of this API).\n        \n        if (\"preprocessed\".equals(formatTag)) {\n            dInfo.addServiceAvailable(new OptionalAccessService(\"preprocessed\", \"application/json\", \"format=prep\", \"Preprocessed data in JSON\"));\n            downloadInstance = new DownloadInstance(dInfo);\n            if (downloadInstance.checkIfServiceSupportedAndSetConverter(\"format\", \"prep\")) {\n                logger.fine(\"Preprocessed data for tabular file \"+fileId);\n            }\n        } else {\n            // All other (deposited) formats:\n            auxFile = auxiliaryFileService.lookupAuxiliaryFile(df, formatTag, formatVersion);\n            \n            if (auxFile == null) {\n                throw new NotFoundException(\"Auxiliary metadata format \"+formatTag+\" is not available for datafile \"+fileId);\n            }\n            \n            if (auxFile.getIsPublic()) {\n                publiclyAvailable = true;\n            }\n            downloadInstance = new DownloadInstance(dInfo);\n            downloadInstance.setAuxiliaryFile(auxFile);\n        }\n        \n        // Unless this format is explicitly authorized to be publicly available, \n        // the following will check access authorization (based on the access rules\n        // as defined for the DataFile itself), and will throw a ForbiddenException \n        // if access is denied:\n        if (!publiclyAvailable) {\n            checkAuthorization(df, apiToken);\n        }\n        \n        return downloadInstance;\n    }\n    \n    /* \n     * API method for downloading zipped bundles of multiple files. Uses POST to avoid long lists of file IDs that can make the URL longer than what's supported by browsers/servers\n    */\n    \n    // TODO: Rather than only supporting looking up files by their database IDs,\n    // consider supporting persistent identifiers.\n    @Path(\"datafiles\")\n    @POST\n    @Consumes(\"text/plain\")\n    @Produces({ \"application/zip\" })\n    public Response postDownloadDatafiles(String fileIds, @QueryParam(\"gbrecs\") boolean gbrecs, @QueryParam(\"key\") String apiTokenParam, @Context UriInfo uriInfo, @Context HttpHeaders headers, @Context HttpServletResponse response) throws WebApplicationException {\n        \n\n        return downloadDatafiles(fileIds, gbrecs, apiTokenParam, uriInfo, headers, response);\n    }\n\n    @Path(\"dataset/{id}\")\n    @GET\n    @Produces({\"application/zip\"})\n    public Response downloadAllFromLatest(@PathParam(\"id\") String datasetIdOrPersistentId, @QueryParam(\"gbrecs\") boolean gbrecs, @QueryParam(\"key\") String apiTokenParam, @Context UriInfo uriInfo, @Context HttpHeaders headers, @Context HttpServletResponse response) throws WebApplicationException {\n        try {\n            DataverseRequest req = createDataverseRequest(findUserOrDie());\n            final Dataset retrieved = execCommand(new GetDatasetCommand(req, findDatasetOrDie(datasetIdOrPersistentId)));\n            final DatasetVersion latest = execCommand(new GetLatestAccessibleDatasetVersionCommand(req, retrieved));\n            String fileIds = getFileIdsAsCommaSeparated(latest.getFileMetadatas());\n            return downloadDatafiles(fileIds, gbrecs, apiTokenParam, uriInfo, headers, response);\n        } catch (WrappedResponse wr) {\n            return wr.getResponse();\n        }\n    }\n\n    @Path(\"dataset/{id}/versions/{versionId}\")\n    @GET\n    @Produces({\"application/zip\"})\n    public Response downloadAllFromVersion(@PathParam(\"id\") String datasetIdOrPersistentId, @PathParam(\"versionId\") String versionId, @QueryParam(\"gbrecs\") boolean gbrecs, @QueryParam(\"key\") String apiTokenParam, @Context UriInfo uriInfo, @Context HttpHeaders headers, @Context HttpServletResponse response) throws WebApplicationException {\n        try {\n            DataverseRequest req = createDataverseRequest(findUserOrDie());\n            final Dataset ds = execCommand(new GetDatasetCommand(req, findDatasetOrDie(datasetIdOrPersistentId)));\n            DatasetVersion dsv = execCommand(handleVersion(versionId, new Datasets.DsVersionHandler<Command<DatasetVersion>>() {\n\n                @Override\n                public Command<DatasetVersion> handleLatest() {\n                    return new GetLatestAccessibleDatasetVersionCommand(req, ds);\n                }\n\n                @Override\n                public Command<DatasetVersion> handleDraft() {\n                    return new GetDraftDatasetVersionCommand(req, ds);\n                }\n\n                @Override\n                public Command<DatasetVersion> handleSpecific(long major, long minor) {\n                    return new GetSpecificPublishedDatasetVersionCommand(req, ds, major, minor);\n                }\n\n                @Override\n                public Command<DatasetVersion> handleLatestPublished() {\n                    return new GetLatestPublishedDatasetVersionCommand(req, ds);\n                }\n            }));\n            if (dsv == null) {\n                return error(BAD_REQUEST, BundleUtil.getStringFromBundle(\"access.api.exception.version.not.found\"));\n            }\n            String fileIds = getFileIdsAsCommaSeparated(dsv.getFileMetadatas());\n            return downloadDatafiles(fileIds, gbrecs, apiTokenParam, uriInfo, headers, response);\n        } catch (WrappedResponse wr) {\n            return wr.getResponse();\n        }\n    }\n\n    private static String getFileIdsAsCommaSeparated(List<FileMetadata> fileMetadatas) {\n        List<String> ids = new ArrayList<>();\n        for (FileMetadata fileMetadata : fileMetadatas) {\n            Long fileId = fileMetadata.getDataFile().getId();\n            ids.add(String.valueOf(fileId));\n        }\n        return String.join(\",\", ids);\n    }\n\n    /*\n     * API method for downloading zipped bundles of multiple files:\n     */\n    @Path(\"datafiles/{fileIds}\")\n    @GET\n    @Produces({\"application/zip\"})\n    public Response datafiles(@PathParam(\"fileIds\") String fileIds, @QueryParam(\"gbrecs\") boolean gbrecs, @QueryParam(\"key\") String apiTokenParam, @Context UriInfo uriInfo, @Context HttpHeaders headers, @Context HttpServletResponse response) throws WebApplicationException {\n        return downloadDatafiles(fileIds, gbrecs, apiTokenParam, uriInfo, headers, response);\n    }\n\n    private Response downloadDatafiles(String rawFileIds, boolean gbrecs, String apiTokenParam, UriInfo uriInfo, HttpHeaders headers, HttpServletResponse response) throws WebApplicationException /* throws NotFoundException, ServiceUnavailableException, PermissionDeniedException, AuthorizationRequiredException*/ {\n        long setLimit = systemConfig.getZipDownloadLimit();\n        if (!(setLimit > 0L)) {\n            setLimit = DataFileZipper.DEFAULT_ZIPFILE_LIMIT;\n        }\n        \n        final long zipDownloadSizeLimit = setLimit; //to use via anon inner class\n        \n        logger.fine(\"setting zip download size limit to \" + zipDownloadSizeLimit + \" bytes.\");\n        \n        if (rawFileIds == null || rawFileIds.equals(\"\")) {\n            throw new BadRequestException();\n        }\n        \n        final String fileIds;\n        if(rawFileIds.startsWith(\"fileIds=\")) {\n            fileIds = rawFileIds.substring(8); // String \"fileIds=\" from the front\n        } else {\n            fileIds=rawFileIds;\n        }\n        /* Note - fileIds coming from the POST ends in '\\n' and a ',' has been added after the last file id number and before a\n         * final '\\n' - this stops the last item from being parsed in the fileIds.split(\",\"); line below.\n         */\n        \n        String customZipServiceUrl = settingsService.getValueForKey(SettingsServiceBean.Key.CustomZipDownloadServiceUrl);\n        boolean useCustomZipService = customZipServiceUrl != null; \n        \n        String apiToken = (apiTokenParam == null || apiTokenParam.equals(\"\")) \n                ? headers.getHeaderString(API_KEY_HEADER) \n                : apiTokenParam;\n        \n        User apiTokenUser = findAPITokenUser(apiToken); //for use in adding gb records if necessary\n        \n        Boolean getOrig = false;\n        for (String key : uriInfo.getQueryParameters().keySet()) {\n            String value = uriInfo.getQueryParameters().getFirst(key);\n            if(\"format\".equals(key) && \"original\".equals(value)) {\n                getOrig = true;\n            }\n        }\n        \n        if (useCustomZipService) {\n            URI redirect_uri = null; \n            try {\n                redirect_uri = handleCustomZipDownload(customZipServiceUrl, fileIds, apiToken, apiTokenUser, uriInfo, headers, gbrecs, true); \n            } catch (WebApplicationException wae) {\n                throw wae;\n            }\n            \n            Response redirect = Response.seeOther(redirect_uri).build();\n            logger.fine(\"Issuing redirect to the file location on S3.\");\n            throw new RedirectionException(redirect);\n\n        }\n        \n        // Not using the \"custom service\" - API will zip the file,  \n        // and stream the output, in the \"normal\" manner:\n        \n        final boolean getOriginal = getOrig; //to use via anon inner class\n        \n        StreamingOutput stream = new StreamingOutput() {\n\n            @Override\n            public void write(OutputStream os) throws IOException,\n                    WebApplicationException {\n                String fileIdParams[] = fileIds.split(\",\");\n                DataFileZipper zipper = null; \n                String fileManifest = \"\";\n                long sizeTotal = 0L;\n                \n                if (fileIdParams != null && fileIdParams.length > 0) {\n                    logger.fine(fileIdParams.length + \" tokens;\");\n                    for (int i = 0; i < fileIdParams.length; i++) {\n                        logger.fine(\"token: \" + fileIdParams[i]);\n                        Long fileId = null;\n                        try {\n                            fileId = new Long(fileIdParams[i]);\n                        } catch (NumberFormatException nfe) {\n                            fileId = null;\n                        }\n                        if (fileId != null) {\n                            logger.fine(\"attempting to look up file id \" + fileId);\n                            DataFile file = dataFileService.find(fileId);\n                            if (file != null) {\n                                if (isAccessAuthorized(file, apiToken)) { \n                                    \n                                    logger.fine(\"adding datafile (id=\" + file.getId() + \") to the download list of the ZippedDownloadInstance.\");\n                                    //downloadInstance.addDataFile(file);\n                                    if (gbrecs != true && file.isReleased()){\n                                        GuestbookResponse  gbr = guestbookResponseService.initAPIGuestbookResponse(file.getOwner(), file, session, apiTokenUser);\n                                        guestbookResponseService.save(gbr);\n                                        MakeDataCountEntry entry = new MakeDataCountEntry(uriInfo, headers, dvRequestService, file);                                        \n                                        mdcLogService.logEntry(entry);\n                                    }\n                                    \n                                    if (zipper == null) {\n                                        // This is the first file we can serve - so we now know that we are going to be able \n                                        // to produce some output.\n                                        zipper = new DataFileZipper(os);\n                                        zipper.setFileManifest(fileManifest);\n                                        response.setHeader(\"Content-disposition\", \"attachment; filename=\\\"dataverse_files.zip\\\"\");\n                                        response.setHeader(\"Content-Type\", \"application/zip; name=\\\"dataverse_files.zip\\\"\");\n                                    }\n                                    \n                                    long size = 0L;\n                                    // is the original format requested, and is this a tabular datafile, with a preserved original?\n                                    if (getOriginal \n                                            && file.isTabularData() \n                                            && !StringUtil.isEmpty(file.getDataTable().getOriginalFileFormat())) {\n                                        //This size check is probably fairly inefficient as we have to get all the AccessObjects\n                                        //We do this again inside the zipper. I don't think there is a better solution\n                                        //without doing a large deal of rewriting or architecture redo.\n                                        //The previous size checks for non-original download is still quick.\n                                        //-MAD 4.9.2\n                                        // OK, here's the better solution: we now store the size of the original file in \n                                        // the database (in DataTable), so we get it for free. \n                                        // However, there may still be legacy datatables for which the size is not saved. \n                                        // so the \"inefficient\" code is kept, below, as a fallback solution. \n                                        // -- L.A., 4.10\n                                        \n                                        if (file.getDataTable().getOriginalFileSize() != null) {\n                                            size = file.getDataTable().getOriginalFileSize();\n                                        } else {\n                                            DataAccessRequest daReq = new DataAccessRequest();\n                                            StorageIO<DataFile> storageIO = DataAccess.getStorageIO(file, daReq);\n                                            storageIO.open();\n                                            size = storageIO.getAuxObjectSize(FileUtil.SAVED_ORIGINAL_FILENAME_EXTENSION);\n\n                                            // save it permanently: \n                                            file.getDataTable().setOriginalFileSize(size);\n                                            fileService.saveDataTable(file.getDataTable());\n                                        }\n                                        if (size == 0L){\n                                            throw new IOException(\"Invalid file size or accessObject when checking limits of zip file\");\n                                        }\n                                    } else {\n                                        size = file.getFilesize();\n                                    }\n                                    if (sizeTotal + size < zipDownloadSizeLimit) {\n                                        sizeTotal += zipper.addFileToZipStream(file, getOriginal);\n                                    } else {\n                                        String fileName = file.getFileMetadata().getLabel();\n                                        String mimeType = file.getContentType();\n                                        \n                                        zipper.addToManifest(fileName + \" (\" + mimeType + \") \" + \" skipped because the total size of the download bundle exceeded the limit of \" + zipDownloadSizeLimit + \" bytes.\\r\\n\");\n                                    }\n                                } else if(file.isRestricted()) {\n                                    if (zipper == null) {\n                                        fileManifest = fileManifest + file.getFileMetadata().getLabel() + \" IS RESTRICTED AND CANNOT BE DOWNLOADED\\r\\n\";\n                                    } else {\n                                        zipper.addToManifest(file.getFileMetadata().getLabel() + \" IS RESTRICTED AND CANNOT BE DOWNLOADED\\r\\n\");\n                                    }\n                                } else {\n                                    fileId = null;\n                                }\n                            \n                            } if (null == fileId) {\n                                // As of now this errors out.\n                                // This is bad because the user ends up with a broken zip and manifest\n                                // This is good in that the zip ends early so the user does not wait for the results\n                                String errorMessage = \"Datafile \" + fileId + \": no such object available\";\n                                throw new NotFoundException(errorMessage);\n                            }\n                        }\n                    }\n                } else {\n                    throw new BadRequestException();\n                }\n\n                if (zipper == null) {\n                    // If the DataFileZipper object is still NULL, it means that \n                    // there were file ids supplied - but none of the corresponding \n                    // files were accessible for this user. \n                    // In which casew we don't bother generating any output, and \n                    // just give them a 403:\n                    throw new ForbiddenException();\n                }\n\n                // This will add the generated File Manifest to the zipped output, \n                // then flush and close the stream:\n                zipper.finalizeZipStream();\n                \n                //os.flush();\n                //os.close();\n            }\n        };\n        return Response.ok(stream).build();\n    }\n    \n    /* \n     * Geting rid of the tempPreview API - it's always been a big, fat hack. \n     * the edit files page is now using the Base64 image strings in the preview \n     * URLs, just like the search and dataset pages.\n    @Path(\"tempPreview/{fileSystemId}\")\n    @GET\n    @Produces({\"image/png\"})\n    public InputStream tempPreview(@PathParam(\"fileSystemId\") String fileSystemId, @Context UriInfo uriInfo, @Context HttpHeaders headers, @Context HttpServletResponse response) {\n\n    }*/\n    \n    \n    \n    // TODO: Rather than only supporting looking up files by their database IDs, consider supporting persistent identifiers.\n    @Path(\"fileCardImage/{fileId}\")\n    @GET\n    @Produces({ \"image/png\" })\n    public InputStream fileCardImage(@PathParam(\"fileId\") Long fileId, @Context UriInfo uriInfo, @Context HttpHeaders headers, @Context HttpServletResponse response) /*throws NotFoundException, ServiceUnavailableException, PermissionDeniedException, AuthorizationRequiredException*/ {        \n        \n        \n        \n        DataFile df = dataFileService.find(fileId);\n        \n        if (df == null) {\n            logger.warning(\"Preview: datafile service could not locate a DataFile object for id \"+fileId+\"!\");\n            return null; \n        }\n        \n        StorageIO<DataFile> thumbnailDataAccess = null;\n        \n        try {\n            StorageIO<DataFile> dataAccess = df.getStorageIO();\n            if (dataAccess != null) { // && dataAccess.isLocalFile()) {\n                dataAccess.open();\n\n                if (\"application/pdf\".equalsIgnoreCase(df.getContentType())\n                        || df.isImage()\n                        || \"application/zipped-shapefile\".equalsIgnoreCase(df.getContentType())) {\n\n                    thumbnailDataAccess = ImageThumbConverter.getImageThumbnailAsInputStream(dataAccess, 48);\n                    if (thumbnailDataAccess != null && thumbnailDataAccess.getInputStream() != null) {\n                        return thumbnailDataAccess.getInputStream();\n                    }\n                }\n            }\n        } catch (IOException ioEx) {\n            return null;\n        }\n\n        return null; \n    }\n    \n    // Note:\n    // the Dataverse page is no longer using this method.\n    @Path(\"dsCardImage/{versionId}\")\n    @GET\n    @Produces({ \"image/png\" })\n    public InputStream dsCardImage(@PathParam(\"versionId\") Long versionId, @Context UriInfo uriInfo, @Context HttpHeaders headers, @Context HttpServletResponse response) /*throws NotFoundException, ServiceUnavailableException, PermissionDeniedException, AuthorizationRequiredException*/ {        \n        \n        \n        DatasetVersion datasetVersion = versionService.find(versionId);\n        \n        if (datasetVersion == null) {\n            logger.warning(\"Preview: Version service could not locate a DatasetVersion object for id \"+versionId+\"!\");\n            return null; \n        }\n        \n        //String imageThumbFileName = null; \n        StorageIO thumbnailDataAccess = null;\n        \n        // First, check if this dataset has a designated thumbnail image: \n        \n        if (datasetVersion.getDataset() != null) {\n            \n            DataFile logoDataFile = datasetVersion.getDataset().getThumbnailFile();\n            if (logoDataFile != null) {\n        \n                try {\n                    StorageIO<DataFile> dataAccess = logoDataFile.getStorageIO();\n                    if (dataAccess != null) { // && dataAccess.isLocalFile()) {\n                        dataAccess.open();\n                        thumbnailDataAccess = ImageThumbConverter.getImageThumbnailAsInputStream(dataAccess, 48);\n                    }\n                    if (thumbnailDataAccess != null && thumbnailDataAccess.getInputStream() != null) {\n                        return thumbnailDataAccess.getInputStream();\n                    } \n                } catch (IOException ioEx) {\n                    thumbnailDataAccess = null; \n                }\n            }\n                \n               \n        \n            // If not, we'll try to use one of the files in this dataset version:\n            /*\n            if (thumbnailDataAccess == null) {\n\n                if (!datasetVersion.getDataset().isHarvested()) {\n                    thumbnailDataAccess = getThumbnailForDatasetVersion(datasetVersion); \n                }\n            }*/\n            \n        }\n\n        return null; \n    }\n    \n    @Path(\"dvCardImage/{dataverseId}\")\n    @GET\n    @Produces({ \"image/png\" })\n    public InputStream dvCardImage(@PathParam(\"dataverseId\") Long dataverseId, @Context UriInfo uriInfo, @Context HttpHeaders headers, @Context HttpServletResponse response) /*throws NotFoundException, ServiceUnavailableException, PermissionDeniedException, AuthorizationRequiredException*/ {        \n        logger.fine(\"entering dvCardImage\");\n        \n        Dataverse dataverse = dataverseService.find(dataverseId);\n        \n        if (dataverse == null) {\n            logger.warning(\"Preview: Version service could not locate a DatasetVersion object for id \"+dataverseId+\"!\");\n            return null; \n        }\n        \n        String imageThumbFileName = null; \n        \n        // First, check if the dataverse has a defined logo: \n        \n        if (dataverse.getDataverseTheme()!=null && dataverse.getDataverseTheme().getLogo() != null && !dataverse.getDataverseTheme().getLogo().equals(\"\")) {\n            File dataverseLogoFile = getLogo(dataverse);\n            if (dataverseLogoFile != null) {\n                logger.fine(\"dvCardImage: logo file found\");\n                String logoThumbNailPath = null;\n                InputStream in = null;\n\n                try {\n                    if (dataverseLogoFile.exists()) {\n                        logoThumbNailPath =  ImageThumbConverter.generateImageThumbnailFromFile(dataverseLogoFile.getAbsolutePath(), 48);\n                        if (logoThumbNailPath != null) {\n                            in = new FileInputStream(logoThumbNailPath);\n                        }\n                    }\n                } catch (Exception ex) {\n                    in = null; \n                }\n                if (in != null) {\n                    logger.fine(\"dvCardImage: successfully obtained thumbnail for dataverse logo.\");\n                    return in;\n                }    \n            }\n        }\n        \n        // If there's no uploaded logo for this dataverse, go through its \n        // [released] datasets and see if any of them have card images:\n        \n        // TODO: figure out if we want to be doing this! \n        // (efficiency considerations...) -- L.A. 4.0 \n        // And we definitely don't want to be doing this for harvested \n        // dataverses:\n        /*\n        StorageIO thumbnailDataAccess = null; \n        \n        if (!dataverse.isHarvested()) {\n            for (Dataset dataset : datasetService.findPublishedByOwnerId(dataverseId)) {\n                logger.info(\"dvCardImage: checking dataset \"+dataset.getGlobalId());\n                if (dataset != null) {\n                    DatasetVersion releasedVersion = dataset.getReleasedVersion();\n                    logger.info(\"dvCardImage: obtained released version \"+releasedVersion.getTitle());\n                    thumbnailDataAccess = getThumbnailForDatasetVersion(releasedVersion); \n                    if (thumbnailDataAccess != null) {\n                        logger.info(\"dvCardImage: obtained thumbnail for the version.\");\n                        break;\n                    }\n                }\n            }\n        }\n        \n        if (thumbnailDataAccess != null && thumbnailDataAccess.getInputStream() != null) {\n            return thumbnailDataAccess.getInputStream();\n        }\n        */\n        return null;\n    }\n    \n    // helper methods:\n    \n    // What the method below does - going through all the files in the version -\n    // is too expensive! Instead we are now selecting an available thumbnail and\n    // giving the dataset card a direct link to that file thumbnail. -- L.A., 4.2.2\n    /*\n    private StorageIO getThumbnailForDatasetVersion(DatasetVersion datasetVersion) {\n        logger.info(\"entering getThumbnailForDatasetVersion()\");\n        StorageIO thumbnailDataAccess = null;\n        if (datasetVersion != null) {\n            List<FileMetadata> fileMetadatas = datasetVersion.getFileMetadatas();\n\n            for (FileMetadata fileMetadata : fileMetadatas) {\n                DataFile dataFile = fileMetadata.getDataFile();\n                logger.info(\"looking at file \"+fileMetadata.getLabel()+\" , file type \"+dataFile.getContentType());\n\n                if (dataFile != null && dataFile.isImage()) {\n\n                    try {\n                        StorageIO dataAccess = dataFile.getStorageIO();\n                        if (dataAccess != null && dataAccess.isLocalFile()) {\n                            dataAccess.open();\n\n                            thumbnailDataAccess = ImageThumbConverter.getImageThumb((FileAccessIO) dataAccess, 48);\n                        }\n                    } catch (IOException ioEx) {\n                        thumbnailDataAccess = null;\n                    }\n                }\n                if (thumbnailDataAccess != null) {\n                    logger.info(\"successfully generated thumbnail, returning.\");\n                    break;\n                }\n            }\n        }\n        return thumbnailDataAccess;\n    }\n    */\n    // TODO: \n    // put this method into the dataverseservice; use it there\n    // -- L.A. 4.0 beta14\n    \n    private File getLogo(Dataverse dataverse) {\n        if (dataverse.getId() == null) {\n            return null; \n        }\n        \n        DataverseTheme theme = dataverse.getDataverseTheme(); \n        if (theme != null && theme.getLogo() != null && !theme.getLogo().equals(\"\")) {\n            Properties p = System.getProperties();\n            String domainRoot = p.getProperty(\"com.sun.aas.instanceRoot\");\n  \n            if (domainRoot != null && !\"\".equals(domainRoot)) {\n                return new File (domainRoot + File.separator + \n                    \"docroot\" + File.separator + \n                    \"logos\" + File.separator + \n                    dataverse.getLogoOwnerId() + File.separator + \n                    theme.getLogo());\n            }\n        }\n            \n        return null;         \n    }\n    \n    /* \n        removing: \n    private String getWebappImageResource(String imageName) {\n        String imageFilePath = null;\n        String persistenceFilePath = null;\n        java.net.URL persistenceFileUrl = Thread.currentThread().getContextClassLoader().getResource(\"META-INF/persistence.xml\");\n        \n        if (persistenceFileUrl != null) {\n            persistenceFilePath = persistenceFileUrl.getDataFile();\n            if (persistenceFilePath != null) {\n                persistenceFilePath = persistenceFilePath.replaceFirst(\"/[^/]*$\", \"/\");\n                imageFilePath = persistenceFilePath + \"../../../resources/images/\" + imageName;\n                return imageFilePath; \n            }\n            logger.warning(\"Null file path representation of the location of persistence.xml in the webapp root directory!\"); \n        } else {\n            logger.warning(\"Could not find the location of persistence.xml in the webapp root directory!\");\n        }\n\n        return null;\n    }\n    */\n    \n    /**\n     * \n     * @param fileId\n     * @param formatTag\n     * @param formatVersion\n     * @param origin\n     * @param isPublic\n     * @param fileInputStream\n     * @param contentDispositionHeader\n     * @param formDataBodyPart\n     * @return \n     */\n    @Path(\"datafile/{fileId}/metadata/{formatTag}/{formatVersion}\")\n    @POST\n    @Consumes(MediaType.MULTIPART_FORM_DATA)\n\n    public Response saveAuxiliaryFileWithVersion(@PathParam(\"fileId\") Long fileId,\n            @PathParam(\"formatTag\") String formatTag,\n            @PathParam(\"formatVersion\") String formatVersion,\n            @FormDataParam(\"origin\") String origin,\n            @FormDataParam(\"isPublic\") boolean isPublic,\n            @FormDataParam(\"file\") InputStream fileInputStream\n          \n    ) {\n        AuthenticatedUser authenticatedUser;\n        try {\n            authenticatedUser = findAuthenticatedUserOrDie();\n        } catch (WrappedResponse ex) {\n            return error(FORBIDDEN, \"Authorized users only.\");\n        }\n\n        DataFile dataFile = dataFileService.find(fileId);\n        if (dataFile == null) {\n            return error(BAD_REQUEST, \"File not found based on id \" + fileId + \".\");\n        }\n        \n         if (!permissionService.userOn(authenticatedUser, dataFile.getOwner()).has(Permission.EditDataset)) {\n            return error(FORBIDDEN, \"User not authorized to edit the dataset.\");\n        }\n\n        if (!dataFile.isTabularData()) {\n            return error(BAD_REQUEST, \"Not a tabular DataFile (db id=\" + fileId + \")\");\n        }\n         \n\n        AuxiliaryFile saved = auxiliaryFileService.processAuxiliaryFile(fileInputStream, dataFile, formatTag, formatVersion, origin, isPublic);\n      \n        if (saved!=null) {\n            return ok(json(saved));\n        } else {\n            return error(BAD_REQUEST, \"Error saving Auxiliary file.\");\n        }\n    }\n  \n    \n\n  \n    \n    /**\n     * Allow (or disallow) access requests to Dataset\n     *\n     * @author sekmiller\n     *\n     * @param datasetToAllowAccessId\n     * @param requestStr\n     * @return\n     */\n    @PUT\n    @Path(\"{id}/allowAccessRequest\")\n    public Response allowAccessRequest(@PathParam(\"id\") String datasetToAllowAccessId, String requestStr) {\n\n        DataverseRequest dataverseRequest = null;\n        Dataset dataset;\n\n        try {\n            dataset = findDatasetOrDie(datasetToAllowAccessId);\n        } catch (WrappedResponse ex) {\n            List<String> args = Arrays.asList(datasetToAllowAccessId);\n            return error(BAD_REQUEST, BundleUtil.getStringFromBundle(\"access.api.allowRequests.failure.noDataset\", args));\n        }\n\n        boolean allowRequest = Boolean.valueOf(requestStr);\n\n        try {\n            dataverseRequest = createDataverseRequest(findUserOrDie());\n        } catch (WrappedResponse wr) {\n            List<String> args = Arrays.asList(wr.getLocalizedMessage());\n            return error(BAD_REQUEST, BundleUtil.getStringFromBundle(\"access.api.fileAccess.failure.noUser\", args));\n        }\n\n        dataset.getEditVersion().getTermsOfUseAndAccess().setFileAccessRequest(allowRequest);\n\n        try {\n            engineSvc.submit(new UpdateDatasetVersionCommand(dataset, dataverseRequest));\n        } catch (CommandException ex) {\n            List<String> args = Arrays.asList(dataset.getDisplayName(), ex.getLocalizedMessage());\n            return error(BAD_REQUEST, BundleUtil.getStringFromBundle(\"access.api.fileAccess.failure.noSave\", args));\n        }\n\n        String text = allowRequest ? BundleUtil.getStringFromBundle(\"access.api.allowRequests.allows\") : BundleUtil.getStringFromBundle(\"access.api.allowRequests.disallows\");\n        List<String> args = Arrays.asList(dataset.getDisplayName(), text);\n        return ok(BundleUtil.getStringFromBundle(\"access.api.allowRequests.success\", args));\n        \n    }\n\n    /**\n     * Request Access to Restricted File\n     *\n     * @author sekmiller\n     *\n     * @param fileToRequestAccessId\n     * @param apiToken\n     * @param headers\n     * @return\n     */\n    @PUT\n    @Path(\"/datafile/{id}/requestAccess\")\n    public Response requestFileAccess(@PathParam(\"id\") String fileToRequestAccessId, @Context HttpHeaders headers) {\n        \n        DataverseRequest dataverseRequest;\n        DataFile dataFile;\n        \n        try {\n            dataFile = findDataFileOrDie(fileToRequestAccessId);\n        } catch (WrappedResponse ex) {\n            List<String> args = Arrays.asList(fileToRequestAccessId);\n            return error(BAD_REQUEST, BundleUtil.getStringFromBundle(\"access.api.requestAccess.fileNotFound\", args));\n        }\n\n        if (!dataFile.getOwner().isFileAccessRequest()) {\n            return error(BAD_REQUEST, BundleUtil.getStringFromBundle(\"access.api.requestAccess.requestsNotAccepted\"));\n        }\n\n        AuthenticatedUser requestor;\n\n        try {\n            requestor = findAuthenticatedUserOrDie();\n            dataverseRequest = createDataverseRequest(requestor);\n        } catch (WrappedResponse wr) {\n            List<String> args = Arrays.asList(wr.getLocalizedMessage());\n            return error(BAD_REQUEST, BundleUtil.getStringFromBundle(\"access.api.fileAccess.failure.noUser\", args));\n        }\n\n        if (isAccessAuthorized(dataFile, getRequestApiKey())) {\n            return error(BAD_REQUEST, BundleUtil.getStringFromBundle(\"access.api.requestAccess.failure.invalidRequest\"));\n        }\n\n        if (dataFile.getFileAccessRequesters().contains(requestor)) {\n            return error(BAD_REQUEST, BundleUtil.getStringFromBundle(\"access.api.requestAccess.failure.requestExists\"));\n        }\n\n        try {\n            engineSvc.submit(new RequestAccessCommand(dataverseRequest, dataFile, true));\n        } catch (CommandException ex) {\n            List<String> args = Arrays.asList(dataFile.getDisplayName(), ex.getLocalizedMessage());\n            return error(BAD_REQUEST, BundleUtil.getStringFromBundle(\"access.api.requestAccess.failure.commandError\", args));\n        }\n        \n        List<String> args = Arrays.asList(dataFile.getDisplayName());\n        return ok(BundleUtil.getStringFromBundle(\"access.api.requestAccess.success.for.single.file\", args));\n\n    }\n\n    /*\n     * List Reqeusts to restricted file\n     *\n     * @author sekmiller\n     *\n     * @param fileToRequestAccessId\n     * @param apiToken\n     * @param headers\n     * @return\n     */\n    @GET\n    @Path(\"/datafile/{id}/listRequests\")\n    public Response listFileAccessRequests(@PathParam(\"id\") String fileToRequestAccessId, @Context HttpHeaders headers) {\n\n        DataverseRequest dataverseRequest;\n\n        DataFile dataFile;\n        try {\n            dataFile = findDataFileOrDie(fileToRequestAccessId);\n        } catch (WrappedResponse ex) {\n            List<String> args = Arrays.asList(fileToRequestAccessId);\n            return error(BAD_REQUEST, BundleUtil.getStringFromBundle(\"access.api.requestList.fileNotFound\", args));\n        }\n\n        try {\n            dataverseRequest = createDataverseRequest(findUserOrDie());\n        } catch (WrappedResponse wr) {\n            List<String> args = Arrays.asList(wr.getLocalizedMessage());\n            return error(BAD_REQUEST, BundleUtil.getStringFromBundle(\"access.api.fileAccess.failure.noUser\", args));\n        }\n\n        if (!(dataverseRequest.getAuthenticatedUser().isSuperuser() || permissionService.requestOn(dataverseRequest, dataFile.getOwner()).has(Permission.ManageDatasetPermissions))) {\n            return error(BAD_REQUEST, BundleUtil.getStringFromBundle(\"access.api.rejectAccess.failure.noPermissions\"));\n        }\n\n        List<AuthenticatedUser> requesters = dataFile.getFileAccessRequesters();\n\n        if (requesters == null || requesters.isEmpty()) {\n            List<String> args = Arrays.asList(dataFile.getDisplayName());\n            return error(BAD_REQUEST, BundleUtil.getStringFromBundle(\"access.api.requestList.noRequestsFound\"));\n        }\n\n        JsonArrayBuilder userArray = Json.createArrayBuilder();\n\n        for (AuthenticatedUser au : requesters) {\n            userArray.add(json(au));\n        }\n\n        return ok(userArray);\n\n    }\n\n    /**\n     * Grant Access to Restricted File\n     *\n     * @author sekmiller\n     *\n     * @param fileToRequestAccessId\n     * @param identifier\n     * @param apiToken\n     * @param headers\n     * @return\n     */\n    @PUT\n    @Path(\"/datafile/{id}/grantAccess/{identifier}\")\n    public Response grantFileAccess(@PathParam(\"id\") String fileToRequestAccessId, @PathParam(\"identifier\") String identifier, @Context HttpHeaders headers) {\n        \n        DataverseRequest dataverseRequest;\n        DataFile dataFile;\n\n        try {\n            dataFile = findDataFileOrDie(fileToRequestAccessId);\n        } catch (WrappedResponse ex) {\n            List<String> args = Arrays.asList(fileToRequestAccessId);\n            return error(BAD_REQUEST, BundleUtil.getStringFromBundle(\"access.api.requestAccess.fileNotFound\", args));\n        }\n\n        RoleAssignee ra = roleAssigneeSvc.getRoleAssignee(identifier);\n\n        if (ra == null) {\n            List<String> args = Arrays.asList(identifier);\n            return error(BAD_REQUEST, BundleUtil.getStringFromBundle(\"access.api.grantAccess.noAssigneeFound\", args));\n        }\n\n        try {\n            dataverseRequest = createDataverseRequest(findUserOrDie());\n        } catch (WrappedResponse wr) {\n            List<String> args = Arrays.asList(identifier);\n            return error(BAD_REQUEST, BundleUtil.getStringFromBundle(\"access.api.fileAccess.failure.noUser\", args));\n        }\n\n        DataverseRole fileDownloaderRole = roleService.findBuiltinRoleByAlias(DataverseRole.FILE_DOWNLOADER);\n\n        try {\n            engineSvc.submit(new AssignRoleCommand(ra, fileDownloaderRole, dataFile, dataverseRequest, null));\n            if (dataFile.getFileAccessRequesters().remove(ra)) {\n                dataFileService.save(dataFile);\n            }\n\n        } catch (CommandException ex) {\n            List<String> args = Arrays.asList(dataFile.getDisplayName(), ex.getLocalizedMessage());\n            return error(BAD_REQUEST, BundleUtil.getStringFromBundle(\"access.api.grantAccess.failure.commandError\", args));\n        }\n\n        try {\n            AuthenticatedUser au = (AuthenticatedUser) ra;\n            userNotificationService.sendNotification(au, new Timestamp(new Date().getTime()), UserNotification.Type.GRANTFILEACCESS, dataFile.getOwner().getId());\n        } catch (ClassCastException e) {\n            //nothing to do here - can only send a notification to an authenticated user\n        }\n\n        List<String> args = Arrays.asList(dataFile.getDisplayName());\n        return ok(BundleUtil.getStringFromBundle(\"access.api.grantAccess.success.for.single.file\", args));\n\n    }\n\n    /**\n     * Revoke Previously Granted Access to Restricted File\n     *\n     * @author sekmiller\n     *\n     * @param fileToRequestAccessId\n     * @param identifier\n     * @param apiToken\n     * @param headers\n     * @return\n     */\n    @DELETE\n    @Path(\"/datafile/{id}/revokeAccess/{identifier}\")\n    public Response revokeFileAccess(@PathParam(\"id\") String fileToRequestAccessId, @PathParam(\"identifier\") String identifier, @Context HttpHeaders headers) {\n\n        DataverseRequest dataverseRequest;\n        DataFile dataFile;\n\n        try {\n            dataFile = findDataFileOrDie(fileToRequestAccessId);\n        } catch (WrappedResponse ex) {\n            List<String> args = Arrays.asList(fileToRequestAccessId);\n            return error(BAD_REQUEST, BundleUtil.getStringFromBundle(\"access.api.requestAccess.fileNotFound\", args));\n        }\n\n        try {\n            dataverseRequest = createDataverseRequest(findUserOrDie());\n        } catch (WrappedResponse wr) {\n            List<String> args = Arrays.asList(wr.getLocalizedMessage());\n            return error(BAD_REQUEST, BundleUtil.getStringFromBundle(\"access.api.fileAccess.failure.noUser\", args));\n        }\n\n        if (identifier == null || identifier.equals(\"\")) {\n            return error(BAD_REQUEST, BundleUtil.getStringFromBundle(\"access.api.requestAccess.noKey\"));\n        }\n\n        RoleAssignee ra = roleAssigneeSvc.getRoleAssignee(identifier);\n        if (ra == null) {\n            List<String> args = Arrays.asList(identifier);\n            return error(BAD_REQUEST, BundleUtil.getStringFromBundle(\"access.api.grantAccess.noAssigneeFound\", args));\n        }\n\n        DataverseRole fileDownloaderRole = roleService.findBuiltinRoleByAlias(DataverseRole.FILE_DOWNLOADER);\n        TypedQuery<RoleAssignment> query = em.createNamedQuery(\n                \"RoleAssignment.listByAssigneeIdentifier_DefinitionPointId_RoleId\",\n                RoleAssignment.class);\n        query.setParameter(\"assigneeIdentifier\", ra.getIdentifier());\n        query.setParameter(\"definitionPointId\", dataFile.getId());\n        query.setParameter(\"roleId\", fileDownloaderRole.getId());\n        List<RoleAssignment> roles = query.getResultList();\n\n        if (roles == null || roles.isEmpty()) {\n            List<String> args = Arrays.asList(identifier);\n            return error(BAD_REQUEST, BundleUtil.getStringFromBundle(\"access.api.revokeAccess.noRoleFound\", args));\n        }\n\n        try {\n            for (RoleAssignment role : roles) {\n                execCommand(new RevokeRoleCommand(role, dataverseRequest));\n            }\n        } catch (WrappedResponse wr) {\n            return wr.getResponse();\n        }\n\n        List<String> args = Arrays.asList(ra.getIdentifier(), dataFile.getDisplayName());\n\n        return ok(BundleUtil.getStringFromBundle(\"access.api.revokeAccess.success.for.single.file\", args));\n\n    }\n\n    /**\n     * Reject Access request to Restricted File\n     *\n     * @author sekmiller\n     *\n     * @param fileToRequestAccessId\n     * @param identifier\n     * @param apiToken\n     * @param headers\n     * @return\n     */\n    @PUT\n    @Path(\"/datafile/{id}/rejectAccess/{identifier}\")\n    public Response rejectFileAccess(@PathParam(\"id\") String fileToRequestAccessId, @PathParam(\"identifier\") String identifier, @Context HttpHeaders headers) {\n\n        DataverseRequest dataverseRequest;\n        DataFile dataFile;\n\n        try {\n            dataFile = findDataFileOrDie(fileToRequestAccessId);\n        } catch (WrappedResponse ex) {\n            List<String> args = Arrays.asList(fileToRequestAccessId);\n            return error(BAD_REQUEST, BundleUtil.getStringFromBundle(\"access.api.requestAccess.fileNotFound\", args));\n        }\n\n        RoleAssignee ra = roleAssigneeSvc.getRoleAssignee(identifier);\n\n        if (ra == null) {\n            List<String> args = Arrays.asList(identifier);\n            return error(BAD_REQUEST, BundleUtil.getStringFromBundle(\"access.api.grantAccess.noAssigneeFound\", args));\n        }\n\n        try {\n            dataverseRequest = createDataverseRequest(findUserOrDie());\n        } catch (WrappedResponse wr) {\n            List<String> args = Arrays.asList(identifier);\n            return error(BAD_REQUEST, BundleUtil.getStringFromBundle(\"access.api.fileAccess.failure.noUser\", args));\n        }\n        \n        if (!(dataverseRequest.getAuthenticatedUser().isSuperuser() || permissionService.requestOn(dataverseRequest, dataFile.getOwner()).has(Permission.ManageDatasetPermissions))) {\n            return error(BAD_REQUEST, BundleUtil.getStringFromBundle(\"access.api.rejectAccess.failure.noPermissions\"));\n        }\n\n        if (dataFile.getFileAccessRequesters().contains(ra)) {\n            dataFile.getFileAccessRequesters().remove(ra);\n            dataFileService.save(dataFile);\n\n            try {\n                AuthenticatedUser au = (AuthenticatedUser) ra;\n                userNotificationService.sendNotification(au, new Timestamp(new Date().getTime()), UserNotification.Type.REJECTFILEACCESS, dataFile.getOwner().getId());\n            } catch (ClassCastException e) {\n                //nothing to do here - can only send a notification to an authenticated user\n            }\n\n            List<String> args = Arrays.asList(dataFile.getDisplayName());\n            return ok(BundleUtil.getStringFromBundle(\"access.api.rejectAccess.success.for.single.file\", args));\n\n        } else {\n            List<String> args = Arrays.asList(dataFile.getDisplayName(), ra.getDisplayInfo().getTitle());\n            return error(BAD_REQUEST, BundleUtil.getStringFromBundle(\"access.api.fileAccess.rejectFailure.noRequest\", args));\n        }\n    }\n    \n    // checkAuthorization is a convenience method; it calls the boolean method\n    // isAccessAuthorized(), the actual workhorse, tand throws a 403 exception if not.\n    \n    private void checkAuthorization(DataFile df, String apiToken) throws WebApplicationException {\n\n        if (!isAccessAuthorized(df, apiToken)) {\n            throw new ForbiddenException();\n        }        \n    }\n    \n\n    \n    private boolean isAccessAuthorized(DataFile df, String apiToken) {\n    // First, check if the file belongs to a released Dataset version: \n        \n        boolean published = false; \n        \n        \n        /*\n        SEK 7/26/2018 for 3661 relying on the version state of the dataset versions\n            to which this file is attached check to see if at least one is  RELEASED\n        */\n        for (FileMetadata fm : df.getFileMetadatas()){\n            if(fm.getDatasetVersion().isPublished()){\n                 published = true; \n                 break;\n            }\n        }\n\n        // TODO: (IMPORTANT!)\n        // Business logic like this should NOT be maintained in individual \n        // application fragments. \n        // At the moment it is duplicated here, and inside the Dataset page.\n        // There are also stubs for file-level permission lookups and caching\n        // inside Gustavo's view-scoped PermissionsWrapper. \n        // All this logic needs to be moved to the PermissionServiceBean where it will be \n        // centrally maintained; with the PermissionsWrapper providing \n        // efficient cached lookups to the pages (that often need to make \n        // repeated lookups on the same files). Care will need to be taken \n        // to preserve the slight differences in logic utilized by the page and \n        // this Access call (the page checks the restriction flag on the\n        // filemetadata, not the datafile - as it needs to reflect the permission \n        // status of the file in the version history).  \n        // I will open a 4.[34] ticket. \n        //\n        // -- L.A. 4.2.1\n        \n        \n        // We don't need to check permissions on files that are \n        // from released Dataset versions and not restricted: \n        \n        boolean restricted = false; \n        \n        if (df.isRestricted()) {\n            restricted = true;\n        } else {\n        \n        // There is also a special case of a restricted file that only exists \n        // in a draft version (i.e., a new file, that hasn't been published yet).\n        // Such files must be considered restricted, for access purposes. I.e., \n        // users with no download access to this particular file, but with the \n        // permission to ViewUnpublished on the dataset, should NOT be allowed \n        // to download it. \n        // Up until 4.2.1 restricting unpublished files was only restricting them \n        // in their Draft version fileMetadata, but not in the DataFile object. \n        // (this is what we still want to do for published files; restricting those\n        // only restricts them in the new draft FileMetadata; until it becomes the \n        // published version, the restriction flag on the DataFile is what governs\n        // the download authorization).\n        \n            //if (!published && df.getOwner().getVersions().size() == 1 && df.getOwner().getLatestVersion().isDraft()) {\n            // !df.isReleased() really means just this: new file, only exists in a Draft version!\n            if (!df.isReleased()) {\n                if (df.getFileMetadata().isRestricted()) {\n                    restricted = true;\n                }\n            }\n        }\n        \n        if (!restricted) {\n            // And if they are not published, they can still be downloaded, if the user\n            // has the permission to view unpublished versions! (this case will \n            // be handled below)\n            if (published) { \n                return true;\n            }\n        }\n        \n        User user = null;\n        \n        /** \n         * Authentication/authorization:\n         * \n         * note that the fragment below - that retrieves the session object\n         * and tries to find the user associated with the session - is really\n         * for logging/debugging purposes only; for practical purposes, it \n         * would be enough to just call \"permissionService.on(df).has(Permission.DownloadFile)\"\n         * and the method does just that, tries to authorize for the user in \n         * the current session (or guest user, if no session user is available):\n         */\n        \n        if (session != null) {\n            if (session.getUser() != null) {\n                if (session.getUser().isAuthenticated()) {\n                    user = session.getUser();\n                } else {\n                    logger.fine(\"User associated with the session is not an authenticated user.\");\n                    if (session.getUser() instanceof PrivateUrlUser) {\n                        logger.fine(\"User associated with the session is a PrivateUrlUser user.\");\n                        user = session.getUser();\n                    }\n                    if (session.getUser() instanceof GuestUser) {\n                        logger.fine(\"User associated with the session is indeed a guest user.\");\n                    }\n                }\n            } else {\n                logger.fine(\"No user associated with the session.\");\n            }\n        } else {\n            logger.fine(\"Session is null.\");\n        } \n        \n        User apiTokenUser = null;\n        \n        if ((apiToken != null)&&(apiToken.length()!=64)) {\n            // We'll also try to obtain the user information from the API token, \n            // if supplied: \n        \n            try {\n                logger.fine(\"calling apiTokenUser = findUserOrDie()...\");\n                apiTokenUser = findUserOrDie();\n            } catch (WrappedResponse wr) {\n                logger.log(Level.FINE, \"Message from findUserOrDie(): {0}\", wr.getMessage());\n            }\n            \n            if (apiTokenUser == null) {\n                logger.warning(\"API token-based auth: Unable to find a user with the API token provided.\");\n            }\n        }\n        \n        // OK, let's revisit the case of non-restricted files, this time in        \n        // an unpublished version:         \n        // (if (published) was already addressed above)\n        \n        if (!restricted) {\n            // If the file is not published, they can still download the file, if the user\n            // has the permission to view unpublished versions:\n            \n            if ( user != null ) {\n                // used in JSF context\n                if (permissionService.requestOn(dvRequestService.getDataverseRequest(), df.getOwner()).has(Permission.ViewUnpublishedDataset)) {\n                    // it's not unthinkable, that a null user (i.e., guest user) could be given\n                    // the ViewUnpublished permission!\n                    logger.log(Level.FINE, \"Session-based auth: user {0} has access rights on the non-restricted, unpublished datafile.\", user.getIdentifier());\n                    return true;\n                }\n            }\n\n            if (apiTokenUser != null) {\n                // used in an API context\n                if (permissionService.requestOn( createDataverseRequest(apiTokenUser), df.getOwner()).has(Permission.ViewUnpublishedDataset)) {\n                    logger.log(Level.FINE, \"Session-based auth: user {0} has access rights on the non-restricted, unpublished datafile.\", apiTokenUser.getIdentifier());\n                    return true;\n                }\n            }\n\n            // last option - guest user in either contexts\n            // Guset user is impled by the code above.\n            if ( permissionService.requestOn(dvRequestService.getDataverseRequest(), df.getOwner()).has(Permission.ViewUnpublishedDataset) ) {\n                return true;\n            }\n                    \n        } else {\n            \n            // OK, this is a restricted file. \n            \n            boolean hasAccessToRestrictedBySession = false; \n            boolean hasAccessToRestrictedByToken = false; \n            \n            if (permissionService.on(df).has(Permission.DownloadFile)) {\n            // Note: PermissionServiceBean.on(Datafile df) will obtain the \n            // User from the Session object, just like in the code fragment \n            // above. That's why it's not passed along as an argument.\n                hasAccessToRestrictedBySession = true; \n            } else if (apiTokenUser != null && permissionService.requestOn(createDataverseRequest(apiTokenUser), df).has(Permission.DownloadFile)) {\n                hasAccessToRestrictedByToken = true; \n            }\n            \n            if (hasAccessToRestrictedBySession || hasAccessToRestrictedByToken) {\n                if (published) {\n                    if (hasAccessToRestrictedBySession) {\n                        if (user != null) {\n                            logger.log(Level.FINE, \"Session-based auth: user {0} is granted access to the restricted, published datafile.\", user.getIdentifier());\n                        } else {\n                            logger.fine(\"Session-based auth: guest user is granted access to the restricted, published datafile.\");\n                        }\n                    } else {\n                        logger.log(Level.FINE, \"Token-based auth: user {0} is granted access to the restricted, published datafile.\", apiTokenUser.getIdentifier());\n                    }\n                    return true;\n                } else {\n                    // if the file is NOT published, we will let them download the \n                    // file ONLY if they also have the permission to view \n                    // unpublished versions:\n                    // Note that the code below does not allow a case where it is the\n                    // session user that has the permission on the file, and the API token \n                    // user with the ViewUnpublished permission, or vice versa!\n                    if (hasAccessToRestrictedBySession) {\n                        if (permissionService.on(df.getOwner()).has(Permission.ViewUnpublishedDataset)) {\n                            if (user != null) {\n                                logger.log(Level.FINE, \"Session-based auth: user {0} is granted access to the restricted, unpublished datafile.\", user.getIdentifier());\n                            } else {\n                                logger.fine(\"Session-based auth: guest user is granted access to the restricted, unpublished datafile.\");\n                            }\n                            return true;\n                        } \n                    } else {\n                        if (apiTokenUser != null && permissionService.requestOn(createDataverseRequest(apiTokenUser), df.getOwner()).has(Permission.ViewUnpublishedDataset)) {\n                            logger.log(Level.FINE, \"Token-based auth: user {0} is granted access to the restricted, unpublished datafile.\", apiTokenUser.getIdentifier());\n                            return true;\n                        }\n                    }\n                }\n            }\n        } \n\n        \n        if ((apiToken != null)) {\n            // Will try to obtain the user information from the API token, \n            // if supplied: \n        \n            try {\n                logger.fine(\"calling user = findUserOrDie()...\");\n                user = findUserOrDie();\n            } catch (WrappedResponse wr) {\n                logger.log(Level.FINE, \"Message from findUserOrDie(): {0}\", wr.getMessage());\n            }\n            \n            if (user == null) {\n                logger.warning(\"API token-based auth: Unable to find a user with the API token provided.\");\n                return false;\n            } \n            \n            if (permissionService.requestOn(createDataverseRequest(user), df).has(Permission.DownloadFile)) {\n                if (published) {\n                    logger.log(Level.FINE, \"API token-based auth: User {0} has rights to access the datafile.\", user.getIdentifier());\n                    return true; \n                } else {\n                    // if the file is NOT published, we will let them download the \n                    // file ONLY if they also have the permission to view \n                    // unpublished versions:\n                    if (permissionService.requestOn(createDataverseRequest(user), df.getOwner()).has(Permission.ViewUnpublishedDataset)) {\n                        logger.log(Level.FINE, \"API token-based auth: User {0} has rights to access the (unpublished) datafile.\", user.getIdentifier());\n                        return true;\n                    } else {\n                        logger.log(Level.FINE, \"API token-based auth: User {0} is not authorized to access the (unpublished) datafile.\", user.getIdentifier());\n                    }\n                }\n            } else {\n                logger.log(Level.FINE, \"API token-based auth: User {0} is not authorized to access the datafile.\", user.getIdentifier());\n            }\n            \n            return false;\n        } \n        \n        if (user != null) {\n            logger.log(Level.FINE, \"Session-based auth: user {0} has NO access rights on the requested datafile.\", user.getIdentifier());\n        } \n        \n        if (apiTokenUser != null) {\n            logger.log(Level.FINE, \"Token-based auth: user {0} has NO access rights on the requested datafile.\", apiTokenUser.getIdentifier());\n        } \n        \n        if (user == null && apiTokenUser == null) {\n            logger.fine(\"Unauthenticated access: No guest access to the datafile.\");\n        }\n        \n        return false; \n    }   \n    \n\n        \n    private User findAPITokenUser(String apiToken) {\n        User apiTokenUser = null;\n\n        if ((apiToken != null) && (apiToken.length() != 64)) {\n            // We'll also try to obtain the user information from the API token, \n            // if supplied: \n\n            try {\n                logger.fine(\"calling apiTokenUser = findUserOrDie()...\");\n                apiTokenUser = findUserOrDie();\n                return apiTokenUser;\n            } catch (WrappedResponse wr) {\n                logger.log(Level.FINE, \"Message from findUserOrDie(): {0}\", wr.getMessage());\n                return null;\n            }\n\n        }\n        return apiTokenUser;\n    }\n\n    private URI handleCustomZipDownload(String customZipServiceUrl, String fileIds, String apiToken, User apiTokenUser, UriInfo uriInfo, HttpHeaders headers, boolean gbrecs, boolean orig) throws WebApplicationException {\n        String zipServiceKey = null; \n        Timestamp timestamp = null; \n        \n        String fileIdParams[] = fileIds.split(\",\");\n        int validIdCount = 0; \n        int validFileCount = 0;\n        int downloadAuthCount = 0; \n\n        if (fileIdParams == null || fileIdParams.length == 0) {\n            throw new BadRequestException();\n        }\n        \n        for (int i = 0; i < fileIdParams.length; i++) {\n            Long fileId = null;\n            try {\n                fileId = new Long(fileIdParams[i]);\n                validIdCount++;\n            } catch (NumberFormatException nfe) {\n                fileId = null;\n            }\n            if (fileId != null) {\n                DataFile file = dataFileService.find(fileId);\n                if (file != null) {\n                    validFileCount++;\n                    if (isAccessAuthorized(file, apiToken)) {\n                        logger.fine(\"adding datafile (id=\" + file.getId() + \") to the download list of the ZippedDownloadInstance.\");\n                        if (gbrecs != true && file.isReleased()) {\n                            GuestbookResponse gbr = guestbookResponseService.initAPIGuestbookResponse(file.getOwner(), file, session, apiTokenUser);\n                            guestbookResponseService.save(gbr);\n                            MakeDataCountEntry entry = new MakeDataCountEntry(uriInfo, headers, dvRequestService, file);\n                            mdcLogService.logEntry(entry);\n                        }\n\n                        if (zipServiceKey == null) {\n                            zipServiceKey = fileDownloadService.generateServiceKey();\n                        }\n                        if (timestamp == null) {\n                            timestamp = new Timestamp(new Date().getTime());\n                        }\n\n                        fileDownloadService.addFileToCustomZipJob(zipServiceKey, file, timestamp, true);\n                        downloadAuthCount++;\n                    }\n                }\n            }\n        }\n\n        if (validIdCount == 0) {\n            throw new BadRequestException();\n        }\n        \n        if (validFileCount == 0) {\n            // no supplied id translated into an existing DataFile\n            throw new NotFoundException();\n        }\n        \n        if (downloadAuthCount == 0) {\n            // none of the DataFiles were authorized for download\n            throw new ForbiddenException();\n        }\n        \n        URI redirectUri = null;\n        try {\n            redirectUri = new URI(customZipServiceUrl + \"?\" + zipServiceKey);\n        } catch (URISyntaxException use) {\n            throw new BadRequestException(); \n        }\n        return redirectUri;\n    }   \n}\n", "idx": 3, "id": 44380, "msg": "", "proj": "IQSS-dataverse", "lang": "java"}
{"patch": "@@ -0,0 +1,25 @@\n+\ufeff// <copyright file=\"IMeasurement.cs\" company=\"OpenTelemetry Authors\">\n+// Copyright 2018, OpenTelemetry Authors\n+//\n+// Licensed under the Apache License, Version 2.0 (the \"License\");\n+// you may not use this file except in compliance with the License.\n+// You may obtain a copy of the License at\n+//\n+//     http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+// </copyright>\n+\n+namespace OpenTelemetry.Metrics\n+{\n+    /// <summary>\n+    /// Immutable representation of a measurement.\n+    /// </summary>\n+    public class IMeasurement\n+    {\n+    }\n+}", "y": 1, "oldf": "", "idx": 1, "id": 11885, "msg": "This should be `interface`", "proj": "open-telemetry-opentelemetry-dotnet", "lang": ".cs"}
{"patch": "@@ -1503,9 +1503,9 @@ public class ZMSImpl implements Authorizer, KeyStore, ZMSHandler {\n         validate(name, TYPE_SIMPLE_NAME, caller);\n \n         // verify that request is properly authenticated for this request\n-        \n+\n         verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(), caller);\n-        \n+\n         deleteDomain(ctx, auditRef, domainName, caller);\n         metric.stopTiming(timerMetric, parent, principalDomain);\n     }", "y": 0, "oldf": "/*\n * Copyright 2016 Yahoo Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.yahoo.athenz.zms;\n\nimport com.yahoo.athenz.auth.*;\nimport com.yahoo.athenz.auth.impl.SimplePrincipal;\nimport com.yahoo.athenz.auth.token.PrincipalToken;\nimport com.yahoo.athenz.auth.util.Crypto;\nimport com.yahoo.athenz.common.metrics.Metric;\nimport com.yahoo.athenz.common.metrics.MetricFactory;\nimport com.yahoo.athenz.common.server.audit.AuditReferenceValidator;\nimport com.yahoo.athenz.common.server.audit.AuditReferenceValidatorFactory;\nimport com.yahoo.athenz.common.server.log.AuditLogger;\nimport com.yahoo.athenz.common.server.log.AuditLoggerFactory;\nimport com.yahoo.athenz.common.server.rest.Http;\nimport com.yahoo.athenz.common.server.rest.Http.AuthorityList;\nimport com.yahoo.athenz.common.server.util.ConfigProperties;\nimport com.yahoo.athenz.common.server.util.ServletRequestUtil;\nimport com.yahoo.athenz.common.server.util.StringUtils;\nimport com.yahoo.athenz.common.utils.SignUtils;\nimport com.yahoo.athenz.zms.config.AllowedOperation;\nimport com.yahoo.athenz.zms.config.AuthorizedService;\nimport com.yahoo.athenz.zms.config.AuthorizedServices;\nimport com.yahoo.athenz.zms.config.SolutionTemplates;\nimport com.yahoo.athenz.zms.store.AthenzDomain;\nimport com.yahoo.athenz.zms.store.ObjectStore;\nimport com.yahoo.athenz.zms.store.ObjectStoreFactory;\nimport com.yahoo.athenz.zms.utils.ZMSUtils;\nimport com.yahoo.rdl.JSON;\nimport com.yahoo.rdl.Schema;\nimport com.yahoo.rdl.Timestamp;\nimport com.yahoo.rdl.UUID;\nimport com.yahoo.rdl.Validator;\nimport com.yahoo.rdl.Validator.Result;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport javax.servlet.http.HttpServletRequest;\nimport javax.servlet.http.HttpServletResponse;\nimport javax.ws.rs.core.EntityTag;\nimport javax.ws.rs.core.Response;\nimport java.io.File;\nimport java.io.IOException;\nimport java.net.InetAddress;\nimport java.net.URISyntaxException;\nimport java.nio.file.Files;\nimport java.nio.file.Path;\nimport java.nio.file.Paths;\nimport java.security.PrivateKey;\nimport java.security.PublicKey;\nimport java.text.ParseException;\nimport java.text.SimpleDateFormat;\nimport java.util.*;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.TimeUnit;\nimport java.util.regex.Pattern;\n\nimport static com.yahoo.athenz.common.server.notification.NotificationService.*;\n\npublic class ZMSImpl implements Authorizer, KeyStore, ZMSHandler {\n\n    private static final Logger LOG = LoggerFactory.getLogger(ZMSImpl.class);\n\n    private static String ROOT_DIR;\n    \n    private static final String ROLE_PREFIX = \"role.\";\n    private static final String POLICY_PREFIX = \"policy.\";\n    \n    private static final String ADMIN_POLICY_NAME = \"admin\";\n    private static final String ADMIN_ROLE_NAME = \"admin\";\n\n    private static final String META_ATTR_ACCOUNT = \"account\";\n    private static final String META_ATTR_YPM_ID = \"ypmid\";\n    private static final String META_ATTR_ALL = \"all\";\n\n    private static final String SYS_AUTH = \"sys.auth\";\n    private static final String USER_TOKEN_DEFAULT_NAME = \"_self_\";\n    \n    // data validation types\n    private static final String TYPE_DOMAIN_NAME = \"DomainName\";\n    private static final String TYPE_ENTITY_NAME = \"EntityName\";\n    private static final String TYPE_SIMPLE_NAME = \"SimpleName\";\n    private static final String TYPE_MEMBER_NAME = \"MemberName\";\n    private static final String TYPE_COMPOUND_NAME = \"CompoundName\";\n    private static final String TYPE_RESOURCE_NAME = \"ResourceName\";\n    private static final String TYPE_SERVICE_NAME = \"ServiceName\";\n    private static final String TYPE_ROLE = \"Role\";\n    private static final String TYPE_POLICY = \"Policy\";\n    private static final String TYPE_ASSERTION = \"Assertion\";\n    private static final String TYPE_SERVICE_IDENTITY = \"ServiceIdentity\";\n    private static final String TYPE_TOP_LEVEL_DOMAIN = \"TopLevelDomain\";\n    private static final String TYPE_SUB_DOMAIN = \"SubDomain\";\n    private static final String TYPE_USER_DOMAIN = \"UserDomain\";\n    private static final String TYPE_DOMAIN_META = \"DomainMeta\";\n    private static final String TYPE_DOMAIN_TEMPLATE = \"DomainTemplate\";\n    private static final String TYPE_TENANT_RESOURCE_GROUP_ROLES = \"TenantResourceGroupRoles\";\n    private static final String TYPE_PROVIDER_RESOURCE_GROUP_ROLES = \"ProviderResourceGroupRoles\";\n    private static final String TYPE_PUBLIC_KEY_ENTRY = \"PublicKeyEntry\";\n    private static final String TYPE_MEMBERSHIP = \"Membership\";\n    private static final String TYPE_QUOTA = \"Quota\";\n    private static final String TYPE_ROLE_SYSTEM_META = \"RoleSystemMeta\";\n    private static final String TYPE_ROLE_META = \"RoleMeta\";\n\n    private static final String SERVER_READ_ONLY_MESSAGE = \"Server in Maintenance Read-Only mode. Please try your request later\";\n\n    public static Metric metric;\n    public static String serverHostName  = null;\n\n    protected DBService dbService = null;\n    protected Schema schema = null;\n    protected ServerPrivateKey privateKey = null;\n    protected ServerPrivateKey privateECKey = null;\n    protected ServerPrivateKey privateRSAKey = null;\n    protected int userTokenTimeout = 3600;\n    protected boolean virtualDomainSupport = true;\n    protected boolean productIdSupport = false;\n    protected int virtualDomainLimit = 2;\n    protected long signedPolicyTimeout;\n    protected int domainNameMaxLen;\n    protected AuthorizedServices serverAuthorizedServices = null;\n    protected static SolutionTemplates serverSolutionTemplates = null;\n    protected Map<String, String> serverPublicKeyMap = null;\n    protected boolean readOnlyMode = false;\n    protected boolean validateUserRoleMembers = false;\n    protected boolean validateServiceRoleMembers = false;\n    protected boolean useMasterCopyForSignedDomains = false;\n    protected Set<String> validateServiceMemberSkipDomains;\n    protected static Validator validator;\n    protected String userDomain;\n    protected String userDomainPrefix;\n    protected String homeDomain;\n    protected String homeDomainPrefix;\n    protected String userDomainAlias;\n    protected String userDomainAliasPrefix;\n    protected String serverRegion = null;\n    protected List<String> addlUserCheckDomainPrefixList = null;\n    protected Http.AuthorityList authorities = null;\n    protected List<String> providerEndpoints = null;\n    protected Set<String> reservedServiceNames = null;\n    protected PrivateKeyStore keyStore = null;\n    protected boolean secureRequestsOnly = true;\n    protected AuditLogger auditLogger = null;\n    protected Authority userAuthority = null;\n    protected Authority principalAuthority = null;\n    protected Set<String> authFreeUriSet = null;\n    protected List<Pattern> authFreeUriList = null;\n    protected Set<String> corsOriginList = null;\n    protected int httpPort;\n    protected int httpsPort;\n    protected int statusPort;\n    protected int serviceNameMinLength;\n    protected Status successServerStatus = null;\n    protected Set<String> reservedSystemDomains = null;\n    protected File healthCheckFile = null;\n    protected AuditReferenceValidator auditReferenceValidator = null;\n    protected NotificationManager notificationManager = null;\n\n    // enum to represent our access response since in some cases we want to\n    // handle domain not founds differently instead of just returning failure\n\n    enum AccessStatus {\n        ALLOWED,\n        DENIED,\n        DENIED_INVALID_ROLE_TOKEN\n    }\n    \n    enum AthenzObject {\n        ASSERTION {\n            void convertToLowerCase(Object obj) {\n                Assertion assertion = (Assertion) obj;\n                assertion.setAction(assertion.getAction().toLowerCase());\n                assertion.setResource(assertion.getResource().toLowerCase());\n                assertion.setRole(assertion.getRole().toLowerCase());\n            }\n        },\n        DEFAULT_ADMINS {\n            void convertToLowerCase(Object obj) {\n                DefaultAdmins defaultAdmins = (DefaultAdmins) obj;\n                LIST.convertToLowerCase(defaultAdmins.getAdmins());\n            }\n        },\n        DOMAIN_TEMPLATE {\n            void convertToLowerCase(Object obj) {\n                DomainTemplate template = (DomainTemplate) obj;\n                if (template != null) {\n                    LIST.convertToLowerCase(template.getTemplateNames());\n                    List<TemplateParam> params = template.getParams();\n                    if (params != null) {\n                        for (TemplateParam param : params) {\n                            param.setName(param.getName().toLowerCase());\n                            param.setValue(param.getValue().toLowerCase());\n                        }\n                    }\n                }\n            }\n        },\n        DOMAIN_TEMPLATE_LIST {\n            void convertToLowerCase(Object obj) {\n                DomainTemplateList templates = (DomainTemplateList) obj;\n                if (templates != null) {\n                    LIST.convertToLowerCase(templates.getTemplateNames());\n                }\n            }\n        },\n        ENTITY {\n            void convertToLowerCase(Object obj) {\n                Entity entity = (Entity) obj;\n                entity.setName(entity.getName().toLowerCase());\n            }\n        },\n        LIST {\n            void convertToLowerCase(Object obj) {\n                @SuppressWarnings(\"unchecked\")\n                List<String> list = (List<String>) obj;\n                if (list != null) {\n                    ListIterator<String> iter = list.listIterator();\n                    while (iter.hasNext()) {\n                        iter.set(iter.next().toLowerCase());\n                    }\n                }\n            }\n        },\n        MEMBERSHIP {\n            void convertToLowerCase(Object obj) {\n                Membership membership = (Membership) obj;\n                membership.setMemberName(membership.getMemberName().toLowerCase());\n                if (membership.getRoleName() != null) {\n                    membership.setRoleName(membership.getRoleName().toLowerCase());\n                }\n            }\n        },\n        POLICY {\n            void convertToLowerCase(Object obj) {\n                Policy policy = (Policy) obj;\n                policy.setName(policy.getName().toLowerCase());\n                if (policy.getAssertions() != null) {\n                    for (Assertion assertion : policy.getAssertions()) {\n                        ASSERTION.convertToLowerCase(assertion);\n                    }\n                }\n            }\n        },\n        PROVIDER_RESOURCE_GROUP_ROLES {\n            void convertToLowerCase(Object obj) {\n                ProviderResourceGroupRoles tenantRoles = (ProviderResourceGroupRoles) obj;\n                tenantRoles.setDomain(tenantRoles.getDomain().toLowerCase());\n                tenantRoles.setService(tenantRoles.getService().toLowerCase());\n                tenantRoles.setTenant(tenantRoles.getTenant().toLowerCase());\n                tenantRoles.setResourceGroup(tenantRoles.getResourceGroup().toLowerCase());\n                if (tenantRoles.getRoles() != null) {\n                    for (TenantRoleAction roleAction : tenantRoles.getRoles()) {\n                        TENANT_ROLE_ACTION.convertToLowerCase(roleAction);\n                    }\n                }\n            }\n        },\n        PUBLIC_KEY_ENTRY {\n            void convertToLowerCase(Object obj) {\n                PublicKeyEntry keyEntry = (PublicKeyEntry) obj;\n                keyEntry.setId(keyEntry.getId().toLowerCase());\n            }\n        },\n        ROLE {\n            void convertToLowerCase(Object obj) {\n                Role role = (Role) obj;\n                role.setName(role.getName().toLowerCase());\n                if (role.getTrust() != null) {\n                    role.setTrust(role.getTrust().toLowerCase());\n                }\n                LIST.convertToLowerCase(role.getMembers());\n                ROLE_MEMBER.convertToLowerCase(role.getRoleMembers());\n            }\n        },\n        ROLE_MEMBER {\n            void convertToLowerCase(Object obj) {\n                @SuppressWarnings(\"unchecked\")\n                List<RoleMember> list = (List<RoleMember>) obj;\n                if (list != null) {\n                    ListIterator<RoleMember> iter = list.listIterator();\n                    while (iter.hasNext()) {\n                        RoleMember roleMember = iter.next();\n                        iter.set(roleMember.setMemberName(roleMember.getMemberName().toLowerCase()));\n                    }\n                }\n            }\n        },\n        SERVICE_IDENTITY {\n            void convertToLowerCase(Object obj) {\n                ServiceIdentity service = (ServiceIdentity) obj;\n                service.setName(service.getName().toLowerCase());\n                LIST.convertToLowerCase(service.getHosts());\n                if (service.getPublicKeys() != null) {\n                    for (PublicKeyEntry key : service.getPublicKeys()) {\n                        PUBLIC_KEY_ENTRY.convertToLowerCase(key);\n                    }\n                }\n            }\n        },\n        SUB_DOMAIN {\n            void convertToLowerCase(Object obj) {\n                SubDomain subdomain = (SubDomain) obj;\n                subdomain.setName(subdomain.getName().toLowerCase());\n                subdomain.setParent(subdomain.getParent().toLowerCase());\n                LIST.convertToLowerCase(subdomain.getAdminUsers());\n                DOMAIN_TEMPLATE_LIST.convertToLowerCase(subdomain.getTemplates());\n            }\n        },\n        TENANCY {\n            void convertToLowerCase(Object obj) {\n                Tenancy tenancy = (Tenancy) obj;\n                tenancy.setDomain(tenancy.getDomain().toLowerCase());\n                tenancy.setService(tenancy.getService().toLowerCase());\n                LIST.convertToLowerCase(tenancy.getResourceGroups());\n            }\n        },\n        TENANT_RESOURCE_GROUP_ROLES {\n            void convertToLowerCase(Object obj) {\n                TenantResourceGroupRoles tenantRoles = (TenantResourceGroupRoles) obj;\n                tenantRoles.setDomain(tenantRoles.getDomain().toLowerCase());\n                tenantRoles.setService(tenantRoles.getService().toLowerCase());\n                tenantRoles.setTenant(tenantRoles.getTenant().toLowerCase());\n                tenantRoles.setResourceGroup(tenantRoles.getResourceGroup().toLowerCase());\n                if (tenantRoles.getRoles() != null) {\n                    for (TenantRoleAction roleAction : tenantRoles.getRoles()) {\n                        TENANT_ROLE_ACTION.convertToLowerCase(roleAction);\n                    }\n                }\n            }\n        },\n        TENANT_ROLE_ACTION {\n            void convertToLowerCase(Object obj) {\n                TenantRoleAction roleAction = (TenantRoleAction) obj;\n                roleAction.setAction(roleAction.getAction().toLowerCase());\n                roleAction.setRole(roleAction.getRole().toLowerCase());\n            }\n        },\n        TOP_LEVEL_DOMAIN {\n            void convertToLowerCase(Object obj) {\n                TopLevelDomain domain = (TopLevelDomain) obj;\n                domain.setName(domain.getName().toLowerCase());\n                LIST.convertToLowerCase(domain.getAdminUsers());\n                DOMAIN_TEMPLATE_LIST.convertToLowerCase(domain.getTemplates());\n                if (domain.getOrg() != null) {\n                    domain.setOrg(domain.getOrg().toLowerCase());\n                }\n            }\n        },\n        QUOTA {\n            void convertToLowerCase(Object obj) {\n                Quota quota = (Quota) obj;\n                quota.setName(quota.getName().toLowerCase());\n            }\n        },\n        USER_DOMAIN {\n            void convertToLowerCase(Object obj) {\n                UserDomain userDomain = (UserDomain) obj;\n                userDomain.setName(userDomain.getName().toLowerCase());\n                DOMAIN_TEMPLATE_LIST.convertToLowerCase(userDomain.getTemplates());\n            }\n        },\n        DOMAIN_META {\n            void convertToLowerCase(Object obj) {\n                DomainMeta domainMeta = (DomainMeta) obj;\n                if (domainMeta.getCertDnsDomain() != null) {\n                    domainMeta.setCertDnsDomain(domainMeta.getCertDnsDomain().toLowerCase());\n                }\n                if (domainMeta.getOrg() != null) {\n                    domainMeta.setOrg(domainMeta.getOrg().toLowerCase());\n                }\n            }\n        };\n            \n        abstract void convertToLowerCase(Object obj);\n    }\n    \n    public ZMSImpl() {\n        \n        // before doing anything else we need to load our\n        // system properties from our config file\n        \n        loadSystemProperties();\n        \n        // let's first get our server hostname\n        \n        ZMSImpl.serverHostName = getServerHostName();\n        \n        // before we do anything we need to load our configuration\n        // settings\n        \n        loadConfigurationSettings();\n        \n        // load our schema validator - we need this before we initialize\n        // our store, if necessary\n        \n        loadSchemaValidator();\n        \n        // let's load our audit logger\n        \n        loadAuditLogger();\n\n        // load any audit reference validator\n\n        loadAuditRefValidator();\n        \n        // load any configured authorities to authenticate principals\n        \n        loadAuthorities();\n        \n        // we need a private key to sign any tokens and documents\n        \n        loadPrivateKeyStore();\n        \n        // check if we need to load any metric support for stats\n        \n        loadMetricObject();\n        \n        // our object store - either mysql or file based\n        \n        loadObjectStore();\n        \n        // initialize our store with default domains\n        // this should only happen when running ZMS in local/debug mode\n        // otherwise the store should have been initialized by now\n        \n        initObjectStore();\n        \n        // load the list of authorized services\n        \n        loadAuthorizedServices();\n        \n        // load the Solution templates\n        \n        loadSolutionTemplates();\n        \n        // retrieve our public keys\n        \n        loadServerPublicKeys();\n        \n        // make sure to set the keystore for any instance that requires it\n        \n        setAuthorityKeyStore();\n\n        // Initialize Notification Manager\n\n        setNotificationManager();\n    }\n\n    private void setNotificationManager() {\n        notificationManager = new NotificationManager(dbService, userDomainPrefix);\n    }\n\n    void loadSystemProperties() {\n        String propFile = System.getProperty(ZMSConsts.ZMS_PROP_FILE_NAME,\n                getRootDir() + \"/conf/zms_server/zms.properties\");\n        ConfigProperties.loadProperties(propFile);\n    }\n    \n    void setAuthorityKeyStore() {\n        for (Authority authority : authorities.getAuthorities()) {\n            if (AuthorityKeyStore.class.isInstance(authority)) {\n                ((AuthorityKeyStore) authority).setKeyStore(this);\n            }\n        }\n    }\n    \n    void loadSchemaValidator() {\n        schema = ZMSSchema.instance();\n        validator = new Validator(schema);\n    }\n    \n    void loadConfigurationSettings() {\n        \n        // make sure all requests run in secure mode\n\n        secureRequestsOnly = Boolean.parseBoolean(System.getProperty(ZMSConsts.ZMS_PROP_SECURE_REQUESTS_ONLY, \"true\"));\n        \n        // retrieve the regular and status ports\n        \n        httpPort = ConfigProperties.getPortNumber(ZMSConsts.ZMS_PROP_HTTP_PORT,\n                ZMSConsts.ZMS_HTTP_PORT_DEFAULT);\n        httpsPort = ConfigProperties.getPortNumber(ZMSConsts.ZMS_PROP_HTTPS_PORT,\n                ZMSConsts.ZMS_HTTPS_PORT_DEFAULT);\n        statusPort = ConfigProperties.getPortNumber(ZMSConsts.ZMS_PROP_STATUS_PORT, 0);\n        \n        successServerStatus = new Status().setCode(ResourceException.OK).setMessage(\"OK\");\n        \n        // retrieve the user domain we're supposed to use\n        \n        userDomain = System.getProperty(ZMSConsts.ZMS_PROP_USER_DOMAIN, ZMSConsts.USER_DOMAIN);\n        userDomainPrefix = userDomain + \".\";\n\n        userDomainAlias = System.getProperty(ZMSConsts.ZMS_PROP_USER_DOMAIN_ALIAS);\n        if (userDomainAlias != null) {\n            userDomainAliasPrefix = userDomainAlias + \".\";\n        }\n\n        final String addlUserCheckDomains = System.getProperty(ZMSConsts.ZMS_PROP_ADDL_USER_CHECK_DOMAINS);\n        if (addlUserCheckDomains != null && !addlUserCheckDomains.isEmpty()) {\n            String[] checkDomains = addlUserCheckDomains.split(\",\");\n            addlUserCheckDomainPrefixList = new ArrayList<>();\n            for (String checkDomain : checkDomains) {\n                addlUserCheckDomainPrefixList.add(checkDomain + \".\");\n            }\n        }\n\n        homeDomain = System.getProperty(ZMSConsts.ZMS_PROP_HOME_DOMAIN, userDomain);\n        homeDomainPrefix = homeDomain + \".\";\n        \n        // default token timeout for issued tokens\n        \n        userTokenTimeout = Integer.parseInt(\n                System.getProperty(ZMSConsts.ZMS_PROP_TIMEOUT, \"3600\"));\n        \n        // check if we need to run in maintenance read only mode\n        \n        readOnlyMode = Boolean.parseBoolean(\n                System.getProperty(ZMSConsts.ZMS_PROP_READ_ONLY_MODE, \"false\"));\n\n        // check to see if we need to validate all user and service members\n        // when adding them to roles\n\n        validateUserRoleMembers = Boolean.parseBoolean(\n                System.getProperty(ZMSConsts.ZMS_PROP_VALIDATE_USER_MEMBERS, \"false\"));\n        validateServiceRoleMembers = Boolean.parseBoolean(\n                System.getProperty(ZMSConsts.ZMS_PROP_VALIDATE_SERVICE_MEMBERS, \"false\"));\n\n        // there are going to be domains like our ci/cd dynamic project domain\n        // where we can't verify the service role members so for those we're\n        // going to skip specific domains from validation checks\n\n        final String skipDomains = System.getProperty(\n                ZMSConsts.ZMS_PROP_VALIDATE_SERVICE_MEMBERS_SKIP_DOMAINS, \"\");\n        validateServiceMemberSkipDomains = new HashSet<>(Arrays.asList(skipDomains.split(\",\")));\n\n        // check to see if we need to support product ids as required\n        // for top level domains\n        \n        productIdSupport = Boolean.parseBoolean(\n                System.getProperty(ZMSConsts.ZMS_PROP_PRODUCT_ID_SUPPORT, \"false\"));\n        \n        // get the list of valid provider endpoints\n        \n        final String endPoints = System.getProperty(ZMSConsts.ZMS_PROP_PROVIDER_ENDPOINTS);\n        if (endPoints != null) {\n            providerEndpoints = Arrays.asList(endPoints.split(\",\"));\n        }\n        \n        // retrieve virtual domain support and limit. If we're given an invalid negative\n        // value for limit, we'll default back to our configured value of 5\n        \n        virtualDomainSupport = Boolean.parseBoolean(\n                System.getProperty(ZMSConsts.ZMS_PROP_VIRTUAL_DOMAIN, \"true\"));\n        virtualDomainLimit = Integer.parseInt(\n                System.getProperty(ZMSConsts.ZMS_PROP_VIRTUAL_DOMAIN_LIMIT, \"5\"));\n        if (virtualDomainLimit < 0) {\n            virtualDomainLimit = 5;\n        }\n        \n        // signedPolicyTimeout is in milliseconds but the config setting should be in seconds\n        // to be consistent with other configuration properties (Default 7 days)\n        \n        signedPolicyTimeout = 1000 * Long.parseLong(\n                System.getProperty(ZMSConsts.ZMS_PROP_SIGNED_POLICY_TIMEOUT, \"604800\"));\n        if (signedPolicyTimeout < 0) {\n            signedPolicyTimeout = 1000 * 604800;\n        }\n\n        useMasterCopyForSignedDomains = Boolean.parseBoolean(\n                System.getProperty(ZMSConsts.ZMS_PROP_MASTER_COPY_FOR_SIGNED_DOMAINS, \"false\"));\n\n        // get the maximum length allowed for a top level domain name\n\n        domainNameMaxLen = Integer.parseInt(System.getProperty(\n                ZMSConsts.ZMS_PROP_DOMAIN_NAME_MAX_SIZE, ZMSConsts.ZMS_DOMAIN_NAME_MAX_SIZE_DEFAULT));\n        if (domainNameMaxLen < 10) { // 10 is arbitrary\n            int domNameMaxDefault = Integer.parseInt(ZMSConsts.ZMS_DOMAIN_NAME_MAX_SIZE_DEFAULT);\n            LOG.warn(\"init: Warning: maximum domain name length specified is too small: \" +\n                domainNameMaxLen + \" : reverting to default: \" + domNameMaxDefault);\n            domainNameMaxLen = domNameMaxDefault;\n        }\n        LOG.info(\"init: using maximum domain name length: \" + domainNameMaxLen);\n        \n        // get the list of uris that we want to allow an-authenticated access\n        \n        final String uriList = System.getProperty(ZMSConsts.ZMS_PROP_NOAUTH_URI_LIST);\n        if (uriList != null) {\n            authFreeUriSet = new HashSet<>();\n            authFreeUriList = new ArrayList<>();\n            String[] list = uriList.split(\",\");\n            for (String uri : list) {\n                if (uri.indexOf('+') != -1) {\n                    authFreeUriList.add(Pattern.compile(uri));\n                } else {\n                    authFreeUriSet.add(uri);\n                }\n            }\n        }\n\n        // get the list of white listed origin values for cors requests\n\n        final String originList = System.getProperty(ZMSConsts.ZMS_PROP_CORS_ORIGIN_LIST);\n        if (originList != null) {\n            corsOriginList = new HashSet<>(Arrays.asList(originList.split(\",\")));\n        }\n\n        // get the list of valid provider endpoints\n\n        final String serviceNames = System.getProperty(ZMSConsts.ZMS_PROP_RESERVED_SERVICE_NAMES,\n                ZMSConsts.ZMS_RESERVED_SERVICE_NAMES_DEFAULT);\n        reservedServiceNames = new HashSet<>(Arrays.asList(serviceNames.split(\",\")));\n\n        // min length for service names\n\n        serviceNameMinLength = Integer.parseInt(\n                System.getProperty(ZMSConsts.ZMS_PROP_SERVICE_NAME_MIN_LENGTH, \"3\"));\n\n        // setup our reserved system domain names\n\n        reservedSystemDomains = new HashSet<>();\n        reservedSystemDomains.add(\"sys\");\n        reservedSystemDomains.add(\"sys.auth\");\n        reservedSystemDomains.add(\"sys.auth.audit\");\n        reservedSystemDomains.add(\"sys.auth.audit.org\");\n        reservedSystemDomains.add(\"sys.auth.audit.domain\");\n        reservedSystemDomains.add(userDomain);\n        reservedSystemDomains.add(homeDomain);\n\n        // setup our health check file\n\n        final String healthCheckPath = System.getProperty(ZMSConsts.ZMS_PROP_HEALTH_CHECK_PATH);\n        if (healthCheckPath != null && !healthCheckPath.isEmpty()) {\n            healthCheckFile = new File(healthCheckPath);\n        }\n\n        // get server region\n\n        serverRegion = System.getProperty(ZMSConsts.ZMS_PROP_SERVER_REGION);\n    }\n    \n    void loadObjectStore() {\n        \n        String objFactoryClass = System.getProperty(ZMSConsts.ZMS_PROP_OBJECT_STORE_FACTORY_CLASS,\n                ZMSConsts.ZMS_OBJECT_STORE_FACTORY_CLASS);\n        ObjectStoreFactory objFactory;\n        try {\n            objFactory = (ObjectStoreFactory) Class.forName(objFactoryClass).newInstance();\n        } catch (InstantiationException | IllegalAccessException | ClassNotFoundException e) {\n            LOG.error(\"Invalid ObjectStoreFactory class: \" + objFactoryClass\n                    + \" error: \" + e.getMessage());\n            throw new IllegalArgumentException(\"Invalid object store\");\n        }\n\n        ZMSConfig zmsConfig = new ZMSConfig();\n        zmsConfig.setUserDomain(userDomain);\n        zmsConfig.setAddlUserCheckDomainPrefixList(addlUserCheckDomainPrefixList);\n        zmsConfig.setUserDomainPrefix(userDomainPrefix);\n\n        ObjectStore store = objFactory.create(keyStore);\n        dbService = new DBService(store, auditLogger, zmsConfig, auditReferenceValidator);\n    }\n    \n    void loadMetricObject() {\n        \n        String metricFactoryClass = System.getProperty(ZMSConsts.ZMS_PROP_METRIC_FACTORY_CLASS,\n                ZMSConsts.ZMS_METRIC_FACTORY_CLASS);\n        MetricFactory metricFactory;\n        try {\n            metricFactory = (MetricFactory) Class.forName(metricFactoryClass).newInstance();\n        } catch (InstantiationException | IllegalAccessException | ClassNotFoundException e) {\n            LOG.error(\"Invalid MetricFactory class: \" + metricFactoryClass\n                    + \" error: \" + e.getMessage());\n            throw new IllegalArgumentException(\"Invalid metric class\");\n        }\n        \n        // create our metric and increment our startup count\n        \n        ZMSImpl.metric = metricFactory.create();\n        metric.increment(\"zms_sa_startup\");\n    }\n    \n    void loadPrivateKeyStore() {\n        \n        String pkeyFactoryClass = System.getProperty(ZMSConsts.ZMS_PROP_PRIVATE_KEY_STORE_FACTORY_CLASS,\n                ZMSConsts.ZMS_PRIVATE_KEY_STORE_FACTORY_CLASS);\n        PrivateKeyStoreFactory pkeyFactory;\n        try {\n            pkeyFactory = (PrivateKeyStoreFactory) Class.forName(pkeyFactoryClass).newInstance();\n        } catch (InstantiationException | IllegalAccessException | ClassNotFoundException e) {\n            LOG.error(\"Invalid PrivateKeyStoreFactory class: \" + pkeyFactoryClass\n                    + \" error: \" + e.getMessage());\n            throw new IllegalArgumentException(\"Invalid private key store\");\n        }\n        \n        // extract the private key and public keys for our service\n        \n        keyStore = pkeyFactory.create();\n\n        privateECKey = keyStore.getPrivateKey(ZMSConsts.ZMS_SERVICE, serverHostName,\n                serverRegion, ZMSConsts.EC);\n\n        privateRSAKey = keyStore.getPrivateKey(ZMSConsts.ZMS_SERVICE, serverHostName,\n                serverRegion, ZMSConsts.RSA);\n\n        // if we don't have ec and rsa specific keys specified then we're going to fall\n        // back and use the old private key api and use that for our private key\n        // if both ec and rsa keys are provided, we use the ec key as preferred\n        // when signing policy files\n\n        if (privateECKey == null && privateRSAKey == null) {\n            StringBuilder privKeyId = new StringBuilder(256);\n            PrivateKey pkey = keyStore.getPrivateKey(ZMSConsts.ZMS_SERVICE, serverHostName, privKeyId);\n            privateKey = new ServerPrivateKey(pkey, privKeyId.toString());\n        } else if (privateECKey != null) {\n            privateKey = privateECKey;\n        } else {\n            privateKey = privateRSAKey;\n        }\n    }\n    \n    void loadAuthorities() {\n        \n        // get our authorities\n        \n        final String authListConfig = System.getProperty(ZMSConsts.ZMS_PROP_AUTHORITY_CLASSES,\n                ZMSConsts.ZMS_PRINCIPAL_AUTHORITY_CLASS);\n        final String principalAuthorityClass = System.getProperty(ZMSConsts.ZMS_PROP_PRINCIPAL_AUTHORITY_CLASS);\n        final String userAuthorityClass = System.getProperty(ZMSConsts.ZMS_PROP_USER_AUTHORITY_CLASS);\n        \n        authorities = new AuthorityList();\n\n        String[] authorityList = authListConfig.split(\",\");\n        for (String authorityClass : authorityList) {\n            Authority authority = getAuthority(authorityClass);\n            if (authority == null) {\n                throw new IllegalArgumentException(\"Invalid authority\");\n            }\n            if (authorityClass.equals(principalAuthorityClass)) {\n                principalAuthority = authority;\n            }\n            if (authorityClass.equals(userAuthorityClass)) {\n                userAuthority = authority;\n            }\n            authority.initialize();\n            authorities.add(authority);\n        }\n    }\n    \n    void loadAuditLogger() {\n        \n        String auditFactoryClass = System.getProperty(ZMSConsts.ZMS_PROP_AUDIT_LOGGER_FACTORY_CLASS,\n                ZMSConsts.ZMS_AUDIT_LOGGER_FACTORY_CLASS);\n        AuditLoggerFactory auditLogFactory;\n        \n        try {\n            auditLogFactory = (AuditLoggerFactory) Class.forName(auditFactoryClass).newInstance();\n        } catch (InstantiationException | IllegalAccessException | ClassNotFoundException e) {\n            LOG.error(\"Invalid AuditLoggerFactory class: \" + auditFactoryClass\n                    + \" error: \" + e.getMessage());\n            throw new IllegalArgumentException(\"Invalid audit logger class\");\n        }\n        \n        // create our audit logger\n        \n        auditLogger = auditLogFactory.create();\n    }\n\n    void loadAuditRefValidator() {\n        final String auditRefValidatorClass = System.getProperty(ZMSConsts.ZMS_PROP_AUDIT_REF_VALIDATOR_FACTORY_CLASS);\n        AuditReferenceValidatorFactory auditReferenceValidatorFactory;\n\n        if (auditRefValidatorClass != null && !auditRefValidatorClass.isEmpty()) {\n\n            try {\n                auditReferenceValidatorFactory = (AuditReferenceValidatorFactory) Class.forName(auditRefValidatorClass).newInstance();\n            } catch (InstantiationException | IllegalAccessException | ClassNotFoundException e) {\n                LOG.error(\"Invalid AuditReferenceValidatorFactory class: \" + auditRefValidatorClass\n                        + \" error: \" + e.getMessage());\n                throw new IllegalArgumentException(\"Invalid audit reference factory class\");\n            }\n\n            // create our audit reference validator\n\n            auditReferenceValidator = auditReferenceValidatorFactory.create();\n        }\n    }\n    \n    void loadServerPublicKeys() {\n        \n        // initialize our public key map\n        \n        serverPublicKeyMap = new ConcurrentHashMap<>();\n        \n        // retrieve our zms service identity object\n        \n        ServiceIdentity identity = dbService.getServiceIdentity(SYS_AUTH, ZMSConsts.ZMS_SERVICE, false);\n        if (identity != null) {\n            \n            // process all the public keys and add them to the map\n            \n            List<PublicKeyEntry> publicKeyList = identity.getPublicKeys();\n            if (publicKeyList != null) {\n                for (PublicKeyEntry entry : publicKeyList) {\n                    serverPublicKeyMap.put(entry.getId(), entry.getKey());\n                }\n            }\n        }\n        \n        // this should never happen but just in case we'll just\n        // use the public key we retrieved ourselves to the map\n        \n        if (serverPublicKeyMap.isEmpty() && privateKey != null) {\n            final String publicKey = Crypto.convertToPEMFormat(Crypto.extractPublicKey(privateKey.getKey()));\n            serverPublicKeyMap.put(privateKey.getId(), Crypto.ybase64EncodeString(publicKey));\n        }\n    }\n    \n    void loadSolutionTemplates() {\n        \n        // get the configured path for the list of service templates\n        \n        String solutionTemplatesFname =  System.getProperty(ZMSConsts.ZMS_PROP_SOLUTION_TEMPLATE_FNAME,\n                getRootDir() + \"/conf/zms_server/solution_templates.json\");\n        \n        Path path = Paths.get(solutionTemplatesFname);\n        try {\n            serverSolutionTemplates = JSON.fromBytes(Files.readAllBytes(path), SolutionTemplates.class);\n        } catch (IOException ex) {\n            LOG.error(\"Unable to parse service templates file {}: {}\",\n                    solutionTemplatesFname, ex.getMessage());\n        }\n        \n        if (serverSolutionTemplates == null) {\n            LOG.error(\"Generating empty solution template list...\");\n            serverSolutionTemplates = new SolutionTemplates();\n            serverSolutionTemplates.setTemplates(new HashMap<>());\n        }\n    }\n    \n    void loadAuthorizedServices() {\n        \n        // get the configured path for the list of authorized services and what operations\n        // those services are allowed to process\n        \n        String authzServiceFname =  System.getProperty(ZMSConsts.ZMS_PROP_AUTHZ_SERVICE_FNAME,\n                getRootDir() + \"/conf/zms_server/authorized_services.json\");\n        \n        Path path = Paths.get(authzServiceFname);\n        try {\n            serverAuthorizedServices = JSON.fromBytes(Files.readAllBytes(path), AuthorizedServices.class);\n        } catch (IOException ex) {\n            LOG.error(\"Unable to parse authorized service file {}: {}\",\n                    authzServiceFname, ex.getMessage());\n        }\n        \n        if (serverAuthorizedServices == null) {\n            LOG.error(\"Generating empty authorized service list...\");\n            serverAuthorizedServices = new AuthorizedServices();\n            serverAuthorizedServices.setTemplates(new HashMap<>());\n        }\n    }\n    \n    void initObjectStore() {\n        \n        final String caller = \"initstore\";\n\n        List<String> domains = dbService.listDomains(null, 0);\n        if (domains.size() > 0 && domains.contains(SYS_AUTH)) {\n            return;\n        }\n        \n        String adminUserList = System.getProperty(ZMSConsts.ZMS_PROP_DOMAIN_ADMIN);\n        if (adminUserList == null) {\n            throw ZMSUtils.internalServerError(\"init: No ZMS admin user specified\", caller);\n        }\n        \n        String[] users = adminUserList.split(\",\");\n        ArrayList<String> adminUsers = new ArrayList<>();\n        for (String user : users) {\n            final String adminUser = user.trim();\n            if (!adminUser.startsWith(userDomainPrefix)) {\n                throw ZMSUtils.internalServerError(\"init: Bad domain user name(\" + adminUser +\n                        \"), must begin with (\" + userDomainPrefix + \")\", caller);\n            }\n            adminUsers.add(adminUser);\n        }\n\n        // create system required top level domains\n\n        Domain domain = new Domain().setName(userDomain).setDescription(\"The reserved domain for user authentication\")\n                .setId(UUID.fromCurrentTime()).setModified(Timestamp.fromCurrentTime());\n        createTopLevelDomain(null, domain, adminUsers, null, \"System Setup\");\n        if (!ZMSConsts.USER_DOMAIN.equals(userDomain)) {\n            domain = new Domain().setName(ZMSConsts.USER_DOMAIN).setDescription(\"The reserved domain for user authentication\")\n                    .setId(UUID.fromCurrentTime()).setModified(Timestamp.fromCurrentTime());\n            createTopLevelDomain(null, domain, adminUsers, null, \"System Setup\");\n        }\n        if (!homeDomain.equals(userDomain)) {\n            domain = new Domain().setName(homeDomain).setDescription(\"The reserved domain for personal user domains\")\n                    .setId(UUID.fromCurrentTime()).setModified(Timestamp.fromCurrentTime());\n            createTopLevelDomain(null, domain, adminUsers, null, \"System Setup\");\n        }\n        domain = new Domain().setName(\"sys\").setDescription(\"The reserved domain for system related information\")\n                .setId(UUID.fromCurrentTime()).setModified(Timestamp.fromCurrentTime());\n        createTopLevelDomain(null, domain, adminUsers, null, \"System Setup\");\n\n        // now create required subdomains in sys top level domain\n\n        domain = new Domain().setName(\"sys.auth\").setDescription(\"he Athenz domain\")\n                .setId(UUID.fromCurrentTime()).setModified(Timestamp.fromCurrentTime());\n        createSubDomain(null, domain, adminUsers, null, \"System Setup\", caller);\n\n        domain = new Domain().setName(\"sys.auth.audit\").setDescription(\"The Athenz audit domain\")\n                .setId(UUID.fromCurrentTime()).setModified(Timestamp.fromCurrentTime());\n        createSubDomain(null, domain, adminUsers, null, \"System Setup\", caller);\n\n        domain = new Domain().setName(\"sys.auth.audit.org\").setDescription(\"The Athenz audit domain based on org name\")\n                .setId(UUID.fromCurrentTime()).setModified(Timestamp.fromCurrentTime());\n        createSubDomain(null, domain, adminUsers, null, \"System Setup\", caller);\n\n        domain = new Domain().setName(\"sys.auth.audit.domain\").setDescription(\"The Athenz audit domain based on domain name\")\n                .setId(UUID.fromCurrentTime()).setModified(Timestamp.fromCurrentTime());\n        createSubDomain(null, domain, adminUsers, null, \"System Setup\", caller);\n\n        if (privateKey != null) {\n            List<PublicKeyEntry> pubKeys = new ArrayList<>();\n            final String publicKey = Crypto.convertToPEMFormat(Crypto.extractPublicKey(privateKey.getKey()));\n            pubKeys.add(new PublicKeyEntry().setId(privateKey.getId()).setKey(Crypto.ybase64EncodeString(publicKey)));\n            ServiceIdentity id = new ServiceIdentity().setName(\"sys.auth.zms\").setPublicKeys(pubKeys);\n            dbService.executePutServiceIdentity(null, SYS_AUTH, ZMSConsts.ZMS_SERVICE, id, null, caller);\n        } else {\n            if (LOG.isWarnEnabled()) {\n                LOG.warn(\"init: Warning: no public key, cannot register sys.auth.zms identity\");\n            }\n        }\n    }\n\n    /**\n     * @return the ZMS Schema object, describing its API and types.\n     */\n    public Schema schema() {\n        return schema;\n    }\n\n    public DomainList getDomainList(ResourceContext ctx, Integer limit, String skip, String prefix,\n            Integer depth, String account, Integer productId, String roleMember, String roleName,\n            String modifiedSince) {\n\n        final String caller = \"getdomainlist\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        metric.increment(ZMSConsts.HTTP_REQUEST);\n        metric.increment(caller);\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        Object timerMetric = metric.startTiming(\"getdomainlist_timing\", null, principalDomain);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"getDomainList: limit: \" + limit + \" skip: \" + skip\n                    + \" prefix: \" + prefix + \" depth: \" + depth + \" modifiedSince: \" + modifiedSince);\n        }\n        \n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        if (skip != null) {\n            skip = skip.toLowerCase();\n        }\n        if (prefix != null) {\n            prefix = prefix.toLowerCase();\n        }\n        if (roleMember != null) {\n            roleMember = roleMember.toLowerCase();\n            validate(roleMember, TYPE_ENTITY_NAME, caller);\n        }\n        if (roleName != null) {\n            roleName = roleName.toLowerCase();\n            validate(roleName, TYPE_ENTITY_NAME, caller);\n        }\n        if (limit != null && limit <= 0) {\n            throw ZMSUtils.requestError(\"getDomainList: limit must be positive: \" + limit, caller);\n        }\n        \n        long modTime = 0;\n        if (modifiedSince != null && !modifiedSince.isEmpty()) {\n            // we only support RFC1123 format for if-modified-since format\n            \n            SimpleDateFormat dateFmt = new SimpleDateFormat(ZMSConsts.HTTP_RFC1123_DATE_FORMAT);\n            dateFmt.setTimeZone(TimeZone.getTimeZone(ZMSConsts.HTTP_DATE_GMT_ZONE));\n            try {\n                Date date = dateFmt.parse(modifiedSince);\n                modTime = date.getTime();\n            } catch (ParseException ex) {\n                throw ZMSUtils.requestError(\"getDomainList: If-Modified-Since header value must be valid RFC1123 date\"\n                        + ex.getMessage(), caller);\n            }\n        }\n        \n        // if we have account specified then we're going to ignore all\n        // other fields since there should only be one domain that\n        // matches the specified account. Otherwise, we're going to do\n        // the same thing for product id since there should also be one\n        // domain with that id. If neither one is present, then we'll\n        // do our regular domain list\n        \n        DomainList dlist;\n        if (account != null && !account.isEmpty()) {\n            dlist = dbService.lookupDomainByAccount(account);\n        } else if (productId != null && productId != 0) {\n            dlist = dbService.lookupDomainByProductId(productId);\n        } else if (roleMember != null || roleName != null) {\n            dlist = dbService.lookupDomainByRole(normalizeDomainAliasUser(roleMember), roleName);\n        } else {\n            dlist = listDomains(limit, skip, prefix, depth, modTime);\n        }\n        \n        metric.stopTiming(timerMetric, null, principalDomain);\n        return dlist;\n    }\n\n    public Domain getDomain(ResourceContext ctx, String domainName) {\n        \n        final String caller = \"getdomain\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n\n        Object timerMetric = metric.startTiming(\"getdomain_timing\", domainName, principalDomain);\n        \n        Domain domain = dbService.getDomain(domainName, false);\n        if (domain == null) {\n            throw ZMSUtils.notFoundError(\"getDomain: Domain not found: \" + domainName, caller);\n        }\n\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n        return domain;\n    }\n\n    public Domain postTopLevelDomain(ResourceContext ctx, String auditRef, TopLevelDomain detail) {\n        \n        final String caller = \"posttopleveldomain\";\n        metric.increment(ZMSConsts.HTTP_POST);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n        \n        validateRequest(ctx.request(), caller);\n\n        validate(detail, TYPE_TOP_LEVEL_DOMAIN, caller);\n        \n        String domainName = detail.getName();\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n\n        domainName = domainName.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"posttopleveldomain_timing\", domainName, principalDomain);\n        \n        if (domainName.indexOf('_') != -1 && !isSysAdminUser(((RsrcCtxWrapper) ctx).principal())) {\n            throw ZMSUtils.requestError(\"Domain name cannot contain underscores\", caller);\n        }\n        \n        // verify length of domain name\n        \n        if (domainName.length() > domainNameMaxLen) {\n            throw ZMSUtils.requestError(\"Invalid Domain name: \" + domainName\n                    + \" : name length cannot exceed: \" + domainNameMaxLen, caller);\n        }\n\n        // verify that request is properly authenticated for this request\n        \n        Principal principal = ((RsrcCtxWrapper) ctx).principal();\n        verifyAuthorizedServiceOperation(principal.getAuthorizedService(), caller);\n        \n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        AthenzObject.TOP_LEVEL_DOMAIN.convertToLowerCase(detail);\n        \n        List<String> solutionTemplates = null;\n        DomainTemplateList templates = detail.getTemplates();\n        if (templates != null) {\n            solutionTemplates = templates.getTemplateNames();\n            validateSolutionTemplates(solutionTemplates, caller);\n        }\n        \n        // check to see if we need to validate our product id for the top\n        // level domains. The server code assumes that product id with\n        // 0 indicates no enforcement\n        \n        int productId = 0;\n        if (productIdSupport) {\n            if (detail.getYpmId() != null) {\n                if ((productId = detail.getYpmId()) <= 0) {\n                    throw ZMSUtils.requestError(\"Product Id must be a positive integer\", caller);\n                }\n            } else {\n                throw ZMSUtils.requestError(\"Product Id is required when creating top level domain\", caller);\n            }\n        }\n\n        Domain topLevelDomain = new Domain()\n                .setName(domainName)\n                .setAuditEnabled(detail.getAuditEnabled())\n                .setDescription(detail.getDescription())\n                .setOrg(detail.getOrg())\n                .setId(UUID.fromCurrentTime())\n                .setAccount(detail.getAccount())\n                .setYpmId(productId)\n                .setModified(Timestamp.fromCurrentTime())\n                .setApplicationId(detail.getApplicationId())\n                .setMemberExpiryDays(detail.getMemberExpiryDays())\n                .setServiceExpiryDays(detail.getServiceExpiryDays())\n                .setTokenExpiryMins(detail.getTokenExpiryMins())\n                .setServiceCertExpiryMins(detail.getServiceCertExpiryMins())\n                .setRoleCertExpiryMins(detail.getRoleCertExpiryMins())\n                .setSignAlgorithm(detail.getSignAlgorithm());\n\n        List<String> adminUsers = normalizedAdminUsers(detail.getAdminUsers());\n        Domain domain = createTopLevelDomain(ctx, topLevelDomain, adminUsers, solutionTemplates, auditRef);\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n        return domain;\n    }\n    \n    public void deleteTopLevelDomain(ResourceContext ctx, String domainName, String auditRef) {\n        \n        final String caller = \"deletetopleveldomain\";\n        metric.increment(ZMSConsts.HTTP_DELETE);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n\n        domainName = domainName.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"deletetopleveldomain_timing\", domainName, principalDomain);\n        \n        // verify that request is properly authenticated for this request\n        \n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(), caller);\n        \n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        deleteDomain(ctx, auditRef, domainName, caller);\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n    }\n\n    void deleteDomain(ResourceContext ctx, String auditRef, String domainName, String caller) {\n\n        // make sure we're not deleting any of the reserved system domain\n\n        if (reservedSystemDomains.contains(domainName)) {\n            throw ZMSUtils.requestError(\"Cannot delete reserved system domain\", caller);\n        }\n\n        DomainList subDomainList = listDomains(null, null, domainName + \".\", null, 0);\n        if (subDomainList.getNames().size() > 0) {\n            throw ZMSUtils.requestError(caller + \": Cannot delete domain \" +\n                    domainName + \": \" + subDomainList.getNames().size() + \" subdomains of it exist\", caller);\n        }\n\n        dbService.executeDeleteDomain(ctx, domainName, auditRef, caller);\n    }\n    \n    boolean isVirtualDomain(String domain) {\n\n        // all virtual domains start with our user domain\n        \n        return domain.startsWith(homeDomainPrefix);\n    }\n    \n    boolean hasExceededVirtualSubDomainLimit(String domain) {\n        \n        // we need to find our username which is our second\n        // component in the domain name - e.g. user.joe[.subdomain]\n        // when counting we need to make to include the trailing .\n        // since we're counting subdomains and we need to make sure\n        // not to match other users who have the same prefix\n        \n        String userDomainCheck;\n        int idx = domain.indexOf('.', homeDomainPrefix.length());\n        if (idx == -1) {\n            userDomainCheck = domain + \".\";\n        } else {\n            userDomainCheck = domain.substring(0, idx + 1);\n        }\n        \n        // retrieve the number of domains with this prefix\n        \n        DomainList dlist = listDomains(null, null, userDomainCheck, null, 0);\n        if (dlist.getNames().size() < virtualDomainLimit) {\n            return false;\n        }\n        \n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"hasExceededVirtualSubDomainLimit: subdomains with prefix \" + userDomainCheck\n                    + \": \" + dlist.getNames().size() + \" while limit is: \" + virtualDomainLimit);\n        }\n        \n        return true;\n    }\n    \n    public Domain postUserDomain(ResourceContext ctx, String name, String auditRef, UserDomain detail) {\n\n        final String caller = \"postuserdomain\";\n        metric.increment(ZMSConsts.HTTP_POST);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n        validate(detail, TYPE_USER_DOMAIN, caller);\n        validate(name, TYPE_SIMPLE_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        name = name.toLowerCase();\n        AthenzObject.USER_DOMAIN.convertToLowerCase(detail);\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, name, principalDomain);\n        metric.increment(caller, name, principalDomain);\n        Object timerMetric = metric.startTiming(\"postuserdomain_timing\", name, principalDomain);\n        \n        if (detail.getName().indexOf('_') != -1 && !isSysAdminUser(((RsrcCtxWrapper) ctx).principal())) {\n            throw ZMSUtils.requestError(\"Domain name cannot contain underscores\", caller);\n        }\n        \n        // verify that request is properly authenticated for this request\n        \n        Principal principal = ((RsrcCtxWrapper) ctx).principal();\n        verifyAuthorizedServiceOperation(principal.getAuthorizedService(), caller);\n        \n        if (!name.equals(detail.getName())) {\n            throw ZMSUtils.forbiddenError(\"postUserDomain: Request and detail domain names do not match\", caller);\n        }\n\n        // we're dealing with user's top level domain so the parent is going\n        // to be the home domain and the admin of the domain is the user\n\n        List<String> adminUsers = new ArrayList<>();\n        adminUsers.add(userDomainPrefix + principal.getName());\n        \n        List<String> solutionTemplates = null;\n        DomainTemplateList templates = detail.getTemplates();\n        if (templates != null) {\n            solutionTemplates = templates.getTemplateNames();\n            validateSolutionTemplates(solutionTemplates, caller);\n        }\n\n        Domain subDomain = new Domain()\n                .setName(homeDomain + \".\" + getUserDomainName(detail.getName()))\n                .setAuditEnabled(detail.getAuditEnabled())\n                .setDescription(detail.getDescription())\n                .setOrg(detail.getOrg())\n                .setId(UUID.fromCurrentTime())\n                .setAccount(detail.getAccount())\n                .setModified(Timestamp.fromCurrentTime())\n                .setApplicationId(detail.getApplicationId())\n                .setMemberExpiryDays(detail.getMemberExpiryDays())\n                .setServiceExpiryDays(detail.getServiceExpiryDays())\n                .setTokenExpiryMins(detail.getTokenExpiryMins())\n                .setServiceCertExpiryMins(detail.getServiceCertExpiryMins())\n                .setRoleCertExpiryMins(detail.getRoleCertExpiryMins())\n                .setSignAlgorithm(detail.getSignAlgorithm());\n\n        Domain domain = createSubDomain(ctx, subDomain, adminUsers, solutionTemplates, auditRef, caller);\n        metric.stopTiming(timerMetric, name, principalDomain);\n        return domain;\n    }\n    \n    public Domain postSubDomain(ResourceContext ctx, String parent, String auditRef, SubDomain detail) {\n\n        final String caller = \"postsubdomain\";\n        metric.increment(ZMSConsts.HTTP_POST);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n        \n        validateRequest(ctx.request(), caller);\n        validate(detail, TYPE_SUB_DOMAIN, caller);\n        validate(parent, TYPE_DOMAIN_NAME, caller);\n        validate(detail.getName(), TYPE_SIMPLE_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        parent = parent.toLowerCase();\n        AthenzObject.SUB_DOMAIN.convertToLowerCase(detail);\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, parent, principalDomain);\n        metric.increment(caller, parent, principalDomain);\n        Object timerMetric = metric.startTiming(\"postsubdomain_timing\", parent, principalDomain);\n        \n        if (detail.getName().indexOf('_') != -1 && !isSysAdminUser(((RsrcCtxWrapper) ctx).principal())) {\n            throw ZMSUtils.requestError(\"Domain name cannot contain underscores\", caller);\n        }\n        \n        // verify that request is properly authenticated for this request\n        \n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(), caller);\n        \n        if (!parent.equals(detail.getParent())) {\n            throw ZMSUtils.forbiddenError(\"postSubDomain: Request and detail parent domains do not match\", caller);\n        }\n\n        // if we're dealing with virtual/home domains (in the user's own namespace)\n        // and we don't have unlimited support for virtual domains then we need to\n        // make sure we don't exceed our configured number of virtual subdomains \n        // allowed per user\n\n        if (virtualDomainLimit != 0 && isVirtualDomain(parent) && hasExceededVirtualSubDomainLimit(parent)) {\n            throw ZMSUtils.forbiddenError(\"postSubDomain: Exceeding the configured number of virtual subdomains\", caller);\n        }\n\n        List<String> solutionTemplates = null;\n        DomainTemplateList templates = detail.getTemplates();\n        if (templates != null) {\n            solutionTemplates = templates.getTemplateNames();\n            validateSolutionTemplates(solutionTemplates, caller);\n        }\n        \n        // while it's not required for sub domains to have product ids\n        // we're going to store it in case there is a requirement to\n        // generate reports based on product ids even for subdomains\n        // unlike top level domains, passing 0 is ok here as it indicates\n        // that there is no product id\n        \n        int productId = 0;\n        if (productIdSupport) {\n            if (detail.getYpmId() != null) {\n                if ((productId = detail.getYpmId()) < 0) {\n                    throw ZMSUtils.requestError(\"Product Id must be a positive integer\", caller);\n                }\n            }\n        }\n        \n        List<String> adminUsers = normalizedAdminUsers(detail.getAdminUsers());\n\n        // inherit audit_enabled flag and organization from parent domain\n\n        AthenzDomain parentDomain = getAthenzDomain(parent, false);\n        if (parentDomain != null && parentDomain.getDomain() != null) {\n            detail.setAuditEnabled(parentDomain.getDomain().getAuditEnabled());\n            detail.setOrg(parentDomain.getDomain().getOrg());\n        }\n\n        Domain subDomain = new Domain()\n                .setName(detail.getParent() + \".\" + detail.getName())\n                .setAuditEnabled(detail.getAuditEnabled())\n                .setDescription(detail.getDescription())\n                .setOrg(detail.getOrg())\n                .setId(UUID.fromCurrentTime())\n                .setYpmId(productId)\n                .setAccount(detail.getAccount())\n                .setModified(Timestamp.fromCurrentTime())\n                .setApplicationId(detail.getApplicationId())\n                .setMemberExpiryDays(detail.getMemberExpiryDays())\n                .setServiceExpiryDays(detail.getServiceExpiryDays())\n                .setTokenExpiryMins(detail.getTokenExpiryMins())\n                .setServiceCertExpiryMins(detail.getServiceCertExpiryMins())\n                .setRoleCertExpiryMins(detail.getRoleCertExpiryMins())\n                .setSignAlgorithm(detail.getSignAlgorithm());\n\n        Domain domain = createSubDomain(ctx, subDomain, adminUsers, solutionTemplates, auditRef, caller);\n        metric.stopTiming(timerMetric, parent, principalDomain);\n        return domain;\n    }\n\n    boolean isSysAdminUser(Principal principal) {\n        \n        // verify we're dealing with system administrator\n        // authorize (\"CREATE\", \"sys.auth:domain\");\n\n        // first check - the domain must be the user domain\n        \n        if (!principal.getDomain().equals(userDomain)) {\n            return false;\n        }\n        \n        AthenzDomain domain = getAthenzDomain(SYS_AUTH, true);\n        \n        // evaluate our domain's roles and policies to see if access\n        // is allowed or not for the given operation and resource\n        // our action are always converted to lowercase\n        \n        String resource = SYS_AUTH + \":domain\";\n        AccessStatus accessStatus = evaluateAccess(domain, principal.getFullName(), \"create\",\n                resource, null, null);\n\n        return accessStatus == AccessStatus.ALLOWED;\n    }\n\n    boolean isAllowedResourceLookForAllUsers(Principal principal) {\n        \n        // the authorization policy resides in official sys.auth domain\n\n        AthenzDomain domain = getAthenzDomain(SYS_AUTH, true);\n        \n        // evaluate our domain's roles and policies to see if access\n        // is allowed or not for the given operation and resource\n        // our action are always converted to lowercase\n\n        String resource = SYS_AUTH + \":resource-lookup-all\";\n        AccessStatus accessStatus = evaluateAccess(domain, principal.getFullName(), \"access\",\n                resource, null, null);\n\n        return accessStatus == AccessStatus.ALLOWED;\n    }\n\n    boolean isAllowedSystemMetaDelete(Principal principal, final String reqDomain,\n            final String attribute) {\n\n        // the authorization policy resides in official sys.auth domain\n\n        AthenzDomain domain = getAthenzDomain(SYS_AUTH, true);\n\n        // evaluate our domain's roles and policies to see if access\n        // is allowed or not for the given operation and resource\n        // our action are always converted to lowercase\n\n        String resource = SYS_AUTH + \":meta.\" + attribute + \".\" + reqDomain;\n        AccessStatus accessStatus = evaluateAccess(domain, principal.getFullName(), \"delete\",\n                resource, null, null);\n\n        return accessStatus == AccessStatus.ALLOWED;\n    }\n\n    public void deleteSubDomain(ResourceContext ctx, String parent, String name, String auditRef) {\n\n        final String caller = \"deletesubdomain\";\n        metric.increment(ZMSConsts.HTTP_DELETE);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        parent = parent.toLowerCase();\n        name = name.toLowerCase();\n        String domainName = parent + \".\" + name;\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, parent, principalDomain);\n        metric.increment(caller, parent, principalDomain);\n        Object timerMetric = metric.startTiming(\"deletesubdomain_timing\", parent, principalDomain);\n\n        validate(parent, TYPE_DOMAIN_NAME, caller);\n        validate(name, TYPE_SIMPLE_NAME, caller);\n\n        // verify that request is properly authenticated for this request\n        \n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(), caller);\n        \n        deleteDomain(ctx, auditRef, domainName, caller);\n        metric.stopTiming(timerMetric, parent, principalDomain);\n    }\n\n    public void deleteUserDomain(ResourceContext ctx, String name, String auditRef) {\n\n        final String caller = \"deleteuserdomain\";\n        metric.increment(ZMSConsts.HTTP_DELETE);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        validate(name, TYPE_SIMPLE_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        name = name.toLowerCase();\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, name, principalDomain);\n        metric.increment(caller, name, principalDomain);\n        Object timerMetric = metric.startTiming(\"deleteuserdomain_timing\", name, principalDomain);\n        \n        // verify that request is properly authenticated for this request\n        \n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(), caller);\n        \n        String domainName = homeDomainPrefix + name;\n        deleteDomain(ctx, auditRef, domainName, caller);\n        metric.stopTiming(timerMetric, name, principalDomain);\n    }\n    \n    public UserList getUserList(ResourceContext ctx) {\n        \n        final String caller = \"getuserlist\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n\n        metric.increment(ZMSConsts.HTTP_REQUEST);\n        metric.increment(caller);\n        final String principalDomain = getPrincipalDomain(ctx);\n        Object timerMetric = metric.startTiming(\"getuserlist_timing\", null, principalDomain);\n        \n        List<String> names = dbService.listPrincipals(userDomain, true);\n        UserList result = new UserList().setNames(names);\n\n        metric.stopTiming(timerMetric, null, principalDomain);\n        return result;\n    }\n\n    @Override\n    public void deleteDomainRoleMember(ResourceContext ctx, String domainName, String memberName, String auditRef) {\n\n        final String caller = \"deletedomainrolemember\";\n        metric.increment(ZMSConsts.HTTP_DELETE);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        validate(memberName, TYPE_MEMBER_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n\n        domainName = domainName.toLowerCase();\n        memberName = memberName.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"deletedomainrolemember_timing\", domainName, principalDomain);\n\n        // verify that request is properly authenticated for this request\n\n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(), caller);\n\n        dbService.executeDeleteDomainRoleMember(ctx, domainName, memberName, auditRef, caller);\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n    }\n\n    @Override\n    public void deleteUser(ResourceContext ctx, String name, String auditRef) {\n        \n        final String caller = \"deleteuser\";\n        metric.increment(ZMSConsts.HTTP_DELETE);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        validate(name, TYPE_SIMPLE_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        name = name.toLowerCase();\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, userDomain, principalDomain);\n        metric.increment(caller, userDomain, principalDomain);\n        Object timerMetric = metric.startTiming(\"deleteuser_timing\", name, principalDomain);\n        \n        // verify that request is properly authenticated for this request\n        \n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(), caller);\n        \n        String userName = userDomainPrefix + name;\n        String domainName = homeDomainPrefix + getUserDomainName(name);\n        dbService.executeDeleteUser(ctx, userName, domainName, auditRef, caller);\n        metric.stopTiming(timerMetric, name, principalDomain);\n    }\n    \n    String getUserDomainName(String userName) {\n        return (userAuthority == null) ? userName : userAuthority.getUserDomainName(userName);\n    }\n    \n    void validateString(final String value, final String type, final String caller) {\n        if (value != null && !value.isEmpty()) {\n            validate(value, type, caller);\n        }\n    }\n\n    @Override\n    public void putDomainMeta(ResourceContext ctx, String domainName, String auditRef,\n            DomainMeta meta) {\n\n        final String caller = \"putdomainmeta\";\n        metric.increment(ZMSConsts.HTTP_PUT);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        validate(meta, TYPE_DOMAIN_META, caller);\n        validateString(meta.getApplicationId(), TYPE_COMPOUND_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        AthenzObject.DOMAIN_META.convertToLowerCase(meta);\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"putdomainmeta_timing\", domainName, principalDomain);\n        \n        // verify that request is properly authenticated for this request\n        \n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(),\n                caller);\n\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"putDomainMeta: name={}, meta={}\", domainName, meta);\n        }\n\n        // process put domain meta request\n\n        dbService.executePutDomainMeta(ctx, domainName, meta, null, false, auditRef, caller);\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n    }\n\n    @Override\n    public void putDomainSystemMeta(ResourceContext ctx, String domainName, String attribute,\n            String auditRef, DomainMeta meta) {\n\n        final String caller = \"putdomainsystemmeta\";\n        metric.increment(ZMSConsts.HTTP_PUT);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        validate(meta, TYPE_DOMAIN_META, caller);\n        validate(attribute, TYPE_SIMPLE_NAME, caller);\n        validateString(meta.getAccount(), TYPE_COMPOUND_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n\n        domainName = domainName.toLowerCase();\n        attribute = attribute.toLowerCase();\n        AthenzObject.DOMAIN_META.convertToLowerCase(meta);\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"putdomainsystemmeta_timing\", domainName, principalDomain);\n\n        // verify that request is properly authenticated for this request\n\n        Principal principal = ((RsrcCtxWrapper) ctx).principal();\n        verifyAuthorizedServiceOperation(principal.getAuthorizedService(), caller);\n\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"putDomainSystemMeta: name={}, attribute={}, meta={}\",\n                    domainName, attribute, meta);\n        }\n\n        // if we are resetting the configured value then the caller\n        // must also have a delete action available for the same resource\n\n        boolean deleteAllowed = isAllowedSystemMetaDelete(principal, domainName, attribute);\n\n        // if this productId is already used by any domain it will be\n        // seen in dbService and exception thrown but we want to make\n        // sure here if product id support is required then we must\n        // have one specified for a top level domain.\n\n        if (productIdSupport && meta.getYpmId() == null && domainName.indexOf('.') == -1 &&\n                ZMSConsts.SYSTEM_META_PRODUCT_ID.equals(attribute)) {\n             throw ZMSUtils.requestError(\"Unique Product Id must be specified for top level domain\", caller);\n        }\n\n        dbService.executePutDomainMeta(ctx, domainName, meta, attribute, deleteAllowed, auditRef, caller);\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n    }\n\n    void validateSolutionTemplates(List<String> templateNames, String caller) {\n        for (String templateName : templateNames) {\n            if (!serverSolutionTemplates.contains(templateName)) {\n                throw ZMSUtils.notFoundError(\"validateSolutionTemplates: Template not found: \"\n                        + templateName, caller);\n            }\n        }\n    }\n    \n    public DomainTemplateList getDomainTemplateList(ResourceContext ctx, String domainName) {\n\n        final String caller = \"getdomaintemplatelist\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"getdomaintemplatelist_timing\", domainName, principalDomain);\n        \n        DomainTemplateList domainTemplateList = dbService.listDomainTemplates(domainName);\n        if (domainTemplateList == null) {\n            throw ZMSUtils.notFoundError(\"getDomainTemplateList: Domain not found: '\" + domainName + \"'\", caller);\n        }\n\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n        return domainTemplateList;\n    }\n\n    @Override\n    public void putDomainTemplate(ResourceContext ctx, String domainName, String auditRef,\n            DomainTemplate domainTemplate) {\n\n        final String caller = \"putdomaintemplate\";\n        metric.increment(ZMSConsts.HTTP_PUT);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        validate(domainTemplate, TYPE_DOMAIN_TEMPLATE, caller);\n        \n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        AthenzObject.DOMAIN_TEMPLATE.convertToLowerCase(domainTemplate);\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"putdomaintemplate_timing\", domainName, principalDomain);\n        \n        // verify that all template names are valid\n        \n        List<String> templateNames = domainTemplate.getTemplateNames();\n        if (templateNames == null || templateNames.size() == 0) {\n            throw ZMSUtils.requestError(\"putDomainTemplate: No templates specified\", caller);\n        }\n        validateSolutionTemplates(templateNames, caller);\n        \n        // verify that request is properly authenticated for this request\n        // Make sure each template name is verified\n        \n        for (String templateName : domainTemplate.getTemplateNames()) {\n            verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(),\n                    caller, \"name\", templateName);\n        }\n\n        dbService.executePutDomainTemplate(ctx, domainName, domainTemplate, auditRef, caller);\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n    }\n\n    @Override\n    public void putDomainTemplateExt(ResourceContext ctx, String domainName,\n            String templateName, String auditRef, DomainTemplate domainTemplate) {\n\n        final String caller = \"putdomaintemplateext\";\n        metric.increment(ZMSConsts.HTTP_PUT);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        validate(templateName, TYPE_SIMPLE_NAME, caller);\n        validate(domainTemplate, TYPE_DOMAIN_TEMPLATE, caller);\n        \n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        templateName = templateName.toLowerCase();\n        AthenzObject.DOMAIN_TEMPLATE.convertToLowerCase(domainTemplate);\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"putdomaintemplateext_timing\", domainName, principalDomain);\n        \n        // verify that all template names are valid\n        \n        List<String> templateNames = domainTemplate.getTemplateNames();\n        if (templateNames == null) {\n            throw ZMSUtils.requestError(\"putDomainTemplateExt: No templates specified\", caller);\n        }\n        \n        // the template name in the object must match to the uri\n        \n        if (!(templateNames.size() == 1 && templateNames.get(0).equals(templateName))) {\n            throw ZMSUtils.requestError(\"putDomainTemplateExt: template name mismatch\", caller);\n        }\n        validateSolutionTemplates(templateNames, caller);\n        \n        // verify that request is properly authenticated for this request\n        // Make sure each template name is verified\n        \n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(),\n                caller, \"name\", templateName);\n\n        dbService.executePutDomainTemplate(ctx, domainName, domainTemplate, auditRef, caller);\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n    }\n    \n    public void deleteDomainTemplate(ResourceContext ctx, String domainName, String templateName, String auditRef) {\n\n        final String caller = \"deletedomaintemplate\";\n        metric.increment(ZMSConsts.HTTP_DELETE);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n        \n        validateRequest(ctx.request(), caller);\n\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        validate(templateName, TYPE_SIMPLE_NAME, caller);\n        \n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n\n        domainName = domainName.toLowerCase();\n        templateName = templateName.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"deletedomaintemplate_timing\", domainName, principalDomain);\n        \n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"deleteDomainTemplate: domain=\" + domainName + \", template=\" + templateName);\n        }\n        \n        // verify that request is properly authenticated for this request\n\n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(),\n                caller, \"name\", templateName);\n\n        List<String> templateNames = new ArrayList<>();\n        templateNames.add(templateName);\n        validateSolutionTemplates(templateNames, caller);\n\n        dbService.executeDeleteDomainTemplate(ctx, domainName, templateName, auditRef, caller);\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n    }\n    \n    Principal createPrincipalForName(String principalName) {\n        \n        String domain;\n        String name;\n        \n        // if we have no . in the principal name we're going to default\n        // to our configured user domain\n        \n        int idx = principalName.lastIndexOf('.');\n        if (idx == -1) {\n            domain = userDomain;\n            name = principalName;\n        } else {\n            domain = principalName.substring(0, idx);\n            if (userDomainAlias != null && userDomainAlias.equals(domain)) {\n                domain = userDomain;\n            }\n            name = principalName.substring(idx + 1);\n        }\n        \n        return SimplePrincipal.create(domain, name, (String) null);\n    }\n    \n    boolean validRoleTokenAccess(String trustDomain, String domainName, String principalName) {\n        \n        if (trustDomain != null) {\n            if (LOG.isWarnEnabled()) {\n                LOG.warn(\"validRoleTokenAccess: Cannot access cross-domain resources with RoleToken\");\n            }\n            return false;\n        }\n        \n        // for Role tokens we don't have a name component in the principal\n        // so the principal name should be the same as the domain value \n        // thus it must match the domain name from the resource\n        \n        if (!domainName.equalsIgnoreCase(principalName)) {\n            if (LOG.isWarnEnabled()) {\n                LOG.warn(\"validRoleTokenAccess: resource domain does not match RoleToken domain\");\n            }\n            return false;\n        }\n        \n        return true;\n    }\n\n    AthenzDomain getAthenzDomain(String domainName, boolean ignoreExceptions) {\n        return getAthenzDomain(domainName, ignoreExceptions, false);\n    }\n    \n    AthenzDomain getAthenzDomain(String domainName, boolean ignoreExceptions, boolean masterCopy) {\n        \n        AthenzDomain domain = null;\n        try {\n            domain = dbService.getAthenzDomain(domainName, masterCopy);\n        } catch (ResourceException ex) {\n            \n            if (LOG.isDebugEnabled()) {\n                LOG.debug(\"getAthenzDomain failure: \" + ex.getMessage());\n            }\n            \n            if (!ignoreExceptions) {\n                if (ex.getCode() != ResourceException.NOT_FOUND) {\n                    throw ex;\n                }\n            }\n        }\n        return domain;\n    }\n    \n    AthenzDomain retrieveAccessDomain(String domainName, Principal principal) {\n        \n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"retrieveAccessDomain: identity: {} domain: {}\", principal.getFullName(), domainName);\n        }\n        \n        AthenzDomain domain = getAthenzDomain(domainName, false);\n        if (domain != null) {\n            return domain;\n        }\n        \n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"retrieveAccessDomain: domain not found, looking for virtual domain\");\n        }\n        \n        // if we don't have virtual/home domains enabled then no need\n        // to continue further\n        \n        if (!virtualDomainSupport) {\n            return null;\n        }\n        \n        if (principal.getDomain() == null) {\n            return null;\n        }\n        \n        // the principals user name must match to the corresponding\n        // home domain name for the user\n        \n        if (!principal.getDomain().equals(userDomain)) {\n            return null;\n        }\n        \n        final String userHomeDomain = homeDomainPrefix + getUserDomainName(principal.getName());\n        if (!userHomeDomain.equals(domainName)) {\n            return null;\n        }\n        \n        return virtualHomeDomain(principal, domainName);\n    }\n\n    AccessStatus evaluateAccess(AthenzDomain domain, String identity, String action, String resource,\n            List<String> authenticatedRoles, String trustDomain) {\n        \n        AccessStatus accessStatus = AccessStatus.DENIED;\n\n        List<Policy> policies = domain.getPolicies();\n        List<Role> roles = domain.getRoles();\n        \n        for (Policy policy : policies) {\n            \n            if (LOG.isDebugEnabled()) {\n                LOG.debug(\"evaluateAccess: processing policy: {}\", policy.getName());\n            }\n            \n            // we are going to process all the assertions defined in this\n            // policy. As soon as we get a match for an assertion that\n            // denies access, we're going to return that result. If we\n            // get a match for an assertion that allows access we're\n            // going to remember that result and continue looking at\n            // all the assertions in case there is something else that\n            // explicitly denies access\n            \n            List<Assertion> assertions = policy.getAssertions();\n            if (assertions == null) {\n                continue;\n            }\n            \n            for (Assertion assertion : assertions) {\n                \n                // get the effect for the assertion which is set\n                // as allowed by default\n\n                AssertionEffect effect = assertion.getEffect();\n                if (effect == null) {\n                    effect = AssertionEffect.ALLOW;\n                }\n\n                // if we have already matched an allow assertion then\n                // we'll automatically skip any assertion that has\n                // allow effect since there is no point of matching it\n                \n                if (accessStatus == AccessStatus.ALLOWED && effect == AssertionEffect.ALLOW) {\n                    continue;\n                }\n                \n                // if no match then process the next assertion\n                \n                if (!assertionMatch(assertion, identity, action, resource, domain.getName(),\n                        roles, authenticatedRoles, trustDomain)) {\n                    continue;\n                }\n                \n                // if the assertion has matched and the effect is deny\n                // then we're going to return right away otherwise we'll\n                // set our return allow matched flag to true and continue\n                // processing other assertions\n                \n                if (effect == AssertionEffect.DENY) {\n                    return AccessStatus.DENIED;\n                }\n                \n                accessStatus = AccessStatus.ALLOWED;\n            }\n        }\n        \n        return accessStatus;\n    }\n    \n    String userHomeDomainResource(String resource) {\n        \n        // if the resource does not start with user domain prefix then\n        // we have nothing to do and we'll return resource as is\n        \n        if (!resource.startsWith(ZMSConsts.USER_DOMAIN_PREFIX)) {\n            return resource;\n        }\n        \n        String homeResource = null;\n        \n        // if we have different userDomain and homeDomain values then\n        // we need to replace both domain and user names otherwise\n        // we only need to update the domain value\n        \n        if (!userDomain.equals(homeDomain)) {\n            \n            // let's extract the user name. at this point we should\n            // have the format user.<user-name>:resource\n            \n            int idx = resource.indexOf(':');\n            if (idx == -1) {\n                return resource;\n            }\n            \n            final String userName = resource.substring(ZMSConsts.USER_DOMAIN_PREFIX.length(), idx);\n            homeResource = homeDomainPrefix + getUserDomainName(userName) + resource.substring(idx);\n            \n        } else if (!homeDomain.equals(ZMSConsts.USER_DOMAIN)) {\n            homeResource = homeDomainPrefix + resource.substring(ZMSConsts.USER_DOMAIN_PREFIX.length());\n        }\n        return homeResource == null ? resource : homeResource;\n    }\n    \n    public boolean access(String action, String resource, Principal principal, String trustDomain) {\n        \n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        resource = resource.toLowerCase();\n        if (trustDomain != null) {\n            trustDomain = trustDomain.toLowerCase();\n        }\n        action = action.toLowerCase();\n        \n        // if the resource starts with the user domain and the environment is using\n        // a different domain name we'll dynamically update the resource value\n        \n        resource = userHomeDomainResource(resource);\n        \n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"access:(\" + action + \", \" + resource + \", \" + principal + \", \" + trustDomain + \")\");\n        }\n        \n        // check to see if the authority is allowed to be processed in\n        // authorization checks. If this value is false then the principal\n        // must get a usertoken from ZMS first and the submit the request\n        // with that token\n        \n        if (!authorityAuthorizationAllowed(principal)) {\n            LOG.error(\"Authority is not allowed to support authorization checks\");\n            return false;\n        }\n        \n        // retrieve our domain based on resource and action/trustDomain pair\n        // we want to provider better error reporting to the users so if we get a\n        // request where the domain is not found instead of just returning 403\n        // forbidden (which is confusing since it assumes the user doesn't have\n        // access as oppose to possible mistype of the domain name by the user)\n        // we want to return 404 not found. The athenz server common has special handling\n        // for rest.ResourceExceptions so we'll throw that exception in this\n        // special case of not found domains.\n        \n        String domainName = retrieveResourceDomain(resource, action, trustDomain);\n        if (domainName == null) {\n            throw new com.yahoo.athenz.common.server.rest.ResourceException(\n                    ResourceException.NOT_FOUND, \"Domain not found\");\n        }\n        AthenzDomain domain = retrieveAccessDomain(domainName, principal);\n        if (domain == null) {\n            throw new com.yahoo.athenz.common.server.rest.ResourceException(\n                    ResourceException.NOT_FOUND, \"Domain not found\");\n        }\n        \n        // if the domain is disabled then we're going to reject this\n        // request right away\n        \n        if (domain.getDomain().getEnabled() == Boolean.FALSE) {\n            throw new com.yahoo.athenz.common.server.rest.ResourceException(\n                    ResourceException.FORBIDDEN, \"Disabled Domain\");\n        }\n        \n        AccessStatus accessStatus = hasAccess(domain, action, resource, principal, trustDomain);\n        return accessStatus == AccessStatus.ALLOWED;\n    }\n    \n    boolean authorityAuthorizationAllowed(Principal principal) {\n        \n        Authority authority = principal.getAuthority();\n        if (authority == null) {\n            return true;\n        }\n        \n        return authority.allowAuthorization();\n    }\n    \n    String retrieveResourceDomain(String resource, String op, String trustDomain) {\n        \n        // special handling for ASSUME_ROLE assertions. Since any assertion with\n        // that action refers to a resource in another domain, there is no point\n        // to retrieve the domain name from the resource. In these cases the caller\n        // must specify the trust domain attribute so we'll use that instead and\n        // if one is not specified then we'll fall back to using the domain name\n        // from the resource\n        \n        String domainName;\n        if (ZMSConsts.ACTION_ASSUME_ROLE.equalsIgnoreCase(op) && trustDomain != null) {\n            domainName = trustDomain;\n        } else {\n            domainName = extractDomainName(resource);\n        }\n        return domainName;\n    }\n    \n    AccessStatus hasAccess(AthenzDomain domain, String action, String resource,\n            Principal principal, String trustDomain) {\n       \n        String identity = principal.getFullName();\n        \n        // if we're dealing with an access check based on a Role token then\n        // make sure it's valid before processing it\n        \n        List<String> authenticatedRoles = principal.getRoles();\n        if (authenticatedRoles != null && !validRoleTokenAccess(trustDomain, domain.getName(), identity)) {\n            return AccessStatus.DENIED_INVALID_ROLE_TOKEN;\n        }\n        \n        // evaluate our domain's roles and policies to see if access\n        // is allowed or not for the given operation and resource\n        \n        return evaluateAccess(domain, identity, action, resource, authenticatedRoles, trustDomain);\n    }\n    \n    public Access getAccessExt(ResourceContext ctx, String action, String resource,\n            String trustDomain, String checkPrincipal) {\n        \n        final String caller = \"getaccessext\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n        validate(action, TYPE_COMPOUND_NAME, caller);\n        \n        return getAccessCheck(((RsrcCtxWrapper) ctx).principal(), action, resource,\n                trustDomain, checkPrincipal);\n    }\n    \n    public Access getAccess(ResourceContext ctx, String action, String resource,\n            String trustDomain, String checkPrincipal) {\n\n        final String caller = \"getaccess\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n        validate(action, TYPE_COMPOUND_NAME, caller);\n        validate(resource, TYPE_RESOURCE_NAME, caller);\n        \n        return getAccessCheck(((RsrcCtxWrapper) ctx).principal(), action, resource,\n                trustDomain, checkPrincipal);\n    }\n    \n    Access getAccessCheck(Principal principal, String action, String resource,\n            String trustDomain, String checkPrincipal) {\n        \n        final String caller = \"getaccess\";\n\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"getAccessCheck:(\" + action + \", \" + resource + \", \" + principal +\n                    \", \" + trustDomain + \", \" + checkPrincipal + \")\");\n        }\n        \n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        action = action.toLowerCase();\n        resource = resource.toLowerCase();\n        if (checkPrincipal != null) {\n            checkPrincipal = checkPrincipal.toLowerCase();\n        }\n        if (trustDomain != null) {\n            trustDomain = trustDomain.toLowerCase();\n        }\n        \n        // retrieve the domain based on our resource and action/trustDomain pair\n        \n        String domainName = retrieveResourceDomain(resource, action, trustDomain);\n        if (domainName == null) {\n            metric.increment(ZMSConsts.HTTP_REQUEST, ZMSConsts.ZMS_INVALID_DOMAIN, principal.getDomain());\n            metric.increment(caller, ZMSConsts.ZMS_INVALID_DOMAIN, principal.getDomain());\n            throw ZMSUtils.notFoundError(\"getAccessCheck: Unable to extract resource domain\", caller);\n        }\n        AthenzDomain domain = retrieveAccessDomain(domainName, principal);\n        if (domain == null) {\n            metric.increment(ZMSConsts.HTTP_REQUEST, ZMSConsts.ZMS_UNKNOWN_DOMAIN, principal.getDomain());\n            metric.increment(caller, ZMSConsts.ZMS_UNKNOWN_DOMAIN, principal.getDomain());\n            throw ZMSUtils.notFoundError(\"getAccessCheck: Resource Domain not found: '\"\n                    + domainName + \"'\", caller);\n        }\n        \n        // if the domain is disabled then we're going to reject this\n        // request right away\n        \n        if (domain.getDomain().getEnabled() == Boolean.FALSE) {\n            throw ZMSUtils.forbiddenError(\"getAccessCheck: Disabled domain: '\"\n                    + domainName + \"'\", caller);\n        }\n\n        // start our counter with domain dimension. we're moving the metric here\n        // after the domain name has been confirmed as valid since with\n        // dimensions we get stuck with persistent indexes so we only want\n        // to create them for valid domain names\n\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principal.getDomain());\n        metric.increment(caller, domainName, principal.getDomain());\n        Object timerMetric = metric.startTiming(\"getaccess_timing\", domainName, principal.getDomain());\n\n        // if the check principal is given then we need to carry out the access\n        // check against that principal\n        \n        if (checkPrincipal != null) {\n            principal = createPrincipalForName(checkPrincipal);\n            if (principal == null) {\n                throw ZMSUtils.unauthorizedError(\"getAccessCheck: Invalid check principal value specified\", caller);\n            }\n        }\n        \n        boolean accessAllowed = false;\n        AccessStatus accessStatus = hasAccess(domain, action, resource, principal, trustDomain);\n        if (accessStatus == AccessStatus.ALLOWED) {\n            accessAllowed = true;\n        }\n        Access access = new Access().setGranted(accessAllowed);\n\n        metric.stopTiming(timerMetric, domainName, principal.getDomain());\n        return access;\n    }\n\n    void validateEntity(String entityName, Entity entity) {\n        \n        final String caller = \"validateentity\";\n        \n        if (!entityName.equals(entity.getName())) {\n            throw ZMSUtils.requestError(\"validateEntity: Entity name mismatch: \" + entityName + \" != \" + entity.getName(), caller);\n        }\n        if (entity.getValue() == null) {\n            throw ZMSUtils.requestError(\"validateEntity: Entity value is empty: \" + entityName, caller);\n        }\n    }\n\n    @Override\n    public void putEntity(ResourceContext ctx, String domainName, String entityName, String auditRef, Entity resource) {\n        \n        final String caller = \"putentity\";\n        metric.increment(ZMSConsts.HTTP_PUT);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        validate(entityName, TYPE_ENTITY_NAME, caller);\n        validateEntity(entityName, resource);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        entityName = entityName.toLowerCase();\n        AthenzObject.ENTITY.convertToLowerCase(resource);\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"putentity_timing\", domainName, principalDomain);\n\n        // verify that request is properly authenticated for this request\n        \n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(), caller);\n        \n        dbService.executePutEntity(ctx, domainName, entityName, resource, auditRef, caller);\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n    }\n\n    @Override\n    public EntityList getEntityList(ResourceContext ctx, String domainName) {\n        \n        final String caller = \"getentitylist\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"getentitylist_timing\", domainName, principalDomain);\n        \n        EntityList result = new EntityList();\n        List<String> names = dbService.listEntities(domainName);\n        result.setNames(names);\n\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n        return result;\n    }\n    \n    public Entity getEntity(ResourceContext ctx, String domainName, String entityName) {\n        \n        final String caller = \"getentity\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        validate(entityName, TYPE_ENTITY_NAME, caller);\n        \n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        entityName = entityName.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"getentity_timing\", domainName, principalDomain);\n\n        Entity entity = dbService.getEntity(domainName, entityName);\n        if (entity == null) {\n            throw ZMSUtils.notFoundError(\"getEntity: Entity not found: '\" +\n                    ZMSUtils.entityResourceName(domainName, entityName) + \"'\", caller);\n        }\n        \n        metric.stopTiming(timerMetric, domainName, principalDomain);\n        return entity;\n    }\n    \n    public void deleteEntity(ResourceContext ctx, String domainName, String entityName, String auditRef) {\n        \n        final String caller = \"deleteentity\";\n        metric.increment(ZMSConsts.HTTP_DELETE);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n        \n        validateRequest(ctx.request(), caller);\n\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        validate(entityName, TYPE_ENTITY_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        entityName = entityName.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"deleteentity_timing\", domainName, principalDomain);\n        \n        // verify that request is properly authenticated for this request\n        \n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(), caller);\n        \n        dbService.executeDeleteEntity(ctx, domainName, entityName, auditRef, caller);\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n    }\n\n    public ServerTemplateList getServerTemplateList(ResourceContext ctx) {\n        \n        final String caller = \"getservertemplatelist\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        metric.increment(ZMSConsts.HTTP_REQUEST);\n        metric.increment(caller);\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        Object timerMetric = metric.startTiming(\"getservertemplatelist_timing\", null, principalDomain);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n\n        ServerTemplateList result = new ServerTemplateList();\n        result.setTemplateNames(new ArrayList<>(serverSolutionTemplates.names()));\n\n        metric.stopTiming(timerMetric, null, principalDomain);\n        return result;\n    }\n    \n    public Template getTemplate(ResourceContext ctx, String templateName) {\n\n        final String caller = \"gettemplate\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        metric.increment(ZMSConsts.HTTP_REQUEST);\n        metric.increment(caller);\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        Object timerMetric = metric.startTiming(\"gettemplate_timing\", null, principalDomain);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n        validate(templateName, TYPE_SIMPLE_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        templateName = templateName.toLowerCase();\n        Template template = serverSolutionTemplates.get(templateName);\n        if (template == null) {\n            throw ZMSUtils.notFoundError(\"getTemplate: Template not found: '\" + templateName + \"'\", caller);\n        }\n        \n        List<Role> roles = template.getRoles();\n        if (roles != null && !roles.isEmpty()) {\n            for (Role role : roles) {\n                List<RoleMember> roleMembers = role.getRoleMembers();\n                if (roleMembers != null) {\n                    role.setMembers(ZMSUtils.convertRoleMembersToMembers(roleMembers));\n                }\n            }\n        }\n        \n        metric.stopTiming(timerMetric, null, principalDomain);\n        return template;\n    }\n\n    public RoleList getRoleList(ResourceContext ctx, String domainName, Integer limit, String skip) {\n        \n        final String caller = \"getrolelist\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        if (skip != null) {\n            skip = skip.toLowerCase();\n        }\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"getrolelist_timing\", domainName, principalDomain);\n        \n        RoleList result = new RoleList();\n        \n        List<String> names = new ArrayList<>();\n        String next = processListRequest(domainName, AthenzObject.ROLE, limit, skip, names);\n        result.setNames(names);\n        if (next != null) {\n            result.setNext(next);\n        }\n\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n        return result;\n    }\n    \n    List<Role> setupRoleList(AthenzDomain domain, Boolean members) {\n        \n        // if we're asked to return the members as well then we\n        // just need to return the data as is without any modifications\n        \n        List<Role> roles;\n        if (members == Boolean.TRUE) {\n            roles = domain.getRoles();\n        } else {\n            roles = new ArrayList<>();\n            for (Role role : domain.getRoles()) {\n                Role newRole = new Role()\n                        .setName(role.getName())\n                        .setModified(role.getModified())\n                        .setTrust(role.getTrust());\n                roles.add(newRole);\n            }\n        }\n        \n        return roles;\n    }\n    \n    public Roles getRoles(ResourceContext ctx, String domainName, Boolean members) {\n        \n        final String caller = \"getroles\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"getroles_timing\", domainName, principalDomain);\n        \n        Roles result = new Roles();\n        \n        AthenzDomain domain = getAthenzDomain(domainName, false);\n        if (domain == null) {\n            throw ZMSUtils.notFoundError(\"getRoles: Domain not found: '\" + domainName + \"'\", caller);\n        }\n\n        result.setList(setupRoleList(domain, members));\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n        return result;\n    }\n\n    @Override\n    public DomainRoleMembers getDomainRoleMembers(ResourceContext ctx, String domainName) {\n\n        final String caller = \"getdomainrolemembers\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n\n        domainName = domainName.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"getdomainrolemembers_timing\", domainName, principalDomain);\n\n        DomainRoleMembers roleMembers = dbService.listDomainRoleMembers(domainName);\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n        return roleMembers;\n    }\n\n    @Override\n    public Role getRole(ResourceContext ctx, String domainName, String roleName,\n            Boolean auditLog, Boolean expand, Boolean pending) {\n        \n        final String caller = \"getrole\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        validate(roleName, TYPE_ENTITY_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        roleName = roleName.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"getrole_timing\", domainName, principalDomain);\n        \n        Role role = dbService.getRole(domainName, roleName, auditLog, expand, pending);\n        if (role == null) {\n            throw ZMSUtils.notFoundError(\"getRole: Role not found: '\" +\n                    ZMSUtils.roleResourceName(domainName, roleName) + \"'\", caller);\n        }\n\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n        return role;\n    }\n\n    List<String> normalizedAdminUsers(List<String> admins) {\n        List<String> normalizedAdmins = new ArrayList<>();\n        for (String admin : admins) {\n            normalizedAdmins.add(normalizeDomainAliasUser(admin));\n        }\n        return normalizedAdmins;\n    }\n    \n    String normalizeDomainAliasUser(String user) {\n        if (user != null && userDomainAliasPrefix != null && user.startsWith(userDomainAliasPrefix)) {\n            if (user.indexOf('.', userDomainAliasPrefix.length()) == -1) {\n                return userDomainPrefix + user.substring(userDomainAliasPrefix.length());\n            }\n        }\n        return user;\n    }\n    \n    private void addNormalizedRoleMember(Map<String, RoleMember> normalizedMembers,\n            RoleMember member) {\n\n        member.setMemberName(normalizeDomainAliasUser(member.getMemberName()));\n\n        // we'll automatically ignore any duplicates\n        \n        if (!normalizedMembers.containsKey(member.getMemberName())) {\n            normalizedMembers.put(member.getMemberName(), member);\n        }\n    }\n    \n    void normalizeRoleMembers(Role role) {\n        \n        Map<String, RoleMember> normalizedMembers = new HashMap<>();\n        \n        // normalize getMembers() first\n        \n        List<String> members = role.getMembers();\n        if (members != null) {\n            for (String memberOld : members) {\n                RoleMember member = new RoleMember().setMemberName(memberOld);\n                addNormalizedRoleMember(normalizedMembers, member);\n            }\n        }\n        \n        // normalize getRoleMembers() now\n        \n        List<RoleMember> roleMembers = role.getRoleMembers();\n        if (roleMembers != null) {\n            for (RoleMember member : roleMembers) {\n                addNormalizedRoleMember(normalizedMembers, member);\n            }\n        }\n        role.setRoleMembers(new ArrayList<>(normalizedMembers.values()));\n        role.setMembers(null);\n    }\n    \n    boolean isConsistentRoleName(final String domainName, final String roleName, Role role) {\n        \n        String resourceName = ZMSUtils.roleResourceName(domainName, roleName);\n        \n        // first lets assume we have the expected name specified in the role\n        \n        if (resourceName.equals(role.getName())) {\n            return true;\n        }\n\n        // if not check to see if the role contains the relative local name\n        // part only instead of the expected resourceName and update accordingly\n        \n        if (roleName.equals(role.getName())) {\n            role.setName(resourceName);\n            return true;\n        }\n        \n        // we have a mismatch\n        \n        return false;\n    }\n\n    @Override\n    public void putRole(ResourceContext ctx, String domainName, String roleName, String auditRef, Role role) {\n        \n        final String caller = \"putrole\";\n        metric.increment(ZMSConsts.HTTP_PUT);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        validate(roleName, TYPE_ENTITY_NAME, caller);\n        validate(role, TYPE_ROLE, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        roleName = roleName.toLowerCase();\n        AthenzObject.ROLE.convertToLowerCase(role);\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"putrole_timing\", domainName, principalDomain);\n        \n        // verify that request is properly authenticated for this request\n        \n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(), caller);\n        \n        // verify the role name in the URI and request are consistent\n        \n        if (!isConsistentRoleName(domainName, roleName, role)) {\n            throw ZMSUtils.requestError(\"putRole: Inconsistent role names - expected: \"\n                    + ZMSUtils.roleResourceName(domainName, roleName) + \", actual: \"\n                    + role.getName(), caller);\n        }\n\n        Domain domain = dbService.getDomain(domainName, false);\n        if (domain == null) {\n            throw ZMSUtils.notFoundError(\"No such domain: \" + domainName, caller);\n        }\n\n        // validate role and trust settings are as expected\n        \n        ZMSUtils.validateRoleStructure(role, caller, domainName);\n        \n        // normalize and remove duplicate members\n        \n        normalizeRoleMembers(role);\n\n        // check to see if we need to validate user and service members\n\n        validateRoleMemberPrincipals(role, caller);\n\n        // update role expiry based on our configurations\n\n        updateRoleMemberExpiration(domain.getMemberExpiryDays(), role.getMemberExpiryDays(),\n                domain.getServiceExpiryDays(), role.getServiceExpiryDays(), role.getRoleMembers());\n\n        // process our request\n        \n        dbService.executePutRole(ctx, domainName, roleName, role, auditRef, caller);\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n    }\n\n    void validateRoleMemberPrincipals(final Role role, final String caller) {\n\n        // make sure we have either one of the options enabled for verification\n\n        if (!validateUserRoleMembers && !validateServiceRoleMembers) {\n            return;\n        }\n\n        for (RoleMember roleMember : role.getRoleMembers()) {\n            validateRoleMemberPrincipal(roleMember.getMemberName(), caller);\n        }\n    }\n\n    void validateRoleMemberPrincipal(final String memberName, final String caller) {\n\n        boolean bUser = ZMSUtils.isUserDomainPrincipal(memberName, userDomainPrefix, addlUserCheckDomainPrefixList);\n        boolean bValidPrincipal = true;\n        if (bUser) {\n\n            // if the account contains a wildcard then we're going\n            // to let the user authority decide if it's valid or not\n\n            if (validateUserRoleMembers && userAuthority != null) {\n                bValidPrincipal = userAuthority.isValidUser(memberName);\n            }\n\n        } else {\n\n            if (validateServiceRoleMembers) {\n\n                // if the account contains a wildcard character then\n                // we're going to assume it's valid\n\n                int idx = memberName.indexOf('*');\n                if (idx == -1) {\n                    idx = memberName.lastIndexOf('.');\n                    if (idx != -1) {\n                        final String domainName = memberName.substring(0, idx);\n                        final String serviceName = memberName.substring(idx + 1);\n\n                        // first we need to check if the domain is on the list of\n                        // our skip domains for service member validation. these\n                        // are typically domains (like for ci/cd) where services\n                        // are dynamic and do not need to be registered in Athenz\n\n                        if (!validateServiceMemberSkipDomains.contains(domainName)) {\n                            bValidPrincipal = dbService.getServiceIdentity(domainName, serviceName, true) != null;\n                        }\n                    } else {\n                        bValidPrincipal = false;\n                    }\n                }\n            }\n        }\n\n        if (!bValidPrincipal) {\n            throw ZMSUtils.requestError(\"Principal \" + memberName + \" is not valid\", caller);\n        }\n    }\n\n    public void deleteRole(ResourceContext ctx, String domainName, String roleName, String auditRef) {\n        \n        final String caller = \"deleterole\";\n        metric.increment(ZMSConsts.HTTP_DELETE);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        validate(roleName, TYPE_ENTITY_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        roleName = roleName.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"deleterole_timing\", domainName, principalDomain);\n        \n        // verify that request is properly authenticated for this request\n        \n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(), caller);\n        \n        /* we are not going to allow any user to delete\n         * the admin role and policy since those are required\n         * for standard domain operations */\n        \n        if (roleName.equalsIgnoreCase(ADMIN_ROLE_NAME)) {\n            throw ZMSUtils.requestError(\"deleteRole: admin role cannot be deleted\", caller);\n        }\n        \n        dbService.executeDeleteRole(ctx, domainName, roleName, auditRef, caller);\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n    }\n\n    boolean memberNameMatch(String memberName, String matchName) {\n        // we are supporting 3 formats for role members\n        // *, <domain>.* and <domain>.<user>*\n        if (memberName.equals(\"*\")) {\n            return true;\n        } else if (memberName.endsWith(\"*\")) {\n            return matchName.startsWith(memberName.substring(0, memberName.length() - 1));\n        } else {\n            return memberName.equals(matchName);\n        }\n    }\n    \n    boolean checkRoleMemberExpiration(List<RoleMember> roleMembers, String member) {\n        \n        boolean isMember = false;\n        for (RoleMember memberInfo: roleMembers) {\n            final String memberName = memberInfo.getMemberName();\n            if (memberNameMatch(memberName, member)) {\n                // check expiration, if is not defined, its not expired.\n                Timestamp expiration = memberInfo.getExpiration();\n                if (expiration != null) {\n                    isMember = !(expiration.millis() < System.currentTimeMillis());\n                } else {\n                    isMember = true;\n                }\n                break;\n            }\n        }\n        return isMember;\n    }\n    \n    boolean isMemberOfRole(Role role, String member) {\n        List<RoleMember> roleMembers = role.getRoleMembers();\n        if (roleMembers == null) {\n            return false;\n        }\n        return checkRoleMemberExpiration(roleMembers, member);\n    }\n\n    @Override\n    public Membership getMembership(ResourceContext ctx, String domainName,\n            String roleName, String memberName, String expiration) {\n        \n        final String caller = \"getmembership\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        validate(roleName, TYPE_ENTITY_NAME, caller);\n        validate(memberName, TYPE_MEMBER_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        roleName = roleName.toLowerCase();\n        memberName = normalizeDomainAliasUser(memberName.toLowerCase());\n        long expiryTimestamp = getModTimestamp(expiration);\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"getmembership_timing\", domainName, principalDomain);\n\n        Membership result = dbService.getMembership(domainName, roleName, memberName, expiryTimestamp);\n        \n        metric.stopTiming(timerMetric, domainName, principalDomain);\n        return result;\n    }\n\n    long configuredExpiryMillis(Integer domainExpiryDays, Integer roleExpiryDays) {\n\n        // the role expiry days settings overrides the domain one if one configured\n\n        int expiryDays = 0;\n        if (roleExpiryDays != null && roleExpiryDays > 0) {\n            expiryDays = roleExpiryDays;\n        } else if (domainExpiryDays != null && domainExpiryDays > 0) {\n            expiryDays = domainExpiryDays;\n        }\n        return expiryDays == 0 ? 0 : System.currentTimeMillis() + TimeUnit.MILLISECONDS.convert(expiryDays, TimeUnit.DAYS);\n    }\n\n    Timestamp getMemberExpiration(long cfgExpiryMillis, Timestamp memberExpiration) {\n        if (memberExpiration == null) {\n            return Timestamp.fromMillis(cfgExpiryMillis);\n        } else if (memberExpiration.millis() > cfgExpiryMillis) {\n            return Timestamp.fromMillis(cfgExpiryMillis);\n        } else {\n            return memberExpiration;\n        }\n    }\n\n    void updateRoleMemberExpiration(Integer domainUserMemberExpiryDays, Integer roleUserMemberExpiryDays,\n            Integer domainServiceMemberExpiryDays, Integer roleServiceMemberExpiryDays, List<RoleMember> roleMembers) {\n\n        long cfgUserMemberExpiryMillis = configuredExpiryMillis(domainUserMemberExpiryDays, roleUserMemberExpiryDays);\n        long cfgServiceMemberExpiryMillis = configuredExpiryMillis(domainServiceMemberExpiryDays, roleServiceMemberExpiryDays);\n\n        // if we have no value configured then we have nothing to\n        // do so we'll just return right away\n\n        if (cfgUserMemberExpiryMillis == 0 && cfgServiceMemberExpiryMillis == 0) {\n            return;\n        }\n\n        // go through the members and update expiration as necessary\n\n        for (RoleMember roleMember : roleMembers) {\n            boolean bUser = ZMSUtils.isUserDomainPrincipal(roleMember.getMemberName(), userDomainPrefix,\n                    addlUserCheckDomainPrefixList);\n            if (bUser && cfgUserMemberExpiryMillis != 0) {\n                roleMember.setExpiration(getMemberExpiration(cfgUserMemberExpiryMillis, roleMember.getExpiration()));\n            } else if (!bUser && cfgServiceMemberExpiryMillis != 0) {\n                roleMember.setExpiration(getMemberExpiration(cfgServiceMemberExpiryMillis, roleMember.getExpiration()));\n            }\n        }\n    }\n\n    Timestamp memberExpiryTimestamp(Integer domainExpiryDays, Integer roleExpiryDays, Timestamp memberExpiration) {\n\n        long cfgExpiryMillis = configuredExpiryMillis(domainExpiryDays, roleExpiryDays);\n\n        // if we have no value configured then return\n        // the membership expiration as is\n\n        if (cfgExpiryMillis == 0) {\n            return memberExpiration;\n        }\n\n        // otherwise compare the configured expiry days with the specified\n        // membership value and choose the smallest expiration value\n\n        return getMemberExpiration(cfgExpiryMillis, memberExpiration);\n    }\n\n    @Override\n    public void putMembership(ResourceContext ctx, String domainName, String roleName,\n            String memberName, String auditRef, Membership membership) {\n        \n        final String caller = \"putmembership\";\n        metric.increment(ZMSConsts.HTTP_PUT);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        validate(roleName, TYPE_ENTITY_NAME, caller);\n        validate(memberName, TYPE_MEMBER_NAME, caller);\n        validate(membership, TYPE_MEMBERSHIP, caller);\n        \n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        roleName = roleName.toLowerCase();\n        memberName = memberName.toLowerCase();\n        AthenzObject.MEMBERSHIP.convertToLowerCase(membership);\n\n        final Principal principal = ((RsrcCtxWrapper) ctx).principal();\n        final String principalDomain = principal.getDomain();\n\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"putmembership_timing\", domainName, principalDomain);\n\n        // verify that request is properly authenticated for this request\n        \n        verifyAuthorizedServiceOperation(principal.getAuthorizedService(), caller, \"role\", roleName);\n        \n        // verify that the member name in the URI and object provided match\n        \n        if (!memberName.equals(membership.getMemberName())) {\n            throw ZMSUtils.requestError(\"putMembership: Member name in URI and Membership object do not match\", caller);\n        }\n        \n        // role name is optional so we'll verify only if the value is present in the object\n        \n        if (membership.getRoleName() != null && !roleName.equals(membership.getRoleName())) {\n            throw ZMSUtils.requestError(\"putMembership: Role name in URI and Membership object do not match\", caller);\n        }\n        \n        // extract our role object to get its attributes\n\n        AthenzDomain domain = getAthenzDomain(domainName, false);\n        Role role = getRoleFromDomain(roleName, domain);\n\n        if (role == null) {\n            throw ZMSUtils.requestError(\"Invalid rolename specified\", caller);\n        }\n\n        // create and normalize the role member object\n\n        RoleMember roleMember = new RoleMember();\n        roleMember.setMemberName(normalizeDomainAliasUser(memberName));\n        boolean bUser = ZMSUtils.isUserDomainPrincipal(roleMember.getMemberName(), userDomainPrefix,\n                addlUserCheckDomainPrefixList);\n        if (bUser) {\n            roleMember.setExpiration(memberExpiryTimestamp(domain.getDomain().getMemberExpiryDays(),\n                    role.getMemberExpiryDays(), membership.getExpiration()));\n        } else {\n            roleMember.setExpiration(memberExpiryTimestamp(domain.getDomain().getServiceExpiryDays(),\n                    role.getServiceExpiryDays(), membership.getExpiration()));\n        }\n\n        // check to see if we need to validate the principal\n\n        if (validateUserRoleMembers || validateServiceRoleMembers) {\n            validateRoleMemberPrincipal(roleMember.getMemberName(), caller);\n        }\n\n        // authorization check which also automatically updates\n        // the active and approved flags for the request\n\n        if (!isAllowedPutMembership(principal, domain, role, roleMember)) {\n            metric.stopTiming(timerMetric, domainName, principalDomain);\n            throw ZMSUtils.forbiddenError(\"putMembership: principal is not authorized to add members\", caller);\n        }\n\n        // add the member to the specified role\n\n        dbService.executePutMembership(ctx, domainName, roleName, roleMember, auditRef, caller);\n\n        // new role member with pending status. Notify approvers\n\n        if (roleMember.getApproved() == Boolean.FALSE) {\n            sendMembershipApprovalNotification(domainName, domain.getDomain().getOrg(), roleName,\n                    roleMember.getMemberName(), auditRef, principal.getFullName(), role.getAuditEnabled(),\n                    role.getSelfServe());\n        }\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n    }\n\n     void sendMembershipApprovalNotification(final String domain, final String org, final String role,\n            final String member, final String auditRef, final String principal, Boolean auditEnabled,\n            Boolean selfServe) {\n\n        Map<String, String> details = new HashMap<>();\n        details.put(NOTIFICATION_DETAILS_DOMAIN, domain);\n        details.put(NOTIFICATION_DETAILS_ROLE, role);\n        details.put(NOTIFICATION_DETAILS_MEMBER, member);\n        details.put(NOTIFICATION_DETAILS_REASON, auditRef);\n        details.put(NOTIFICATION_DETAILS_REQUESTER, principal);\n\n         if (LOG.isDebugEnabled()) {\n             LOG.debug(\"Sending Membership Approval notification after putMembership\");\n         }\n        notificationManager.generateAndSendPostPutMembershipNotification(domain, org, auditEnabled,\n                selfServe, details);\n    }\n\n    public void deleteMembership(ResourceContext ctx, String domainName, String roleName,\n            String memberName, String auditRef) {\n        \n        final String caller = \"deletemembership\";\n        metric.increment(ZMSConsts.HTTP_DELETE);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        validate(roleName, TYPE_ENTITY_NAME, caller);\n        validate(memberName, TYPE_MEMBER_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        roleName = roleName.toLowerCase();\n        memberName = memberName.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"deletemembership_timing\", domainName, principalDomain);\n        \n        // verify that request is properly authenticated for this request\n        \n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(), caller);\n\n        dbService.executeDeleteMembership(ctx, domainName, roleName,\n                normalizeDomainAliasUser(memberName), auditRef, caller);\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n    }\n\n    public Quota getQuota(ResourceContext ctx, String domainName) {\n        \n        final String caller = \"getquota\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"getquota_timing\", domainName, principalDomain);\n\n        Quota result = dbService.getQuota(domainName);\n        \n        metric.stopTiming(timerMetric, domainName, principalDomain);\n        return result;\n    }\n\n    @Override\n    public void putQuota(ResourceContext ctx, String domainName, String auditRef, Quota quota) {\n        \n        final String caller = \"putQuota\";\n        metric.increment(ZMSConsts.HTTP_PUT);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        validate(quota, TYPE_QUOTA, caller);\n        \n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        AthenzObject.QUOTA.convertToLowerCase(quota);\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"putquota_timing\", domainName, principalDomain);\n\n        // verify that request is properly authenticated for this request\n        \n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(),\n                caller);\n        \n        // verify that the domain name in the URI and object provided match\n        \n        if (!domainName.equals(quota.getName())) {\n            throw ZMSUtils.requestError(\"putQuota: Domain name in URI and Quota object do not match\", caller);\n        }\n\n        dbService.executePutQuota(ctx, domainName, quota, auditRef, caller);\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n    }\n\n    public void deleteQuota(ResourceContext ctx, String domainName, String auditRef) {\n        \n        final String caller = \"deleteQuota\";\n        metric.increment(ZMSConsts.HTTP_DELETE);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"deletequota_timing\", domainName, principalDomain);\n        \n        // verify that request is properly authenticated for this request\n        \n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(), caller);\n        \n        dbService.executeDeleteQuota(ctx, domainName, auditRef, caller);\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n    }\n    \n    boolean hasExceededListLimit(Integer limit, int count) {\n        \n        if (limit == null) {\n            return false;\n        }\n\n        return limit > 0 && count > limit;\n    }\n    \n    /**\n     * process the list request for the given object type - e.g. role, policy, etc\n     * if the limit is specified and we have reached that limit then return\n     * the name of the object that should be set at the next item for the\n     * subsequent list operation.\n     */\n    String processListRequest(String domainName, AthenzObject objType, Integer limit,\n            String skip, List<String> names) {\n        \n        switch (objType) {\n            case ROLE:\n                names.addAll(dbService.listRoles(domainName));\n                break;\n            case POLICY:\n                names.addAll(dbService.listPolicies(domainName));\n                break;\n            case SERVICE_IDENTITY:\n                names.addAll(dbService.listServiceIdentities(domainName));\n                break;\n            default:\n                return null;\n        }\n        \n        int count = names.size();\n        if (skip != null) {\n            for (int i = 0; i < count; i++) {\n                String name = names.get(i);\n                if (skip.equals(name)) {\n                    names.subList(0, i + 1).clear();\n                    count = names.size();\n                    break;\n                }\n            }\n        }\n        \n        String next = null;\n        if (hasExceededListLimit(limit, count)) {\n            names.subList(limit, count).clear();\n            next = names.get(limit - 1);\n        }\n        \n        return next;\n    }\n    \n    public PolicyList getPolicyList(ResourceContext ctx, String domainName, Integer limit, String skip) {\n        \n        final String caller = \"getpolicylist\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        if (skip != null) {\n            skip = skip.toLowerCase();\n        }\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"getpolicylist_timing\", domainName, principalDomain);\n        \n        List<String> names = new ArrayList<>();\n        String next = processListRequest(domainName, AthenzObject.POLICY, limit, skip, names);\n        PolicyList result = new PolicyList().setNames(names);\n        if (next != null) {\n            result.setNext(next);\n        }\n        \n        metric.stopTiming(timerMetric, domainName, principalDomain);\n        return result;\n    }\n\n    List<Policy> setupPolicyList(AthenzDomain domain, Boolean assertions) {\n        \n        // if we're asked to return the assertions as well then we\n        // just need to return the data as is without any modifications\n        \n        List<Policy> policies;\n        if (assertions == Boolean.TRUE) {\n            policies = domain.getPolicies();\n        } else {\n            policies = new ArrayList<>();\n            for (Policy policy : domain.getPolicies()) {\n                Policy newPolicy = new Policy()\n                        .setName(policy.getName())\n                        .setModified(policy.getModified());\n                policies.add(newPolicy);\n            }\n        }\n        \n        return policies;\n    }\n    \n    public Policies getPolicies(ResourceContext ctx, String domainName, Boolean assertions) {\n        \n        final String caller = \"getpolicies\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"getpolicies_timing\", domainName, principalDomain);\n        \n        Policies result = new Policies();\n        \n        AthenzDomain domain = getAthenzDomain(domainName, false);\n        if (domain == null) {\n            throw ZMSUtils.notFoundError(\"getPolicies: Domain not found: '\" + domainName + \"'\", caller);\n        }\n\n        result.setList(setupPolicyList(domain, assertions));\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n        return result;\n    }\n    \n    public Policy getPolicy(ResourceContext ctx, String domainName, String policyName) {\n        \n        final String caller = \"getpolicy\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        validate(policyName, TYPE_ENTITY_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        policyName = policyName.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"getpolicy_timing\", domainName, principalDomain);\n        \n        Policy policy = dbService.getPolicy(domainName, policyName);\n        if (policy == null) {\n            throw ZMSUtils.notFoundError(\"getPolicy: Policy not found: '\" +\n                    ZMSUtils.policyResourceName(domainName, policyName) + \"'\", caller);\n        }\n\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n        return policy;\n    }\n    \n    public Assertion getAssertion(ResourceContext ctx, String domainName, String policyName,\n            Long assertionId) {\n        \n        final String caller = \"getassertion\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        validate(policyName, TYPE_ENTITY_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        policyName = policyName.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"getassertion_timing\", domainName, principalDomain);\n        \n        Assertion assertion = dbService.getAssertion(domainName, policyName, assertionId);\n        if (assertion == null) {\n            throw ZMSUtils.notFoundError(\"getAssertion: Assertion not found: '\" +\n                    ZMSUtils.policyResourceName(domainName, policyName) + \"' Assertion: '\" +\n                    assertionId + \"'\", caller);\n        }\n\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n        return assertion;\n    }\n\n    @Override\n    public Assertion putAssertion(ResourceContext ctx, String domainName, String policyName,\n            String auditRef, Assertion assertion) {\n        \n        final String caller = \"putassertion\";\n        metric.increment(ZMSConsts.HTTP_PUT);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        validate(policyName, TYPE_COMPOUND_NAME, caller);\n        validate(assertion, TYPE_ASSERTION, caller);\n\n        // verify that request is properly authenticated for this request\n        \n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(), caller);\n        \n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        policyName = policyName.toLowerCase();\n        AthenzObject.ASSERTION.convertToLowerCase(assertion);\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"putassertion_timing\", domainName, principalDomain);\n\n        // we are not going to allow any user to update\n        // the admin policy since that is required\n        // for standard domain operations */\n        \n        if (policyName.equalsIgnoreCase(ADMIN_POLICY_NAME)) {\n            throw ZMSUtils.requestError(\"putAssertion: admin policy cannot be modified\", caller);\n        }\n        \n        // validate to make sure we have expected values for assertion fields\n        \n        validatePolicyAssertion(assertion, caller);\n        \n        dbService.executePutAssertion(ctx, domainName, policyName, assertion, auditRef, caller);\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n        return assertion;\n    }\n    \n    public void deleteAssertion(ResourceContext ctx, String domainName, String policyName,\n            Long assertionId, String auditRef) {\n        \n        final String caller = \"deleteassertion\";\n        metric.increment(ZMSConsts.HTTP_DELETE);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        validate(policyName, TYPE_ENTITY_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        policyName = policyName.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"deleteassertion_timing\", domainName, principalDomain);\n        \n        // we are not going to allow any user to update\n        // the admin policy since that is required\n        // for standard domain operations */\n        \n        if (policyName.equalsIgnoreCase(ADMIN_POLICY_NAME)) {\n            throw ZMSUtils.requestError(\"deleteAssertion: admin policy cannot be modified\", caller);\n        }\n        \n        // verify that request is properly authenticated for this request\n        \n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(), caller);\n        \n        dbService.executeDeleteAssertion(ctx, domainName, policyName, assertionId, auditRef, caller);\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n    }\n    \n    void validatePolicyAssertions(List<Assertion> assertions, String caller) {\n        \n        if (assertions == null) {\n            return;\n        }\n        \n        for (Assertion assertion : assertions) {\n            validatePolicyAssertion(assertion, caller);\n        }\n    }\n    \n    void validatePolicyAssertion(Assertion assertion, String caller) {\n            \n        // extract the domain name from the resource\n        \n        final String resource = assertion.getResource();\n        int idx = resource.indexOf(':');\n        if (idx == -1) {\n            throw ZMSUtils.requestError(\"Missing domain name from assertion resource: \"\n                    + resource, caller);\n        }\n\n        // we need to validate our domain name with special\n        // case of * that is allowed to match any domain\n        \n        String domainName = resource.substring(0, idx);\n        if (!domainName.equals(\"*\")) {\n            validate(domainName, TYPE_DOMAIN_NAME, caller);\n        }\n        \n        // we'll also verify that the resource does not contain\n        // any control characters since those cause issues when\n        // data is serialized/deserialized and signature is generated\n        \n        if (StringUtils.containsControlCharacter(resource)) {\n            throw ZMSUtils.requestError(\"Assertion resource contains control characters: \"\n                    + resource, caller);\n        }\n        \n        // verify the action is not empty and does not contain\n        // any control characters\n        \n        final String action = assertion.getAction();\n        if (action == null || action.isEmpty()) {\n            throw ZMSUtils.requestError(\"Assertion action cannot be empty\", caller);\n        }\n        \n        if (StringUtils.containsControlCharacter(action)) {\n            throw ZMSUtils.requestError(\"Assertion action contains control characters: \"\n                    + resource, caller);\n        }\n    }\n    \n    boolean isConsistentPolicyName(final String domainName, final String policyName, Policy policy) {\n        \n        String resourceName = ZMSUtils.policyResourceName(domainName, policyName);\n        \n        // first lets assume we have the expected name specified in the policy\n        \n        if (resourceName.equals(policy.getName())) {\n            return true;\n        }\n\n        // if not check to see if the policy contains the relative local name\n        // part only instead of the expected resourceName and update accordingly\n        \n        if (policyName.equals(policy.getName())) {\n            policy.setName(resourceName);\n            return true;\n        }\n        \n        // we have a mismatch\n        \n        return false;\n    }\n\n    @Override\n    public void putPolicy(ResourceContext ctx, String domainName, String policyName, String auditRef, Policy policy) {\n        \n        final String caller = \"putpolicy\";\n        metric.increment(ZMSConsts.HTTP_PUT);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        validate(policyName, TYPE_COMPOUND_NAME, caller);\n        validate(policy, TYPE_POLICY, caller);\n\n        // verify that request is properly authenticated for this request\n        \n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(), caller);\n        \n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        policyName = policyName.toLowerCase();\n        AthenzObject.POLICY.convertToLowerCase(policy);\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"putpolicy_timing\", domainName, principalDomain);\n        \n        // we are not going to allow any user to update\n        // the admin policy since that is required\n        // for standard domain operations */\n        \n        if (policyName.equalsIgnoreCase(ADMIN_POLICY_NAME)) {\n            throw ZMSUtils.requestError(\"putPolicy: admin policy cannot be modified\", caller);\n        }\n        \n        // verify the policy name in the URI and request are consistent\n        \n        if (!isConsistentPolicyName(domainName, policyName, policy)) {\n            throw ZMSUtils.requestError(\"putPolicy: Inconsistent policy names - expected: \"\n                    + ZMSUtils.policyResourceName(domainName, policyName) + \", actual: \"\n                    + policy.getName(), caller);\n        }\n        \n        // validate to make sure we have expected values for assertion fields\n        \n        validatePolicyAssertions(policy.getAssertions(), caller);\n        \n        dbService.executePutPolicy(ctx, domainName, policyName, policy, auditRef, caller);\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n    }\n    \n    public void deletePolicy(ResourceContext ctx, String domainName, String policyName, String auditRef) {\n        \n        final String caller = \"deletepolicy\";\n        metric.increment(ZMSConsts.HTTP_DELETE);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        validate(policyName, TYPE_ENTITY_NAME, caller);\n\n        // verify that request is properly authenticated for this request\n\n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(), caller);\n        \n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        policyName = policyName.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"deletepolicy_timing\", domainName, principalDomain);\n\n        // we are not going to allow any user to delete\n        // the admin role and policy since those are required\n        // for standard domain operations */\n        \n        if (policyName.equalsIgnoreCase(ADMIN_POLICY_NAME)) {\n            throw ZMSUtils.requestError(\"deletePolicy: admin policy cannot be deleted\", caller);\n        }\n        \n        dbService.executeDeletePolicy(ctx, domainName, policyName, auditRef, caller);\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n    }\n\n    boolean matchDelegatedTrustAssertion(Assertion assertion, String roleName, \n            String roleMember, List<Role> roles) {\n        \n        if (!ZMSUtils.assumeRoleResourceMatch(roleName, assertion)) {\n            return false;\n        }\n        \n        String rolePattern = StringUtils.patternFromGlob(assertion.getRole());\n        for (Role role : roles) {\n            String name = role.getName();\n            if (!name.matches(rolePattern)) {\n                continue;\n            }\n            \n            if (isMemberOfRole(role, roleMember)) {\n                return true;\n            }\n        }\n        \n        return false;\n    }\n    \n    boolean matchDelegatedTrustPolicy(Policy policy, String roleName, String roleMember, List<Role> roles) {\n        \n        List<Assertion> assertions = policy.getAssertions();\n        if (assertions == null) {\n            return false;\n        }\n        \n        for (Assertion assertion : assertions) {\n            if (matchDelegatedTrustAssertion(assertion, roleName, roleMember, roles)) {\n                return true;\n            }\n        }\n        \n        return false;\n    }\n    \n    boolean delegatedTrust(String domainName, String roleName, String roleMember) {\n        \n        AthenzDomain domain = getAthenzDomain(domainName, true);\n        if (domain == null) {\n            return false;\n        }\n        \n        for (Policy policy : domain.getPolicies()) {\n            if (matchDelegatedTrustPolicy(policy, roleName, roleMember, domain.getRoles())) {\n                return true;\n            }\n        }\n        \n        return false;\n    }\n\n    boolean matchRole(String domain, List<Role> roles, String rolePattern,\n            List<String> authenticatedRoles) {\n        \n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"matchRole domain: \" + domain + \" rolePattern: \" + rolePattern);\n        }\n        \n        String prefix = domain + \":role.\";\n        int prefixLen = prefix.length();\n        for (Role role : roles) {\n            String name = role.getName();\n            if (!name.matches(rolePattern)) {\n                continue;\n            }\n            \n            String shortName = name.substring(prefixLen);\n            if (authenticatedRoles.contains(shortName)) {\n                return true;\n            }\n        }\n        return false;\n    }\n\n    boolean shouldRunDelegatedTrustCheck(String trust, String trustDomain) {\n        \n        // if no trust field field then no delegated trust check\n        \n        if (trust == null) {\n            return false;\n        }\n        \n        // if no specific trust domain specifies then we need\n        // run the delegated trust check for this domain\n        \n        if (trustDomain == null) {\n            return true;\n        }\n        \n        // otherwise we'll run the delegated trust check only if\n        // domain name matches\n        \n        return trust.equalsIgnoreCase(trustDomain);\n    }\n    \n    boolean matchPrincipalInRole(Role role, String roleName, String fullUser, String trustDomain) {\n        \n        // if we have members in the role then we're going to check\n        // against that list only\n        \n        if (role.getRoleMembers() != null) {\n            return isMemberOfRole(role, fullUser);\n        }\n        \n        // no members so let's check if this is a trust domain\n        \n        String trust = role.getTrust();\n        if (!shouldRunDelegatedTrustCheck(trust, trustDomain)) {\n            return false;\n        }\n\n        // delegate to another domain.\n        \n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"matchPrincipal: [delegated trust. Checking with: \" + trust + \"]\");\n        }\n        \n        return delegatedTrust(trust, roleName, fullUser);\n    }\n    \n    boolean matchPrincipal(List<Role> roles, String rolePattern, String fullUser, String trustDomain) {\n\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"matchPrincipal - rolePattern: \" + rolePattern + \" user: \" + fullUser +\n                    \" trust: \" + trustDomain);\n        }\n\n        for (Role role : roles) {\n            \n            String name = role.getName();\n            if (!name.matches(rolePattern)) {\n                continue;\n            }\n            \n            if (matchPrincipalInRole(role, name, fullUser, trustDomain)) {\n                if (LOG.isDebugEnabled()) {\n                    LOG.debug(\"assertionMatch: -> OK (by principal)\");\n                }\n                return true;\n            }\n        }\n        return false;\n    }\n\n    AthenzDomain virtualHomeDomain(Principal principal, String domainName) {\n\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"homeDomain: home domain detected. Create on the fly.\");\n        }\n        \n        AthenzDomain athenzDomain = new AthenzDomain(domainName);\n        \n        Domain domain = new Domain().setName(domainName).setEnabled(Boolean.TRUE);\n        athenzDomain.setDomain(domain);\n        \n        List<String> adminUsers = new ArrayList<>();\n        adminUsers.add(principal.getFullName());\n        \n        Role role = ZMSUtils.makeAdminRole(domainName, adminUsers);\n        athenzDomain.getRoles().add(role);\n        \n        Policy policy = ZMSUtils.makeAdminPolicy(domainName, role);\n        athenzDomain.getPolicies().add(policy);\n        \n        return athenzDomain;\n    }\n    \n    boolean assertionMatch(Assertion assertion, String identity, String action, String resource,\n            String domain, List<Role> roles, List<String> authenticatedRoles, String trustDomain) {\n        \n        String actionPattern = StringUtils.patternFromGlob(assertion.getAction());\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"assertionMatch: action '{}' pattern '{}'\", action, actionPattern);\n        }\n        if (!action.matches(actionPattern)) {\n            return false;\n        }\n        \n        String rezPattern = StringUtils.patternFromGlob(assertion.getResource());\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"assertionMatch: resource '{}' pattern '{}'\", resource, rezPattern);\n        }\n        if (!resource.matches(rezPattern)) {\n            return false;\n        }\n        \n        boolean matchResult;\n        String rolePattern = StringUtils.patternFromGlob(assertion.getRole());\n        if (authenticatedRoles != null) {\n            matchResult = matchRole(domain, roles, rolePattern, authenticatedRoles);\n        } else {\n            matchResult = matchPrincipal(roles, rolePattern, identity, trustDomain);\n        }\n        \n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"assertionMatch: -> \" + matchResult +\n                    \" (effect: \" + assertion.getEffect() + \")\");\n        }\n\n        return matchResult;\n    }\n    \n    boolean verifyProviderEndpoint(String providerEndpoint) {\n        \n        // verify that we have a valid endpoint that ends in one of our\n        // configured domains. if it's not present or an empty value then\n        // there is no field to verify\n        \n        if (providerEndpoint == null) {\n            return true;\n        }\n        \n        if (providerEndpoint.isEmpty()) {\n            return true;\n        }\n        \n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"verifyProviderEndpoint: verifying endpoint: \" + providerEndpoint);\n        }\n        \n        java.net.URI uri;\n        try {\n            uri = new java.net.URI(providerEndpoint);\n        } catch (URISyntaxException ex) {\n            return false;\n        }\n        \n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"verifyProviderEndpoint: host: \" + uri.getHost() + \" scheme: \" + uri.getScheme());\n        }\n        \n        String scheme = uri.getScheme();\n        if (scheme == null) {\n            return false;\n        }\n        \n        scheme = scheme.toLowerCase();\n        \n        // if our scheme is class then we have no further checks to carry\n        \n        if (scheme.equalsIgnoreCase(ZMSConsts.SCHEME_CLASS)) {\n            return true;\n        }\n        \n        // otherwise it must be one of our http schemes\n\n        if (!(scheme.equalsIgnoreCase(ZMSConsts.SCHEME_HTTP) || scheme.equalsIgnoreCase(ZMSConsts.SCHEME_HTTPS))) {\n            return false;\n        }\n        \n        String host = uri.getHost();\n        if (host == null) {\n            return false;\n        }\n        host = host.toLowerCase();\n        \n        // if we have no endpoint configured then we should\n        // allow all hostnames\n        \n        if (providerEndpoints == null || providerEndpoints.isEmpty()) {\n            return true;\n        }\n        \n        // we're going to allow localhost as a special case since\n        // that's often used for dev testing\n        \n        boolean valid = host.equals(ZMSConsts.LOCALHOST);\n        if (!valid) {\n            for (String endpoint : providerEndpoints) {\n                valid = host.endsWith(endpoint);\n                if (valid) {\n                    break;\n                }\n            }\n        }\n\n        return valid;\n    }\n    \n    boolean verifyServicePublicKey(String key) {\n        try {\n            PublicKey pub = Crypto.loadPublicKey(Crypto.ybase64DecodeString(key));\n            if (LOG.isDebugEnabled()) {\n                LOG.debug(\"verifyServicePublicKey: public key looks valid: \" + pub);\n            }\n        } catch (Exception ex) {\n            LOG.error(\"verifyServicePublicKey: Invalid Public Key: \" + ex.getMessage());\n            return false;\n        }\n        return true;\n    }\n    \n    boolean verifyServicePublicKeys(ServiceIdentity service) {\n\n        // verify that the public keys specified are valid\n        // It's okay to not specify any public keys\n\n        List<PublicKeyEntry> publicKeyList = service.getPublicKeys();\n        if (publicKeyList == null || publicKeyList.size() == 0) {\n            return true;\n        }\n\n        for (PublicKeyEntry entry : publicKeyList) {\n            if (!verifyServicePublicKey(entry.getKey())) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    public boolean isValidServiceName(final String serviceName) {\n\n        if (reservedServiceNames != null && reservedServiceNames.contains(serviceName)) {\n            return false;\n        }\n\n        if (serviceNameMinLength > 0 && serviceNameMinLength > serviceName.length()) {\n            return false;\n        }\n\n        return true;\n    }\n\n    @Override\n    public void putServiceIdentity(ResourceContext ctx, String domainName, String serviceName,\n                                   String auditRef, ServiceIdentity service) {\n        \n        final String caller = \"putserviceidentity\";\n        metric.increment(ZMSConsts.HTTP_PUT);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        validate(serviceName, TYPE_SIMPLE_NAME, caller);\n        validate(service, TYPE_SERVICE_IDENTITY, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        serviceName = serviceName.toLowerCase();\n        AthenzObject.SERVICE_IDENTITY.convertToLowerCase(service);\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"putserviceidentity_timing\", domainName, principalDomain);\n\n        // validate that the service name is valid\n\n        if (!isValidServiceName(serviceName)) {\n            throw ZMSUtils.requestError(\"putServiceIdentity: Invalid/Reserved service name\", caller);\n        }\n\n        // verify that request is properly authenticated for this request\n        \n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(), caller);\n        \n        if (!ZMSUtils.serviceResourceName(domainName, serviceName).equals(service.getName())) {\n            throw ZMSUtils.requestError(\"putServiceIdentity: Inconsistent service/domain names\", caller);\n        }\n        \n        if (!verifyServicePublicKeys(service)) {\n            throw ZMSUtils.requestError(\"putServiceIdentity: Provided public key is invalid\", caller);\n        }\n\n        if (!verifyProviderEndpoint(service.getProviderEndpoint())) {\n            throw ZMSUtils.requestError(\"putServiceIdentity: Invalid endpoint: \"\n                + service.getProviderEndpoint() + \" - must be http(s) and in configured domain\", caller);\n        }\n        \n        dbService.executePutServiceIdentity(ctx, domainName, serviceName, service, auditRef, caller);\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n    }\n    \n    public ServiceIdentity getServiceIdentity(ResourceContext ctx, String domainName, String serviceName) {\n        \n        final String caller = \"getserviceidentity\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        validate(serviceName, TYPE_SIMPLE_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        serviceName = serviceName.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"getserviceidentity_timing\", domainName, principalDomain);\n\n        ServiceIdentity service = dbService.getServiceIdentity(domainName, serviceName, false);\n        if (service == null) {\n            throw ZMSUtils.notFoundError(\"getServiceIdentity: Service not found: '\" +\n                    ZMSUtils.serviceResourceName(domainName, serviceName) + \"'\", caller);\n        }\n        \n        metric.stopTiming(timerMetric, domainName, principalDomain);\n        return service;\n    }\n    \n    public void deleteServiceIdentity(ResourceContext ctx, String domainName,\n            String serviceName, String auditRef) {\n        \n        final String caller = \"deleteserviceidentity\";\n        metric.increment(ZMSConsts.HTTP_DELETE);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        validate(serviceName, TYPE_SIMPLE_NAME, caller);\n        \n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        serviceName = serviceName.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"deleteserviceidentity_timing\", domainName, principalDomain);\n        \n        // verify that request is properly authenticated for this request\n        \n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(), caller);\n        \n        dbService.executeDeleteServiceIdentity(ctx, domainName, serviceName, auditRef, caller);\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n    }\n\n    List<ServiceIdentity> setupServiceIdentityList(AthenzDomain domain, Boolean publicKeys, Boolean hosts) {\n        \n        // if we're asked to return the public keys and hosts as well then we\n        // just need to return the data as is without any modifications\n        \n        List<ServiceIdentity> services;\n        if (publicKeys == Boolean.TRUE && hosts == Boolean.TRUE) {\n            services = domain.getServices();\n        } else {\n            services = new ArrayList<>();\n            for (ServiceIdentity service : domain.getServices()) {\n                ServiceIdentity newService = new ServiceIdentity()\n                        .setName(service.getName())\n                        .setModified(service.getModified())\n                        .setExecutable(service.getExecutable())\n                        .setGroup(service.getGroup())\n                        .setUser(service.getUser())\n                        .setProviderEndpoint(service.getProviderEndpoint());\n                if (publicKeys == Boolean.TRUE) {\n                    newService.setPublicKeys(service.getPublicKeys());\n                } else if (hosts == Boolean.TRUE) {\n                    newService.setHosts(service.getHosts());\n                }\n                services.add(newService);\n            }\n        }\n        \n        return services;\n    }\n    \n    public ServiceIdentities getServiceIdentities(ResourceContext ctx, String domainName,\n            Boolean publicKeys, Boolean hosts) {\n        \n        final String caller = \"getserviceidentities\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"getserviceidentities_timing\", domainName, principalDomain);\n        \n        ServiceIdentities result = new ServiceIdentities();\n        \n        AthenzDomain domain = getAthenzDomain(domainName, false);\n        if (domain == null) {\n            throw ZMSUtils.notFoundError(\"getServiceIdentities: Domain not found: '\"\n                    + domainName + \"'\", caller);\n        }\n\n        result.setList(setupServiceIdentityList(domain, publicKeys, hosts));\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n        return result;\n    }\n    \n    public ServiceIdentityList getServiceIdentityList(ResourceContext ctx, String domainName,\n            Integer limit, String skip) {\n       \n        final String caller = \"getserviceidentitylist\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        \n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        if (skip != null) {\n            skip = skip.toLowerCase();\n        }\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"getserviceidentitylist_timing\", domainName, principalDomain);\n        \n        List<String> names = new ArrayList<>();\n        String next = processListRequest(domainName, AthenzObject.SERVICE_IDENTITY, limit, skip, names);\n        ServiceIdentityList result = new ServiceIdentityList().setNames(names);\n        if (next != null) {\n            result.setNext(next);\n        }\n\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n        return result;\n    }\n\n    public PublicKeyEntry getPublicKeyEntry(ResourceContext ctx, String domainName, String serviceName, String keyId) {\n        \n        final String caller = \"getpublickeyentry\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        validate(serviceName, TYPE_SIMPLE_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        serviceName = serviceName.toLowerCase();\n        keyId = keyId.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"getpublickeyentry_timing\", domainName, principalDomain);\n        \n        PublicKeyEntry entry = dbService.getServicePublicKeyEntry(domainName, serviceName, keyId, false);\n        if (entry == null) {\n            throw ZMSUtils.notFoundError(\"getPublicKeyEntry: PublicKey \" + keyId + \" in service \" +\n                    ZMSUtils.serviceResourceName(domainName, serviceName) + \" not found\", caller);\n        }\n        \n        metric.stopTiming(timerMetric, domainName, principalDomain);\n        return entry;\n    }\n\n    public void deletePublicKeyEntry(ResourceContext ctx, String domainName, String serviceName,\n            String keyId, String auditRef) {\n        \n        final String caller = \"deletepublickeyentry\";\n        metric.increment(ZMSConsts.HTTP_DELETE);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n        \n        validateRequest(ctx.request(), caller);\n\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        validate(serviceName, TYPE_SIMPLE_NAME, caller);\n        \n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        serviceName = serviceName.toLowerCase();\n        keyId = keyId.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"deletepublickeyentry_timing\", domainName, principalDomain);\n\n        // verify that request is properly authenticated for this request\n        \n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(), caller);\n\n        dbService.executeDeletePublicKeyEntry(ctx, domainName, serviceName, keyId, auditRef, caller);\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n    }\n\n    @Override\n    public void putPublicKeyEntry(ResourceContext ctx, String domainName, String serviceName,\n            String keyId, String auditRef, PublicKeyEntry keyEntry) {\n        \n        final String caller = \"putpublickeyentry\";\n        metric.increment(ZMSConsts.HTTP_PUT);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        validate(serviceName, TYPE_SIMPLE_NAME, caller);\n        validate(keyEntry, TYPE_PUBLIC_KEY_ENTRY, caller);\n        \n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        serviceName = serviceName.toLowerCase();\n        keyId = keyId.toLowerCase();\n        AthenzObject.PUBLIC_KEY_ENTRY.convertToLowerCase(keyEntry);\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"putpublickeyentry_timing\", domainName, principalDomain);\n\n        // verify that request is properly authenticated for this request\n        \n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(), caller);\n\n        // verify that key id specified in request and object do match\n        \n        if (!keyId.equals(keyEntry.getId())) {\n            throw ZMSUtils.requestError(\"putPublicKeyEntry: keyId in URI and PublicKeyEntry object do not match\", caller);\n        }\n        \n        // verify we have a valid public key specified\n        \n        if (!verifyServicePublicKey(keyEntry.getKey())) {\n            throw ZMSUtils.requestError(\"putPublicKeyEntry: Invalid public key\", caller);\n        }\n        \n        dbService.executePutPublicKeyEntry(ctx, domainName, serviceName, keyEntry, auditRef, caller);\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n    }\n\n    String removeQuotes(String value) {\n        if (value.startsWith(\"\\\"\")) {\n            value = value.substring(1, value.length());\n        }\n        if (value.endsWith(\"\\\"\")) {\n            value = value.substring(0, value.length() - 1);\n        }\n        return value;\n    }\n    \n    long getModTimestamp(String matchingTag) {\n        \n        long timestamp = 0;\n        if (matchingTag == null) {\n            return timestamp;\n        }\n\n        matchingTag = removeQuotes(matchingTag);\n\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"getModTimestamp: matching tag ({})\", matchingTag);\n        }\n\n        if (matchingTag.isEmpty()) {\n            return timestamp;\n        }\n\n        try {\n            Timestamp tagStamp = Timestamp.fromString(matchingTag);\n            if (tagStamp == null) {\n                throw new IllegalArgumentException(\"Timestamp failed\");\n            }\n            timestamp = tagStamp.millis();\n        } catch (IllegalArgumentException exc) {\n            if (LOG.isWarnEnabled()) {\n                LOG.warn(\"getModTimestamp: matching tag({}) has bad format. Return 0 by default.\",\n                        matchingTag);\n            }\n        }\n        \n        return timestamp;\n    }\n\n    SignedDomain createSignedDomain(String domainName, long modifiedTime) {\n        SignedDomain signedDomain = new SignedDomain();\n        DomainData domainData = new DomainData().setName(domainName);\n        signedDomain.setDomain(domainData);\n        domainData.setModified(Timestamp.fromMillis(modifiedTime));\n        return signedDomain;\n    }\n\n    SignedDomain retrieveSignedDomainMeta(final String domainName, long modifiedTime,\n         final String account, Integer ypmId, final String metaAttr) {\n\n        SignedDomain signedDomain = createSignedDomain(domainName, modifiedTime);\n        if (metaAttr != null) {\n            switch (metaAttr) {\n                case META_ATTR_ACCOUNT:\n                    if (account == null) {\n                        return null;\n                    }\n                    signedDomain.getDomain().setAccount(account);\n                    break;\n                case META_ATTR_YPM_ID:\n                    if (ypmId == null) {\n                        return null;\n                    }\n                    signedDomain.getDomain().setYpmId(ypmId);\n                    break;\n                case META_ATTR_ALL:\n                    signedDomain.getDomain().setAccount(account);\n                    signedDomain.getDomain().setYpmId(ypmId);\n                    break;\n            }\n        }\n        return signedDomain;\n    }\n\n    SignedDomain retrieveSignedDomain(Domain domain, final String metaAttr, boolean setMetaDataOnly, boolean masterCopy) {\n\n        // check if we're asked to only return the meta data which\n        // we already have - name and last modified time, so we can\n        // add the domain to our return list and continue with the\n        // next domain\n\n        SignedDomain signedDomain;\n        if (setMetaDataOnly) {\n            signedDomain = retrieveSignedDomainMeta(domain.getName(), domain.getModified().millis(),\n                    domain.getAccount(), domain.getYpmId(), metaAttr);\n        } else {\n            signedDomain = retrieveSignedDomainData(domain.getName(), domain.getModified().millis(), masterCopy);\n        }\n        return signedDomain;\n    }\n\n    SignedDomain retrieveSignedDomain(DomainModified domainModified, final String metaAttr,\n            boolean setMetaDataOnly, boolean masterCopy) {\n\n        // check if we're asked to only return the meta data which\n        // we already have - name and last modified time, so we can\n        // add the domain to our return list and continue with the\n        // next domain\n\n        SignedDomain signedDomain;\n        if (setMetaDataOnly) {\n            signedDomain = retrieveSignedDomainMeta(domainModified.getName(), domainModified.getModified(),\n                    domainModified.getAccount(), domainModified.getYpmId(), metaAttr);\n        } else {\n            signedDomain = retrieveSignedDomainData(domainModified.getName(), domainModified.getModified(), masterCopy);\n        }\n        return signedDomain;\n    }\n\n    SignedDomain retrieveSignedDomainData(final String domainName, long modifiedTime, boolean masterCopy) {\n\n        // generate our signed domain object\n\n        SignedDomain signedDomain = createSignedDomain(domainName, modifiedTime);\n\n        // get the policies, roles, and service identities to create the\n        // DomainData\n\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"retrieveSignedDomain: retrieving domain \" + domainName);\n        }\n        \n        AthenzDomain athenzDomain = getAthenzDomain(domainName, true, masterCopy);\n        \n        // it's possible that our domain was deleted by another\n        // thread while we were processing this request so\n        // we'll return null so the caller can skip this domain\n        \n        if (athenzDomain == null) {\n            return null;\n        }\n\n        // set domain attributes - for enabled flag only set it\n        // if it set to false\n\n        DomainData domainData = signedDomain.getDomain();\n\n        if (athenzDomain.getDomain().getEnabled() == Boolean.FALSE) {\n            domainData.setEnabled(false);\n        }\n        if (athenzDomain.getDomain().getAuditEnabled() == Boolean.TRUE) {\n            domainData.setAuditEnabled(true);\n        }\n        domainData.setAccount(athenzDomain.getDomain().getAccount());\n        domainData.setYpmId(athenzDomain.getDomain().getYpmId());\n        domainData.setApplicationId(athenzDomain.getDomain().getApplicationId());\n        domainData.setSignAlgorithm(athenzDomain.getDomain().getSignAlgorithm());\n        if (athenzDomain.getDomain().getServiceCertExpiryMins() != null) {\n            domainData.setServiceCertExpiryMins(athenzDomain.getDomain().getServiceCertExpiryMins());\n        }\n        if (athenzDomain.getDomain().getRoleCertExpiryMins() != null) {\n            domainData.setRoleCertExpiryMins(athenzDomain.getDomain().getRoleCertExpiryMins());\n        }\n        if (athenzDomain.getDomain().getTokenExpiryMins() != null) {\n            domainData.setTokenExpiryMins(athenzDomain.getDomain().getTokenExpiryMins());\n        }\n\n        // set the roles and services\n\n        domainData.setRoles(athenzDomain.getRoles());\n        domainData.setServices(athenzDomain.getServices());\n\n        // generate the domain policy object that includes the domain\n        // name and all policies. Then we'll sign this struct using\n        // server's private key to get signed policy object\n        \n        DomainPolicies domainPolicies = new DomainPolicies().setDomain(domainName);\n        domainPolicies.setPolicies(getPolicyListWithoutAssertionId(athenzDomain.getPolicies()));\n        SignedPolicies signedPolicies = new SignedPolicies();\n        signedPolicies.setContents(domainPolicies);\n        domainData.setPolicies(signedPolicies);\n\n        String signature = Crypto.sign(\n                SignUtils.asCanonicalString(signedPolicies.getContents()), privateKey.getKey());\n        signedPolicies.setSignature(signature).setKeyId(privateKey.getId());\n\n        // then sign the data and set the data and signature in a SignedDomain\n        \n        signature = Crypto.sign(SignUtils.asCanonicalString(domainData), privateKey.getKey());\n        signedDomain.setSignature(signature).setKeyId(privateKey.getId());\n        return signedDomain;\n    }\n    \n    public Response getSignedDomains(ResourceContext ctx, String domainName, String metaOnly,\n            String metaAttr, String matchingTag) {\n\n        final String caller = \"getsigneddomains\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        metric.increment(ZMSConsts.HTTP_REQUEST);\n        metric.increment(caller);\n        final String principalDomain = getPrincipalDomain(ctx);\n        Object timerMetric = metric.startTiming(\"getsigneddomains_timing\", null, principalDomain);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n\n        if (domainName != null) {\n            domainName = domainName.toLowerCase();\n            validate(domainName, TYPE_DOMAIN_NAME, caller);\n        }\n        if (metaAttr != null) {\n            metaAttr = metaAttr.toLowerCase();\n            validate(metaAttr, TYPE_SIMPLE_NAME, caller);\n        }\n        \n        boolean setMetaDataOnly = ZMSUtils.parseBoolean(metaOnly, false);\n        long timestamp = getModTimestamp(matchingTag);\n        \n        // if this is one of our system principals then we're going to\n        // to use the master copy instead of read-only replicas\n        // unless we're configured to always use read-only replicas\n        // for all signed domain operations\n        \n        Principal principal = ((RsrcCtxWrapper) ctx).principal();\n        boolean masterCopy = useMasterCopyForSignedDomains && principal.getFullName().startsWith(\"sys.\");\n        \n        // if we're given a specific domain then we don't need to\n        // retrieve the list of modified domains\n        \n        List<SignedDomain> sdList = new ArrayList<>();\n        Long youngestDomMod = -1L;\n\n        if (domainName != null && !domainName.isEmpty()) {\n        \n            Domain domain = null;\n            try {\n                domain = dbService.getDomain(domainName, masterCopy);\n            } catch (ResourceException ex) {\n                \n                // in case the domain does not exist we're just\n                // going to return an empty set\n                \n                if (ex.getCode() != ResourceException.NOT_FOUND) {\n                    throw ex;\n                }\n            }\n\n            if (domain != null) {\n                youngestDomMod = domain.getModified().millis();\n\n                if (timestamp != 0 && youngestDomMod <= timestamp) {\n                    EntityTag eTag = new EntityTag(domain.getModified().toString());\n                    return Response.status(ResourceException.NOT_MODIFIED)\n                            .header(\"ETag\", eTag.toString()).build();\n                }\n                \n                // generate our signed domain object\n                \n                SignedDomain signedDomain = retrieveSignedDomain(domain, metaAttr, setMetaDataOnly, masterCopy);\n                \n                if (signedDomain != null) {\n                    sdList.add(signedDomain);\n                }\n            } else {\n                youngestDomMod = System.currentTimeMillis();\n            }\n            \n        } else {\n\n            // if we don't have a domain name then the meta flag must\n            // be set to true otherwise it's expensive to fetch all\n            // domains and sign all domains into a single response\n            // unless the request is from a system service\n\n            if (!setMetaDataOnly && !masterCopy)  {\n                return Response.status(ResourceException.BAD_REQUEST).build();\n            }\n\n            // we should get our matching tag before calling get modified list\n            // in case we get a domain added/updated right after an empty domain list\n            // was returned and before the matchingTag was set to a value\n            \n            if (matchingTag == null) {\n                EntityTag eTag = new EntityTag(Timestamp.fromMillis(0).toString());\n                matchingTag = eTag.toString();\n            }\n            \n            DomainModifiedList dmlist = dbService.listModifiedDomains(timestamp);\n            List<DomainModified> modlist = dmlist.getNameModList();\n            if (modlist == null || modlist.size() == 0) {\n                return Response.status(ResourceException.NOT_MODIFIED)\n                        .header(\"ETag\", matchingTag).build();\n            }\n            \n            // now we can iterate through our list and retrieve each domain\n\n            //noinspection ConstantConditions\n            for (DomainModified dmod : modlist) {\n                \n                Long domModMillis = dmod.getModified();\n                if (domModMillis.compareTo(youngestDomMod) > 0) {\n                    youngestDomMod = domModMillis;\n                }\n                \n                // generate our signed domain object\n                \n                SignedDomain signedDomain = retrieveSignedDomain(dmod, metaAttr, setMetaDataOnly, masterCopy);\n                \n                // it's possible that our domain was deleted by another\n                // thread while we were processing this request so\n                // if we get a null object, we'll just skip this\n                // item and continue with the next one\n                \n                if (signedDomain == null) {\n                    continue;\n                }\n                \n                // we have a valid domain so we'll add it to our return list\n                \n                sdList.add(signedDomain);\n            }\n        }\n\n        SignedDomains sdoms = new SignedDomains();\n        sdoms.setDomains(sdList);\n\n        Timestamp youngest = Timestamp.fromMillis(youngestDomMod);\n        EntityTag eTag = new EntityTag(youngest.toString());\n\n        metric.stopTiming(timerMetric, null, principalDomain);\n        return Response.status(ResourceException.OK).entity(sdoms)\n                .header(\"ETag\", eTag.toString()).build();\n    }\n    \n    List<Policy> getPolicyListWithoutAssertionId(List<Policy> policies) {\n        \n        if (policies == null) {\n            return null;\n        }\n        \n        // we are going to remove the assertion id from our assertions\n        // since the data is signed and the clients don't need to be\n        // updated due to this new attribute being returned\n        \n        List<Policy> policyList = new ArrayList<>();\n\n        for (Policy policy : policies) {\n            Policy newPolicy = new Policy()\n                    .setModified(policy.getModified())\n                    .setName(policy.getName());\n            if (policy.getAssertions() != null) {\n                List<Assertion> assertions = new ArrayList<>();\n                for (Assertion assertion : policy.getAssertions()) {\n                    Assertion newAssertion = new Assertion()\n                            .setAction(assertion.getAction())\n                            .setResource(assertion.getResource())\n                            .setRole(assertion.getRole());\n                    if (assertion.getEffect() != null) {\n                        newAssertion.setEffect(assertion.getEffect());\n                    } else {\n                        newAssertion.setEffect(AssertionEffect.ALLOW);\n                    }\n                    assertions.add(newAssertion);\n                }\n                newPolicy.setAssertions(assertions);\n            }\n            policyList.add(newPolicy);\n        }\n        return policyList;\n    }\n\n    boolean isValidUserTokenRequest(Principal principal, String userName) {\n        \n        if (principal == null) {\n            return false;\n        }\n\n        Authority authority = principal.getAuthority();\n        if (authority == null) {\n            return false;\n        }\n\n        // if authority allowed to carry out authorization checks there\n        // is no need to request user tokens\n        \n        if (authority.allowAuthorization()) {\n            if (LOG.isDebugEnabled()) {\n                LOG.debug(\"User Token request - Authority cannot request user tokens\");\n            }\n            return false;\n        }\n        \n        String authDomain = authority.getDomain();\n        if (authDomain == null || !authDomain.equalsIgnoreCase(userDomain)) {\n            if (LOG.isDebugEnabled()) {\n                LOG.debug(\"User Token request - not authenticated by User Authority\");\n            }\n            return false;\n        }\n\n        // if the username is not our pre-defined skip value we are going\n        // to verify that it matches to the principal's name\n        \n        if (userName.equalsIgnoreCase(USER_TOKEN_DEFAULT_NAME)) {\n            return true;\n        }\n        \n        if (!userName.equalsIgnoreCase(principal.getName())) {\n            if (LOG.isDebugEnabled()) {\n                LOG.debug(\"User Token request - mismatch between request user name and userid\");\n            }\n            return false;\n        }\n        \n        return true;\n    }\n    \n    @Override\n    public UserToken getUserToken(ResourceContext ctx, String userName, String authorizedServices,\n            Boolean header) {\n\n        final String caller = \"getusertoken\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        metric.increment(ZMSConsts.HTTP_REQUEST);\n        metric.increment(caller);\n        final String principalDomain = getPrincipalDomain(ctx);\n        Object timerMetric = metric.startTiming(\"getusertoken_timing\", null, principalDomain);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        userName = userName.toLowerCase();\n        \n        Principal principal = ((RsrcCtxWrapper) ctx).principal();\n        if (!isValidUserTokenRequest(principal, userName)) {\n            throw ZMSUtils.unauthorizedError(\"getUserToken: Invalid request - missing User credentials or userName mismatch\", caller);\n        }\n\n        // if the user is requesting authorized services we need to verify that\n        // all the service names are valid\n        \n        List<String> services = null;\n        if (authorizedServices != null && !authorizedServices.isEmpty()) {\n            services = Arrays.asList(authorizedServices.split(\",\"));\n            for (String service : services) {\n                if (!serverAuthorizedServices.contains(service)) {\n                    throw ZMSUtils.unauthorizedError(\"getUserToken: Service \" + service + \" is not authorized in ZMS\", caller);\n                }\n            }\n        }\n        \n        PrincipalToken token = new PrincipalToken.Builder(\"U1\", userDomain, principal.getName())\n            .expirationWindow(userTokenTimeout).keyId(privateKey.getId()).host(serverHostName)\n            .ip(ServletRequestUtil.getRemoteAddress(ctx.request())).authorizedServices(services).build();\n        \n        token.sign(privateKey.getKey());\n        UserToken userToken = new UserToken().setToken(token.getSignedToken());\n        \n        if (header == Boolean.TRUE && principalAuthority != null) {\n            userToken.setHeader(principalAuthority.getHeader());\n        }\n        \n        // set our standard CORS headers in our response if we're processing\n        // a get user token for an authorized service\n        \n        if (services != null)  {\n            setStandardCORSHeaders(ctx);\n        }\n\n        metric.stopTiming(timerMetric, null, principalDomain);\n        return userToken;\n    }\n\n    public UserToken optionsUserToken(ResourceContext ctx, String userName, String authorizedServices) {\n\n        final String caller = \"optionsusertoken\";\n        metric.increment(ZMSConsts.HTTP_OPTIONS);\n        metric.increment(ZMSConsts.HTTP_REQUEST);\n        metric.increment(caller);\n        final String principalDomain = getPrincipalDomain(ctx);\n        Object timerMetric = metric.startTiming(\"optionsusertoken_timing\", null, principalDomain);\n        \n        validateRequest(ctx.request(), caller);\n\n        // if the user must be requesting authorized service token\n        \n        if (authorizedServices == null || authorizedServices.isEmpty()) {\n            throw ZMSUtils.requestError(\"optionsUserToken: No authorized services specified in the request\", caller);\n        }\n        \n        // verify that all specified services are valid\n        \n        String[] services = authorizedServices.split(\",\");\n        for (String service : services) {\n            if (!serverAuthorizedServices.contains(service)) {\n                throw ZMSUtils.requestError(\"optionsUserToken: Service \" + service + \" is not authorized in ZMS\", caller);\n            }\n        }\n        \n        // set our standard CORS headers in our response\n        \n        setStandardCORSHeaders(ctx);\n        \n        // since this is the preflight request we are going to report that\n        // we only allow GET method and configure the user-agent to cache\n        // this request results for up-to 30 days\n        \n        ctx.response().addHeader(ZMSConsts.HTTP_ACCESS_CONTROL_ALLOW_METHODS, ZMSConsts.HTTP_GET);\n        ctx.response().addHeader(ZMSConsts.HTTP_ACCESS_CONTROL_MAX_AGE, \"2592000\");\n        \n        metric.stopTiming(timerMetric, null, principalDomain);\n        return null;\n    }\n\n    boolean isValidCORSOrigin(final String origin) {\n\n        // first check for non-empty origin value\n\n        if (origin == null || origin.isEmpty()) {\n            return false;\n        }\n\n        // check if we have whitelist configured\n\n        if (corsOriginList == null || corsOriginList.isEmpty()) {\n            return true;\n        }\n\n        return corsOriginList.contains(origin);\n    }\n\n    void setStandardCORSHeaders(ResourceContext ctx) {\n\n        // if we get an Origin header in our request then we're going to return\n        // the same value in the Allow-Origin header\n        \n        String origin = ctx.request().getHeader(ZMSConsts.HTTP_ORIGIN);\n        if (isValidCORSOrigin(origin)) {\n            ctx.response().addHeader(ZMSConsts.HTTP_ACCESS_CONTROL_ALLOW_ORIGIN, origin);\n        }\n        \n        // we must allow credentials to be passed by the client\n        \n        ctx.response().addHeader(ZMSConsts.HTTP_ACCESS_CONTROL_ALLOW_CREDENTIALS, \"true\");\n        \n        // if the client is asking us to allow any headers then we're going\n        // to return that set back as allowed\n        \n        String allowHeaders = ctx.request().getHeader(ZMSConsts.HTTP_ACCESS_CONTROL_REQUEST_HEADERS);\n        if (allowHeaders != null && !allowHeaders.isEmpty()) {\n            ctx.response().addHeader(ZMSConsts.HTTP_ACCESS_CONTROL_ALLOW_HEADERS, allowHeaders);\n        }\n    }\n\n    String providerServiceDomain(String provider) {\n        int n = provider.lastIndexOf('.');\n        if (n <= 0 || n == provider.length() - 1) {\n            return null;\n        }\n        return provider.substring(0, n);\n    }\n    \n    String providerServiceName(String provider) {\n        int n = provider.lastIndexOf('.');\n        if (n <= 0 || n == provider.length() - 1) {\n            return null;\n        }\n        return provider.substring(n + 1);\n    }\n\n    @Override\n    public void putTenancy(ResourceContext ctx, String tenantDomain, String provider,\n            String auditRef, Tenancy detail) {\n\n        final String caller = \"puttenancy\";\n        metric.increment(ZMSConsts.HTTP_PUT);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        validate(tenantDomain, TYPE_DOMAIN_NAME, caller);\n        validate(provider, TYPE_SERVICE_NAME, caller); //the fully qualified service name to provision on\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        tenantDomain = tenantDomain.toLowerCase();\n        provider = provider.toLowerCase();\n        AthenzObject.TENANCY.convertToLowerCase(detail);\n\n        // validate our detail object against uri components\n\n        if (!validateTenancyObject(detail, tenantDomain, provider)) {\n            throw ZMSUtils.requestError(\"Invalid tenancy object\", caller);\n        }\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, tenantDomain, principalDomain);\n        metric.increment(caller, tenantDomain, principalDomain);\n        Object timerMetric = metric.startTiming(\"puttenancy_timing\", tenantDomain, principalDomain);\n\n        // verify that request is properly authenticated for this request\n        \n        String authorizedService = ((RsrcCtxWrapper) ctx).principal().getAuthorizedService();\n        verifyAuthorizedServiceOperation(authorizedService, caller);\n\n        String provSvcDomain = providerServiceDomain(provider); // provider service domain\n        String provSvcName = providerServiceName(provider); // provider service name\n\n        // we can't have the provider and tenant be in the same domain\n        // as we don't allow delegation of roles onto themselves\n\n        if (provSvcDomain.equals(tenantDomain)) {\n            throw ZMSUtils.requestError(\"Provider and tenant domains cannot be the same\", caller);\n        }\n\n        if (dbService.getServiceIdentity(provSvcDomain, provSvcName, true) == null) {\n            throw ZMSUtils.notFoundError(\"Unable to retrieve service=\" + provider, caller);\n        }\n\n        // we are going to allow the authorize service token owner to call\n        // put tenancy on its own service\n\n        boolean authzServiceTokenOperation = isAuthorizedProviderService(authorizedService,\n                provSvcDomain, provSvcName);\n\n        if (authorizedService != null && !authzServiceTokenOperation) {\n            throw ZMSUtils.requestError(\"Authorized service provider mismatch: \"\n                    + provider + \"/\" + authorizedService, caller);\n        }\n\n        // set up our tenant admin policy so provider can check admin's access\n        \n        dbService.setupTenantAdminPolicy(tenantDomain, provSvcDomain,\n                provSvcName, auditRef, caller);\n        \n        // if this is an authorized service token request then we're going to create\n        // the corresponding admin role in the provider domain since that's been\n        // authenticated already\n        \n        if (authzServiceTokenOperation) {\n            setupTenantAdminPolicyInProvider(ctx, provSvcDomain, provSvcName, tenantDomain,\n                    auditRef, caller);\n        }\n\n        metric.stopTiming(timerMetric, tenantDomain, principalDomain);\n    }\n\n    @Override\n    public void deleteTenancy(ResourceContext ctx, String tenantDomain, String provider, String auditRef) {\n        \n        final String caller = \"deletetenancy\";\n        metric.increment(ZMSConsts.HTTP_DELETE);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        validate(tenantDomain, TYPE_DOMAIN_NAME, caller);\n        validate(provider, TYPE_SERVICE_NAME, caller); // fully qualified provider's service name\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        tenantDomain = tenantDomain.toLowerCase();\n        provider = provider.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, tenantDomain, principalDomain);\n        metric.increment(caller, tenantDomain, principalDomain);\n        Object timerMetric = metric.startTiming(\"deletetenancy_timing\", tenantDomain, principalDomain);\n\n        // verify that request is properly authenticated for this request\n        \n        String authorizedService = ((RsrcCtxWrapper) ctx).principal().getAuthorizedService();\n        verifyAuthorizedServiceOperation(authorizedService, caller);\n\n        // make sure we have a valid provider service\n        \n        String provSvcDomain = providerServiceDomain(provider);\n        String provSvcName   = providerServiceName(provider);\n\n        if (dbService.getServiceIdentity(provSvcDomain, provSvcName, true) == null) {\n            throw ZMSUtils.notFoundError(\"Unable to retrieve service: \" + provider, caller);\n        }\n\n        // we are going to allow the authorize service token owner to call\n        // delete tenancy on its own service without configuring a controller\n        // end point\n        \n        boolean authzServiceTokenOperation = isAuthorizedProviderService(authorizedService,\n            provSvcDomain, provSvcName);\n        \n        if (authzServiceTokenOperation) {\n            dbService.executeDeleteTenantRoles(ctx, provSvcDomain, provSvcName, tenantDomain, null,\n                auditRef, caller);\n        }\n\n        // now clean-up local domain roles and policies for this tenant\n        \n        dbService.executeDeleteTenancy(ctx, tenantDomain, provSvcDomain, provSvcName,\n                null, auditRef, caller);\n\n        metric.stopTiming(timerMetric, tenantDomain, principalDomain);\n    }\n\n    @Override\n    public void putTenant(ResourceContext ctx, String providerDomain, String providerService,\n           String tenantDomain, String auditRef, Tenancy detail) {\n\n        final String caller = \"puttenant\";\n        metric.increment(ZMSConsts.HTTP_PUT);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        validate(providerDomain, TYPE_DOMAIN_NAME, caller);\n        validate(providerService, TYPE_SIMPLE_NAME, caller);\n        validate(tenantDomain, TYPE_DOMAIN_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n\n        providerDomain = providerDomain.toLowerCase();\n        providerService = providerService.toLowerCase();\n        tenantDomain = tenantDomain.toLowerCase();\n        AthenzObject.TENANCY.convertToLowerCase(detail);\n\n        // we can't have the provider and tenant be in the same domain\n        // as we don't allow delegation of roles onto themselves\n\n        if (providerDomain.equals(tenantDomain)) {\n            throw ZMSUtils.requestError(\"Provider and tenant domains cannot be the same\", caller);\n        }\n\n        // validate our detail object against uri components\n\n        if (!validateTenancyObject(detail, tenantDomain, providerDomain + \".\" + providerService)) {\n            throw ZMSUtils.requestError(\"Invalid tenancy object\", caller);\n        }\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, providerDomain, principalDomain);\n        metric.increment(caller, providerDomain, principalDomain);\n        Object timerMetric = metric.startTiming(\"puttenant_timing\", providerDomain, principalDomain);\n\n        // verify that request is properly authenticated for this request\n\n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(), caller);\n\n        if (dbService.getServiceIdentity(providerDomain, providerService, true) == null) {\n            throw ZMSUtils.notFoundError(\"Unable to retrieve service=\" + providerService, caller);\n        }\n\n        setupTenantAdminPolicyInProvider(ctx, providerDomain, providerService, tenantDomain,\n                auditRef, caller);\n\n        metric.stopTiming(timerMetric, providerDomain, principalDomain);\n    }\n\n    @Override\n    public void deleteTenant(ResourceContext ctx, String providerDomain, String providerService,\n            String tenantDomain, String auditRef) {\n\n        final String caller = \"deletetenant\";\n        metric.increment(ZMSConsts.HTTP_DELETE);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        validate(providerDomain, TYPE_DOMAIN_NAME, caller);\n        validate(providerService, TYPE_SIMPLE_NAME, caller);\n        validate(tenantDomain, TYPE_DOMAIN_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n\n        providerDomain = providerDomain.toLowerCase();\n        providerService = providerService.toLowerCase();\n        tenantDomain = tenantDomain.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, providerDomain, principalDomain);\n        metric.increment(caller, providerDomain, principalDomain);\n        Object timerMetric = metric.startTiming(\"deletetenant_timing\", providerDomain, principalDomain);\n\n        // verify that request is properly authenticated for this request\n\n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(), caller);\n\n        if (dbService.getServiceIdentity(providerDomain, providerService, true) == null) {\n            throw ZMSUtils.notFoundError(\"Unable to retrieve service=\" + providerService, caller);\n        }\n\n        dbService.executeDeleteTenantRoles(ctx, providerDomain, providerService, tenantDomain,\n                null, auditRef, caller);\n\n        metric.stopTiming(timerMetric, providerDomain, principalDomain);\n    }\n\n    boolean validateTenancyObject(Tenancy tenant, final String tenantDomain, final String providerService) {\n\n        if (!tenant.getDomain().equals(tenantDomain)) {\n            return false;\n        }\n        return tenant.getService().equals(providerService);\n    }\n\n    boolean validateTenantResourceGroupRolesObject(TenantResourceGroupRoles roles, final String providerDomain,\n            final String providerService, final String tenantDomain, final String resourceGroup) {\n\n        if (!providerDomain.equals(roles.getDomain())) {\n            return false;\n        }\n        if (!providerService.equals(roles.getService())) {\n            return false;\n        }\n        if (!tenantDomain.equals(roles.getTenant())) {\n            return false;\n        }\n        if (!resourceGroup.equals(roles.getResourceGroup())) {\n            return false;\n        }\n\n        // we must have at least one role in the object\n\n        List<TenantRoleAction> list = roles.getRoles();\n        return (list != null && list.size() > 0);\n    }\n\n    boolean validateProviderResourceGroupRolesObject(ProviderResourceGroupRoles roles, final String providerDomain,\n            final String providerService, final String tenantDomain, final String resourceGroup) {\n\n        if (!providerDomain.equals(roles.getDomain())) {\n            return false;\n        }\n        if (!providerService.equals(roles.getService())) {\n            return false;\n        }\n        if (!tenantDomain.equals(roles.getTenant())) {\n            return false;\n        }\n        if (!resourceGroup.equals(roles.getResourceGroup())) {\n            return false;\n        }\n\n        // we must have at least one role in the object\n\n        List<TenantRoleAction> list = roles.getRoles();\n        return (list != null && list.size() > 0);\n    }\n\n    // put the trust roles into provider domain\n    //\n    @Override\n    public TenantResourceGroupRoles putTenantResourceGroupRoles(ResourceContext ctx, String provSvcDomain,\n            String provSvcName, String tenantDomain, String resourceGroup, String auditRef,\n            TenantResourceGroupRoles detail) {\n\n        final String caller = \"puttenantresourcegrouproles\";\n        metric.increment(ZMSConsts.HTTP_PUT);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        validate(provSvcDomain, TYPE_DOMAIN_NAME, caller);\n        validate(provSvcName, TYPE_SIMPLE_NAME, caller); //not including the domain, this is the domain's service\n        validate(tenantDomain, TYPE_DOMAIN_NAME, caller);\n        validate(detail, TYPE_TENANT_RESOURCE_GROUP_ROLES, caller);\n        validate(resourceGroup, TYPE_COMPOUND_NAME, caller);\n        \n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        provSvcDomain = provSvcDomain.toLowerCase();\n        provSvcName = provSvcName.toLowerCase();\n        tenantDomain = tenantDomain.toLowerCase();\n        resourceGroup = resourceGroup.toLowerCase();\n        AthenzObject.TENANT_RESOURCE_GROUP_ROLES.convertToLowerCase(detail);\n\n        // we can't have the provider and tenant be in the same domain\n        // as we don't allow delegation of roles onto themselves\n\n        if (provSvcDomain.equals(tenantDomain)) {\n            throw ZMSUtils.requestError(\"Provider and tenant domains cannot be the same\", caller);\n        }\n\n        // validate our detail object against uri components\n\n        if (!validateTenantResourceGroupRolesObject(detail, provSvcDomain, provSvcName, tenantDomain,\n                resourceGroup)) {\n            throw ZMSUtils.requestError(\"Invalid tenant resource group role object\", caller);\n        }\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, provSvcDomain, principalDomain);\n        metric.increment(caller, provSvcDomain, principalDomain);\n        Object timerMetric = metric.startTiming(\"puttenantresourcegrouproles_timing\", provSvcDomain, principalDomain);\n        \n        // verify that request is properly authenticated for this request\n        \n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(), caller);\n        \n        if (LOG.isInfoEnabled()) {\n            LOG.info(\"putTenantResourceGroupRoles: ==== putTenantRoles(domain=\" + provSvcDomain + \", service=\" +\n                provSvcName + \", tenant-domain=\" + tenantDomain + \", resource-group=\" + resourceGroup +\n                \", detail=\" + detail + \")\");\n        }\n\n        // first setup the domain as a tenant in the provider domain\n\n        setupTenantAdminPolicyInProvider(ctx, provSvcDomain, provSvcName, tenantDomain,\n                auditRef, caller);\n\n        // then setup the requested resource group roles\n\n        dbService.executePutTenantRoles(ctx, provSvcDomain, provSvcName, tenantDomain,\n                resourceGroup, detail.getRoles(), auditRef, caller);\n        metric.stopTiming(timerMetric, provSvcDomain, principalDomain);\n        return detail;\n    }\n\n    @SuppressWarnings(\"ConstantConditions\")\n    public DomainDataCheck getDomainDataCheck(ResourceContext ctx, String domainName) {\n        \n        final String caller = \"getdomaindatacheck\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        \n        domainName = domainName.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"getdomaindatacheck_timing\", domainName, principalDomain);\n        \n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"getDomainDataCheck: domain=\" + domainName);\n        }\n\n        AthenzDomain domain = getAthenzDomain(domainName, false);\n        if (domain == null) {\n            throw ZMSUtils.notFoundError(\"getDomainDataCheck: Domain not found: '\" + domainName + \"'\", caller);\n        }\n\n        // build set of roles\n        // iterate them to look for trust roles - in case this is a provider domain\n        \n        Set<String> roleSet      = new HashSet<>();\n        Set<String> trustRoleSet = new HashSet<>();\n\n        // map per trust/tenant domain that contains the trust roles\n        \n        Map<String, Set<String>> trustRoleMap = new HashMap<>();\n        for (Role role : domain.getRoles()) {\n            if (LOG.isDebugEnabled()) {\n                LOG.debug(\"getDomainDataCheck: processing role - \" + role.getName());\n            }\n            roleSet.add(role.getName());\n            String roleName = ZMSUtils.removeDomainPrefix(role.getName(), domainName, ROLE_PREFIX);\n            String trustDomain = role.getTrust();\n            if (trustDomain != null) {\n                if (LOG.isDebugEnabled()) {\n                    LOG.debug(\"trust role for domain: \" + trustDomain);\n                }\n                trustRoleSet.add(trustDomain);\n                Set<String> tset = trustRoleMap.computeIfAbsent(trustDomain, k -> new HashSet<>());\n                tset.add(roleName);\n            }\n        }\n\n        // look for dangling roles and policies\n        //\n        int assertionCount = 0;\n        int roleWildcardCount = 0;\n        Set<String> usedRoleSet = new HashSet<>(); // keep track of roles used by policies\n        Set<String> providerSet = new HashSet<>(); // keep track of providers from assume_role policies\n\n        // assume_role resources are placed into the set per provider service domain\n        \n        Map<String, Set<String>> svcRoleMap = new HashMap<>();\n        List<DanglingPolicy> danglingPolicies = new ArrayList<>();\n        List<Policy> policies = domain.getPolicies();\n        for (Policy policy : policies) {\n            String pname = ZMSUtils.removeDomainPrefix(policy.getName(), domainName, POLICY_PREFIX);\n            if (LOG.isDebugEnabled()) {\n                LOG.debug(\"getDomainDataCheck: processing policy=\" + pname + \" in domain=\" + domainName);\n            }\n\n            List<Assertion> assertions = policy.getAssertions();\n            if (assertions == null) {\n                continue;\n            }\n            \n            for (Assertion assertion : assertions) {\n                assertionCount++;\n                if (ZMSConsts.ACTION_ASSUME_ROLE.equalsIgnoreCase(assertion.getAction())) {\n                    // get provider domain+service name and add to set of providers\n                    // Note there may be a resource appended - to be dealt with later\n                    // ex: testgetdomaindatacheck:policy.tenancy.testgetdomaindatacheckprovider.storage.reader\n                    // ex: testgetdomaindatacheck:policy.tenancy.testgetdomaindatacheckprovider.sub.storage.res_group.ravers.reader\n                    // index after \"tenancy.\" and index of last dot\n                    int index = pname.indexOf(\"tenancy.\");\n                    if (index == -1) {\n                        continue;\n                    }\n                    int lindex = pname.lastIndexOf('.');\n                    if (lindex == -1) {\n                        continue;\n                    }\n                    String provSvcDomain = pname.substring(index + \"tenancy.\".length(), lindex);\n                    providerSet.add(provSvcDomain);\n\n                    // lets collect the resource field that is name of role in provider\n                    // ex: testgetdomaindatacheckprovider.sub:role.storage.tenant.testgetdomaindatacheck.reader\n                    // ex: testgetdomaindatacheckprovider.sub:role.storage.tenant.testgetdomaindatacheck.res_group.ravers.reader\n                    String rsrc = assertion.getResource();\n                    Set<String> rset = svcRoleMap.computeIfAbsent(provSvcDomain, k -> new HashSet<>());\n                    rset.add(rsrc);\n                }\n\n                String roleName = assertion.getRole();\n\n                // check for wildcard role\n                if (roleName.lastIndexOf('*') != -1) {\n                    roleWildcardCount++;\n                    // make sure there is at least 1 role that can match\n                    // this wildcard - else its a dangling policy\n                    String rolePattern = StringUtils.patternFromGlob(roleName);\n                    boolean wildCardMatch = false;\n                    for (String role: roleSet) {\n                        if (role.matches(rolePattern)) {\n                            wildCardMatch = true;\n                            break;\n                        }\n                    }\n                    if (!wildCardMatch) { // dangling policy\n                        DanglingPolicy dp = new DanglingPolicy();\n                        // we need to remove the domain:role. and domain:policy prefixes\n                        // according to RDL definitions for role and policy names\n                        dp.setRoleName(ZMSUtils.removeDomainPrefix(roleName, domainName, ROLE_PREFIX));\n                        dp.setPolicyName(ZMSUtils.removeDomainPrefix(pname, domainName, POLICY_PREFIX));\n                        danglingPolicies.add(dp);\n                    }\n                } else if (roleSet.contains(roleName)) {\n                    usedRoleSet.add(roleName);\n                } else { // dangling policy\n                    DanglingPolicy dp = new DanglingPolicy();\n                    // we need to remove the domain:role. and domain:policy prefixes\n                    // according to RDL definitions for role and policy names\n                    dp.setRoleName(ZMSUtils.removeDomainPrefix(roleName, domainName, ROLE_PREFIX));\n                    dp.setPolicyName(ZMSUtils.removeDomainPrefix(pname, domainName, POLICY_PREFIX));\n                    danglingPolicies.add(dp);\n                }\n            }\n        }\n\n        DomainDataCheck ddc = new DomainDataCheck();\n        ddc.setPolicyCount(policies.size());\n        ddc.setAssertionCount(assertionCount);\n        ddc.setRoleWildCardCount(roleWildcardCount);\n        if (!danglingPolicies.isEmpty()) {\n            ddc.setDanglingPolicies(danglingPolicies);\n        }\n\n        if (roleSet.size() != usedRoleSet.size()) {\n            // oh oh, some roles are unused - need to subtract the usedRoleSet\n            // from roleSet - the leftovers are the unused roles\n            roleSet.removeAll(usedRoleSet);\n            // we need to remove the domain:role. prefix according to\n            // RDL definition for dangling role names\n            List<String> danglingRoleList = new ArrayList<>();\n            for (String roleName : roleSet) {\n                danglingRoleList.add(ZMSUtils.removeDomainPrefix(roleName, domainName, ROLE_PREFIX));\n            }\n            ddc.setDanglingRoles(danglingRoleList);\n        }\n\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"getDomainDataCheck: domain=\" + domainName +\n                \" policy-count=\" + policies.size() + \" assertion-count=\" +\n                assertionCount + \" wildcard-count==\" + roleWildcardCount +\n                \" dangling-policies=\" + danglingPolicies.size() +\n                \" dangling-roles=\" + roleSet.size());\n        }\n\n        // Tenant Domain Check: does each provider fully support this tenant?\n        // collect Service names (domain.service) for domains that don't contain\n        // trust role\n        List<String> provsWithoutTrust = new ArrayList<>();\n        for (String provSvc : providerSet) {\n            if (LOG.isDebugEnabled()) {\n                LOG.debug(\"getDomainDataCheck: domain=\" + domainName +\n                    \" provider-service=\" + provSvc);\n            }\n\n            // 2 cases to resolve, one with resource group, one without\n            // ex: iaas.stuff.storage.read\n            // ex: iaas.stuff.storage.res_group.my_resource_group.read\n            \n            int idx = provSvc.indexOf(\".res_group.\");\n            String provSvcDomain;\n            if (idx == -1) {\n                provSvcDomain = providerServiceDomain(provSvc);\n            } else {\n                provSvcDomain = providerServiceDomain(provSvc.substring(0, idx));\n            }\n            \n            AthenzDomain providerDomain = getAthenzDomain(provSvcDomain, true);\n            Set<String> rset = svcRoleMap.get(provSvc);\n            if (rset == null || rset.isEmpty() || providerDomain == null) {\n                provsWithoutTrust.add(provSvc);\n                continue;\n            }\n            \n            // find trust role in the provider that contains the tenant domain\n            int foundTrust = 0;\n            for (Role role : providerDomain.getRoles()) {\n                String trustDomain = role.getTrust();\n                if (trustDomain != null) {\n                    if (domainName.equals(trustDomain)) {\n                        // is this role a match for an assume role in the tenant\n                        // look for the role in the role set for this service\n                        if (rset.contains(role.getName())) {\n                            foundTrust++;\n                        }\n                    }\n                }\n            }\n            if (foundTrust != rset.size()) {\n                provsWithoutTrust.add(provSvc);\n            }\n        }\n        if (!provsWithoutTrust.isEmpty()) {\n            ddc.setProvidersWithoutTrust(provsWithoutTrust);\n        }\n\n        // Provider Domain Check: does each tenant have all the assume_role\n        // assertions to match each trust role.\n\n        // tenantsWithoutProv: names of Tenant domains that don't contain assume\n        // role assertions if this is a provider domain\n        List<String> tenantsWithoutProv = new ArrayList<>();\n\n        // tenantDomMap: optimize reading tenant domains once already read\n        // This is optimizing for Providers with lots of tenants.\n        Map<String, AthenzDomain> tenantDomMap = new HashMap<>();\n        for (String trustRole: trustRoleSet) {\n            \n            if (LOG.isDebugEnabled()) {\n                LOG.debug(\"getDomainDataCheck: processing trust role: \" + trustRole);\n            }\n            \n            AthenzDomain tenantDomain = tenantDomMap.get(trustRole);\n            if (tenantDomain == null) {\n                tenantDomain = getAthenzDomain(trustRole, true);\n                if (tenantDomain == null) {\n                    tenantsWithoutProv.add(trustRole);\n                    continue;\n                } else {\n                    tenantDomMap.put(trustRole, tenantDomain);\n                }\n            }\n\n            // Get set of providers trust roles for trust/tenant domain.\n            Set<String> tset = trustRoleMap.get(trustRole);\n            if (tset == null || tset.isEmpty()) {\n                tenantsWithoutProv.add(trustRole);\n                continue;\n            }\n\n            int foundProviderCnt = 0;\n\n            // Check for assume_role containing the provider in the tenantDomain\n            for (Policy policy : tenantDomain.getPolicies()) {\n                List<Assertion> assertions = policy.getAssertions();\n                if (assertions == null) {\n                    continue;\n                }\n                for (Assertion assertion : assertions) {\n                    if (ZMSConsts.ACTION_ASSUME_ROLE.equalsIgnoreCase(assertion.getAction())) {\n                        String rsrc = assertion.getResource();\n                        // If the provider domain contains a role that matches\n                        // the tenant domain resource - then the tenant is supported\n                        if (roleSet.contains(rsrc)) {\n                            // HAVE: an assume_role with resource pointing at the provider\n                            foundProviderCnt++;\n                        }\n                    }\n                }\n            }\n            if (foundProviderCnt < tset.size()) {\n                // didn't find all required matching provider trust-role to assume_role-resource pairs\n                tenantsWithoutProv.add(trustRole);\n            }\n        }\n        if (!tenantsWithoutProv.isEmpty()) {\n            ddc.setTenantsWithoutAssumeRole(tenantsWithoutProv);\n        }\n\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n        return ddc;\n    }\n     \n    public void deleteProviderResourceGroupRoles(ResourceContext ctx, String tenantDomain,\n             String provSvcDomain, String provSvcName, String resourceGroup, String auditRef) {\n         \n        final String caller = \"deleteproviderresourcegrouproles\";\n        metric.increment(ZMSConsts.HTTP_DELETE);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n        \n        validateRequest(ctx.request(), caller);\n\n        validate(provSvcDomain, TYPE_DOMAIN_NAME, caller);\n        validate(provSvcName, TYPE_SIMPLE_NAME, caller);\n        validate(tenantDomain, TYPE_DOMAIN_NAME, caller);\n        validate(resourceGroup, TYPE_COMPOUND_NAME, caller);\n        \n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        provSvcDomain = provSvcDomain.toLowerCase();\n        provSvcName = provSvcName.toLowerCase();\n        tenantDomain = tenantDomain.toLowerCase();\n        resourceGroup = resourceGroup.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, provSvcDomain, principalDomain);\n        metric.increment(caller, provSvcDomain, principalDomain);\n        Object timerMetric = metric.startTiming(\"deleteproviderresourcegrouproles_timing\", provSvcDomain, principalDomain);\n        \n        // verify that request is properly authenticated for this request\n        \n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(), caller);\n        \n        // first clean-up local domain roles and policies for this tenant\n        \n        dbService.executeDeleteTenancy(ctx, tenantDomain, provSvcDomain, provSvcName,\n             resourceGroup, auditRef, caller);\n\n        // at this point the tenant side is complete. If the token was a chained\n        // token signed by the provider service then we're going to process the\n        // provider side as well thus complete the tenancy delete process\n        \n        String authorizedService = ((RsrcCtxWrapper) ctx).principal().getAuthorizedService();\n        if (isAuthorizedProviderService(authorizedService, provSvcDomain, provSvcName)) {\n         \n            dbService.executeDeleteTenantRoles(ctx, provSvcDomain, provSvcName, tenantDomain,\n                resourceGroup, auditRef, caller);\n        }\n\n        metric.stopTiming(timerMetric, provSvcDomain, principalDomain);\n    }\n\n    public ProviderResourceGroupRoles getProviderResourceGroupRoles(ResourceContext ctx, String tenantDomain,\n            String provSvcDomain, String provSvcName, String resourceGroup) {\n\n        final String caller = \"getproviderresourcegrouproles\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n        validate(provSvcDomain, TYPE_DOMAIN_NAME, caller);\n        validate(provSvcName, TYPE_SIMPLE_NAME, caller);\n        validate(tenantDomain, TYPE_DOMAIN_NAME, caller);\n        validate(resourceGroup, TYPE_COMPOUND_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n\n        provSvcDomain = provSvcDomain.toLowerCase();\n        provSvcName = provSvcName.toLowerCase();\n        tenantDomain = tenantDomain.toLowerCase();\n        resourceGroup = resourceGroup.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, provSvcDomain, principalDomain);\n        metric.increment(caller, provSvcDomain, principalDomain);\n        Object timerMetric = metric.startTiming(\"getproviderresourcegrouproles_timing\", provSvcDomain, principalDomain);\n\n        if (dbService.getDomain(tenantDomain, false) == null) {\n            throw ZMSUtils.notFoundError(\"No such domain: \" + tenantDomain, caller);\n        }\n\n        // look for this provider roles, ex: storage.tenant.sports.reader\n\n        String rolePrefix = ZMSUtils.getProviderResourceGroupRolePrefix(provSvcDomain, provSvcName, resourceGroup);\n        ProviderResourceGroupRoles provRoles = new ProviderResourceGroupRoles().setDomain(provSvcDomain)\n                .setService(provSvcName).setTenant(tenantDomain).setResourceGroup(resourceGroup);\n\n        List<TenantRoleAction> tralist = new ArrayList<>();\n\n        // find roles matching the prefix\n\n        List<String> rcollection = dbService.listRoles(tenantDomain);\n        for (String rname: rcollection) {\n\n            if (dbService.isTenantRolePrefixMatch(rname, rolePrefix, resourceGroup, null)) {\n\n                // for provider roles we don't have the action, that's\n                // for the provider domain only so we're just going\n                // to return the list of roles without any actions\n                // for the role name we must return the SimpleName\n                // part only so we'll remove the prefix section\n\n                TenantRoleAction tra = new TenantRoleAction()\n                        .setRole(rname.substring(rolePrefix.length()))\n                        .setAction(\"n/a\");\n                tralist.add(tra);\n            }\n        }\n        provRoles.setRoles(tralist);\n\n        metric.stopTiming(timerMetric, provSvcDomain, principalDomain);\n        return provRoles;\n    }\n     \n    boolean isAuthorizedProviderService(String authorizedService, String provSvcDomain,\n             String provSvcName) {\n        \n         // make sure we have a service provided and it matches to our provider\n         \n         if (authorizedService == null) {\n             return false;\n         }\n         \n         if (!authorizedService.equals(provSvcDomain + \".\" + provSvcName)) {\n             return false;\n         }\n         \n         // verify that provider service does indeed have access to provision\n         // its own tenants. the authorize statement for the putTenantRole\n         // command is defined in the RDL as:\n         // authorize (\"UPDATE\", \"{domain}:tenant.{service}\");\n\n         AthenzDomain domain = getAthenzDomain(provSvcDomain, true);\n         if (domain == null) {\n             return false;\n         }\n         \n         // evaluate our domain's roles and policies to see if access\n         // is allowed or not for the given operation and resource\n         \n         String resource = provSvcDomain + \":tenant.\" + provSvcName;\n         AccessStatus accessStatus = evaluateAccess(domain, authorizedService, \"update\",\n                 resource, null, null);\n\n        return accessStatus == AccessStatus.ALLOWED;\n    }\n     \n    /**\n     * This sets up the assume roles in the tenant. If the tenants admin user\n     * token has been authorized by the provider, the providers domain will be\n     * updated as well, thus completing the tenancy on-boarding in a single step.\n    **/\n    @Override\n    public ProviderResourceGroupRoles putProviderResourceGroupRoles(ResourceContext ctx, String tenantDomain,\n             String provSvcDomain, String provSvcName, String resourceGroup, String auditRef,\n             ProviderResourceGroupRoles detail) {\n\n        final String caller = \"putproviderresourcegrouproles\";\n        metric.increment(ZMSConsts.HTTP_PUT);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        validate(provSvcDomain, TYPE_DOMAIN_NAME, caller);\n        validate(provSvcName, TYPE_SIMPLE_NAME, caller); //not including the domain, this is the domain's service\n        validate(tenantDomain, TYPE_DOMAIN_NAME, caller);\n        validate(detail, TYPE_PROVIDER_RESOURCE_GROUP_ROLES, caller);\n        validate(resourceGroup, TYPE_COMPOUND_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        provSvcDomain = provSvcDomain.toLowerCase();\n        provSvcName = provSvcName.toLowerCase();\n        tenantDomain = tenantDomain.toLowerCase();\n        resourceGroup = resourceGroup.toLowerCase();\n        AthenzObject.PROVIDER_RESOURCE_GROUP_ROLES.convertToLowerCase(detail);\n\n        // we can't have the provider and tenant be in the same domain\n        // as we don't allow delegation of roles onto themselves\n\n        if (provSvcDomain.equals(tenantDomain)) {\n            throw ZMSUtils.requestError(\"Provider and tenant domains cannot be the same\", caller);\n        }\n\n        // validate our detail object against uri components\n\n        if (!validateProviderResourceGroupRolesObject(detail, provSvcDomain, provSvcName, tenantDomain,\n                resourceGroup)) {\n            throw ZMSUtils.requestError(\"Invalid provider resource group role object\", caller);\n        }\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, provSvcDomain, principalDomain);\n        metric.increment(caller, provSvcDomain, principalDomain);\n        Object timerMetric = metric.startTiming(\"putproviderresourcegrouproles_timing\", provSvcDomain, principalDomain);\n        \n        // verify that request is properly authenticated for this request\n        \n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(), caller);\n        \n        if (LOG.isInfoEnabled()) {\n            LOG.info(\"putProviderResourceGroupRoles: domain=\" + provSvcDomain + \", service=\" +\n                provSvcName + \", tenant-domain=\" + tenantDomain + \", resource-group=\" + resourceGroup +\n                \", detail=\" + detail);\n        }\n        \n        // set up our tenant admin policy so provider can check admin's access\n        \n        dbService.setupTenantAdminPolicy(tenantDomain, provSvcDomain, provSvcName, auditRef, caller);\n        \n        // now we're going to setup our roles\n        \n        List<TenantRoleAction> roleActions = detail.getRoles();\n        List<String> roles = new ArrayList<>();\n        for (TenantRoleAction roleAction : roleActions) {\n            roles.add(roleAction.getRole());\n        }\n        \n        // we're going to create a separate role for each one of tenant roles returned\n        // based on its action and set the caller as a member in each role\n        \n        dbService.executePutProviderRoles(ctx, tenantDomain, provSvcDomain, provSvcName, resourceGroup,\n            roles, auditRef, caller);\n        \n        // at this point the tenant side is complete. If the token was a chained\n        // token signed by the provider service then we're going to process the\n        // provider side as well thus complete the tenancy on-boarding process\n        \n        String authorizedService = ((RsrcCtxWrapper) ctx).principal().getAuthorizedService();\n        if (isAuthorizedProviderService(authorizedService, provSvcDomain, provSvcName)) {\n\n            // first we need to setup the admin roles in case this\n            // happens to be the first resource group\n\n            setupTenantAdminPolicyInProvider(ctx, provSvcDomain, provSvcName, tenantDomain,\n                    auditRef, caller);\n\n            // now onboard the requested resource group\n\n            dbService.executePutTenantRoles(ctx, provSvcDomain, provSvcName, tenantDomain,\n                    resourceGroup, roleActions, auditRef, caller);\n        }\n\n        metric.stopTiming(timerMetric, provSvcDomain, principalDomain);\n        return detail;\n    }\n\n    void setupTenantAdminPolicyInProvider(ResourceContext ctx, final String provSvcDomain,\n            final String provSvcName, final String tenantDomain, final String auditRef,\n            final String caller) {\n\n        List<TenantRoleAction> roles = new ArrayList<>();\n        TenantRoleAction roleAction = new TenantRoleAction().setAction(\"*\").setRole(ADMIN_ROLE_NAME);\n        roles.add(roleAction);\n        dbService.executePutTenantRoles(ctx, provSvcDomain, provSvcName, tenantDomain, null,\n                roles, auditRef, caller);\n    }\n\n    String getProviderRoleAction(String provSvcDomain, String roleName) {\n        \n        // if no match then we're going to default action of empty string\n        \n        Policy policy = dbService.getPolicy(provSvcDomain, roleName); // policy has same name\n        if (policy == null) {\n            return \"\";\n        }\n        \n        List<Assertion> assertions = policy.getAssertions();\n        if (assertions == null) {\n            return \"\";\n        }\n\n        for (Assertion assertion : assertions) {\n            if (!assertion.getRole().endsWith(roleName)) {\n                continue;\n            }\n            \n            return assertion.getAction();\n        }\n        \n        return \"\";\n    }\n    \n    public TenantResourceGroupRoles getTenantResourceGroupRoles(ResourceContext ctx, String provSvcDomain,\n            String provSvcName, String tenantDomain, String resourceGroup) {\n        \n        final String caller = \"gettenantresourcegrouproles\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n        validate(provSvcDomain, TYPE_DOMAIN_NAME, caller);\n        validate(provSvcName, TYPE_SIMPLE_NAME, caller); // not including the domain, this is the domain's service type\n        validate(tenantDomain, TYPE_DOMAIN_NAME, caller);\n        validate(resourceGroup, TYPE_COMPOUND_NAME, caller);\n        \n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        provSvcDomain = provSvcDomain.toLowerCase();\n        provSvcName = provSvcName.toLowerCase();\n        tenantDomain = tenantDomain.toLowerCase();\n        resourceGroup = resourceGroup.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, provSvcDomain, principalDomain);\n        metric.increment(caller, provSvcDomain, principalDomain);\n        Object timerMetric = metric.startTiming(\"gettenantresourcegrouproles_timing\", provSvcDomain, principalDomain);\n\n        if (dbService.getDomain(provSvcDomain, false) == null) {\n            throw ZMSUtils.notFoundError(\"getTenantResourceGroupRoles: No such domain: \" + provSvcDomain, caller);\n        }\n\n        // look for this tenants roles, ex: storage.tenant.sports.reader\n\n        String rolePrefix = ZMSUtils.getTenantResourceGroupRolePrefix(provSvcName, tenantDomain, resourceGroup);\n        TenantResourceGroupRoles troles = new TenantResourceGroupRoles().setDomain(provSvcDomain)\n                .setService(provSvcName).setTenant(tenantDomain).setResourceGroup(resourceGroup);\n\n        List<TenantRoleAction> tralist = new ArrayList<>();\n        \n        // find roles matching the prefix\n        \n        List<String> rcollection = dbService.listRoles(provSvcDomain);\n        for (String rname: rcollection) {\n            if (dbService.isTrustRoleForTenant(provSvcDomain, rname, rolePrefix, resourceGroup, tenantDomain)) {\n                \n                // good, its exactly what we are looking for, but\n                // now we want the ACTION that was set in the provider\n                \n                String action = getProviderRoleAction(provSvcDomain, rname);\n                \n                // for the role name we must return the SimpleName\n                // part only so we'll remove the prefix section\n                \n                TenantRoleAction tra = new TenantRoleAction()\n                        .setRole(rname.substring(rolePrefix.length()))\n                        .setAction(action);\n                tralist.add(tra);\n            }\n        }\n        troles.setRoles(tralist);\n\n        metric.stopTiming(timerMetric, provSvcDomain, principalDomain);\n        return troles;\n    }\n\n    public void deleteTenantResourceGroupRoles(ResourceContext ctx, String provSvcDomain,\n            String provSvcName, String tenantDomain, String resourceGroup, String auditRef) {\n        \n        final String caller = \"deletetenantresourcegrouproles\";\n        metric.increment(ZMSConsts.HTTP_DELETE);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        validate(provSvcDomain, TYPE_DOMAIN_NAME, caller);\n        validate(provSvcName, TYPE_SIMPLE_NAME, caller); // not including the domain, this is the domain's service type\n        validate(tenantDomain, TYPE_DOMAIN_NAME, caller);\n        validate(resourceGroup, TYPE_COMPOUND_NAME, caller);\n        \n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        provSvcDomain = provSvcDomain.toLowerCase();\n        provSvcName = provSvcName.toLowerCase();\n        tenantDomain = tenantDomain.toLowerCase();\n        resourceGroup = resourceGroup.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, provSvcDomain, principalDomain);\n        metric.increment(caller, provSvcDomain, principalDomain);\n        Object timerMetric = metric.startTiming(\"deletetenantresourcegrouproles_timing\", provSvcDomain, principalDomain);\n\n        // verify that request is properly authenticated for this request\n        \n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(), caller);\n        \n        dbService.executeDeleteTenantRoles(ctx, provSvcDomain, provSvcName, tenantDomain,\n                resourceGroup, auditRef, caller);\n        metric.stopTiming(timerMetric, provSvcDomain, principalDomain);\n    }\n    \n    String extractDomainName(String resource) {\n        int idx = resource.indexOf(':');\n        if (idx == -1) {\n            if (LOG.isDebugEnabled()) {\n                LOG.debug(\"extractDomainName: missing domain name: \" + resource);\n            }\n            return null;\n        }\n        return resource.substring(0, idx);\n    }\n\n    void validateRequest(HttpServletRequest request, String caller) {\n        validateRequest(request, caller, false);\n    }\n    \n    void validateRequest(HttpServletRequest request, String caller, boolean statusRequest) {\n        \n        // first validate if we're required process this over TLS only\n        \n        if (secureRequestsOnly && !request.isSecure()) {\n            throw ZMSUtils.requestError(caller + \"request must be over TLS\", caller);\n        }\n        \n        // second check if this is a status port so we can only\n        // process on status requests\n        \n        if (statusPort > 0 && statusPort != httpPort && statusPort != httpsPort) {\n            \n            // non status requests must not take place on the status port\n            \n            if (!statusRequest && request.getLocalPort() == statusPort) {\n                throw ZMSUtils.requestError(\"incorrect port number for a non-status request\", caller);\n            }\n            \n            // status requests must not take place on a non-status port\n            \n            if (statusRequest && request.getLocalPort() != statusPort) {\n                throw ZMSUtils.requestError(\"incorrect port number for a status request\", caller);\n            }\n        }\n    }\n    \n    void validate(Object val, String type, String caller) {\n        if (val == null) {\n            throw ZMSUtils.requestError(\"Missing or malformed \" + type, caller);\n        }\n        \n        Result result = validator.validate(val, type);\n        if (!result.valid) {\n            throw ZMSUtils.requestError(\"Invalid \" + type  + \" error: \" + result.error, caller);\n        }\n    }\n    \n    List<String> validatedAdminUsers(List<String> lst) {\n        \n        final String caller = \"validatedadminusers\";\n        \n        if (lst == null || lst.size() == 0) {\n            throw ZMSUtils.requestError(\"validatedAdminUsers: Missing adminUsers\", caller);\n        }\n        Set<String> users = new HashSet<>();\n        for (String user : lst) {\n            validate(user, TYPE_RESOURCE_NAME, caller);\n            users.add(user);\n        }\n        return new ArrayList<>(users);\n    }\n    \n    Domain createTopLevelDomain(ResourceContext ctx, Domain domain, List<String> adminUsers,\n                List<String> solutionTemplates, String auditRef) {\n        List<String> users = validatedAdminUsers(adminUsers);\n        return dbService.makeDomain(ctx, domain, users, solutionTemplates, auditRef);\n    }\n    \n    Domain createSubDomain(ResourceContext ctx, Domain domain, List<String> adminUsers,\n                List<String> solutionTemplates, String auditRef, String caller) {\n\n        // verify length of full sub domain name\n\n        if (domain.getName().length() > domainNameMaxLen) {\n            throw ZMSUtils.requestError(\"Invalid SubDomain name: \" + domain.getName()\n                    + \" : name length cannot exceed: \" + domainNameMaxLen, caller);\n        } \n\n        List<String> users = validatedAdminUsers(adminUsers);\n        return dbService.makeDomain(ctx, domain, users, solutionTemplates, auditRef);\n    }\n\n    int countDots(String str) {\n        int count = 0;\n        int i = str.indexOf('.');\n        while (i >= 0) {\n            count++;\n            i = str.indexOf('.', i + 1);\n        }\n        return count;\n    }\n\n    boolean hasExceededDepthLimit(Integer depth, String name) {\n        \n        if (depth == null) {\n            return false;\n        }\n        \n        // depth=0 means only top level\n\n        return countDots(name) > depth;\n    }\n    \n    DomainList listDomains(Integer limit, String skip, String prefix, Integer depth, long modTime) {\n            \n        //note: we don't use the store's options, because we also need to filter on depth\n        \n        List<String> allDomains = dbService.listDomains(prefix, modTime);\n        List<String> names = new ArrayList<>();\n        \n        for (String name : allDomains) {\n            if (hasExceededDepthLimit(depth, name)) {\n                continue;\n            }\n            names.add(name);\n        }\n        \n        int count = names.size();\n        if (skip != null) {\n            for (int i = 0; i < count; i++) {\n                String name = names.get(i);\n                if (skip.equals(name)) {\n                    names = names.subList(i + 1, count);\n                    count = names.size();\n                    break;\n                }\n            }\n        }\n        \n        DomainList result = new DomainList();\n\n        // if we have exceeded our requested list then\n        // set the next skip entry in our result\n        \n        if (hasExceededListLimit(limit, count)) {\n            names = names.subList(0, limit);\n            result.setNext(names.get(limit - 1));\n        }\n        \n        result.setNames(names);\n        return result;\n    }\n    \n    boolean isZMSService(String domain, String service) {\n        return (SYS_AUTH.equalsIgnoreCase(domain) && ZMSConsts.ZMS_SERVICE.equalsIgnoreCase(service));\n    }\n    \n    /**\n     * implements KeyStore getPublicKey\n     * @return String with PEM encoded key, which should be ybase64decoded prior\n     *         to return if ybase64encoded\n     **/\n    @Override\n    public String getPublicKey(String domain, String service, String keyId) {\n        \n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"getPublicKey: service=\" + domain + \".\" + service + \" key-id=\" + keyId);\n        }\n        \n        if (service == null || keyId == null) {\n            return null;\n        }\n        \n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domain = domain.toLowerCase();\n        service = service.toLowerCase();\n        keyId = keyId.toLowerCase();\n        \n        // special handling for service sys.auth.zms which is ourselves\n        // so we'll just lookup our key in our map\n\n        String pubKey = null;\n        if (isZMSService(domain, service)) {\n            pubKey = serverPublicKeyMap.get(keyId);\n        }\n        \n        // if it's not the ZMS Server public key then lookup the \n        // public key from ZMS data\n        \n        if (pubKey == null) {\n            try {\n                PublicKeyEntry keyEntry = dbService.getServicePublicKeyEntry(domain, service, keyId, true);\n                if (keyEntry != null) {\n                    pubKey = keyEntry.getKey();\n                }\n            } catch (ResourceException ex) {\n                if (LOG.isDebugEnabled()) {\n                    LOG.debug(\"getPublicKey: unable to get public key: \" + ex.getMessage());\n                }\n                return null;\n            }\n        }\n\n        if (pubKey == null) {\n            if (LOG.isWarnEnabled()) {\n                LOG.warn(\"getPublicKey: service=\" + domain + \".\" + service + \" has no public key registered\");\n            }\n            return null;\n        }\n        \n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"getPublicKey: service public key: \" + pubKey);\n        }\n        \n        return Crypto.ybase64DecodeString(pubKey);\n    }\n    \n    @Override\n    public void putDefaultAdmins(ResourceContext ctx, String domainName, String auditRef,\n            DefaultAdmins defaultAdmins) {\n        \n        final String caller = \"putdefaultadmins\";\n        metric.increment(ZMSConsts.HTTP_PUT);\n        metric.increment(ZMSConsts.HTTP_REQUEST);\n        metric.increment(caller);\n        logPrincipal(ctx);\n\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"putDefaultAdmins: domain = \" + domainName);\n        }\n        \n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        final String principalDomain = getPrincipalDomain(ctx);\n        Object timerMetric = metric.startTiming(\"putdefaultadmins_timing\", domainName, principalDomain);\n\n        // verify that request is properly authenticated for this request\n        \n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(), caller);\n        \n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n        \n        domainName = domainName.toLowerCase();\n        AthenzObject.DEFAULT_ADMINS.convertToLowerCase(defaultAdmins);\n        defaultAdmins.setAdmins(normalizedAdminUsers(defaultAdmins.getAdmins()));\n        \n        AthenzDomain domain = getAthenzDomain(domainName, false);\n        if (domain == null) {\n            throw ZMSUtils.notFoundError(\"putDefaultAdmins: Domain not found: '\" + domainName + \"'\", caller);\n        }\n        \n        Role adminRole = null;\n        for (Role role : domain.getRoles()) {\n            if (ADMIN_ROLE_NAME.equals(ZMSUtils.removeDomainPrefix(role.getName(), domainName, ROLE_PREFIX))) {\n                adminRole = role;\n                break;\n            }\n        }\n        if (adminRole == null) {\n            // if the admin role does not exist in the role section then add it\n            // this typically should never happen since we have added the\n            // check to disallow deletion of the admin role but we'll keep\n            // the logic in place\n        \n            if (LOG.isInfoEnabled()) {\n                LOG.info(\"putDefaultAdmins: Adding domain admin role because no domain admin role was found for domain: \" + domainName);\n            }\n            adminRole = ZMSUtils.makeAdminRole(domainName, new ArrayList<>());\n            dbService.executePutRole(ctx, domainName, ADMIN_ROLE_NAME, adminRole, auditRef, caller);\n        }\n            \n        Policy adminPolicy = null;\n        for (Policy policy : domain.getPolicies()) {\n            if (ADMIN_POLICY_NAME.equals(ZMSUtils.removeDomainPrefix(policy.getName(), domainName, POLICY_PREFIX))) {\n                adminPolicy = policy;\n                break;\n            }\n        }\n        if (adminPolicy == null) {\n            // if the admin policy does not exist in the policy section then add it\n            // this typically should never happen since we have added the\n            // check to disallow deletion of the admin policy but we'll keep\n            // the logic in place\n            \n            if (LOG.isInfoEnabled()) {\n                LOG.info(\"putDefaultAdmins: Adding domain admin policy  because no domain admin policy  was found for domain: \" + domainName);\n            }\n            //Create and add the admin policy\n            adminPolicy = ZMSUtils.makeAdminPolicy(domainName, adminRole);\n            dbService.executePutPolicy(ctx, domainName, ADMIN_POLICY_NAME, adminPolicy, auditRef, caller);\n        }\n        \n        addDefaultAdminAssertion(ctx, domainName, adminPolicy, auditRef, caller);\n        \n        removeAdminDenyAssertions(ctx, domainName, domain.getPolicies(), domain.getRoles(), adminRole,\n                defaultAdmins, auditRef, caller);\n        \n        addDefaultAdminMembers(ctx, domainName, adminRole, defaultAdmins, auditRef, caller);\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n    }\n\n    void addDefaultAdminAssertion(ResourceContext ctx, String domainName, Policy adminPolicy,\n            String auditRef, String caller) {\n\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"addDefaultAdminAssertion\");\n        }\n        \n        String domainAllResources = domainName + \":*\";\n        String domainAdminRole = ZMSUtils.roleResourceName(domainName, ADMIN_ROLE_NAME);\n        \n        List<Assertion> assertions = adminPolicy.getAssertions();\n        if (assertions != null) {\n            \n            for (Assertion assertion : assertions) {\n                String resource = assertion.getResource();\n                if (resource == null) {\n                    continue;\n                }\n            \n                String action = assertion.getAction();  \n                if (action == null) {\n                    continue;\n                }\n            \n                String role = assertion.getRole();\n                if (role == null) {\n                    continue;\n                }\n            \n                // default effect is no value is ALLOW\n                AssertionEffect effect = assertion.getEffect();\n                if (effect == null) {\n                    effect = AssertionEffect.ALLOW;\n                }\n            \n                if (resource.equals(domainAllResources) && action.equals(\"*\") && \n                        role.equals(domainAdminRole) && (effect == AssertionEffect.ALLOW)) {\n                    // found an assertion for resource = <domain>:*, with action = \"*\", \n                    // for role = <domainName>:role.admin and effect = \"ALLOW\" \n                    // (if effect is null then defaults to ALLOW) so no need to add it\n                    return;\n                }\n            }\n        }\n        \n        if (LOG.isInfoEnabled()) {\n            LOG.info(\"Adding default admin assertion to admin policy because no default admin assertion was found for admin policy for domain: \" + domainName);\n        }\n        \n        ZMSUtils.addAssertion(adminPolicy, domainAllResources, \"*\", domainAdminRole, AssertionEffect.ALLOW);\n        dbService.executePutPolicy(ctx, domainName, ADMIN_POLICY_NAME, adminPolicy, auditRef, caller);\n    }\n    \n    void removeAdminDenyAssertions(ResourceContext ctx, String domainName, List<Policy> policies,\n            List<Role> roles, Role adminRole, DefaultAdmins defaultAdmins, String auditRef, String caller) {\n\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"removeAdminDenyAssertions\");\n        }\n        \n        for (Policy policy : policies) {\n            \n            if (LOG.isDebugEnabled()) {\n                LOG.debug(\"access: processing policy: \" + policy.getName());\n            }\n            \n            // Process all the assertions defined in this policy\n            // As soon as match for an assertion that \n            // denies access to the admin role is detected, remove it\n            \n            List<Assertion> assertions = policy.getAssertions();\n            if (assertions == null) {\n                continue;\n            }\n            List<Assertion> assertionsToDelete = new ArrayList<>();\n            \n            for (Assertion assertion : assertions) {\n\n                // If there is no \"effect\" in the assertion then default is ALLOW\n                // so continue because logic is looking for DENY\n                AssertionEffect effect = assertion.getEffect();\n                if (effect == null || effect != AssertionEffect.DENY) {\n                    continue;\n                }\n                \n                // If there is no role in the assertion then admin is not being denied\n                String assertionRole = assertion.getRole();\n                if (assertionRole == null) {\n                    continue;\n                }\n\n                if (LOG.isDebugEnabled()) {\n                    LOG.debug(\"Found DENY assertion for role \" + assertionRole);\n                }\n                    \n                // role matches admin role then remove it\n                if (assertionRole.equals(adminRole.getName())) {\n                    assertionsToDelete.add(assertion);\n                } else {\n                    removeAdminMembers(ctx, domainName, roles, assertionRole, defaultAdmins, auditRef, caller);\n                }\n            }\n            \n            if (assertionsToDelete.isEmpty()) {\n                continue;\n            }\n            \n            if (LOG.isInfoEnabled()) {\n                LOG.info(\"Removing assertion from policy: \" + policy.getName() + \" because it was for the domain admin role.\");\n            }\n            \n            for (Assertion assertion : assertionsToDelete) {\n                assertions.remove(assertion);\n            }\n\n            String policyName = ZMSUtils.removeDomainPrefix(policy.getName(), domainName, POLICY_PREFIX);\n            if (assertions.size() == 0) {\n                if (LOG.isInfoEnabled()) {\n                    LOG.info(\"Removing  policy: \" + policyName +\n                            \" because it did not have any assertions after removing a DENY\" +\n                            \" assertion for the domain admin role.\");\n                }\n\n                dbService.executeDeletePolicy(ctx, domainName, policyName, auditRef, caller);\n            } else {\n                dbService.executePutPolicy(ctx, domainName, policyName, policy, auditRef, caller);\n            }\n        }\n    }\n    \n    void removeAdminMembers(ResourceContext ctx, String domainName, List<Role> roles,\n            String assertionRole, DefaultAdmins defaultAdmins, String auditRef, String caller) {\n            \n        \n        for (Role role : roles) {\n            \n            if (LOG.isDebugEnabled()) {\n                LOG.debug(\"removeAdminMembers: Removing admin members from role: \" + role.getName());\n            }\n            \n            if (!assertionRole.equals(role.getName())) {\n                continue;\n            }\n\n            String roleName = ZMSUtils.removeDomainPrefix(role.getName(), domainName, ROLE_PREFIX);\n            for (String adminName : defaultAdmins.getAdmins()) {\n                if (isMemberOfRole(role, adminName)) {\n                    if (LOG.isInfoEnabled()) {\n                        LOG.info(\"removeAdminMembers: removing member: \" + adminName + \" from role: \" +\n                                roleName + \" because there is a DENY assertion for this role in this domain.\");\n                    }\n                    \n                    dbService.executeDeleteMembership(ctx, domainName, roleName, adminName, auditRef, caller);\n                }\n            }\n        }\n    }\n\n    void addDefaultAdminMembers(ResourceContext ctx, String domainName, Role adminRole,\n            DefaultAdmins defaultAdmins, String auditRef, String caller) {\n\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"addDefaultAdminMembers\");\n        }\n        \n        for (String adminName : defaultAdmins.getAdmins()) {\n            if (!isMemberOfRole(adminRole, adminName)) {\n                if (LOG.isInfoEnabled()) {\n                    LOG.info(\"Adding member: \" + adminName + \" to admin role for domain: \" + domainName);\n                }\n                RoleMember roleMember = new RoleMember().setMemberName(adminName);\n                dbService.executePutMembership(ctx, domainName, ADMIN_ROLE_NAME,\n                        roleMember, auditRef, caller);\n            }\n        }\n    }\n\n    public ServicePrincipal getServicePrincipal(ResourceContext ctx) {\n\n        final String caller = \"getserviceprincipal\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n        \n        Principal principal = ((RsrcCtxWrapper) ctx).principal();\n        final String principalDomain = principal.getDomain();\n\n        Authority authority = principal.getAuthority();\n\n        metric.increment(ZMSConsts.HTTP_REQUEST, principalDomain, principalDomain);\n        metric.increment(caller, principalDomain, principalDomain);\n        Object timerMetric = metric.startTiming(\"getserviceprincipal_timing\", principalDomain, principalDomain);\n\n        // If the authority does not support authorization then we're going to\n        // generate a new ServiceToken signed by ZMS and send that back.\n\n        ServicePrincipal servicePrincipal = new ServicePrincipal();\n        servicePrincipal.setDomain(principal.getDomain());\n        servicePrincipal.setService(principal.getName());\n        \n        if (!authority.allowAuthorization()) {\n        \n            PrincipalToken sdToken = new PrincipalToken(principal.getCredentials());\n            PrincipalToken zmsToken = new PrincipalToken.Builder(\"S1\", sdToken.getDomain(), sdToken.getName())\n                .issueTime(sdToken.getTimestamp())\n                .expirationWindow(sdToken.getExpiryTime() - sdToken.getTimestamp())\n                .ip(sdToken.getIP()).keyId(privateKey.getId()).host(serverHostName)\n                .keyService(ZMSConsts.ZMS_SERVICE).build();\n            zmsToken.sign(privateKey.getKey());\n\n            servicePrincipal.setToken(zmsToken.getSignedToken());\n            \n        } else {\n            servicePrincipal.setToken(principal.getCredentials());\n        }\n\n        metric.stopTiming(timerMetric, principalDomain, principalDomain);\n        return servicePrincipal;\n    }\n    \n    void verifyAuthorizedServiceOperation(String authorizedService, String operationName) {\n        verifyAuthorizedServiceOperation(authorizedService, operationName, null, null);\n    }\n    \n    /**\n     * If opItemType and value are not defined in the authorized_services JSON file,\n     * you can simply pass NULL for these two values.\n     */\n    void verifyAuthorizedServiceOperation(String authorizedService, String operationName,\n            String opItemType, String opItemVal) {\n        \n        // only process this request if we have an authorized service specified\n        \n        if (authorizedService == null) {\n            return;\n        }\n        \n        // lookup the authorized services struct and see if we have the\n        // service specified in the allowed list\n        \n        AuthorizedService authzService = serverAuthorizedServices.get(authorizedService);\n        if (authzService == null) {\n            throw ZMSUtils.forbiddenError(\"Unauthorized Service \" + authorizedService,\n                    operationName);\n        }\n        \n        // if the list is empty then we do not allow any operations\n        \n        ArrayList<AllowedOperation> ops = authzService.getAllowedOperations();\n        if (ops == null || ops.isEmpty()) {\n            throw ZMSUtils.forbiddenError(\"Unauthorized Operation (\" + operationName\n                    + \") for Service \" + authorizedService, operationName);\n        }\n        \n        // otherwise make sure the operation is allowed for this service\n        \n        boolean opAllowed = false;\n        for (AllowedOperation op : ops) {\n            if (!op.getName().equalsIgnoreCase(operationName)) {\n                continue;\n            }\n            \n            opAllowed = op.isOperationAllowedOn(opItemType, opItemVal);\n            break;\n        }\n        \n        if (!opAllowed) {\n            throw ZMSUtils.forbiddenError(\"Unauthorized Operation (\" + operationName\n                    + \") for Service \" + authorizedService\n                    + (opItemType != null && !opItemType.isEmpty() ? \" on opItemKey \" + opItemType + \" and opItemVal \" + opItemVal : \"\"),\n                    operationName);\n        }\n    }\n\n    @Override\n    public ResourceAccessList getResourceAccessList(ResourceContext ctx, String principal,\n            String action) {\n        \n        final String caller = \"getresourceaccesslist\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        metric.increment(ZMSConsts.HTTP_REQUEST);\n        metric.increment(caller);\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        Object timerMetric = metric.startTiming(\"getresourceaccesslist_timing\", null, principalDomain);\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n\n        Principal ctxPrincipal = ((RsrcCtxWrapper) ctx).principal();\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"getResourceAccessList:(\" + ctxPrincipal + \", \" + principal\n                    + \", \" + action + \")\");\n        }\n        \n        if (principal != null) {\n            validate(principal, TYPE_ENTITY_NAME, caller);\n            principal = normalizeDomainAliasUser(principal.toLowerCase());\n        }\n        if (action != null) {\n            validate(action, TYPE_COMPOUND_NAME, caller);\n            action = action.toLowerCase();\n        }\n        \n        // if principal is null then we it's a special case\n        // so we need to make sure the caller is authorized\n        // to make this request\n        \n        if (principal == null || principal.isEmpty()) {\n            if (!isAllowedResourceLookForAllUsers(ctxPrincipal)) {\n                throw ZMSUtils.forbiddenError(\"Principal: \" + ctxPrincipal.getFullName() +\n                        \" not authorized to lookup resources for all users in Athenz\", caller);\n            }\n        }\n        \n        ResourceAccessList rsrcAccessList = dbService.getResourceAccessList(principal, action);\n\n        metric.stopTiming(timerMetric, null, principalDomain);\n        return rsrcAccessList;\n    }\n\n    @Override\n    public Status getStatus(ResourceContext ctx) {\n        \n        final String caller = \"getstatus\";\n        metric.increment(ZMSConsts.HTTP_GET);\n        logPrincipal(ctx);\n\n        // validate our request as status request\n        \n        validateRequest(ctx.request(), caller, true);\n        \n        // create our timer object\n        \n        metric.increment(caller);\n        final String principalDomain = getPrincipalDomain(ctx);\n        Object timerMetric = metric.startTiming(\"getstatus_timing\", null, principalDomain);\n        \n        // for now we're going to verify our database connectivity\n        // in case of failure we're going to return not found\n\n        DomainList dlist = listDomains(null, null, null, null, 0);\n        if (dlist.getNames() == null || dlist.getNames().isEmpty()) {\n            throw ZMSUtils.notFoundError(\"Error - no domains available\", caller);\n        }\n\n        // check if we're configured to check for the status file\n\n        if (healthCheckFile != null && !healthCheckFile.exists()) {\n            throw ZMSUtils.notFoundError(\"Error - no status available\", caller);\n        }\n\n        metric.stopTiming(timerMetric, null, principalDomain);\n        return successServerStatus;\n    }\n\n    String getPrincipalDomain(ResourceContext ctx) {\n        final Principal ctxPrincipal = ((RsrcCtxWrapper) ctx).principal();\n        return ctxPrincipal == null ? null : ctxPrincipal.getDomain();\n    }\n\n    void logPrincipal(ResourceContext ctx) {\n        \n        // we are going to log our principal and validate that it\n        // contains expected data\n        \n        final Principal ctxPrincipal = ((RsrcCtxWrapper) ctx).principal();\n        ((RsrcCtxWrapper) ctx).logPrincipal(ctxPrincipal);\n        if (ctxPrincipal != null && ctxPrincipal.getFullName() != null) {\n            validate(ctxPrincipal.getFullName(), TYPE_SERVICE_NAME, \"logPrincipal\");\n        }\n    }\n\n    public ResourceContext newResourceContext(HttpServletRequest request,\n            HttpServletResponse response) {\n        \n        // check to see if we want to allow this URI to be available\n        // with optional authentication support\n        \n        boolean optionalAuth = StringUtils.requestUriMatch(request.getRequestURI(),\n                authFreeUriSet, authFreeUriList);\n        return new RsrcCtxWrapper(request, response, authorities, optionalAuth, this);\n    }\n    \n    @Override\n    public Schema getRdlSchema(ResourceContext context) {\n        return schema;\n    }\n    \n    static String getServerHostName() {\n        \n        String serverHostName = System.getProperty(ZMSConsts.ZMS_PROP_HOSTNAME);\n        if (serverHostName == null || serverHostName.isEmpty()) {\n            try {\n                InetAddress localhost = java.net.InetAddress.getLocalHost();\n                serverHostName = localhost.getCanonicalHostName();\n            } catch (java.net.UnknownHostException e) {\n                LOG.info(\"Unable to determine local hostname: \" + e.getMessage());\n                serverHostName = \"localhost\";\n            }\n        }\n        \n        return serverHostName;\n    }\n    \n    Authority getAuthority(String className) {\n        \n        LOG.debug(\"Loading authority {}...\", className);\n        \n        Authority authority;\n        try {\n            authority = (Authority) Class.forName(className).newInstance();\n        } catch (InstantiationException | IllegalAccessException | ClassNotFoundException e) {\n            LOG.error(\"Invalid Authority class: \" + className + \" error: \" + e.getMessage());\n            return null;\n        }\n        return authority;\n    }\n    \n    public static String getRootDir() {\n        \n        if (ROOT_DIR == null) {\n            ROOT_DIR = System.getProperty(ZMSConsts.ZMS_PROP_ROOT_DIR, ZMSConsts.STR_DEF_ROOT);\n        }\n\n        return ROOT_DIR;\n    }\n\n    boolean isAllowedRoleSystemMetaDelete(Principal principal, final String reqDomain,\n            final String attribute) {\n\n        // the authorization policy resides in official sys.auth domain\n\n        AthenzDomain domain = getAthenzDomain(SYS_AUTH, true);\n\n        // evaluate our domain's roles and policies to see if access\n        // is allowed or not for the given operation and resource\n        // our action are always converted to lowercase\n\n        String resource = SYS_AUTH + \":role.meta.\" + attribute + \".\" + reqDomain;\n        AccessStatus accessStatus = evaluateAccess(domain, principal.getFullName(), \"delete\",\n                resource, null, null);\n\n        return accessStatus == AccessStatus.ALLOWED;\n    }\n\n    @Override\n    public void putRoleSystemMeta(ResourceContext ctx, String domainName, String roleName, String attribute,\n            String auditRef, RoleSystemMeta meta) {\n\n        final String caller = \"putrolesystemmeta\";\n        metric.increment(ZMSConsts.HTTP_PUT);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        validate(roleName, TYPE_ENTITY_NAME, caller);\n        validate(meta, TYPE_ROLE_SYSTEM_META, caller);\n        validate(attribute, TYPE_SIMPLE_NAME, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n\n        domainName = domainName.toLowerCase();\n        roleName = roleName.toLowerCase();\n        attribute = attribute.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"putrolesystemmeta_timing\", domainName, principalDomain);\n\n        // verify that request is properly authenticated for this request\n\n        Principal principal = ((RsrcCtxWrapper) ctx).principal();\n        verifyAuthorizedServiceOperation(principal.getAuthorizedService(), caller);\n\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"putRoleSystemMeta: name={}, role={} attribute={}, meta={}\",\n                    domainName, roleName, attribute, meta);\n        }\n\n        // if we are resetting the configured value then the caller\n        // must also have a delete action available for the same resource\n\n        boolean deleteAllowed = isAllowedRoleSystemMetaDelete(principal, domainName, attribute);\n\n        dbService.executePutRoleSystemMeta(ctx, domainName, roleName, meta, attribute, deleteAllowed, auditRef, caller);\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n    }\n\n    @Override\n    public void putRoleMeta(ResourceContext ctx, String domainName, String roleName, String auditRef, RoleMeta meta) {\n\n        final String caller = \"putrolemeta\";\n        metric.increment(ZMSConsts.HTTP_PUT);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        validate(roleName, TYPE_ENTITY_NAME, caller);\n        validate(meta, TYPE_ROLE_META, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n\n        domainName = domainName.toLowerCase();\n        roleName = roleName.toLowerCase();\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"putrolemeta_timing\", domainName, principalDomain);\n\n        // verify that request is properly authenticated for this request\n\n        Principal principal = ((RsrcCtxWrapper) ctx).principal();\n        verifyAuthorizedServiceOperation(principal.getAuthorizedService(), caller);\n\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"putRoleMeta: name={}, role={} meta={}\", domainName, roleName, meta);\n        }\n\n        dbService.executePutRoleMeta(ctx, domainName, roleName, meta, auditRef, caller);\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n    }\n\n    @Override\n    public void putMembershipDecision(ResourceContext ctx, String domainName, String roleName,\n            String memberName, String auditRef, Membership membership) {\n\n        final String caller = \"putmembershipdecision\";\n        metric.increment(ZMSConsts.HTTP_PUT);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        validate(roleName, TYPE_ENTITY_NAME, caller);\n        validate(memberName, TYPE_MEMBER_NAME, caller);\n        validate(membership, TYPE_MEMBERSHIP, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n\n        domainName = domainName.toLowerCase();\n        roleName = roleName.toLowerCase();\n        memberName = memberName.toLowerCase();\n        AthenzObject.MEMBERSHIP.convertToLowerCase(membership);\n\n        final Principal principal = ((RsrcCtxWrapper) ctx).principal();\n        final String principalDomain = principal.getDomain();\n\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(\"putmembershipdecision_timing\", domainName, principalDomain);\n\n        // verify that request is properly authenticated for this request\n\n        verifyAuthorizedServiceOperation(principal.getAuthorizedService(), caller, \"role\", roleName);\n\n        // verify that the member name in the URI and object provided match\n\n        if (!memberName.equals(membership.getMemberName())) {\n            throw ZMSUtils.requestError(\"putMembershipDecision: Member name in URI and Membership object do not match\", caller);\n        }\n\n        // role name is optional so we'll verify only if the value is present in the object\n\n        if (membership.getRoleName() != null && !roleName.equals(membership.getRoleName())) {\n            throw ZMSUtils.requestError(\"putMembershipDecision: Role name in URI and Membership object do not match\", caller);\n        }\n\n        AthenzDomain domain = getAthenzDomain(domainName, false);\n        Role role = getRoleFromDomain(roleName, domain);\n        if (role == null) {\n            throw ZMSUtils.requestError(\"Invalid rolename specified\", caller);\n        }\n\n        // authorization check\n\n        if (!isAllowedPutMembershipDecision(principal, domain, role)) {\n            throw ZMSUtils.forbiddenError(\"putMembershipDecision: principal is not authorized to approve / reject members\", caller);\n        }\n\n        RoleMember roleMember = new RoleMember();\n        roleMember.setMemberName(normalizeDomainAliasUser(memberName));\n        boolean bUser = ZMSUtils.isUserDomainPrincipal(roleMember.getMemberName(), userDomainPrefix,\n                addlUserCheckDomainPrefixList);\n        if (bUser) {\n            roleMember.setExpiration(memberExpiryTimestamp(domain.getDomain().getMemberExpiryDays(),\n                    role.getMemberExpiryDays(), membership.getExpiration()));\n        } else {\n            roleMember.setExpiration(memberExpiryTimestamp(domain.getDomain().getServiceExpiryDays(),\n                    role.getServiceExpiryDays(), membership.getExpiration()));\n        }\n        roleMember.setApproved(membership.getApproved());\n        roleMember.setActive(membership.getActive());\n\n        // check to see if we need to validate the principal\n        // but only if the decision is to approve. We don't\n        // want to block removal of rejected user requests\n\n        if (roleMember.getApproved() == Boolean.TRUE &&\n                (validateUserRoleMembers || validateServiceRoleMembers)) {\n            validateRoleMemberPrincipal(roleMember.getMemberName(), caller);\n        }\n\n        dbService.executePutMembershipDecision(ctx, domainName, roleName,\n                roleMember, auditRef, caller);\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n    }\n\n    private boolean isAllowedPutMembershipDecision(final Principal principal, final AthenzDomain domain,\n            final Role role) {\n\n        if (role.getAuditEnabled() == Boolean.TRUE) {\n            // check authorization in sys.auth.audit domains\n            return isAllowedAuditRoleMembershipApproval(principal, domain);\n        } else {\n            return isAllowedPutMembershipAccess(principal, domain, role);\n        }\n    }\n\n    boolean isAllowedAuditRoleMembershipApproval(Principal principal, final AthenzDomain reqDomain) {\n\n        // the authorization policy resides in official sys.auth.audit domains\n        // first we're going to check the per domain one and then we'll\n        // follow up with per org domain\n\n        AthenzDomain authDomain = getAthenzDomain(ZMSConsts.SYS_AUTH_AUDIT_BY_DOMAIN, true);\n\n        // evaluate our domain's roles and policies to see if access\n        // is allowed or not for the given operation and resource\n        // our action are always converted to lowercase\n\n        String resource = ZMSConsts.SYS_AUTH_AUDIT_BY_DOMAIN + \":audit.\" + reqDomain.getDomain().getName();\n        AccessStatus accessStatus = evaluateAccess(authDomain, principal.getFullName(),\n                \"update\", resource, null, null);\n        if (accessStatus == AccessStatus.ALLOWED) {\n            return true;\n        }\n\n        // if we didn't find any authorization for the per-domain setup\n        // we're going to look at the per-org setup\n\n        authDomain = getAthenzDomain(ZMSConsts.SYS_AUTH_AUDIT_BY_ORG, true);\n        resource = ZMSConsts.SYS_AUTH_AUDIT_BY_ORG + \":audit.\" + reqDomain.getDomain().getOrg();\n        accessStatus = evaluateAccess(authDomain, principal.getFullName(),\n                \"update\", resource, null, null);\n\n        return accessStatus == AccessStatus.ALLOWED;\n    }\n\n    Role getRoleFromDomain(final String roleName, AthenzDomain domain) {\n         if (domain != null && domain.getRoles() != null) {\n            for (Role role : domain.getRoles()) {\n                if (role.getName().equalsIgnoreCase(domain.getName() + \":role.\" + roleName)) {\n                    return role;\n                }\n            }\n        }\n        return null;\n    }\n\n    boolean isAllowedPutMembershipAccess(Principal principal, final AthenzDomain domain, final Role role) {\n\n        // evaluate our domain's roles and policies to see if access\n        // is allowed or not for the given operation and resource\n        // our action are always converted to lowercase\n\n        AccessStatus accessStatus = evaluateAccess(domain, principal.getFullName(), \"update\", role.getName(), null, null);\n        return accessStatus == AccessStatus.ALLOWED;\n    }\n\n    boolean isAllowedPutMembershipWithoutApproval(Principal principal, final AthenzDomain reqDomain, final Role role) {\n        if (role.getAuditEnabled() == Boolean.TRUE) {\n            return false;\n        } else {\n            return isAllowedPutMembershipAccess(principal, reqDomain, role);\n        }\n    }\n\n    boolean isAllowedPutMembershipSelfServe(final Principal principal, final String memberName) {\n        return principal.getFullName().equals(memberName);\n    }\n\n    boolean isAllowedPutMembership(Principal principal, final AthenzDomain domain, final Role role,\n            final RoleMember member) {\n\n        // first lets check if the principal has update access on the role\n\n        if (isAllowedPutMembershipAccess(principal, domain, role)) {\n\n            // even with update access, if the role is auditEnabled, member status\n            // can not be set to active/approved. It has to be approved by audit admins.\n            // for normal / selfserve roles, set member status to active/approved\n            // immediately\n\n            boolean auditEnabled = (role.getAuditEnabled() == Boolean.TRUE);\n            member.setActive(!auditEnabled);\n            member.setApproved(!auditEnabled);\n            return true;\n\n        } else if (role.getSelfServe() == Boolean.TRUE && isAllowedPutMembershipSelfServe(principal, member.getMemberName())) {\n\n            // if the role is selfserve, and users are trying to add themselves, allow it\n            // but with member status set to inactive. It has to be approved by domain admins.\n\n            member.setActive(false);\n            member.setApproved(false);\n            return true;\n        }\n\n        return false;\n    }\n\n    @Override\n    public DomainRoleMembership getPendingDomainRoleMembersList(ResourceContext ctx, String principal) {\n\n        final String caller = \"getpendingdomainrolememberslist\";\n\n        metric.increment(ZMSConsts.HTTP_GET);\n        metric.increment(ZMSConsts.HTTP_REQUEST);\n        metric.increment(caller);\n\n        final Principal ctxPrincipal = ((RsrcCtxWrapper) ctx).principal();\n        Object timerMetric = metric.startTiming(\"getpendingdomainrolememberslist_timing\", null, ctxPrincipal.getDomain());\n        logPrincipal(ctx);\n\n        validateRequest(ctx.request(), caller);\n\n        String checkPrincipal;\n        if (principal != null && !principal.isEmpty()) {\n            validate(principal, TYPE_ENTITY_NAME, caller);\n            checkPrincipal = normalizeDomainAliasUser(principal.toLowerCase());\n        } else {\n            checkPrincipal = ctxPrincipal.getFullName();\n        }\n\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"getpendingdomainrolememberslist principal: ({})\", checkPrincipal);\n        }\n\n        DomainRoleMembership domainRoleMembership = dbService.getPendingDomainRoleMembers(checkPrincipal);\n        metric.stopTiming(timerMetric, null, ctxPrincipal.getDomain());\n        return domainRoleMembership;\n    }\n\n    @Override\n    public void putRoleReview(ResourceContext ctx, String domainName, String roleName, String auditRef, Role role) {\n        final String caller = \"putrolereview\";\n        metric.increment(ZMSConsts.HTTP_PUT);\n        logPrincipal(ctx);\n\n        if (readOnlyMode) {\n            throw ZMSUtils.requestError(SERVER_READ_ONLY_MESSAGE, caller);\n        }\n\n        validateRequest(ctx.request(), caller);\n\n        validate(domainName, TYPE_DOMAIN_NAME, caller);\n        validate(roleName, TYPE_ENTITY_NAME, caller);\n        validate(role, TYPE_ROLE, caller);\n\n        // for consistent handling of all requests, we're going to convert\n        // all incoming object values into lower case (e.g. domain, role,\n        // policy, service, etc name)\n\n        domainName = domainName.toLowerCase();\n        roleName = roleName.toLowerCase();\n        AthenzObject.ROLE.convertToLowerCase(role);\n\n        final String principalDomain = getPrincipalDomain(ctx);\n        metric.increment(ZMSConsts.HTTP_REQUEST, domainName, principalDomain);\n        metric.increment(caller, domainName, principalDomain);\n        Object timerMetric = metric.startTiming(caller + \"_timing\", domainName, principalDomain);\n\n        // verify that request is properly authenticated for this request\n\n        verifyAuthorizedServiceOperation(((RsrcCtxWrapper) ctx).principal().getAuthorizedService(), caller);\n\n        // verify the role name in the URI and request are consistent\n\n        if (!isConsistentRoleName(domainName, roleName, role)) {\n            throw ZMSUtils.requestError(caller + \": Inconsistent role names - expected: \"\n                    + ZMSUtils.roleResourceName(domainName, roleName) + \", actual: \"\n                    + role.getName(), caller);\n        }\n\n        AthenzDomain domain = getAthenzDomain(domainName, false);\n        if (domain == null) {\n            throw ZMSUtils.notFoundError(\"No such domain: \" + domainName, caller);\n        }\n\n        Role dbRole = getRoleFromDomain(roleName, domain);\n\n        if (configuredExpiryMillis(domain.getDomain().getMemberExpiryDays(), dbRole.getMemberExpiryDays()) == 0 &&\n                configuredExpiryMillis(domain.getDomain().getServiceExpiryDays(), dbRole.getServiceExpiryDays()) == 0) {\n            throw ZMSUtils.requestError(caller + \": Domain member expiry / Role member expiry must be set to review the role. \", caller);\n        }\n\n        // normalize and remove duplicate members\n\n        normalizeRoleMembers(role);\n\n        // update role expiry based on our configurations\n\n        updateRoleMemberExpiration(domain.getDomain().getMemberExpiryDays(), dbRole.getMemberExpiryDays(),\n                domain.getDomain().getServiceExpiryDays(), dbRole.getServiceExpiryDays(), role.getRoleMembers());\n\n        // process our request\n\n        dbService.executePutRoleReview(ctx, domainName, roleName, role, auditRef, caller);\n        metric.stopTiming(timerMetric, domainName, principalDomain);\n    }\n}\n", "idx": 47, "id": 4922, "msg": "", "proj": "AthenZ-athenz", "lang": "java"}
{"patch": "@@ -1516,5 +1516,33 @@ module RSpec::Core\n         expect(groups.ordered).to eq([4, 3, 2, 1])\n       end\n     end\n+\n+    describe '#warnings' do\n+      around do |example|\n+        @_original_setting = $VERBOSE\n+        example.run\n+        $VERBOSE = @_original_setting\n+      end\n+\n+      it \"sets verbose to true when true\" do\n+        config.warnings = true\n+        expect($VERBOSE).to eq true\n+      end\n+\n+      it \"sets verbose to false when true\" do\n+        config.warnings = false\n+        expect($VERBOSE).to eq false\n+      end\n+\n+      it 'returns the verbosity setting' do\n+        expect(config.warnings).to eq $VERBOSE\n+      end\n+\n+      it 'is loaded from config by #force' do\n+        config.force :warnings => true\n+        expect($VERBOSE).to eq true\n+      end\n+    end\n+\n   end\n end", "y": 1, "oldf": "require 'spec_helper'\nrequire 'tmpdir'\n\nmodule RSpec::Core\n\n  describe Configuration do\n\n    let(:config) { Configuration.new }\n\n    describe \"RSpec.configuration with a block\" do\n      before { RSpec.stub(:warn_deprecation) }\n\n      it \"is deprecated\" do\n        RSpec.should_receive(:warn_deprecation)\n        RSpec.configuration {}\n      end\n    end\n\n    describe \"#setup_load_path_and_require\" do\n      include_context \"isolate load path mutation\"\n\n      def absolute_path_to(dir)\n        File.expand_path(\"../../../../#{dir}\", __FILE__)\n      end\n\n      it 'adds `lib` to the load path' do\n        lib_dir = absolute_path_to(\"lib\")\n        $LOAD_PATH.delete(lib_dir)\n\n        expect($LOAD_PATH).not_to include(lib_dir)\n        config.setup_load_path_and_require []\n        expect($LOAD_PATH).to include(lib_dir)\n      end\n\n      it 'adds the configured `default_path` to the load path' do\n        config.default_path = 'features'\n        foo_dir = absolute_path_to(\"features\")\n\n        expect($LOAD_PATH).not_to include(foo_dir)\n        config.setup_load_path_and_require []\n        expect($LOAD_PATH).to include(foo_dir)\n      end\n\n      it 'stores the required files' do\n        config.should_receive(:require).with('a/path')\n        config.setup_load_path_and_require ['a/path']\n        expect(config.requires).to eq ['a/path']\n      end\n\n      context \"when `default_path` refers to a file rather than a directory\" do\n        it 'does not add it to the load path' do\n          config.default_path = 'Rakefile'\n          config.setup_load_path_and_require []\n          expect($LOAD_PATH).not_to include(match /Rakefile/)\n        end\n      end\n    end\n\n    describe \"#load_spec_files\" do\n      it \"loads files using load\" do\n        config.files_to_run = [\"foo.bar\", \"blah_spec.rb\"]\n        config.should_receive(:load).twice\n        config.load_spec_files\n      end\n\n      it \"loads each file once, even if duplicated in list\" do\n        config.files_to_run = [\"a_spec.rb\", \"a_spec.rb\"]\n        config.should_receive(:load).once\n        config.load_spec_files\n      end\n\n      context \"with rspec-1 loaded\" do\n        before { stub_const(\"Spec::VERSION::MAJOR\", 1) }\n\n        it \"raises with a helpful message\" do\n          expect {\n            config.load_spec_files\n          }.to raise_error(/rspec-1 has been loaded/)\n        end\n      end\n    end\n\n    describe \"#treat_symbols_as_metadata_keys_with_true_values?\" do\n      it 'defaults to false' do\n        expect(config.treat_symbols_as_metadata_keys_with_true_values?).to be_false\n      end\n\n      it 'can be set to true' do\n        config.treat_symbols_as_metadata_keys_with_true_values = true\n        expect(config.treat_symbols_as_metadata_keys_with_true_values?).to be_true\n      end\n    end\n\n    describe \"#mock_framework\" do\n      it \"defaults to :rspec\" do\n        config.should_receive(:require).with('rspec/core/mocking/with_rspec')\n        config.mock_framework\n      end\n    end\n\n    describe \"#mock_framework=\"do\n      it \"delegates to mock_with\" do\n        config.should_receive(:mock_with).with(:rspec)\n        config.mock_framework = :rspec\n      end\n    end\n\n    shared_examples \"a configurable framework adapter\" do |m|\n      it \"yields a config object if the framework_module supports it\" do\n        custom_config = Struct.new(:custom_setting).new\n        mod = Module.new\n        mod.stub(:configuration => custom_config)\n\n        config.send m, mod do |mod_config|\n          mod_config.custom_setting = true\n        end\n\n        expect(custom_config.custom_setting).to be_true\n      end\n\n      it \"raises if framework module doesn't support configuration\" do\n        mod = Module.new\n\n        expect {\n          config.send m, mod do |mod_config|\n          end\n        }.to raise_error(/must respond to `configuration`/)\n      end\n    end\n\n    describe \"#mock_with\" do\n      before { config.stub(:require) }\n\n      it_behaves_like \"a configurable framework adapter\", :mock_with\n\n      [:rspec, :mocha, :rr, :flexmock].each do |framework|\n        context \"with #{framework}\" do\n          it \"requires the adapter for #{framework}\" do\n            config.should_receive(:require).with(\"rspec/core/mocking/with_#{framework}\")\n            config.mock_with framework\n          end\n        end\n      end\n\n      it \"allows rspec-mocks to be configured with a provided block\" do\n        mod = Module.new\n\n        RSpec::Mocks.configuration.should_receive(:add_stub_and_should_receive_to).with(mod)\n\n        config.mock_with :rspec do |c|\n          c.add_stub_and_should_receive_to mod\n        end\n      end\n\n      context \"with a module\" do\n        it \"sets the mock_framework_adapter to that module\" do\n          mod = Module.new\n          config.mock_with mod\n          expect(config.mock_framework).to eq(mod)\n        end\n      end\n\n      it \"uses the null adapter when set to any unknown key\" do\n        config.should_receive(:require).with('rspec/core/mocking/with_absolutely_nothing')\n        config.mock_with :crazy_new_mocking_framework_ive_not_yet_heard_of\n      end\n\n      context 'when there are already some example groups defined' do\n        it 'raises an error since this setting must be applied before any groups are defined' do\n          RSpec.world.stub(:example_groups).and_return([double.as_null_object])\n          expect {\n            config.mock_with :mocha\n          }.to raise_error(/must be configured before any example groups are defined/)\n        end\n\n        it 'does not raise an error if the default `mock_with :rspec` is re-configured' do\n          config.mock_framework # called by RSpec when configuring the first example group\n          RSpec.world.stub(:example_groups).and_return([double.as_null_object])\n          config.mock_with :rspec\n        end\n\n        it 'does not raise an error if re-setting the same config' do\n          groups = []\n          RSpec.world.stub(:example_groups => groups)\n          config.mock_with :mocha\n          groups << double.as_null_object\n          config.mock_with :mocha\n        end\n      end\n    end\n\n    describe \"#expectation_framework\" do\n      it \"defaults to :rspec\" do\n        config.should_receive(:require).with('rspec/expectations')\n        config.expectation_frameworks\n      end\n    end\n\n    describe \"#expectation_framework=\" do\n      it \"delegates to expect_with=\" do\n        config.should_receive(:expect_with).with(:rspec)\n        config.expectation_framework = :rspec\n      end\n    end\n\n    describe \"#expect_with\" do\n      before do\n        stub_const(\"Test::Unit::Assertions\", Module.new)\n        config.stub(:require)\n      end\n\n      it_behaves_like \"a configurable framework adapter\", :expect_with\n\n      [\n        [:rspec,  'rspec/expectations'],\n        [:stdlib, 'test/unit/assertions']\n      ].each do |framework, required_file|\n        context \"with #{framework}\" do\n          it \"requires #{required_file}\" do\n            config.should_receive(:require).with(required_file)\n            config.expect_with framework\n          end\n        end\n      end\n\n      it \"supports multiple calls\" do\n        config.expect_with :rspec\n        config.expect_with :stdlib\n        expect(config.expectation_frameworks).to eq [RSpec::Matchers, Test::Unit::Assertions]\n      end\n\n      it \"raises if block given with multiple args\" do\n        expect {\n          config.expect_with :rspec, :stdlib do |mod_config|\n          end\n        }.to raise_error(/expect_with only accepts/)\n      end\n\n      it \"raises ArgumentError if framework is not supported\" do\n        expect do\n          config.expect_with :not_supported\n        end.to raise_error(ArgumentError)\n      end\n\n      context 'when there are already some example groups defined' do\n        it 'raises an error since this setting must be applied before any groups are defined' do\n          RSpec.world.stub(:example_groups).and_return([double.as_null_object])\n          expect {\n            config.expect_with :rspec\n          }.to raise_error(/must be configured before any example groups are defined/)\n        end\n\n        it 'does not raise an error if the default `expect_with :rspec` is re-configured' do\n          config.expectation_frameworks # called by RSpec when configuring the first example group\n          RSpec.world.stub(:example_groups).and_return([double.as_null_object])\n          config.expect_with :rspec\n        end\n\n        it 'does not raise an error if re-setting the same config' do\n          groups = []\n          RSpec.world.stub(:example_groups => groups)\n          config.expect_with :stdlib\n          groups << double.as_null_object\n          config.expect_with :stdlib\n        end\n      end\n    end\n\n    describe \"#expecting_with_rspec?\" do\n      before do\n        stub_const(\"Test::Unit::Assertions\", Module.new)\n        config.stub(:require)\n      end\n\n      it \"returns false by default\" do\n        expect(config).not_to be_expecting_with_rspec\n      end\n\n      it \"returns true when `expect_with :rspec` has been configured\" do\n        config.expect_with :rspec\n        expect(config).to be_expecting_with_rspec\n      end\n\n      it \"returns true when `expect_with :rspec, :stdlib` has been configured\" do\n        config.expect_with :rspec, :stdlib\n        expect(config).to be_expecting_with_rspec\n      end\n\n      it \"returns true when `expect_with :stdlib, :rspec` has been configured\" do\n        config.expect_with :stdlib, :rspec\n        expect(config).to be_expecting_with_rspec\n      end\n\n      it \"returns false when `expect_with :stdlib` has been configured\" do\n        config.expect_with :stdlib\n        expect(config).not_to be_expecting_with_rspec\n      end\n    end\n\n    describe \"#files_to_run\" do\n      it \"loads files not following pattern if named explicitly\" do\n        config.files_or_directories_to_run = \"spec/rspec/core/resources/a_bar.rb\"\n        expect(config.files_to_run).to eq([      \"spec/rspec/core/resources/a_bar.rb\"])\n      end\n\n      it \"prevents repetition of dir when start of the pattern\" do\n        config.pattern = \"spec/**/a_spec.rb\"\n        config.files_or_directories_to_run = \"spec\"\n        expect(config.files_to_run).to eq([\"spec/rspec/core/resources/a_spec.rb\"])\n      end\n\n      it \"does not prevent repetition of dir when later of the pattern\" do\n        config.pattern = \"rspec/**/a_spec.rb\"\n        config.files_or_directories_to_run = \"spec\"\n        expect(config.files_to_run).to eq([\"spec/rspec/core/resources/a_spec.rb\"])\n      end\n\n      context \"with <path>:<line_number>\" do\n        it \"overrides inclusion filters set on config\" do\n          config.filter_run_including :foo => :bar\n          config.files_or_directories_to_run = \"path/to/file.rb:37\"\n          expect(config.inclusion_filter.size).to eq(1)\n          expect(config.inclusion_filter[:locations].keys.first).to match(/path\\/to\\/file\\.rb$/)\n          expect(config.inclusion_filter[:locations].values.first).to eq([37])\n        end\n\n        it \"overrides inclusion filters set before config\" do\n          config.force(:inclusion_filter => {:foo => :bar})\n          config.files_or_directories_to_run = \"path/to/file.rb:37\"\n          expect(config.inclusion_filter.size).to eq(1)\n          expect(config.inclusion_filter[:locations].keys.first).to match(/path\\/to\\/file\\.rb$/)\n          expect(config.inclusion_filter[:locations].values.first).to eq([37])\n        end\n\n        it \"clears exclusion filters set on config\" do\n          config.exclusion_filter = { :foo => :bar }\n          config.files_or_directories_to_run = \"path/to/file.rb:37\"\n          expect(config.exclusion_filter).to be_empty,\n            \"expected exclusion filter to be empty:\\n#{config.exclusion_filter}\"\n        end\n\n        it \"clears exclusion filters set before config\" do\n          config.force(:exclusion_filter => { :foo => :bar })\n          config.files_or_directories_to_run = \"path/to/file.rb:37\"\n          expect(config.exclusion_filter).to be_empty,\n            \"expected exclusion filter to be empty:\\n#{config.exclusion_filter}\"\n        end\n      end\n\n      context \"with default pattern\" do\n        it \"loads files named _spec.rb\" do\n          config.files_or_directories_to_run = \"spec/rspec/core/resources\"\n          expect(config.files_to_run).to eq([      \"spec/rspec/core/resources/a_spec.rb\"])\n        end\n\n        it \"loads files in Windows\", :if => RSpec.windows_os? do\n          config.files_or_directories_to_run = \"C:\\\\path\\\\to\\\\project\\\\spec\\\\sub\\\\foo_spec.rb\"\n          expect(config.files_to_run).to eq([      \"C:/path/to/project/spec/sub/foo_spec.rb\"])\n        end\n\n        it \"loads files in Windows when directory is specified\", :if => RSpec.windows_os? do\n          config.files_or_directories_to_run = \"spec\\\\rspec\\\\core\\\\resources\"\n          expect(config.files_to_run).to eq([      \"spec/rspec/core/resources/a_spec.rb\"])\n        end\n      end\n\n      context \"with default default_path\" do\n        it \"loads files in the default path when run by rspec\" do\n          config.stub(:command) { 'rspec' }\n          config.files_or_directories_to_run = []\n          expect(config.files_to_run).not_to be_empty\n        end\n\n        it \"loads files in the default path when run with DRB (e.g., spork)\" do\n          config.stub(:command) { 'spork' }\n          RSpec::Core::Runner.stub(:running_in_drb?) { true }\n          config.files_or_directories_to_run = []\n          expect(config.files_to_run).not_to be_empty\n        end\n\n        it \"does not load files in the default path when run by ruby\" do\n          config.stub(:command) { 'ruby' }\n          config.files_or_directories_to_run = []\n          expect(config.files_to_run).to be_empty\n        end\n      end\n\n      def specify_consistent_ordering_of_files_to_run\n        File.stub(:directory?).with('a') { true }\n\n        orderings = [\n          %w[ a/1.rb a/2.rb a/3.rb ],\n          %w[ a/2.rb a/1.rb a/3.rb ],\n          %w[ a/3.rb a/2.rb a/1.rb ]\n        ].map do |files|\n          Dir.should_receive(:[]).with(/^\\{?a/) { files }\n          yield\n          config.files_to_run\n        end\n\n        expect(orderings.uniq.size).to eq(1)\n      end\n\n      context 'when the given directories match the pattern' do\n        it 'orders the files in a consistent ordering, regardless of the underlying OS ordering' do\n          specify_consistent_ordering_of_files_to_run do\n            config.pattern = 'a/*.rb'\n            config.files_or_directories_to_run = 'a'\n          end\n        end\n      end\n\n      context 'when the pattern is given relative to the given directories' do\n        it 'orders the files in a consistent ordering, regardless of the underlying OS ordering' do\n          specify_consistent_ordering_of_files_to_run do\n            config.pattern = '*.rb'\n            config.files_or_directories_to_run = 'a'\n          end\n        end\n      end\n\n      context 'when given multiple file paths' do\n        it 'orders the files in a consistent ordering, regardless of the given order' do\n          File.stub(:directory?) { false } # fake it into thinking these a full file paths\n\n          files = ['a/b/c_spec.rb', 'c/b/a_spec.rb']\n          config.files_or_directories_to_run = *files\n          ordering_1 = config.files_to_run\n\n          config.files_or_directories_to_run = *(files.reverse)\n          ordering_2 = config.files_to_run\n\n          expect(ordering_1).to eq(ordering_2)\n        end\n      end\n    end\n\n    %w[pattern= filename_pattern=].each do |setter|\n      describe \"##{setter}\" do\n        context \"with single pattern\" do\n          before { config.send(setter, \"**/*_foo.rb\") }\n          it \"loads files following pattern\" do\n            file = File.expand_path(File.dirname(__FILE__) + \"/resources/a_foo.rb\")\n            config.files_or_directories_to_run = file\n            expect(config.files_to_run).to include(file)\n          end\n\n          it \"loads files in directories following pattern\" do\n            dir = File.expand_path(File.dirname(__FILE__) + \"/resources\")\n            config.files_or_directories_to_run = dir\n            expect(config.files_to_run).to include(\"#{dir}/a_foo.rb\")\n          end\n\n          it \"does not load files in directories not following pattern\" do\n            dir = File.expand_path(File.dirname(__FILE__) + \"/resources\")\n            config.files_or_directories_to_run = dir\n            expect(config.files_to_run).not_to include(\"#{dir}/a_bar.rb\")\n          end\n        end\n\n        context \"with multiple patterns\" do\n          it \"supports comma separated values\" do\n            config.send(setter, \"**/*_foo.rb,**/*_bar.rb\")\n            dir = File.expand_path(File.dirname(__FILE__) + \"/resources\")\n            config.files_or_directories_to_run = dir\n            expect(config.files_to_run).to include(\"#{dir}/a_foo.rb\")\n            expect(config.files_to_run).to include(\"#{dir}/a_bar.rb\")\n          end\n\n          it \"supports comma separated values with spaces\" do\n            config.send(setter, \"**/*_foo.rb, **/*_bar.rb\")\n            dir = File.expand_path(File.dirname(__FILE__) + \"/resources\")\n            config.files_or_directories_to_run = dir\n            expect(config.files_to_run).to include(\"#{dir}/a_foo.rb\")\n            expect(config.files_to_run).to include(\"#{dir}/a_bar.rb\")\n          end\n\n          it \"supports curly braces glob syntax\" do\n            config.send(setter, \"**/*_{foo,bar}.rb\")\n            dir = File.expand_path(File.dirname(__FILE__) + \"/resources\")\n            config.files_or_directories_to_run = dir\n            expect(config.files_to_run).to include(\"#{dir}/a_foo.rb\")\n            expect(config.files_to_run).to include(\"#{dir}/a_bar.rb\")\n          end\n        end\n      end\n    end\n\n    describe \"path with line number\" do\n      it \"assigns the line number as a location filter\" do\n        config.files_or_directories_to_run = \"path/to/a_spec.rb:37\"\n        expect(config.filter).to eq({:locations => {File.expand_path(\"path/to/a_spec.rb\") => [37]}})\n      end\n    end\n\n    context \"with full_description set\" do\n      it \"overrides filters\" do\n        config.filter_run :focused => true\n        config.full_description = \"foo\"\n        expect(config.filter).not_to have_key(:focused)\n      end\n\n      it 'is possible to access the full description regular expression' do\n        config.full_description = \"foo\"\n        expect(config.full_description).to eq /foo/\n      end\n    end\n\n    context \"without full_description having been set\" do\n      it 'returns nil from #full_description' do\n        expect(config.full_description).to eq nil\n      end\n    end\n\n    context \"with line number\" do\n      it \"assigns the file and line number as a location filter\" do\n        config.files_or_directories_to_run = \"path/to/a_spec.rb:37\"\n        expect(config.filter).to eq({:locations => {File.expand_path(\"path/to/a_spec.rb\") => [37]}})\n      end\n\n      it \"assigns multiple files with line numbers as location filters\" do\n        config.files_or_directories_to_run = \"path/to/a_spec.rb:37\", \"other_spec.rb:44\"\n        expect(config.filter).to eq({:locations => {File.expand_path(\"path/to/a_spec.rb\") => [37],\n                                                File.expand_path(\"other_spec.rb\") => [44]}})\n      end\n\n      it \"assigns files with multiple line numbers as location filters\" do\n        config.files_or_directories_to_run = \"path/to/a_spec.rb:37\", \"path/to/a_spec.rb:44\"\n        expect(config.filter).to eq({:locations => {File.expand_path(\"path/to/a_spec.rb\") => [37, 44]}})\n      end\n    end\n\n    context \"with multiple line numbers\" do\n      it \"assigns the file and line numbers as a location filter\" do\n        config.files_or_directories_to_run = \"path/to/a_spec.rb:1:3:5:7\"\n        expect(config.filter).to eq({:locations => {File.expand_path(\"path/to/a_spec.rb\") => [1,3,5,7]}})\n      end\n    end\n\n    it \"assigns the example name as the filter on description\" do\n      config.full_description = \"foo\"\n      expect(config.filter).to eq({:full_description => /foo/})\n    end\n\n    it \"assigns the example names as the filter on description if description is an array\" do\n      config.full_description = [ \"foo\", \"bar\" ]\n      expect(config.filter).to eq({:full_description => Regexp.union(/foo/, /bar/)})\n    end\n\n    it 'is possible to access the full description regular expression' do\n      config.full_description = \"foo\",\"bar\"\n      expect(config.full_description).to eq Regexp.union(/foo/,/bar/)\n    end\n\n    describe \"#default_path\" do\n      it 'defaults to \"spec\"' do\n        expect(config.default_path).to eq('spec')\n      end\n    end\n\n    describe \"#include\" do\n\n      module InstanceLevelMethods\n        def you_call_this_a_blt?\n          \"egad man, where's the mayo?!?!?\"\n        end\n      end\n\n      it_behaves_like \"metadata hash builder\" do\n        def metadata_hash(*args)\n          config.include(InstanceLevelMethods, *args)\n          config.include_or_extend_modules.last.last\n        end\n      end\n\n      context \"with no filter\" do\n        it \"includes the given module into each example group\" do\n          RSpec.configure do |c|\n            c.include(InstanceLevelMethods)\n          end\n\n          group = ExampleGroup.describe('does like, stuff and junk', :magic_key => :include) { }\n          expect(group).not_to respond_to(:you_call_this_a_blt?)\n          expect(group.new.you_call_this_a_blt?).to eq(\"egad man, where's the mayo?!?!?\")\n        end\n      end\n\n      context \"with a filter\" do\n        it \"includes the given module into each matching example group\" do\n          RSpec.configure do |c|\n            c.include(InstanceLevelMethods, :magic_key => :include)\n          end\n\n          group = ExampleGroup.describe('does like, stuff and junk', :magic_key => :include) { }\n          expect(group).not_to respond_to(:you_call_this_a_blt?)\n          expect(group.new.you_call_this_a_blt?).to eq(\"egad man, where's the mayo?!?!?\")\n        end\n      end\n\n    end\n\n    describe \"#extend\" do\n\n      module ThatThingISentYou\n        def that_thing\n        end\n      end\n\n      it_behaves_like \"metadata hash builder\" do\n        def metadata_hash(*args)\n          config.extend(ThatThingISentYou, *args)\n          config.include_or_extend_modules.last.last\n        end\n      end\n\n      it \"extends the given module into each matching example group\" do\n        RSpec.configure do |c|\n          c.extend(ThatThingISentYou, :magic_key => :extend)\n        end\n\n        group = ExampleGroup.describe(ThatThingISentYou, :magic_key => :extend) { }\n        expect(group).to respond_to(:that_thing)\n      end\n\n    end\n\n    describe \"#run_all_when_everything_filtered?\" do\n\n      it \"defaults to false\" do\n        expect(config.run_all_when_everything_filtered?).to be_false\n      end\n\n      it \"can be queried with question method\" do\n        config.run_all_when_everything_filtered = true\n        expect(config.run_all_when_everything_filtered?).to be_true\n      end\n    end\n\n    %w[color color_enabled].each do |color_option|\n      describe \"##{color_option}=\" do\n        context \"given true\" do\n          before { config.send \"#{color_option}=\", true }\n\n          context \"with config.tty? and output.tty?\" do\n            it \"does not set color_enabled\" do\n              output = StringIO.new\n              config.output_stream = output\n\n              config.tty = true\n              config.output_stream.stub :tty? => true\n\n              expect(config.send(color_option)).to be_true\n              expect(config.send(color_option, output)).to be_true\n            end\n          end\n\n          context \"with config.tty? and !output.tty?\" do\n            it \"sets color_enabled\" do\n              output = StringIO.new\n              config.output_stream = output\n\n              config.tty = true\n              config.output_stream.stub :tty? => false\n\n              expect(config.send(color_option)).to be_true\n              expect(config.send(color_option, output)).to be_true\n            end\n          end\n\n          context \"with config.tty? and !output.tty?\" do\n            it \"does not set color_enabled\" do\n              output = StringIO.new\n              config.output_stream = output\n\n              config.tty = false\n              config.output_stream.stub :tty? => true\n\n              expect(config.send(color_option)).to be_true\n              expect(config.send(color_option, output)).to be_true\n            end\n          end\n\n          context \"with !config.tty? and !output.tty?\" do\n            it \"does not set color_enabled\" do\n              output = StringIO.new\n              config.output_stream = output\n\n              config.tty = false\n              config.output_stream.stub :tty? => false\n\n              expect(config.send(color_option)).to be_false\n              expect(config.send(color_option, output)).to be_false\n            end\n          end\n\n          context \"on windows\" do\n            before do\n              @original_host  = RbConfig::CONFIG['host_os']\n              RbConfig::CONFIG['host_os'] = 'mingw'\n              config.stub(:require)\n              config.stub(:warn)\n            end\n\n            after do\n              RbConfig::CONFIG['host_os'] = @original_host\n            end\n\n            context \"with ANSICON available\" do\n              around(:each) { |e| with_env_vars('ANSICON' => 'ANSICON', &e) }\n\n              it \"enables colors\" do\n                config.output_stream = StringIO.new\n                config.output_stream.stub :tty? => true\n                config.send \"#{color_option}=\", true\n                expect(config.send(color_option)).to be_true\n              end\n\n              it \"leaves output stream intact\" do\n                config.output_stream = $stdout\n                config.stub(:require) do |what|\n                  config.output_stream = 'foo' if what =~ /Win32/\n                end\n                config.send \"#{color_option}=\", true\n                expect(config.output_stream).to eq($stdout)\n              end\n            end\n\n            context \"with ANSICON NOT available\" do\n              it \"warns to install ANSICON\" do\n                config.stub(:require) { raise LoadError }\n                config.should_receive(:warn).\n                  with(/You must use ANSICON/)\n                config.send \"#{color_option}=\", true\n              end\n\n              it \"sets color_enabled to false\" do\n                config.stub(:require) { raise LoadError }\n                config.send \"#{color_option}=\", true\n                config.color_enabled = true\n                expect(config.send(color_option)).to be_false\n              end\n            end\n          end\n        end\n      end\n\n      it \"prefers incoming cli_args\" do\n        config.output_stream = StringIO.new\n        config.output_stream.stub :tty? => true\n        config.force :color => true\n        config.color = false\n        expect(config.color).to be_true\n      end\n    end\n\n    describe '#formatter=' do\n      it \"delegates to add_formatter (better API for user-facing configuration)\" do\n        config.should_receive(:add_formatter).with('these','options')\n        config.add_formatter('these','options')\n      end\n    end\n\n    describe \"#add_formatter\" do\n\n      it \"adds to the list of formatters\" do\n        config.add_formatter :documentation\n        expect(config.formatters.first).to be_an_instance_of(Formatters::DocumentationFormatter)\n      end\n\n      it \"finds a formatter by name (w/ Symbol)\" do\n        config.add_formatter :documentation\n        expect(config.formatters.first).to be_an_instance_of(Formatters::DocumentationFormatter)\n      end\n\n      it \"finds a formatter by name (w/ String)\" do\n        config.add_formatter 'documentation'\n        expect(config.formatters.first).to be_an_instance_of(Formatters::DocumentationFormatter)\n      end\n\n      it \"finds a formatter by class\" do\n        formatter_class = Class.new(Formatters::BaseTextFormatter)\n        config.add_formatter formatter_class\n        expect(config.formatters.first).to be_an_instance_of(formatter_class)\n      end\n\n      it \"finds a formatter by class name\" do\n        stub_const(\"CustomFormatter\", Class.new(Formatters::BaseFormatter))\n        config.add_formatter \"CustomFormatter\"\n        expect(config.formatters.first).to be_an_instance_of(CustomFormatter)\n      end\n\n      it \"finds a formatter by class fully qualified name\" do\n        stub_const(\"RSpec::CustomFormatter\", Class.new(Formatters::BaseFormatter))\n        config.add_formatter \"RSpec::CustomFormatter\"\n        expect(config.formatters.first).to be_an_instance_of(RSpec::CustomFormatter)\n      end\n\n      it \"requires a formatter file based on its fully qualified name\" do\n        config.should_receive(:require).with('rspec/custom_formatter') do\n          stub_const(\"RSpec::CustomFormatter\", Class.new(Formatters::BaseFormatter))\n        end\n        config.add_formatter \"RSpec::CustomFormatter\"\n        expect(config.formatters.first).to be_an_instance_of(RSpec::CustomFormatter)\n      end\n\n      it \"raises NameError if class is unresolvable\" do\n        config.should_receive(:require).with('rspec/custom_formatter3')\n        expect(lambda { config.add_formatter \"RSpec::CustomFormatter3\" }).to raise_error(NameError)\n      end\n\n      it \"raises ArgumentError if formatter is unknown\" do\n        expect(lambda { config.add_formatter :progresss }).to raise_error(ArgumentError)\n      end\n\n      context \"with a 2nd arg defining the output\" do\n        it \"creates a file at that path and sets it as the output\" do\n          path = File.join(Dir.tmpdir, 'output.txt')\n          config.add_formatter('doc', path)\n          expect(config.formatters.first.output).to be_a(File)\n          expect(config.formatters.first.output.path).to eq(path)\n        end\n      end\n    end\n\n    describe \"#filter_run_including\" do\n      it_behaves_like \"metadata hash builder\" do\n        def metadata_hash(*args)\n          config.filter_run_including(*args)\n          config.inclusion_filter\n        end\n      end\n\n      it \"sets the filter with a hash\" do\n        config.filter_run_including :foo => true\n        expect(config.inclusion_filter[:foo]).to be(true)\n      end\n\n      it \"sets the filter with a symbol\" do\n        RSpec.configuration.stub(:treat_symbols_as_metadata_keys_with_true_values? => true)\n        config.filter_run_including :foo\n        expect(config.inclusion_filter[:foo]).to be(true)\n      end\n\n      it \"merges with existing filters\" do\n        config.filter_run_including :foo => true\n        config.filter_run_including :bar => false\n\n        expect(config.inclusion_filter[:foo]).to be(true)\n        expect(config.inclusion_filter[:bar]).to be(false)\n      end\n    end\n\n    describe \"#filter_run_excluding\" do\n      it_behaves_like \"metadata hash builder\" do\n        def metadata_hash(*args)\n          config.filter_run_excluding(*args)\n          config.exclusion_filter\n        end\n      end\n\n      it \"sets the filter\" do\n        config.filter_run_excluding :foo => true\n        expect(config.exclusion_filter[:foo]).to be(true)\n      end\n\n      it \"sets the filter using a symbol\" do\n        RSpec.configuration.stub(:treat_symbols_as_metadata_keys_with_true_values? => true)\n        config.filter_run_excluding :foo\n        expect(config.exclusion_filter[:foo]).to be(true)\n      end\n\n      it \"merges with existing filters\" do\n        config.filter_run_excluding :foo => true\n        config.filter_run_excluding :bar => false\n\n        expect(config.exclusion_filter[:foo]).to be(true)\n        expect(config.exclusion_filter[:bar]).to be(false)\n      end\n    end\n\n    describe \"#inclusion_filter\" do\n      it \"returns {} even if set to nil\" do\n        config.inclusion_filter = nil\n        expect(config.inclusion_filter).to eq({})\n      end\n    end\n\n    describe \"#inclusion_filter=\" do\n      it \"treats symbols as hash keys with true values when told to\" do\n        RSpec.configuration.stub(:treat_symbols_as_metadata_keys_with_true_values? => true)\n        config.inclusion_filter = :foo\n        expect(config.inclusion_filter).to eq({:foo => true})\n      end\n\n      it \"overrides any inclusion filters set on the command line or in configuration files\" do\n        config.force(:inclusion_filter => { :foo => :bar })\n        config.inclusion_filter = {:want => :this}\n        expect(config.inclusion_filter).to eq({:want => :this})\n      end\n    end\n\n    describe \"#exclusion_filter\" do\n      it \"returns {} even if set to nil\" do\n        config.exclusion_filter = nil\n        expect(config.exclusion_filter).to eq({})\n      end\n\n      describe \"the default :if filter\" do\n        it \"does not exclude a spec with  { :if => true } metadata\" do\n          expect(config.exclusion_filter[:if].call(true)).to be_false\n        end\n\n        it \"excludes a spec with  { :if => false } metadata\" do\n          expect(config.exclusion_filter[:if].call(false)).to be_true\n        end\n\n        it \"excludes a spec with  { :if => nil } metadata\" do\n          expect(config.exclusion_filter[:if].call(nil)).to be_true\n        end\n      end\n\n      describe \"the default :unless filter\" do\n        it \"excludes a spec with  { :unless => true } metadata\" do\n          expect(config.exclusion_filter[:unless].call(true)).to be_true\n        end\n\n        it \"does not exclude a spec with { :unless => false } metadata\" do\n          expect(config.exclusion_filter[:unless].call(false)).to be_false\n        end\n\n        it \"does not exclude a spec with { :unless => nil } metadata\" do\n          expect(config.exclusion_filter[:unless].call(nil)).to be_false\n        end\n      end\n    end\n\n    describe \"#exclusion_filter=\" do\n      it \"treats symbols as hash keys with true values when told to\" do\n        RSpec.configuration.stub(:treat_symbols_as_metadata_keys_with_true_values? => true)\n        config.exclusion_filter = :foo\n        expect(config.exclusion_filter).to eq({:foo => true})\n      end\n\n      it \"overrides any exclusion filters set on the command line or in configuration files\" do\n        config.force(:exclusion_filter => { :foo => :bar })\n        config.exclusion_filter = {:want => :this}\n        expect(config.exclusion_filter).to eq({:want => :this})\n      end\n    end\n\n    describe \"line_numbers=\" do\n      before { config.filter_manager.stub(:warn) }\n\n      it \"sets the line numbers\" do\n        config.line_numbers = ['37']\n        expect(config.filter).to eq({:line_numbers => [37]})\n      end\n\n      it \"overrides filters\" do\n        config.filter_run :focused => true\n        config.line_numbers = ['37']\n        expect(config.filter).to eq({:line_numbers => [37]})\n      end\n\n      it \"prevents subsequent filters\" do\n        config.line_numbers = ['37']\n        config.filter_run :focused => true\n        expect(config.filter).to eq({:line_numbers => [37]})\n      end\n    end\n\n    describe \"line_numbers\" do\n      it \"returns the line numbers from the filter\" do\n        config.line_numbers = ['42']\n        expect(config.line_numbers).to eq [42]\n      end\n\n      it \"defaults to empty\" do\n        expect(config.line_numbers).to eq []\n      end\n    end\n\n    describe \"#full_backtrace=\" do\n      context \"given true\" do\n        it \"clears the backtrace exclusion patterns\" do\n          config.full_backtrace = true\n          expect(config.backtrace_exclusion_patterns).to eq([])\n        end\n      end\n\n      context \"given false\" do\n        it \"restores backtrace clean patterns\" do\n          config.full_backtrace = false\n          expect(config.backtrace_exclusion_patterns).to eq(RSpec::Core::BacktraceCleaner::DEFAULT_EXCLUSION_PATTERNS)\n        end\n      end\n\n      it \"doesn't impact other instances of config\" do\n        config_1 = Configuration.new\n        config_2 = Configuration.new\n\n        config_1.full_backtrace = true\n        expect(config_2.backtrace_exclusion_patterns).not_to be_empty\n      end\n    end\n\n    describe \"#backtrace_clean_patterns=\" do\n      it \"actually receives the new filter values\" do\n        RSpec.stub(:warn_deprecation)\n        config = Configuration.new\n        config.backtrace_clean_patterns = [/.*/]\n        expect(config.backtrace_cleaner.exclude? \"this\").to be_true\n      end\n    end\n\n    describe 'full_backtrace' do\n      it 'returns true when backtrace patterns is empty' do\n        config.backtrace_exclusion_patterns = []\n        expect(config.full_backtrace?).to eq true\n      end\n\n      it 'returns false when backtrace patterns isnt empty' do\n        config.backtrace_exclusion_patterns = [:lib]\n        expect(config.full_backtrace?).to eq false\n      end\n    end\n\n    describe \"#backtrace_clean_patterns\" do\n      it \"is deprecated\" do\n        RSpec.stub(:warn_deprecation)\n        RSpec.should_receive(:warn_deprecation)\n        config = Configuration.new\n        config.backtrace_clean_patterns\n      end\n\n      it \"can be appended to\" do\n        RSpec.stub(:warn_deprecation)\n        config = Configuration.new\n        config.backtrace_clean_patterns << /.*/\n        expect(config.backtrace_cleaner.exclude? \"this\").to be_true\n      end\n    end\n\n    describe \".backtrace_cleaner#exclude? defaults\" do\n      it \"returns true for rspec files\" do\n        expect(config.backtrace_cleaner.exclude?(\"lib/rspec/core.rb\")).to be_true\n      end\n\n      it \"returns true for spec_helper\" do\n        expect(config.backtrace_cleaner.exclude?(\"spec/spec_helper.rb\")).to be_true\n      end\n\n      it \"returns true for java files (for JRuby)\" do\n        expect(config.backtrace_cleaner.exclude?(\"org/jruby/RubyArray.java:2336\")).to be_true\n      end\n\n      it \"returns true for files within installed gems\" do\n        expect(config.backtrace_cleaner.exclude?('ruby-1.8.7-p334/gems/mygem-2.3.0/lib/mygem.rb')).to be_true\n      end\n\n      it \"returns false for files in projects containing 'gems' in the name\" do\n        expect(config.backtrace_cleaner.exclude?('code/my-gems-plugin/lib/plugin.rb')).to be_false\n      end\n\n      it \"returns false for something in the current working directory\" do\n        expect(config.backtrace_cleaner.exclude?(\"#{Dir.getwd}/arbitrary\")).to be_false\n      end\n    end\n\n    describe \"#debug=true\" do\n      before do\n        if defined?(Debugger)\n          @orig_debugger = Debugger\n          Object.send(:remove_const, :Debugger)\n        else\n          @orig_debugger = nil\n        end\n        config.stub(:require)\n        Object.const_set(\"Debugger\", debugger)\n      end\n\n      after do\n        Object.send(:remove_const, :Debugger)\n        Object.const_set(\"Debugger\", @orig_debugger) if @orig_debugger\n      end\n\n      let(:debugger) { double('Debugger').as_null_object }\n\n      it \"requires 'ruby-debug'\" do\n        config.should_receive(:require).with('ruby-debug')\n        config.debug = true\n      end\n\n      it \"starts the debugger\" do\n        debugger.should_receive(:start)\n        config.debug = true\n      end\n\n      it 'sets the reader to true' do\n        config.debug = true\n        expect(config.debug?).to eq true\n      end\n    end\n\n    describe \"#debug=false\" do\n      it \"does not require 'ruby-debug'\" do\n        config.should_not_receive(:require).with('ruby-debug')\n        config.debug = false\n      end\n\n      it 'sets the reader to false' do\n        config.debug = false\n        expect(config.debug?).to eq false\n      end\n    end\n\n    describe \"#output=\" do\n      it \"sets the output\" do\n        output = double(\"output\")\n        config.output = output\n        expect(config.output).to equal(output)\n      end\n    end\n\n    describe \"#libs=\" do\n      include_context \"isolate load path mutation\"\n\n      it \"adds directories to the LOAD_PATH\" do\n        $LOAD_PATH.should_receive(:unshift).with(\"a/dir\")\n        config.libs = [\"a/dir\"]\n      end\n    end\n\n    describe \"libs\" do\n      include_context \"isolate load path mutation\"\n\n      it 'records paths added to the load path' do\n        config.libs = [\"a/dir\"]\n        expect(config.libs).to eq [\"a/dir\"]\n      end\n    end\n\n    describe \"#requires=\" do\n      before { RSpec.should_receive :deprecate }\n\n      it \"requires the configured files\" do\n        config.should_receive(:require).with('foo').ordered\n        config.should_receive(:require).with('bar').ordered\n        config.requires = ['foo', 'bar']\n      end\n\n      it \"stores require paths\" do\n        config.should_receive(:require).with(\"a/path\")\n        config.requires = [\"a/path\"]\n        expect(config.requires).to eq ['a/path']\n      end\n    end\n\n    describe \"#add_setting\" do\n      describe \"with no modifiers\" do\n        context \"with no additional options\" do\n          before do\n            config.add_setting :custom_option\n          end\n\n          it \"defaults to nil\" do\n            expect(config.custom_option).to be_nil\n          end\n\n          it \"adds a predicate\" do\n            expect(config.custom_option?).to be_false\n          end\n\n          it \"can be overridden\" do\n            config.custom_option = \"a value\"\n            expect(config.custom_option).to eq(\"a value\")\n          end\n        end\n\n        context \"with :default => 'a value'\" do\n          before do\n            config.add_setting :custom_option, :default => 'a value'\n          end\n\n          it \"defaults to 'a value'\" do\n            expect(config.custom_option).to eq(\"a value\")\n          end\n\n          it \"returns true for the predicate\" do\n            expect(config.custom_option?).to be_true\n          end\n\n          it \"can be overridden with a truthy value\" do\n            config.custom_option = \"a new value\"\n            expect(config.custom_option).to eq(\"a new value\")\n          end\n\n          it \"can be overridden with nil\" do\n            config.custom_option = nil\n            expect(config.custom_option).to eq(nil)\n          end\n\n          it \"can be overridden with false\" do\n            config.custom_option = false\n            expect(config.custom_option).to eq(false)\n          end\n        end\n      end\n\n      context \"with :alias => \" do\n        it \"is deprecated\" do\n          RSpec::should_receive(:warn).with(/deprecated/)\n          config.add_setting :custom_option\n          config.add_setting :another_custom_option, :alias => :custom_option\n        end\n      end\n\n      context \"with :alias_with => \" do\n        before do\n          config.add_setting :custom_option, :alias_with => :another_custom_option\n        end\n\n        it \"delegates the getter to the other option\" do\n          config.another_custom_option = \"this value\"\n          expect(config.custom_option).to eq(\"this value\")\n        end\n\n        it \"delegates the setter to the other option\" do\n          config.custom_option = \"this value\"\n          expect(config.another_custom_option).to eq(\"this value\")\n        end\n\n        it \"delegates the predicate to the other option\" do\n          config.custom_option = true\n          expect(config.another_custom_option?).to be_true\n        end\n      end\n    end\n\n    describe \"#configure_group\" do\n      it \"extends with 'extend'\" do\n        mod = Module.new\n        group = ExampleGroup.describe(\"group\", :foo => :bar)\n\n        config.extend(mod, :foo => :bar)\n        config.configure_group(group)\n        expect(group).to be_a(mod)\n      end\n\n      it \"extends with 'module'\" do\n        mod = Module.new\n        group = ExampleGroup.describe(\"group\", :foo => :bar)\n\n        config.include(mod, :foo => :bar)\n        config.configure_group(group)\n        expect(group.included_modules).to include(mod)\n      end\n\n      it \"requires only one matching filter\" do\n        mod = Module.new\n        group = ExampleGroup.describe(\"group\", :foo => :bar)\n\n        config.include(mod, :foo => :bar, :baz => :bam)\n        config.configure_group(group)\n        expect(group.included_modules).to include(mod)\n      end\n\n      it \"includes each one before deciding whether to include the next\" do\n        mod1 = Module.new do\n          def self.included(host)\n            host.metadata[:foo] = :bar\n          end\n        end\n        mod2 = Module.new\n\n        group = ExampleGroup.describe(\"group\")\n\n        config.include(mod1)\n        config.include(mod2, :foo => :bar)\n        config.configure_group(group)\n        expect(group.included_modules).to include(mod1)\n        expect(group.included_modules).to include(mod2)\n      end\n\n      module IncludeOrExtendMeOnce\n        def self.included(host)\n          raise \"included again\" if host.instance_methods.include?(:foobar)\n          host.class_eval { def foobar; end }\n        end\n\n        def self.extended(host)\n          raise \"extended again\" if host.respond_to?(:foobar)\n          def host.foobar; end\n        end\n      end\n\n      it \"doesn't include a module when already included in ancestor\" do\n        config.include(IncludeOrExtendMeOnce, :foo => :bar)\n\n        group = ExampleGroup.describe(\"group\", :foo => :bar)\n        child = group.describe(\"child\")\n\n        config.configure_group(group)\n        config.configure_group(child)\n      end\n\n      it \"doesn't extend when ancestor is already extended with same module\" do\n        config.extend(IncludeOrExtendMeOnce, :foo => :bar)\n\n        group = ExampleGroup.describe(\"group\", :foo => :bar)\n        child = group.describe(\"child\")\n\n        config.configure_group(group)\n        config.configure_group(child)\n      end\n    end\n\n    describe \"#alias_example_to\" do\n      it_behaves_like \"metadata hash builder\" do\n        after do\n          RSpec::Core::ExampleGroup.module_eval do\n            class << self\n              undef :my_example_method if method_defined? :my_example_method\n            end\n          end\n        end\n        def metadata_hash(*args)\n          config.alias_example_to :my_example_method, *args\n          group = ExampleGroup.describe(\"group\")\n          example = group.my_example_method(\"description\")\n          example.metadata\n        end\n      end\n    end\n\n    describe \"#reset\" do\n      it \"clears the reporter\" do\n        expect(config.reporter).not_to be_nil\n        config.reset\n        expect(config.instance_variable_get(\"@reporter\")).to be_nil\n      end\n\n      it \"clears the formatters\" do\n        config.add_formatter \"doc\"\n        config.reset\n        expect(config.formatters).to be_empty\n      end\n    end\n\n    describe \"#force\" do\n      it \"forces order\" do\n        config.force :order => \"default\"\n        config.order = \"rand\"\n        expect(config.order).to eq(\"default\")\n      end\n\n      it \"forces order and seed with :order => 'rand:37'\" do\n        config.force :order => \"rand:37\"\n        config.order = \"default\"\n        expect(config.order).to eq(\"rand\")\n        expect(config.seed).to eq(37)\n      end\n\n      it \"forces order and seed with :seed => '37'\" do\n        config.force :seed => \"37\"\n        config.order = \"default\"\n        expect(config.seed).to eq(37)\n        expect(config.order).to eq(\"rand\")\n      end\n\n      it 'can set random ordering' do\n        config.force :seed => \"rand:37\"\n        RSpec.stub(:configuration => config)\n        list = [1, 2, 3, 4].extend(Extensions::Ordered::Examples)\n        Kernel.should_receive(:rand).and_return(3, 1, 4, 2)\n        expect(list.ordered).to eq([2, 4, 1, 3])\n      end\n\n      it \"forces 'false' value\" do\n        config.add_setting :custom_option\n        config.custom_option = true\n        expect(config.custom_option?).to be_true\n        config.force :custom_option => false\n        expect(config.custom_option?).to be_false\n        config.custom_option = true\n        expect(config.custom_option?).to be_false\n      end\n    end\n\n    describe '#seed' do\n      it 'returns the seed as an int' do\n        config.seed = '123'\n        expect(config.seed).to eq(123)\n      end\n    end\n\n    describe '#randomize?' do\n      context 'with order set to :random' do\n        before { config.order = :random }\n\n        it 'returns true' do\n          expect(config.randomize?).to be_true\n        end\n      end\n\n      context 'with order set to nil' do\n        before { config.order = nil }\n\n        it 'returns false' do\n          expect(config.randomize?).to be_false\n        end\n      end\n    end\n\n    describe '#order=' do\n      context 'given \"random:123\"' do\n        before { config.order = 'random:123' }\n\n        it 'sets order to \"random\"' do\n          expect(config.order).to eq('random')\n        end\n\n        it 'sets seed to 123' do\n          expect(config.seed).to eq(123)\n        end\n\n        it 'sets up random ordering' do\n          RSpec.stub(:configuration => config)\n          list = [1, 2, 3, 4].extend(Extensions::Ordered::Examples)\n          Kernel.should_receive(:rand).and_return(3, 1, 4, 2)\n          expect(list.ordered).to eq([2, 4, 1, 3])\n        end\n      end\n\n      context 'given \"default\"' do\n        before do\n          config.order = 'rand:123'\n          config.order = 'default'\n        end\n\n        it \"sets the order to nil\" do\n          expect(config.order).to be_nil\n        end\n\n        it \"sets the seed to nil\" do\n          expect(config.seed).to be_nil\n        end\n\n        it 'clears the random ordering' do\n          RSpec.stub(:configuration => config)\n          list = [1, 2, 3, 4].extend(Extensions::Ordered::Examples)\n          Kernel.should_not_receive(:rand)\n          expect(list.ordered).to eq([1, 2, 3, 4])\n        end\n      end\n    end\n\n    describe \"#order_examples\" do\n      before { RSpec.stub(:configuration => config) }\n\n      it 'sets a block that determines the ordering of a collection extended with Extensions::Ordered::Examples' do\n        examples = [1, 2, 3, 4]\n        examples.extend Extensions::Ordered::Examples\n        config.order_examples { |examples| examples.reverse }\n        expect(examples.ordered).to eq([4, 3, 2, 1])\n      end\n\n      it 'sets #order to \"custom\"' do\n        config.order_examples { |examples| examples.reverse }\n        expect(config.order).to eq(\"custom\")\n      end\n    end\n\n    describe \"#example_ordering_block\" do\n      it 'defaults to a block that returns the passed argument' do\n        expect(config.example_ordering_block.call([1, 2, 3])).to eq([1, 2, 3])\n      end\n    end\n\n    describe \"#order_groups\" do\n      before { RSpec.stub(:configuration => config) }\n\n      it 'sets a block that determines the ordering of a collection extended with Extensions::Ordered::ExampleGroups' do\n        groups = [1, 2, 3, 4]\n        groups.extend Extensions::Ordered::ExampleGroups\n        config.order_groups { |groups| groups.reverse }\n        expect(groups.ordered).to eq([4, 3, 2, 1])\n      end\n\n      it 'sets #order to \"custom\"' do\n        config.order_groups { |groups| groups.reverse }\n        expect(config.order).to eq(\"custom\")\n      end\n    end\n\n    describe \"#group_ordering_block\" do\n      it 'defaults to a block that returns the passed argument' do\n        expect(config.group_ordering_block.call([1, 2, 3])).to eq([1, 2, 3])\n      end\n    end\n\n    describe \"#order_groups_and_examples\" do\n      let(:examples) { [1, 2, 3, 4].extend Extensions::Ordered::Examples }\n      let(:groups)   { [1, 2, 3, 4].extend Extensions::Ordered::ExampleGroups }\n\n      before do\n        RSpec.stub(:configuration => config)\n        config.order_groups_and_examples { |list| list.reverse }\n      end\n\n      it 'sets a block that determines the ordering of a collection extended with Extensions::Ordered::Examples' do\n        expect(examples.ordered).to eq([4, 3, 2, 1])\n      end\n\n      it 'sets a block that determines the ordering of a collection extended with Extensions::Ordered::ExampleGroups' do\n        expect(groups.ordered).to eq([4, 3, 2, 1])\n      end\n    end\n  end\nend\n", "idx": 1, "id": 9110, "msg": "Should be \"when false\", I think.", "proj": "rspec-rspec-core", "lang": "rb"}
{"patch": "@@ -282,7 +282,9 @@ class UtilController extends AbstractBase\n             ->get(\\VuFind\\Config\\PluginManager::class);\n         $generator = new Sitemap(\n             $this->serviceLocator->get(\\VuFind\\Search\\BackendManager::class),\n-            $configLoader->get('config')->Site->url, $configLoader->get('sitemap')\n+            $this->serviceLocator->get(\\VuFindSearch\\Service::class),\n+            $configLoader->get('config')->Site->url,\n+            $configLoader->get('sitemap')\n         );\n         $request = $this->getRequest();\n         $generator->setVerbose($request->getParam('verbose', false));", "y": 1, "oldf": "<?php\n/**\n * CLI Controller Module\n *\n * PHP version 7\n *\n * Copyright (C) Villanova University 2010.\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License version 2,\n * as published by the Free Software Foundation.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA\n *\n * @category VuFind\n * @package  Controller\n * @author   Chris Hallberg <challber@villanova.edu>\n * @license  http://opensource.org/licenses/gpl-2.0.php GNU General Public License\n * @link     https://vufind.org/wiki/development:plugins:controllers Wiki\n */\nnamespace VuFindConsole\\Controller;\n\nuse File_MARC;\nuse File_MARCXML;\nuse VuFind\\Config\\Locator as ConfigLocator;\nuse VuFind\\Config\\Writer as ConfigWriter;\nuse VuFind\\Sitemap\\Generator as Sitemap;\nuse VuFindSearch\\Backend\\Solr\\Document\\UpdateDocument;\nuse VuFindSearch\\Backend\\Solr\\Record\\SerializableRecord;\nuse Zend\\Console\\Console;\nuse Zend\\Crypt\\BlockCipher as BlockCipher;\nuse Zend\\Crypt\\Symmetric\\Openssl;\n\n/**\n * This controller handles various command-line tools\n *\n * @category VuFind\n * @package  Controller\n * @author   Chris Hallberg <challber@villanova.edu>\n * @license  http://opensource.org/licenses/gpl-2.0.php GNU General Public License\n * @link     https://vufind.org/wiki/development:plugins:controllers Wiki\n */\nclass UtilController extends AbstractBase\n{\n    /**\n     * Display help for the index reserves action.\n     *\n     * @param string $msg Extra message to display\n     *\n     * @return \\Zend\\Console\\Response\n     */\n    protected function indexReservesHelp($msg = '')\n    {\n        if (!empty($msg)) {\n            foreach (explode(\"\\n\", $msg) as $line) {\n                Console::writeLine($line);\n            }\n            Console::writeLine('');\n        }\n\n        Console::writeLine('Course reserves index builder');\n        Console::writeLine('');\n        Console::writeLine(\n            'If run with no options, this will attempt to load data from your ILS.'\n        );\n        Console::writeLine('');\n        Console::writeLine(\n            'Switches may be used to index from delimited files instead:'\n        );\n        Console::writeLine('');\n        Console::writeLine(\n            ' -f [filename] loads a file (may be repeated for multiple files)'\n        );\n        Console::writeLine(\n            ' -d [delimiter] specifies a delimiter (comma is default)'\n        );\n        Console::writeLine(\n            ' -t [template] provides a template showing where important values'\n        );\n        Console::writeLine(\n            '     can be found within the file.  The template is a comma-'\n        );\n        Console::writeLine('     separated list of values.  Choose from:');\n        Console::writeLine('          BIB_ID     - bibliographic ID');\n        Console::writeLine('          COURSE     - course name');\n        Console::writeLine('          DEPARTMENT - department name');\n        Console::writeLine('          INSTRUCTOR - instructor name');\n        Console::writeLine('          SKIP       - ignore data in this position');\n        Console::writeLine(\n            '     Default template is BIB_ID,COURSE,INSTRUCTOR,DEPARTMENT'\n        );\n        Console::writeLine(' -h or --help display this help information.');\n\n        return $this->getFailureResponse();\n    }\n\n    /**\n     * Build the Reserves index.\n     *\n     * @return \\Zend\\Console\\Response\n     */\n    public function indexreservesAction()\n    {\n        ini_set('memory_limit', '50M');\n        ini_set('max_execution_time', '3600');\n\n        $request = $this->getRequest();\n\n        if ($request->getParam('h') || $request->getParam('help')) {\n            return $this->indexReservesHelp();\n        } elseif ($file = $request->getParam('f')) {\n            try {\n                $delimiter = $request->getParam('d', ',');\n                $template = $request->getParam('t');\n                $reader = new \\VuFind\\Reserves\\CsvReader(\n                    $file, $delimiter, $template\n                );\n                $instructors = $reader->getInstructors();\n                $courses = $reader->getCourses();\n                $departments = $reader->getDepartments();\n                $reserves = $reader->getReserves();\n            } catch (\\Exception $e) {\n                return $this->indexReservesHelp($e->getMessage());\n            }\n        } elseif ($request->getParam('d')) {\n            return $this->indexReservesHelp('-d is meaningless without -f');\n        } elseif ($request->getParam('t')) {\n            return $this->indexReservesHelp('-t is meaningless without -f');\n        } else {\n            try {\n                // Connect to ILS and load data:\n                $catalog = $this->getILS();\n                $instructors = $catalog->getInstructors();\n                $courses = $catalog->getCourses();\n                $departments = $catalog->getDepartments();\n                $reserves = $catalog->findReserves('', '', '');\n            } catch (\\Exception $e) {\n                return $this->indexReservesHelp($e->getMessage());\n            }\n        }\n\n        // Make sure we have reserves and at least one of: instructors, courses,\n        // departments:\n        if ((!empty($instructors) || !empty($courses) || !empty($departments))\n            && !empty($reserves)\n        ) {\n            // Setup Solr Connection\n            $solr = $this->serviceLocator->get(\\VuFind\\Solr\\Writer::class);\n\n            // Delete existing records\n            $solr->deleteAll('SolrReserves');\n\n            // Build and Save the index\n            $index = $this->buildReservesIndex(\n                $instructors, $courses, $departments, $reserves\n            );\n            $solr->save('SolrReserves', $index);\n\n            // Commit and Optimize the Solr Index\n            $solr->commit('SolrReserves');\n            $solr->optimize('SolrReserves');\n\n            Console::writeLine('Successfully loaded ' . count($reserves) . ' rows.');\n            return $this->getSuccessResponse();\n        }\n        return $this->indexReservesHelp('Unable to load data.');\n    }\n\n    /**\n     * Build the reserves index from date returned by the ILS driver,\n     * specifically: getInstructors, getDepartments, getCourses, findReserves\n     *\n     * @param array $instructors Array of instructors $instructor_id => $instructor\n     * @param array $courses     Array of courses     $course_id => $course\n     * @param array $departments Array of department  $dept_id => $department\n     * @param array $reserves    Array of reserves records from driver's\n     * findReserves.\n     *\n     * @return UpdateDocument\n     */\n    protected function buildReservesIndex($instructors, $courses, $departments,\n        $reserves\n    ) {\n        foreach ($reserves as $record) {\n            if (!isset($record['INSTRUCTOR_ID']) || !isset($record['COURSE_ID'])\n                || !isset($record['DEPARTMENT_ID'])\n            ) {\n                throw new \\Exception(\n                    'INSTRUCTOR_ID and/or COURSE_ID and/or DEPARTMENT_ID fields ' .\n                    'not present in reserve records. Please update ILS driver.'\n                );\n            }\n            $instructor_id = $record['INSTRUCTOR_ID'];\n            $course_id = $record['COURSE_ID'];\n            $department_id = $record['DEPARTMENT_ID'];\n            $id = $course_id . '|' . $instructor_id . '|' . $department_id;\n\n            if (!isset($index[$id])) {\n                $index[$id] = [\n                    'id' => $id,\n                    'bib_id' => [],\n                    'instructor_id' => $instructor_id,\n                    'instructor' => $instructors[$instructor_id] ?? '',\n                    'course_id' => $course_id,\n                    'course' => $courses[$course_id] ?? '',\n                    'department_id' => $department_id,\n                    'department' => $departments[$department_id] ?? ''\n                ];\n            }\n            $index[$id]['bib_id'][] = $record['BIB_ID'];\n        }\n\n        $updates = new UpdateDocument();\n        foreach ($index as $id => $data) {\n            if (!empty($data['bib_id'])) {\n                $updates->addRecord(new SerializableRecord($data));\n            }\n        }\n        return $updates;\n    }\n\n    /**\n     * Commit the Solr index.\n     *\n     * @return \\Zend\\Console\\Response\n     */\n    public function commitAction()\n    {\n        return $this->performCommit();\n    }\n\n    /**\n     * Optimize the Solr index.\n     *\n     * @return \\Zend\\Console\\Response\n     */\n    public function optimizeAction()\n    {\n        return $this->performCommit(true);\n    }\n\n    /**\n     * Commit (and possibly optimize) the Solr index.\n     *\n     * @param bool $optimize Should we optimize?\n     *\n     * @return \\Zend\\Console\\Response\n     */\n    protected function performCommit($optimize = false)\n    {\n        ini_set('memory_limit', '50M');\n        ini_set('max_execution_time', '3600');\n\n        // Setup Solr Connection -- Allow core to be specified from command line.\n        $core = $this->getRequest()->getParam('core', 'Solr');\n\n        // Commit and Optimize the Solr Index\n        $solr = $this->serviceLocator->get(\\VuFind\\Solr\\Writer::class);\n        $solr->commit($core);\n        if ($optimize) {\n            $solr->optimize($core);\n        }\n        return $this->getSuccessResponse();\n    }\n\n    /**\n     * Generate a Sitemap\n     *\n     * @return \\Zend\\Console\\Response\n     */\n    public function sitemapAction()\n    {\n        // Build sitemap and display appropriate warnings if needed:\n        $configLoader = $this->serviceLocator\n            ->get(\\VuFind\\Config\\PluginManager::class);\n        $generator = new Sitemap(\n            $this->serviceLocator->get(\\VuFind\\Search\\BackendManager::class),\n            $configLoader->get('config')->Site->url, $configLoader->get('sitemap')\n        );\n        $request = $this->getRequest();\n        $generator->setVerbose($request->getParam('verbose', false));\n        $generator->generate();\n        foreach ($generator->getWarnings() as $warning) {\n            Console::writeLine(\"$warning\");\n        }\n        return $this->getSuccessResponse();\n    }\n\n    /**\n     * Command-line tool to batch-delete records from the Solr index.\n     *\n     * @return \\Zend\\Console\\Response\n     */\n    public function deletesAction()\n    {\n        // Parse the command line parameters -- check verbosity, see if we are in\n        // \"flat file\" mode, find out what file we are reading in, and determine\n        // the index we are affecting!\n        $request = $this->getRequest();\n        $verbose = $request->getParam('verbose');\n        $filename = $request->getParam('filename');\n        $mode = $request->getParam('format', 'marc');\n        $index = $request->getParam('index', 'Solr');\n\n        // No filename specified?  Give usage guidelines:\n        if (empty($filename)) {\n            $scriptName = $this->getRequest()->getScriptName();\n            if (substr($scriptName, -9) === 'index.php') {\n                $scriptName .= ' util deletes';\n            }\n            Console::writeLine(\"Delete records from VuFind's index.\");\n            Console::writeLine('');\n            Console::writeLine(\n                'Usage: ' . $scriptName . ' [--verbose] FILENAME FORMAT INDEX'\n            );\n            Console::writeLine('');\n            Console::writeLine(\n                'The optional --verbose switch turns on detailed feedback.'\n            );\n            Console::writeLine(\n                'FILENAME is the file containing records to delete.'\n            );\n            Console::writeLine(\n                'FORMAT is the format of the file -- '\n                . 'it may be one of the following:'\n            );\n            Console::writeLine(\n                \"\\tflat - flat text format \"\n                . '(deletes all IDs in newline-delimited file)'\n            );\n            Console::writeLine(\n                \"\\tmarc - binary MARC format (delete all record IDs from 001 fields)\"\n            );\n            Console::writeLine(\n                \"\\tmarcxml - MARC-XML format (delete all record IDs from 001 fields)\"\n            );\n            Console::writeLine(\n                '\"marc\" is used by default if no format is specified.'\n            );\n            Console::writeLine('INDEX is the index to use (default = Solr)');\n            return $this->getFailureResponse();\n        }\n\n        // File doesn't exist?\n        if (!file_exists($filename)) {\n            Console::writeLine(\"Cannot find file: {$filename}\");\n            return $this->getFailureResponse();\n        }\n\n        // Build list of records to delete:\n        $ids = [];\n\n        // Flat file mode:\n        if ($verbose) {\n            Console::writeLine(\"Loading IDs in {$mode} mode.\");\n        }\n        if ($mode == 'flat') {\n            foreach (explode(\"\\n\", file_get_contents($filename)) as $id) {\n                $id = trim($id);\n                if (!empty($id)) {\n                    $ids[] = $id;\n                }\n            }\n        } else {\n            // MARC file mode...  We need to load the MARC record differently if it's\n            // XML or binary:\n            $collection = ($mode == 'marcxml')\n                ? new File_MARCXML($filename) : new File_MARC($filename);\n\n            // Once the records are loaded, the rest of the logic is always the same:\n            $missingIdCount = 0;\n            while ($record = $collection->next()) {\n                $idField = $record->getField('001');\n                if ($idField) {\n                    $ids[] = (string)$idField->getData();\n                } else {\n                    $missingIdCount++;\n                }\n            }\n            if ($verbose && $missingIdCount) {\n                Console::writeLine(\n                    \"Encountered $missingIdCount record(s) without IDs.\"\n                );\n            }\n        }\n\n        // Delete, Commit and Optimize if necessary:\n        if (!empty($ids)) {\n            if ($verbose) {\n                Console::writeLine(\n                    'Attempting to delete ' . count($ids) . ' record(s): '\n                    . implode(', ', $ids)\n                );\n            }\n            $writer = $this->serviceLocator->get(\\VuFind\\Solr\\Writer::class);\n            $writer->deleteRecords($index, $ids);\n            if ($verbose) {\n                Console::writeLine('Delete operation completed.');\n            }\n        } elseif ($verbose) {\n            Console::writeLine('Nothing to delete.');\n        }\n\n        return $this->getSuccessResponse();\n    }\n\n    /**\n     * Command-line tool to clear unwanted entries\n     * from record cache table.\n     *\n     * @return \\Zend\\Console\\Response\n     */\n    public function cleanuprecordcacheAction()\n    {\n        $request = $this->getRequest();\n        if ($request->getParam('help') || $request->getParam('h')) {\n            Console::writeLine('Clean up unused cached records from the database.');\n            return $this->getFailureResponse();\n        }\n\n        $recordTable = $this->serviceLocator\n            ->get(\\VuFind\\Db\\Table\\PluginManager::class)\n            ->get('Record');\n\n        $count = $recordTable->cleanup();\n\n        Console::writeLine(\"$count records deleted.\");\n        return $this->getSuccessResponse();\n    }\n\n    /**\n     * Display help for the search or session expiration actions\n     *\n     * @param string $rows Plural name of records to delete\n     *\n     * @return \\Zend\\Console\\Response\n     */\n    protected function expirationHelp($rows)\n    {\n        Console::writeLine(\"Expire old $rows in the database.\");\n        Console::writeLine('');\n        Console::writeLine(\n            'Optional parameters: [--batch=size] [--sleep=time] [age]'\n        );\n        Console::writeLine('');\n        Console::writeLine(\n            '  batch: number of records to delete in a single batch'\n            . ' (default 1000)'\n        );\n        Console::writeLine(\n            '  sleep: milliseconds to sleep between batches (default 100)'\n        );\n\n        Console::writeLine(\n            \"  age: the age (in days) of $rows to expire (default 2)\"\n        );\n        Console::writeLine('');\n        Console::writeLine(\n            \"By default, $rows more than 2 days old will be removed.\"\n        );\n        return $this->getFailureResponse();\n    }\n\n    /**\n     * Command-line tool to clear unwanted entries\n     * from search history database table.\n     *\n     * @return \\Zend\\Console\\Response\n     */\n    public function expiresearchesAction()\n    {\n        $request = $this->getRequest();\n        if ($request->getParam('help') || $request->getParam('h')) {\n            return $this->expirationHelp('searches');\n        }\n\n        return $this->expire(\n            'Search',\n            '%%count%% expired searches deleted.',\n            'No expired searches to delete.'\n        );\n    }\n\n    /**\n     * Command-line tool to clear unwanted entries\n     * from session database table.\n     *\n     * @return \\Zend\\Console\\Response\n     */\n    public function expiresessionsAction()\n    {\n        $request = $this->getRequest();\n        if ($request->getParam('help') || $request->getParam('h')) {\n            return $this->expirationHelp('sessions');\n        }\n\n        return $this->expire(\n            'Session',\n            '%%count%% expired sessions deleted.',\n            'No expired sessions to delete.'\n        );\n    }\n\n    /**\n     * Command-line tool to clear unwanted entries\n     * from external_session database table.\n     *\n     * @return \\Zend\\Console\\Response\n     */\n    public function expireExternalSessionsAction()\n    {\n        $request = $this->getRequest();\n        if ($request->getParam('help') || $request->getParam('h')) {\n            return $this->expirationHelp('external sessions');\n        }\n\n        return $this->expire(\n            'ExternalSession',\n            '%%count%% expired external sessions deleted.',\n            'No expired external sessions to delete.'\n        );\n    }\n\n    /**\n     * Command-line tool to delete suppressed records from the index.\n     *\n     * @return \\Zend\\Console\\Response\n     */\n    public function suppressedAction()\n    {\n        $request = $this->getRequest();\n        if ($request->getParam('help') || $request->getParam('h')) {\n            Console::writeLine('Available switches:');\n            Console::writeLine(\n                '--authorities =>'\n                . ' Delete authority records instead of bibliographic records'\n            );\n            Console::writeLine('--help or -h => Show this message');\n            Console::writeLine(\n                '--outfile=[/path/to/file] => Write the ID list to the specified'\n                . ' file instead of updating Solr (optional)'\n            );\n            return $this->getFailureResponse();\n        }\n\n        // Setup Solr Connection\n        $backend = $request->getParam('authorities') ? 'SolrAuth' : 'Solr';\n\n        // Make ILS Connection\n        try {\n            $catalog = $this->getILS();\n            $result = ($backend == 'SolrAuth')\n                ? $catalog->getSuppressedAuthorityRecords()\n                : $catalog->getSuppressedRecords();\n        } catch (\\Exception $e) {\n            Console::writeLine(\"ILS error -- \" . $e->getMessage());\n            return $this->getFailureResponse();\n        }\n\n        // Validate result:\n        if (!is_array($result)) {\n            Console::writeLine(\"Could not obtain suppressed record list from ILS.\");\n            return $this->getFailureResponse();\n        } elseif (empty($result)) {\n            Console::writeLine(\"No suppressed records to delete.\");\n            return $this->getSuccessResponse();\n        }\n\n        // If 'outfile' set, write the list\n        if ($file = $request->getParam('outfile')) {\n            if (!file_put_contents($file, implode(\"\\n\", $result))) {\n                Console::writeLine(\"Problem writing to $file\");\n                return $this->getFailureResponse();\n            }\n        } else {\n            // Default behavior: Get Suppressed Records and Delete from index\n            $solr = $this->serviceLocator->get(\\VuFind\\Solr\\Writer::class);\n            $solr->deleteRecords($backend, $result);\n            $solr->commit($backend);\n            $solr->optimize($backend);\n        }\n        return $this->getSuccessResponse();\n    }\n\n    /**\n     * Tool to auto-fill hierarchy cache.\n     *\n     * @return \\Zend\\Console\\Response\n     */\n    public function createhierarchytreesAction()\n    {\n        $request = $this->getRequest();\n        if ($request->getParam('help') || $request->getParam('h')) {\n            $scriptName = $this->getRequest()->getScriptName();\n            if (substr($scriptName, -9) === 'index.php') {\n                $scriptName .= ' util createHierarchyTrees';\n            }\n            Console::writeLine(\n                'Usage: ' . $scriptName\n                . ' [<backend>] [--skip-xml or -sx] [--skip-json or -sj]'\n                . ' [--help or -h]'\n            );\n            Console::writeLine(\n                \"\\t<backend> => Search backend, e.g. \" . DEFAULT_SEARCH_BACKEND\n                . \" (default) or Search2\"\n            );\n            Console::writeLine(\"\\t--skip-xml or -sx => Skip the XML cache\");\n            Console::writeLine(\"\\t--skip-json or -sj => Skip the JSON cache\");\n            Console::writeLine(\"\\t--help or -h => Show this message\");\n            return $this->getFailureResponse();\n        }\n        $skipJson = $request->getParam('skip-json') || $request->getParam('sj');\n        $skipXml = $request->getParam('skip-xml') || $request->getParam('sx');\n        $backendId = $request->getParam('backend') ?? DEFAULT_SEARCH_BACKEND;\n        $recordLoader = $this->serviceLocator->get(\\VuFind\\Record\\Loader::class);\n        $hierarchies = $this->serviceLocator\n            ->get(\\VuFind\\Search\\Results\\PluginManager::class)->get($backendId)\n            ->getFullFieldFacets(['hierarchy_top_id']);\n        if (!isset($hierarchies['hierarchy_top_id']['data']['list'])) {\n            $hierarchies['hierarchy_top_id']['data']['list'] = [];\n        }\n        foreach ($hierarchies['hierarchy_top_id']['data']['list'] as $hierarchy) {\n            $recordid = $hierarchy['value'];\n            $count = $hierarchy['count'];\n            if (empty($recordid)) {\n                continue;\n            }\n            Console::writeLine(\n                \"\\tBuilding tree for \" . $recordid . '... '\n                . number_format($count) . ' records'\n            );\n            try {\n                $driver = $recordLoader->load($recordid, $backendId);\n                // Only do this if the record is actually a hierarchy type record\n                if ($driver->getHierarchyType()) {\n                    // JSON\n                    if (!$skipJson) {\n                        Console::writeLine(\"\\t\\tJSON cache...\");\n                        $driver->getHierarchyDriver()->getTreeSource()->getJSON(\n                            $recordid, ['refresh' => true]\n                        );\n                    } else {\n                        Console::writeLine(\"\\t\\tJSON skipped.\");\n                    }\n                    // XML\n                    if (!$skipXml) {\n                        Console::writeLine(\"\\t\\tXML cache...\");\n                        $driver->getHierarchyDriver()->getTreeSource()->getXML(\n                            $recordid, ['refresh' => true]\n                        );\n                    } else {\n                        Console::writeLine(\"\\t\\tXML skipped.\");\n                    }\n                }\n            } catch (\\VuFind\\Exception\\RecordMissing $e) {\n                Console::writeLine(\n                    'WARNING! - Caught exception: ' . $e->getMessage() . \"\\n\"\n                );\n            }\n        }\n        Console::writeLine(\n            count($hierarchies['hierarchy_top_id']['data']['list']) . ' files'\n        );\n\n        return $this->getSuccessResponse();\n    }\n\n    /**\n     * Compile CSS files from LESS.\n     *\n     * @return \\Zend\\Console\\Response\n     */\n    public function cssbuilderAction()\n    {\n        $compiler = new \\VuFindTheme\\LessCompiler(true);\n        $cacheManager = $this->serviceLocator->get(\\VuFind\\Cache\\Manager::class);\n        $cacheDir = $cacheManager->getCacheDir() . 'less/';\n        $compiler->setTempPath($cacheDir);\n        $compiler->compile(array_unique($this->getRequest()->getParam('themes')));\n        return $this->getSuccessResponse();\n    }\n\n    /**\n     * Abstract delete method.\n     *\n     * @param string    $tableName     Table to operate on.\n     * @param string    $successString String for reporting success.\n     * @param string    $failString    String for reporting failure.\n     * @param int|float $minAge        Minimum age allowed for expiration in days\n     * (also used as default value).\n     *\n     * @return mixed\n     */\n    protected function expire($tableName, $successString, $failString, $minAge = 2)\n    {\n        // Get command-line arguments\n        $request = $this->getRequest();\n\n        // Use command line value as expiration age, or default to $minAge.\n        $daysOld = floatval($request->getParam('daysOld', $minAge));\n\n        // Use command line values for batch size and sleep time if specified.\n        $batchSize = $request->getParam('batch', 1000);\n        $sleepTime = $request->getParam('sleep', 100);\n\n        // Abort if we have an invalid expiration age.\n        if ($daysOld < $minAge) {\n            Console::writeLine(\n                str_replace(\n                    '%%age%%', $minAge,\n                    'Expiration age must be at least %%age%% days.'\n                )\n            );\n            return $this->getFailureResponse();\n        }\n\n        // Delete the expired rows--this cleans up any junk left in the database\n        // e.g. from old searches or sessions that were not caught by the session\n        // garbage collector.\n        $table = $this->getTable($tableName);\n        if (!method_exists($table, 'getExpiredIdRange')) {\n            throw new \\Exception(\"$tableName does not support getExpiredIdRange()\");\n        }\n        if (!method_exists($table, 'deleteExpired')) {\n            throw new \\Exception(\"$tableName does not support deleteExpired()\");\n        }\n\n        $idRange = $table->getExpiredIdRange($daysOld);\n        if (false === $idRange) {\n            $this->timestampedMessage($failString);\n            return $this->getSuccessResponse();\n        }\n\n        // Delete records in batches\n        for ($batch = $idRange[0]; $batch <= $idRange[1]; $batch += $batchSize) {\n            $count = $table->deleteExpired(\n                $daysOld, $batch, $batch + $batchSize - 1\n            );\n            $this->timestampedMessage(\n                str_replace('%%count%%', $count, $successString)\n            );\n            // Be nice to others and wait between batches\n            if ($batch + $batchSize <= $idRange[1]) {\n                usleep($sleepTime * 1000);\n            }\n        }\n        return $this->getSuccessResponse();\n    }\n\n    /**\n     * Print a message with a time stamp to the console\n     *\n     * @param string $msg Message\n     *\n     * @return void\n     */\n    protected function timestampedMessage($msg)\n    {\n        Console::writeLine('[' . date('Y-m-d H:i:s') . '] ' . $msg);\n    }\n\n    /**\n     * Convert hash algorithms\n     * Expected parameters: oldmethod:oldkey (or none) newmethod:newkey\n     *\n     * @return \\Zend\\Console\\Response\n     */\n    public function switchdbhashAction()\n    {\n        // Validate command line arguments:\n        $request = $this->getRequest();\n        $newhash = $request->getParam('newhash');\n        if (empty($newhash)) {\n            Console::writeLine(\n                'Expected parameters: newmethod [newkey]'\n            );\n            return $this->getFailureResponse();\n        }\n\n        // Pull existing encryption settings from the configuration:\n        $config = $this->getConfig();\n        if (!isset($config->Authentication->encrypt_ils_password)\n            || !isset($config->Authentication->ils_encryption_key)\n            || !$config->Authentication->encrypt_ils_password\n        ) {\n            $oldhash = 'none';\n            $oldkey = null;\n        } else {\n            $oldhash = isset($config->Authentication->ils_encryption_algo)\n                ? $config->Authentication->ils_encryption_algo : 'blowfish';\n            $oldkey = $config->Authentication->ils_encryption_key;\n        }\n\n        // Pull new encryption settings from arguments:\n        $newkey = $request->getParam('newkey', $oldkey);\n\n        // No key specified AND no key on file = fatal error:\n        if ($newkey === null) {\n            Console::writeLine('Please specify a key as the second parameter.');\n            return $this->getFailureResponse();\n        }\n\n        // If no changes were requested, abort early:\n        if ($oldkey == $newkey && $oldhash == $newhash) {\n            Console::writeLine('No changes requested -- no action needed.');\n            return $this->getSuccessResponse();\n        }\n\n        // Initialize Openssl first, so we can catch any illegal algorithms before\n        // making any changes:\n        try {\n            if ($oldhash != 'none') {\n                $oldCrypt = new Openssl(['algorithm' => $oldhash]);\n            }\n            $newCrypt = new Openssl(['algorithm' => $newhash]);\n        } catch (\\Exception $e) {\n            Console::writeLine($e->getMessage());\n            return $this->getFailureResponse();\n        }\n\n        // Next update the config file, so if we are unable to write the file,\n        // we don't go ahead and make unwanted changes to the database:\n        $configPath = ConfigLocator::getLocalConfigPath('config.ini', null, true);\n        Console::writeLine(\"\\tUpdating $configPath...\");\n        $writer = new ConfigWriter($configPath);\n        $writer->set('Authentication', 'encrypt_ils_password', true);\n        $writer->set('Authentication', 'ils_encryption_algo', $newhash);\n        $writer->set('Authentication', 'ils_encryption_key', $newkey);\n        if (!$writer->save()) {\n            Console::writeLine(\"\\tWrite failed!\");\n            return $this->getFailureResponse();\n        }\n\n        // Now do the database rewrite:\n        $userTable = $this->serviceLocator\n            ->get(\\VuFind\\Db\\Table\\PluginManager::class)\n            ->get('User');\n        $users = $userTable->select(\n            function ($select) {\n                $select->where->isNotNull('cat_username');\n            }\n        );\n        Console::writeLine(\"\\tConverting hashes for \" . count($users) . ' user(s).');\n        foreach ($users as $row) {\n            $pass = null;\n            if ($oldhash != 'none' && isset($row['cat_pass_enc'])) {\n                $oldcipher = new BlockCipher($oldCrypt);\n                $oldcipher->setKey($oldkey);\n                $pass = $oldcipher->decrypt($row['cat_pass_enc']);\n            } else {\n                $pass = $row['cat_password'];\n            }\n            $newcipher = new BlockCipher($newCrypt);\n            $newcipher->setKey($newkey);\n            $row['cat_password'] = null;\n            $row['cat_pass_enc'] = $newcipher->encrypt($pass);\n            $row->save();\n        }\n\n        // If we got this far, all went well!\n        Console::writeLine(\"\\tFinished.\");\n        return $this->getSuccessResponse();\n    }\n\n    /**\n     * Lint a file of MARC records.\n     *\n     * @return \\Zend\\Console\\Response\n     */\n    public function lintmarcAction()\n    {\n        $request = $this->getRequest();\n        $filename = $request->getParam('filename');\n        $marc = substr($filename, -3) !== 'xml'\n            ? new File_MARC($filename) : new File_MARCXML($filename);\n        $linter = new \\File_MARC_Lint();\n        $i = 0;\n        while ($record = $marc->next()) {\n            $i++;\n            $field001 = $record->getField('001');\n            $field001 = $field001 ? (string)$field001->getData() : 'undefined';\n            Console::writeLine(\"Checking record $i (001 = $field001)...\");\n            $warnings = $linter->checkRecord($record);\n            if (count($warnings) > 0) {\n                Console::writeLine('Warnings: ' . implode(\"\\n\", $warnings));\n            }\n        }\n        return $this->getSuccessResponse();\n    }\n}\n", "idx": 1, "id": 28457, "msg": "I wonder if it's worth setting up a factory for the Sitemap class rather than doing all this work inline in the controller. Certainly not a requirement right now, but maybe a change worth considering while we're touching things anyway.", "proj": "vufind-org-vufind", "lang": "php"}
{"patch": "@@ -381,7 +381,14 @@ Blockly.Variables.createVariable = function(workspace, opt_callback) {\n                 });\n           }\n           else {\n-            workspace.createVariable(text);\n+            var variable = workspace.createVariable(text);\n+\n+            var fl = workspace.getFlyout();\n+            var variableBlockId = 'VAR_' + variable.name;\n+            if (fl.setCheckboxState) {\n+              fl.setCheckboxState(variableBlockId, true);\n+            }\n+\n             if (opt_callback) {\n               opt_callback(text);\n             }", "y": 1, "oldf": "/**\n * @license\n * Visual Blocks Editor\n *\n * Copyright 2012 Google Inc.\n * https://developers.google.com/blockly/\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * @fileoverview Utility functions for handling variables.\n * @author fraser@google.com (Neil Fraser)\n */\n'use strict';\n\n/**\n * @name Blockly.Variables\n * @namespace\n **/\ngoog.provide('Blockly.Variables');\n\ngoog.require('Blockly.Blocks');\ngoog.require('Blockly.constants');\ngoog.require('Blockly.VariableModel');\ngoog.require('Blockly.Workspace');\ngoog.require('goog.string');\n\n\n/**\n * Constant to separate variable names from procedures and generated functions\n * when running generators.\n * @deprecated Use Blockly.VARIABLE_CATEGORY_NAME\n */\nBlockly.Variables.NAME_TYPE = Blockly.VARIABLE_CATEGORY_NAME;\n\n/**\n * Find all user-created variables that are in use in the workspace.\n * For use by generators.\n * @param {!Blockly.Block|!Blockly.Workspace} root Root block or workspace.\n * @return {!Array.<string>} Array of variable names.\n */\nBlockly.Variables.allUsedVariables = function(root) {\n  var blocks;\n  if (root instanceof Blockly.Block) {\n    // Root is Block.\n    blocks = root.getDescendants();\n  } else if (root instanceof Blockly.Workspace ||\n      root instanceof Blockly.WorkspaceSvg) {\n    // Root is Workspace.\n    blocks = root.getAllBlocks();\n  } else {\n    throw 'Not Block or Workspace: ' + root;\n  }\n\n  var ignorableName = Blockly.Variables.noVariableText();\n\n  var variableHash = Object.create(null);\n  // Iterate through every block and add each variable to the hash.\n  for (var x = 0; x < blocks.length; x++) {\n    var blockVariables = blocks[x].getVars();\n    if (blockVariables) {\n      for (var y = 0; y < blockVariables.length; y++) {\n        var varName = blockVariables[y];\n        // Variable name may be null if the block is only half-built.\n        if (varName && varName.toLowerCase() != ignorableName) {\n          variableHash[varName.toLowerCase()] = varName;\n        }\n      }\n    }\n  }\n  // Flatten the hash into a list.\n  var variableList = [];\n  for (var name in variableHash) {\n    variableList.push(variableHash[name]);\n  }\n  return variableList;\n};\n\n/**\n * Find all variables that the user has created through the workspace or\n * toolbox.  For use by generators.\n * @param {!Blockly.Workspace} root The workspace to inspect.\n * @return {!Array.<Blockly.VariableModel>} Array of variable models.\n */\nBlockly.Variables.allVariables = function(root) {\n  if (root instanceof Blockly.Block) {\n    // Root is Block.\n    console.warn('Deprecated call to Blockly.Variables.allVariables ' +\n                 'with a block instead of a workspace.  You may want ' +\n                 'Blockly.Variables.allUsedVariables');\n    return {};\n  }\n  return root.getAllVariables();\n};\n\n/**\n * Construct the blocks required by the flyout for the variable category.\n * @param {!Blockly.Workspace} workspace The workspace contianing variables.\n * @return {!Array.<!Element>} Array of XML block elements.\n */\nBlockly.Variables.flyoutCategory = function(workspace) {\n  var variableModelList = workspace.getVariablesOfType('');\n  variableModelList.sort(Blockly.VariableModel.compareByName);\n\n  var xmlList = [];\n  var button = goog.dom.createDom('button');\n  button.setAttribute('text', Blockly.Msg.NEW_VARIABLE);\n  button.setAttribute('callbackKey', 'CREATE_VARIABLE');\n\n  workspace.registerButtonCallback('CREATE_VARIABLE', function(button) {\n    Blockly.Variables.createVariable(button.getTargetWorkspace());\n  });\n\n  xmlList.push(button);\n\n  for (var i = 0; i < variableModelList.length; i++) {\n    if (Blockly.Blocks['data_variable']) {\n      // <block type=\"data_variable\">\n      //    <field name=\"VARIABLE\" variableType=\"\" id=\"\">variablename</field>\n      // </block>\n      var block = goog.dom.createDom('block');\n      block.setAttribute('type', 'data_variable');\n      block.setAttribute('gap', 8);\n      block.setAttribute('id', 'VAR_' + variableModelList[i].name);\n\n      var field = goog.dom.createDom('field', null, variableModelList[i].name);\n      field.setAttribute('name', 'VARIABLE');\n      field.setAttribute('variableType', variableModelList[i].type);\n      field.setAttribute('id', variableModelList[i].getId());\n      block.appendChild(field);\n\n      xmlList.push(block);\n    }\n  }\n\n  if (xmlList.length > 1) { // The button is always there.\n    xmlList[xmlList.length - 1].setAttribute('gap', 24);\n\n    if (Blockly.Blocks['data_setvariableto']) {\n      // <block type=\"data_setvariableto\" gap=\"20\">\n      //   <value name=\"VARIABLE\">\n      //    <shadow type=\"data_variablemenu\"></shadow>\n      //   </value>\n      //   <value name=\"VALUE\">\n      //     <shadow type=\"text\">\n      //       <field name=\"TEXT\">0</field>\n      //     </shadow>\n      //   </value>\n      // </block>\n      var block = goog.dom.createDom('block');\n      block.setAttribute('type', 'data_setvariableto');\n      block.setAttribute('gap', 8);\n      block.appendChild(Blockly.Variables.createVariableDom_(variableModelList[0]));\n      block.appendChild(Blockly.Variables.createTextDom_());\n      xmlList.push(block);\n    }\n    if (Blockly.Blocks['data_changevariableby']) {\n      // <block type=\"data_changevariableby\">\n      //   <value name=\"VARIABLE\">\n      //    <shadow type=\"data_variablemenu\"></shadow>\n      //   </value>\n      //   <value name=\"VALUE\">\n      //     <shadow type=\"math_number\">\n      //       <field name=\"NUM\">0</field>\n      //     </shadow>\n      //   </value>\n      // </block>\n      var block = goog.dom.createDom('block');\n      block.setAttribute('type', 'data_changevariableby');\n      block.setAttribute('gap', 8);\n      block.appendChild(Blockly.Variables.createVariableDom_(variableModelList[0]));\n      block.appendChild(Blockly.Variables.createMathNumberDom_());\n      xmlList.push(block);\n    }\n    if (Blockly.Blocks['data_showvariable']) {\n      // <block type=\"data_showvariable\">\n      //   <value name=\"VARIABLE\">\n      //     <shadow type=\"data_variablemenu\"></shadow>\n      //   </value>\n      // </block>\n      var block = goog.dom.createDom('block');\n      block.setAttribute('type', 'data_showvariable');\n      block.setAttribute('gap', 8);\n      block.appendChild(Blockly.Variables.createVariableDom_(variableModelList[0]));\n      xmlList.push(block);\n    }\n    if (Blockly.Blocks['data_hidevariable']) {\n      // <block type=\"data_showvariable\">\n      //   <value name=\"VARIABLE\">\n      //     <shadow type=\"data_variablemenu\"></shadow>\n      //   </value>\n      // </block>\n      var block = goog.dom.createDom('block');\n      block.setAttribute('type', 'data_hidevariable');\n      block.appendChild(Blockly.Variables.createVariableDom_(variableModelList[0]));\n      xmlList.push(block);\n    }\n  }\n  return xmlList;\n};\n\n/**\n * Create a dom element for a value tag with the given name attribute.\n * @param {string} name The value to use for the name attribute.\n * @return {!Element} An XML element: <value name=\"name\"></value>\n */\nBlockly.Variables.createValueDom_ = function(name) {\n  var value = goog.dom.createDom('value');\n  value.setAttribute('name', name);\n  return value;\n};\n\n/**\n * Create a dom element for a shadow tag with the given tupe attribute.\n * @param {string} type The value to use for the type attribute.\n * @param {string} value The value to have inside the tag.\n * @return {!Element} An XML element: <shadow type=\"type\">value</shadow>\n */\nBlockly.Variables.createShadowDom_ = function(type) {\n  var shadow = goog.dom.createDom('shadow');\n  shadow.setAttribute('type', type);\n  return shadow;\n};\n\n/**\n * Create a dom element for value tag with a shadow variable inside.\n * @param {Blockly.VariableModel} variableModel The variable to use.\n * @return {!Element} An XML element.\n */\nBlockly.Variables.createVariableDom_ = function(variableModel) {\n  //   <value name=\"VARIABLE\">\n  //     <shadow type=\"data_variablemenu\">\n  //       <field name=\"VARIABLE\">variablename\n  //       </field>\n  //     </shadow>\n  //   </value>\n  var value = Blockly.Variables.createValueDom_('VARIABLE');\n  var shadow = Blockly.Variables.createShadowDom_('data_variablemenu');\n  var field = goog.dom.createDom('field', null, variableModel.name);\n  field.setAttribute('name', 'VARIABLE');\n  field.setAttribute('variableType', variableModel.type);\n  field.setAttribute('id', variableModel.getId());\n  shadow.appendChild(field);\n  value.appendChild(shadow);\n  return value;\n};\n\n/**\n * Create a dom element for value tag with a shadow text inside.\n * @return {!Element} An XML element.\n */\nBlockly.Variables.createTextDom_ = function() {\n  //   <value name=\"VALUE\">\n  //     <shadow type=\"text\">\n  //       <field name=\"TEXT\">0</field>\n  //     </shadow>\n  //   </value>\n  var value = Blockly.Variables.createValueDom_('VALUE');\n  var shadow = Blockly.Variables.createShadowDom_('text');\n  var field = goog.dom.createDom('field', null, '0');\n  field.setAttribute('name', 'TEXT');\n  shadow.appendChild(field);\n  value.appendChild(shadow);\n  return value;\n};\n\n/**\n * Create a dom element for value tag with a shadow number inside.\n * @return {!Element} An XML element.\n */\nBlockly.Variables.createMathNumberDom_ = function() {\n  //   <value name=\"VALUE\">\n  //     <shadow type=\"math_number\">\n  //       <field name=\"NUM\">0</field>\n  //     </shadow>\n  //   </value>\n  var value = Blockly.Variables.createValueDom_('VALUE');\n  var shadow = Blockly.Variables.createShadowDom_('math_number');\n  var field = goog.dom.createDom('field', null, '1');\n  field.setAttribute('name', 'NUM');\n  shadow.appendChild(field);\n  value.appendChild(shadow);\n  return value;\n};\n\n/**\n * Return the text that should be used in a field_variable or\n * field_variable_getter when no variable exists.\n * TODO: #572\n * @return {string} The text to display.\n */\nBlockly.Variables.noVariableText = function() {\n  return \"No variable selected\";\n};\n\n/**\n* Return a new variable name that is not yet being used. This will try to\n* generate single letter variable names in the range 'i' to 'z' to start with.\n* If no unique name is located it will try 'i' to 'z', 'a' to 'h',\n* then 'i2' to 'z2' etc.  Skip 'l'.\n * @param {!Blockly.Workspace} workspace The workspace to be unique in.\n* @return {string} New variable name.\n*/\nBlockly.Variables.generateUniqueName = function(workspace) {\n  var variableList = workspace.getAllVariables();\n  var newName = '';\n  if (variableList.length) {\n    var nameSuffix = 1;\n    var letters = 'ijkmnopqrstuvwxyzabcdefgh';  // No 'l'.\n    var letterIndex = 0;\n    var potName = letters.charAt(letterIndex);\n    while (!newName) {\n      var inUse = false;\n      for (var i = 0; i < variableList.length; i++) {\n        if (variableList[i].name.toLowerCase() == potName) {\n          // This potential name is already used.\n          inUse = true;\n          break;\n        }\n      }\n      if (inUse) {\n        // Try the next potential name.\n        letterIndex++;\n        if (letterIndex == letters.length) {\n          // Reached the end of the character sequence so back to 'i'.\n          // a new suffix.\n          letterIndex = 0;\n          nameSuffix++;\n        }\n        potName = letters.charAt(letterIndex);\n        if (nameSuffix > 1) {\n          potName += nameSuffix;\n        }\n      } else {\n        // We can use the current potential name.\n        newName = potName;\n      }\n    }\n  } else {\n    newName = 'i';\n  }\n  return newName;\n};\n\n/**\n * Create a new variable on the given workspace.\n * @param {!Blockly.Workspace} workspace The workspace on which to create the\n *     variable.\n * @param {function(?string=)=} opt_callback A callback. It will\n *     be passed an acceptable new variable name, or null if change is to be\n *     aborted (cancel button), or undefined if an existing variable was chosen.\n */\nBlockly.Variables.createVariable = function(workspace, opt_callback) {\n  var promptAndCheckWithAlert = function(defaultName) {\n    Blockly.Variables.promptName(Blockly.Msg.NEW_VARIABLE_TITLE, defaultName,\n      function(text) {\n        if (text) {\n          if (workspace.getVariable(text)) {\n            Blockly.alert(Blockly.Msg.VARIABLE_ALREADY_EXISTS.replace('%1',\n                text.toLowerCase()),\n                function() {\n                  promptAndCheckWithAlert(text);  // Recurse\n                });\n          }\n          else if (!Blockly.Procedures.isLegalName_(text, workspace)) {\n            Blockly.alert(Blockly.Msg.PROCEDURE_ALREADY_EXISTS.replace('%1',\n                text.toLowerCase()),\n                function() {\n                  promptAndCheckWithAlert(text);  // Recurse\n                });\n          }\n          else {\n            workspace.createVariable(text);\n            if (opt_callback) {\n              opt_callback(text);\n            }\n          }\n        } else {\n          // User canceled prompt without a value.\n          if (opt_callback) {\n            opt_callback(null);\n          }\n        }\n      });\n  };\n  promptAndCheckWithAlert('');\n};\n\n/**\n * Prompt the user for a new variable name.\n * @param {string} promptText The string of the prompt.\n * @param {string} defaultText The default value to show in the prompt's field.\n * @param {function(?string)} callback A callback. It will be passed the new\n *     variable name, or null if the user picked something illegal.\n */\nBlockly.Variables.promptName = function(promptText, defaultText, callback) {\n  Blockly.prompt(promptText, defaultText, function(newVar) {\n    // Merge runs of whitespace.  Strip leading and trailing whitespace.\n    // Beyond this, all names are legal.\n    if (newVar) {\n      newVar = newVar.replace(/[\\s\\xa0]+/g, ' ').replace(/^ | $/g, '');\n      if (newVar == Blockly.Msg.RENAME_VARIABLE ||\n          newVar == Blockly.Msg.NEW_VARIABLE) {\n        // Ok, not ALL names are legal...\n        newVar = null;\n      }\n    }\n    callback(newVar);\n  });\n};\n", "idx": 1, "id": 8386, "msg": "Please rename to `flyout`.", "proj": "LLK-scratch-blocks", "lang": "js"}
{"patch": "@@ -7,6 +7,7 @@\n package staking\n \n import (\n+\t\"bytes\"\n \t\"github.com/pkg/errors\"\n \n \t\"github.com/iotexproject/iotex-address/address\"", "y": 0, "oldf": "// Copyright (c) 2020 IoTeX Foundation\n// This is an alpha (internal) release and is not suitable for production. This source code is provided 'as is' and no\n// warranties are given as to title or non-infringement, merchantability or fitness for purpose and, to the extent\n// permitted by law, all liability for your use of the code is disclaimed. This source code is governed by Apache\n// License 2.0 that can be found in the LICENSE file.\n\npackage staking\n\nimport (\n\t\"github.com/pkg/errors\"\n\n\t\"github.com/iotexproject/iotex-address/address\"\n\n\t\"github.com/iotexproject/iotex-core/action/protocol\"\n\t\"github.com/iotexproject/iotex-core/state\"\n)\n\ntype (\n\t// CandidateStateManager is candidate manager on top of StateMangaer\n\tCandidateStateManager interface {\n\t\tprotocol.StateManager\n\t\t// candidate-related\n\t\tSize() int\n\t\tContainsName(string) bool\n\t\tContainsOwner(address.Address) bool\n\t\tContainsOperator(address.Address) bool\n\t\tContainsSelfStakingBucket(uint64) bool\n\t\tGetByName(string) *Candidate\n\t\tGetByOwner(address.Address) *Candidate\n\t\tGetBySelfStakingIndex(uint64) *Candidate\n\t\tUpsert(*Candidate) error\n\t\tCommit() error\n\t}\n\n\tcandSM struct {\n\t\tprotocol.StateManager\n\t\tCandidateCenter\n\t}\n)\n\n// NewCandidateStateManager returns a new CandidateStateManager instance\nfunc NewCandidateStateManager(sm protocol.StateManager, c CandidateCenter) (CandidateStateManager, error) {\n\tif sm == nil {\n\t\treturn nil, ErrMissingField\n\t}\n\n\tcsm := candSM{\n\t\tsm,\n\t\tc,\n\t}\n\n\t// extract view change from SM\n\tdelta, err := retrieveDeltaFromSM(sm)\n\tswitch errors.Cause(err) {\n\tcase ErrTypeAssertion:\n\t\t{\n\t\t\treturn nil, errors.Wrap(err, \"failed to create CandidateStateManager\")\n\t\t}\n\tcase ErrNilParameters:\n\t\t{\n\t\t\treturn &csm, nil\n\t\t}\n\t}\n\n\t// add delta to the center\n\tif err := c.SetDelta(delta); err != nil {\n\t\treturn nil, err\n\t}\n\treturn &csm, nil\n}\n\n// Upsert writes the candidate into state manager and cand center\nfunc (csm *candSM) Upsert(d *Candidate) error {\n\tif err := csm.CandidateCenter.Upsert(d); err != nil {\n\t\treturn err\n\t}\n\n\tif err := putCandidate(csm.StateManager, d); err != nil {\n\t\treturn err\n\t}\n\n\tdelta := csm.Delta()\n\tif len(delta) == 0 {\n\t\treturn nil\n\t}\n\n\tser, err := delta.Serialize()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// load change to sm\n\tcsm.StateManager.Load(protocolID, ser)\n\treturn nil\n}\n\nfunc (csm *candSM) Commit() error {\n\tif err := csm.CandidateCenter.Commit(); err != nil {\n\t\treturn err\n\t}\n\n\t// write update view back to state factory\n\treturn csm.WriteView(protocolID, csm.CandidateCenter)\n}\n\nfunc getOrCreateCandCenter(sr protocol.StateReader) (CandidateCenter, error) {\n\tc, err := getCandCenter(sr)\n\tif err != nil {\n\t\tif errors.Cause(err) == protocol.ErrNoName {\n\t\t\t// the view does not exist yet, create it\n\t\t\tcc, err := createCandCenter(sr)\n\t\t\treturn cc, err\n\t\t}\n\t\treturn nil, err\n\t}\n\treturn c, nil\n}\n\nfunc getCandCenter(sr protocol.StateReader) (CandidateCenter, error) {\n\tv, err := sr.ReadView(protocolID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif center, ok := v.(CandidateCenter); ok {\n\t\treturn center, nil\n\t}\n\treturn nil, errors.Wrap(ErrTypeAssertion, \"expecting CandidateCenter\")\n}\n\nfunc createCandCenter(sr protocol.StateReader) (CandidateCenter, error) {\n\tall, err := loadCandidatesFromSR(sr)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn NewCandidateCenter(all)\n}\n\nfunc loadCandidatesFromSR(sr protocol.StateReader) (CandidateList, error) {\n\t_, iter, err := sr.States(protocol.NamespaceOption(CandidateNameSpace))\n\tif errors.Cause(err) == state.ErrStateNotExist {\n\t\treturn nil, nil\n\t}\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tcands := make(CandidateList, 0, iter.Size())\n\tfor i := 0; i < iter.Size(); i++ {\n\t\tc := &Candidate{}\n\t\tif err := iter.Next(c); err != nil {\n\t\t\treturn nil, errors.Wrapf(err, \"failed to deserialize candidate\")\n\t\t}\n\t\tcands = append(cands, c)\n\t}\n\treturn cands, nil\n}\n\nfunc retrieveDeltaFromSM(sm protocol.StateManager) (CandidateList, error) {\n\tv, err := sm.Unload(protocolID)\n\tif err != nil {\n\t\tif errors.Cause(err) == protocol.ErrNoName {\n\t\t\t// the protocol hasn't pushed any data yet, return empty\n\t\t\treturn nil, ErrNilParameters\n\t\t}\n\t\treturn nil, err\n\t}\n\n\tser, ok := v.([]byte)\n\tif !ok {\n\t\treturn nil, errors.Wrap(ErrTypeAssertion, \"failed to retrieveDeltaFromSM, expecting []byte\")\n\t}\n\n\tl := CandidateList{}\n\tif err := l.Deserialize(ser); err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to retrieveDeltaFromSM\")\n\t}\n\treturn l, nil\n}\n", "idx": 1, "id": 21927, "msg": "", "proj": "iotexproject-iotex-core", "lang": "go"}
{"patch": "@@ -1002,7 +1002,9 @@ def parse_unique_log(compilation_database,\n \n             action = parse_options(entry,\n                                    compiler_info_file,\n-                                   keep_gcc_fix_headers)\n+                                   keep_gcc_fix_headers,\n+                                   clangsa.version.get,\n+                                   env)\n \n             if not action.lang:\n                 continue", "y": 0, "oldf": "# -------------------------------------------------------------------------\n#                     The CodeChecker Infrastructure\n#   This file is distributed under the University of Illinois Open Source\n#   License. See LICENSE.TXT for details.\n# -------------------------------------------------------------------------\n\nfrom __future__ import print_function\nfrom __future__ import absolute_import\n\nfrom collections import defaultdict\n# pylint: disable=no-name-in-module\nfrom distutils.spawn import find_executable\n\nimport json\nimport os\nimport re\nimport shlex\nimport subprocess\nimport sys\nimport tempfile\nimport traceback\n\nfrom codechecker_common.logger import get_logger\nfrom codechecker_common.util import load_json_or_empty\n\nfrom .. import gcc_toolchain\nfrom .build_action import BuildAction\n\nLOG = get_logger('buildlogger')\n\n# Replace gcc/g++ build target options with values accepted by Clang.\nREPLACE_OPTIONS_MAP = {\n    '-mips32': ['-target', 'mips', '-mips32'],\n    '-mips64': ['-target', 'mips64', '-mips64'],\n    '-mpowerpc': ['-target', 'powerpc'],\n    '-mpowerpc64': ['-target', 'powerpc64']\n}\n\n# The compilation flags of which the prefix is any of these regular expressions\n# will not be included in the output Clang command.\nIGNORED_OPTIONS = [\n    # --- UNKNOWN BY CLANG --- #\n    '-fallow-fetchr-insn',\n    '-fcall-saved-',\n    '-fcond-mismatch',\n    '-fconserve-stack',\n    '-fcrossjumping',\n    '-fcse-follow-jumps',\n    '-fcse-skip-blocks',\n    '-ffixed-r2',\n    '-ffp$',\n    '-fgcse-lm',\n    '-fhoist-adjacent-loads',\n    '-findirect-inlining',\n    '-finline-limit',\n    '-finline-local-initialisers',\n    '-fipa-sra',\n    '-fno-aggressive-loop-optimizations',\n    '-fno-delete-null-pointer-checks',\n    '-fno-jump-table',\n    '-fno-strength-reduce',\n    '-fno-toplevel-reorder',\n    '-fno-unit-at-a-time',\n    '-fno-var-tracking-assignments',\n    '-fobjc-link-runtime',\n    '-fpartial-inlining',\n    '-fpeephole2',\n    '-fr$',\n    '-fregmove',\n    '-frename-registers',\n    '-freorder-functions',\n    '-frerun-cse-after-loop',\n    '-fs$',\n    '-fsched-spec',\n    '-fstack-reuse',\n    '-fthread-jumps',\n    '-ftree-pre',\n    '-ftree-switch-conversion',\n    '-ftree-tail-merge',\n    '-m(no-)?abm',\n    '-m(no-)?sdata',\n    '-m(no-)?spe',\n    '-m(no-)?string$',\n    '-m(no-)?dsbt',\n    '-m(no-)?fixed-ssp',\n    '-m(no-)?pointers-to-nested-functions',\n    '-mpcrel-func-addr',\n    '-maccumulate-outgoing-args',\n    '-mcall-aixdesc',\n    '-mppa3-addr-bug',\n    '-mtraceback=',\n    '-mtext=',\n    '-misa=',\n    '-mfunction-return=',\n    '-mindirect-branch-register',\n    '-mindirect-branch=',\n    '-mfix-cortex-m3-ldrd$',\n    '-mmultiple$',\n    '-msahf$',\n    '-mthumb-interwork$',\n    '-mupdate$',\n\n    # Deprecated ARM specific option\n    # to Generate a stack frame that is compliant\n    # with the ARM Procedure Call Standard.\n    '-mapcs',\n    '-fno-merge-const-bfstores$',\n    '-fno-ipa-sra$',\n    '-mno-thumb-interwork$',\n    # ARM specific option.\n    # Prevent the reordering of\n    # instructions in the function prologue.\n    '-mno-sched-prolog',\n    # This is not unknown but we want to preserve asserts to improve the\n    # quality of analysis.\n    '-DNDEBUG$',\n\n    # --- IGNORED --- #\n    '-save-temps',\n    # Clang gives different warnings than GCC. Thus if these flags are kept,\n    # '-Werror', '-pedantic-errors' the analysis with Clang can fail even\n    # if the compilation passes with GCC.\n    '-Werror',\n    '-pedantic-errors',\n    '-g(.+)?$',\n    # Link Time Optimization:\n    '-flto',\n    # MicroBlaze Options:\n    '-mxl',\n    # PowerPC SPE Options:\n    '-mfloat-gprs',\n    '-mabi'\n]\n\nIGNORED_OPTIONS = re.compile('|'.join(IGNORED_OPTIONS))\n\n# The compilation flags of which the prefix is any of these regular expressions\n# will not be included in the output Clang command. These flags have further\n# parameters which are also omitted. The number of parameters is indicated in\n# this dictionary.\nIGNORED_PARAM_OPTIONS = {\n    re.compile('-install_name'): 1,\n    re.compile('-exported_symbols_list'): 1,\n    re.compile('-current_version'): 1,\n    re.compile('-compatibility_version'): 1,\n    re.compile('-init$'): 1,\n    re.compile('-e$'): 1,\n    re.compile('-seg1addr'): 1,\n    re.compile('-bundle_loader'): 1,\n    re.compile('-multiply_defined'): 1,\n    re.compile('-sectorder'): 3,\n    re.compile('--param$'): 1,\n    re.compile('-u$'): 1,\n    re.compile('--serialize-diagnostics'): 1,\n    re.compile('-framework'): 1,\n    # Skip paired Xclang options like \"-Xclang -mllvm\".\n    re.compile('-Xclang'): 1,\n    # Darwin linker can be given a file with lists the sources for linking.\n    re.compile('-filelist'): 1\n}\n\n# These flag groups are ignored together.\n# TODO: This list is not used yet, but will be applied in the next release.\nIGNORED_FLAG_LISTS = [\n  ['-Xclang', '-mllvm'],\n  ['-Xclang', '-emit-llvm'],\n  ['-Xclang', '-instcombine-lower-dbg-declare=0']\n]\n\nCOMPILE_OPTIONS = [\n    '-nostdinc',\n    r'-nostdinc\\+\\+',\n    '-pedantic',\n    '-O[1-3]',\n    '-Os',\n    '-std=',\n    '-stdlib=',\n    '-f',\n    '-m',\n    '-Wno-',\n    '--sysroot=',\n    '--gcc-toolchain='\n]\n\nCOMPILE_OPTIONS = re.compile('|'.join(COMPILE_OPTIONS))\n\nCOMPILE_OPTIONS_MERGED = [\n    '--sysroot',\n    '--include',\n    '-include',\n    '-iquote',\n    '-[DIUF]',\n    '-idirafter',\n    '-isystem',\n    '-macros',\n    '-isysroot',\n    '-iprefix',\n    '-iwithprefix',\n    '-iwithprefixbefore'\n]\n\n\nCOMPILE_OPTIONS_MERGED = \\\n    re.compile('(' + '|'.join(COMPILE_OPTIONS_MERGED) + ')')\n\nPRECOMPILATION_OPTION = re.compile('-(E|M[T|Q|F|J|P|V|M]*)$')\n\n\ndef filter_compiler_includes_extra_args(compiler_flags):\n    \"\"\"Return the list of flags which affect the list of implicit includes.\n\n    compiler_flags -- A list of compiler flags which may affect the list\n                      of implicit compiler include paths, like -std=,\n                      --sysroot=, -m32, -m64, -nostdinc or -stdlib=.\n    \"\"\"\n    # If these options are present in the original build command, they must\n    # be forwarded to get_compiler_includes and get_compiler_defines so the\n    # resulting includes point to the target that was used in the build.\n    pattern = re.compile('-m(32|64)|-std=|-stdlib=|-nostdinc')\n    extra_opts = filter(pattern.match, compiler_flags)\n\n    pos = next((pos for pos, val in enumerate(compiler_flags)\n                if val.startswith('--sysroot')), None)\n    if pos is not None:\n        if compiler_flags[pos] == '--sysroot':\n            extra_opts.append('--sysroot=' + compiler_flags[pos + 1])\n        else:\n            extra_opts.append(compiler_flags[pos])\n\n    return extra_opts\n\n\nclass ImplicitCompilerInfo(object):\n    \"\"\"\n    This class helps to fetch and set some additional compiler flags which are\n    implicitly added when using GCC.\n    \"\"\"\n    # TODO: This dict is mapping compiler to the corresponding information.\n    # It may not be enough to use the compiler as a key, because the implicit\n    # information depends on other data like language or target architecture.\n    compiler_info = defaultdict(dict)\n    compiler_isexecutable = {}\n\n    @staticmethod\n    def c():\n        return \"c\"\n\n    @staticmethod\n    def cpp():\n        return \"c++\"\n\n    @staticmethod\n    def is_executable_compiler(compiler):\n        if compiler not in ImplicitCompilerInfo.compiler_isexecutable:\n            ImplicitCompilerInfo.compiler_isexecutable[compiler] = \\\n                find_executable(compiler) is not None\n\n        return ImplicitCompilerInfo.compiler_isexecutable[compiler]\n\n    @staticmethod\n    def __get_compiler_err(cmd):\n        \"\"\"\n        Returns the stderr of a compiler invocation as string\n        or None in case of error.\n        \"\"\"\n        try:\n            LOG.debug(\"Retrieving default includes via '\" + cmd + \"'\")\n            proc = subprocess.Popen(shlex.split(cmd),\n                                    stdin=subprocess.PIPE,\n                                    stdout=subprocess.PIPE,\n                                    stderr=subprocess.PIPE,\n                                    universal_newlines=True)\n\n            _, err = proc.communicate(\"\")\n            return err\n        except OSError as oerr:\n            LOG.error(\"Error during process execution: \" + cmd + '\\n' +\n                      oerr.strerror + \"\\n\")\n\n    @staticmethod\n    def __parse_compiler_includes(lines):\n        \"\"\"\n        Parse the compiler include paths from a string\n        \"\"\"\n        start_mark = \"#include <...> search starts here:\"\n        end_mark = \"End of search list.\"\n\n        include_paths = []\n\n        if not lines:\n            return include_paths\n\n        do_append = False\n        for line in lines.splitlines():\n            if line.startswith(end_mark):\n                break\n            if do_append:\n                line = line.strip()\n                # On OSX there are framework includes,\n                # where we need to strip the \"(framework directory)\" string.\n                # For instance:\n                # /System/Library/Frameworks (framework directory)\n                fpos = line.find(\"(framework directory)\")\n                if fpos == -1:\n                    include_paths.append(line)\n                else:\n                    include_paths.append(line[:fpos - 1])\n\n            if line.startswith(start_mark):\n                do_append = True\n\n        return include_paths\n\n    @staticmethod\n    def get_compiler_includes(compiler, language, compiler_flags):\n        \"\"\"\n        Returns a list of default includes of the given compiler.\n\n        compiler -- The compiler binary of which the implicit include paths are\n                    fetched.\n        language -- The programming language being compiled (e.g. 'c' or 'c++')\n        compiler_flags -- the flags used for compilation\n        \"\"\"\n        extra_opts = filter_compiler_includes_extra_args(compiler_flags)\n        cmd = compiler + \" \" + ' '.join(extra_opts) \\\n            + \" -E -x \" + language + \" - -v \"\n\n        ICI = ImplicitCompilerInfo\n        include_dirs = \\\n            ICI.__parse_compiler_includes(ICI.__get_compiler_err(cmd))\n\n        return map(os.path.normpath, include_dirs)\n\n    @staticmethod\n    def get_compiler_target(compiler):\n        \"\"\"\n        Returns the target triple of the given compiler as a string.\n\n        compiler -- The compiler binary of which the target architecture is\n                    fetched.\n        \"\"\"\n        lines = ImplicitCompilerInfo.__get_compiler_err(compiler + ' -v')\n\n        if lines is None:\n            return \"\"\n\n        target_label = \"Target:\"\n        target = \"\"\n\n        for line in lines.splitlines(True):\n            line = line.strip().split()\n            if len(line) > 1 and line[0] == target_label:\n                target = line[1]\n\n        return target\n\n    @staticmethod\n    def get_compiler_standard(compiler, language):\n        \"\"\"\n        Returns the default compiler standard of the given compiler. The\n        standard is determined by the values of __STDC_VERSION__ and\n        __cplusplus predefined macros. These values are integers indicating the\n        date of the standard. However, GCC supports a GNU extension for each\n        standard. For sake of generality we return the GNU extended standard,\n        since it should be a superset of the non-extended one, thus applicable\n        in a more general manner.\n\n        compiler -- The compiler binary of which the default compiler standard\n                    is fetched.\n        language -- The programming lenguage being compiled (e.g. 'c' or 'c++')\n        \"\"\"\n        VERSION_C = u\"\"\"\n#ifdef __STDC_VERSION__\n#  if __STDC_VERSION__ >= 201710L\n#    error CC_FOUND_STANDARD_VER#17\n#  elif __STDC_VERSION__ >= 201112L\n#    error CC_FOUND_STANDARD_VER#11\n#  elif __STDC_VERSION__ >= 199901L\n#    error CC_FOUND_STANDARD_VER#99\n#  elif __STDC_VERSION__ >= 199409L\n#    error CC_FOUND_STANDARD_VER#94\n#  else\n#    error CC_FOUND_STANDARD_VER#90\n#  endif\n#else\n#  error CC_FOUND_STANDARD_VER#90\n#endif\n        \"\"\"\n\n        VERSION_CPP = u\"\"\"\n#ifdef __cplusplus\n#  if __cplusplus >= 201703L\n#    error CC_FOUND_STANDARD_VER#17\n#  elif __cplusplus >= 201402L\n#    error CC_FOUND_STANDARD_VER#14\n#  elif __cplusplus >= 201103L\n#    error CC_FOUND_STANDARD_VER#11\n#  elif __cplusplus >= 199711L\n#    error CC_FOUND_STANDARD_VER#98\n#  else\n#    error CC_FOUND_STANDARD_VER#98\n#  endif\n#else\n#  error CC_FOUND_STANDARD_VER#98\n#endif\n        \"\"\"\n\n        standard = \"\"\n        with tempfile.NamedTemporaryFile(\n                mode='w+',\n                suffix=('.c' if language == 'c' else '.cpp')) as source:\n\n            with source.file as f:\n                f.write(VERSION_C if language == 'c' else VERSION_CPP)\n\n            err = ImplicitCompilerInfo.\\\n                __get_compiler_err(\" \".join([compiler, source.name]))\n\n            if err is not None:\n                finding = re.search('CC_FOUND_STANDARD_VER#(.+)', err)\n                if finding:\n                    standard = finding.group(1)\n\n        if standard:\n            if standard == '94':\n                # Special case for C94 standard.\n                standard = '-std=iso9899:199409'\n            else:\n                standard = '-std=gnu' \\\n                    + ('' if language == 'c' else '++') \\\n                    + standard\n\n        return standard\n\n    @staticmethod\n    def load_compiler_info(filename, compiler):\n        \"\"\"Load compiler information from a file.\"\"\"\n        contents = load_json_or_empty(filename, {})\n        compiler_info = contents.get(compiler)\n        if compiler_info is None:\n            LOG.error(\"Could not find compiler %s in file %s\",\n                      compiler, filename)\n            return\n\n        ICI = ImplicitCompilerInfo\n\n        if not ICI.compiler_info.get(compiler):\n            ICI.compiler_info[compiler] = defaultdict(dict)\n\n        # Load for language C\n        ICI.compiler_info[compiler][ICI.c()]['compiler_includes'] = []\n        c_lang_data = compiler_info.get(ICI.c())\n        if c_lang_data:\n            for element in map(shlex.split,\n                               c_lang_data.get(\"compiler_includes\")):\n                element = filter(lambda x: x != '-isystem', element)\n                ICI.compiler_info[compiler][ICI.c()]['compiler_includes'] \\\n                    .extend(element)\n            ICI.compiler_info[compiler][ICI.c()]['compiler_standard'] = \\\n                c_lang_data.get('compiler_standard')\n            ICI.compiler_info[compiler][ICI.c()]['target'] = \\\n                c_lang_data.get('target')\n\n        # Load for language C++\n        ICI.compiler_info[compiler][ICI.cpp()]['compiler_includes'] = []\n        cpp_lang_data = compiler_info.get(ICI.cpp())\n        if cpp_lang_data:\n            for element in map(shlex.split,\n                               cpp_lang_data.get('compiler_includes')):\n                element = filter(lambda x: x != '-isystem', element)\n                ICI.compiler_info[compiler][ICI.cpp()]['compiler_includes'] \\\n                    .extend(element)\n            ICI.compiler_info[compiler][ICI.cpp()]['compiler_standard'] = \\\n                cpp_lang_data.get('compiler_standard')\n            ICI.compiler_info[compiler][ICI.cpp()]['target'] = \\\n                cpp_lang_data.get('target')\n\n    @staticmethod\n    def set(details, compiler_info_file=None):\n        \"\"\"Detect and set the impicit compiler information.\n\n        If compiler_info_file is available the implicit compiler\n        information will be loaded and set from it.\n        \"\"\"\n        ICI = ImplicitCompilerInfo\n\n        compiler = details['compiler']\n        if compiler_info_file and os.path.exists(compiler_info_file):\n            # Compiler info file exists, load it.\n            ICI.load_compiler_info(compiler_info_file, compiler)\n        else:\n            # Invoke compiler to gather implicit compiler info.\n            # Independently of the actual compilation language in the\n            # compile command collect the iformation for C and C++.\n            if not ICI.compiler_info.get(compiler):\n                ICI.compiler_info[compiler] = defaultdict(dict)\n\n                # Collect for C\n                ICI.compiler_info[compiler][ICI.c()]['compiler_includes'] = \\\n                    ICI.get_compiler_includes(compiler, ICI.c(),\n                                              details['analyzer_options'])\n                ICI.compiler_info[compiler][ICI.c()]['target'] = \\\n                    ICI.get_compiler_target(compiler)\n                ICI.compiler_info[compiler][ICI.c()]['compiler_standard'] = \\\n                    ICI.get_compiler_standard(compiler, ICI.c())\n\n                # Collect for C++\n                ICI.compiler_info[compiler][ICI.cpp()]['compiler_includes'] = \\\n                    ICI.get_compiler_includes(compiler, ICI.cpp(),\n                                              details['analyzer_options'])\n                ICI.compiler_info[compiler][ICI.cpp()]['target'] = \\\n                    ICI.get_compiler_target(compiler)\n                ICI.compiler_info[compiler][ICI.cpp()]['compiler_standard'] = \\\n                    ICI.get_compiler_standard(compiler, ICI.cpp())\n\n        def set_details_from_ICI(key, lang):\n            \"\"\"Set compiler related information in the 'details' dictionary.\n\n            If the language dependent value is not set yet, get the compiler\n            information from ICI.\n            \"\"\"\n\n            parsed_value = details[key].get(lang)\n            if parsed_value:\n                details[key][lang] = parsed_value\n            else:\n                # Only set what is available from ICI.\n                compiler_data = ICI.compiler_info.get(compiler)\n                if compiler_data:\n                    language_data = compiler_data.get(lang)\n                    if language_data:\n                        details[key][lang] = language_data.get(key)\n\n        set_details_from_ICI('compiler_includes', ICI.c())\n        set_details_from_ICI('compiler_standard', ICI.c())\n        set_details_from_ICI('target', ICI.c())\n\n        set_details_from_ICI('compiler_includes', ICI.cpp())\n        set_details_from_ICI('compiler_standard', ICI.cpp())\n        set_details_from_ICI('target', ICI.cpp())\n\n    @staticmethod\n    def get():\n        return ImplicitCompilerInfo.compiler_info\n\n\nclass OptionIterator(object):\n\n    def __init__(self, args):\n        self._item = None\n        self._it = iter(args)\n\n    def __next__(self):\n        self._item = next(self._it)\n        return self\n\n    next = __next__\n\n    def __iter__(self):\n        return self\n\n    @property\n    def item(self):\n        return self._item\n\n\ndef get_language(extension):\n    # TODO: There are even more in the man page of gcc.\n    mapping = {'.c': 'c',\n               '.cp': 'c++',\n               '.cpp': 'c++',\n               '.cxx': 'c++',\n               '.txx': 'c++',\n               '.cc': 'c++',\n               '.C': 'c++',\n               '.ii': 'c++',\n               '.m': 'objective-c',\n               '.mm': 'objective-c++'}\n    return mapping.get(extension)\n\n\ndef determine_compiler(gcc_command, is_executable_compiler_fun):\n    \"\"\"\n    This function determines the compiler from the given compilation command.\n    If the first part of the gcc_command is ccache invocation then the rest\n    should be a complete compilation command.\n\n    CCache may have three forms:\n    1. ccache g++ main.cpp\n    2. ccache main.cpp\n    3. /usr/lib/ccache/gcc main.cpp\n    In the first case this function drops \"ccache\" from gcc_command and returns\n    the next compiler name.\n    In the second case the compiler can be given by config files or an\n    environment variable. Currently we don't handle this version, and in this\n    case the compiler remanis \"ccache\" and the gcc_command is not changed.\n    The two cases are distinguished by checking whether the second parameter is\n    an executable or not.\n    In the third case gcc is a symlink to ccache, but we can handle\n    it as a normal compiler.\n\n    gcc_command -- A split build action as a list which may or may not start\n                   with ccache.\n\n    TODO: The second case could be handled if there was a way for querying the\n    used compiler from ccache. This can be configured for ccache in config\n    files or environment variables.\n    \"\"\"\n    if gcc_command[0].endswith('ccache'):\n        if is_executable_compiler_fun(gcc_command[1]):\n            return gcc_command[1]\n\n    return gcc_command[0]\n\n\ndef filter_compiler_includes(include_dirs):\n    \"\"\"\n    Filter the list of compiler includes.\n    We want to elide GCC's include-fixed and instrinsic directory.\n    See docs/gcc_incompatibilities.md\n    \"\"\"\n\n    def contains_intrinsic_headers(include_dir):\n        \"\"\"\n        Returns True if the given directory contains at least one intrinsic\n        header.\n        \"\"\"\n        if not os.path.exists(include_dir):\n            return False\n        for f in os.listdir(include_dir):\n            if f.endswith(\"intrin.h\"):\n                return True\n        return False\n\n    result = []\n    for include_dir in include_dirs:\n        # Skip GCC's fixinclude dir\n        if os.path.basename(\n                os.path.normpath(include_dir)) == \"include-fixed\":\n            continue\n        if contains_intrinsic_headers(include_dir):\n            continue\n        result.append(include_dir)\n    return result\n\n\ndef __collect_compile_opts(flag_iterator, details):\n    \"\"\"\n    This function collects the compilation (i.e. not linker or preprocessor)\n    flags to the buildaction.\n    \"\"\"\n    if COMPILE_OPTIONS.match(flag_iterator.item):\n        details['analyzer_options'].append(flag_iterator.item)\n        return True\n\n    m = COMPILE_OPTIONS_MERGED.match(flag_iterator.item)\n\n    if m:\n        flag = m.group(0)\n        together = len(flag) != len(flag_iterator.item)\n\n        if together:\n            param = flag_iterator.item[len(flag):]\n        else:\n            next(flag_iterator)\n            param = flag_iterator.item\n\n        # The .plist file contains a section with a list of files. For some\n        # further actions these need to be given with an absolute path. Clang\n        # prints them with absolute path if the original compiler invocation\n        # was given absolute paths.\n        # TODO: If Clang will be extended with an extra analyzer option in\n        # order to print these absolute paths natively, this conversion will\n        # not be necessary.\n        flags_with_path = ['-I', '-idirafter', '-imacros', '-imultilib',\n                           '-include', '-iquote', '-isysroot', '-isystem',\n                           '-iwithprefix', '-iwithprefixbefore', '-sysroot',\n                           '--sysroot']\n        if flag in flags_with_path:\n            param = os.path.normpath(\n                os.path.join(details['directory'], param))\n\n        if together:\n            details['analyzer_options'].append(flag + param)\n        else:\n            details['analyzer_options'].extend([flag, param])\n\n        return True\n\n    return False\n\n\ndef __skip_sources(flag_iterator, _):\n    \"\"\"\n    This function skips the compiled source file names (i.e. the arguments\n    which don't start with a dash character).\n    \"\"\"\n    if flag_iterator.item[0] != '-':\n        return True\n\n    return False\n\n\ndef __determine_action_type(flag_iterator, details):\n    \"\"\"\n    This function determines whether this is a preprocessing, compilation or\n    linking action and sets it in the buildaction object. If the action type is\n    set to COMPILE earlier then we don't set it to anything else.\n    \"\"\"\n    if flag_iterator.item == '-c':\n        details['action_type'] = BuildAction.COMPILE\n        return True\n    elif flag_iterator.item.startswith('-print-prog-name'):\n        if details['action_type'] != BuildAction.COMPILE:\n            details['action_type'] = BuildAction.INFO\n        return True\n    elif PRECOMPILATION_OPTION.match(flag_iterator.item):\n        if details['action_type'] != BuildAction.COMPILE:\n            details['action_type'] = BuildAction.PREPROCESS\n        return True\n\n    return False\n\n\ndef __get_arch(flag_iterator, details):\n    \"\"\"\n    This function consumes -arch flag which is followed by the target\n    architecture. This is then collected to the buildaction object.\n    \"\"\"\n    # TODO: Is this really a target architecture? Have we seen this flag being\n    # used in a real project? This -arch flag is not really documented among\n    # GCC flags.\n    # Where do we use this architecture during analysis and why?\n    if flag_iterator.item == '-arch':\n        next(flag_iterator)\n        details['arch'] = flag_iterator.item\n        return True\n\n    return False\n\n\ndef __get_language(flag_iterator, details):\n    \"\"\"\n    This function consumes -x flag which is followed by the language. This\n    language is then collected to the buildaction object.\n    \"\"\"\n    # TODO: Known issue: a -x flag may precede all source files in the build\n    # command with different languages.\n    if flag_iterator.item.startswith('-x'):\n        if flag_iterator.item == '-x':\n            next(flag_iterator)\n            details['lang'] = flag_iterator.item\n        else:\n            details['lang'] = flag_iterator.item[2:]  # 2 == len('-x')\n        return True\n    return False\n\n\ndef __get_output(flag_iterator, details):\n    \"\"\"\n    This function consumes -o flag which is followed by the output file of the\n    action. This file is then collected to the buildaction object.\n    \"\"\"\n    if flag_iterator.item == '-o':\n        next(flag_iterator)\n        details['output'] = flag_iterator.item\n        return True\n\n    return False\n\n\ndef __replace(flag_iterator, details):\n    \"\"\"\n    This function extends the analyzer options list with the corresponding\n    replacement based on REPLACE_OPTIONS_MAP if the flag_iterator is currently\n    pointing to a flag to replace.\n    \"\"\"\n    value = REPLACE_OPTIONS_MAP.get(flag_iterator.item)\n\n    if value:\n        details['analyzer_options'].extend(value)\n\n    return bool(value)\n\n\ndef __skip(flag_iterator, _):\n    \"\"\"\n    This function skips the flag pointed by the given flag_iterator with its\n    parameters if any.\n    \"\"\"\n    if IGNORED_OPTIONS.match(flag_iterator.item):\n        return True\n\n    for pattern, arg_num in IGNORED_PARAM_OPTIONS.items():\n        if pattern.match(flag_iterator.item):\n            for _ in range(arg_num):\n                next(flag_iterator)\n            return True\n\n    return False\n\n\ndef parse_options(compilation_db_entry,\n                  compiler_info_file=None,\n                  keep_gcc_fix_headers=False):\n    \"\"\"\n    This function parses a GCC compilation action and returns a BuildAction\n    object which can be the input of Clang analyzer tools.\n\n    compilation_db_entry -- An entry from a valid compilation database JSON\n                            file, i.e. a dictionary with the compilation\n                            command, the compiled file and the current working\n                            directory.\n    compiler_info_file -- Contains the path to a compiler info file.\n    keep_gcc_fix_headers -- There are some implicit include paths which are\n                            only used by GCC (include-fixed). This flag\n                            determines whether these should be kept among\n                            the implicit include paths.\n    \"\"\"\n\n    details = {\n        'analyzer_options': [],\n        'compiler_includes': defaultdict(dict),  # For each language c/cpp.\n        'compiler_standard': defaultdict(dict),  # For each language c/cpp.\n        'analyzer_type': -1,\n        'original_command': '',\n        'directory': '',\n        'output': '',\n        'lang': None,\n        'arch': '',  # Target in the compile command set by -arch.\n        'target': defaultdict(dict),\n        'source': ''}\n\n    if 'arguments' in compilation_db_entry:\n        gcc_command = compilation_db_entry['arguments']\n        details['original_command'] = ' '.join(gcc_command)\n    elif 'command' in compilation_db_entry:\n        details['original_command'] = compilation_db_entry['command']\n        gcc_command = shlex.split(compilation_db_entry['command'])\n    else:\n        raise KeyError(\"No valid 'command' or 'arguments' entry found!\")\n\n    details['directory'] = compilation_db_entry['directory']\n    details['action_type'] = None\n    details['compiler'] =\\\n        determine_compiler(gcc_command,\n                           ImplicitCompilerInfo.is_executable_compiler)\n    if '++' in os.path.basename(details['compiler']):\n        details['lang'] = 'c++'\n\n    flag_transformers = [\n        __skip,\n        __replace,\n        __collect_compile_opts,\n        __determine_action_type,\n        __skip_sources,\n        __get_arch,\n        __get_language,\n        __get_output]\n\n    for it in OptionIterator(gcc_command[1:]):\n        for flag_transformer in flag_transformers:\n            if flag_transformer(it, details):\n                break\n        else:\n            pass\n            # print('Unhandled argument: ' + it.item)\n\n    if details['action_type'] is None:\n        details['action_type'] = BuildAction.COMPILE\n\n    details['source'] = os.path.normpath(\n        os.path.join(compilation_db_entry['directory'],\n                     compilation_db_entry['file']))\n\n    # In case the file attribute in the entry is empty.\n    if details['source'] == '.':\n        details['source'] = ''\n\n    lang = get_language(os.path.splitext(details['source'])[1])\n    if lang:\n        if details['lang'] is None:\n            details['lang'] = lang\n    else:\n        details['action_type'] = BuildAction.LINK\n\n    # Option parser detects target architecture but does not know about the\n    # language during parsing. Set the collected compilation target for the\n    # language detected language.\n    details['target'][lang] = details['arch']\n\n    # With gcc-toolchain a non default compiler toolchain can be set. Clang\n    # will search for include paths and libraries based on the gcc-toolchain\n    # parameter. Detecting extra include paths from the host compiler could\n    # conflict with this.\n\n    # For example if the compiler in the compile command is clang and\n    # gcc-toolchain is set we will get the include paths for clang and not for\n    # the compiler set in gcc-toolchain. This can cause missing headers during\n    # the analysis.\n\n    toolchain = \\\n        gcc_toolchain.toolchain_in_args(details['analyzer_options'])\n\n    # Store the compiler built in include paths and defines.\n    if not toolchain:\n        ImplicitCompilerInfo.set(details, compiler_info_file)\n\n    if not keep_gcc_fix_headers:\n        for lang, includes in details['compiler_includes'].items():\n            details['compiler_includes'][lang] = \\\n                filter_compiler_includes(includes)\n\n    return BuildAction(**details)\n\n\nclass CompileCommandEncoder(json.JSONEncoder):\n    \"\"\"JSON serializer for objects not serializable by default json code\"\"\"\n    # pylint: disable=method-hidden\n    def default(self, o):\n        if isinstance(o, BuildAction):\n            return o.to_dict()\n        # Let the base class default method raise the TypeError\n        return json.JSONEncoder.default(self, o)\n\n\nclass CompileActionUniqueingType(object):\n    NONE = 0  # Full Action text\n    SOURCE_ALPHA = 1  # Based on source file, uniqueing by\n    # on alphanumerically first target\n    SOURCE_REGEX = 2  # Based on source file, uniqueing by regex filter\n    STRICT = 3  # Gives error in case of duplicate\n\n\ndef parse_unique_log(compilation_database,\n                     report_dir,\n                     compile_uniqueing=\"none\",\n                     compiler_info_file=None,\n                     keep_gcc_fix_headers=False,\n                     analysis_skip_handler=None,\n                     pre_analysis_skip_handler=None):\n    \"\"\"\n    This function reads up the compilation_database\n    and returns with a list of build actions that is prepared for clang\n    execution. That means that gcc specific parameters are filtered out\n    and gcc built in targets and include paths are added.\n    It also filters out duplicate compilation actions based on the\n    compile_uniqueing parameter.\n    This function also dumps auto-detected the compiler info\n    into <report_dir>/compiler_info.json.\n\n    compilation_database -- A compilation database as a list of dict objects.\n                            These object should contain \"file\", \"dictionary\"\n                            and \"command\" keys. The \"command\" may be replaced\n                            by \"arguments\" which is a split command. Older\n                            versions of intercept-build provide the build\n                            command this way.\n    report_dir  -- The output report directory. The compiler infos\n                   will be written to <report_dir>/compiler.info.json.\n    compile_uniqueing -- Compilation database uniqueing mode.\n                         If there are more than one compile commands for a\n                         target file, only a single one is kept.\n    compiler_info_file -- compiler_info.json. If exists, it will be used for\n                    analysis.\n    keep_gcc_fix_headers -- There are some implicit include paths which are\n                            only used by GCC (include-fixed). This flag\n                            determines whether these should be kept among\n                            the implicit include paths.\n\n    Separate skip handlers are required because it is possible that different\n    files are skipped during pre analysis and the actual analysis. In the\n    pre analysis step nothing should be skipped to collect the required\n    information for the analysis step where not all the files are analyzed.\n\n    analysis_skip_handler -- skip handler for files which should be skipped\n                             during analysis\n    pre_analysis_skip_handler -- skip handler for files wich should be skipped\n                                 during pre analysis\n    \"\"\"\n    try:\n        uniqued_build_actions = dict()\n\n        if compile_uniqueing == \"alpha\":\n            build_action_uniqueing = CompileActionUniqueingType.SOURCE_ALPHA\n        elif compile_uniqueing == \"none\":\n            build_action_uniqueing = CompileActionUniqueingType.NONE\n        elif compile_uniqueing == \"strict\":\n            build_action_uniqueing = CompileActionUniqueingType.STRICT\n        else:\n            build_action_uniqueing = CompileActionUniqueingType.SOURCE_REGEX\n            uniqueing_re = re.compile(compile_uniqueing)\n\n        for entry in compilation_database:\n            # Skip parsing the compilaton commands if it should be skipped\n            # at both analysis phases (pre analysis and analysis).\n            full_path = os.path.join(entry[\"directory\"], entry[\"file\"])\n            if analysis_skip_handler \\\n                    and analysis_skip_handler.should_skip(full_path) \\\n                    and pre_analysis_skip_handler \\\n                    and pre_analysis_skip_handler.should_skip(full_path):\n                continue\n\n            action = parse_options(entry,\n                                   compiler_info_file,\n                                   keep_gcc_fix_headers)\n\n            if not action.lang:\n                continue\n            if action.action_type != BuildAction.COMPILE:\n                continue\n            if build_action_uniqueing == CompileActionUniqueingType.NONE:\n                if action.__hash__ not in uniqued_build_actions:\n                    uniqued_build_actions[action.__hash__] = action\n            elif build_action_uniqueing == CompileActionUniqueingType.STRICT:\n                if action.source not in uniqued_build_actions:\n                    uniqued_build_actions[action.source] = action\n                else:\n                    LOG.error(\"Build Action uniqueing failed\"\n                              \" as both '%s' and '%s'\",\n                              uniqued_build_actions[action.source]\n                              .original_command,\n                              action.original_command)\n                    sys.exit(1)\n            elif build_action_uniqueing ==\\\n                    CompileActionUniqueingType.SOURCE_ALPHA:\n                if action.source not in uniqued_build_actions:\n                    uniqued_build_actions[action.source] = action\n                elif action.output <\\\n                        uniqued_build_actions[action.source].output:\n                    uniqued_build_actions[action.source] = action\n            elif build_action_uniqueing ==\\\n                    CompileActionUniqueingType.SOURCE_REGEX:\n                LOG.debug(\"uniqueing regex\")\n                if action.source not in uniqued_build_actions:\n                    uniqued_build_actions[action.source] = action\n                elif uniqueing_re.match(action.original_command) and\\\n                    not uniqueing_re.match(\n                        uniqued_build_actions[action.source].original_command):\n                    uniqued_build_actions[action.source] = action\n                elif uniqueing_re.match(action.original_command) and\\\n                    uniqueing_re.match(\n                        uniqued_build_actions[action.source].original_command):\n                    LOG.error(\"Build Action uniqueing failed as both \\n %s\"\n                              \"\\n and \\n %s \\n match regex pattern:%s\",\n                              uniqued_build_actions[action.source].\n                              original_command,\n                              action.original_command,\n                              compile_uniqueing)\n                    sys.exit(1)\n\n        compiler_info_out = os.path.join(report_dir, \"compiler_info.json\")\n        with open(compiler_info_out, 'w') as f:\n            LOG.debug(\"Writing compiler info into:\"+compiler_info_out)\n            json.dump(ImplicitCompilerInfo.get(), f)\n\n        LOG.debug('Parsing log file done.')\n        return list(uniqued_build_actions.values())\n\n    except (ValueError, KeyError, TypeError) as ex:\n        if not compilation_database:\n            LOG.error('The compile database is empty.')\n        else:\n            LOG.error('The compile database is not valid.')\n        LOG.debug(traceback.format_exc())\n        LOG.debug(ex)\n        sys.exit(1)\n", "idx": 17, "id": 11045, "msg": "", "proj": "Ericsson-codechecker", "lang": "c"}
{"patch": "@@ -0,0 +1,55 @@\n+package pipeline\n+\n+import (\n+\t\"github.com/ethersphere/bee/pkg/storage\"\n+)\n+\n+type pipeWriteArgs struct {\n+\tref  []byte\n+\tkey  []byte\n+\tspan []byte\n+\tdata []byte //data includes the span too!\n+}\n+\n+type Pipeline struct {\n+\thead Interface\n+}\n+\n+func (p *Pipeline) Write(b []byte) (int, error) {\n+\treturn p.head.Write(b)\n+}\n+\n+func (p *Pipeline) Sum() ([]byte, error) {\n+\treturn p.head.Sum()\n+}\n+\n+func NewPipeline(s storage.Storer) Interface {\n+\t// DATA -> FEEDER -> BMT -> STORAGE -> TRIE\n+\ttw := NewHashTrieWriter(4096, 128, 32, NewShortPipeline(s))\n+\tlsw := NewStoreWriter(s, tw)\n+\tb := NewBmtWriter(128, lsw)\n+\tfeeder := NewChunkFeederWriter(4096, b)\n+\n+\treturn &Pipeline{head: feeder}\n+}\n+\n+type pipelineFunc func(p *pipeWriteArgs) ChainWriter\n+\n+// this is just a hashing pipeline. needed for level wrapping inside the hash trie writer\n+func NewShortPipeline(s storage.Storer) func(*pipeWriteArgs) ChainWriter {\n+\treturn func(p *pipeWriteArgs) ChainWriter {\n+\t\trsw := NewResultWriter(p)\n+\t\tlsw := NewStoreWriter(s, rsw)\n+\t\tbw := NewBmtWriter(128, lsw)\n+\n+\t\treturn bw\n+\t}\n+}\n+\n+//func NewEncryptionPipeline() EndPipeWriter {\n+//tw := NewHashTrieWriter()\n+//lsw := NewStoreWriter()\n+//b := NewEncryptingBmtWriter(128, lsw) // needs to pass the key somehwoe...\n+//enc := NewEncryptionWriter(b)\n+//return\n+//}", "y": 1, "oldf": "", "idx": 1, "id": 12043, "msg": "call this chunk please", "proj": "ethersphere-bee", "lang": "go"}
{"patch": "@@ -23,16 +23,18 @@ import (\n )\n \n type IssuanceCfg struct {\n-\tdb          kv.RwDB\n-\tchainConfig *params.ChainConfig\n-\tblockReader interfaces.FullBlockReader\n+\tdb              kv.RwDB\n+\tchainConfig     *params.ChainConfig\n+\tblockReader     interfaces.FullBlockReader\n+\tenabledIssuance bool\n }\n \n-func StageIssuanceCfg(db kv.RwDB, chainConfig *params.ChainConfig, blockReader interfaces.FullBlockReader) IssuanceCfg {\n+func StageIssuanceCfg(db kv.RwDB, chainConfig *params.ChainConfig, blockReader interfaces.FullBlockReader, enabledIssuance bool) IssuanceCfg {\n \treturn IssuanceCfg{\n-\t\tdb:          db,\n-\t\tchainConfig: chainConfig,\n-\t\tblockReader: blockReader,\n+\t\tdb:              db,\n+\t\tchainConfig:     chainConfig,\n+\t\tblockReader:     blockReader,\n+\t\tenabledIssuance: enabledIssuance,\n \t}\n }\n ", "y": 0, "oldf": "package stagedsync\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"fmt\"\n\t\"math/big\"\n\t\"time\"\n\n\t\"github.com/holiman/uint256\"\n\t\"github.com/ledgerwatch/erigon-lib/kv\"\n\t\"github.com/ledgerwatch/erigon/cmd/rpcdaemon/interfaces\"\n\t\"github.com/ledgerwatch/erigon/common\"\n\t\"github.com/ledgerwatch/erigon/common/dbutils\"\n\t\"github.com/ledgerwatch/erigon/consensus/ethash\"\n\t\"github.com/ledgerwatch/erigon/consensus/serenity\"\n\t\"github.com/ledgerwatch/erigon/core/rawdb\"\n\t\"github.com/ledgerwatch/erigon/core/types\"\n\t\"github.com/ledgerwatch/erigon/eth/stagedsync/stages\"\n\t\"github.com/ledgerwatch/erigon/params\"\n\t\"github.com/ledgerwatch/erigon/rlp\"\n\t\"github.com/ledgerwatch/log/v3\"\n)\n\ntype IssuanceCfg struct {\n\tdb          kv.RwDB\n\tchainConfig *params.ChainConfig\n\tblockReader interfaces.FullBlockReader\n}\n\nfunc StageIssuanceCfg(db kv.RwDB, chainConfig *params.ChainConfig, blockReader interfaces.FullBlockReader) IssuanceCfg {\n\treturn IssuanceCfg{\n\t\tdb:          db,\n\t\tchainConfig: chainConfig,\n\t\tblockReader: blockReader,\n\t}\n}\n\nfunc SpawnStageIssuance(cfg IssuanceCfg, s *StageState, tx kv.RwTx, ctx context.Context) error {\n\tuseExternalTx := tx != nil\n\n\tif !useExternalTx {\n\t\tvar err error\n\t\ttx, err = cfg.db.BeginRw(context.Background())\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tdefer tx.Rollback()\n\t}\n\n\theadNumber, err := stages.GetStageProgress(tx, stages.Bodies)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"getting headers progress: %w\", err)\n\t}\n\n\tif headNumber == s.BlockNumber {\n\t\treturn nil\n\t}\n\tif cfg.chainConfig.Consensus != params.EtHashConsensus {\n\t\tif err = s.Update(tx, headNumber); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif !useExternalTx {\n\t\t\tif err = tx.Commit(); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n\t// Log timer\n\tlogEvery := time.NewTicker(logInterval)\n\tdefer logEvery.Stop()\n\t// Read previous issuance\n\ttotalIssued, err := rawdb.ReadTotalIssued(tx, s.BlockNumber)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\ttotalBurnt, err := rawdb.ReadTotalBurnt(tx, s.BlockNumber)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tstopped := false\n\tprevProgress := s.BlockNumber\n\tcurrentBlockNumber := s.BlockNumber + 1\n\theaderC, err := tx.Cursor(kv.Headers)\n\tif err != nil {\n\t\treturn err\n\t}\n\tfor k, v, err := headerC.Seek(dbutils.EncodeBlockNumber(currentBlockNumber)); k != nil && !stopped; k, v, err = headerC.Next() {\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif len(k) != 40 {\n\t\t\tcontinue\n\t\t}\n\n\t\tcurrentBlockNumber, err = dbutils.DecodeBlockNumber(k[:8])\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif currentBlockNumber > headNumber {\n\t\t\tcurrentBlockNumber = headNumber\n\t\t\tbreak\n\t\t}\n\t\t// read body without transactions\n\t\thash, err := rawdb.ReadCanonicalHash(tx, currentBlockNumber)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif hash != common.BytesToHash(k[8:]) {\n\t\t\tcontinue\n\t\t}\n\t\tvar header types.Header\n\t\tif err := rlp.Decode(bytes.NewReader(v), &header); err != nil {\n\t\t\tlog.Error(\"Invalid block header RLP\", \"hash\", hash, \"err\", err)\n\t\t\treturn nil\n\t\t}\n\n\t\tburnt := big.NewInt(0)\n\t\t// burnt: len(Transactions) * baseFee * gasUsed\n\t\tif header.BaseFee != nil {\n\t\t\tburnt.Set(header.BaseFee)\n\t\t\tburnt.Mul(burnt, big.NewInt(int64(header.GasUsed)))\n\t\t}\n\t\t// TotalIssued, BlockReward and UncleReward, depends on consensus engine\n\t\tif header.Difficulty.Cmp(serenity.SerenityDifficulty) == 0 {\n\t\t\t// Proof-of-stake is 0.3 ether per block\n\t\t\ttotalIssued.Add(totalIssued, serenity.RewardSerenity)\n\t\t} else {\n\t\t\tvar blockReward uint256.Int\n\t\t\tvar uncleRewards []uint256.Int\n\t\t\tif header.UncleHash == types.EmptyUncleHash {\n\t\t\t\tblockReward, uncleRewards = ethash.AccumulateRewards(cfg.chainConfig, &header, nil)\n\t\t\t} else {\n\t\t\t\tbody, err := cfg.blockReader.Body(ctx, tx, hash, currentBlockNumber)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tblockReward, uncleRewards = ethash.AccumulateRewards(cfg.chainConfig, &header, body.Uncles)\n\t\t\t}\n\t\t\t// Set BlockReward\n\t\t\ttotalIssued.Add(totalIssued, blockReward.ToBig())\n\t\t\t// Compute uncleRewards\n\t\t\tfor _, uncleReward := range uncleRewards {\n\t\t\t\ttotalIssued.Add(totalIssued, uncleReward.ToBig())\n\t\t\t}\n\t\t}\n\t\ttotalBurnt.Add(totalBurnt, burnt)\n\t\t// Write to database\n\t\tif err := rawdb.WriteTotalIssued(tx, currentBlockNumber, totalIssued); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := rawdb.WriteTotalBurnt(tx, currentBlockNumber, totalBurnt); err != nil {\n\t\t\treturn err\n\t\t}\n\t\t// Sleep and check for logs\n\t\ttimer := time.NewTimer(1 * time.Nanosecond)\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tstopped = true\n\t\tcase <-logEvery.C:\n\t\t\tlog.Info(fmt.Sprintf(\"[%s] Wrote Block Issuance\", s.LogPrefix()),\n\t\t\t\t\"now\", currentBlockNumber, \"blk/sec\", float64(currentBlockNumber-prevProgress)/float64(logInterval/time.Second))\n\t\t\tprevProgress = currentBlockNumber\n\t\tcase <-timer.C:\n\t\t\tlog.Trace(\"RequestQueueTime (header) ticked\")\n\t\t}\n\t\t// Cleanup timer\n\t\ttimer.Stop()\n\t}\n\tif err = s.Update(tx, currentBlockNumber); err != nil {\n\t\treturn err\n\t}\n\tif !useExternalTx {\n\t\tif err = tx.Commit(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc UnwindIssuanceStage(u *UnwindState, tx kv.RwTx, ctx context.Context) (err error) {\n\tuseExternalTx := tx != nil\n\n\tif err = u.Done(tx); err != nil {\n\t\treturn fmt.Errorf(\" reset: %w\", err)\n\t}\n\tif !useExternalTx {\n\t\tif err = tx.Commit(); err != nil {\n\t\t\treturn fmt.Errorf(\"failed to write db commit: %w\", err)\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc PruneIssuanceStage(p *PruneState, tx kv.RwTx, ctx context.Context) (err error) {\n\tif tx != nil {\n\t\tif err = tx.Commit(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n", "idx": 1, "id": 23199, "msg": "", "proj": "ledgerwatch-erigon", "lang": "go"}
{"patch": "@@ -29,7 +29,6 @@ import (\n \t\"github.com/GoogleCloudPlatform/compute-image-tools/cli_tools/google-osconfig-agent/patch\"\n \t\"github.com/GoogleCloudPlatform/compute-image-tools/cli_tools/google-osconfig-agent/service\"\n \t\"github.com/GoogleCloudPlatform/compute-image-tools/go/packages\"\n-\t\"google.golang.org/api/option\"\n )\n \n var version string", "y": 0, "oldf": "//  Copyright 2018 Google Inc. All Rights Reserved.\n//\n//  Licensed under the Apache License, Version 2.0 (the \"License\");\n//  you may not use this file except in compliance with the License.\n//  You may obtain a copy of the License at\n//\n//      http://www.apache.org/licenses/LICENSE-2.0\n//\n//  Unless required by applicable law or agreed to in writing, software\n//  distributed under the License is distributed on an \"AS IS\" BASIS,\n//  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n//  See the License for the specific language governing permissions and\n//  limitations under the License.\n\n// osconfig_agent interacts with the osconfig api.\npackage main\n\nimport (\n\t\"context\"\n\t\"flag\"\n\t\"log\"\n\t\"os\"\n\n\tosconfig \"github.com/GoogleCloudPlatform/compute-image-tools/cli_tools/google-osconfig-agent/_internal/gapi-cloud-osconfig-go/cloud.google.com/go/osconfig/apiv1alpha1\"\n\t\"github.com/GoogleCloudPlatform/compute-image-tools/cli_tools/google-osconfig-agent/config\"\n\t\"github.com/GoogleCloudPlatform/compute-image-tools/cli_tools/google-osconfig-agent/inventory\"\n\t\"github.com/GoogleCloudPlatform/compute-image-tools/cli_tools/google-osconfig-agent/logger\"\n\t\"github.com/GoogleCloudPlatform/compute-image-tools/cli_tools/google-osconfig-agent/ospackage\"\n\t\"github.com/GoogleCloudPlatform/compute-image-tools/cli_tools/google-osconfig-agent/patch\"\n\t\"github.com/GoogleCloudPlatform/compute-image-tools/cli_tools/google-osconfig-agent/service\"\n\t\"github.com/GoogleCloudPlatform/compute-image-tools/go/packages\"\n\t\"google.golang.org/api/option\"\n)\n\nvar version string\n\nfunc init() {\n\t// We do this here so the -X value doesn't need the full path.\n\tconfig.SetVersion(version)\n}\n\ntype logWritter struct{}\n\nfunc (l *logWritter) Write(b []byte) (int, error) {\n\tlogger.Debug(logger.LogEntry{CallDepth: 3, Message: string(b)})\n\treturn len(b), nil\n}\n\nfunc main() {\n\tflag.Parse()\n\tctx := context.Background()\n\n\tif config.Debug() {\n\t\tpackages.DebugLogger = log.New(&logWritter{}, \"\", 0)\n\t}\n\n\tproj, err := config.Project()\n\tif err != nil {\n\t\tlogger.Fatalf(err.Error())\n\t}\n\n\tlogger.Init(ctx, proj)\n\n\taction := flag.Arg(0)\n\tif action == \"inventory\" {\n\t\t// Just run inventory and exit.\n\t\tinventory.RunInventory()\n\t\tlogger.Close()\n\t\tos.Exit(0)\n\t}\n\n\tif action == \"ospackage\" {\n\t\t// Just run SetConfig and exit.\n\t\tclient, err := osconfig.NewClient(ctx, option.WithEndpoint(config.SvcEndpoint()), option.WithCredentialsFile(config.OAuthPath()))\n\t\tif err != nil {\n\t\t\tlogger.Fatalf(\"NewClient Error: %v\", err)\n\t\t}\n\n\t\tres, err := config.Instance()\n\t\tif err != nil {\n\t\t\tlogger.Fatalf(\"Instance error: %v\", err)\n\t\t}\n\n\t\tresp, err := service.LookupConfigs(ctx, client, res)\n\t\tif err != nil {\n\t\t\tlogger.Fatalf(\"LookupConfigs error: %v\", err)\n\t\t}\n\t\tif err := ospackage.SetConfig(resp); err != nil {\n\t\t\tlogger.Fatalf(\"SetConfig error: %v\", err)\n\t\t}\n\t\tos.Exit(0)\n\t}\n\n\tif action == \"ospatch\" {\n\t\tpatch.RunPatchAgent(ctx)\n\t\tos.Exit(0)\n\t}\n\n\tif action == \"\" {\n\t\taction = \"run\"\n\t}\n\tif err := service.Run(ctx, action); err != nil {\n\t\tlogger.Fatalf(err.Error())\n\t}\n}\n", "idx": 2, "id": 8348, "msg": "", "proj": "GoogleCloudPlatform-compute-image-tools", "lang": "go"}
{"patch": "@@ -196,15 +196,15 @@ var _ = framework.CertManagerDescribe(\"ACME Certificate (HTTP01)\", func() {\n \t\tExpect(err).NotTo(HaveOccurred())\n \n \t\tBy(\"Waiting for the Certificate to have the Ready=True condition\")\n-\t\t_, err = f.Helper().WaitForCertificateReadyUpdate(cert, time.Minute*5)\n+\t\tcert, err = f.Helper().WaitForCertificateReadyAndDoneIssuing(cert, time.Minute*5)\n \t\tExpect(err).NotTo(HaveOccurred())\n \n \t\tBy(\"Sanity checking the issued Certificate\")\n-\t\terr = f.Helper().ValidateCertificate(f.Namespace.Name, certificateName, validations...)\n+\t\terr = f.Helper().ValidateCertificate(cert, validations...)\n \t\tExpect(err).NotTo(HaveOccurred())\n \n \t\tBy(\"Checking that the secret contains this dns name\")\n-\t\terr = f.Helper().ValidateCertificate(f.Namespace.Name, certificateName, func(cert *v1.Certificate, secret *corev1.Secret) error {\n+\t\terr = f.Helper().ValidateCertificate(cert, func(cert *v1.Certificate, secret *corev1.Secret) error {\n \t\t\tdnsnames, err := findDNSNames(secret)\n \t\t\tif err != nil {\n \t\t\t\treturn err", "y": 0, "oldf": "/*\nCopyright 2020 The cert-manager Authors.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage certificate\n\nimport (\n\t\"context\"\n\t\"crypto/tls\"\n\t\"crypto/x509\"\n\t\"fmt\"\n\t\"strings\"\n\t\"time\"\n\n\t. \"github.com/onsi/ginkgo\"\n\t. \"github.com/onsi/gomega\"\n\tcorev1 \"k8s.io/api/core/v1\"\n\tnetworkingv1 \"k8s.io/api/networking/v1\"\n\tnetworkingv1beta1 \"k8s.io/api/networking/v1beta1\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/apimachinery/pkg/util/intstr\"\n\t\"k8s.io/apimachinery/pkg/util/wait\"\n\t\"k8s.io/client-go/util/retry\"\n\t\"k8s.io/utils/pointer\"\n\n\tcmacme \"github.com/jetstack/cert-manager/pkg/apis/acme/v1\"\n\tv1 \"github.com/jetstack/cert-manager/pkg/apis/certmanager/v1\"\n\tcmmeta \"github.com/jetstack/cert-manager/pkg/apis/meta/v1\"\n\t\"github.com/jetstack/cert-manager/test/e2e/framework\"\n\t\"github.com/jetstack/cert-manager/test/e2e/framework/helper/featureset\"\n\t\"github.com/jetstack/cert-manager/test/e2e/framework/helper/validation\"\n\t\"github.com/jetstack/cert-manager/test/e2e/framework/log\"\n\t. \"github.com/jetstack/cert-manager/test/e2e/framework/matcher\"\n\t\"github.com/jetstack/cert-manager/test/e2e/util\"\n\te2eutil \"github.com/jetstack/cert-manager/test/e2e/util\"\n\t\"github.com/jetstack/cert-manager/test/unit/gen\"\n)\n\nconst foreverTestTimeout = time.Second * 60\n\nvar _ = framework.CertManagerDescribe(\"ACME Certificate (HTTP01)\", func() {\n\tf := framework.NewDefaultFramework(\"create-acme-certificate-http01\")\n\n\tvar acmeIngressDomain string\n\tissuerName := \"test-acme-issuer\"\n\tcertificateName := \"test-acme-certificate\"\n\tcertificateSecretName := \"test-acme-certificate\"\n\t// fixedIngressName is the name of an ingress resource that is configured\n\t// with a challenge solve.\n\t// To utilise this solver, add the 'testing.cert-manager.io/fixed-ingress: \"true\"' label.\n\tfixedIngressName := \"testingress\"\n\n\t// ACME Issuer does not return a ca.crt. See:\n\t// https://github.com/jetstack/cert-manager/issues/1571\n\tunsupportedFeatures := featureset.NewFeatureSet(featureset.SaveCAToSecret)\n\tvalidations := validation.CertificateSetForUnsupportedFeatureSet(unsupportedFeatures)\n\n\tBeforeEach(func() {\n\t\tsolvers := []cmacme.ACMEChallengeSolver{\n\t\t\t{\n\t\t\t\tHTTP01: &cmacme.ACMEChallengeSolverHTTP01{\n\t\t\t\t\tIngress: &cmacme.ACMEChallengeSolverHTTP01Ingress{\n\t\t\t\t\t\tClass: &f.Config.Addons.IngressController.IngressClass,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tSelector: &cmacme.CertificateDNSNameSelector{\n\t\t\t\t\tMatchLabels: map[string]string{\n\t\t\t\t\t\t\"testing.cert-manager.io/fixed-ingress\": \"true\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tHTTP01: &cmacme.ACMEChallengeSolverHTTP01{\n\t\t\t\t\tIngress: &cmacme.ACMEChallengeSolverHTTP01Ingress{\n\t\t\t\t\t\tName: fixedIngressName,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tacmeIssuer := gen.Issuer(issuerName,\n\t\t\tgen.SetIssuerNamespace(f.Namespace.Name),\n\t\t\tgen.SetIssuerACMEEmail(f.Config.Addons.ACMEServer.TestingACMEEmail),\n\t\t\tgen.SetIssuerACMEURL(f.Config.Addons.ACMEServer.URL),\n\t\t\tgen.SetIssuerACMEPrivKeyRef(f.Config.Addons.ACMEServer.TestingACMEPrivateKey),\n\t\t\tgen.SetIssuerACMESkipTLSVerify(true),\n\t\t\tgen.SetIssuerACMESolvers(solvers))\n\t\tBy(\"Creating an Issuer\")\n\t\t_, err := f.CertManagerClientSet.CertmanagerV1().Issuers(f.Namespace.Name).Create(context.TODO(), acmeIssuer, metav1.CreateOptions{})\n\t\tExpect(err).NotTo(HaveOccurred())\n\t\tBy(\"Waiting for Issuer to become Ready\")\n\t\terr = util.WaitForIssuerCondition(f.CertManagerClientSet.CertmanagerV1().Issuers(f.Namespace.Name),\n\t\t\tissuerName,\n\t\t\tv1.IssuerCondition{\n\t\t\t\tType:   v1.IssuerConditionReady,\n\t\t\t\tStatus: cmmeta.ConditionTrue,\n\t\t\t})\n\t\tExpect(err).NotTo(HaveOccurred())\n\t\tBy(\"Verifying the ACME account URI is set\")\n\t\terr = util.WaitForIssuerStatusFunc(f.CertManagerClientSet.CertmanagerV1().Issuers(f.Namespace.Name),\n\t\t\tissuerName,\n\t\t\tfunc(i *v1.Issuer) (bool, error) {\n\t\t\t\tif i.GetStatus().ACMEStatus().URI == \"\" {\n\t\t\t\t\treturn false, nil\n\t\t\t\t}\n\t\t\t\treturn true, nil\n\t\t\t})\n\t\tExpect(err).NotTo(HaveOccurred())\n\t\tBy(\"Verifying ACME account private key exists\")\n\t\tsecret, err := f.KubeClientSet.CoreV1().Secrets(f.Namespace.Name).Get(context.TODO(), f.Config.Addons.ACMEServer.TestingACMEPrivateKey, metav1.GetOptions{})\n\t\tExpect(err).NotTo(HaveOccurred())\n\t\tif len(secret.Data) != 1 {\n\t\t\tFail(\"Expected 1 key in ACME account private key secret, but there was %d\", len(secret.Data))\n\t\t}\n\t})\n\n\tJustBeforeEach(func() {\n\t\tacmeIngressDomain = e2eutil.RandomSubdomain(f.Config.Addons.IngressController.Domain)\n\t})\n\n\tAfterEach(func() {\n\t\tBy(\"Cleaning up\")\n\t\tf.CertManagerClientSet.CertmanagerV1().Issuers(f.Namespace.Name).Delete(context.TODO(), issuerName, metav1.DeleteOptions{})\n\t\tf.KubeClientSet.CoreV1().Secrets(f.Namespace.Name).Delete(context.TODO(), f.Config.Addons.ACMEServer.TestingACMEPrivateKey, metav1.DeleteOptions{})\n\t})\n\n\tIt(\"should allow updating an existing failing certificate that had a blocked dns name\", func() {\n\t\tcertClient := f.CertManagerClientSet.CertmanagerV1().Certificates(f.Namespace.Name)\n\n\t\tBy(\"Creating a failing Certificate\")\n\t\t// In \"devel/addon/pebble/chart/templates/configmap.yaml\"\n\t\t// the \"google.com\" domain is configured in the pebble blocklist.\n\t\tcert := gen.Certificate(certificateName,\n\t\t\tgen.SetCertificateSecretName(certificateSecretName),\n\t\t\tgen.SetCertificateIssuer(cmmeta.ObjectReference{Name: issuerName}),\n\t\t\tgen.SetCertificateDNSNames(\"google.com\"),\n\t\t)\n\t\tcert.Namespace = f.Namespace.Name\n\n\t\t_, err := certClient.Create(context.TODO(), cert, metav1.CreateOptions{})\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\tBy(\"Making sure the Order failed with a 400 since google.com is invalid\")\n\t\torder := &cmacme.Order{}\n\t\terr = wait.PollImmediate(1*time.Second, 1*time.Minute, func() (done bool, err error) {\n\t\t\torders, err := listOwnedOrders(f.CertManagerClientSet, cert)\n\t\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\t\tif len(orders) == 0 || len(orders) > 1 {\n\t\t\t\tlog.Logf(\"Waiting as one Order should exist, but we found %d\", len(orders))\n\t\t\t\treturn false, nil\n\t\t\t}\n\t\t\torder = orders[0]\n\n\t\t\texpected := `400 urn:ietf:params:acme:error:rejectedIdentifier`\n\t\t\tif !strings.Contains(order.Status.Reason, expected) {\n\t\t\t\tlog.Logf(\"Waiting for Order's reason, current: %s, should contain: %s\", order.Status.Reason, expected)\n\t\t\t\treturn false, nil\n\t\t\t}\n\n\t\t\treturn true, nil\n\t\t})\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\tBy(\"Waiting for the Certificate to be not ready\")\n\t\t_, err = f.Helper().WaitForCertificateNotReadyUpdate(cert, 30*time.Second)\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\terr = retry.RetryOnConflict(retry.DefaultRetry, func() error {\n\t\t\tBy(\"Getting the latest version of the Certificate\")\n\t\t\tcert, err = certClient.Get(context.TODO(), certificateName, metav1.GetOptions{})\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tBy(\"Replacing dnsNames with a valid dns name\")\n\t\t\tcert = cert.DeepCopy()\n\t\t\tcert.Spec.DNSNames = []string{e2eutil.RandomSubdomain(acmeIngressDomain)}\n\t\t\t_, err = certClient.Update(context.TODO(), cert, metav1.UpdateOptions{})\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\treturn nil\n\t\t})\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\tBy(\"Waiting for the Certificate to have the Ready=True condition\")\n\t\t_, err = f.Helper().WaitForCertificateReadyUpdate(cert, time.Minute*5)\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\tBy(\"Sanity checking the issued Certificate\")\n\t\terr = f.Helper().ValidateCertificate(f.Namespace.Name, certificateName, validations...)\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\tBy(\"Checking that the secret contains this dns name\")\n\t\terr = f.Helper().ValidateCertificate(f.Namespace.Name, certificateName, func(cert *v1.Certificate, secret *corev1.Secret) error {\n\t\t\tdnsnames, err := findDNSNames(secret)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tExpect(cert.Spec.DNSNames).To(ContainElements(dnsnames))\n\t\t\treturn nil\n\t\t})\n\t\tExpect(err).NotTo(HaveOccurred())\n\t})\n\n\tIt(\"should fail to obtain a certificate for a blocked ACME dns name\", func() {\n\t\tBy(\"Creating a Certificate\")\n\t\t// In \"devel/addon/pebble/chart/templates/configmap.yaml\"\n\t\t// the \"google.com\" domain is configured in the pebble blocklist.\n\t\tcert := gen.Certificate(certificateName,\n\t\t\tgen.SetCertificateSecretName(certificateSecretName),\n\t\t\tgen.SetCertificateIssuer(cmmeta.ObjectReference{Name: issuerName}),\n\t\t\tgen.SetCertificateDNSNames(\"google.com\"),\n\t\t)\n\t\tcert.Namespace = f.Namespace.Name\n\n\t\tcert, err := f.CertManagerClientSet.CertmanagerV1().Certificates(f.Namespace.Name).Create(context.TODO(), cert, metav1.CreateOptions{})\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\tnotReadyCondition := v1.CertificateCondition{\n\t\t\tType:   v1.CertificateConditionReady,\n\t\t\tStatus: cmmeta.ConditionFalse,\n\t\t}\n\t\tEventually(cert, \"30s\", \"1s\").Should(HaveCondition(f, notReadyCondition))\n\t\tConsistently(cert, \"1m\", \"10s\").Should(HaveCondition(f, notReadyCondition))\n\t})\n\n\tIt(\"should obtain a signed certificate with a single CN from the ACME server when putting an annotation on an ingress resource\", func() {\n\n\t\tswitch {\n\t\tcase util.HasIngresses(f.KubeClientSet.Discovery(), networkingv1.SchemeGroupVersion.String()):\n\t\t\tingClient := f.KubeClientSet.NetworkingV1().Ingresses(f.Namespace.Name)\n\t\t\tBy(\"Creating an Ingress with the issuer name annotation set\")\n\t\t\t_, err := ingClient.Create(context.TODO(), util.NewIngress(certificateSecretName, certificateSecretName, map[string]string{\n\t\t\t\t\"cert-manager.io/issuer\": issuerName,\n\t\t\t}, acmeIngressDomain), metav1.CreateOptions{})\n\t\t\tExpect(err).NotTo(HaveOccurred())\n\t\tcase util.HasIngresses(f.KubeClientSet.Discovery(), networkingv1beta1.SchemeGroupVersion.String()):\n\t\t\tingClient := f.KubeClientSet.NetworkingV1beta1().Ingresses(f.Namespace.Name)\n\t\t\tBy(\"Creating an Ingress with the issuer name annotation set\")\n\t\t\t_, err := ingClient.Create(context.TODO(), util.NewV1Beta1Ingress(certificateSecretName, certificateSecretName, map[string]string{\n\t\t\t\t\"cert-manager.io/issuer\": issuerName,\n\t\t\t}, acmeIngressDomain), metav1.CreateOptions{})\n\t\t\tExpect(err).NotTo(HaveOccurred())\n\t\tdefault:\n\t\t\tFail(\"Neither \" + networkingv1.SchemeGroupVersion.String() + \" nor \" + networkingv1beta1.SchemeGroupVersion.String() + \" were discovered in the API server\")\n\t\t}\n\n\t\tcertClient := f.CertManagerClientSet.CertmanagerV1().Certificates(f.Namespace.Name)\n\t\tBy(\"Waiting for Certificate to exist\")\n\t\terr := util.WaitForCertificateToExist(certClient, certificateSecretName, foreverTestTimeout)\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\tBy(\"Waiting for the Certificate to be issued...\")\n\t\t_, err = f.Helper().WaitForCertificateReady(f.Namespace.Name, certificateName, time.Minute*5)\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\tBy(\"Validating the issued Certificate...\")\n\t\terr = f.Helper().ValidateCertificate(f.Namespace.Name, certificateName, validations...)\n\t\tExpect(err).NotTo(HaveOccurred())\n\t})\n\n\tIt(\"should obtain a signed certificate with a single CN from the ACME server when redirected\", func() {\n\t\tcertClient := f.CertManagerClientSet.CertmanagerV1().Certificates(f.Namespace.Name)\n\n\t\t// force-ssl-redirect should make every request turn into a redirect,\n\t\t// but I haven't been able to make this happen. Create a TLS cert via\n\t\t// the self-sign issuer to make it have a \"proper\" TLS cert\n\t\t// TODO: investigate if we still need to use the self-signed issuer here\n\n\t\tissuer := gen.Issuer(\"selfsign\",\n\t\t\tgen.SetIssuerNamespace(f.Namespace.Name),\n\t\t\tgen.SetIssuerSelfSigned(v1.SelfSignedIssuer{}))\n\t\t_, err := f.CertManagerClientSet.CertmanagerV1().Issuers(f.Namespace.Name).Create(context.TODO(), issuer, metav1.CreateOptions{})\n\t\tExpect(err).NotTo(HaveOccurred())\n\t\tBy(\"Waiting for (selfsign) Issuer to become Ready\")\n\t\terr = util.WaitForIssuerCondition(f.CertManagerClientSet.CertmanagerV1().Issuers(f.Namespace.Name),\n\t\t\tissuerName,\n\t\t\tv1.IssuerCondition{\n\t\t\t\tType:   v1.IssuerConditionReady,\n\t\t\t\tStatus: cmmeta.ConditionTrue,\n\t\t\t})\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\tconst dummycert = \"dummy-tls\"\n\t\tconst secretname = \"dummy-tls-secret\"\n\n\t\tselfcert := util.NewCertManagerBasicCertificate(\"dummy-tls\", secretname, \"selfsign\", v1.IssuerKind, nil, nil, acmeIngressDomain)\n\t\t_, err = certClient.Create(context.TODO(), selfcert, metav1.CreateOptions{})\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\tBy(\"Waiting for the Certificate to be issued...\")\n\t\t_, err = f.Helper().WaitForCertificateReady(f.Namespace.Name, dummycert, time.Minute*5)\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\tBy(\"Validating the issued Certificate...\")\n\t\terr = f.Helper().ValidateCertificate(f.Namespace.Name, dummycert, validations...)\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\t// create an ingress that points at nothing, but has the TLS redirect annotation set\n\t\t// using the TLS secret that we just got from the self-sign\n\n\t\tswitch {\n\t\tcase util.HasIngresses(f.KubeClientSet.Discovery(), networkingv1.SchemeGroupVersion.String()):\n\t\t\tingress := f.KubeClientSet.NetworkingV1().Ingresses(f.Namespace.Name)\n\t\t\t_, err = ingress.Create(context.TODO(), &networkingv1.Ingress{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tName: fixedIngressName,\n\t\t\t\t\tAnnotations: map[string]string{\n\t\t\t\t\t\t\"nginx.ingress.kubernetes.io/force-ssl-redirect\": \"true\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tSpec: networkingv1.IngressSpec{\n\t\t\t\t\tIngressClassName: pointer.StringPtr(\"nginx\"),\n\t\t\t\t\tTLS: []networkingv1.IngressTLS{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tHosts:      []string{acmeIngressDomain},\n\t\t\t\t\t\t\tSecretName: secretname,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tRules: []networkingv1.IngressRule{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tHost: acmeIngressDomain,\n\t\t\t\t\t\t\tIngressRuleValue: networkingv1.IngressRuleValue{\n\t\t\t\t\t\t\t\tHTTP: &networkingv1.HTTPIngressRuleValue{\n\t\t\t\t\t\t\t\t\tPaths: []networkingv1.HTTPIngressPath{\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tPath:     \"/\",\n\t\t\t\t\t\t\t\t\t\t\tPathType: func() *networkingv1.PathType { s := networkingv1.PathTypePrefix; return &s }(),\n\t\t\t\t\t\t\t\t\t\t\tBackend: networkingv1.IngressBackend{\n\t\t\t\t\t\t\t\t\t\t\t\tService: &networkingv1.IngressServiceBackend{\n\t\t\t\t\t\t\t\t\t\t\t\t\tName: \"doesnotexist\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tPort: networkingv1.ServiceBackendPort{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tNumber: 443,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}, metav1.CreateOptions{})\n\t\t\tExpect(err).NotTo(HaveOccurred())\n\t\tcase util.HasIngresses(f.KubeClientSet.Discovery(), networkingv1beta1.SchemeGroupVersion.String()):\n\t\t\tingress := f.KubeClientSet.NetworkingV1beta1().Ingresses(f.Namespace.Name)\n\t\t\t_, err = ingress.Create(context.TODO(), &networkingv1beta1.Ingress{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tName: fixedIngressName,\n\t\t\t\t\tAnnotations: map[string]string{\n\t\t\t\t\t\t\"nginx.ingress.kubernetes.io/force-ssl-redirect\": \"true\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tSpec: networkingv1beta1.IngressSpec{\n\t\t\t\t\tIngressClassName: pointer.StringPtr(\"nginx\"),\n\t\t\t\t\tTLS: []networkingv1beta1.IngressTLS{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tHosts:      []string{acmeIngressDomain},\n\t\t\t\t\t\t\tSecretName: secretname,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tRules: []networkingv1beta1.IngressRule{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tHost: acmeIngressDomain,\n\t\t\t\t\t\t\tIngressRuleValue: networkingv1beta1.IngressRuleValue{\n\t\t\t\t\t\t\t\tHTTP: &networkingv1beta1.HTTPIngressRuleValue{\n\t\t\t\t\t\t\t\t\tPaths: []networkingv1beta1.HTTPIngressPath{\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tPath: \"/\",\n\t\t\t\t\t\t\t\t\t\t\tBackend: networkingv1beta1.IngressBackend{\n\t\t\t\t\t\t\t\t\t\t\t\tServiceName: \"doesnotexist\",\n\t\t\t\t\t\t\t\t\t\t\t\tServicePort: intstr.FromInt(443),\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}, metav1.CreateOptions{})\n\t\t\tExpect(err).NotTo(HaveOccurred())\n\t\tdefault:\n\t\t\tFail(\"Neither \" + networkingv1.SchemeGroupVersion.String() + \" nor \" + networkingv1beta1.SchemeGroupVersion.String() + \" were discovered in the API server\")\n\t\t}\n\n\t\t// This is a special cert for the test suite, where we specify an ingress rather than a\n\t\t// class\n\t\tBy(\"Creating a Certificate\")\n\t\tcert := gen.Certificate(certificateName,\n\t\t\tgen.SetCertificateSecretName(certificateSecretName),\n\t\t\tgen.SetCertificateIssuer(cmmeta.ObjectReference{Name: issuerName}),\n\t\t\tgen.SetCertificateDNSNames(acmeIngressDomain),\n\t\t)\n\t\tcert.Namespace = f.Namespace.Name\n\t\tcert.Labels = map[string]string{\n\t\t\t\"testing.cert-manager.io/fixed-ingress\": \"true\",\n\t\t}\n\n\t\t_, err = certClient.Create(context.TODO(), cert, metav1.CreateOptions{})\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\tBy(\"Waiting for the Certificate to be issued...\")\n\t\t_, err = f.Helper().WaitForCertificateReady(f.Namespace.Name, certificateName, time.Minute*5)\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\tBy(\"Validating the issued Certificate...\")\n\t\terr = f.Helper().ValidateCertificate(f.Namespace.Name, certificateName, validations...)\n\t\tExpect(err).NotTo(HaveOccurred())\n\t})\n\n\tIt(\"should automatically recreate challenge pod and still obtain a certificate if it is manually deleted\", func() {\n\t\tcertClient := f.CertManagerClientSet.CertmanagerV1().Certificates(f.Namespace.Name)\n\n\t\tBy(\"Creating a Certificate\")\n\t\tcert := gen.Certificate(certificateName,\n\t\t\tgen.SetCertificateSecretName(certificateSecretName),\n\t\t\tgen.SetCertificateIssuer(cmmeta.ObjectReference{Name: issuerName}),\n\t\t\tgen.SetCertificateDNSNames(acmeIngressDomain),\n\t\t)\n\t\tcert.Namespace = f.Namespace.Name\n\t\t_, err := certClient.Create(context.TODO(), cert, metav1.CreateOptions{})\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\tBy(\"killing the solver pod\")\n\t\tpodClient := f.KubeClientSet.CoreV1().Pods(f.Namespace.Name)\n\t\tvar pod corev1.Pod\n\t\terr = wait.PollImmediate(1*time.Second, time.Minute,\n\t\t\tfunc() (bool, error) {\n\t\t\t\tlog.Logf(\"Waiting for solver pod to exist\")\n\t\t\t\tpodlist, err := podClient.List(context.TODO(), metav1.ListOptions{})\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn false, err\n\t\t\t\t}\n\n\t\t\t\tfor _, p := range podlist.Items {\n\t\t\t\t\tlog.Logf(\"solver pod %s\", p.Name)\n\t\t\t\t\t// TODO(dmo): make this cleaner instead of just going by name\n\t\t\t\t\tif strings.Contains(p.Name, \"http-solver\") {\n\t\t\t\t\t\tpod = p\n\t\t\t\t\t\treturn true, nil\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn false, nil\n\n\t\t\t},\n\t\t)\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\terr = podClient.Delete(context.TODO(), pod.Name, metav1.DeleteOptions{})\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\t// The pod should get remade and the certificate should be made valid.\n\t\t// Killing the pod could potentially make the validation invalid if pebble\n\t\t// were to ask us for the challenge after the pod was killed, but because\n\t\t// we kill it so early, we should always be in the self-check phase\n\t\tBy(\"Waiting for the Certificate to be issued...\")\n\t\t_, err = f.Helper().WaitForCertificateReady(f.Namespace.Name, certificateName, time.Minute*5)\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\tBy(\"Validating the issued Certificate...\")\n\t\terr = f.Helper().ValidateCertificate(f.Namespace.Name, certificateName, validations...)\n\t\tExpect(err).NotTo(HaveOccurred())\n\t})\n})\n\n// findDNSNames decodes and returns the dns names (SANs) contained in a\n// certificate secret.\nfunc findDNSNames(s *corev1.Secret) ([]string, error) {\n\tif s.Data == nil {\n\t\treturn nil, fmt.Errorf(\"secret contains no data\")\n\t}\n\tpkData := s.Data[corev1.TLSPrivateKeyKey]\n\tcertData := s.Data[corev1.TLSCertKey]\n\tif len(pkData) == 0 || len(certData) == 0 {\n\t\treturn nil, fmt.Errorf(\"missing data in CA secret\")\n\t}\n\tcert, err := tls.X509KeyPair(certData, pkData)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to parse data in CA secret: %w\", err)\n\t}\n\n\tx509Cert, err := x509.ParseCertificate(cert.Certificate[0])\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"internal error parsing x509 certificate: %w\", err)\n\t}\n\n\treturn x509Cert.DNSNames, nil\n}\n", "idx": 3, "id": 28839, "msg": "", "proj": "jetstack-cert-manager", "lang": "go"}
{"patch": "@@ -537,7 +537,8 @@ module BoltServer\n         'config' => {\n           'transport' => 'winrm',\n           'winrm' => opts.slice(*Bolt::Config::Transport::WinRM.options)\n-        }\n+        },\n+        'plugin_hooks' => target_hash['plugin_hooks']\n       }\n \n       inventory = Bolt::Inventory.empty", "y": 0, "oldf": "# frozen_string_literal: true\n\nrequire 'sinatra'\nrequire 'addressable/uri'\nrequire 'bolt'\nrequire 'bolt/error'\nrequire 'bolt/inventory'\nrequire 'bolt/project'\nrequire 'bolt/target'\nrequire 'bolt_server/file_cache'\nrequire 'bolt_server/plugin'\nrequire 'bolt_server/plugin/puppet_connect_data'\nrequire 'bolt_server/request_error'\nrequire 'bolt/task/puppet_server'\nrequire 'json'\nrequire 'json-schema'\n\n# These are only needed for the `/plans` endpoint.\nrequire 'puppet'\n\n# Needed by the `/project_file_metadatas` endpoint\nrequire 'puppet/file_serving/fileset'\n\n# Needed by the 'project_facts_plugin_tarball' endpoint\nrequire 'minitar'\nrequire 'zlib'\n\nmodule BoltServer\n  class TransportApp < Sinatra::Base\n    # This disables Sinatra's error page generation\n    set :show_exceptions, false\n\n    # These partial schemas are reused to build multiple request schemas\n    PARTIAL_SCHEMAS = %w[target-any target-ssh target-winrm task].freeze\n\n    # These schemas combine shared schemas to describe client requests\n    REQUEST_SCHEMAS = %w[\n      action-check_node_connections\n      action-run_command\n      action-run_task\n      action-run_script\n      action-upload_file\n      transport-ssh\n      transport-winrm\n      connect-data\n    ].freeze\n\n    # PE_BOLTLIB_PATH is intended to function exactly like the BOLTLIB_PATH used\n    # in Bolt::PAL. Paths and variable names are similar to what exists in\n    # Bolt::PAL, but with a 'PE' prefix.\n    PE_BOLTLIB_PATH = '/opt/puppetlabs/server/apps/bolt-server/pe-bolt-modules'\n\n    # For now at least, we maintain an entirely separate codedir from\n    # puppetserver by default, so that filesync can work properly. If filesync\n    # is not used, this can instead match the usual puppetserver codedir.\n    # See the `orchestrator.bolt.codedir` tk config setting.\n    DEFAULT_BOLT_CODEDIR = '/opt/puppetlabs/server/data/orchestration-services/code'\n\n    def initialize(config)\n      @config = config\n      @schemas = Hash[REQUEST_SCHEMAS.map do |basename|\n        [basename, JSON.parse(File.read(File.join(__dir__, ['schemas', \"#{basename}.json\"])))]\n      end]\n\n      PARTIAL_SCHEMAS.each do |basename|\n        schema_content = JSON.parse(File.read(File.join(__dir__, ['schemas', 'partials', \"#{basename}.json\"])))\n        shared_schema = JSON::Schema.new(schema_content, Addressable::URI.parse(\"partial:#{basename}\"))\n        JSON::Validator.add_schema(shared_schema)\n      end\n\n      @executor = Bolt::Executor.new(0)\n\n      @file_cache = BoltServer::FileCache.new(@config).setup\n\n      # This is needed until the PAL is threadsafe.\n      @pal_mutex = Mutex.new\n\n      @logger = Bolt::Logger.logger(self)\n\n      super(nil)\n    end\n\n    def scrub_stack_trace(result)\n      if result.dig('value', '_error', 'details', 'stack_trace')\n        result['value']['_error']['details'].reject! { |k| k == 'stack_trace' }\n      end\n      result\n    end\n\n    def validate_schema(schema, body)\n      schema_error = JSON::Validator.fully_validate(schema, body)\n      if schema_error.any?\n        raise BoltServer::RequestError.new(\"There was an error validating the request body.\",\n                                           schema_error)\n      end\n    end\n\n    # Turns a Bolt::ResultSet object into a status hash that is fit\n    # to return to the client in a response. In the case of every action\n    # *except* check_node_connections the response will be a single serialized Result.\n    # In the check_node_connections case the response will be a hash with the top level \"status\"\n    # of the result and the serialized individual target results.\n    def result_set_to_data(result_set, aggregate: false)\n      # use ResultSet#ok method to determine status of a (potentially) aggregate result before serializing\n      result_set_status = result_set.ok ? 'success' : 'failure'\n      scrubbed_results = result_set.map do |result|\n        scrub_stack_trace(result.to_data)\n      end\n\n      if aggregate\n        {\n          status: result_set_status,\n          result: scrubbed_results\n        }\n      else\n        # If there was only one target, return the first result on its own\n        scrubbed_results.first\n      end\n    end\n\n    def run_task(target, body)\n      validate_schema(@schemas[\"action-run_task\"], body)\n\n      task_data = body['task']\n      task = Bolt::Task::PuppetServer.new(task_data['name'], task_data['metadata'], task_data['files'], @file_cache)\n      parameters = body['parameters'] || {}\n      # Wrap parameters marked with '\"sensitive\": true' in the task metadata with a\n      # Sensitive wrapper type. This way it's not shown in logs.\n      if (param_spec = task.parameters)\n        parameters.each do |k, v|\n          if param_spec[k] && param_spec[k]['sensitive']\n            parameters[k] = Puppet::Pops::Types::PSensitiveType::Sensitive.new(v)\n          end\n        end\n      end\n\n      @executor.run_task(target, task, parameters).each do |result|\n        value = result.value\n        next unless value.is_a?(Hash)\n        next unless value.key?('_sensitive')\n        value['_sensitive'] = value['_sensitive'].unwrap\n      end\n    end\n\n    def run_command(target, body)\n      validate_schema(@schemas[\"action-run_command\"], body)\n      command = body['command']\n      @executor.run_command(target, command)\n    end\n\n    def check_node_connections(targets, body)\n      validate_schema(@schemas[\"action-check_node_connections\"], body)\n\n      # Puppet Enterprise's orchestrator service uses the\n      # check_node_connections endpoint to check whether nodes that should be\n      # contacted over SSH or WinRM are responsive. The wait time here is 0\n      # because the endpoint is meant to be used for a single check of all\n      # nodes; External implementations of wait_until_available (like\n      # orchestrator's) should contact the endpoint in their own loop.\n      @executor.wait_until_available(targets, wait_time: 0)\n    end\n\n    def upload_file(target, body)\n      validate_schema(@schemas[\"action-upload_file\"], body)\n      files = body['files']\n      destination = body['destination']\n      job_id = body['job_id']\n      cache_dir = @file_cache.create_cache_dir(job_id.to_s)\n      FileUtils.mkdir_p(cache_dir)\n      files.each do |file|\n        relative_path = file['relative_path']\n        uri = file['uri']\n        sha256 = file['sha256']\n        kind = file['kind']\n        path = File.join(cache_dir, relative_path)\n        case kind\n        when 'file'\n          # The parent should already be created by `directory` entries,\n          # but this is to be on the safe side.\n          parent = File.dirname(path)\n          FileUtils.mkdir_p(parent)\n          @file_cache.serial_execute { @file_cache.download_file(path, sha256, uri) }\n        when 'directory'\n          # Create directory in cache so we can move files in.\n          FileUtils.mkdir_p(path)\n        else\n          raise BoltServer::RequestError, \"Invalid kind: '#{kind}' supplied. Must be 'file' or 'directory'.\"\n        end\n      end\n      # We need to special case the scenario where only one file was\n      # included in the request to download. Otherwise, the call to upload_file\n      # will attempt to upload with a directory as a source and potentially a\n      # filename as a destination on the host. In that case the end result will\n      # be the file downloaded to a directory with the same name as the source\n      # filename, rather than directly to the filename set in the destination.\n      upload_source = if files.size == 1 && files[0]['kind'] == 'file'\n                        File.join(cache_dir, files[0]['relative_path'])\n                      else\n                        cache_dir\n                      end\n      @executor.upload_file(target, upload_source, destination)\n    end\n\n    def run_script(target, body)\n      validate_schema(@schemas[\"action-run_script\"], body)\n      # Download the file onto the machine.\n      file_location = @file_cache.update_file(body['script'])\n      @executor.run_script(target, file_location, body['arguments'])\n    end\n\n    # This function is nearly identical to Bolt::Pal's `with_puppet_settings` with the\n    # one difference that we set the codedir to point to actual code, rather than the\n    # tmpdir. We only use this funtion inside the Modulepath initializer so that Puppet\n    # is correctly configured to pull environment configuration correctly. If we don't\n    # set codedir in this way: when we try to load and interpolate the modulepath it\n    # won't correctly load.\n    #\n    # WARNING: THIS FUNCTION SHOULD ONLY BE CALLED INSIDE A SYNCHRONIZED PAL MUTEX\n    def with_pe_pal_init_settings(codedir, environmentpath, basemodulepath)\n      Dir.mktmpdir('pe-bolt') do |dir|\n        cli = []\n        Puppet::Settings::REQUIRED_APP_SETTINGS.each do |setting|\n          dir = setting == :codedir ? codedir : dir\n          cli << \"--#{setting}\" << dir\n        end\n        cli << \"--environmentpath\" << environmentpath\n        cli << \"--basemodulepath\" << basemodulepath\n        Puppet.settings.send(:clear_everything_for_tests)\n        Puppet.initialize_settings(cli)\n        yield\n      end\n    end\n\n    # Use puppet to identify the modulepath from an environment.\n    #\n    # WARNING: THIS FUNCTION SHOULD ONLY BE CALLED INSIDE A SYNCHRONIZED PAL MUTEX\n    def modulepath_from_environment(environment_name)\n      codedir = @config['environments-codedir'] || DEFAULT_BOLT_CODEDIR\n      environmentpath = @config['environmentpath'] || \"#{codedir}/environments\"\n      basemodulepath = @config['basemodulepath'] || \"#{codedir}/modules:/opt/puppetlabs/puppet/modules\"\n      with_pe_pal_init_settings(codedir, environmentpath, basemodulepath) do\n        environment = Puppet.lookup(:environments).get!(environment_name)\n        environment.modulepath\n      end\n    end\n\n    def in_pe_pal_env(environment)\n      raise BoltServer::RequestError, \"'environment' is a required argument\" if environment.nil?\n      @pal_mutex.synchronize do\n        modulepath_obj = Bolt::Config::Modulepath.new(\n          modulepath_from_environment(environment),\n          boltlib_path: [PE_BOLTLIB_PATH, Bolt::Config::Modulepath::BOLTLIB_PATH]\n        )\n        pal = Bolt::PAL.new(modulepath_obj, nil, nil)\n        yield pal\n      rescue Puppet::Environments::EnvironmentNotFound\n        raise BoltServer::RequestError, \"environment: '#{environment}' does not exist\"\n      end\n    end\n\n    def config_from_project(versioned_project)\n      project_dir = File.join(@config['projects-dir'], versioned_project)\n      unless Dir.exist?(project_dir)\n        raise BoltServer::RequestError,\n              \"versioned_project: '#{project_dir}' does not exist\"\n      end\n      project = Bolt::Project.create_project(project_dir)\n      Bolt::Config.from_project(project, { log: { 'bolt-debug.log' => 'disable' } })\n    end\n\n    def pal_from_project_bolt_config(bolt_config)\n      modulepath_object = Bolt::Config::Modulepath.new(\n        bolt_config.modulepath,\n        boltlib_path: [PE_BOLTLIB_PATH, Bolt::Config::Modulepath::BOLTLIB_PATH],\n        builtin_content_path: @config['builtin-content-dir']\n      )\n      Bolt::PAL.new(modulepath_object, nil, nil, nil, nil, nil, bolt_config.project)\n    end\n\n    def in_bolt_project(versioned_project)\n      @pal_mutex.synchronize do\n        bolt_config = config_from_project(versioned_project)\n        pal = pal_from_project_bolt_config(bolt_config)\n        context = {\n          pal: pal,\n          config: bolt_config\n        }\n        yield context\n      end\n    end\n\n    def pe_plan_info(pal, module_name, plan_name)\n      # Handle case where plan name is simply module name with special `init.pp` plan\n      plan_name = if plan_name == 'init' || plan_name.nil?\n                    module_name\n                  else\n                    \"#{module_name}::#{plan_name}\"\n                  end\n      plan_info = pal.get_plan_info(plan_name)\n      # Path to module is meaningless in PE\n      plan_info.delete('module')\n      plan_info\n    end\n\n    def build_puppetserver_uri(file_identifier, module_name, parameters)\n      segments = file_identifier.split('/', 3)\n      if segments.size == 1\n        {\n          'path' => \"/puppet/v3/file_content/tasks/#{module_name}/#{file_identifier}\",\n          'params' => parameters\n        }\n      else\n        module_segment, mount_segment, name_segment = *segments\n        {\n          'path' => case mount_segment\n                    when 'files'\n                      \"/puppet/v3/file_content/modules/#{module_segment}/#{name_segment}\"\n                    when 'tasks'\n                      \"/puppet/v3/file_content/tasks/#{module_segment}/#{name_segment}\"\n                    when 'lib'\n                      \"/puppet/v3/file_content/plugins/#{name_segment}\"\n                    end,\n          'params' => parameters\n        }\n      end\n    end\n\n    def pe_task_info(pal, module_name, task_name, parameters)\n      # Handle case where task name is simply module name with special `init` task\n      task_name = if task_name == 'init' || task_name.nil?\n                    module_name\n                  else\n                    \"#{module_name}::#{task_name}\"\n                  end\n      task = pal.get_task(task_name)\n      files = task.files.map do |file_hash|\n        {\n          'filename' => file_hash['name'],\n          'sha256' => Digest::SHA256.hexdigest(File.read(file_hash['path'])),\n          'size_bytes' => File.size(file_hash['path']),\n          'uri' => build_puppetserver_uri(file_hash['name'], module_name, parameters)\n        }\n      end\n      {\n        'metadata' => task.metadata,\n        'name' => task.name,\n        'files' => files\n      }\n    end\n\n    def allowed_helper(pal, metadata, allowlist)\n      allowed = !pal.filter_content([metadata['name']], allowlist).empty?\n      metadata.merge({ 'allowed' => allowed })\n    end\n\n    def task_list(pal)\n      tasks = pal.list_tasks\n      tasks.map { |task_name, _description| { 'name' => task_name } }\n    end\n\n    def plan_list(pal)\n      plans = pal.list_plans.flatten\n      plans.map { |plan_name| { 'name' => plan_name } }\n    end\n\n    def file_metadatas(versioned_project, module_name, file)\n      abs_file_path = @pal_mutex.synchronize do\n        bolt_config = config_from_project(versioned_project)\n        pal = pal_from_project_bolt_config(bolt_config)\n        pal.in_bolt_compiler do\n          mod = Puppet.lookup(:current_environment).module(module_name)\n          raise BoltServer::RequestError, \"module_name: '#{module_name}' does not exist\" unless mod\n          mod.file(file)\n        end\n      end\n\n      unless abs_file_path\n        raise BoltServer::RequestError,\n              \"file: '#{file}' does not exist inside the module's 'files' directory\"\n      end\n\n      fileset = Puppet::FileServing::Fileset.new(abs_file_path, 'recurse' => 'yes')\n      Puppet::FileServing::Fileset.merge(fileset).collect do |relative_file_path, base_path|\n        metadata = Puppet::FileServing::Metadata.new(base_path, relative_path: relative_file_path)\n        metadata.checksum_type = 'sha256'\n        metadata.links = 'follow'\n        metadata.collect\n        metadata.to_data_hash\n      end\n    end\n\n    # The provided block takes a module object and returns the list\n    # of directories to search through. This is similar to\n    # Bolt::Applicator.build_plugin_tarball.\n    def build_project_plugins_tarball(versioned_project, &block)\n      start_time = Time.now\n\n      # Fetch the plugin files\n      plugin_files = in_bolt_project(versioned_project) do |context|\n        files = {}\n\n        # Bolt also sets plugin_modulepath to user modulepath so do it here too for\n        # consistency\n        plugin_modulepath = context[:pal].user_modulepath\n        Puppet.lookup(:current_environment).override_with(modulepath: plugin_modulepath).modules.each do |mod|\n          search_dirs = block.call(mod)\n\n          files[mod] ||= []\n          Find.find(*search_dirs).each do |file|\n            files[mod] << file if File.file?(file)\n          end\n        end\n\n        files\n      end\n\n      # Pack the plugin files\n      sio = StringIO.new\n      begin\n        output = Minitar::Output.new(Zlib::GzipWriter.new(sio))\n\n        plugin_files.each do |mod, files|\n          tar_dir = Pathname.new(mod.name)\n          mod_dir = Pathname.new(mod.path)\n\n          files.each do |file|\n            tar_path = tar_dir + Pathname.new(file).relative_path_from(mod_dir)\n            stat = File.stat(file)\n            content = File.binread(file)\n            output.tar.add_file_simple(\n              tar_path.to_s,\n              data: content,\n              size: content.size,\n              mode: stat.mode & 0o777,\n              mtime: stat.mtime\n            )\n          end\n        end\n\n        duration = Time.now - start_time\n        @logger.trace(\"Packed plugins in #{duration * 1000} ms\")\n      ensure\n        output.close\n      end\n\n      Base64.encode64(sio.string)\n    end\n\n    get '/' do\n      200\n    end\n\n    if ENV['RACK_ENV'] == 'dev'\n      get '/admin/gc' do\n        GC.start\n        200\n      end\n    end\n\n    get '/admin/gc_stat' do\n      [200, GC.stat.to_json]\n    end\n\n    get '/admin/status' do\n      stats = Puma.stats\n      [200, stats.is_a?(Hash) ? stats.to_json : stats]\n    end\n\n    get '/500_error' do\n      raise 'Unexpected error'\n    end\n\n    ACTIONS = %w[\n      check_node_connections\n      run_command\n      run_task\n      run_script\n      upload_file\n    ].freeze\n\n    def make_ssh_target(target_hash)\n      defaults = {\n        'host-key-check' => false\n      }\n\n      overrides = {\n        'load-config' => false\n      }\n\n      opts = defaults.merge(target_hash).merge(overrides)\n\n      if opts['private-key-content']\n        private_key_content = opts.delete('private-key-content')\n        opts['private-key'] = { 'key-data' => private_key_content }\n      end\n\n      data = {\n        'uri' => target_hash['hostname'],\n        'config' => {\n          'transport' => 'ssh',\n          'ssh' => opts.slice(*Bolt::Config::Transport::SSH.options)\n        }\n      }\n\n      inventory = Bolt::Inventory.empty\n      Bolt::Target.from_hash(data, inventory)\n    end\n\n    post '/ssh/:action' do\n      not_found unless ACTIONS.include?(params[:action])\n\n      content_type :json\n      body = JSON.parse(request.body.read)\n\n      validate_schema(@schemas[\"transport-ssh\"], body)\n\n      targets = (body['targets'] || [body['target']]).map do |target|\n        make_ssh_target(target)\n      end\n\n      result_set = method(params[:action]).call(targets, body)\n\n      aggregate = params[:action] == 'check_node_connections'\n      [200, result_set_to_data(result_set, aggregate: aggregate).to_json]\n    end\n\n    def make_winrm_target(target_hash)\n      defaults = {\n        'ssl' => false,\n        'ssl-verify' => false\n      }\n\n      opts = defaults.merge(target_hash)\n\n      data = {\n        'uri' => target_hash['hostname'],\n        'config' => {\n          'transport' => 'winrm',\n          'winrm' => opts.slice(*Bolt::Config::Transport::WinRM.options)\n        }\n      }\n\n      inventory = Bolt::Inventory.empty\n      Bolt::Target.from_hash(data, inventory)\n    end\n\n    post '/winrm/:action' do\n      not_found unless ACTIONS.include?(params[:action])\n\n      content_type :json\n      body = JSON.parse(request.body.read)\n\n      validate_schema(@schemas[\"transport-winrm\"], body)\n\n      targets = (body['targets'] || [body['target']]).map do |target|\n        make_winrm_target(target)\n      end\n\n      result_set = method(params[:action]).call(targets, body)\n\n      aggregate = params[:action] == 'check_node_connections'\n      [200, result_set_to_data(result_set, aggregate: aggregate).to_json]\n    end\n\n    # Fetches the metadata for a single plan\n    #\n    # @param environment [String] the environment to fetch the plan from\n    get '/plans/:module_name/:plan_name' do\n      in_pe_pal_env(params['environment']) do |pal|\n        plan_info = pe_plan_info(pal, params[:module_name], params[:plan_name])\n        [200, plan_info.to_json]\n      end\n    end\n\n    # Fetches the metadata for a single plan\n    #\n    # @param versioned_project [String] the project to fetch the plan from\n    get '/project_plans/:module_name/:plan_name' do\n      raise BoltServer::RequestError, \"'versioned_project' is a required argument\" if params['versioned_project'].nil?\n      in_bolt_project(params['versioned_project']) do |context|\n        plan_info = pe_plan_info(context[:pal], params[:module_name], params[:plan_name])\n        plan_info = allowed_helper(context[:pal], plan_info, context[:config].project.plans)\n        [200, plan_info.to_json]\n      end\n    end\n\n    # Fetches the metadata for a single task\n    #\n    # @param environment [String] the environment to fetch the task from\n    get '/tasks/:module_name/:task_name' do\n      in_pe_pal_env(params['environment']) do |pal|\n        ps_parameters = {\n          'environment' => params['environment']\n        }\n        task_info = pe_task_info(pal, params[:module_name], params[:task_name], ps_parameters)\n        [200, task_info.to_json]\n      end\n    end\n\n    # Fetches the metadata for a single task\n    #\n    # @param bolt_versioned_project [String] the reference to the bolt-project directory to load task metadata from\n    get '/project_tasks/:module_name/:task_name' do\n      raise BoltServer::RequestError, \"'versioned_project' is a required argument\" if params['versioned_project'].nil?\n      in_bolt_project(params['versioned_project']) do |context|\n        ps_parameters = {\n          'versioned_project' => params['versioned_project']\n        }\n        task_info = pe_task_info(context[:pal], params[:module_name], params[:task_name], ps_parameters)\n        task_info = allowed_helper(context[:pal], task_info, context[:config].project.tasks)\n        [200, task_info.to_json]\n      end\n    end\n\n    # Fetches the list of plans for an environment, optionally fetching all metadata for each plan\n    #\n    # @param environment [String] the environment to fetch the list of plans from\n    # @param metadata [Boolean] Set to true to fetch all metadata for each plan. Defaults to false\n    get '/plans' do\n      in_pe_pal_env(params['environment']) do |pal|\n        plans = pal.list_plans.flatten\n        if params['metadata']\n          plan_info = plans.each_with_object({}) do |full_name, acc|\n            # Break apart module name from plan name\n            module_name, plan_name = full_name.split('::', 2)\n            acc[full_name] = pe_plan_info(pal, module_name, plan_name)\n          end\n          [200, plan_info.to_json]\n        else\n          # We structure this array of plans to be an array of hashes so that it matches the structure\n          # returned by the puppetserver API that serves data like this. Structuring the output this way\n          # makes switching between puppetserver and bolt-server easier, which makes changes to switch\n          # to bolt-server smaller/simpler.\n          [200, plans.map { |plan| { 'name' => plan } }.to_json]\n        end\n      end\n    end\n\n    # Fetches the list of plans for a project\n    #\n    # @param versioned_project [String] the project to fetch the list of plans from\n    get '/project_plans' do\n      raise BoltServer::RequestError, \"'versioned_project' is a required argument\" if params['versioned_project'].nil?\n      in_bolt_project(params['versioned_project']) do |context|\n        plans_response = plan_list(context[:pal])\n\n        # Dig in context for the allowlist of plans from project object\n        plans_response.map! { |metadata| allowed_helper(context[:pal], metadata, context[:config].project.plans) }\n\n        # We structure this array of plans to be an array of hashes so that it matches the structure\n        # returned by the puppetserver API that serves data like this. Structuring the output this way\n        # makes switching between puppetserver and bolt-server easier, which makes changes to switch\n        # to bolt-server smaller/simpler.\n        [200, plans_response.to_json]\n      end\n    end\n\n    # Fetches the list of tasks for an environment\n    #\n    # @param environment [String] the environment to fetch the list of tasks from\n    get '/tasks' do\n      in_pe_pal_env(params['environment']) do |pal|\n        tasks_response = task_list(pal).to_json\n\n        # We structure this array of tasks to be an array of hashes so that it matches the structure\n        # returned by the puppetserver API that serves data like this. Structuring the output this way\n        # makes switching between puppetserver and bolt-server easier, which makes changes to switch\n        # to bolt-server smaller/simpler.\n        [200, tasks_response]\n      end\n    end\n\n    # Fetches the list of tasks for a bolt-project\n    #\n    # @param versioned_project [String] the project to fetch the list of tasks from\n    get '/project_tasks' do\n      raise BoltServer::RequestError, \"'versioned_project' is a required argument\" if params['versioned_project'].nil?\n      in_bolt_project(params['versioned_project']) do |context|\n        tasks_response = task_list(context[:pal])\n\n        # Dig in context for the allowlist of tasks from project object\n        tasks_response.map! { |metadata| allowed_helper(context[:pal], metadata, context[:config].project.tasks) }\n\n        # We structure this array of tasks to be an array of hashes so that it matches the structure\n        # returned by the puppetserver API that serves data like this. Structuring the output this way\n        # makes switching between puppetserver and bolt-server easier, which makes changes to switch\n        # to bolt-server smaller/simpler.\n        [200, tasks_response.to_json]\n      end\n    end\n\n    # Implements puppetserver's file_metadatas endpoint for projects.\n    #\n    # @param versioned_project [String] the versioned_project to fetch the file metadatas from\n    get '/project_file_metadatas/:module_name/*' do\n      raise BoltServer::RequestError, \"'versioned_project' is a required argument\" if params['versioned_project'].nil?\n      file = params[:splat].first\n      metadatas = file_metadatas(params['versioned_project'], params[:module_name], file)\n      [200, metadatas.to_json]\n    rescue ArgumentError => e\n      [500, e.message]\n    end\n\n    # Returns a list of targets parsed from a Project inventory\n    #\n    # @param versioned_project [String] the versioned_project to compute the inventory from\n    post '/project_inventory_targets' do\n      content_type :json\n      body = JSON.parse(request.body.read)\n      validate_schema(@schemas[\"connect-data\"], body)\n      in_bolt_project(body['versioned_project']) do |context|\n        if context[:config].inventoryfile &&\n           context[:config].project.inventory_file.to_s !=\n           context[:config].inventoryfile\n          raise Bolt::ValidationError, \"Project inventory must be defined in the \" \\\n            \"inventory.yaml file at the root of the project directory\"\n        end\n\n        Bolt::Util.validate_file('inventory file', context[:config].project.inventory_file)\n\n        begin\n          # Set the default puppet_library plugin hook if it has not already been\n          # set\n          context[:config].data['plugin-hooks']['puppet_library'] ||= {\n            'plugin'     => 'task',\n            'task'       => 'puppet_agent::install',\n            'parameters' => {\n              'stop_service' => true\n            }\n          }\n\n          connect_plugin = BoltServer::Plugin::PuppetConnectData.new(body['puppet_connect_data'])\n          plugins = Bolt::Plugin.setup(context[:config], context[:pal], load_plugins: false)\n          plugins.add_plugin(connect_plugin)\n          %w[aws_inventory azure_inventory gcloud_inventory].each do |plugin_name|\n            plugins.add_module_plugin(plugin_name) if plugins.known_plugin?(plugin_name)\n          end\n          inventory = Bolt::Inventory.from_config(context[:config], plugins)\n          target_list = inventory.get_targets('all').map do |targ|\n            targ.to_h.merge({ 'transport' => targ.transport, 'plugin_hooks' => targ.plugin_hooks })\n          end\n        rescue Bolt::Plugin::PluginError::LoadingDisabled => e\n          msg = \"Cannot load plugin #{e.details['plugin_name']}: plugin not supported\"\n          raise BoltServer::Plugin::PluginNotSupported.new(msg, e.details['plugin_name'])\n        end\n\n        [200, target_list.to_json]\n      end\n    end\n\n    # Returns the base64 encoded tar archive of plugin code that is needed to calculate\n    # custom facts\n    #\n    # @param versioned_project [String] the versioned_project to build the plugin tarball from\n    get '/project_facts_plugin_tarball' do\n      raise BoltServer::RequestError, \"'versioned_project' is a required argument\" if params['versioned_project'].nil?\n      content_type :json\n\n      plugins_tarball = build_project_plugins_tarball(params['versioned_project']) do |mod|\n        search_dirs = []\n        search_dirs << mod.plugins if mod.plugins?\n        search_dirs << mod.pluginfacts if mod.pluginfacts?\n        search_dirs\n      end\n\n      [200, plugins_tarball.to_json]\n    end\n\n    # Returns the base64 encoded tar archive of _all_ plugin code for a project\n    #\n    # @param versioned_project [String] the versioned_project to build the plugin tarball from\n    get '/project_plugin_tarball' do\n      raise BoltServer::RequestError, \"'versioned_project' is a required argument\" if params['versioned_project'].nil?\n      content_type :json\n\n      plugins_tarball = build_project_plugins_tarball(params['versioned_project']) do |mod|\n        search_dirs = []\n        search_dirs << mod.plugins if mod.plugins?\n        search_dirs << mod.pluginfacts if mod.pluginfacts?\n        search_dirs << mod.files if mod.files?\n        type_files = \"#{mod.path}/types\"\n        search_dirs << type_files if File.exist?(type_files)\n        search_dirs\n      end\n\n      [200, plugins_tarball.to_json]\n    end\n\n    error 404 do\n      err = Bolt::Error.new(\"Could not find route #{request.path}\",\n                            'boltserver/not-found')\n      [404, err.to_json]\n    end\n\n    error BoltServer::RequestError do |err|\n      [400, err.to_json]\n    end\n\n    error Bolt::Error do |err|\n      # In order to match the request code pattern, unknown plan/task content should 400. This also\n      # gives us an opportunity to trim the message instructing users to use CLI to show available content.\n      if ['bolt/unknown-plan', 'bolt/unknown-task'].include?(err.kind)\n        [404, BoltServer::RequestError.new(err.msg.split('.').first).to_json]\n      else\n        [500, err.to_json]\n      end\n    end\n\n    error StandardError do\n      e = env['sinatra.error']\n      err = Bolt::Error.new(\"500: Unknown error: #{e.message}\",\n                            'boltserver/server-error')\n      [500, err.to_json]\n    end\n  end\nend\n", "idx": 6, "id": 18978, "msg": "", "proj": "puppetlabs-bolt", "lang": "rb"}
{"patch": "@@ -0,0 +1,15 @@\n+<?php\n+\n+/**\n+ * Copyright \u00a9 Bold Brand Commerce Sp. z o.o. All rights reserved.\n+ * See LICENSE.txt for license details.\n+ */\n+\n+declare(strict_types=1);\n+\n+namespace Ergonode\\Importer\\Domain\\Command\\Attribute;\n+\n+class ImportTextAttributeCommand extends AbstractImportAttributeCommand\n+{\n+\n+}", "y": 1, "oldf": "", "idx": 1, "id": 9436, "msg": "Why every Command is \"that same\" ? In that case one command its be enough and on handler side use a resolver to create or update attribute. That solution is right now.", "proj": "ergonode-backend", "lang": "php"}
{"patch": "@@ -224,38 +224,44 @@ module Selenium\n         end\n \n         def window_handle\n-          execute :get_current_window_handle\n+          execute :get_window_handle\n         end\n \n         def resize_window(width, height, handle = :current)\n-          execute :set_window_size, {window_handle: handle},\n-                  {width: width,\n-                   height: height}\n+          unless handle == :current\n+            raise Error::WebDriverError, 'Switch to desired window before changing its size'\n+          end\n+          execute :set_window_size, {}, {width: width,\n+                                         height: height}\n         end\n \n         def maximize_window(handle = :current)\n-          execute :maximize_window, window_handle: handle\n+          unless handle == :current\n+            raise Error::UnsupportedOperationError, 'Switch to desired window before changing its size'\n+          end\n+          execute :maximize_window\n         end\n \n         def window_size(handle = :current)\n-          data = execute :get_window_size, window_handle: handle\n+          unless handle == :current\n+            raise Error::UnsupportedOperationError, 'Switch to desired window before getting its size'\n+          end\n+          data = execute :get_window_size\n \n           Dimension.new data['width'], data['height']\n         end\n \n-        def reposition_window(x, y, handle = :current)\n-          execute :set_window_position, {window_handle: handle},\n-                  {x: x, y: y}\n+        def reposition_window(x, y)\n+          execute :set_window_position, {}, {x: x, y: y}\n         end\n \n-        def window_position(handle = :current)\n-          data = execute :get_window_position, window_handle: handle\n-\n+        def window_position\n+          data = execute :get_window_position\n           Point.new data['x'], data['y']\n         end\n \n         def screenshot\n-          execute :screenshot\n+          execute :take_screenshot\n         end\n \n         #", "y": 0, "oldf": "# encoding: utf-8\n#\n# Licensed to the Software Freedom Conservancy (SFC) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The SFC licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\nmodule Selenium\n  module WebDriver\n    module Remote\n      #\n      # Low level bridge to the remote server, through which the rest of the API works.\n      #\n      # @api private\n      #\n\n      class Bridge\n        include BridgeHelper\n\n        attr_accessor :context, :http, :file_detector\n        attr_reader :capabilities\n\n        #\n        # Initializes the bridge with the given server URL.\n        #\n        # @param url         [String] url for the remote server\n        # @param http_client [Object] an HTTP client instance that implements the same protocol as Http::Default\n        # @param desired_capabilities [Capabilities] an instance of Remote::Capabilities describing the capabilities you want\n        #\n\n        def initialize(opts = {})\n          opts = opts.dup\n\n          port = opts.delete(:port) || 4444\n          http_client = opts.delete(:http_client) { Http::Default.new }\n          desired_capabilities = opts.delete(:desired_capabilities) { Capabilities.firefox }\n          url = opts.delete(:url) { \"http://#{Platform.localhost}:#{port}/wd/hub\" }\n\n          unless opts.empty?\n            raise ArgumentError, \"unknown option#{'s' if opts.size != 1}: #{opts.inspect}\"\n          end\n\n          if desired_capabilities.is_a?(Symbol)\n            unless Capabilities.respond_to?(desired_capabilities)\n              raise Error::WebDriverError, \"invalid desired capability: #{desired_capabilities.inspect}\"\n            end\n\n            desired_capabilities = Capabilities.send(desired_capabilities)\n          end\n\n          uri = url.is_a?(URI) ? url : URI.parse(url)\n          uri.path += '/' unless uri.path =~ %r{\\/$}\n\n          http_client.server_url = uri\n\n          @http = http_client\n          @capabilities = create_session(desired_capabilities)\n\n          @file_detector = nil\n        end\n\n        def browser\n          @browser ||= (\n            name = @capabilities.browser_name\n            name ? name.tr(' ', '_').to_sym : 'unknown'\n          )\n        end\n\n        def driver_extensions\n          [\n            DriverExtensions::HasInputDevices,\n            DriverExtensions::UploadsFiles,\n            DriverExtensions::TakesScreenshot,\n            DriverExtensions::HasSessionId,\n            DriverExtensions::Rotatable,\n            DriverExtensions::HasTouchScreen,\n            DriverExtensions::HasLocation,\n            DriverExtensions::HasNetworkConnection,\n            DriverExtensions::HasRemoteStatus,\n            DriverExtensions::HasWebStorage\n          ]\n        end\n\n        def commands(command)\n          COMMANDS[command]\n        end\n\n        #\n        # Returns the current session ID.\n        #\n\n        def session_id\n          @session_id || raise(Error::WebDriverError, 'no current session exists')\n        end\n\n        def create_session(desired_capabilities)\n          resp = raw_execute :new_session, {}, {desiredCapabilities: desired_capabilities}\n          @session_id = resp['sessionId']\n          return Capabilities.json_create resp['value'] if @session_id\n\n          raise Error::WebDriverError, 'no sessionId in returned payload'\n        end\n\n        def status\n          execute :status\n        end\n\n        def get(url)\n          execute :get, {}, {url: url}\n        end\n\n        def session_capabilities\n          Capabilities.json_create execute(:get_capabilities)\n        end\n\n        def implicit_wait_timeout=(milliseconds)\n          execute :implicitly_wait, {}, {ms: milliseconds}\n        end\n\n        def script_timeout=(milliseconds)\n          execute :set_script_timeout, {}, {ms: milliseconds}\n        end\n\n        def timeout(type, milliseconds)\n          execute :set_timeout, {}, {type: type, ms: milliseconds}\n        end\n\n        #\n        # alerts\n        #\n\n        def accept_alert\n          execute :accept_alert\n        end\n\n        def dismiss_alert\n          execute :dismiss_alert\n        end\n\n        def alert=(keys)\n          execute :set_alert_value, {}, {text: keys.to_s}\n        end\n\n        def alert_text\n          execute :get_alert_text\n        end\n\n        def authentication(credentials)\n          execute :set_authentication, {}, credentials\n        end\n\n        #\n        # navigation\n        #\n\n        def go_back\n          execute :go_back\n        end\n\n        def go_forward\n          execute :go_forward\n        end\n\n        def url\n          execute :get_current_url\n        end\n\n        def title\n          execute :get_title\n        end\n\n        def page_source\n          execute :get_page_source\n        end\n\n        def switch_to_window(name)\n          execute :switch_to_window, {}, {name: name}\n        end\n\n        def switch_to_frame(id)\n          execute :switch_to_frame, {}, {id: id}\n        end\n\n        def switch_to_parent_frame\n          execute :switch_to_parent_frame\n        end\n\n        def switch_to_default_content\n          switch_to_frame(nil)\n        end\n\n        def quit\n          execute :quit\n          http.close\n        rescue *http.quit_errors\n        end\n\n        def close\n          execute :close\n        end\n\n        def refresh\n          execute :refresh\n        end\n\n        #\n        # window handling\n        #\n\n        def window_handles\n          execute :get_window_handles\n        end\n\n        def window_handle\n          execute :get_current_window_handle\n        end\n\n        def resize_window(width, height, handle = :current)\n          execute :set_window_size, {window_handle: handle},\n                  {width: width,\n                   height: height}\n        end\n\n        def maximize_window(handle = :current)\n          execute :maximize_window, window_handle: handle\n        end\n\n        def window_size(handle = :current)\n          data = execute :get_window_size, window_handle: handle\n\n          Dimension.new data['width'], data['height']\n        end\n\n        def reposition_window(x, y, handle = :current)\n          execute :set_window_position, {window_handle: handle},\n                  {x: x, y: y}\n        end\n\n        def window_position(handle = :current)\n          data = execute :get_window_position, window_handle: handle\n\n          Point.new data['x'], data['y']\n        end\n\n        def screenshot\n          execute :screenshot\n        end\n\n        #\n        # HTML 5\n        #\n\n        def local_storage_item(key, value = nil)\n          if value\n            execute :set_local_storage_item, {}, {key: key, value: value}\n          else\n            execute :get_local_storage_item, key: key\n          end\n        end\n\n        def remove_local_storage_item(key)\n          execute :remove_local_storage_item, key: key\n        end\n\n        def local_storage_keys\n          execute :get_local_storage_keys\n        end\n\n        def clear_local_storage\n          execute :clear_local_storage\n        end\n\n        def local_storage_size\n          execute :get_local_storage_size\n        end\n\n        def session_storage_item(key, value = nil)\n          if value\n            execute :set_session_storage_item, {}, {key: key, value: value}\n          else\n            execute :get_session_storage_item, key: key\n          end\n        end\n\n        def remove_session_storage_item(key)\n          execute :remove_session_storage_item, key: key\n        end\n\n        def session_storage_keys\n          execute :get_session_storage_keys\n        end\n\n        def clear_session_storage\n          execute :clear_session_storage\n        end\n\n        def session_storage_size\n          execute :get_session_storage_size\n        end\n\n        def location\n          obj = execute(:get_location) || {}\n          Location.new obj['latitude'], obj['longitude'], obj['altitude']\n        end\n\n        def set_location(lat, lon, alt)\n          loc = {latitude: lat, longitude: lon, altitude: alt}\n          execute :set_location, {}, {location: loc}\n        end\n\n        def network_connection\n          execute :get_network_connection\n        end\n\n        def network_connection=(type)\n          execute :set_network_connection, {}, {parameters: {type: type}}\n        end\n\n        #\n        # javascript execution\n        #\n\n        def execute_script(script, *args)\n          assert_javascript_enabled\n\n          result = execute :execute_script, {}, {script: script, args: args}\n          unwrap_script_result result\n        end\n\n        def execute_async_script(script, *args)\n          assert_javascript_enabled\n\n          result = execute :execute_async_script, {}, {script: script, args: args}\n          unwrap_script_result result\n        end\n\n        #\n        # cookies\n        #\n\n        def options\n          @options ||= WebDriver::Options.new(self)\n        end\n\n        def add_cookie(cookie)\n          execute :add_cookie, {}, {cookie: cookie}\n        end\n\n        def delete_cookie(name)\n          execute :delete_cookie, name: name\n        end\n\n        def cookies\n          execute :get_cookies\n        end\n\n        def delete_all_cookies\n          execute :delete_all_cookies\n        end\n\n        #\n        # actions\n        #\n\n        def click_element(element)\n          execute :click_element, id: element\n        end\n\n        def click\n          execute :click, {}, {button: 0}\n        end\n\n        def double_click\n          execute :double_click\n        end\n\n        def context_click\n          execute :click, {}, {button: 2}\n        end\n\n        def mouse_down\n          execute :mouse_down\n        end\n\n        def mouse_up\n          execute :mouse_up\n        end\n\n        def mouse_move_to(element, x = nil, y = nil)\n          params = {element: element}\n\n          if x && y\n            params[:xoffset] = x\n            params[:yoffset] = y\n          end\n\n          execute :mouse_move_to, {}, params\n        end\n\n        def send_keys_to_active_element(key)\n          execute :send_keys_to_active_element, {}, {value: key}\n        end\n\n        def send_keys_to_element(element, keys)\n          if @file_detector\n            local_file = @file_detector.call(keys)\n            keys = upload(local_file) if local_file\n          end\n\n          execute :send_keys_to_element, {id: element}, {value: Array(keys)}\n        end\n\n        def upload(local_file)\n          unless File.file?(local_file)\n            raise Error::WebDriverError, \"you may only upload files: #{local_file.inspect}\"\n          end\n\n          execute :upload_file, {}, {file: Zipper.zip_file(local_file)}\n        end\n\n        def clear_element(element)\n          execute :clear_element, id: element\n        end\n\n        def submit_element(element)\n          execute :submit_element, id: element\n        end\n\n        def drag_element(element, right_by, down_by)\n          execute :drag_element, {id: element}, {x: right_by, y: down_by}\n        end\n\n        def touch_single_tap(element)\n          execute :touch_single_tap, {}, {element: element}\n        end\n\n        def touch_double_tap(element)\n          execute :touch_double_tap, {}, {element: element}\n        end\n\n        def touch_long_press(element)\n          execute :touch_long_press, {}, {element: element}\n        end\n\n        def touch_down(x, y)\n          execute :touch_down, {}, {x: x, y: y}\n        end\n\n        def touch_up(x, y)\n          execute :touch_up, {}, {x: x, y: y}\n        end\n\n        def touch_move(x, y)\n          execute :touch_move, {}, {x: x, y: y}\n        end\n\n        def touch_scroll(element, x, y)\n          if element\n            execute :touch_scroll, {}, {element: element,\n                                       xoffset: x,\n                                       yoffset: y}\n          else\n            execute :touch_scroll, {}, {xoffset: x, yoffset: y}\n          end\n        end\n\n        def touch_flick(xspeed, yspeed)\n          execute :touch_flick, {}, {xspeed: xspeed, yspeed: yspeed}\n        end\n\n        def touch_element_flick(element, right_by, down_by, speed)\n          execute :touch_flick, {}, {element: element,\n                                    xoffset: right_by,\n                                    yoffset: down_by,\n                                    speed: speed}\n        end\n\n        def screen_orientation=(orientation)\n          execute :set_screen_orientation, {}, {orientation: orientation}\n        end\n\n        def screen_orientation\n          execute :get_screen_orientation\n        end\n\n        #\n        # logs\n        #\n\n        def available_log_types\n          types = execute :get_available_log_types\n          Array(types).map(&:to_sym)\n        end\n\n        def log(type)\n          data = execute :get_log, {}, {type: type.to_s}\n\n          Array(data).map do |l|\n            begin\n              LogEntry.new l.fetch('level', 'UNKNOWN'), l.fetch('timestamp'), l.fetch('message')\n            rescue KeyError\n              next\n            end\n          end\n        end\n\n        #\n        # element properties\n        #\n\n        def element_tag_name(element)\n          execute :get_element_tag_name, id: element\n        end\n\n        def element_attribute(element, name)\n          execute :get_element_attribute, id: element.ref, name: name\n        end\n\n        # Backwards compatibility for w3c\n        def element_property(element, name)\n          execute_script 'return arguments[0][arguments[1]]', element, name\n        end\n\n        def element_value(element)\n          execute :get_element_value, id: element\n        end\n\n        def element_text(element)\n          execute :get_element_text, id: element\n        end\n\n        def element_location(element)\n          data = execute :get_element_location, id: element\n\n          Point.new data['x'], data['y']\n        end\n\n        def element_location_once_scrolled_into_view(element)\n          data = execute :get_element_location_once_scrolled_into_view, id: element\n\n          Point.new data['x'], data['y']\n        end\n\n        def element_size(element)\n          data = execute :get_element_size, id: element\n\n          Dimension.new data['width'], data['height']\n        end\n\n        def element_enabled?(element)\n          execute :is_element_enabled, id: element\n        end\n\n        def element_selected?(element)\n          execute :is_element_selected, id: element\n        end\n\n        def element_displayed?(element)\n          execute :is_element_displayed, id: element\n        end\n\n        def element_value_of_css_property(element, prop)\n          execute :get_element_value_of_css_property, id: element, property_name: prop\n        end\n\n        #\n        # finding elements\n        #\n\n        def active_element\n          Element.new self, element_id_from(execute(:get_active_element))\n        end\n\n        alias_method :switch_to_active_element, :active_element\n\n        def find_element_by(how, what, parent = nil)\n          id = if parent\n                 execute :find_child_element, {id: parent}, {using: how, value: what}\n               else\n                 execute :find_element, {}, {using: how, value: what}\n               end\n\n          Element.new self, element_id_from(id)\n        end\n\n        def find_elements_by(how, what, parent = nil)\n          ids = if parent\n                  execute :find_child_elements, {id: parent}, {using: how, value: what}\n                else\n                  execute :find_elements, {}, {using: how, value: what}\n                end\n\n          ids.map { |id| Element.new self, element_id_from(id) }\n        end\n\n        private\n\n        def assert_javascript_enabled\n          return if capabilities.javascript_enabled?\n          raise Error::UnsupportedOperationError, 'underlying webdriver instance does not support javascript'\n        end\n\n        #\n        # executes a command on the remote server.\n        #\n        #\n        # Returns the 'value' of the returned payload\n        #\n\n        def execute(*args)\n          raw_execute(*args)['value']\n        end\n\n        #\n        # executes a command on the remote server.\n        #\n        # @return [WebDriver::Remote::Response]\n        #\n\n        def raw_execute(command, opts = {}, command_hash = nil)\n          verb, path = commands(command) || raise(ArgumentError, \"unknown command: #{command.inspect}\")\n          path = path.dup\n\n          path[':session_id'] = @session_id if path.include?(':session_id')\n\n          begin\n            opts.each { |key, value| path[key.inspect] = escaper.escape(value.to_s) }\n          rescue IndexError\n            raise ArgumentError, \"#{opts.inspect} invalid for #{command.inspect}\"\n          end\n\n          puts \"-> #{verb.to_s.upcase} #{path}\" if $DEBUG\n          http.call verb, path, command_hash\n        end\n\n        def escaper\n          @escaper ||= defined?(URI::Parser) ? URI::Parser.new : URI\n        end\n      end # Bridge\n    end # Remote\n  end # WebDriver\nend # Selenium\n", "idx": 7, "id": 14231, "msg": "", "proj": "SeleniumHQ-selenium", "lang": "rb"}
{"patch": "@@ -223,7 +223,6 @@ public class TestHiveIcebergStorageHandlerNoScan {\n   @Test\n   public void testCreateTableWithUnpartitionedSpec() {\n     TableIdentifier identifier = TableIdentifier.of(\"default\", \"customers\");\n-\n     // We need the location for HadoopTable based tests only\n     shell.executeStatement(\"CREATE EXTERNAL TABLE customers \" +\n         \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +", "y": 0, "oldf": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\n\npackage org.apache.iceberg.mr.hive;\n\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.Collection;\nimport java.util.Collections;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Properties;\nimport java.util.Set;\nimport java.util.stream.Collectors;\nimport org.apache.hadoop.fs.FileSystem;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.hive.common.StatsSetupConst;\nimport org.apache.hadoop.hive.metastore.api.hive_metastoreConstants;\nimport org.apache.iceberg.AssertHelpers;\nimport org.apache.iceberg.BaseMetastoreTableOperations;\nimport org.apache.iceberg.BaseTable;\nimport org.apache.iceberg.FileFormat;\nimport org.apache.iceberg.PartitionSpec;\nimport org.apache.iceberg.PartitionSpecParser;\nimport org.apache.iceberg.Schema;\nimport org.apache.iceberg.SchemaParser;\nimport org.apache.iceberg.SnapshotSummary;\nimport org.apache.iceberg.TableProperties;\nimport org.apache.iceberg.catalog.TableIdentifier;\nimport org.apache.iceberg.data.Record;\nimport org.apache.iceberg.exceptions.NoSuchTableException;\nimport org.apache.iceberg.hadoop.Util;\nimport org.apache.iceberg.hive.HiveSchemaUtil;\nimport org.apache.iceberg.hive.MetastoreUtil;\nimport org.apache.iceberg.mr.Catalogs;\nimport org.apache.iceberg.mr.InputFormatConfig;\nimport org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\nimport org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\nimport org.apache.iceberg.relocated.com.google.common.collect.ImmutableSet;\nimport org.apache.iceberg.types.Type;\nimport org.apache.iceberg.types.Types;\nimport org.apache.thrift.TException;\nimport org.junit.After;\nimport org.junit.AfterClass;\nimport org.junit.Assert;\nimport org.junit.Assume;\nimport org.junit.Before;\nimport org.junit.BeforeClass;\nimport org.junit.Rule;\nimport org.junit.Test;\nimport org.junit.rules.TemporaryFolder;\nimport org.junit.runner.RunWith;\nimport org.junit.runners.Parameterized;\n\nimport static org.apache.iceberg.types.Types.NestedField.optional;\nimport static org.junit.runners.Parameterized.Parameter;\nimport static org.junit.runners.Parameterized.Parameters;\n\n@RunWith(Parameterized.class)\npublic class TestHiveIcebergStorageHandlerNoScan {\n  private static final PartitionSpec SPEC = PartitionSpec.unpartitioned();\n\n  private static final Schema COMPLEX_SCHEMA = new Schema(\n      optional(1, \"id\", Types.LongType.get()),\n      optional(2, \"name\", Types.StringType.get()),\n      optional(3, \"employee_info\", Types.StructType.of(\n          optional(7, \"employer\", Types.StringType.get()),\n          optional(8, \"id\", Types.LongType.get()),\n          optional(9, \"address\", Types.StringType.get())\n      )),\n      optional(4, \"places_lived\", Types.ListType.ofOptional(10, Types.StructType.of(\n          optional(11, \"street\", Types.StringType.get()),\n          optional(12, \"city\", Types.StringType.get()),\n          optional(13, \"country\", Types.StringType.get())\n      ))),\n      optional(5, \"memorable_moments\", Types.MapType.ofOptional(14, 15,\n          Types.StringType.get(),\n          Types.StructType.of(\n              optional(16, \"year\", Types.IntegerType.get()),\n              optional(17, \"place\", Types.StringType.get()),\n              optional(18, \"details\", Types.StringType.get())\n          ))),\n      optional(6, \"current_address\", Types.StructType.of(\n          optional(19, \"street_address\", Types.StructType.of(\n              optional(22, \"street_number\", Types.IntegerType.get()),\n              optional(23, \"street_name\", Types.StringType.get()),\n              optional(24, \"street_type\", Types.StringType.get())\n          )),\n          optional(20, \"country\", Types.StringType.get()),\n          optional(21, \"postal_code\", Types.StringType.get())\n      ))\n  );\n\n  private static final Set<String> IGNORED_PARAMS = ImmutableSet.of(\"bucketing_version\", \"numFilesErasureCoded\");\n\n  @Parameters(name = \"catalog={0}\")\n  public static Collection<Object[]> parameters() {\n    Collection<Object[]> testParams = new ArrayList<>();\n    for (TestTables.TestTableType testTableType : TestTables.ALL_TABLE_TYPES) {\n      testParams.add(new Object[] {testTableType});\n    }\n\n    return testParams;\n  }\n\n  private static TestHiveShell shell;\n\n  private TestTables testTables;\n\n  @Parameter(0)\n  public TestTables.TestTableType testTableType;\n\n  @Rule\n  public TemporaryFolder temp = new TemporaryFolder();\n\n  @BeforeClass\n  public static void beforeClass() {\n    shell = HiveIcebergStorageHandlerTestUtils.shell();\n  }\n\n  @AfterClass\n  public static void afterClass() {\n    shell.stop();\n  }\n\n  @Before\n  public void before() throws IOException {\n    testTables = HiveIcebergStorageHandlerTestUtils.testTables(shell, testTableType, temp);\n    // Uses spark as an engine so we can detect if we unintentionally try to use any execution engines\n    HiveIcebergStorageHandlerTestUtils.init(shell, testTables, temp, \"spark\");\n  }\n\n  @After\n  public void after() throws Exception {\n    HiveIcebergStorageHandlerTestUtils.close(shell);\n  }\n\n  @Test\n  public void testCreateDropTable() throws TException, IOException, InterruptedException {\n    TableIdentifier identifier = TableIdentifier.of(\"default\", \"customers\");\n\n    shell.executeStatement(\"CREATE EXTERNAL TABLE customers \" +\n        \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n        testTables.locationForCreateTableSQL(identifier) +\n        \"TBLPROPERTIES ('\" + InputFormatConfig.TABLE_SCHEMA + \"'='\" +\n        SchemaParser.toJson(HiveIcebergStorageHandlerTestUtils.CUSTOMER_SCHEMA) + \"', \" +\n        \"'\" + InputFormatConfig.PARTITION_SPEC + \"'='\" +\n        PartitionSpecParser.toJson(PartitionSpec.unpartitioned()) + \"', \" +\n        \"'dummy'='test')\");\n\n    // Check the Iceberg table data\n    org.apache.iceberg.Table icebergTable = testTables.loadTable(identifier);\n    Assert.assertEquals(HiveIcebergStorageHandlerTestUtils.CUSTOMER_SCHEMA.asStruct(),\n        icebergTable.schema().asStruct());\n    Assert.assertEquals(PartitionSpec.unpartitioned(), icebergTable.spec());\n\n    if (!Catalogs.hiveCatalog(shell.getHiveConf())) {\n      shell.executeStatement(\"DROP TABLE customers\");\n\n      // Check if the table was really dropped even from the Catalog\n      AssertHelpers.assertThrows(\"should throw exception\", NoSuchTableException.class,\n          \"Table does not exist\", () -> {\n            testTables.loadTable(identifier);\n          }\n      );\n    } else {\n      org.apache.hadoop.hive.metastore.api.Table hmsTable = shell.metastore().getTable(\"default\", \"customers\");\n      Path hmsTableLocation = new Path(hmsTable.getSd().getLocation());\n\n      // Drop the table\n      shell.executeStatement(\"DROP TABLE customers\");\n\n      // Check if we drop an exception when trying to load the table\n      AssertHelpers.assertThrows(\"should throw exception\", NoSuchTableException.class,\n          \"Table does not exist\", () -> {\n            testTables.loadTable(identifier);\n          }\n      );\n\n      // Check if the files are removed\n      FileSystem fs = Util.getFs(hmsTableLocation, shell.getHiveConf());\n      if (fs.exists(hmsTableLocation)) {\n        // if table directory has been deleted, we're good. This is the expected behavior in Hive4.\n        // if table directory exists, its contents should have been cleaned up, save for an empty metadata dir (Hive3).\n        Assert.assertEquals(1, fs.listStatus(hmsTableLocation).length);\n        Assert.assertEquals(0, fs.listStatus(new Path(hmsTableLocation, \"metadata\")).length);\n      }\n    }\n  }\n\n  @Test\n  public void testCreateTableWithoutSpec() {\n    TableIdentifier identifier = TableIdentifier.of(\"default\", \"customers\");\n\n    shell.executeStatement(\"CREATE EXTERNAL TABLE customers \" +\n        \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n        testTables.locationForCreateTableSQL(identifier) +\n        \"TBLPROPERTIES ('\" + InputFormatConfig.TABLE_SCHEMA + \"'='\" +\n        SchemaParser.toJson(HiveIcebergStorageHandlerTestUtils.CUSTOMER_SCHEMA) + \"')\");\n\n    // Check the Iceberg table partition data\n    org.apache.iceberg.Table icebergTable = testTables.loadTable(identifier);\n    Assert.assertEquals(PartitionSpec.unpartitioned(), icebergTable.spec());\n  }\n\n  @Test\n  public void testCreateTableWithUnpartitionedSpec() {\n    TableIdentifier identifier = TableIdentifier.of(\"default\", \"customers\");\n\n    // We need the location for HadoopTable based tests only\n    shell.executeStatement(\"CREATE EXTERNAL TABLE customers \" +\n        \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n        testTables.locationForCreateTableSQL(identifier) +\n        \"TBLPROPERTIES ('\" + InputFormatConfig.TABLE_SCHEMA + \"'='\" +\n        SchemaParser.toJson(HiveIcebergStorageHandlerTestUtils.CUSTOMER_SCHEMA) + \"', \" +\n        \"'\" + InputFormatConfig.PARTITION_SPEC + \"'='\" +\n        PartitionSpecParser.toJson(PartitionSpec.unpartitioned()) + \"')\");\n\n    // Check the Iceberg table partition data\n    org.apache.iceberg.Table icebergTable = testTables.loadTable(identifier);\n    Assert.assertEquals(SPEC, icebergTable.spec());\n  }\n\n  @Test\n  public void testDeleteBackingTable() throws TException, IOException, InterruptedException {\n    TableIdentifier identifier = TableIdentifier.of(\"default\", \"customers\");\n\n    shell.executeStatement(\"CREATE EXTERNAL TABLE customers \" +\n        \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n        testTables.locationForCreateTableSQL(identifier) +\n        \"TBLPROPERTIES ('\" + InputFormatConfig.TABLE_SCHEMA + \"'='\" +\n        SchemaParser.toJson(HiveIcebergStorageHandlerTestUtils.CUSTOMER_SCHEMA) + \"', \" +\n        \"'\" + InputFormatConfig.EXTERNAL_TABLE_PURGE + \"'='FALSE')\");\n\n    if (!Catalogs.hiveCatalog(shell.getHiveConf())) {\n      shell.executeStatement(\"DROP TABLE customers\");\n\n      // Check if the table remains\n      testTables.loadTable(identifier);\n    } else {\n      // Check the HMS table parameters\n      org.apache.hadoop.hive.metastore.api.Table hmsTable = shell.metastore().getTable(\"default\", \"customers\");\n      Path hmsTableLocation = new Path(hmsTable.getSd().getLocation());\n\n      // Drop the table\n      shell.executeStatement(\"DROP TABLE customers\");\n\n      // Check if we drop an exception when trying to drop the table\n      AssertHelpers.assertThrows(\"should throw exception\", NoSuchTableException.class,\n          \"Table does not exist\", () -> {\n            testTables.loadTable(identifier);\n          }\n      );\n\n      // Check if the files are kept\n      FileSystem fs = Util.getFs(hmsTableLocation, shell.getHiveConf());\n      Assert.assertEquals(1, fs.listStatus(hmsTableLocation).length);\n      Assert.assertEquals(1, fs.listStatus(new Path(hmsTableLocation, \"metadata\")).length);\n    }\n  }\n\n  @Test\n  public void testCreateTableError() {\n    TableIdentifier identifier = TableIdentifier.of(\"default\", \"withShell2\");\n\n    // Wrong schema\n    AssertHelpers.assertThrows(\"should throw exception\", IllegalArgumentException.class,\n        \"Unrecognized token 'WrongSchema'\", () -> {\n          shell.executeStatement(\"CREATE EXTERNAL TABLE withShell2 \" +\n              \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n              testTables.locationForCreateTableSQL(identifier) +\n              \"TBLPROPERTIES ('\" + InputFormatConfig.TABLE_SCHEMA + \"'='WrongSchema')\");\n        }\n    );\n\n    // Missing schema, we try to get the schema from the table and fail\n    AssertHelpers.assertThrows(\"should throw exception\", IllegalArgumentException.class,\n        \"Please provide \", () -> {\n          shell.executeStatement(\"CREATE EXTERNAL TABLE withShell2 \" +\n              \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n              testTables.locationForCreateTableSQL(identifier));\n        }\n    );\n\n    if (!testTables.locationForCreateTableSQL(identifier).isEmpty()) {\n      // Only test this if the location is required\n      AssertHelpers.assertThrows(\"should throw exception\", IllegalArgumentException.class,\n          \"Table location not set\", () -> {\n            shell.executeStatement(\"CREATE EXTERNAL TABLE withShell2 \" +\n                \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n                \"TBLPROPERTIES ('\" + InputFormatConfig.TABLE_SCHEMA + \"'='\" +\n                SchemaParser.toJson(HiveIcebergStorageHandlerTestUtils.CUSTOMER_SCHEMA) + \"')\");\n          }\n      );\n    }\n  }\n\n  @Test\n  public void testCreateTableAboveExistingTable() throws IOException {\n    // Create the Iceberg table\n    testTables.createIcebergTable(shell.getHiveConf(), \"customers\", COMPLEX_SCHEMA, FileFormat.PARQUET,\n        Collections.emptyList());\n\n    if (Catalogs.hiveCatalog(shell.getHiveConf())) {\n      // In HiveCatalog we just expect an exception since the table is already exists\n      AssertHelpers.assertThrows(\"should throw exception\", IllegalArgumentException.class,\n          \"customers already exists\", () -> {\n            shell.executeStatement(\"CREATE EXTERNAL TABLE customers \" +\n                \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n                \"TBLPROPERTIES ('\" + InputFormatConfig.TABLE_SCHEMA + \"'='\" +\n                SchemaParser.toJson(HiveIcebergStorageHandlerTestUtils.CUSTOMER_SCHEMA) + \"')\");\n          }\n      );\n    } else {\n      // With other catalogs, table creation should succeed\n      shell.executeStatement(\"CREATE EXTERNAL TABLE customers \" +\n          \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n          testTables.locationForCreateTableSQL(TableIdentifier.of(\"default\", \"customers\")));\n    }\n  }\n\n  @Test\n  public void testCreatePartitionedTableWithPropertiesAndWithColumnSpecification() {\n    PartitionSpec spec =\n        PartitionSpec.builderFor(HiveIcebergStorageHandlerTestUtils.CUSTOMER_SCHEMA).identity(\"last_name\").build();\n\n    AssertHelpers.assertThrows(\"should throw exception\", IllegalArgumentException.class,\n        \"Provide only one of the following\", () -> {\n          shell.executeStatement(\"CREATE EXTERNAL TABLE customers (customer_id BIGINT) \" +\n              \"PARTITIONED BY (first_name STRING) \" +\n              \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n              testTables.locationForCreateTableSQL(TableIdentifier.of(\"default\", \"customers\")) +\n              \" TBLPROPERTIES ('\" + InputFormatConfig.PARTITION_SPEC + \"'='\" +\n              PartitionSpecParser.toJson(spec) + \"')\");\n        }\n    );\n  }\n\n  @Test\n  public void testCreateTableWithColumnSpecificationHierarchy() {\n    TableIdentifier identifier = TableIdentifier.of(\"default\", \"customers\");\n\n    shell.executeStatement(\"CREATE EXTERNAL TABLE customers (\" +\n        \"id BIGINT, name STRING, \" +\n        \"employee_info STRUCT < employer: STRING, id: BIGINT, address: STRING >, \" +\n        \"places_lived ARRAY < STRUCT <street: STRING, city: STRING, country: STRING >>, \" +\n        \"memorable_moments MAP < STRING, STRUCT < year: INT, place: STRING, details: STRING >>, \" +\n        \"current_address STRUCT < street_address: STRUCT \" +\n        \"<street_number: INT, street_name: STRING, street_type: STRING>, country: STRING, postal_code: STRING >) \" +\n        \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n        testTables.locationForCreateTableSQL(identifier));\n\n    // Check the Iceberg table data\n    org.apache.iceberg.Table icebergTable = testTables.loadTable(identifier);\n    Assert.assertEquals(COMPLEX_SCHEMA.asStruct(), icebergTable.schema().asStruct());\n  }\n\n  @Test\n  public void testCreateTableWithAllSupportedTypes() {\n    TableIdentifier identifier = TableIdentifier.of(\"default\", \"all_types\");\n    Schema allSupportedSchema = new Schema(\n        optional(1, \"t_float\", Types.FloatType.get()),\n        optional(2, \"t_double\", Types.DoubleType.get()),\n        optional(3, \"t_boolean\", Types.BooleanType.get()),\n        optional(4, \"t_int\", Types.IntegerType.get()),\n        optional(5, \"t_bigint\", Types.LongType.get()),\n        optional(6, \"t_binary\", Types.BinaryType.get()),\n        optional(7, \"t_string\", Types.StringType.get()),\n        optional(8, \"t_timestamp\", Types.TimestampType.withoutZone()),\n        optional(9, \"t_date\", Types.DateType.get()),\n        optional(10, \"t_decimal\", Types.DecimalType.of(3, 2))\n    );\n\n    // Intentionally adding some mixed letters to test that we handle them correctly\n    shell.executeStatement(\"CREATE EXTERNAL TABLE all_types (\" +\n        \"t_Float FLOaT, t_dOuble DOUBLE, t_boolean BOOLEAN, t_int INT, t_bigint BIGINT, t_binary BINARY, \" +\n        \"t_string STRING, t_timestamp TIMESTAMP, t_date DATE, t_decimal DECIMAL(3,2)) \" +\n        \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n        testTables.locationForCreateTableSQL(identifier));\n\n    // Check the Iceberg table data\n    org.apache.iceberg.Table icebergTable = testTables.loadTable(identifier);\n    Assert.assertEquals(allSupportedSchema.asStruct(), icebergTable.schema().asStruct());\n  }\n\n  @Test\n  public void testCreateTableWithNotSupportedTypes() {\n    TableIdentifier identifier = TableIdentifier.of(\"default\", \"not_supported_types\");\n    // Can not create INTERVAL types from normal create table, so leave them out from this test\n    Map<String, Type> notSupportedTypes = ImmutableMap.of(\n        \"TINYINT\", Types.IntegerType.get(),\n        \"SMALLINT\", Types.IntegerType.get(),\n        \"VARCHAR(1)\", Types.StringType.get(),\n        \"CHAR(1)\", Types.StringType.get());\n\n    for (String notSupportedType : notSupportedTypes.keySet()) {\n      AssertHelpers.assertThrows(\"should throw exception\", IllegalArgumentException.class,\n          \"Unsupported Hive type\", () -> {\n            shell.executeStatement(\"CREATE EXTERNAL TABLE not_supported_types \" +\n                \"(not_supported \" + notSupportedType + \") \" +\n                \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n                testTables.locationForCreateTableSQL(identifier));\n          }\n      );\n    }\n  }\n\n  @Test\n  public void testCreateTableWithNotSupportedTypesWithAutoConversion() {\n    TableIdentifier identifier = TableIdentifier.of(\"default\", \"not_supported_types\");\n    // Can not create INTERVAL types from normal create table, so leave them out from this test\n    Map<String, Type> notSupportedTypes = ImmutableMap.of(\n        \"TINYINT\", Types.IntegerType.get(),\n        \"SMALLINT\", Types.IntegerType.get(),\n        \"VARCHAR(1)\", Types.StringType.get(),\n         \"CHAR(1)\", Types.StringType.get());\n\n    shell.setHiveSessionValue(InputFormatConfig.SCHEMA_AUTO_CONVERSION, \"true\");\n\n    for (String notSupportedType : notSupportedTypes.keySet()) {\n      shell.executeStatement(\"CREATE EXTERNAL TABLE not_supported_types (not_supported \" + notSupportedType + \") \" +\n              \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n              testTables.locationForCreateTableSQL(identifier));\n\n      org.apache.iceberg.Table icebergTable = testTables.loadTable(identifier);\n      Assert.assertEquals(notSupportedTypes.get(notSupportedType), icebergTable.schema().columns().get(0).type());\n      shell.executeStatement(\"DROP TABLE not_supported_types\");\n    }\n  }\n\n  @Test\n  public void testCreateTableWithColumnComments() {\n    TableIdentifier identifier = TableIdentifier.of(\"default\", \"comment_table\");\n    shell.executeStatement(\"CREATE EXTERNAL TABLE comment_table (\" +\n        \"t_int INT COMMENT 'int column',  \" +\n        \"t_string STRING COMMENT 'string column') \" +\n        \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n        testTables.locationForCreateTableSQL(identifier));\n    org.apache.iceberg.Table icebergTable = testTables.loadTable(identifier);\n\n    List<Object[]> rows = shell.executeStatement(\"DESCRIBE default.comment_table\");\n    Assert.assertEquals(icebergTable.schema().columns().size(), rows.size());\n    for (int i = 0; i < icebergTable.schema().columns().size(); i++) {\n      Types.NestedField field = icebergTable.schema().columns().get(i);\n      Assert.assertArrayEquals(new Object[] {field.name(), HiveSchemaUtil.convert(field.type()).getTypeName(),\n          field.doc()}, rows.get(i));\n    }\n  }\n\n  @Test\n  public void testCreateTableWithoutColumnComments() {\n    TableIdentifier identifier = TableIdentifier.of(\"default\", \"without_comment_table\");\n    shell.executeStatement(\"CREATE EXTERNAL TABLE without_comment_table (\" +\n            \"t_int INT,  \" +\n            \"t_string STRING) \" +\n            \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n            testTables.locationForCreateTableSQL(identifier));\n    org.apache.iceberg.Table icebergTable = testTables.loadTable(identifier);\n\n    List<Object[]> rows = shell.executeStatement(\"DESCRIBE default.without_comment_table\");\n    Assert.assertEquals(icebergTable.schema().columns().size(), rows.size());\n    for (int i = 0; i < icebergTable.schema().columns().size(); i++) {\n      Types.NestedField field = icebergTable.schema().columns().get(i);\n      Assert.assertNull(field.doc());\n      Assert.assertArrayEquals(new Object[] {field.name(), HiveSchemaUtil.convert(field.type()).getTypeName(),\n          \"from deserializer\"}, rows.get(i));\n    }\n  }\n\n  @Test\n  public void testIcebergAndHmsTableProperties() throws Exception {\n    TableIdentifier identifier = TableIdentifier.of(\"default\", \"customers\");\n\n    shell.executeStatement(String.format(\"CREATE EXTERNAL TABLE default.customers \" +\n        \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' %s\" +\n        \"TBLPROPERTIES ('%s'='%s', '%s'='%s', '%s'='%s')\",\n        testTables.locationForCreateTableSQL(identifier), // we need the location for HadoopTable based tests only\n        InputFormatConfig.TABLE_SCHEMA, SchemaParser.toJson(HiveIcebergStorageHandlerTestUtils.CUSTOMER_SCHEMA),\n        InputFormatConfig.PARTITION_SPEC, PartitionSpecParser.toJson(SPEC),\n        \"custom_property\", \"initial_val\"));\n\n\n    // Check the Iceberg table parameters\n    org.apache.iceberg.Table icebergTable = testTables.loadTable(identifier);\n\n    Map<String, String> expectedIcebergProperties = new HashMap<>();\n    expectedIcebergProperties.put(\"custom_property\", \"initial_val\");\n    expectedIcebergProperties.put(\"EXTERNAL\", \"TRUE\");\n    expectedIcebergProperties.put(\"storage_handler\", HiveIcebergStorageHandler.class.getName());\n    if (Catalogs.hiveCatalog(shell.getHiveConf())) {\n      expectedIcebergProperties.put(TableProperties.ENGINE_HIVE_ENABLED, \"true\");\n    }\n    if (MetastoreUtil.hive3PresentOnClasspath()) {\n      expectedIcebergProperties.put(\"bucketing_version\", \"2\");\n    }\n    Assert.assertEquals(expectedIcebergProperties, icebergTable.properties());\n\n    // Check the HMS table parameters\n    org.apache.hadoop.hive.metastore.api.Table hmsTable = shell.metastore().getTable(\"default\", \"customers\");\n    Map<String, String> hmsParams = hmsTable.getParameters()\n        .entrySet().stream()\n        .filter(e -> !IGNORED_PARAMS.contains(e.getKey()))\n        .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));\n\n    if (Catalogs.hiveCatalog(shell.getHiveConf())) {\n      Assert.assertEquals(9, hmsParams.size());\n      Assert.assertEquals(\"initial_val\", hmsParams.get(\"custom_property\"));\n      Assert.assertEquals(\"TRUE\", hmsParams.get(InputFormatConfig.EXTERNAL_TABLE_PURGE));\n      Assert.assertEquals(\"TRUE\", hmsParams.get(\"EXTERNAL\"));\n      Assert.assertEquals(\"true\", hmsParams.get(TableProperties.ENGINE_HIVE_ENABLED));\n      Assert.assertEquals(HiveIcebergStorageHandler.class.getName(),\n          hmsParams.get(hive_metastoreConstants.META_TABLE_STORAGE));\n      Assert.assertEquals(BaseMetastoreTableOperations.ICEBERG_TABLE_TYPE_VALUE.toUpperCase(),\n          hmsParams.get(BaseMetastoreTableOperations.TABLE_TYPE_PROP));\n      Assert.assertEquals(hmsParams.get(BaseMetastoreTableOperations.METADATA_LOCATION_PROP),\n              getCurrentSnapshotForHiveCatalogTable(icebergTable));\n      Assert.assertNull(hmsParams.get(BaseMetastoreTableOperations.PREVIOUS_METADATA_LOCATION_PROP));\n      Assert.assertNotNull(hmsParams.get(hive_metastoreConstants.DDL_TIME));\n    } else {\n      Assert.assertEquals(7, hmsParams.size());\n      Assert.assertNull(hmsParams.get(TableProperties.ENGINE_HIVE_ENABLED));\n    }\n\n    // Check HMS inputformat/outputformat/serde\n    Assert.assertEquals(HiveIcebergInputFormat.class.getName(), hmsTable.getSd().getInputFormat());\n    Assert.assertEquals(HiveIcebergOutputFormat.class.getName(), hmsTable.getSd().getOutputFormat());\n    Assert.assertEquals(HiveIcebergSerDe.class.getName(), hmsTable.getSd().getSerdeInfo().getSerializationLib());\n\n    // Add two new properties to the Iceberg table and update an existing one\n    icebergTable.updateProperties()\n        .set(\"new_prop_1\", \"true\")\n        .set(\"new_prop_2\", \"false\")\n        .set(\"custom_property\", \"new_val\")\n        .commit();\n\n    // Refresh the HMS table to see if new Iceberg properties got synced into HMS\n    hmsParams = shell.metastore().getTable(\"default\", \"customers\").getParameters()\n        .entrySet().stream()\n        .filter(e -> !IGNORED_PARAMS.contains(e.getKey()))\n        .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));\n\n    if (Catalogs.hiveCatalog(shell.getHiveConf())) {\n      Assert.assertEquals(12, hmsParams.size()); // 2 newly-added properties + previous_metadata_location prop\n      Assert.assertEquals(\"true\", hmsParams.get(\"new_prop_1\"));\n      Assert.assertEquals(\"false\", hmsParams.get(\"new_prop_2\"));\n      Assert.assertEquals(\"new_val\", hmsParams.get(\"custom_property\"));\n      String prevSnapshot = getCurrentSnapshotForHiveCatalogTable(icebergTable);\n      icebergTable.refresh();\n      String newSnapshot = getCurrentSnapshotForHiveCatalogTable(icebergTable);\n      Assert.assertEquals(hmsParams.get(BaseMetastoreTableOperations.PREVIOUS_METADATA_LOCATION_PROP), prevSnapshot);\n      Assert.assertEquals(hmsParams.get(BaseMetastoreTableOperations.METADATA_LOCATION_PROP), newSnapshot);\n    } else {\n      Assert.assertEquals(7, hmsParams.size());\n    }\n\n    // Remove some Iceberg props and see if they're removed from HMS table props as well\n    if (Catalogs.hiveCatalog(shell.getHiveConf())) {\n      icebergTable.updateProperties()\n          .remove(\"custom_property\")\n          .remove(\"new_prop_1\")\n          .commit();\n      hmsParams = shell.metastore().getTable(\"default\", \"customers\").getParameters();\n      Assert.assertFalse(hmsParams.containsKey(\"custom_property\"));\n      Assert.assertFalse(hmsParams.containsKey(\"new_prop_1\"));\n      Assert.assertTrue(hmsParams.containsKey(\"new_prop_2\"));\n    }\n\n    // append some data and check whether HMS stats are aligned with snapshot summary\n    if (Catalogs.hiveCatalog(shell.getHiveConf())) {\n      List<Record> records = HiveIcebergStorageHandlerTestUtils.CUSTOMER_RECORDS;\n      testTables.appendIcebergTable(shell.getHiveConf(), icebergTable, FileFormat.PARQUET, null, records);\n      hmsParams = shell.metastore().getTable(\"default\", \"customers\").getParameters();\n      Map<String, String> summary = icebergTable.currentSnapshot().summary();\n      Assert.assertEquals(summary.get(SnapshotSummary.TOTAL_DATA_FILES_PROP), hmsParams.get(StatsSetupConst.NUM_FILES));\n      Assert.assertEquals(summary.get(SnapshotSummary.TOTAL_RECORDS_PROP), hmsParams.get(StatsSetupConst.ROW_COUNT));\n      Assert.assertEquals(summary.get(SnapshotSummary.TOTAL_FILE_SIZE_PROP), hmsParams.get(StatsSetupConst.TOTAL_SIZE));\n    }\n  }\n\n  @Test\n  public void testDropTableWithAppendedData() throws IOException {\n    TableIdentifier identifier = TableIdentifier.of(\"default\", \"customers\");\n\n    testTables.createTable(shell, identifier.name(), HiveIcebergStorageHandlerTestUtils.CUSTOMER_SCHEMA, SPEC,\n        FileFormat.PARQUET, ImmutableList.of());\n\n    org.apache.iceberg.Table icebergTable = testTables.loadTable(identifier);\n    testTables.appendIcebergTable(shell.getHiveConf(), icebergTable, FileFormat.PARQUET, null,\n        HiveIcebergStorageHandlerTestUtils.CUSTOMER_RECORDS);\n\n    shell.executeStatement(\"DROP TABLE customers\");\n  }\n\n  @Test\n  public void testDropHiveTableWithoutUnderlyingTable() throws IOException {\n    Assume.assumeFalse(\"Not relevant for HiveCatalog\", Catalogs.hiveCatalog(shell.getHiveConf()));\n\n    TableIdentifier identifier = TableIdentifier.of(\"default\", \"customers\");\n    // Create the Iceberg table in non-HiveCatalog\n    testTables.createIcebergTable(shell.getHiveConf(), identifier.name(),\n        HiveIcebergStorageHandlerTestUtils.CUSTOMER_SCHEMA, FileFormat.PARQUET,\n        HiveIcebergStorageHandlerTestUtils.CUSTOMER_RECORDS);\n\n    // Create Hive table on top\n    String tableLocation = testTables.locationForCreateTableSQL(identifier);\n    shell.executeStatement(testTables.createHiveTableSQL(identifier,\n        ImmutableMap.of(InputFormatConfig.EXTERNAL_TABLE_PURGE, \"TRUE\")));\n\n    // Drop the Iceberg table\n    Properties properties = new Properties();\n    properties.put(Catalogs.NAME, identifier.toString());\n    properties.put(Catalogs.LOCATION, tableLocation);\n    Catalogs.dropTable(shell.getHiveConf(), properties);\n\n    // Finally drop the Hive table as well\n    shell.executeStatement(\"DROP TABLE \" + identifier);\n  }\n\n  private String getCurrentSnapshotForHiveCatalogTable(org.apache.iceberg.Table icebergTable) {\n    return ((BaseMetastoreTableOperations) ((BaseTable) icebergTable).operations()).currentMetadataLocation();\n  }\n}\n", "idx": 7, "id": 32590, "msg": "", "proj": "apache-iceberg", "lang": "java"}
{"patch": "@@ -48,6 +48,7 @@ THE SOFTWARE.\n #include <utility>\n #include <vector>\n #include \"../include/hip/hcc_detail/code_object_bundle.hpp\"\n+#include \"hip_fatbin.h\"\n // TODO Use Pool APIs from HCC to get memory regions.\n \n using namespace ELFIO;", "y": 0, "oldf": "/*\nCopyright (c) 2015 - present Advanced Micro Devices, Inc. All rights reserved.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\n#include \"elfio/elfio.hpp\"\n#include \"hip/hip_runtime.h\"\n#include \"hip/hcc_detail/program_state.hpp\"\n#include \"hip_hcc_internal.h\"\n#include \"hsa_helpers.hpp\"\n#include \"trace_helper.h\"\n\n#include <hsa/amd_hsa_kernel_code.h>\n#include <hsa/hsa.h>\n#include <hsa/hsa_ext_amd.h>\n\n#include <algorithm>\n#include <cassert>\n#include <cstdint>\n#include <cstdio>\n#include <cstdlib>\n#include <fstream>\n#include <map>\n#include <memory>\n#include <mutex>\n#include <sstream>\n#include <stdexcept>\n#include <string>\n#include <tuple>\n#include <unordered_map>\n#include <utility>\n#include <vector>\n#include \"../include/hip/hcc_detail/code_object_bundle.hpp\"\n// TODO Use Pool APIs from HCC to get memory regions.\n\nusing namespace ELFIO;\nusing namespace hip_impl;\nusing namespace std;\n\ninline uint64_t alignTo(uint64_t Value, uint64_t Align, uint64_t Skew = 0) {\n    assert(Align != 0u && \"Align can't be 0.\");\n    Skew %= Align;\n    return (Value + Align - 1 - Skew) / Align * Align + Skew;\n}\n\n\nstruct ihipKernArgInfo {\n    vector<uint32_t> Size;\n    vector<uint32_t> Align;\n    vector<string> ArgType;\n    vector<string> ArgName;\n    uint32_t totalSize;\n};\n\nmap<string, ihipKernArgInfo> kernelArguments;\n\nstruct ihipModuleSymbol_t {\n    uint64_t _object{};  // The kernel object.\n    amd_kernel_code_t const* _header{};\n    string _name;  // TODO - review for performance cost.  Name is just used for debug.\n};\n\ntemplate <>\nstring ToString(hipFunction_t v) {\n    std::ostringstream ss;\n    ss << \"0x\" << std::hex << v->_object;\n    return ss.str();\n};\n\nstd::string& FunctionSymbol(hipFunction_t f) { return f->_name; };\n\n#define CHECK_HSA(hsaStatus, hipStatus)                                                            \\\n    if (hsaStatus != HSA_STATUS_SUCCESS) {                                                         \\\n        return hipStatus;                                                                          \\\n    }\n\n#define CHECKLOG_HSA(hsaStatus, hipStatus)                                                         \\\n    if (hsaStatus != HSA_STATUS_SUCCESS) {                                                         \\\n        return ihipLogStatus(hipStatus);                                                           \\\n    }\n\nhipError_t hipModuleUnload(hipModule_t hmod) {\n    HIP_INIT_API(hipModuleUnload, hmod);\n\n    // TODO - improve this synchronization so it is thread-safe.\n    // Currently we want for all inflight activity to complete, but don't prevent another\n    // thread from launching new kernels before we finish this operation.\n    ihipSynchronize();\n\n    delete hmod;  // The ihipModule_t dtor will clean everything up.\n    hmod = nullptr;\n\n    return ihipLogStatus(hipSuccess);\n}\n\nhipError_t ihipModuleLaunchKernel(hipFunction_t f, uint32_t globalWorkSizeX,\n                                  uint32_t globalWorkSizeY, uint32_t globalWorkSizeZ,\n                                  uint32_t localWorkSizeX, uint32_t localWorkSizeY,\n                                  uint32_t localWorkSizeZ, size_t sharedMemBytes,\n                                  hipStream_t hStream, void** kernelParams, void** extra,\n                                  hipEvent_t startEvent, hipEvent_t stopEvent) {\n    auto ctx = ihipGetTlsDefaultCtx();\n    hipError_t ret = hipSuccess;\n\n    if (ctx == nullptr) {\n        ret = hipErrorInvalidDevice;\n\n    } else {\n        int deviceId = ctx->getDevice()->_deviceId;\n        ihipDevice_t* currentDevice = ihipGetDevice(deviceId);\n        hsa_agent_t gpuAgent = (hsa_agent_t)currentDevice->_hsaAgent;\n\n        void* config[5] = {0};\n        size_t kernArgSize;\n\n        if (kernelParams != NULL) {\n            std::string name = f->_name;\n            struct ihipKernArgInfo pl = kernelArguments[name];\n            char* argBuf = (char*)malloc(pl.totalSize);\n            memset(argBuf, 0, pl.totalSize);\n            int index = 0;\n            for (int i = 0; i < pl.Size.size(); i++) {\n                memcpy(argBuf + index, kernelParams[i], pl.Size[i]);\n                index += pl.Align[i];\n            }\n            config[1] = (void*)argBuf;\n            kernArgSize = pl.totalSize;\n        } else if (extra != NULL) {\n            memcpy(config, extra, sizeof(size_t) * 5);\n            if (config[0] == HIP_LAUNCH_PARAM_BUFFER_POINTER &&\n                config[2] == HIP_LAUNCH_PARAM_BUFFER_SIZE && config[4] == HIP_LAUNCH_PARAM_END) {\n                kernArgSize = *(size_t*)(config[3]);\n            } else {\n                return hipErrorNotInitialized;\n            }\n\n        } else {\n            return hipErrorInvalidValue;\n        }\n\n\n        /*\n          Kernel argument preparation.\n        */\n        grid_launch_parm lp;\n        lp.dynamic_group_mem_bytes =\n            sharedMemBytes;  // TODO - this should be part of preLaunchKernel.\n        hStream = ihipPreLaunchKernel(\n            hStream, dim3(globalWorkSizeX, globalWorkSizeY, globalWorkSizeZ),\n            dim3(localWorkSizeX, localWorkSizeY, localWorkSizeZ), &lp, f->_name.c_str());\n\n\n        hsa_kernel_dispatch_packet_t aql;\n\n        memset(&aql, 0, sizeof(aql));\n\n        // aql.completion_signal._handle = 0;\n        // aql.kernarg_address = 0;\n\n        aql.workgroup_size_x = localWorkSizeX;\n        aql.workgroup_size_y = localWorkSizeY;\n        aql.workgroup_size_z = localWorkSizeZ;\n        aql.grid_size_x = globalWorkSizeX;\n        aql.grid_size_y = globalWorkSizeY;\n        aql.grid_size_z = globalWorkSizeZ;\n        aql.group_segment_size =\n            f->_header->workgroup_group_segment_byte_size + sharedMemBytes;\n        aql.private_segment_size =\n            f->_header->workitem_private_segment_byte_size;\n        aql.kernel_object = f->_object;\n        aql.setup = 3 << HSA_KERNEL_DISPATCH_PACKET_SETUP_DIMENSIONS;\n        aql.header =\n            (HSA_PACKET_TYPE_KERNEL_DISPATCH << HSA_PACKET_HEADER_TYPE) |\n            (1 << HSA_PACKET_HEADER_BARRIER);  // TODO - honor queue setting for execute_in_order\n\n        if (HCC_OPT_FLUSH) {\n            aql.header |= (HSA_FENCE_SCOPE_AGENT << HSA_PACKET_HEADER_ACQUIRE_FENCE_SCOPE) |\n                          (HSA_FENCE_SCOPE_AGENT << HSA_PACKET_HEADER_RELEASE_FENCE_SCOPE);\n        } else {\n            aql.header |= (HSA_FENCE_SCOPE_SYSTEM << HSA_PACKET_HEADER_ACQUIRE_FENCE_SCOPE) |\n                          (HSA_FENCE_SCOPE_SYSTEM << HSA_PACKET_HEADER_RELEASE_FENCE_SCOPE);\n        };\n\n\n        hc::completion_future cf;\n\n        lp.av->dispatch_hsa_kernel(&aql, config[1] /* kernarg*/, kernArgSize,\n                                   (startEvent || stopEvent) ? &cf : nullptr\n#if (__hcc_workweek__ > 17312)\n                                   ,\n                                   f->_name.c_str()\n#endif\n        );\n\n\n        if (startEvent) {\n            startEvent->attachToCompletionFuture(&cf, hStream, hipEventTypeStartCommand);\n        }\n        if (stopEvent) {\n            stopEvent->attachToCompletionFuture(&cf, hStream, hipEventTypeStopCommand);\n        }\n\n\n        if (kernelParams != NULL) {\n            free(config[1]);\n        }\n        ihipPostLaunchKernel(f->_name.c_str(), hStream, lp);\n    }\n\n    return ret;\n}\n\nhipError_t hipModuleLaunchKernel(hipFunction_t f, uint32_t gridDimX, uint32_t gridDimY,\n                                 uint32_t gridDimZ, uint32_t blockDimX, uint32_t blockDimY,\n                                 uint32_t blockDimZ, uint32_t sharedMemBytes, hipStream_t hStream,\n                                 void** kernelParams, void** extra) {\n    HIP_INIT_API(hipModuleLaunchKernel, f, gridDimX, gridDimY, gridDimZ, blockDimX, blockDimY, blockDimZ, sharedMemBytes,\n                 hStream, kernelParams, extra);\n    return ihipLogStatus(ihipModuleLaunchKernel(\n        f, blockDimX * gridDimX, blockDimY * gridDimY, gridDimZ * blockDimZ, blockDimX, blockDimY,\n        blockDimZ, sharedMemBytes, hStream, kernelParams, extra, nullptr, nullptr));\n}\n\n\nhipError_t hipHccModuleLaunchKernel(hipFunction_t f, uint32_t globalWorkSizeX,\n                                    uint32_t globalWorkSizeY, uint32_t globalWorkSizeZ,\n                                    uint32_t localWorkSizeX, uint32_t localWorkSizeY,\n                                    uint32_t localWorkSizeZ, size_t sharedMemBytes,\n                                    hipStream_t hStream, void** kernelParams, void** extra,\n                                    hipEvent_t startEvent, hipEvent_t stopEvent) {\n    HIP_INIT_API(hipHccModuleLaunchKernel, f, globalWorkSizeX, globalWorkSizeY, globalWorkSizeZ, localWorkSizeX,\n                 localWorkSizeY, localWorkSizeZ, sharedMemBytes, hStream, kernelParams, extra);\n    return ihipLogStatus(ihipModuleLaunchKernel(\n        f, globalWorkSizeX, globalWorkSizeY, globalWorkSizeZ, localWorkSizeX, localWorkSizeY,\n        localWorkSizeZ, sharedMemBytes, hStream, kernelParams, extra, startEvent, stopEvent));\n}\n\nnamespace {\nstruct Agent_global {\n    string name;\n    hipDeviceptr_t address;\n    uint32_t byte_cnt;\n};\n\ninline void track(const Agent_global& x, hsa_agent_t agent) {\n    tprintf(DB_MEM, \"  add variable '%s' with ptr=%p size=%u to tracker\\n\", x.name.c_str(),\n            x.address, x.byte_cnt);\n\n    int deviceIndex =0;\n    for ( deviceIndex = 0; deviceIndex < g_deviceCnt; deviceIndex++) {\n        if(g_allAgents[deviceIndex] == agent)\n           break;\n    }\n    auto device = ihipGetDevice(deviceIndex - 1);\n    hc::AmPointerInfo ptr_info(nullptr, x.address, x.address, x.byte_cnt, device->_acc, true,\n                               false);\n    hc::am_memtracker_add(x.address, ptr_info);\n#if USE_APP_PTR_FOR_CTX\n    hc::am_memtracker_update(x.address, device->_deviceId, 0u, ihipGetTlsDefaultCtx());\n#else\n    hc::am_memtracker_update(x.address, device->_deviceId, 0u);\n#endif\n\n}\n\ntemplate <typename Container = vector<Agent_global>>\ninline hsa_status_t copy_agent_global_variables(hsa_executable_t, hsa_agent_t agent,\n                                                hsa_executable_symbol_t x, void* out) {\n    assert(out);\n\n    hsa_symbol_kind_t t = {};\n    hsa_executable_symbol_get_info(x, HSA_EXECUTABLE_SYMBOL_INFO_TYPE, &t);\n\n    if (t == HSA_SYMBOL_KIND_VARIABLE) {\n        static_cast<Container*>(out)->push_back(Agent_global{name(x), address(x), size(x)});\n\n        track(static_cast<Container*>(out)->back(),agent);\n    }\n\n    return HSA_STATUS_SUCCESS;\n}\n\ninline hsa_agent_t this_agent() {\n    auto ctx = ihipGetTlsDefaultCtx();\n\n    if (!ctx) throw runtime_error{\"No active HIP context.\"};\n\n    auto device = ctx->getDevice();\n\n    if (!device) throw runtime_error{\"No device available for HIP.\"};\n\n    ihipDevice_t* currentDevice = ihipGetDevice(device->_deviceId);\n\n    if (!currentDevice) throw runtime_error{\"No active device for HIP.\"};\n\n    return currentDevice->_hsaAgent;\n}\n\ninline vector<Agent_global> read_agent_globals(hsa_agent_t agent, hsa_executable_t executable) {\n    vector<Agent_global> r;\n\n    hsa_executable_iterate_agent_symbols(executable, agent, copy_agent_global_variables, &r);\n\n    return r;\n}\n\ntemplate <typename ForwardIterator>\npair<hipDeviceptr_t, size_t> read_global_description(ForwardIterator f, ForwardIterator l,\n                                                     const char* name) {\n    const auto it = std::find_if(f, l, [=](const Agent_global& x) { return x.name == name; });\n\n    return it == l ? make_pair(nullptr, 0u) : make_pair(it->address, it->byte_cnt);\n}\n\nhipError_t read_agent_global_from_module(hipDeviceptr_t* dptr, size_t* bytes, hipModule_t hmod,\n                                         const char* name) {\n    static unordered_map<hipModule_t, vector<Agent_global>> agent_globals;\n\n    // TODO: this is not particularly robust.\n    if (agent_globals.count(hmod) == 0) {\n        static mutex mtx;\n        lock_guard<mutex> lck{mtx};\n\n        if (agent_globals.count(hmod) == 0) {\n            agent_globals.emplace(hmod, read_agent_globals(this_agent(), hmod->executable));\n        }\n    }\n\n    // TODO: This is unsafe iff some other emplacement triggers rehashing.\n    //       It will have to be properly fleshed out in the future.\n    const auto it0 = agent_globals.find(hmod);\n    if (it0 == agent_globals.cend()) {\n        throw runtime_error{\"agent_globals data structure corrupted.\"};\n    }\n\n    tie(*dptr, *bytes) = read_global_description(it0->second.cbegin(), it0->second.cend(), name);\n\n    return *dptr ? hipSuccess : hipErrorNotFound;\n}\n\nhipError_t read_agent_global_from_process(hipDeviceptr_t* dptr, size_t* bytes, const char* name) {\n    static unordered_map<hsa_agent_t, vector<Agent_global>> agent_globals;\n    static std::once_flag f;\n\n    call_once(f, []() {\n        for (auto&& agent_executables : hip_impl::executables()) {\n            vector<Agent_global> tmp0;\n            for (auto&& executable : agent_executables.second) {\n                auto tmp1 = read_agent_globals(agent_executables.first, executable);\n                tmp0.insert(tmp0.end(), make_move_iterator(tmp1.begin()),\n                            make_move_iterator(tmp1.end()));\n            }\n            agent_globals.emplace(agent_executables.first, move(tmp0));\n        }\n    });\n\n    const auto it = agent_globals.find(this_agent());\n\n    if (it == agent_globals.cend()) return hipErrorNotInitialized;\n\n    tie(*dptr, *bytes) = read_global_description(it->second.cbegin(), it->second.cend(), name);\n\n    return *dptr ? hipSuccess : hipErrorNotFound;\n}\n\nhsa_executable_symbol_t find_kernel_by_name(hsa_executable_t executable, const char* kname) {\n    pair<const char*, hsa_executable_symbol_t> r{kname, {}};\n\n    hsa_executable_iterate_agent_symbols(\n        executable, this_agent(),\n        [](hsa_executable_t, hsa_agent_t, hsa_executable_symbol_t x, void* s) {\n            auto p = static_cast<pair<const char*, hsa_executable_symbol_t>*>(s);\n\n            if (type(x) != HSA_SYMBOL_KIND_KERNEL) {\n                return HSA_STATUS_SUCCESS;\n            }\n            if (name(x) != p->first) return HSA_STATUS_SUCCESS;\n\n            p->second = x;\n\n            return HSA_STATUS_INFO_BREAK;\n        },\n        &r);\n\n    return r.second;\n}\n\nstring read_elf_file_as_string(\n    const void* file) {  // Precondition: file points to an ELF image that was BITWISE loaded\n    //               into process accessible memory, and not one loaded by\n    //               the loader. This is because in the latter case\n    //               alignment may differ, which will break the size\n    //               computation.\n    //               the image is Elf64, and matches endianness i.e. it is\n    //               Little Endian.\n    if (!file) return {};\n\n    auto h = static_cast<const Elf64_Ehdr*>(file);\n    auto s = static_cast<const char*>(file);\n    // This assumes the common case of SHT being the last part of the ELF.\n    auto sz = sizeof(Elf64_Ehdr) + h->e_shoff + h->e_shentsize * h->e_shnum;\n\n    return string{s, s + sz};\n}\n\nstring code_object_blob_for_agent(const void* maybe_bundled_code, hsa_agent_t agent) {\n    if (!maybe_bundled_code) return {};\n\n    Bundled_code_header tmp{maybe_bundled_code};\n\n    if (!valid(tmp)) return {};\n\n    const auto agent_isa = isa(agent);\n\n    const auto it = find_if(bundles(tmp).cbegin(), bundles(tmp).cend(), [=](const Bundled_code& x) {\n        return agent_isa == triple_to_hsa_isa(x.triple);\n        ;\n    });\n\n    if (it == bundles(tmp).cend()) return {};\n\n    return string{it->blob.cbegin(), it->blob.cend()};\n}\n}  // namespace\n\nhipError_t ihipModuleGetFunction(hipFunction_t* func, hipModule_t hmod, const char* name) {\n\n    if (!func || !name) return hipErrorInvalidValue;\n\n    auto ctx = ihipGetTlsDefaultCtx();\n\n    if (!ctx) return hipErrorInvalidContext;\n\n    *func = new ihipModuleSymbol_t;\n\n    if (!*func) return hipErrorInvalidValue;\n\n    auto kernel = find_kernel_by_name(hmod->executable, name);\n\n    if (kernel.handle == 0u) return hipErrorNotFound;\n\n    // TODO: refactor the whole ihipThisThat, which is a mess and yields the\n    //       below, due to hipFunction_t being a pointer to ihipModuleSymbol_t.\n    func[0][0] = *static_cast<hipFunction_t>(\n        Kernel_descriptor{kernel_object(kernel), name});\n\n    return hipSuccess;\n}\n\nhipError_t hipModuleGetFunction(hipFunction_t* hfunc, hipModule_t hmod, const char* name) {\n    HIP_INIT_API(hipModuleGetFunction, hfunc, hmod, name);\n    return ihipLogStatus(ihipModuleGetFunction(hfunc, hmod, name));\n}\n\nhipError_t hipModuleGetGlobal(hipDeviceptr_t* dptr, size_t* bytes, hipModule_t hmod,\n                              const char* name) {\n    HIP_INIT_API(hipModuleGetGlobal, dptr, bytes, hmod, name);\n\n    return ihipLogStatus(ihipModuleGetGlobal(dptr, bytes, hmod, name));\n}\n\nhipError_t ihipModuleGetGlobal(hipDeviceptr_t* dptr, size_t* bytes, hipModule_t hmod,\n                               const char* name) {\n    if (!dptr || !bytes) return hipErrorInvalidValue;\n\n    if (!name) return hipErrorNotInitialized;\n\n    const auto r = hmod ? read_agent_global_from_module(dptr, bytes, hmod, name)\n                        : read_agent_global_from_process(dptr, bytes, name);\n\n    return r;\n}\n\nnamespace\n{\n    inline\n    hipFuncAttributes make_function_attributes(const amd_kernel_code_t& header)\n    {\n        hipFuncAttributes r{};\n\n        hipDeviceProp_t prop{};\n        hipGetDeviceProperties(\n            &prop, ihipGetTlsDefaultCtx()->getDevice()->_deviceId);\n        // TODO: at the moment there is no way to query the count of registers\n        //       available per CU, therefore we hardcode it to 64 KiRegisters.\n        prop.regsPerBlock = prop.regsPerBlock ? prop.regsPerBlock : 64 * 1024;\n        \n        r.localSizeBytes = header.workitem_private_segment_byte_size;\n        r.sharedSizeBytes = header.workgroup_group_segment_byte_size;\n        r.maxDynamicSharedSizeBytes =\n            prop.sharedMemPerBlock - r.sharedSizeBytes;\n        r.numRegs = header.workitem_vgpr_count;\n        r.maxThreadsPerBlock = r.numRegs ?\n            std::min(prop.maxThreadsPerBlock, prop.regsPerBlock / r.numRegs) :\n            prop.maxThreadsPerBlock;\n        r.binaryVersion =\n            header.amd_machine_version_major * 10 +\n            header.amd_machine_version_minor;\n        r.ptxVersion = prop.major * 10 + prop.minor; // HIP currently presents itself as PTX 3.0.\n\n        return r;\n    }\n}\n\nhipError_t hipFuncGetAttributes(hipFuncAttributes* attr, const void* func)\n{\n    if (!attr) return hipErrorInvalidValue;\n    if (!func) return hipErrorInvalidDeviceFunction;\n\n    const auto it0 = functions().find(reinterpret_cast<uintptr_t>(func));\n\n    if (it0 == functions().cend()) return hipErrorInvalidDeviceFunction;\n\n    auto agent = this_agent();\n    const auto it1 = find_if(\n        it0->second.cbegin(),\n        it0->second.cend(),\n        [=](const pair<hsa_agent_t, Kernel_descriptor>& x) {\n        return x.first == agent;\n    });\n\n    if (it1 == it0->second.cend()) return hipErrorInvalidDeviceFunction;\n\n    const auto header = static_cast<hipFunction_t>(it1->second)->_header;\n\n    if (!header) throw runtime_error{\"Ill-formed Kernel_descriptor.\"};\n\n    *attr = make_function_attributes(*header);\n\n    return hipSuccess;\n}\n\nhipError_t ihipModuleLoadData(hipModule_t* module, const void* image) {\n\n    if (!module) return hipErrorInvalidValue;\n\n    *module = new ihipModule_t;\n\n    auto ctx = ihipGetTlsDefaultCtx();\n    if (!ctx) return hipErrorInvalidContext;\n\n    hsa_executable_create_alt(HSA_PROFILE_FULL, HSA_DEFAULT_FLOAT_ROUNDING_MODE_DEFAULT, nullptr,\n                              &(*module)->executable);\n\n    auto tmp = code_object_blob_for_agent(image, this_agent());\n\n    (*module)->executable = hip_impl::load_executable(\n        tmp.empty() ? read_elf_file_as_string(image) : tmp, (*module)->executable, this_agent());\n\n    return (*module)->executable.handle ? hipSuccess : hipErrorUnknown;\n}\n\nhipError_t hipModuleLoadData(hipModule_t* module, const void* image) {\n    HIP_INIT_API(hipModuleLoadData, module, image);\n    return ihipLogStatus(ihipModuleLoadData(module,image));\n}\n\nhipError_t hipModuleLoad(hipModule_t* module, const char* fname) {\n    HIP_INIT_API(hipModuleLoad, module, fname);\n\n    if (!fname) return ihipLogStatus(hipErrorInvalidValue);\n\n    ifstream file{fname};\n\n    if (!file.is_open()) return ihipLogStatus(hipErrorFileNotFound);\n\n    vector<char> tmp{istreambuf_iterator<char>{file}, istreambuf_iterator<char>{}};\n\n    return ihipLogStatus(ihipModuleLoadData(module, tmp.data()));\n}\n\nhipError_t hipModuleLoadDataEx(hipModule_t* module, const void* image, unsigned int numOptions,\n                               hipJitOption* options, void** optionValues) {\n    HIP_INIT_API(hipModuleLoadDataEx, module, image, numOptions, options, optionValues);\n    return ihipLogStatus(ihipModuleLoadData(module, image));\n}\n\nhipError_t hipModuleGetTexRef(textureReference** texRef, hipModule_t hmod, const char* name) {\n    HIP_INIT_API(hipModuleGetTexRef, texRef, hmod, name);\n\n    hipError_t ret = hipErrorNotFound;\n    if (!texRef) return ihipLogStatus(hipErrorInvalidValue);\n\n    if (!hmod || !name) return ihipLogStatus(hipErrorNotInitialized);\n\n    const auto it = globals().find(name);\n    if (it == globals().end()) return ihipLogStatus(hipErrorInvalidValue);\n\n    *texRef = reinterpret_cast<textureReference*>(it->second);\n    return ihipLogStatus(hipSuccess);\n}\n", "idx": 1, "id": 7225, "msg": "", "proj": "ROCm-Developer-Tools-HIP", "lang": "cpp"}
{"patch": "@@ -3366,6 +3366,7 @@ var pkgAST = &ast.Package{\n \t\t\t\t\t\t\t\tValue: \"_measurement\",\n \t\t\t\t\t\t\t},\n \t\t\t\t\t\t}},\n+\t\t\t\t\t\tWith: nil,\n \t\t\t\t\t}},\n \t\t\t\t\tBaseNode: ast.BaseNode{\n \t\t\t\t\t\tErrors: nil,", "y": 0, "oldf": "// DO NOT EDIT: This file is autogenerated via the builtin command.\n\npackage v1\n\nimport (\n\tflux \"github.com/influxdata/flux\"\n\tast \"github.com/influxdata/flux/ast\"\n)\n\nfunc init() {\n\tflux.RegisterPackage(pkgAST)\n}\n\nvar pkgAST = &ast.Package{\n\tBaseNode: ast.BaseNode{\n\t\tErrors: nil,\n\t\tLoc:    nil,\n\t},\n\tFiles: []*ast.File{&ast.File{\n\t\tBaseNode: ast.BaseNode{\n\t\t\tErrors: nil,\n\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\tEnd: ast.Position{\n\t\t\t\t\tColumn: 51,\n\t\t\t\t\tLine:   45,\n\t\t\t\t},\n\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\tSource: \"package v1\\n\\n// Json parses an InfluxDB 1.x json result into a table stream.\\nbuiltin json\\n\\n// Databases returns the list of available databases, it has no parameters.\\nbuiltin databases\\n\\n// fieldsAsCols is a special application of pivot that will automatically align fields within each measurement that have the same timestamp.\\nfieldsAsCols = (tables=<-) =>\\n    tables\\n        |> pivot(rowKey:[\\\"_time\\\"], columnKey: [\\\"_field\\\"], valueColumn: \\\"_value\\\")\\n\\n// TagValues returns the unique values for a given tag.\\n// The return value is always a single table with a single column \\\"_value\\\".\\ntagValues = (bucket, tag, predicate=(r) => true, start=-30d) =>\\n    from(bucket: bucket)\\n      |> range(start: start)\\n      |> filter(fn: predicate)\\n      |> keep(columns: [tag])\\n      |> group()\\n      |> distinct(column: tag)\\n\\n// MeasurementTagValues returns a single table with a single column \\\"_value\\\" that contains the\\n// The return value is always a single table with a single column \\\"_value\\\".\\nmeasurementTagValues = (bucket, measurement, tag) =>\\n    tagValues(bucket: bucket, tag: tag, predicate: (r) => r._measurement == measurement)\\n\\n// TagKeys returns the list of tag keys for all series that match the predicate.\\n// The return value is always a single table with a single column \\\"_value\\\".\\ntagKeys = (bucket, predicate=(r) => true, start=-30d) =>\\n    from(bucket: bucket)\\n        |> range(start: start)\\n        |> filter(fn: predicate)\\n        |> keys()\\n        |> keep(columns: [\\\"_value\\\"])\\n        |> distinct()\\n\\n// MeasurementTagKeys returns the list of tag keys for a specific measurement.\\nmeasurementTagKeys = (bucket, measurement) =>\\n    tagKeys(bucket: bucket, predicate: (r) => r._measurement == measurement)\\n\\n// Measurements returns the list of measurements in a specific bucket.\\nmeasurements = (bucket) =>\\n    tagValues(bucket: bucket, tag: \\\"_measurement\\\")\",\n\t\t\t\tStart: ast.Position{\n\t\t\t\t\tColumn: 1,\n\t\t\t\t\tLine:   1,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tBody: []ast.Statement{&ast.BuiltinStatement{\n\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\tErrors: nil,\n\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\tColumn: 13,\n\t\t\t\t\t\tLine:   4,\n\t\t\t\t\t},\n\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\tSource: \"builtin json\",\n\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\tColumn: 1,\n\t\t\t\t\t\tLine:   4,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tID: &ast.Identifier{\n\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\tErrors: nil,\n\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\tColumn: 13,\n\t\t\t\t\t\t\tLine:   4,\n\t\t\t\t\t\t},\n\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\tSource: \"json\",\n\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\tColumn: 9,\n\t\t\t\t\t\t\tLine:   4,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tName: \"json\",\n\t\t\t},\n\t\t}, &ast.BuiltinStatement{\n\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\tErrors: nil,\n\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\tColumn: 18,\n\t\t\t\t\t\tLine:   7,\n\t\t\t\t\t},\n\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\tSource: \"builtin databases\",\n\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\tColumn: 1,\n\t\t\t\t\t\tLine:   7,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tID: &ast.Identifier{\n\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\tErrors: nil,\n\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\tColumn: 18,\n\t\t\t\t\t\t\tLine:   7,\n\t\t\t\t\t\t},\n\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\tSource: \"databases\",\n\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\tColumn: 9,\n\t\t\t\t\t\t\tLine:   7,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tName: \"databases\",\n\t\t\t},\n\t\t}, &ast.VariableAssignment{\n\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\tErrors: nil,\n\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\tColumn: 81,\n\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t},\n\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\tSource: \"fieldsAsCols = (tables=<-) =>\\n    tables\\n        |> pivot(rowKey:[\\\"_time\\\"], columnKey: [\\\"_field\\\"], valueColumn: \\\"_value\\\")\",\n\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\tColumn: 1,\n\t\t\t\t\t\tLine:   10,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tID: &ast.Identifier{\n\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\tErrors: nil,\n\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\tColumn: 13,\n\t\t\t\t\t\t\tLine:   10,\n\t\t\t\t\t\t},\n\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\tSource: \"fieldsAsCols\",\n\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\tColumn: 1,\n\t\t\t\t\t\t\tLine:   10,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tName: \"fieldsAsCols\",\n\t\t\t},\n\t\t\tInit: &ast.FunctionExpression{\n\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\tErrors: nil,\n\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\tColumn: 81,\n\t\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t\t},\n\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\tSource: \"(tables=<-) =>\\n    tables\\n        |> pivot(rowKey:[\\\"_time\\\"], columnKey: [\\\"_field\\\"], valueColumn: \\\"_value\\\")\",\n\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\tColumn: 16,\n\t\t\t\t\t\t\tLine:   10,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tBody: &ast.PipeExpression{\n\t\t\t\t\tArgument: &ast.Identifier{\n\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 11,\n\t\t\t\t\t\t\t\t\tLine:   11,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\tSource: \"tables\",\n\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t\t\t\t\tLine:   11,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tName: \"tables\",\n\t\t\t\t\t},\n\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 81,\n\t\t\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\tSource: \"tables\\n        |> pivot(rowKey:[\\\"_time\\\"], columnKey: [\\\"_field\\\"], valueColumn: \\\"_value\\\")\",\n\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t\t\t\tLine:   11,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tCall: &ast.CallExpression{\n\t\t\t\t\t\tArguments: []ast.Expression{&ast.ObjectExpression{\n\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 80,\n\t\t\t\t\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\tSource: \"rowKey:[\\\"_time\\\"], columnKey: [\\\"_field\\\"], valueColumn: \\\"_value\\\"\",\n\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 18,\n\t\t\t\t\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tProperties: []*ast.Property{&ast.Property{\n\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 34,\n\t\t\t\t\t\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\tSource: \"rowKey:[\\\"_time\\\"]\",\n\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 18,\n\t\t\t\t\t\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 24,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\tSource: \"rowKey\",\n\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 18,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tName: \"rowKey\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tValue: &ast.ArrayExpression{\n\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 34,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\tSource: \"[\\\"_time\\\"]\",\n\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 25,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tElements: []ast.Expression{&ast.StringLiteral{\n\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 33,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\tSource: \"\\\"_time\\\"\",\n\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 26,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tValue: \"_time\",\n\t\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t}, &ast.Property{\n\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 57,\n\t\t\t\t\t\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\tSource: \"columnKey: [\\\"_field\\\"]\",\n\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 36,\n\t\t\t\t\t\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 45,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\tSource: \"columnKey\",\n\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 36,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tName: \"columnKey\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tValue: &ast.ArrayExpression{\n\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 57,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\tSource: \"[\\\"_field\\\"]\",\n\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 47,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tElements: []ast.Expression{&ast.StringLiteral{\n\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 56,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\tSource: \"\\\"_field\\\"\",\n\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 48,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tValue: \"_field\",\n\t\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t}, &ast.Property{\n\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 80,\n\t\t\t\t\t\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\tSource: \"valueColumn: \\\"_value\\\"\",\n\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 59,\n\t\t\t\t\t\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 70,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\tSource: \"valueColumn\",\n\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 59,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tName: \"valueColumn\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tValue: &ast.StringLiteral{\n\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 80,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\tSource: \"\\\"_value\\\"\",\n\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 72,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tValue: \"_value\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t}},\n\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 81,\n\t\t\t\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\tSource: \"pivot(rowKey:[\\\"_time\\\"], columnKey: [\\\"_field\\\"], valueColumn: \\\"_value\\\")\",\n\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 12,\n\t\t\t\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tCallee: &ast.Identifier{\n\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 17,\n\t\t\t\t\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\tSource: \"pivot\",\n\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 12,\n\t\t\t\t\t\t\t\t\t\tLine:   12,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tName: \"pivot\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tParams: []*ast.Property{&ast.Property{\n\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 26,\n\t\t\t\t\t\t\t\tLine:   10,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\tSource: \"tables=<-\",\n\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 17,\n\t\t\t\t\t\t\t\tLine:   10,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 23,\n\t\t\t\t\t\t\t\t\tLine:   10,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\tSource: \"tables\",\n\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 17,\n\t\t\t\t\t\t\t\t\tLine:   10,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tName: \"tables\",\n\t\t\t\t\t},\n\t\t\t\t\tValue: &ast.PipeLiteral{BaseNode: ast.BaseNode{\n\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 26,\n\t\t\t\t\t\t\t\tLine:   10,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\tSource: \"<-\",\n\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 24,\n\t\t\t\t\t\t\t\tLine:   10,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t}},\n\t\t\t\t}},\n\t\t\t},\n\t\t}, &ast.VariableAssignment{\n\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\tErrors: nil,\n\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\tColumn: 31,\n\t\t\t\t\t\tLine:   22,\n\t\t\t\t\t},\n\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\tSource: \"tagValues = (bucket, tag, predicate=(r) => true, start=-30d) =>\\n    from(bucket: bucket)\\n      |> range(start: start)\\n      |> filter(fn: predicate)\\n      |> keep(columns: [tag])\\n      |> group()\\n      |> distinct(column: tag)\",\n\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\tColumn: 1,\n\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tID: &ast.Identifier{\n\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\tErrors: nil,\n\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\tColumn: 10,\n\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t},\n\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\tSource: \"tagValues\",\n\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\tColumn: 1,\n\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tName: \"tagValues\",\n\t\t\t},\n\t\t\tInit: &ast.FunctionExpression{\n\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\tErrors: nil,\n\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\tColumn: 31,\n\t\t\t\t\t\t\tLine:   22,\n\t\t\t\t\t\t},\n\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\tSource: \"(bucket, tag, predicate=(r) => true, start=-30d) =>\\n    from(bucket: bucket)\\n      |> range(start: start)\\n      |> filter(fn: predicate)\\n      |> keep(columns: [tag])\\n      |> group()\\n      |> distinct(column: tag)\",\n\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\tColumn: 13,\n\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tBody: &ast.PipeExpression{\n\t\t\t\t\tArgument: &ast.PipeExpression{\n\t\t\t\t\t\tArgument: &ast.PipeExpression{\n\t\t\t\t\t\t\tArgument: &ast.PipeExpression{\n\t\t\t\t\t\t\t\tArgument: &ast.PipeExpression{\n\t\t\t\t\t\t\t\t\tArgument: &ast.CallExpression{\n\t\t\t\t\t\t\t\t\t\tArguments: []ast.Expression{&ast.ObjectExpression{\n\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 24,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   17,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"bucket: bucket\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 10,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   17,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tProperties: []*ast.Property{&ast.Property{\n\t\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 24,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   17,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"bucket: bucket\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 10,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   17,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 16,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   17,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"bucket\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 10,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   17,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\tName: \"bucket\",\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tValue: &ast.Identifier{\n\t\t\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 24,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   17,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"bucket\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 18,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   17,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\tName: \"bucket\",\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 25,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   17,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\tSource: \"from(bucket: bucket)\",\n\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   17,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tCallee: &ast.Identifier{\n\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 9,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   17,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"from\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   17,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tName: \"from\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 29,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   18,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\tSource: \"from(bucket: bucket)\\n      |> range(start: start)\",\n\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   17,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tCall: &ast.CallExpression{\n\t\t\t\t\t\t\t\t\t\tArguments: []ast.Expression{&ast.ObjectExpression{\n\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 28,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   18,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"start: start\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 16,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   18,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tProperties: []*ast.Property{&ast.Property{\n\t\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 28,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   18,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"start: start\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 16,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   18,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 21,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   18,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"start\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 16,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   18,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\tName: \"start\",\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tValue: &ast.Identifier{\n\t\t\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 28,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   18,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"start\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 23,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   18,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\tName: \"start\",\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 29,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   18,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\tSource: \"range(start: start)\",\n\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 10,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   18,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tCallee: &ast.Identifier{\n\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 15,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   18,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"range\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 10,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   18,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tName: \"range\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 31,\n\t\t\t\t\t\t\t\t\t\t\tLine:   19,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\tSource: \"from(bucket: bucket)\\n      |> range(start: start)\\n      |> filter(fn: predicate)\",\n\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t\t\t\t\t\t\tLine:   17,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tCall: &ast.CallExpression{\n\t\t\t\t\t\t\t\t\tArguments: []ast.Expression{&ast.ObjectExpression{\n\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 30,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   19,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\tSource: \"fn: predicate\",\n\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 17,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   19,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tProperties: []*ast.Property{&ast.Property{\n\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 30,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   19,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"fn: predicate\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 17,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   19,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 19,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   19,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"fn\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 17,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   19,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tName: \"fn\",\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tValue: &ast.Identifier{\n\t\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 30,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   19,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"predicate\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 21,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   19,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tName: \"predicate\",\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 31,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   19,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\tSource: \"filter(fn: predicate)\",\n\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 10,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   19,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tCallee: &ast.Identifier{\n\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 16,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   19,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\tSource: \"filter\",\n\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 10,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   19,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tName: \"filter\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 30,\n\t\t\t\t\t\t\t\t\t\tLine:   20,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\tSource: \"from(bucket: bucket)\\n      |> range(start: start)\\n      |> filter(fn: predicate)\\n      |> keep(columns: [tag])\",\n\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t\t\t\t\t\tLine:   17,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tCall: &ast.CallExpression{\n\t\t\t\t\t\t\t\tArguments: []ast.Expression{&ast.ObjectExpression{\n\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 29,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   20,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\tSource: \"columns: [tag]\",\n\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 15,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   20,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tProperties: []*ast.Property{&ast.Property{\n\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 29,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   20,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\tSource: \"columns: [tag]\",\n\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 15,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   20,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 22,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   20,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"columns\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 15,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   20,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tName: \"columns\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tValue: &ast.ArrayExpression{\n\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 29,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   20,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"[tag]\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 24,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   20,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tElements: []ast.Expression{&ast.Identifier{\n\t\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 28,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   20,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"tag\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 25,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   20,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tName: \"tag\",\n\t\t\t\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 30,\n\t\t\t\t\t\t\t\t\t\t\tLine:   20,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\tSource: \"keep(columns: [tag])\",\n\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 10,\n\t\t\t\t\t\t\t\t\t\t\tLine:   20,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tCallee: &ast.Identifier{\n\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 14,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   20,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\tSource: \"keep\",\n\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 10,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   20,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tName: \"keep\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 17,\n\t\t\t\t\t\t\t\t\tLine:   21,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\tSource: \"from(bucket: bucket)\\n      |> range(start: start)\\n      |> filter(fn: predicate)\\n      |> keep(columns: [tag])\\n      |> group()\",\n\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t\t\t\t\tLine:   17,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tCall: &ast.CallExpression{\n\t\t\t\t\t\t\tArguments: nil,\n\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 17,\n\t\t\t\t\t\t\t\t\t\tLine:   21,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\tSource: \"group()\",\n\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 10,\n\t\t\t\t\t\t\t\t\t\tLine:   21,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tCallee: &ast.Identifier{\n\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 15,\n\t\t\t\t\t\t\t\t\t\t\tLine:   21,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\tSource: \"group\",\n\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 10,\n\t\t\t\t\t\t\t\t\t\t\tLine:   21,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tName: \"group\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 31,\n\t\t\t\t\t\t\t\tLine:   22,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\tSource: \"from(bucket: bucket)\\n      |> range(start: start)\\n      |> filter(fn: predicate)\\n      |> keep(columns: [tag])\\n      |> group()\\n      |> distinct(column: tag)\",\n\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t\t\t\tLine:   17,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tCall: &ast.CallExpression{\n\t\t\t\t\t\tArguments: []ast.Expression{&ast.ObjectExpression{\n\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 30,\n\t\t\t\t\t\t\t\t\t\tLine:   22,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\tSource: \"column: tag\",\n\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 19,\n\t\t\t\t\t\t\t\t\t\tLine:   22,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tProperties: []*ast.Property{&ast.Property{\n\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 30,\n\t\t\t\t\t\t\t\t\t\t\tLine:   22,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\tSource: \"column: tag\",\n\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 19,\n\t\t\t\t\t\t\t\t\t\t\tLine:   22,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 25,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   22,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\tSource: \"column\",\n\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 19,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   22,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tName: \"column\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tValue: &ast.Identifier{\n\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 30,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   22,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\tSource: \"tag\",\n\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 27,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   22,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tName: \"tag\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t}},\n\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 31,\n\t\t\t\t\t\t\t\t\tLine:   22,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\tSource: \"distinct(column: tag)\",\n\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 10,\n\t\t\t\t\t\t\t\t\tLine:   22,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tCallee: &ast.Identifier{\n\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 18,\n\t\t\t\t\t\t\t\t\t\tLine:   22,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\tSource: \"distinct\",\n\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 10,\n\t\t\t\t\t\t\t\t\t\tLine:   22,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tName: \"distinct\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tParams: []*ast.Property{&ast.Property{\n\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 20,\n\t\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\tSource: \"bucket\",\n\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 14,\n\t\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 20,\n\t\t\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\tSource: \"bucket\",\n\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 14,\n\t\t\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tName: \"bucket\",\n\t\t\t\t\t},\n\t\t\t\t\tValue: nil,\n\t\t\t\t}, &ast.Property{\n\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 25,\n\t\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\tSource: \"tag\",\n\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 22,\n\t\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 25,\n\t\t\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\tSource: \"tag\",\n\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 22,\n\t\t\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tName: \"tag\",\n\t\t\t\t\t},\n\t\t\t\t\tValue: nil,\n\t\t\t\t}, &ast.Property{\n\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 48,\n\t\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\tSource: \"predicate=(r) => true\",\n\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 27,\n\t\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 36,\n\t\t\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\tSource: \"predicate\",\n\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 27,\n\t\t\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tName: \"predicate\",\n\t\t\t\t\t},\n\t\t\t\t\tValue: &ast.FunctionExpression{\n\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 48,\n\t\t\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\tSource: \"(r) => true\",\n\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 37,\n\t\t\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tBody: &ast.Identifier{\n\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 48,\n\t\t\t\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\tSource: \"true\",\n\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 44,\n\t\t\t\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tName: \"true\",\n\t\t\t\t\t\t},\n\t\t\t\t\t\tParams: []*ast.Property{&ast.Property{\n\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 39,\n\t\t\t\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\tSource: \"r\",\n\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 38,\n\t\t\t\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 39,\n\t\t\t\t\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\tSource: \"r\",\n\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 38,\n\t\t\t\t\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tName: \"r\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tValue: nil,\n\t\t\t\t\t\t}},\n\t\t\t\t\t},\n\t\t\t\t}, &ast.Property{\n\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 60,\n\t\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\tSource: \"start=-30d\",\n\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 50,\n\t\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 55,\n\t\t\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\tSource: \"start\",\n\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 50,\n\t\t\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tName: \"start\",\n\t\t\t\t\t},\n\t\t\t\t\tValue: &ast.UnaryExpression{\n\t\t\t\t\t\tArgument: &ast.DurationLiteral{\n\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 60,\n\t\t\t\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\tSource: \"30d\",\n\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 57,\n\t\t\t\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tValues: []ast.Duration{ast.Duration{\n\t\t\t\t\t\t\t\tMagnitude: int64(30),\n\t\t\t\t\t\t\t\tUnit:      \"d\",\n\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 60,\n\t\t\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\tSource: \"-30d\",\n\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 56,\n\t\t\t\t\t\t\t\t\tLine:   16,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tOperator: 4,\n\t\t\t\t\t},\n\t\t\t\t}},\n\t\t\t},\n\t\t}, &ast.VariableAssignment{\n\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\tErrors: nil,\n\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\tColumn: 89,\n\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t},\n\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\tSource: \"measurementTagValues = (bucket, measurement, tag) =>\\n    tagValues(bucket: bucket, tag: tag, predicate: (r) => r._measurement == measurement)\",\n\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\tColumn: 1,\n\t\t\t\t\t\tLine:   26,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tID: &ast.Identifier{\n\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\tErrors: nil,\n\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\tColumn: 21,\n\t\t\t\t\t\t\tLine:   26,\n\t\t\t\t\t\t},\n\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\tSource: \"measurementTagValues\",\n\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\tColumn: 1,\n\t\t\t\t\t\t\tLine:   26,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tName: \"measurementTagValues\",\n\t\t\t},\n\t\t\tInit: &ast.FunctionExpression{\n\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\tErrors: nil,\n\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\tColumn: 89,\n\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t},\n\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\tSource: \"(bucket, measurement, tag) =>\\n    tagValues(bucket: bucket, tag: tag, predicate: (r) => r._measurement == measurement)\",\n\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\tColumn: 24,\n\t\t\t\t\t\t\tLine:   26,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tBody: &ast.CallExpression{\n\t\t\t\t\tArguments: []ast.Expression{&ast.ObjectExpression{\n\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 88,\n\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\tSource: \"bucket: bucket, tag: tag, predicate: (r) => r._measurement == measurement\",\n\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 15,\n\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tProperties: []*ast.Property{&ast.Property{\n\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 29,\n\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\tSource: \"bucket: bucket\",\n\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 15,\n\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 21,\n\t\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\tSource: \"bucket\",\n\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 15,\n\t\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tName: \"bucket\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tValue: &ast.Identifier{\n\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 29,\n\t\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\tSource: \"bucket\",\n\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 23,\n\t\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tName: \"bucket\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t}, &ast.Property{\n\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 39,\n\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\tSource: \"tag: tag\",\n\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 31,\n\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 34,\n\t\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\tSource: \"tag\",\n\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 31,\n\t\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tName: \"tag\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tValue: &ast.Identifier{\n\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 39,\n\t\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\tSource: \"tag\",\n\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 36,\n\t\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tName: \"tag\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t}, &ast.Property{\n\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 88,\n\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\tSource: \"predicate: (r) => r._measurement == measurement\",\n\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 41,\n\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 50,\n\t\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\tSource: \"predicate\",\n\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 41,\n\t\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tName: \"predicate\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tValue: &ast.FunctionExpression{\n\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 88,\n\t\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\tSource: \"(r) => r._measurement == measurement\",\n\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 52,\n\t\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tBody: &ast.BinaryExpression{\n\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 88,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\tSource: \"r._measurement == measurement\",\n\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 59,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tLeft: &ast.MemberExpression{\n\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 73,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\tSource: \"r._measurement\",\n\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 59,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tObject: &ast.Identifier{\n\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 60,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"r\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 59,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tName: \"r\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tProperty: &ast.Identifier{\n\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 73,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"_measurement\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 61,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tName: \"_measurement\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tOperator: 14,\n\t\t\t\t\t\t\t\t\tRight: &ast.Identifier{\n\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 88,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\tSource: \"measurement\",\n\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 77,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tName: \"measurement\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tParams: []*ast.Property{&ast.Property{\n\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 54,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\tSource: \"r\",\n\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 53,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 54,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\tSource: \"r\",\n\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 53,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tName: \"r\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tValue: nil,\n\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t}},\n\t\t\t\t\t}},\n\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 89,\n\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\tSource: \"tagValues(bucket: bucket, tag: tag, predicate: (r) => r._measurement == measurement)\",\n\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tCallee: &ast.Identifier{\n\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 14,\n\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\tSource: \"tagValues\",\n\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t\t\t\t\tLine:   27,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tName: \"tagValues\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tParams: []*ast.Property{&ast.Property{\n\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 31,\n\t\t\t\t\t\t\t\tLine:   26,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\tSource: \"bucket\",\n\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 25,\n\t\t\t\t\t\t\t\tLine:   26,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 31,\n\t\t\t\t\t\t\t\t\tLine:   26,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\tSource: \"bucket\",\n\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 25,\n\t\t\t\t\t\t\t\t\tLine:   26,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tName: \"bucket\",\n\t\t\t\t\t},\n\t\t\t\t\tValue: nil,\n\t\t\t\t}, &ast.Property{\n\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 44,\n\t\t\t\t\t\t\t\tLine:   26,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\tSource: \"measurement\",\n\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 33,\n\t\t\t\t\t\t\t\tLine:   26,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 44,\n\t\t\t\t\t\t\t\t\tLine:   26,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\tSource: \"measurement\",\n\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 33,\n\t\t\t\t\t\t\t\t\tLine:   26,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tName: \"measurement\",\n\t\t\t\t\t},\n\t\t\t\t\tValue: nil,\n\t\t\t\t}, &ast.Property{\n\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 49,\n\t\t\t\t\t\t\t\tLine:   26,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\tSource: \"tag\",\n\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 46,\n\t\t\t\t\t\t\t\tLine:   26,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 49,\n\t\t\t\t\t\t\t\t\tLine:   26,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\tSource: \"tag\",\n\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 46,\n\t\t\t\t\t\t\t\t\tLine:   26,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tName: \"tag\",\n\t\t\t\t\t},\n\t\t\t\t\tValue: nil,\n\t\t\t\t}},\n\t\t\t},\n\t\t}, &ast.VariableAssignment{\n\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\tErrors: nil,\n\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\tColumn: 22,\n\t\t\t\t\t\tLine:   37,\n\t\t\t\t\t},\n\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\tSource: \"tagKeys = (bucket, predicate=(r) => true, start=-30d) =>\\n    from(bucket: bucket)\\n        |> range(start: start)\\n        |> filter(fn: predicate)\\n        |> keys()\\n        |> keep(columns: [\\\"_value\\\"])\\n        |> distinct()\",\n\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\tColumn: 1,\n\t\t\t\t\t\tLine:   31,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tID: &ast.Identifier{\n\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\tErrors: nil,\n\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\tColumn: 8,\n\t\t\t\t\t\t\tLine:   31,\n\t\t\t\t\t\t},\n\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\tSource: \"tagKeys\",\n\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\tColumn: 1,\n\t\t\t\t\t\t\tLine:   31,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tName: \"tagKeys\",\n\t\t\t},\n\t\t\tInit: &ast.FunctionExpression{\n\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\tErrors: nil,\n\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\tColumn: 22,\n\t\t\t\t\t\t\tLine:   37,\n\t\t\t\t\t\t},\n\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\tSource: \"(bucket, predicate=(r) => true, start=-30d) =>\\n    from(bucket: bucket)\\n        |> range(start: start)\\n        |> filter(fn: predicate)\\n        |> keys()\\n        |> keep(columns: [\\\"_value\\\"])\\n        |> distinct()\",\n\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\tColumn: 11,\n\t\t\t\t\t\t\tLine:   31,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tBody: &ast.PipeExpression{\n\t\t\t\t\tArgument: &ast.PipeExpression{\n\t\t\t\t\t\tArgument: &ast.PipeExpression{\n\t\t\t\t\t\t\tArgument: &ast.PipeExpression{\n\t\t\t\t\t\t\t\tArgument: &ast.PipeExpression{\n\t\t\t\t\t\t\t\t\tArgument: &ast.CallExpression{\n\t\t\t\t\t\t\t\t\t\tArguments: []ast.Expression{&ast.ObjectExpression{\n\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 24,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   32,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"bucket: bucket\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 10,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   32,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tProperties: []*ast.Property{&ast.Property{\n\t\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 24,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   32,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"bucket: bucket\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 10,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   32,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 16,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   32,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"bucket\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 10,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   32,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\tName: \"bucket\",\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tValue: &ast.Identifier{\n\t\t\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 24,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   32,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"bucket\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 18,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   32,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\tName: \"bucket\",\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 25,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   32,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\tSource: \"from(bucket: bucket)\",\n\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   32,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tCallee: &ast.Identifier{\n\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 9,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   32,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"from\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   32,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tName: \"from\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 31,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   33,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\tSource: \"from(bucket: bucket)\\n        |> range(start: start)\",\n\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   32,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tCall: &ast.CallExpression{\n\t\t\t\t\t\t\t\t\t\tArguments: []ast.Expression{&ast.ObjectExpression{\n\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 30,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   33,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"start: start\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 18,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   33,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tProperties: []*ast.Property{&ast.Property{\n\t\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 30,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   33,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"start: start\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 18,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   33,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 23,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   33,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"start\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 18,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   33,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\tName: \"start\",\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tValue: &ast.Identifier{\n\t\t\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 30,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   33,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"start\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 25,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   33,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\tName: \"start\",\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 31,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   33,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\tSource: \"range(start: start)\",\n\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 12,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   33,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tCallee: &ast.Identifier{\n\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 17,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   33,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"range\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 12,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   33,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tName: \"range\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 33,\n\t\t\t\t\t\t\t\t\t\t\tLine:   34,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\tSource: \"from(bucket: bucket)\\n        |> range(start: start)\\n        |> filter(fn: predicate)\",\n\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t\t\t\t\t\t\tLine:   32,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tCall: &ast.CallExpression{\n\t\t\t\t\t\t\t\t\tArguments: []ast.Expression{&ast.ObjectExpression{\n\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 32,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   34,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\tSource: \"fn: predicate\",\n\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 19,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   34,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tProperties: []*ast.Property{&ast.Property{\n\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 32,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   34,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"fn: predicate\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 19,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   34,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 21,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   34,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"fn\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 19,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   34,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tName: \"fn\",\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tValue: &ast.Identifier{\n\t\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 32,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   34,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"predicate\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 23,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   34,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tName: \"predicate\",\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 33,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   34,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\tSource: \"filter(fn: predicate)\",\n\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 12,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   34,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tCallee: &ast.Identifier{\n\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 18,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   34,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\tSource: \"filter\",\n\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 12,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   34,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tName: \"filter\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 18,\n\t\t\t\t\t\t\t\t\t\tLine:   35,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\tSource: \"from(bucket: bucket)\\n        |> range(start: start)\\n        |> filter(fn: predicate)\\n        |> keys()\",\n\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t\t\t\t\t\tLine:   32,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tCall: &ast.CallExpression{\n\t\t\t\t\t\t\t\tArguments: nil,\n\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 18,\n\t\t\t\t\t\t\t\t\t\t\tLine:   35,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\tSource: \"keys()\",\n\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 12,\n\t\t\t\t\t\t\t\t\t\t\tLine:   35,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tCallee: &ast.Identifier{\n\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 16,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   35,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\tSource: \"keys\",\n\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 12,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   35,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tName: \"keys\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 37,\n\t\t\t\t\t\t\t\t\tLine:   36,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\tSource: \"from(bucket: bucket)\\n        |> range(start: start)\\n        |> filter(fn: predicate)\\n        |> keys()\\n        |> keep(columns: [\\\"_value\\\"])\",\n\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t\t\t\t\tLine:   32,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tCall: &ast.CallExpression{\n\t\t\t\t\t\t\tArguments: []ast.Expression{&ast.ObjectExpression{\n\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 36,\n\t\t\t\t\t\t\t\t\t\t\tLine:   36,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\tSource: \"columns: [\\\"_value\\\"]\",\n\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 17,\n\t\t\t\t\t\t\t\t\t\t\tLine:   36,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tProperties: []*ast.Property{&ast.Property{\n\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 36,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   36,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\tSource: \"columns: [\\\"_value\\\"]\",\n\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 17,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   36,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 24,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   36,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\tSource: \"columns\",\n\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 17,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   36,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tName: \"columns\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tValue: &ast.ArrayExpression{\n\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 36,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   36,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\tSource: \"[\\\"_value\\\"]\",\n\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 26,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   36,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tElements: []ast.Expression{&ast.StringLiteral{\n\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 35,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   36,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"\\\"_value\\\"\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 27,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   36,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tValue: \"_value\",\n\t\t\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 37,\n\t\t\t\t\t\t\t\t\t\tLine:   36,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\tSource: \"keep(columns: [\\\"_value\\\"])\",\n\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 12,\n\t\t\t\t\t\t\t\t\t\tLine:   36,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tCallee: &ast.Identifier{\n\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 16,\n\t\t\t\t\t\t\t\t\t\t\tLine:   36,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\tSource: \"keep\",\n\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 12,\n\t\t\t\t\t\t\t\t\t\t\tLine:   36,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tName: \"keep\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 22,\n\t\t\t\t\t\t\t\tLine:   37,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\tSource: \"from(bucket: bucket)\\n        |> range(start: start)\\n        |> filter(fn: predicate)\\n        |> keys()\\n        |> keep(columns: [\\\"_value\\\"])\\n        |> distinct()\",\n\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t\t\t\tLine:   32,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tCall: &ast.CallExpression{\n\t\t\t\t\t\tArguments: nil,\n\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 22,\n\t\t\t\t\t\t\t\t\tLine:   37,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\tSource: \"distinct()\",\n\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 12,\n\t\t\t\t\t\t\t\t\tLine:   37,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tCallee: &ast.Identifier{\n\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 20,\n\t\t\t\t\t\t\t\t\t\tLine:   37,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\tSource: \"distinct\",\n\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 12,\n\t\t\t\t\t\t\t\t\t\tLine:   37,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tName: \"distinct\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tParams: []*ast.Property{&ast.Property{\n\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 18,\n\t\t\t\t\t\t\t\tLine:   31,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\tSource: \"bucket\",\n\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 12,\n\t\t\t\t\t\t\t\tLine:   31,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 18,\n\t\t\t\t\t\t\t\t\tLine:   31,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\tSource: \"bucket\",\n\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 12,\n\t\t\t\t\t\t\t\t\tLine:   31,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tName: \"bucket\",\n\t\t\t\t\t},\n\t\t\t\t\tValue: nil,\n\t\t\t\t}, &ast.Property{\n\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 41,\n\t\t\t\t\t\t\t\tLine:   31,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\tSource: \"predicate=(r) => true\",\n\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 20,\n\t\t\t\t\t\t\t\tLine:   31,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 29,\n\t\t\t\t\t\t\t\t\tLine:   31,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\tSource: \"predicate\",\n\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 20,\n\t\t\t\t\t\t\t\t\tLine:   31,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tName: \"predicate\",\n\t\t\t\t\t},\n\t\t\t\t\tValue: &ast.FunctionExpression{\n\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 41,\n\t\t\t\t\t\t\t\t\tLine:   31,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\tSource: \"(r) => true\",\n\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 30,\n\t\t\t\t\t\t\t\t\tLine:   31,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tBody: &ast.Identifier{\n\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 41,\n\t\t\t\t\t\t\t\t\t\tLine:   31,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\tSource: \"true\",\n\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 37,\n\t\t\t\t\t\t\t\t\t\tLine:   31,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tName: \"true\",\n\t\t\t\t\t\t},\n\t\t\t\t\t\tParams: []*ast.Property{&ast.Property{\n\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 32,\n\t\t\t\t\t\t\t\t\t\tLine:   31,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\tSource: \"r\",\n\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 31,\n\t\t\t\t\t\t\t\t\t\tLine:   31,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 32,\n\t\t\t\t\t\t\t\t\t\t\tLine:   31,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\tSource: \"r\",\n\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 31,\n\t\t\t\t\t\t\t\t\t\t\tLine:   31,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tName: \"r\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tValue: nil,\n\t\t\t\t\t\t}},\n\t\t\t\t\t},\n\t\t\t\t}, &ast.Property{\n\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 53,\n\t\t\t\t\t\t\t\tLine:   31,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\tSource: \"start=-30d\",\n\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 43,\n\t\t\t\t\t\t\t\tLine:   31,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 48,\n\t\t\t\t\t\t\t\t\tLine:   31,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\tSource: \"start\",\n\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 43,\n\t\t\t\t\t\t\t\t\tLine:   31,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tName: \"start\",\n\t\t\t\t\t},\n\t\t\t\t\tValue: &ast.UnaryExpression{\n\t\t\t\t\t\tArgument: &ast.DurationLiteral{\n\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 53,\n\t\t\t\t\t\t\t\t\t\tLine:   31,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\tSource: \"30d\",\n\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 50,\n\t\t\t\t\t\t\t\t\t\tLine:   31,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tValues: []ast.Duration{ast.Duration{\n\t\t\t\t\t\t\t\tMagnitude: int64(30),\n\t\t\t\t\t\t\t\tUnit:      \"d\",\n\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 53,\n\t\t\t\t\t\t\t\t\tLine:   31,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\tSource: \"-30d\",\n\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 49,\n\t\t\t\t\t\t\t\t\tLine:   31,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tOperator: 4,\n\t\t\t\t\t},\n\t\t\t\t}},\n\t\t\t},\n\t\t}, &ast.VariableAssignment{\n\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\tErrors: nil,\n\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\tColumn: 77,\n\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t},\n\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\tSource: \"measurementTagKeys = (bucket, measurement) =>\\n    tagKeys(bucket: bucket, predicate: (r) => r._measurement == measurement)\",\n\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\tColumn: 1,\n\t\t\t\t\t\tLine:   40,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tID: &ast.Identifier{\n\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\tErrors: nil,\n\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\tColumn: 19,\n\t\t\t\t\t\t\tLine:   40,\n\t\t\t\t\t\t},\n\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\tSource: \"measurementTagKeys\",\n\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\tColumn: 1,\n\t\t\t\t\t\t\tLine:   40,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tName: \"measurementTagKeys\",\n\t\t\t},\n\t\t\tInit: &ast.FunctionExpression{\n\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\tErrors: nil,\n\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\tColumn: 77,\n\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t},\n\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\tSource: \"(bucket, measurement) =>\\n    tagKeys(bucket: bucket, predicate: (r) => r._measurement == measurement)\",\n\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\tColumn: 22,\n\t\t\t\t\t\t\tLine:   40,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tBody: &ast.CallExpression{\n\t\t\t\t\tArguments: []ast.Expression{&ast.ObjectExpression{\n\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 76,\n\t\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\tSource: \"bucket: bucket, predicate: (r) => r._measurement == measurement\",\n\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 13,\n\t\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tProperties: []*ast.Property{&ast.Property{\n\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 27,\n\t\t\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\tSource: \"bucket: bucket\",\n\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 13,\n\t\t\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 19,\n\t\t\t\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\tSource: \"bucket\",\n\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 13,\n\t\t\t\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tName: \"bucket\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tValue: &ast.Identifier{\n\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 27,\n\t\t\t\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\tSource: \"bucket\",\n\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 21,\n\t\t\t\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tName: \"bucket\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t}, &ast.Property{\n\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 76,\n\t\t\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\tSource: \"predicate: (r) => r._measurement == measurement\",\n\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 29,\n\t\t\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 38,\n\t\t\t\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\tSource: \"predicate\",\n\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 29,\n\t\t\t\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tName: \"predicate\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tValue: &ast.FunctionExpression{\n\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 76,\n\t\t\t\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\tSource: \"(r) => r._measurement == measurement\",\n\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 40,\n\t\t\t\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tBody: &ast.BinaryExpression{\n\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 76,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\tSource: \"r._measurement == measurement\",\n\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 47,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tLeft: &ast.MemberExpression{\n\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 61,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\tSource: \"r._measurement\",\n\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 47,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tObject: &ast.Identifier{\n\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 48,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"r\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 47,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tName: \"r\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tProperty: &ast.Identifier{\n\t\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 61,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tSource: \"_measurement\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 49,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tName: \"_measurement\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tOperator: 14,\n\t\t\t\t\t\t\t\t\tRight: &ast.Identifier{\n\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 76,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\tSource: \"measurement\",\n\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 65,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tName: \"measurement\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tParams: []*ast.Property{&ast.Property{\n\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 42,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\tSource: \"r\",\n\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\tColumn: 41,\n\t\t\t\t\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 42,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\t\t\tSource: \"r\",\n\t\t\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\t\t\tColumn: 41,\n\t\t\t\t\t\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tName: \"r\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tValue: nil,\n\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t}},\n\t\t\t\t\t}},\n\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 77,\n\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\tSource: \"tagKeys(bucket: bucket, predicate: (r) => r._measurement == measurement)\",\n\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tCallee: &ast.Identifier{\n\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 12,\n\t\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\tSource: \"tagKeys\",\n\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t\t\t\t\tLine:   41,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tName: \"tagKeys\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tParams: []*ast.Property{&ast.Property{\n\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 29,\n\t\t\t\t\t\t\t\tLine:   40,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\tSource: \"bucket\",\n\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 23,\n\t\t\t\t\t\t\t\tLine:   40,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 29,\n\t\t\t\t\t\t\t\t\tLine:   40,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\tSource: \"bucket\",\n\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 23,\n\t\t\t\t\t\t\t\t\tLine:   40,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tName: \"bucket\",\n\t\t\t\t\t},\n\t\t\t\t\tValue: nil,\n\t\t\t\t}, &ast.Property{\n\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 42,\n\t\t\t\t\t\t\t\tLine:   40,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\tSource: \"measurement\",\n\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 31,\n\t\t\t\t\t\t\t\tLine:   40,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 42,\n\t\t\t\t\t\t\t\t\tLine:   40,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\tSource: \"measurement\",\n\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 31,\n\t\t\t\t\t\t\t\t\tLine:   40,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tName: \"measurement\",\n\t\t\t\t\t},\n\t\t\t\t\tValue: nil,\n\t\t\t\t}},\n\t\t\t},\n\t\t}, &ast.VariableAssignment{\n\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\tErrors: nil,\n\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\tColumn: 51,\n\t\t\t\t\t\tLine:   45,\n\t\t\t\t\t},\n\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\tSource: \"measurements = (bucket) =>\\n    tagValues(bucket: bucket, tag: \\\"_measurement\\\")\",\n\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\tColumn: 1,\n\t\t\t\t\t\tLine:   44,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tID: &ast.Identifier{\n\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\tErrors: nil,\n\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\tColumn: 13,\n\t\t\t\t\t\t\tLine:   44,\n\t\t\t\t\t\t},\n\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\tSource: \"measurements\",\n\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\tColumn: 1,\n\t\t\t\t\t\t\tLine:   44,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tName: \"measurements\",\n\t\t\t},\n\t\t\tInit: &ast.FunctionExpression{\n\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\tErrors: nil,\n\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\tColumn: 51,\n\t\t\t\t\t\t\tLine:   45,\n\t\t\t\t\t\t},\n\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\tSource: \"(bucket) =>\\n    tagValues(bucket: bucket, tag: \\\"_measurement\\\")\",\n\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\tColumn: 16,\n\t\t\t\t\t\t\tLine:   44,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tBody: &ast.CallExpression{\n\t\t\t\t\tArguments: []ast.Expression{&ast.ObjectExpression{\n\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 50,\n\t\t\t\t\t\t\t\t\tLine:   45,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\tSource: \"bucket: bucket, tag: \\\"_measurement\\\"\",\n\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 15,\n\t\t\t\t\t\t\t\t\tLine:   45,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tProperties: []*ast.Property{&ast.Property{\n\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 29,\n\t\t\t\t\t\t\t\t\t\tLine:   45,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\tSource: \"bucket: bucket\",\n\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 15,\n\t\t\t\t\t\t\t\t\t\tLine:   45,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 21,\n\t\t\t\t\t\t\t\t\t\t\tLine:   45,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\tSource: \"bucket\",\n\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 15,\n\t\t\t\t\t\t\t\t\t\t\tLine:   45,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tName: \"bucket\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tValue: &ast.Identifier{\n\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 29,\n\t\t\t\t\t\t\t\t\t\t\tLine:   45,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\tSource: \"bucket\",\n\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 23,\n\t\t\t\t\t\t\t\t\t\t\tLine:   45,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tName: \"bucket\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t}, &ast.Property{\n\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 50,\n\t\t\t\t\t\t\t\t\t\tLine:   45,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\tSource: \"tag: \\\"_measurement\\\"\",\n\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\tColumn: 31,\n\t\t\t\t\t\t\t\t\t\tLine:   45,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 34,\n\t\t\t\t\t\t\t\t\t\t\tLine:   45,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\tSource: \"tag\",\n\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 31,\n\t\t\t\t\t\t\t\t\t\t\tLine:   45,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tName: \"tag\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tValue: &ast.StringLiteral{\n\t\t\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 50,\n\t\t\t\t\t\t\t\t\t\t\tLine:   45,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\t\t\tSource: \"\\\"_measurement\\\"\",\n\t\t\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\t\t\tColumn: 36,\n\t\t\t\t\t\t\t\t\t\t\tLine:   45,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tValue: \"_measurement\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t}},\n\t\t\t\t\t}},\n\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 51,\n\t\t\t\t\t\t\t\tLine:   45,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\tSource: \"tagValues(bucket: bucket, tag: \\\"_measurement\\\")\",\n\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t\t\t\tLine:   45,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tCallee: &ast.Identifier{\n\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 14,\n\t\t\t\t\t\t\t\t\tLine:   45,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\tSource: \"tagValues\",\n\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 5,\n\t\t\t\t\t\t\t\t\tLine:   45,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tName: \"tagValues\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tParams: []*ast.Property{&ast.Property{\n\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 23,\n\t\t\t\t\t\t\t\tLine:   44,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\tSource: \"bucket\",\n\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\tColumn: 17,\n\t\t\t\t\t\t\t\tLine:   44,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tKey: &ast.Identifier{\n\t\t\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\t\t\tErrors: nil,\n\t\t\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 23,\n\t\t\t\t\t\t\t\t\tLine:   44,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\t\t\tSource: \"bucket\",\n\t\t\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\t\t\tColumn: 17,\n\t\t\t\t\t\t\t\t\tLine:   44,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tName: \"bucket\",\n\t\t\t\t\t},\n\t\t\t\t\tValue: nil,\n\t\t\t\t}},\n\t\t\t},\n\t\t}},\n\t\tImports: nil,\n\t\tName:    \"v1.flux\",\n\t\tPackage: &ast.PackageClause{\n\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\tErrors: nil,\n\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\tColumn: 11,\n\t\t\t\t\t\tLine:   1,\n\t\t\t\t\t},\n\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\tSource: \"package v1\",\n\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\tColumn: 1,\n\t\t\t\t\t\tLine:   1,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tName: &ast.Identifier{\n\t\t\t\tBaseNode: ast.BaseNode{\n\t\t\t\t\tErrors: nil,\n\t\t\t\t\tLoc: &ast.SourceLocation{\n\t\t\t\t\t\tEnd: ast.Position{\n\t\t\t\t\t\t\tColumn: 11,\n\t\t\t\t\t\t\tLine:   1,\n\t\t\t\t\t\t},\n\t\t\t\t\t\tFile:   \"v1.flux\",\n\t\t\t\t\t\tSource: \"v1\",\n\t\t\t\t\t\tStart: ast.Position{\n\t\t\t\t\t\t\tColumn: 9,\n\t\t\t\t\t\t\tLine:   1,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tName: \"v1\",\n\t\t\t},\n\t\t},\n\t}},\n\tPackage: \"v1\",\n\tPath:    \"influxdata/influxdb/v1\",\n}\n", "idx": 17, "id": 10619, "msg": "", "proj": "influxdata-flux", "lang": "go"}
{"patch": "@@ -42,13 +42,15 @@ describe Cancellation do\n     it \"cancels with Stripe\" do\n       cancellation = build_cancellation\n       allow(Stripe::Customer).to receive(:retrieve).and_return(stripe_customer)\n-      analytics_updater = double(\"AnalyticsUpdater\", track_cancelled: true)\n-      allow(Analytics).to receive(:new).and_return(analytics_updater)\n+      analytics = stub_analytics\n \n       cancellation.cancel_now\n \n       expect(stripe_customer.subscriptions.first).to have_received(:delete)\n-      expect(analytics_updater).to have_received(:track_cancelled)\n+      expect(analytics).to(\n+        have_received(:track).\n+        with(event: \"Cancelled\", properties: { reason: \"reason\" })\n+      )\n     end\n \n     it \"retrieves the customer correctly\" do", "y": 1, "oldf": "require \"rails_helper\"\n\ndescribe Cancellation do\n  it \"should be ActiveModel-compliant\" do\n    cancellation = build_cancellation\n\n    expect(cancellation).to be_a(ActiveModel::Model)\n  end\n\n  it \"validates presence of reason\" do\n    cancellation = build_cancellation(reason: \"\")\n\n    expect(cancellation).to be_invalid\n    expect(cancellation.errors[:reason]).to eq([\"can't be blank\"])\n  end\n\n  describe \"#process\" do\n    before :each do\n      allow(subscription).to receive(:stripe_customer_id).\n        and_return(\"cus_1CXxPJDpw1VLvJ\")\n    end\n\n    context \"with an active subscription\" do\n      it \"makes the subscription inactive and records the current date\" do\n        cancellation.process\n\n        expect(subscription.deactivated_on).to eq Time.zone.today\n      end\n    end\n  end\n\n  describe \"#cancel_now\" do\n    it \"makes the subscription inactive and records the current date\" do\n      allow(subscription).to receive(:stripe_customer_id).\n        and_return(\"cus_1CXxPJDpw1VLvJ\")\n\n      cancellation.cancel_now\n\n      expect(subscription.deactivated_on).to eq Time.zone.today\n    end\n\n    it \"cancels with Stripe\" do\n      cancellation = build_cancellation\n      allow(Stripe::Customer).to receive(:retrieve).and_return(stripe_customer)\n      analytics_updater = double(\"AnalyticsUpdater\", track_cancelled: true)\n      allow(Analytics).to receive(:new).and_return(analytics_updater)\n\n      cancellation.cancel_now\n\n      expect(stripe_customer.subscriptions.first).to have_received(:delete)\n      expect(analytics_updater).to have_received(:track_cancelled)\n    end\n\n    it \"retrieves the customer correctly\" do\n      cancellation = build_cancellation(subscription: subscription)\n      allow(subscription).to receive(:stripe_customer_id).\n        and_return(\"cus_1CXxPJDpw1VLvJ\")\n      allow(Stripe::Customer).to receive(:retrieve).\n        and_return(stripe_customer)\n\n      cancellation.cancel_now\n\n      expect(Stripe::Customer).to have_received(:retrieve).\n        with(\"cus_1CXxPJDpw1VLvJ\")\n    end\n\n    it \"does not make the subscription inactive if stripe unsubscribe fails\" do\n      cancellation = build_cancellation(subscription: subscription)\n      stripe_invalid_request_error = double(\"String::InvalidRequestError\")\n      allow(stripe_customer.subscriptions.first).to receive(:delete).\n        and_raise(stripe_invalid_request_error)\n      allow(Stripe::Customer).to receive(:retrieve).\n        and_return(stripe_customer)\n      allow(Analytics).to receive(:new)\n\n      expect { cancellation.cancel_now }.to raise_error\n      expect(subscription.reload).to be_active\n      expect(Analytics).not_to have_received(:new)\n    end\n\n    it \"does not unsubscribe from stripe if deactivating the subscription failed\" do\n      cancellation = build_cancellation(subscription: subscription)\n\n      stripe_customer = double(\"Stripe::Customer\")\n      allow(subscription).to receive(:destroy).\n        and_raise(ActiveRecord::RecordNotSaved, \"error\")\n      allow(subscription).to receive(:cancel_subscription)\n      allow(Stripe::Customer).to receive(:retrieve).and_return(stripe_customer)\n      allow(Analytics).to receive(:new)\n\n      expect { cancellation.cancel_now }.to raise_error\n      expect(subscription).not_to have_received(:cancel_subscription)\n      expect(Analytics).not_to have_received(:new)\n    end\n  end\n\n  describe \"schedule\" do\n    it \"schedules a cancellation with Stripe\" do\n      cancellation = build_cancellation(subscription: subscription)\n      allow(Stripe::Customer).to receive(:retrieve).and_return(stripe_customer)\n      analytics_updater = double(\"AnalyticsUpdater\", track_cancelled: true)\n      allow(Analytics).to receive(:new).and_return(analytics_updater)\n\n      cancellation.schedule\n\n      subscription.reload\n      expect(stripe_customer.subscriptions.first).\n        to have_received(:delete).with(at_period_end: true)\n      expect(subscription.scheduled_for_cancellation_on).\n        to eq Time.zone.at(1361234235).to_date\n      expect(analytics_updater).\n        to have_received(:track_cancelled).with(\"reason\")\n    end\n\n    it \"returns true when valid\" do\n      cancellation = build_cancellation\n      allow(Stripe::Customer).to receive(:retrieve).\n        and_return(stripe_customer)\n      analytics_updater = double(\"AnalyticsUpdater\", track_cancelled: true)\n      allow(Analytics).to receive(:new).with(anything).\n        and_return(analytics_updater)\n\n      expect(cancellation.schedule).to eq true\n    end\n\n    it \"returns false when invalid\" do\n      cancellation = build_cancellation(reason: nil)\n      allow(Stripe::Customer).to receive(:retrieve).and_return(stripe_customer)\n      analytics_updater = double(\"AnalyticsUpdater\", track_cancelled: true)\n      allow(Analytics).to receive(:new).and_return(analytics_updater)\n\n      expect(cancellation.schedule).to eq false\n    end\n\n    it \"retrieves the customer correctly\" do\n      cancellation = build_cancellation(subscription: subscription)\n\n      allow(subscription).to receive(:stripe_customer_id).\n        and_return(\"cus_1CXxPJDpw1VLvJ\")\n      allow(Stripe::Customer).to receive(:retrieve).\n        and_return(stripe_customer)\n      cancellation.schedule\n\n      expect(Stripe::Customer).to have_received(:retrieve).\n        with(\"cus_1CXxPJDpw1VLvJ\")\n    end\n\n    it \"does not make the subscription inactive if stripe unsubscribe fails\" do\n      cancellation = build_cancellation(subscription: subscription)\n\n      stripe_invalid_request_error = double(\"String::InvalidRequestError\")\n      allow(stripe_customer.subscriptions.first).to receive(:delete).\n        and_raise(stripe_invalid_request_error)\n      allow(Stripe::Customer).to receive(:retrieve).\n        and_return(stripe_customer)\n      allow(Analytics).to receive(:new)\n\n      expect { cancellation.schedule }.to raise_error\n      expect(subscription.reload).to be_active\n      expect(Analytics).not_to have_received(:new)\n    end\n\n    it \"does not unsubscribe from stripe if deactivating the subscription failed\" do\n      cancellation = build_cancellation(subscription: subscription)\n\n      stripe_customer = double(\"Stripe::Customer\")\n      allow(subscription).to receive(:destroy).\n        and_raise(ActiveRecord::RecordNotSaved, \"error\")\n      allow(subscription).to receive(:cancel_subscription)\n      allow(Stripe::Customer).to receive(:retrieve).\n        and_return(stripe_customer)\n      allow(Analytics).to receive(:new)\n\n      expect { cancellation.schedule }.to raise_error\n      expect(subscription).not_to have_received(:cancel_subscription)\n      expect(Analytics).not_to have_received(:new)\n    end\n  end\n\n  describe \"#subscribed_plan\" do\n    it \"returns the plan from the subscription\" do\n      subscription = build_stubbed(:subscription)\n      cancellation = build_cancellation(subscription: subscription)\n\n      expect(cancellation.subscribed_plan).to eq(subscription.plan)\n    end\n  end\n\n  def build_cancellation(subscription: create(:subscription),\n                         reason: \"reason\")\n    Cancellation.new(\n      subscription: subscription,\n      reason: reason\n    )\n  end\n\n  def subscription\n    @subscription ||= create(:subscription, :purchased)\n  end\n\n  def cancellation\n    @cancellation ||= build_cancellation(subscription: subscription)\n  end\n\n  def stripe_customer\n    @stripe_customer ||= double(\n      \"Stripe::Customer\",\n      subscriptions: [\n        double(\n          \"Subscription\",\n          current_period_end: 1361234235,\n          delete: true\n        )\n      ]\n    )\n  end\nend\n", "idx": 1, "id": 14939, "msg": "Space inside parentheses detected.", "proj": "thoughtbot-upcase", "lang": "rb"}
{"patch": "@@ -17,7 +17,8 @@ use Sonata\\MediaBundle\\Model\\MediaInterface;\n use Symfony\\Component\\DependencyInjection\\ContainerInterface;\n use Symfony\\Component\\HttpFoundation\\Request;\n use Symfony\\Component\\HttpFoundation\\Session\\SessionInterface;\n-use Symfony\\Component\\Translation\\TranslatorInterface;\n+use Symfony\\Component\\Translation\\TranslatorInterface as LegacyTranslatorInterface;\n+use Symfony\\Contracts\\Translation\\TranslatorInterface;\n \n /**\n  * @final since sonata-project/media-bundle 3.21.0", "y": 0, "oldf": "<?php\n\ndeclare(strict_types=1);\n\n/*\n * This file is part of the Sonata Project package.\n *\n * (c) Thomas Rabaix <thomas.rabaix@sonata-project.org>\n *\n * For the full copyright and license information, please view the LICENSE\n * file that was distributed with this source code.\n */\n\nnamespace Sonata\\MediaBundle\\Security;\n\nuse Sonata\\MediaBundle\\Model\\MediaInterface;\nuse Symfony\\Component\\DependencyInjection\\ContainerInterface;\nuse Symfony\\Component\\HttpFoundation\\Request;\nuse Symfony\\Component\\HttpFoundation\\Session\\SessionInterface;\nuse Symfony\\Component\\Translation\\TranslatorInterface;\n\n/**\n * @final since sonata-project/media-bundle 3.21.0\n *\n * @author Ahmet Akbana <ahmetakbana@gmail.com>\n */\nclass SessionDownloadStrategy implements DownloadStrategyInterface\n{\n    /**\n     * @var ContainerInterface\n     *\n     * @deprecated since sonata-project/media-bundle 3.1, will be removed in 4.0.\n     * NEXT_MAJOR : remove this property\n     */\n    protected $container;\n\n    /**\n     * @var TranslatorInterface\n     */\n    protected $translator;\n\n    /**\n     * @var int\n     */\n    protected $times;\n\n    /**\n     * @var string\n     */\n    protected $sessionKey = 'sonata/media/session/times';\n\n    /**\n     * @var SessionInterface\n     */\n    private $session;\n\n    /**\n     * @param ContainerInterface|SessionInterface $sessionOrContainer\n     * @param int                                 $times\n     */\n    public function __construct(TranslatorInterface $translator, object $sessionOrContainer, $times)\n    {\n        // NEXT_MAJOR: Remove these checks and declare `SessionInterface` for argument 2.\n        if ($sessionOrContainer instanceof SessionInterface) {\n            $this->session = $sessionOrContainer;\n        } elseif ($sessionOrContainer instanceof ContainerInterface) {\n            @trigger_error(sprintf(\n                'Passing other type than \"%s\" as argument 2 to \"%s()\" is deprecated since sonata-project/media-bundle 3.1'\n                .' and will throw a \"\\TypeError\" error in 4.0.',\n                SessionInterface::class,\n                __METHOD__\n            ), \\E_USER_DEPRECATED);\n\n            $this->session = $sessionOrContainer->get('session');\n        } else {\n            throw new \\TypeError(sprintf(\n                'Argument 2 passed to \"%s()\" MUST be an instance of \"%s\" or \"%s\", \"%s\" given.',\n                __METHOD__,\n                SessionInterface::class,\n                ContainerInterface::class,\n                \\get_class($sessionOrContainer)\n            ));\n        }\n\n        $this->times = $times;\n        $this->translator = $translator;\n    }\n\n    public function isGranted(MediaInterface $media, Request $request)\n    {\n        $times = $this->session->get($this->sessionKey, 0);\n\n        if ($times >= $this->times) {\n            return false;\n        }\n\n        ++$times;\n\n        $this->session->set($this->sessionKey, $times);\n\n        return true;\n    }\n\n    public function getDescription()\n    {\n        return $this->translator->transChoice(\n            'description.session_download_strategy',\n            $this->times,\n            ['%times%' => $this->times],\n            'SonataMediaBundle'\n        );\n    }\n}\n", "idx": 1, "id": 11800, "msg": "", "proj": "sonata-project-SonataMediaBundle", "lang": "php"}
{"patch": "@@ -521,13 +521,15 @@ public class PlaybackController {\n      * Should be used by classes which implement the OnSeekBarChanged interface.\n      */\n     public float onSeekBarProgressChanged(SeekBar seekBar, int progress,\n-                                          boolean fromUser, TextView txtvPosition) {\n+                                          boolean fromUser, TextView txtvPosition, TextView seekDisplay) {\n         if (fromUser && playbackService != null && media != null) {\n             float prog = progress / ((float) seekBar.getMax());\n             int duration = media.getDuration();\n+            if (duration == -1) duration = getDuration();\n             TimeSpeedConverter converter = new TimeSpeedConverter(playbackService.getCurrentPlaybackSpeed());\n             int position = converter.convert((int) (prog * duration));\n             txtvPosition.setText(Converter.getDurationStringLong(position));\n+            seekDisplay.setText(Converter.getDurationStringLong(position));\n             return prog;\n         }\n         return 0;", "y": 1, "oldf": "package de.danoeh.antennapod.core.util.playback;\n\nimport android.app.Activity;\nimport android.content.BroadcastReceiver;\nimport android.content.ComponentName;\nimport android.content.Context;\nimport android.content.Intent;\nimport android.content.IntentFilter;\nimport android.content.ServiceConnection;\nimport android.content.res.TypedArray;\nimport android.media.MediaPlayer;\nimport android.os.Build;\nimport android.os.IBinder;\nimport androidx.annotation.NonNull;\nimport androidx.core.content.ContextCompat;\nimport android.text.TextUtils;\nimport android.util.Log;\nimport android.util.Pair;\nimport android.view.SurfaceHolder;\nimport android.widget.ImageButton;\nimport android.widget.SeekBar;\nimport android.widget.TextView;\n\nimport de.danoeh.antennapod.core.util.ThemeUtils;\nimport java.util.concurrent.ScheduledThreadPoolExecutor;\n\nimport de.danoeh.antennapod.core.R;\nimport de.danoeh.antennapod.core.event.ServiceEvent;\nimport de.danoeh.antennapod.core.feed.Chapter;\nimport de.danoeh.antennapod.core.feed.FeedMedia;\nimport de.danoeh.antennapod.core.feed.MediaType;\nimport de.danoeh.antennapod.core.preferences.PlaybackPreferences;\nimport de.danoeh.antennapod.core.feed.util.PlaybackSpeedUtils;\nimport de.danoeh.antennapod.core.preferences.UserPreferences;\nimport de.danoeh.antennapod.core.service.playback.PlaybackService;\nimport de.danoeh.antennapod.core.service.playback.PlaybackServiceMediaPlayer;\nimport de.danoeh.antennapod.core.service.playback.PlayerStatus;\nimport de.danoeh.antennapod.core.storage.DBTasks;\nimport de.danoeh.antennapod.core.util.Converter;\nimport de.danoeh.antennapod.core.util.Optional;\nimport de.danoeh.antennapod.core.util.TimeSpeedConverter;\nimport de.danoeh.antennapod.core.util.playback.Playable.PlayableUtils;\nimport io.reactivex.Maybe;\nimport io.reactivex.MaybeOnSubscribe;\nimport io.reactivex.Observable;\nimport io.reactivex.android.schedulers.AndroidSchedulers;\nimport io.reactivex.disposables.Disposable;\nimport io.reactivex.schedulers.Schedulers;\nimport org.greenrobot.eventbus.EventBus;\nimport org.greenrobot.eventbus.Subscribe;\nimport org.greenrobot.eventbus.ThreadMode;\n\n/**\n * Communicates with the playback service. GUI classes should use this class to\n * control playback instead of communicating with the PlaybackService directly.\n */\npublic class PlaybackController {\n\n    private static final String TAG = \"PlaybackController\";\n\n    private static final int INVALID_TIME = -1;\n\n    private final Activity activity;\n\n    private PlaybackService playbackService;\n    private Playable media;\n    private PlayerStatus status = PlayerStatus.STOPPED;\n\n    private final ScheduledThreadPoolExecutor schedExecutor;\n    private static final int SCHED_EX_POOLSIZE = 1;\n\n    private boolean mediaInfoLoaded = false;\n    private boolean released = false;\n    private boolean initialized = false;\n    private boolean eventsRegistered = false;\n\n    private Disposable serviceBinder;\n    private Disposable mediaLoader;\n\n    /**\n     * True if controller should reinit playback service if 'pause' button is\n     * pressed.\n     */\n    private final boolean reinitOnPause;\n\n    public PlaybackController(@NonNull Activity activity, boolean reinitOnPause) {\n\n        this.activity = activity;\n        this.reinitOnPause = reinitOnPause;\n        schedExecutor = new ScheduledThreadPoolExecutor(SCHED_EX_POOLSIZE,\n                r -> {\n                    Thread t = new Thread(r);\n                    t.setPriority(Thread.MIN_PRIORITY);\n                    return t;\n                }, (r, executor) -> Log.w(TAG, \"Rejected execution of runnable in schedExecutor\")\n        );\n    }\n\n    /**\n     * Creates a new connection to the playbackService.\n     */\n    public synchronized void init() {\n        if (!eventsRegistered) {\n            EventBus.getDefault().register(this);\n            eventsRegistered = true;\n        }\n        if (PlaybackService.isRunning) {\n            initServiceRunning();\n        } else {\n            initServiceNotRunning();\n        }\n    }\n\n    @Subscribe(threadMode = ThreadMode.MAIN)\n    public void onEventMainThread(ServiceEvent event) {\n        if (event.action == ServiceEvent.Action.SERVICE_STARTED) {\n            init();\n        }\n    }\n\n    private synchronized void initServiceRunning() {\n        if (initialized) {\n            return;\n        }\n        initialized = true;\n\n        activity.registerReceiver(statusUpdate, new IntentFilter(\n            PlaybackService.ACTION_PLAYER_STATUS_CHANGED));\n\n        activity.registerReceiver(notificationReceiver, new IntentFilter(\n            PlaybackService.ACTION_PLAYER_NOTIFICATION));\n\n        activity.registerReceiver(shutdownReceiver, new IntentFilter(\n                PlaybackService.ACTION_SHUTDOWN_PLAYBACK_SERVICE));\n\n        if (!released) {\n            bindToService();\n        } else {\n            throw new IllegalStateException(\"Can't call init() after release() has been called\");\n        }\n        checkMediaInfoLoaded();\n    }\n\n    /**\n     * Should be called if the PlaybackController is no longer needed, for\n     * example in the activity's onStop() method.\n     */\n    public void release() {\n        Log.d(TAG, \"Releasing PlaybackController\");\n\n        try {\n            activity.unregisterReceiver(statusUpdate);\n        } catch (IllegalArgumentException e) {\n            // ignore\n        }\n\n        try {\n            activity.unregisterReceiver(notificationReceiver);\n        } catch (IllegalArgumentException e) {\n            // ignore\n        }\n\n        if(serviceBinder != null) {\n            serviceBinder.dispose();\n        }\n        try {\n            activity.unbindService(mConnection);\n        } catch (IllegalArgumentException e) {\n            // ignore\n        }\n\n        try {\n            activity.unregisterReceiver(shutdownReceiver);\n        } catch (IllegalArgumentException e) {\n            // ignore\n        }\n        schedExecutor.shutdownNow();\n        media = null;\n        released = true;\n\n        if (eventsRegistered) {\n            EventBus.getDefault().unregister(this);\n            eventsRegistered = false;\n        }\n    }\n\n    /**\n     * Should be called in the activity's onPause() method.\n     */\n    public void pause() {\n        mediaInfoLoaded = false;\n    }\n\n    /**\n     * Tries to establish a connection to the PlaybackService. If it isn't\n     * running, the PlaybackService will be started with the last played media\n     * as the arguments of the launch intent.\n     */\n    private void bindToService() {\n        Log.d(TAG, \"Trying to connect to service\");\n        if (serviceBinder != null) {\n            serviceBinder.dispose();\n        }\n        serviceBinder = Observable.fromCallable(this::getPlayLastPlayedMediaIntent)\n                .subscribeOn(Schedulers.io())\n                .observeOn(AndroidSchedulers.mainThread())\n                .subscribe(optionalIntent -> {\n                    boolean bound = false;\n                    if (!PlaybackService.isRunning) {\n                        if (optionalIntent.isPresent()) {\n                            Log.d(TAG, \"Calling start service\");\n                            ContextCompat.startForegroundService(activity, optionalIntent.get());\n                            bound = activity.bindService(optionalIntent.get(), mConnection, 0);\n                        } else {\n                            status = PlayerStatus.STOPPED;\n                            setupGUI();\n                            handleStatus();\n                        }\n                    } else {\n                        Log.d(TAG, \"PlaybackService is running, trying to connect without start command.\");\n                        bound = activity.bindService(new Intent(activity, PlaybackService.class),\n                                mConnection, 0);\n                    }\n                    Log.d(TAG, \"Result for service binding: \" + bound);\n                }, error -> Log.e(TAG, Log.getStackTraceString(error)));\n    }\n\n    /**\n     * Returns an intent that starts the PlaybackService and plays the last\n     * played media or null if no last played media could be found.\n     */\n    @NonNull\n    private Optional<Intent> getPlayLastPlayedMediaIntent() {\n        Log.d(TAG, \"Trying to restore last played media\");\n        Playable media = PlayableUtils.createInstanceFromPreferences(activity);\n        if (media == null) {\n            Log.d(TAG, \"No last played media found\");\n            return Optional.empty();\n        }\n\n        boolean fileExists = media.localFileAvailable();\n        boolean lastIsStream = PlaybackPreferences.getCurrentEpisodeIsStream();\n        if (!fileExists && !lastIsStream && media instanceof FeedMedia) {\n            DBTasks.notifyMissingFeedMediaFile(activity, (FeedMedia) media);\n        }\n\n        return Optional.of(new PlaybackServiceStarter(activity, media)\n                .startWhenPrepared(false)\n                .shouldStream(lastIsStream || !fileExists)\n                .getIntent());\n    }\n\n    private final ServiceConnection mConnection = new ServiceConnection() {\n        public void onServiceConnected(ComponentName className, IBinder service) {\n            if(service instanceof PlaybackService.LocalBinder) {\n                playbackService = ((PlaybackService.LocalBinder) service).getService();\n                if (!released) {\n                    queryService();\n                    Log.d(TAG, \"Connection to Service established\");\n                } else {\n                    Log.i(TAG, \"Connection to playback service has been established, \" +\n                            \"but controller has already been released\");\n                }\n            }\n        }\n\n        @Override\n        public void onServiceDisconnected(ComponentName name) {\n            playbackService = null;\n            Log.d(TAG, \"Disconnected from Service\");\n        }\n    };\n\n    private final BroadcastReceiver statusUpdate = new BroadcastReceiver() {\n        @Override\n        public void onReceive(Context context, Intent intent) {\n            Log.d(TAG, \"Received statusUpdate Intent.\");\n            if (isConnectedToPlaybackService()) {\n                PlaybackServiceMediaPlayer.PSMPInfo info = playbackService.getPSMPInfo();\n                status = info.playerStatus;\n                media = info.playable;\n                handleStatus();\n            } else {\n                Log.w(TAG, \"Couldn't receive status update: playbackService was null\");\n                bindToService();\n            }\n        }\n    };\n\n    private final BroadcastReceiver notificationReceiver = new BroadcastReceiver() {\n\n        @Override\n        public void onReceive(Context context, Intent intent) {\n            if (!isConnectedToPlaybackService()) {\n                bindToService();\n                return;\n            }\n                int type = intent.getIntExtra(PlaybackService.EXTRA_NOTIFICATION_TYPE, -1);\n                int code = intent.getIntExtra(PlaybackService.EXTRA_NOTIFICATION_CODE, -1);\n            if(code == -1 || type == -1) {\n                Log.d(TAG, \"Bad arguments. Won't handle intent\");\n                return;\n            }\n            switch (type) {\n                case PlaybackService.NOTIFICATION_TYPE_ERROR:\n                    handleError(code);\n                    break;\n                case PlaybackService.NOTIFICATION_TYPE_BUFFER_UPDATE:\n                    float progress = ((float) code) / 100;\n                    onBufferUpdate(progress);\n                    break;\n                case PlaybackService.NOTIFICATION_TYPE_RELOAD:\n                    mediaInfoLoaded = false;\n                    queryService();\n                    onReloadNotification(intent.getIntExtra(\n                            PlaybackService.EXTRA_NOTIFICATION_CODE, -1));\n                    break;\n                case PlaybackService.NOTIFICATION_TYPE_SLEEPTIMER_UPDATE:\n                    onSleepTimerUpdate();\n                    break;\n                case PlaybackService.NOTIFICATION_TYPE_BUFFER_START:\n                    onBufferStart();\n                    break;\n                case PlaybackService.NOTIFICATION_TYPE_BUFFER_END:\n                    onBufferEnd();\n                    break;\n                case PlaybackService.NOTIFICATION_TYPE_PLAYBACK_END:\n                    onPlaybackEnd();\n                    break;\n                case PlaybackService.NOTIFICATION_TYPE_PLAYBACK_SPEED_CHANGE:\n                    onPlaybackSpeedChange();\n                    break;\n                case PlaybackService.NOTIFICATION_TYPE_SET_SPEED_ABILITY_CHANGED:\n                    onSetSpeedAbilityChanged();\n                    break;\n                case PlaybackService.NOTIFICATION_TYPE_SHOW_TOAST:\n                    postStatusMsg(code, true);\n            }\n        }\n\n    };\n\n    private final BroadcastReceiver shutdownReceiver = new BroadcastReceiver() {\n\n        @Override\n        public void onReceive(Context context, Intent intent) {\n            if (isConnectedToPlaybackService()) {\n                if (TextUtils.equals(intent.getAction(),\n                        PlaybackService.ACTION_SHUTDOWN_PLAYBACK_SERVICE)) {\n                    release();\n                    onShutdownNotification();\n                }\n            }\n        }\n    };\n\n    public void setupGUI() {}\n\n    public void onPositionObserverUpdate() {}\n\n\n    public void onPlaybackSpeedChange() {}\n\n    public void onSetSpeedAbilityChanged() {}\n\n    public void onShutdownNotification() {}\n\n    /**\n     * Called when the currently displayed information should be refreshed.\n     */\n    public void onReloadNotification(int code) {}\n\n    public void onBufferStart() {}\n\n    public void onBufferEnd() {}\n\n    public void onBufferUpdate(float progress) {}\n\n    public void onSleepTimerUpdate() {}\n\n    public void handleError(int code) {}\n\n    public void onPlaybackEnd() {}\n\n    public void repeatHandleStatus() {\n        if (status != null && playbackService != null) {\n            handleStatus();\n        }\n    }\n\n    /**\n     * Is called whenever the PlaybackService changes its status. This method\n     * should be used to update the GUI or start/cancel background threads.\n     */\n    private void handleStatus() {\n        final int playResource;\n        final int pauseResource;\n        final CharSequence playText = activity.getString(R.string.play_label);\n        final CharSequence pauseText = activity.getString(R.string.pause_label);\n\n        if (PlaybackService.getCurrentMediaType() == MediaType.AUDIO  ||  PlaybackService.isCasting()) {\n            TypedArray res = activity.obtainStyledAttributes(new int[]{ R.attr.av_play, R.attr.av_pause});\n            playResource = res.getResourceId(0, R.drawable.ic_av_play_dark_48dp);\n            pauseResource = res.getResourceId(1, R.drawable.ic_av_pause_dark_48dp);\n            res.recycle();\n        } else {\n            playResource = R.drawable.ic_av_play_white_80dp;\n            pauseResource = R.drawable.ic_av_pause_white_80dp;\n        }\n\n        Log.d(TAG, \"status: \" + status.toString());\n        switch (status) {\n            case ERROR:\n                postStatusMsg(R.string.player_error_msg, false);\n                handleError(MediaPlayer.MEDIA_ERROR_UNKNOWN);\n                break;\n            case PAUSED:\n                clearStatusMsg();\n                checkMediaInfoLoaded();\n                onPositionObserverUpdate();\n                updatePlayButtonAppearance(playResource, playText);\n                if (!PlaybackService.isCasting() &&\n                        PlaybackService.getCurrentMediaType() == MediaType.VIDEO) {\n                    setScreenOn(false);\n                }\n                break;\n            case PLAYING:\n                clearStatusMsg();\n                checkMediaInfoLoaded();\n                if (!PlaybackService.isCasting() &&\n                        PlaybackService.getCurrentMediaType() == MediaType.VIDEO) {\n                    onAwaitingVideoSurface();\n                    setScreenOn(true);\n                }\n                updatePlayButtonAppearance(pauseResource, pauseText);\n                break;\n            case PREPARING:\n                postStatusMsg(R.string.player_preparing_msg, false);\n                checkMediaInfoLoaded();\n                if (playbackService != null) {\n                    if (playbackService.isStartWhenPrepared()) {\n                        updatePlayButtonAppearance(pauseResource, pauseText);\n                    } else {\n                        updatePlayButtonAppearance(playResource, playText);\n                    }\n                }\n                break;\n            case STOPPED:\n                postStatusMsg(R.string.player_stopped_msg, false);\n                break;\n            case PREPARED:\n                checkMediaInfoLoaded();\n                postStatusMsg(R.string.player_ready_msg, false);\n                updatePlayButtonAppearance(playResource, playText);\n                onPositionObserverUpdate();\n                break;\n            case SEEKING:\n                onPositionObserverUpdate();\n                postStatusMsg(R.string.player_seeking_msg, false);\n                break;\n            case INITIALIZED:\n                checkMediaInfoLoaded();\n                clearStatusMsg();\n                updatePlayButtonAppearance(playResource, playText);\n                break;\n        }\n    }\n\n    private void checkMediaInfoLoaded() {\n        mediaInfoLoaded = (mediaInfoLoaded || loadMediaInfo());\n    }\n\n    private void updatePlayButtonAppearance(int resource, CharSequence contentDescription) {\n        ImageButton butPlay = getPlayButton();\n        if(butPlay != null) {\n            butPlay.setImageResource(resource);\n            butPlay.setContentDescription(contentDescription);\n        }\n    }\n\n    public ImageButton getPlayButton() {\n        return null;\n    }\n\n    public void postStatusMsg(int msg, boolean showToast) {}\n\n    public void clearStatusMsg() {}\n\n    public boolean loadMediaInfo() {\n        return false;\n    }\n\n    public  void onAwaitingVideoSurface()  {}\n\n    /**\n     * Called when connection to playback service has been established or\n     * information has to be refreshed\n     */\n    private void queryService() {\n        Log.d(TAG, \"Querying service info\");\n        if (playbackService != null) {\n            PlaybackServiceMediaPlayer.PSMPInfo info = playbackService.getPSMPInfo();\n            status = info.playerStatus;\n            media = info.playable;\n            onServiceQueried();\n\n            setupGUI();\n            handleStatus();\n            // make sure that new media is loaded if it's available\n            mediaInfoLoaded = false;\n\n        } else {\n            Log.e(TAG,\n                    \"queryService() was called without an existing connection to playbackservice\");\n        }\n    }\n\n    public void onServiceQueried()  {}\n\n    /**\n     * Should be used by classes which implement the OnSeekBarChanged interface.\n     */\n    public float onSeekBarProgressChanged(SeekBar seekBar, int progress,\n                                          boolean fromUser, TextView txtvPosition) {\n        if (fromUser && playbackService != null && media != null) {\n            float prog = progress / ((float) seekBar.getMax());\n            int duration = media.getDuration();\n            TimeSpeedConverter converter = new TimeSpeedConverter(playbackService.getCurrentPlaybackSpeed());\n            int position = converter.convert((int) (prog * duration));\n            txtvPosition.setText(Converter.getDurationStringLong(position));\n            return prog;\n        }\n        return 0;\n\n    }\n\n    /**\n     * Should be used by classes which implement the OnSeekBarChanged interface.\n     */\n    public void onSeekBarStartTrackingTouch(SeekBar seekBar) {\n        // interrupt position Observer, restart later\n    }\n\n    /**\n     * Should be used by classes which implement the OnSeekBarChanged interface.\n     */\n    public void onSeekBarStopTrackingTouch(SeekBar seekBar, float prog) {\n        if (playbackService != null && media != null) {\n            seekTo((int) (prog * getDuration()));\n        }\n    }\n\n    /**\n     * Should be implemented by classes that show a video. The default implementation\n     * does nothing\n     *\n     * @param enable True if the screen should be kept on, false otherwise\n     */\n    protected void setScreenOn(boolean enable) {\n\n    }\n\n    public void playPause() {\n        if (playbackService == null) {\n            new PlaybackServiceStarter(activity, media)\n                    .startWhenPrepared(true)\n                    .streamIfLastWasStream()\n                    .start();\n            Log.w(TAG, \"Play/Pause button was pressed, but playbackservice was null!\");\n            return;\n        }\n        switch (status) {\n            case PLAYING:\n                playbackService.pause(true, reinitOnPause);\n                break;\n            case PAUSED:\n            case PREPARED:\n                playbackService.resume();\n                break;\n            case PREPARING:\n                playbackService.setStartWhenPrepared(!playbackService\n                        .isStartWhenPrepared());\n                if (reinitOnPause\n                        && !playbackService.isStartWhenPrepared()) {\n                    playbackService.reinit();\n                }\n                break;\n            case INITIALIZED:\n                playbackService.setStartWhenPrepared(true);\n                playbackService.prepare();\n                break;\n        }\n    }\n\n    public boolean serviceAvailable() {\n        return playbackService != null;\n    }\n\n    public int getPosition() {\n        if (playbackService != null) {\n            return playbackService.getCurrentPosition();\n        } else if (media != null) {\n            return media.getPosition();\n        } else {\n            return PlaybackService.INVALID_TIME;\n        }\n    }\n\n    public int getDuration() {\n        if (playbackService != null) {\n            return playbackService.getDuration();\n        } else if (media != null) {\n            return media.getDuration();\n        } else {\n            return PlaybackService.INVALID_TIME;\n        }\n    }\n\n    public Playable getMedia() {\n        if (media == null) {\n            media = PlayableUtils.createInstanceFromPreferences(activity);\n        }\n        return media;\n    }\n\n    public boolean sleepTimerActive() {\n        return playbackService != null && playbackService.sleepTimerActive();\n    }\n\n    public void disableSleepTimer() {\n        if (playbackService != null) {\n            playbackService.disableSleepTimer();\n        }\n    }\n\n    public long getSleepTimerTimeLeft() {\n        if (playbackService != null) {\n            return playbackService.getSleepTimerTimeLeft();\n        } else {\n            return INVALID_TIME;\n        }\n    }\n\n    public void setSleepTimer(long time, boolean shakeToReset, boolean vibrate) {\n        if (playbackService != null) {\n            playbackService.setSleepTimer(time, shakeToReset, vibrate);\n        }\n    }\n\n    public void seekToChapter(Chapter chapter) {\n        if (playbackService != null) {\n            playbackService.seekToChapter(chapter);\n        }\n    }\n\n    public void seekTo(int time) {\n        if (playbackService != null) {\n            playbackService.seekTo(time);\n        }\n    }\n\n    public void setVideoSurface(SurfaceHolder holder) {\n        if (playbackService != null) {\n            playbackService.setVideoSurface(holder);\n        }\n    }\n\n    public PlayerStatus getStatus() {\n        return status;\n    }\n\n    public boolean canSetPlaybackSpeed() {\n        return UserPreferences.useSonic()\n                || UserPreferences.useExoplayer()\n                || Build.VERSION.SDK_INT >= 23\n                || (playbackService != null && playbackService.canSetSpeed());\n    }\n\n    public void setPlaybackSpeed(float speed) {\n        if (playbackService != null) {\n            playbackService.setSpeed(speed);\n        } else {\n            onPlaybackSpeedChange();\n        }\n    }\n    public void setSkipSilence(boolean skipSilence) {\n        if (playbackService != null) {\n            playbackService.skipSilence(skipSilence);\n        }\n    }\n\n    public void setVolume(float leftVolume, float rightVolume) {\n        if (playbackService != null) {\n            playbackService.setVolume(leftVolume, rightVolume);\n        }\n    }\n\n    public float getCurrentPlaybackSpeedMultiplier() {\n        if (playbackService != null && canSetPlaybackSpeed()) {\n            return playbackService.getCurrentPlaybackSpeed();\n        } else {\n            return PlaybackSpeedUtils.getCurrentPlaybackSpeed(getMedia());\n        }\n    }\n\n    public boolean canDownmix() {\n        return (playbackService != null && playbackService.canDownmix())\n                || UserPreferences.useSonic();\n    }\n\n    public void setDownmix(boolean enable) {\n        if(playbackService != null) {\n            playbackService.setDownmix(enable);\n        }\n    }\n\n    public boolean isPlayingVideoLocally() {\n        if (PlaybackService.isCasting()) {\n            return false;\n        } else if (playbackService != null) {\n            return PlaybackService.getCurrentMediaType() == MediaType.VIDEO;\n        } else {\n            return getMedia() != null && getMedia().getMediaType() == MediaType.VIDEO;\n        }\n    }\n\n    public Pair<Integer, Integer> getVideoSize() {\n        if (playbackService != null) {\n            return playbackService.getVideoSize();\n        } else {\n            return null;\n        }\n    }\n\n\n    /**\n     * Returns true if PlaybackController can communicate with the playback\n     * service.\n     */\n    private boolean isConnectedToPlaybackService() {\n        return playbackService != null;\n    }\n\n    public void notifyVideoSurfaceAbandoned() {\n        if (playbackService != null) {\n            playbackService.notifyVideoSurfaceAbandoned();\n        }\n    }\n\n    /**\n     * Move service into INITIALIZED state if it's paused to save bandwidth\n     */\n    public void reinitServiceIfPaused() {\n        if (playbackService != null\n                && playbackService.isStreaming()\n                && !PlaybackService.isCasting()\n                && (playbackService.getStatus() == PlayerStatus.PAUSED ||\n                (playbackService.getStatus() == PlayerStatus.PREPARING &&\n                        !playbackService.isStartWhenPrepared()))) {\n            playbackService.reinit();\n        }\n    }\n\n    private void initServiceNotRunning() {\n        if (getPlayButton() == null) {\n            return;\n        }\n        Log.v(TAG, \"initServiceNotRunning()\");\n        mediaLoader = Maybe.create((MaybeOnSubscribe<Playable>) emitter -> {\n            Playable media = getMedia();\n            if (media != null) {\n                emitter.onSuccess(media);\n            } else {\n                emitter.onComplete();\n            }\n        })\n            .subscribeOn(Schedulers.io())\n            .observeOn(AndroidSchedulers.mainThread())\n            .subscribe(media -> {\n                if (media.getMediaType() == MediaType.AUDIO) {\n                    getPlayButton().setImageResource(\n                            ThemeUtils.getDrawableFromAttr(activity, de.danoeh.antennapod.core.R.attr.av_play));\n                } else {\n                    getPlayButton().setImageResource(R.drawable.ic_av_play_white_80dp);\n                }\n            }, error -> Log.e(TAG, Log.getStackTraceString(error)));\n    }\n}\n", "idx": 1, "id": 15884, "msg": "Can you just replace media.getDuration with getDuration? I think this should solve the issue too, without having to add checks.", "proj": "AntennaPod-AntennaPod", "lang": "java"}
{"patch": "@@ -246,6 +246,10 @@ func (m *Manager) Apply(pid int) error {\n \t\treturn err\n \t}\n \n+\tif err := joinPids(c, pid); err != nil {\n+\t\treturn err\n+\t}\n+\n \tif err := joinCpuset(c, pid); err != nil {\n \t\treturn err\n \t}", "y": 0, "oldf": "// +build linux\n\npackage systemd\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\tsystemdDbus \"github.com/coreos/go-systemd/dbus\"\n\tsystemdUtil \"github.com/coreos/go-systemd/util\"\n\t\"github.com/godbus/dbus\"\n\t\"github.com/opencontainers/runc/libcontainer/cgroups\"\n\t\"github.com/opencontainers/runc/libcontainer/cgroups/fs\"\n\t\"github.com/opencontainers/runc/libcontainer/configs\"\n)\n\ntype Manager struct {\n\tmu      sync.Mutex\n\tCgroups *configs.Cgroup\n\tPaths   map[string]string\n}\n\ntype subsystem interface {\n\t// Name returns the name of the subsystem.\n\tName() string\n\t// Returns the stats, as 'stats', corresponding to the cgroup under 'path'.\n\tGetStats(path string, stats *cgroups.Stats) error\n\t// Set the cgroup represented by cgroup.\n\tSet(path string, cgroup *configs.Cgroup) error\n}\n\nvar errSubsystemDoesNotExist = errors.New(\"cgroup: subsystem does not exist\")\n\ntype subsystemSet []subsystem\n\nfunc (s subsystemSet) Get(name string) (subsystem, error) {\n\tfor _, ss := range s {\n\t\tif ss.Name() == name {\n\t\t\treturn ss, nil\n\t\t}\n\t}\n\treturn nil, errSubsystemDoesNotExist\n}\n\nvar subsystems = subsystemSet{\n\t&fs.CpusetGroup{},\n\t&fs.DevicesGroup{},\n\t&fs.MemoryGroup{},\n\t&fs.CpuGroup{},\n\t&fs.CpuacctGroup{},\n\t&fs.BlkioGroup{},\n\t&fs.HugetlbGroup{},\n\t&fs.PerfEventGroup{},\n\t&fs.FreezerGroup{},\n\t&fs.NetPrioGroup{},\n\t&fs.NetClsGroup{},\n\t&fs.NameGroup{GroupName: \"name=systemd\"},\n}\n\nconst (\n\ttestScopeWait = 4\n)\n\nvar (\n\tconnLock                        sync.Mutex\n\ttheConn                         *systemdDbus.Conn\n\thasStartTransientUnit           bool\n\thasTransientDefaultDependencies bool\n)\n\nfunc newProp(name string, units interface{}) systemdDbus.Property {\n\treturn systemdDbus.Property{\n\t\tName:  name,\n\t\tValue: dbus.MakeVariant(units),\n\t}\n}\n\nfunc UseSystemd() bool {\n\tif !systemdUtil.IsRunningSystemd() {\n\t\treturn false\n\t}\n\n\tconnLock.Lock()\n\tdefer connLock.Unlock()\n\n\tif theConn == nil {\n\t\tvar err error\n\t\ttheConn, err = systemdDbus.New()\n\t\tif err != nil {\n\t\t\treturn false\n\t\t}\n\n\t\t// Assume we have StartTransientUnit\n\t\thasStartTransientUnit = true\n\n\t\t// But if we get UnknownMethod error we don't\n\t\tif _, err := theConn.StartTransientUnit(\"test.scope\", \"invalid\", nil, nil); err != nil {\n\t\t\tif dbusError, ok := err.(dbus.Error); ok {\n\t\t\t\tif dbusError.Name == \"org.freedesktop.DBus.Error.UnknownMethod\" {\n\t\t\t\t\thasStartTransientUnit = false\n\t\t\t\t\treturn hasStartTransientUnit\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Ensure the scope name we use doesn't exist. Use the Pid to\n\t\t// avoid collisions between multiple libcontainer users on a\n\t\t// single host.\n\t\tscope := fmt.Sprintf(\"libcontainer-%d-systemd-test-default-dependencies.scope\", os.Getpid())\n\t\ttestScopeExists := true\n\t\tfor i := 0; i <= testScopeWait; i++ {\n\t\t\tif _, err := theConn.StopUnit(scope, \"replace\", nil); err != nil {\n\t\t\t\tif dbusError, ok := err.(dbus.Error); ok {\n\t\t\t\t\tif strings.Contains(dbusError.Name, \"org.freedesktop.systemd1.NoSuchUnit\") {\n\t\t\t\t\t\ttestScopeExists = false\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\ttime.Sleep(time.Millisecond)\n\t\t}\n\n\t\t// Bail out if we can't kill this scope without testing for DefaultDependencies\n\t\tif testScopeExists {\n\t\t\treturn hasStartTransientUnit\n\t\t}\n\n\t\t// Assume StartTransientUnit on a scope allows DefaultDependencies\n\t\thasTransientDefaultDependencies = true\n\t\tddf := newProp(\"DefaultDependencies\", false)\n\t\tif _, err := theConn.StartTransientUnit(scope, \"replace\", []systemdDbus.Property{ddf}, nil); err != nil {\n\t\t\tif dbusError, ok := err.(dbus.Error); ok {\n\t\t\t\tif strings.Contains(dbusError.Name, \"org.freedesktop.DBus.Error.PropertyReadOnly\") {\n\t\t\t\t\thasTransientDefaultDependencies = false\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Not critical because of the stop unit logic above.\n\t\ttheConn.StopUnit(scope, \"replace\", nil)\n\t}\n\treturn hasStartTransientUnit\n}\n\nfunc getIfaceForUnit(unitName string) string {\n\tif strings.HasSuffix(unitName, \".scope\") {\n\t\treturn \"Scope\"\n\t}\n\tif strings.HasSuffix(unitName, \".service\") {\n\t\treturn \"Service\"\n\t}\n\treturn \"Unit\"\n}\n\nfunc (m *Manager) Apply(pid int) error {\n\tvar (\n\t\tc          = m.Cgroups\n\t\tunitName   = getUnitName(c)\n\t\tslice      = \"system.slice\"\n\t\tproperties []systemdDbus.Property\n\t)\n\n\tif c.Parent != \"\" {\n\t\tslice = c.Parent\n\t}\n\n\tproperties = append(properties,\n\t\tsystemdDbus.PropSlice(slice),\n\t\tsystemdDbus.PropDescription(\"docker container \"+c.Name),\n\t\tnewProp(\"PIDs\", []uint32{uint32(pid)}),\n\t)\n\n\t// Always enable accounting, this gets us the same behaviour as the fs implementation,\n\t// plus the kernel has some problems with joining the memory cgroup at a later time.\n\tproperties = append(properties,\n\t\tnewProp(\"MemoryAccounting\", true),\n\t\tnewProp(\"CPUAccounting\", true),\n\t\tnewProp(\"BlockIOAccounting\", true))\n\n\tif hasTransientDefaultDependencies {\n\t\tproperties = append(properties,\n\t\t\tnewProp(\"DefaultDependencies\", false))\n\t}\n\n\tif c.Resources.Memory != 0 {\n\t\tproperties = append(properties,\n\t\t\tnewProp(\"MemoryLimit\", uint64(c.Resources.Memory)))\n\t}\n\n\tif c.Resources.CpuShares != 0 {\n\t\tproperties = append(properties,\n\t\t\tnewProp(\"CPUShares\", uint64(c.Resources.CpuShares)))\n\t}\n\n\tif c.Resources.BlkioWeight != 0 {\n\t\tproperties = append(properties,\n\t\t\tnewProp(\"BlockIOWeight\", uint64(c.Resources.BlkioWeight)))\n\t}\n\n\t// We need to set kernel memory before processes join cgroup because\n\t// kmem.limit_in_bytes can only be set when the cgroup is empty.\n\t// And swap memory limit needs to be set after memory limit, only\n\t// memory limit is handled by systemd, so it's kind of ugly here.\n\tif c.Resources.KernelMemory > 0 {\n\t\tif err := setKernelMemory(c); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif _, err := theConn.StartTransientUnit(unitName, \"replace\", properties, nil); err != nil {\n\t\treturn err\n\t}\n\n\tif err := joinDevices(c, pid); err != nil {\n\t\treturn err\n\t}\n\n\t// TODO: CpuQuota and CpuPeriod not available in systemd\n\t// we need to manually join the cpu.cfs_quota_us and cpu.cfs_period_us\n\tif err := joinCpu(c, pid); err != nil {\n\t\treturn err\n\t}\n\n\t// TODO: MemoryReservation and MemorySwap not available in systemd\n\tif err := joinMemory(c, pid); err != nil {\n\t\treturn err\n\t}\n\n\t// we need to manually join the freezer, net_cls, net_prio and cpuset cgroup in systemd\n\t// because it does not currently support it via the dbus api.\n\tif err := joinFreezer(c, pid); err != nil {\n\t\treturn err\n\t}\n\n\tif err := joinNetPrio(c, pid); err != nil {\n\t\treturn err\n\t}\n\tif err := joinNetCls(c, pid); err != nil {\n\t\treturn err\n\t}\n\n\tif err := joinCpuset(c, pid); err != nil {\n\t\treturn err\n\t}\n\n\tif err := joinHugetlb(c, pid); err != nil {\n\t\treturn err\n\t}\n\n\tif err := joinPerfEvent(c, pid); err != nil {\n\t\treturn err\n\t}\n\t// FIXME: Systemd does have `BlockIODeviceWeight` property, but we got problem\n\t// using that (at least on systemd 208, see https://github.com/opencontainers/runc/libcontainer/pull/354),\n\t// so use fs work around for now.\n\tif err := joinBlkio(c, pid); err != nil {\n\t\treturn err\n\t}\n\n\tpaths := make(map[string]string)\n\tfor _, s := range subsystems {\n\t\tsubsystemPath, err := getSubsystemPath(m.Cgroups, s.Name())\n\t\tif err != nil {\n\t\t\t// Don't fail if a cgroup hierarchy was not found, just skip this subsystem\n\t\t\tif cgroups.IsNotFound(err) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\t\tpaths[s.Name()] = subsystemPath\n\t}\n\tm.Paths = paths\n\n\tif paths[\"cpu\"] != \"\" {\n\t\tif err := fs.CheckCpushares(paths[\"cpu\"], c.Resources.CpuShares); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc (m *Manager) Destroy() error {\n\tm.mu.Lock()\n\tdefer m.mu.Unlock()\n\ttheConn.StopUnit(getUnitName(m.Cgroups), \"replace\", nil)\n\tif err := cgroups.RemovePaths(m.Paths); err != nil {\n\t\treturn err\n\t}\n\tm.Paths = make(map[string]string)\n\treturn nil\n}\n\nfunc (m *Manager) GetPaths() map[string]string {\n\tm.mu.Lock()\n\tpaths := m.Paths\n\tm.mu.Unlock()\n\treturn paths\n}\n\nfunc writeFile(dir, file, data string) error {\n\t// Normally dir should not be empty, one case is that cgroup subsystem\n\t// is not mounted, we will get empty dir, and we want it fail here.\n\tif dir == \"\" {\n\t\treturn fmt.Errorf(\"no such directory for %s.\", file)\n\t}\n\treturn ioutil.WriteFile(filepath.Join(dir, file), []byte(data), 0700)\n}\n\nfunc join(c *configs.Cgroup, subsystem string, pid int) (string, error) {\n\tpath, err := getSubsystemPath(c, subsystem)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tif err := os.MkdirAll(path, 0755); err != nil {\n\t\treturn \"\", err\n\t}\n\tif err := writeFile(path, \"cgroup.procs\", strconv.Itoa(pid)); err != nil {\n\t\treturn \"\", err\n\t}\n\n\treturn path, nil\n}\n\nfunc joinCpu(c *configs.Cgroup, pid int) error {\n\tpath, err := getSubsystemPath(c, \"cpu\")\n\tif err != nil && !cgroups.IsNotFound(err) {\n\t\treturn err\n\t}\n\tif c.Resources.CpuQuota != 0 {\n\t\tif err = writeFile(path, \"cpu.cfs_quota_us\", strconv.FormatInt(c.Resources.CpuQuota, 10)); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tif c.Resources.CpuPeriod != 0 {\n\t\tif err = writeFile(path, \"cpu.cfs_period_us\", strconv.FormatInt(c.Resources.CpuPeriod, 10)); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tif c.Resources.CpuRtPeriod != 0 {\n\t\tif err = writeFile(path, \"cpu.rt_period_us\", strconv.FormatInt(c.Resources.CpuRtPeriod, 10)); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tif c.Resources.CpuRtRuntime != 0 {\n\t\tif err = writeFile(path, \"cpu.rt_runtime_us\", strconv.FormatInt(c.Resources.CpuRtRuntime, 10)); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc joinFreezer(c *configs.Cgroup, pid int) error {\n\tpath, err := join(c, \"freezer\", pid)\n\tif err != nil && !cgroups.IsNotFound(err) {\n\t\treturn err\n\t}\n\tfreezer, err := subsystems.Get(\"freezer\")\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn freezer.Set(path, c)\n}\n\nfunc joinNetPrio(c *configs.Cgroup, pid int) error {\n\tpath, err := join(c, \"net_prio\", pid)\n\tif err != nil && !cgroups.IsNotFound(err) {\n\t\treturn err\n\t}\n\tnetPrio, err := subsystems.Get(\"net_prio\")\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn netPrio.Set(path, c)\n}\n\nfunc joinNetCls(c *configs.Cgroup, pid int) error {\n\tpath, err := join(c, \"net_cls\", pid)\n\tif err != nil && !cgroups.IsNotFound(err) {\n\t\treturn err\n\t}\n\tnetcls, err := subsystems.Get(\"net_cls\")\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn netcls.Set(path, c)\n}\n\nfunc getSubsystemPath(c *configs.Cgroup, subsystem string) (string, error) {\n\tmountpoint, err := cgroups.FindCgroupMountpoint(subsystem)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tinitPath, err := cgroups.GetInitCgroupDir(subsystem)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tslice := \"system.slice\"\n\tif c.Parent != \"\" {\n\t\tslice = c.Parent\n\t}\n\n\treturn filepath.Join(mountpoint, initPath, slice, getUnitName(c)), nil\n}\n\nfunc (m *Manager) Freeze(state configs.FreezerState) error {\n\tpath, err := getSubsystemPath(m.Cgroups, \"freezer\")\n\tif err != nil {\n\t\treturn err\n\t}\n\tprevState := m.Cgroups.Resources.Freezer\n\tm.Cgroups.Resources.Freezer = state\n\tfreezer, err := subsystems.Get(\"freezer\")\n\tif err != nil {\n\t\treturn err\n\t}\n\terr = freezer.Set(path, m.Cgroups)\n\tif err != nil {\n\t\tm.Cgroups.Resources.Freezer = prevState\n\t\treturn err\n\t}\n\treturn nil\n}\n\nfunc (m *Manager) GetPids() ([]int, error) {\n\tpath, err := getSubsystemPath(m.Cgroups, \"devices\")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn cgroups.GetPids(path)\n}\n\nfunc (m *Manager) GetStats() (*cgroups.Stats, error) {\n\tm.mu.Lock()\n\tdefer m.mu.Unlock()\n\tstats := cgroups.NewStats()\n\tfor name, path := range m.Paths {\n\t\tsys, err := subsystems.Get(name)\n\t\tif err == errSubsystemDoesNotExist || !cgroups.PathExists(path) {\n\t\t\tcontinue\n\t\t}\n\t\tif err := sys.GetStats(path, stats); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn stats, nil\n}\n\nfunc (m *Manager) Set(container *configs.Config) error {\n\tfor name, path := range m.Paths {\n\t\tsys, err := subsystems.Get(name)\n\t\tif err == errSubsystemDoesNotExist || !cgroups.PathExists(path) {\n\t\t\tcontinue\n\t\t}\n\t\tif err := sys.Set(path, container.Cgroups); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc getUnitName(c *configs.Cgroup) string {\n\treturn fmt.Sprintf(\"%s-%s.scope\", c.ScopePrefix, c.Name)\n}\n\n// Atm we can't use the systemd device support because of two missing things:\n// * Support for wildcards to allow mknod on any device\n// * Support for wildcards to allow /dev/pts support\n//\n// The second is available in more recent systemd as \"char-pts\", but not in e.g. v208 which is\n// in wide use. When both these are available we will be able to switch, but need to keep the old\n// implementation for backwards compat.\n//\n// Note: we can't use systemd to set up the initial limits, and then change the cgroup\n// because systemd will re-write the device settings if it needs to re-apply the cgroup context.\n// This happens at least for v208 when any sibling unit is started.\nfunc joinDevices(c *configs.Cgroup, pid int) error {\n\tpath, err := join(c, \"devices\", pid)\n\t// Even if it's `not found` error, we'll return err because devices cgroup\n\t// is hard requirement for container security.\n\tif err != nil {\n\t\treturn err\n\t}\n\tdevices, err := subsystems.Get(\"devices\")\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn devices.Set(path, c)\n}\n\nfunc setKernelMemory(c *configs.Cgroup) error {\n\tpath, err := getSubsystemPath(c, \"memory\")\n\tif err != nil && !cgroups.IsNotFound(err) {\n\t\treturn err\n\t}\n\n\tif err := os.MkdirAll(path, 0755); err != nil {\n\t\treturn err\n\t}\n\n\tif c.Resources.KernelMemory > 0 {\n\t\terr = writeFile(path, \"memory.kmem.limit_in_bytes\", strconv.FormatInt(c.Resources.KernelMemory, 10))\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc joinMemory(c *configs.Cgroup, pid int) error {\n\tpath, err := getSubsystemPath(c, \"memory\")\n\tif err != nil && !cgroups.IsNotFound(err) {\n\t\treturn err\n\t}\n\n\t// -1 disables memoryswap\n\tif c.Resources.MemorySwap > 0 {\n\t\terr = writeFile(path, \"memory.memsw.limit_in_bytes\", strconv.FormatInt(c.Resources.MemorySwap, 10))\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tif c.Resources.MemoryReservation > 0 {\n\t\terr = writeFile(path, \"memory.soft_limit_in_bytes\", strconv.FormatInt(c.Resources.MemoryReservation, 10))\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tif c.Resources.OomKillDisable {\n\t\tif err := writeFile(path, \"memory.oom_control\", \"1\"); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif c.Resources.MemorySwappiness >= 0 && c.Resources.MemorySwappiness <= 100 {\n\t\terr = writeFile(path, \"memory.swappiness\", strconv.FormatInt(c.Resources.MemorySwappiness, 10))\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t} else if c.Resources.MemorySwappiness == -1 {\n\t\treturn nil\n\t} else {\n\t\treturn fmt.Errorf(\"invalid value:%d. valid memory swappiness range is 0-100\", c.Resources.MemorySwappiness)\n\t}\n\n\treturn nil\n}\n\n// systemd does not atm set up the cpuset controller, so we must manually\n// join it. Additionally that is a very finicky controller where each\n// level must have a full setup as the default for a new directory is \"no cpus\"\nfunc joinCpuset(c *configs.Cgroup, pid int) error {\n\tpath, err := getSubsystemPath(c, \"cpuset\")\n\tif err != nil && !cgroups.IsNotFound(err) {\n\t\treturn err\n\t}\n\n\ts := &fs.CpusetGroup{}\n\n\treturn s.ApplyDir(path, c, pid)\n}\n\n// `BlockIODeviceWeight` property of systemd does not work properly, and systemd\n// expects device path instead of major minor numbers, which is also confusing\n// for users. So we use fs work around for now.\nfunc joinBlkio(c *configs.Cgroup, pid int) error {\n\tpath, err := getSubsystemPath(c, \"blkio\")\n\tif err != nil {\n\t\treturn err\n\t}\n\t// systemd doesn't directly support this in the dbus properties\n\tif c.Resources.BlkioLeafWeight != 0 {\n\t\tif err := writeFile(path, \"blkio.leaf_weight\", strconv.FormatUint(uint64(c.Resources.BlkioLeafWeight), 10)); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tfor _, wd := range c.Resources.BlkioWeightDevice {\n\t\tif err := writeFile(path, \"blkio.weight_device\", wd.WeightString()); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := writeFile(path, \"blkio.leaf_weight_device\", wd.LeafWeightString()); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tfor _, td := range c.Resources.BlkioThrottleReadBpsDevice {\n\t\tif err := writeFile(path, \"blkio.throttle.read_bps_device\", td.String()); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tfor _, td := range c.Resources.BlkioThrottleWriteBpsDevice {\n\t\tif err := writeFile(path, \"blkio.throttle.write_bps_device\", td.String()); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tfor _, td := range c.Resources.BlkioThrottleReadIOPSDevice {\n\t\tif err := writeFile(path, \"blkio.throttle.read_iops_device\", td.String()); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tfor _, td := range c.Resources.BlkioThrottleWriteIOPSDevice {\n\t\tif err := writeFile(path, \"blkio.throttle.write_iops_device\", td.String()); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc joinHugetlb(c *configs.Cgroup, pid int) error {\n\tpath, err := join(c, \"hugetlb\", pid)\n\tif err != nil && !cgroups.IsNotFound(err) {\n\t\treturn err\n\t}\n\thugetlb, err := subsystems.Get(\"hugetlb\")\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn hugetlb.Set(path, c)\n}\n\nfunc joinPerfEvent(c *configs.Cgroup, pid int) error {\n\tpath, err := join(c, \"perf_event\", pid)\n\tif err != nil && !cgroups.IsNotFound(err) {\n\t\treturn err\n\t}\n\tperfEvent, err := subsystems.Get(\"perf_event\")\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn perfEvent.Set(path, c)\n}\n", "idx": 3, "id": 6704, "msg": "", "proj": "opencontainers-runc", "lang": "go"}
{"patch": "@@ -3,16 +3,16 @@ package identity\n import (\n \t\"errors\"\n \t\"testing\"\n-\n \t\"github.com/ethereum/go-ethereum/accounts\"\n \t\"github.com/stretchr/testify/assert\"\n+\t\"github.com/ethereum/go-ethereum/accounts/keystore\"\n )\n \n func newManager(accountValue string) *identityManager {\n \treturn &identityManager{\n \t\tkeystoreManager: &keyStoreFake{\n \t\t\tAccountsMock: []accounts.Account{\n-\t\t\t\tidentityToAccount(accountValue),\n+\t\t\t\tidentityToAccount(FromAddress(accountValue)),\n \t\t\t},\n \t\t},\n \t}", "y": 1, "oldf": "package identity\n\nimport (\n\t\"errors\"\n\t\"testing\"\n\n\t\"github.com/ethereum/go-ethereum/accounts\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc newManager(accountValue string) *identityManager {\n\treturn &identityManager{\n\t\tkeystoreManager: &keyStoreFake{\n\t\t\tAccountsMock: []accounts.Account{\n\t\t\t\tidentityToAccount(accountValue),\n\t\t\t},\n\t\t},\n\t}\n}\n\nfunc newManagerWithError(errorMock error) *identityManager {\n\treturn &identityManager{\n\t\tkeystoreManager: &keyStoreFake{\n\t\t\tErrorMock: errorMock,\n\t\t},\n\t}\n}\n\nfunc Test_CreateNewIdentity(t *testing.T) {\n\tmanager := newManager(\"0x000000000000000000000000000000000000000A\")\n\tidentity, err := manager.CreateNewIdentity(\"\")\n\n\tassert.NoError(t, err)\n\tassert.Equal(t, identity, FromAddress(\"0x000000000000000000000000000000000000bEEF\"))\n\tassert.Len(t, manager.keystoreManager.Accounts(), 2)\n}\n\nfunc Test_CreateNewIdentityError(t *testing.T) {\n\tim := newManagerWithError(errors.New(\"identity create failed\"))\n\tidentity, err := im.CreateNewIdentity(\"\")\n\n\tassert.EqualError(t, err, \"identity create failed\")\n\tassert.Empty(t, identity.Address)\n}\n\nfunc Test_GetIdentities(t *testing.T) {\n\tmanager := newManager(\"0x000000000000000000000000000000000000000A\")\n\n\tassert.Equal(\n\t\tt,\n\t\t[]Identity{\n\t\t\tFromAddress(\"0x000000000000000000000000000000000000000A\"),\n\t\t},\n\t\tmanager.GetIdentities(),\n\t)\n}\n\nfunc Test_GetIdentity(t *testing.T) {\n\tmanager := newManager(\"0x000000000000000000000000000000000000000A\")\n\n\tidentity, err := manager.GetIdentity(\"0x000000000000000000000000000000000000000A\")\n\tassert.Nil(t, err)\n\tassert.Equal(\n\t\tt,\n\t\tFromAddress(\"0x000000000000000000000000000000000000000A\"),\n\t\tidentity,\n\t)\n\n\tidentity, err = manager.GetIdentity(\"0x000000000000000000000000000000000000000a\")\n\tassert.Nil(t, err)\n\tassert.Equal(\n\t\tt,\n\t\tFromAddress(\"0x000000000000000000000000000000000000000A\"),\n\t\tidentity,\n\t)\n\n\tidentity, err = manager.GetIdentity(\"0x000000000000000000000000000000000000000B\")\n\tassert.Error(\n\t\tt,\n\t\terr,\n\t\terrors.New(\"identity not found\"),\n\t)\n}\n\nfunc Test_HasIdentity(t *testing.T) {\n\tmanager := newManager(\"0x000000000000000000000000000000000000000A\")\n\n\tassert.True(t, manager.HasIdentity(\"0x000000000000000000000000000000000000000A\"))\n\tassert.True(t, manager.HasIdentity(\"0x000000000000000000000000000000000000000a\"))\n\tassert.False(t, manager.HasIdentity(\"0x000000000000000000000000000000000000000B\"))\n}\n", "idx": 1, "id": 9896, "msg": "This unit was using mocked keystore, we should not need Ethereum library and real keystore with filesystem.", "proj": "mysteriumnetwork-node", "lang": "go"}
{"patch": "@@ -0,0 +1,27 @@\n+// +build !baremetal,!js,!wasi\n+\n+// TODO: Move this into os_test.go (as upstream has it) when wasi supports chmod\n+\n+package os_test\n+\n+import (\n+\t. \"os\"\n+\t\"runtime\"\n+\t\"testing\"\n+)\n+\n+func TestChmod(t *testing.T) {\n+\tf := newFile(\"TestChmod\", t)\n+\tdefer Remove(f.Name())\n+\tdefer f.Close()\n+\t// Creation mode is read write\n+\n+\tfm := FileMode(0456)\n+\tif runtime.GOOS == \"windows\" {\n+\t\tfm = FileMode(0444) // read-only file\n+\t}\n+\tif err := Chmod(f.Name(), fm); err != nil {\n+\t\tt.Fatalf(\"chmod %s %#o: %s\", f.Name(), fm, err)\n+\t}\n+\tcheckMode(t, f.Name(), fm)\n+}", "y": 1, "oldf": "", "idx": 1, "id": 13963, "msg": "Should this keep the license header from `os_test.go`?", "proj": "tinygo-org-tinygo", "lang": "go"}
{"patch": "@@ -25,7 +25,21 @@ module RSpec\n         @configuration.reporter.report(@world.example_count, @configuration.randomize? ? @configuration.seed : nil) do |reporter|\n           begin\n             @configuration.run_hook(:before, :suite)\n-            @world.example_groups.ordered.map {|g| g.run(reporter)}.all? ? 0 : @configuration.failure_exit_code\n+            unless @configuration.stress_test\n+              @world.example_groups.ordered.map {|g| g.run(reporter)}.all?\n+            else\n+              success = true\n+              random = Random.new(@configuration.seed)\n+              all_examples = @world.all_examples\n+              end_time = Time.now + @configuration.stress_test\n+              while Time.now < end_time\n+                example = all_examples.sample(random: random)\n+                chain_to_execute = [example] + example.example_group.parent_groups.dup\n+                success &= chain_to_execute.pop.run(reporter, chain_to_execute)\n+                break if RSpec.wants_to_quit\n+              end\n+              success\n+            end ? 0 : @configuration.failure_exit_code\n           ensure\n             @configuration.run_hook(:after, :suite)\n           end", "y": 1, "oldf": "module RSpec\n  module Core\n    class CommandLine\n      def initialize(options, configuration=RSpec::configuration, world=RSpec::world)\n        if Array === options\n          options = ConfigurationOptions.new(options)\n          options.parse_options\n        end\n        @options       = options\n        @configuration = configuration\n        @world         = world\n      end\n\n      # Configures and runs a suite\n      #\n      # @param [IO] err\n      # @param [IO] out\n      def run(err, out)\n        @configuration.error_stream = err\n        @configuration.output_stream ||= out\n        @options.configure(@configuration)\n        @configuration.load_spec_files\n        @world.announce_filters\n\n        @configuration.reporter.report(@world.example_count, @configuration.randomize? ? @configuration.seed : nil) do |reporter|\n          begin\n            @configuration.run_hook(:before, :suite)\n            @world.example_groups.ordered.map {|g| g.run(reporter)}.all? ? 0 : @configuration.failure_exit_code\n          ensure\n            @configuration.run_hook(:after, :suite)\n          end\n        end\n      end\n    end\n  end\nend\n", "idx": 1, "id": 9179, "msg": "I'm not sure I like this, can you explain why you are passing in `chain_to_execute` rather than re-randomising and running the whole suite as normal? You might also want to directly reference `::RSpec::Core::Time`, which is more likely not to be polluted.", "proj": "rspec-rspec-core", "lang": "rb"}
{"patch": "@@ -254,6 +254,10 @@ func (r fakeRandSrc) Randomness(_ context.Context, _ acrypto.DomainSeparationTag\n \n type ValidationApplier struct{}\n \n+func (a *ValidationApplier) ApplyTipSetMessages(state vstate.VMWrapper, blocks []vtypes.BlockMessagesInfo, epoch abi.ChainEpoch, rnd vstate.RandomnessSource) ([]vtypes.MessageReceipt, error) {\n+\tpanic(\"implement me\")\n+}\n+\n func (a *ValidationApplier) ApplyMessage(context *vtypes.ExecutionContext, state vstate.VMWrapper, msg *vtypes.Message) (vtypes.MessageReceipt, error) {\n \tst := state.(*ValidationVMWrapper)\n ", "y": 0, "oldf": "package vmcontext\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"math/rand\"\n\n\tvtypes \"github.com/filecoin-project/chain-validation/chain/types\"\n\tvstate \"github.com/filecoin-project/chain-validation/state\"\n\t\"github.com/filecoin-project/go-address\"\n\t\"github.com/filecoin-project/go-crypto\"\n\t\"github.com/filecoin-project/specs-actors/actors/abi\"\n\t\"github.com/filecoin-project/specs-actors/actors/abi/big\"\n\t\"github.com/filecoin-project/specs-actors/actors/builtin\"\n\tinit_ \"github.com/filecoin-project/specs-actors/actors/builtin/init\"\n\tacrypto \"github.com/filecoin-project/specs-actors/actors/crypto\"\n\t\"github.com/filecoin-project/specs-actors/actors/runtime\"\n\t\"github.com/filecoin-project/specs-actors/actors/util/adt\"\n\t\"github.com/ipfs/go-cid\"\n\t\"github.com/ipfs/go-datastore\"\n\tblockstore \"github.com/ipfs/go-ipfs-blockstore\"\n\n\tffi \"github.com/filecoin-project/filecoin-ffi\"\n\t\"github.com/filecoin-project/go-filecoin/internal/pkg/cborutil\"\n\tgfcrypto \"github.com/filecoin-project/go-filecoin/internal/pkg/crypto\"\n\t\"github.com/filecoin-project/go-filecoin/internal/pkg/enccid\"\n\t\"github.com/filecoin-project/go-filecoin/internal/pkg/types\"\n\t\"github.com/filecoin-project/go-filecoin/internal/pkg/vm/actor\"\n\tgfcBuiltin \"github.com/filecoin-project/go-filecoin/internal/pkg/vm/actor/builtin\"\n\t\"github.com/filecoin-project/go-filecoin/internal/pkg/vm/internal/storage\"\n\t\"github.com/filecoin-project/go-filecoin/internal/pkg/vm/state\"\n)\n\nvar _ vstate.Factories = &Factories{}\nvar _ vstate.VMWrapper = (*ValidationVMWrapper)(nil)\nvar _ vstate.Applier = (*ValidationApplier)(nil)\nvar _ vstate.KeyManager = (*KeyManager)(nil)\n\ntype Factories struct {\n\tvstate.Applier\n}\n\nfunc NewFactories() *Factories {\n\tfactory := &Factories{&ValidationApplier{}}\n\treturn factory\n}\n\nfunc (f *Factories) NewState() vstate.VMWrapper {\n\treturn NewState()\n}\n\nfunc (f *Factories) NewKeyManager() vstate.KeyManager {\n\treturn newKeyManager()\n}\n\nfunc (f *Factories) NewValidationConfig() vstate.ValidationConfig {\n\treturn &ValidationConfig{\n\t\t// TODO enable this when ready https://github.com/filecoin-project/go-filecoin/issues/3801\n\t\ttrackGas:         false,\n\t\tcheckExitCode:    true,\n\t\tcheckReturnValue: true,\n\t}\n}\n\n//\n// ValidationConfig\n//\n\ntype ValidationConfig struct {\n\ttrackGas         bool\n\tcheckExitCode    bool\n\tcheckReturnValue bool\n}\n\nfunc (v ValidationConfig) ValidateGas() bool {\n\treturn v.trackGas\n}\n\nfunc (v ValidationConfig) ValidateExitCode() bool {\n\treturn v.checkExitCode\n}\n\nfunc (v ValidationConfig) ValidateReturnValue() bool {\n\treturn v.checkReturnValue\n}\n\n//\n// VMWrapper\n//\n\nfunc NewState() *ValidationVMWrapper {\n\tbs := blockstore.NewBlockstore(datastore.NewMapDatastore())\n\tcst := cborutil.NewIpldStore(bs)\n\tvmstrg := storage.NewStorage(bs)\n\tvm := NewVM(gfcBuiltin.DefaultActors, &vmstrg, state.NewState(cst))\n\treturn &ValidationVMWrapper{\n\t\tvm: &vm,\n\t}\n}\n\ntype ValidationVMWrapper struct {\n\tvm *VM\n}\n\n// Root implements ValidationVMWrapper.\nfunc (w *ValidationVMWrapper) Root() cid.Cid {\n\troot, dirty := w.vm.state.Root()\n\tif !dirty {\n\t\treturn root\n\t}\n\n\troot, err := w.vm.state.Commit(w.vm.context)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn root\n}\n\n// Store implements ValidationVMWrapper.\nfunc (w *ValidationVMWrapper) Store() adt.Store {\n\treturn w.vm.ContextStore()\n}\n\n// Actor implements ValidationVMWrapper.\nfunc (w *ValidationVMWrapper) Actor(addr address.Address) (vstate.Actor, error) {\n\tidAddr, found := w.vm.normalizeFrom(addr)\n\tif !found {\n\t\treturn nil, fmt.Errorf(\"failed to normalize address: %s\", addr)\n\t}\n\n\ta, found, err := w.vm.state.GetActor(w.vm.context, idAddr)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif !found {\n\t\treturn nil, fmt.Errorf(\"actor not found\")\n\t}\n\treturn &actorWrapper{a}, nil\n}\n\n// CreateActor implements ValidationVMWrapper.\nfunc (w *ValidationVMWrapper) CreateActor(code cid.Cid, addr address.Address, balance abi.TokenAmount, newState runtime.CBORMarshaler) (vstate.Actor, address.Address, error) {\n\tidAddr := addr\n\tif addr.Protocol() != address.ID {\n\t\t// go through init to register\n\t\tinitActorEntry, found, err := w.vm.state.GetActor(w.vm.context, builtin.InitActorAddr)\n\t\tif err != nil {\n\t\t\treturn nil, address.Undef, err\n\t\t}\n\t\tif !found {\n\t\t\treturn nil, address.Undef, fmt.Errorf(\"actor not found\")\n\t\t}\n\n\t\t// get a view into the actor state\n\t\tvar initState init_.State\n\t\tif err := w.vm.store.Get(initActorEntry.Head.Cid, &initState); err != nil {\n\t\t\treturn nil, address.Undef, err\n\t\t}\n\n\t\t// add addr to inits map\n\t\tidAddr, err = initState.MapAddressToNewID(w.vm.ContextStore(), addr)\n\t\tif err != nil {\n\t\t\treturn nil, address.Undef, err\n\t\t}\n\n\t\t// persist the init actor state\n\t\tinitHead, err := w.vm.store.Put(&initState)\n\t\tif err != nil {\n\t\t\treturn nil, address.Undef, err\n\t\t}\n\t\tinitActorEntry.Head = enccid.NewCid(initHead)\n\t\tif err := w.vm.state.SetActor(w.vm.context, builtin.InitActorAddr, initActorEntry); err != nil {\n\t\t\treturn nil, address.Undef, err\n\t\t}\n\t\t// persist state below\n\t}\n\n\t// create actor on state stree\n\n\t// store newState\n\thead, err := w.vm.store.Put(newState)\n\tif err != nil {\n\t\treturn nil, address.Undef, err\n\t}\n\n\t// create and store actor object\n\ta := &actor.Actor{\n\t\tCode:    enccid.NewCid(code),\n\t\tHead:    enccid.NewCid(head),\n\t\tBalance: balance,\n\t}\n\tif err := w.vm.state.SetActor(w.vm.context, idAddr, a); err != nil {\n\t\treturn nil, address.Undef, err\n\t}\n\n\tif err := w.PersistChanges(); err != nil {\n\t\treturn nil, address.Undef, err\n\t}\n\n\treturn &actorWrapper{a}, idAddr, nil\n}\n\n// SetActorState implements ValidationVMWrapper.\nfunc (w *ValidationVMWrapper) SetActorState(addr address.Address, balance big.Int, state runtime.CBORMarshaler) (vstate.Actor, error) {\n\tidAddr, ok := w.vm.normalizeFrom(addr)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"actor not found\")\n\t}\n\n\ta, found, err := w.vm.state.GetActor(w.vm.context, idAddr)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif !found {\n\t\treturn nil, fmt.Errorf(\"actor not found\")\n\t}\n\t// store state\n\thead, err := w.vm.store.Put(state)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\t// update fields\n\ta.Head = enccid.NewCid(head)\n\ta.Balance = balance\n\n\tif err := w.vm.state.SetActor(w.vm.context, idAddr, a); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := w.PersistChanges(); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &actorWrapper{a}, nil\n}\n\nfunc (w *ValidationVMWrapper) PersistChanges() error {\n\tif _, err := w.vm.commit(); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n\n//\n// Applier\n//\n\ntype fakeRandSrc struct {\n}\n\nfunc (r fakeRandSrc) Randomness(_ context.Context, _ acrypto.DomainSeparationTag, _ abi.ChainEpoch, _ []byte) (abi.Randomness, error) {\n\tpanic(\"implement me\")\n}\n\ntype ValidationApplier struct{}\n\nfunc (a *ValidationApplier) ApplyMessage(context *vtypes.ExecutionContext, state vstate.VMWrapper, msg *vtypes.Message) (vtypes.MessageReceipt, error) {\n\tst := state.(*ValidationVMWrapper)\n\n\t// set epoch\n\t// Note: this would have normally happened during `ApplyTipset()`\n\tst.vm.currentEpoch = context.Epoch\n\n\t// map message\n\t// Dragons: fix after cleaning up our msg\n\tourmsg := &types.UnsignedMessage{\n\t\tTo:         msg.To,\n\t\tFrom:       msg.From,\n\t\tCallSeqNum: uint64(msg.CallSeqNum),\n\t\tValue:      msg.Value,\n\t\tMethod:     msg.Method,\n\t\tParams:     msg.Params,\n\t\tGasPrice:   msg.GasPrice,\n\t\tGasLimit:   types.GasUnits(msg.GasLimit),\n\t}\n\n\t// invoke vm\n\tourreceipt, _, _ := st.vm.applyMessage(ourmsg, ourmsg.OnChainLen(), &fakeRandSrc{})\n\n\t// commit and persist changes\n\t// Note: this is not done on production for each msg\n\tif err := st.PersistChanges(); err != nil {\n\t\treturn vtypes.MessageReceipt{}, err\n\t}\n\n\t// map receipt\n\treceipt := vtypes.MessageReceipt{\n\t\tExitCode:    ourreceipt.ExitCode,\n\t\tReturnValue: ourreceipt.ReturnValue,\n\t\tGasUsed:     big.Int(ourreceipt.GasUsed),\n\t}\n\n\treturn receipt, nil\n}\n\n//\n// KeyManager\n//\n\ntype KeyManager struct {\n\t// Private keys by address\n\tkeys map[address.Address]*gfcrypto.KeyInfo\n\n\t// Seed for deterministic secp key generation.\n\tsecpSeed int64\n\t// Seed for deterministic bls key generation.\n\tblsSeed int64 // nolint: structcheck\n}\n\nfunc newKeyManager() *KeyManager {\n\treturn &KeyManager{\n\t\tkeys:     make(map[address.Address]*gfcrypto.KeyInfo),\n\t\tsecpSeed: 0,\n\t}\n}\n\nfunc (k *KeyManager) NewSECP256k1AccountAddress() address.Address {\n\tsecpKey := k.newSecp256k1Key()\n\taddr, err := secpKey.Address()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tk.keys[addr] = secpKey\n\treturn addr\n}\n\nfunc (k *KeyManager) NewBLSAccountAddress() address.Address {\n\tblsKey := k.newBLSKey()\n\taddr, err := blsKey.Address()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tk.keys[addr] = blsKey\n\treturn addr\n}\n\nfunc (k *KeyManager) Sign(addr address.Address, data []byte) (acrypto.Signature, error) {\n\tki, ok := k.keys[addr]\n\tif !ok {\n\t\treturn acrypto.Signature{}, fmt.Errorf(\"unknown address %v\", addr)\n\t}\n\treturn gfcrypto.Sign(data, ki.PrivateKey, ki.SigType)\n}\n\nfunc (k *KeyManager) newSecp256k1Key() *gfcrypto.KeyInfo {\n\trandSrc := rand.New(rand.NewSource(k.secpSeed))\n\tprv, err := crypto.GenerateKeyFromSeed(randSrc)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tk.secpSeed++\n\treturn &gfcrypto.KeyInfo{\n\t\tSigType:    acrypto.SigTypeSecp256k1,\n\t\tPrivateKey: prv,\n\t}\n}\n\nfunc (k *KeyManager) newBLSKey() *gfcrypto.KeyInfo {\n\t// FIXME: bls needs deterministic key generation\n\t//sk := ffi.PrivateKeyGenerate(s.blsSeed)\n\t// s.blsSeed++\n\tsk := ffi.PrivateKeyGenerate()\n\treturn &gfcrypto.KeyInfo{\n\t\tSigType:    acrypto.SigTypeBLS,\n\t\tPrivateKey: sk[:],\n\t}\n}\n\n//\n// Actor\n//\n\ntype actorWrapper struct {\n\t*actor.Actor\n}\n\nfunc (a *actorWrapper) Code() cid.Cid {\n\treturn a.Actor.Code.Cid\n}\nfunc (a *actorWrapper) Head() cid.Cid {\n\treturn a.Actor.Head.Cid\n}\nfunc (a *actorWrapper) CallSeqNum() int64 {\n\treturn int64(a.Actor.CallSeqNum)\n}\nfunc (a *actorWrapper) Balance() abi.TokenAmount {\n\treturn a.Actor.Balance\n}\n", "idx": 2, "id": 23059, "msg": "", "proj": "filecoin-project-venus", "lang": "go"}
{"patch": "@@ -29,11 +29,37 @@ namespace Nethermind.Baseline.Test\n         public void Can_set()\n         {\n             BaselineConfig config = new BaselineConfig();\n+            var dbCacheIndexAndFilterBlocks = true;\n+            uint dbBlockCacheSize = 100;\n+            uint dbWriteBufferSize = 300;\n+            uint dbWriteBufferNumber = 3;\n             config.Enabled.Should().BeFalse();\n             config.Enabled = true;\n             config.Enabled.Should().BeTrue();\n             config.Enabled = false;\n             config.Enabled.Should().BeFalse();\n+\n+            config.BaselineTreeDbCacheIndexAndFilterBlocks.Should().BeFalse();\n+            config.BaselineTreeMetadataDbCacheIndexAndFilterBlocks.Should().BeFalse();\n+            config.BaselineTreeDbCacheIndexAndFilterBlocks = dbCacheIndexAndFilterBlocks;\n+            config.BaselineTreeMetadataDbCacheIndexAndFilterBlocks = dbCacheIndexAndFilterBlocks;\n+            config.BaselineTreeDbCacheIndexAndFilterBlocks.Should().BeTrue();\n+            config.BaselineTreeMetadataDbCacheIndexAndFilterBlocks.Should().BeTrue();\n+\n+            config.BaselineTreeDbBlockCacheSize = dbBlockCacheSize;\n+            config.BaselineTreeMetadataDbBlockCacheSize = dbBlockCacheSize;\n+            config.BaselineTreeDbCacheIndexAndFilterBlocks.Should().Equals(dbBlockCacheSize);\n+            config.BaselineTreeMetadataDbCacheIndexAndFilterBlocks.Should().Equals(dbBlockCacheSize);\n+\n+            config.BaselineTreeDbWriteBufferSize = dbWriteBufferSize;\n+            config.BaselineTreeMetadataDbWriteBufferSize = dbWriteBufferSize;\n+            config.BaselineTreeDbWriteBufferSize.Should().Equals(dbWriteBufferSize);\n+            config.BaselineTreeMetadataDbWriteBufferSize.Should().Equals(dbWriteBufferSize);\n+\n+            config.BaselineTreeDbWriteBufferNumber = dbWriteBufferNumber;\n+            config.BaselineTreeMetadataDbWriteBufferNumber = dbWriteBufferNumber;\n+            config.BaselineTreeDbWriteBufferNumber.Should().Equals(dbWriteBufferNumber);\n+            config.BaselineTreeMetadataDbWriteBufferNumber.Should().Equals(dbWriteBufferNumber);\n         }\n         \n         [TestCase(\"baseline\", true)]", "y": 1, "oldf": "//  Copyright (c) 2018 Demerzel Solutions Limited\n//  This file is part of the Nethermind library.\n// \n//  The Nethermind library is free software: you can redistribute it and/or modify\n//  it under the terms of the GNU Lesser General Public License as published by\n//  the Free Software Foundation, either version 3 of the License, or\n//  (at your option) any later version.\n// \n//  The Nethermind library is distributed in the hope that it will be useful,\n//  but WITHOUT ANY WARRANTY; without even the implied warranty of\n//  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n//  GNU Lesser General Public License for more details.\n// \n//  You should have received a copy of the GNU Lesser General Public License\n//  along with the Nethermind. If not, see <http://www.gnu.org/licenses/>.\n\nusing System.Collections.Generic;\nusing FluentAssertions;\nusing Nethermind.Baseline.Config;\nusing Nethermind.Config.Test;\nusing NUnit.Framework;\n\nnamespace Nethermind.Baseline.Test\n{\n    [TestFixture]\n    public class BaselineConfigTests : ConfigFileTestsBase\n    {\n        [Test]\n        public void Can_set()\n        {\n            BaselineConfig config = new BaselineConfig();\n            config.Enabled.Should().BeFalse();\n            config.Enabled = true;\n            config.Enabled.Should().BeTrue();\n            config.Enabled = false;\n            config.Enabled.Should().BeFalse();\n        }\n        \n        [TestCase(\"baseline\", true)]\n        [TestCase(\"spaceneth\", true)]\n        [TestCase(\"^baseline ^spaceneth\", false)]\n        public void Baseline_is_disabled_by_default(string configWildcard, bool enabled)\n        {\n            Test<IBaselineConfig, bool>(configWildcard, c => c.Enabled, enabled);\n        }\n        \n        protected override IEnumerable<string> Configs { get; } = new HashSet<string>\n        {\n            \"ropsten_archive.cfg\",\n            \"ropsten_beam.cfg\",\n            \"ropsten.cfg\",\n            \"rinkeby_archive.cfg\",\n            \"rinkeby_beam.cfg\",\n            \"rinkeby.cfg\",\n            \"goerli_archive.cfg\",\n            \"goerli_beam.cfg\",\n            \"goerli.cfg\",\n            \"kovan.cfg\",\n            \"kovan_archive.cfg\",\n            \"mainnet_archive.cfg\",\n            \"mainnet_beam.cfg\",\n            \"mainnet.cfg\",\n            \"sokol.cfg\",\n            \"sokol_archive.cfg\",\n            \"sokol_validator.cfg\",\n            \"poacore.cfg\",\n            \"poacore_archive.cfg\",\n            \"poacore_beam.cfg\",\n            \"poacore_validator.cfg\",\n            \"xdai.cfg\",\n            \"xdai_archive.cfg\",\n            \"xdai_validator.cfg\",\n            \"spaceneth.cfg\",\n            \"spaceneth_persistent.cfg\",\n            \"volta.cfg\",\n            \"volta_archive.cfg\",\n            \"volta.cfg\",\n            \"volta_archive.cfg\",\n            \"energyweb.cfg\",\n            \"energyweb_archive.cfg\",\n            \"baseline.cfg\",\n            \"baseline_ropsten.cfg\"\n        };\n    }\n}\n", "idx": 1, "id": 24737, "msg": "can we get rid of this and hardcode it / read it - I do not want user to have to set this up", "proj": "NethermindEth-nethermind", "lang": ".cs"}
{"patch": "@@ -0,0 +1,39 @@\n+<?php\n+\n+/**\n+ * Copyright \u00a9 Bold Brand Commerce Sp. z o.o. All rights reserved.\n+ * See LICENSE.txt for license details.\n+ */\n+\n+declare(strict_types = 1);\n+\n+namespace Ergonode\\Multimedia\\Tests\\Domain\\ValueObject;\n+\n+use Ergonode\\Multimedia\\Domain\\ValueObject\\ImageFormat;\n+use PHPUnit\\Framework\\TestCase;\n+\n+/**\n+ */\n+class ImageFormatTest extends TestCase\n+{\n+    /**\n+     */\n+    public function testValueCreation(): void\n+    {\n+        $format = 'jpg';\n+\n+        $valueObject = new ImageFormat($format);\n+\n+        $this->assertSame($format, $valueObject->getFormat());\n+    }\n+\n+    /**\n+     * @expectedException \\InvalidArgumentException\n+     */\n+    public function testNotValidFormat(): void\n+    {\n+        $format = 'format';\n+\n+        $valueObject = new ImageFormat($format);\n+    }\n+}", "y": 1, "oldf": "", "idx": 1, "id": 8470, "msg": "test all supported extensions, data provider should be handy.", "proj": "ergonode-backend", "lang": "php"}
{"patch": "@@ -40,6 +40,10 @@ public abstract class DateTimeUtils {\n     }\n   }\n \n+  public static String withTimezone(Date date) {\n+      return DATE_FORMAT_WITH_TIMEZONE.format(date);\n+  }\n+\n   public static Date updateTime(Date now, Date newTime) {\n     Calendar c = Calendar.getInstance();\n     c.setTime(now);", "y": 1, "oldf": "/*\n * Copyright \u00a9 2013-2018 camunda services GmbH and various authors (info@camunda.com)\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.camunda.bpm.engine.rest.util;\n\nimport java.text.ParseException;\nimport java.text.SimpleDateFormat;\nimport java.util.Calendar;\nimport java.util.Date;\n\npublic abstract class DateTimeUtils {\n\n  public static final SimpleDateFormat DATE_FORMAT_WITHOUT_TIMEZONE = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss\");\n  public static final SimpleDateFormat DATE_FORMAT_WITH_TIMEZONE = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSSZ\");\n\n  /**\n   * Converts date string without timezone to the one with timezone.\n   * @param dateString\n   * @return\n   */\n  public static String withTimezone(String dateString) {\n    final Date parse;\n    try {\n      parse = DATE_FORMAT_WITHOUT_TIMEZONE.parse(dateString);\n      return DATE_FORMAT_WITH_TIMEZONE.format(parse);\n    } catch (ParseException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n  public static Date updateTime(Date now, Date newTime) {\n    Calendar c = Calendar.getInstance();\n    c.setTime(now);\n    Calendar newTimeCalendar = Calendar.getInstance();\n    newTimeCalendar.setTime(newTime);\n    c.set(Calendar.ZONE_OFFSET, newTimeCalendar.get(Calendar.ZONE_OFFSET));\n    c.set(Calendar.DST_OFFSET, newTimeCalendar.get(Calendar.DST_OFFSET));\n    c.set(Calendar.HOUR_OF_DAY, newTimeCalendar.get(Calendar.HOUR_OF_DAY));\n    c.set(Calendar.MINUTE, newTimeCalendar.get(Calendar.MINUTE));\n    c.set(Calendar.SECOND, newTimeCalendar.get(Calendar.SECOND));\n    c.set(Calendar.MILLISECOND, newTimeCalendar.get(Calendar.MILLISECOND));\n    return c.getTime();\n  }\n\n  public static Date addDays(Date date, int amount) {\n    Calendar c = Calendar.getInstance();\n    c.setTime(date);\n    c.add(Calendar.DATE, amount);\n    return c.getTime();\n  }\n}\n", "idx": 1, "id": 9215, "msg": "I would also call this method in the `return` statement of the `withTimezone(String dateString)` method above (line 37), so we don't have duplicate methods.", "proj": "camunda-camunda-bpm-platform", "lang": "java"}
{"patch": "@@ -18,12 +18,18 @@ import (\n \t\"go.opentelemetry.io/api/core\"\n )\n \n-// Event interface provides methods to retrieve Event properties.\n-type Event interface {\n+// Event describes an event with a message string and set of attributes.\n+type Event struct {\n+\tmessage string\n+\tattr    []core.KeyValue\n+}\n \n-\t// Message interface retrieves message string of the Event.\n-\tMessage() string\n+// Message retrieves message string of the Event.\n+func (e *Event) Message() string {\n+\treturn e.message\n+}\n \n-\t// Attributes interface returns a copy of attributes associated with the Event.\n-\tAttributes() []core.KeyValue\n+// Attributes returns a copy of attributes associated with the Event.\n+func (e *Event) Attributes() []core.KeyValue {\n+\treturn e.attr\n }", "y": 1, "oldf": "// Copyright 2019, OpenTelemetry Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage event\n\nimport (\n\t\"go.opentelemetry.io/api/core\"\n)\n\n// Event interface provides methods to retrieve Event properties.\ntype Event interface {\n\n\t// Message interface retrieves message string of the Event.\n\tMessage() string\n\n\t// Attributes interface returns a copy of attributes associated with the Event.\n\tAttributes() []core.KeyValue\n}\n", "idx": 1, "id": 9755, "msg": "This should be a copy of attrs so the Event is immutable.", "proj": "open-telemetry-opentelemetry-go", "lang": "go"}
{"patch": "@@ -0,0 +1,26 @@\n+package langserver\n+\n+import (\n+\t\"context\"\n+\t\"core\"\n+\t\"path\"\n+\t\"testing\"\n+\t\"tools/build_langserver/lsp\"\n+\n+)\n+\n+func TestGetHoverContent(t *testing.T) {\n+\tcore.FindRepoRoot()\n+\tctx := context.Background()\n+\tfilepath := path.Join(core.RepoRoot, \"tools/build_langserver/langserver/BUILD\")\n+\turi := lsp.DocumentURI(\"file://\" + filepath)\n+\tanalyzer := newAnalyzer()\n+\tposition := lsp.Position{\n+\t\tLine: 18,\n+\t\tCharacter: 3,\n+\t}\n+\n+\t_, err := getHoverContent(ctx, analyzer, uri, position)\n+\tt.Log(err)\n+\tt.Log(filepath)\n+}", "y": 1, "oldf": "", "idx": 1, "id": 8452, "msg": "this is just logging things, it's not asserting anything?", "proj": "thought-machine-please", "lang": "go"}
{"patch": "@@ -204,6 +204,13 @@ func (d *Dispenser) SyntaxErr(expected string) error {\n \treturn errors.New(msg)\n }\n \n+// RewritePathErr returns an error indicating the path being rewritten to\n+// is missing an initial /\n+func (d *Dispenser) RewritePathErr() error {\n+\tmsg := fmt.Sprintf(\"%s:%d - Syntax error: Rewrite path must begin with '/'. Provided: '%s'\", d.File(), d.Line(), d.Val())\n+\treturn errors.New(msg)\n+}\n+\n // EOFErr returns an error indicating that the dispenser reached\n // the end of the input when searching for the next token.\n func (d *Dispenser) EOFErr() error {", "y": 1, "oldf": "package caddyfile\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"strings\"\n)\n\n// Dispenser is a type that dispenses tokens, similarly to a lexer,\n// except that it can do so with some notion of structure and has\n// some really convenient methods.\ntype Dispenser struct {\n\tfilename string\n\ttokens   []Token\n\tcursor   int\n\tnesting  int\n}\n\n// NewDispenser returns a Dispenser, ready to use for parsing the given input.\nfunc NewDispenser(filename string, input io.Reader) Dispenser {\n\ttokens, _ := allTokens(input) // ignoring error because nothing to do with it\n\treturn Dispenser{\n\t\tfilename: filename,\n\t\ttokens:   tokens,\n\t\tcursor:   -1,\n\t}\n}\n\n// NewDispenserTokens returns a Dispenser filled with the given tokens.\nfunc NewDispenserTokens(filename string, tokens []Token) Dispenser {\n\treturn Dispenser{\n\t\tfilename: filename,\n\t\ttokens:   tokens,\n\t\tcursor:   -1,\n\t}\n}\n\n// Next loads the next token. Returns true if a token\n// was loaded; false otherwise. If false, all tokens\n// have been consumed.\nfunc (d *Dispenser) Next() bool {\n\tif d.cursor < len(d.tokens)-1 {\n\t\td.cursor++\n\t\treturn true\n\t}\n\treturn false\n}\n\n// NextArg loads the next token if it is on the same\n// line. Returns true if a token was loaded; false\n// otherwise. If false, all tokens on the line have\n// been consumed. It handles imported tokens correctly.\nfunc (d *Dispenser) NextArg() bool {\n\tif d.cursor < 0 {\n\t\td.cursor++\n\t\treturn true\n\t}\n\tif d.cursor >= len(d.tokens) {\n\t\treturn false\n\t}\n\tif d.cursor < len(d.tokens)-1 &&\n\t\td.tokens[d.cursor].File == d.tokens[d.cursor+1].File &&\n\t\td.tokens[d.cursor].Line+d.numLineBreaks(d.cursor) == d.tokens[d.cursor+1].Line {\n\t\td.cursor++\n\t\treturn true\n\t}\n\treturn false\n}\n\n// NextLine loads the next token only if it is not on the same\n// line as the current token, and returns true if a token was\n// loaded; false otherwise. If false, there is not another token\n// or it is on the same line. It handles imported tokens correctly.\nfunc (d *Dispenser) NextLine() bool {\n\tif d.cursor < 0 {\n\t\td.cursor++\n\t\treturn true\n\t}\n\tif d.cursor >= len(d.tokens) {\n\t\treturn false\n\t}\n\tif d.cursor < len(d.tokens)-1 &&\n\t\t(d.tokens[d.cursor].File != d.tokens[d.cursor+1].File ||\n\t\t\td.tokens[d.cursor].Line+d.numLineBreaks(d.cursor) < d.tokens[d.cursor+1].Line) {\n\t\td.cursor++\n\t\treturn true\n\t}\n\treturn false\n}\n\n// NextBlock can be used as the condition of a for loop\n// to load the next token as long as it opens a block or\n// is already in a block. It returns true if a token was\n// loaded, or false when the block's closing curly brace\n// was loaded and thus the block ended. Nested blocks are\n// not supported.\nfunc (d *Dispenser) NextBlock() bool {\n\tif d.nesting > 0 {\n\t\td.Next()\n\t\tif d.Val() == \"}\" {\n\t\t\td.nesting--\n\t\t\treturn false\n\t\t}\n\t\treturn true\n\t}\n\tif !d.NextArg() { // block must open on same line\n\t\treturn false\n\t}\n\tif d.Val() != \"{\" {\n\t\td.cursor-- // roll back if not opening brace\n\t\treturn false\n\t}\n\td.Next()\n\tif d.Val() == \"}\" {\n\t\t// Open and then closed right away\n\t\treturn false\n\t}\n\td.nesting++\n\treturn true\n}\n\n// Val gets the text of the current token. If there is no token\n// loaded, it returns empty string.\nfunc (d *Dispenser) Val() string {\n\tif d.cursor < 0 || d.cursor >= len(d.tokens) {\n\t\treturn \"\"\n\t}\n\treturn d.tokens[d.cursor].Text\n}\n\n// Line gets the line number of the current token. If there is no token\n// loaded, it returns 0.\nfunc (d *Dispenser) Line() int {\n\tif d.cursor < 0 || d.cursor >= len(d.tokens) {\n\t\treturn 0\n\t}\n\treturn d.tokens[d.cursor].Line\n}\n\n// File gets the filename of the current token. If there is no token loaded,\n// it returns the filename originally given when parsing started.\nfunc (d *Dispenser) File() string {\n\tif d.cursor < 0 || d.cursor >= len(d.tokens) {\n\t\treturn d.filename\n\t}\n\tif tokenFilename := d.tokens[d.cursor].File; tokenFilename != \"\" {\n\t\treturn tokenFilename\n\t}\n\treturn d.filename\n}\n\n// Args is a convenience function that loads the next arguments\n// (tokens on the same line) into an arbitrary number of strings\n// pointed to in targets. If there are fewer tokens available\n// than string pointers, the remaining strings will not be changed\n// and false will be returned. If there were enough tokens available\n// to fill the arguments, then true will be returned.\nfunc (d *Dispenser) Args(targets ...*string) bool {\n\tenough := true\n\tfor i := 0; i < len(targets); i++ {\n\t\tif !d.NextArg() {\n\t\t\tenough = false\n\t\t\tbreak\n\t\t}\n\t\t*targets[i] = d.Val()\n\t}\n\treturn enough\n}\n\n// RemainingArgs loads any more arguments (tokens on the same line)\n// into a slice and returns them. Open curly brace tokens also indicate\n// the end of arguments, and the curly brace is not included in\n// the return value nor is it loaded.\nfunc (d *Dispenser) RemainingArgs() []string {\n\tvar args []string\n\n\tfor d.NextArg() {\n\t\tif d.Val() == \"{\" {\n\t\t\td.cursor--\n\t\t\tbreak\n\t\t}\n\t\targs = append(args, d.Val())\n\t}\n\n\treturn args\n}\n\n// ArgErr returns an argument error, meaning that another\n// argument was expected but not found. In other words,\n// a line break or open curly brace was encountered instead of\n// an argument.\nfunc (d *Dispenser) ArgErr() error {\n\tif d.Val() == \"{\" {\n\t\treturn d.Err(\"Unexpected token '{', expecting argument\")\n\t}\n\treturn d.Errf(\"Wrong argument count or unexpected line ending after '%s'\", d.Val())\n}\n\n// SyntaxErr creates a generic syntax error which explains what was\n// found and what was expected.\nfunc (d *Dispenser) SyntaxErr(expected string) error {\n\tmsg := fmt.Sprintf(\"%s:%d - Syntax error: Unexpected token '%s', expecting '%s'\", d.File(), d.Line(), d.Val(), expected)\n\treturn errors.New(msg)\n}\n\n// EOFErr returns an error indicating that the dispenser reached\n// the end of the input when searching for the next token.\nfunc (d *Dispenser) EOFErr() error {\n\treturn d.Errf(\"Unexpected EOF\")\n}\n\n// Err generates a custom parse error with a message of msg.\nfunc (d *Dispenser) Err(msg string) error {\n\tmsg = fmt.Sprintf(\"%s:%d - Parse error: %s\", d.File(), d.Line(), msg)\n\treturn errors.New(msg)\n}\n\n// Errf is like Err, but for formatted error messages\nfunc (d *Dispenser) Errf(format string, args ...interface{}) error {\n\treturn d.Err(fmt.Sprintf(format, args...))\n}\n\n// numLineBreaks counts how many line breaks are in the token\n// value given by the token index tknIdx. It returns 0 if the\n// token does not exist or there are no line breaks.\nfunc (d *Dispenser) numLineBreaks(tknIdx int) int {\n\tif tknIdx < 0 || tknIdx >= len(d.tokens) {\n\t\treturn 0\n\t}\n\treturn strings.Count(d.tokens[tknIdx].Text, \"\\n\")\n}\n\n// isNewLine determines whether the current token is on a different\n// line (higher line number) than the previous token. It handles imported\n// tokens correctly. If there isn't a previous token, it returns true.\nfunc (d *Dispenser) isNewLine() bool {\n\tif d.cursor < 1 {\n\t\treturn true\n\t}\n\tif d.cursor > len(d.tokens)-1 {\n\t\treturn false\n\t}\n\treturn d.tokens[d.cursor-1].File != d.tokens[d.cursor].File ||\n\t\td.tokens[d.cursor-1].Line+d.numLineBreaks(d.cursor-1) < d.tokens[d.cursor].Line\n}\n", "idx": 1, "id": 10688, "msg": "Since `rewrite` is simply a directive, I do not think it is best to have it's error as part of the dispenser. This looks out of place to me.", "proj": "caddyserver-caddy", "lang": "go"}
{"patch": "@@ -48,6 +48,7 @@ import org.apache.iceberg.hive.HiveSchemaUtil;\n import org.apache.iceberg.hive.MetastoreUtil;\n import org.apache.iceberg.mr.Catalogs;\n import org.apache.iceberg.mr.InputFormatConfig;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n import org.apache.iceberg.relocated.com.google.common.collect.ImmutableSet;\n import org.apache.iceberg.types.Type;", "y": 0, "oldf": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\n\npackage org.apache.iceberg.mr.hive;\n\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.Collection;\nimport java.util.Collections;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.stream.Collectors;\nimport org.apache.hadoop.fs.FileSystem;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.hive.common.StatsSetupConst;\nimport org.apache.hadoop.hive.metastore.api.hive_metastoreConstants;\nimport org.apache.iceberg.AssertHelpers;\nimport org.apache.iceberg.BaseMetastoreTableOperations;\nimport org.apache.iceberg.BaseTable;\nimport org.apache.iceberg.FileFormat;\nimport org.apache.iceberg.PartitionSpec;\nimport org.apache.iceberg.PartitionSpecParser;\nimport org.apache.iceberg.Schema;\nimport org.apache.iceberg.SchemaParser;\nimport org.apache.iceberg.TableProperties;\nimport org.apache.iceberg.catalog.TableIdentifier;\nimport org.apache.iceberg.exceptions.NoSuchTableException;\nimport org.apache.iceberg.hadoop.Util;\nimport org.apache.iceberg.hive.HiveSchemaUtil;\nimport org.apache.iceberg.hive.MetastoreUtil;\nimport org.apache.iceberg.mr.Catalogs;\nimport org.apache.iceberg.mr.InputFormatConfig;\nimport org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\nimport org.apache.iceberg.relocated.com.google.common.collect.ImmutableSet;\nimport org.apache.iceberg.types.Type;\nimport org.apache.iceberg.types.Types;\nimport org.apache.thrift.TException;\nimport org.junit.After;\nimport org.junit.AfterClass;\nimport org.junit.Assert;\nimport org.junit.Before;\nimport org.junit.BeforeClass;\nimport org.junit.Rule;\nimport org.junit.Test;\nimport org.junit.rules.TemporaryFolder;\nimport org.junit.runner.RunWith;\nimport org.junit.runners.Parameterized;\n\nimport static org.apache.iceberg.types.Types.NestedField.optional;\nimport static org.junit.runners.Parameterized.Parameter;\nimport static org.junit.runners.Parameterized.Parameters;\n\n@RunWith(Parameterized.class)\npublic class TestHiveIcebergStorageHandlerNoScan {\n  private static final PartitionSpec SPEC = PartitionSpec.unpartitioned();\n\n  private static final Schema COMPLEX_SCHEMA = new Schema(\n      optional(1, \"id\", Types.LongType.get()),\n      optional(2, \"name\", Types.StringType.get()),\n      optional(3, \"employee_info\", Types.StructType.of(\n          optional(7, \"employer\", Types.StringType.get()),\n          optional(8, \"id\", Types.LongType.get()),\n          optional(9, \"address\", Types.StringType.get())\n      )),\n      optional(4, \"places_lived\", Types.ListType.ofOptional(10, Types.StructType.of(\n          optional(11, \"street\", Types.StringType.get()),\n          optional(12, \"city\", Types.StringType.get()),\n          optional(13, \"country\", Types.StringType.get())\n      ))),\n      optional(5, \"memorable_moments\", Types.MapType.ofOptional(14, 15,\n          Types.StringType.get(),\n          Types.StructType.of(\n              optional(16, \"year\", Types.IntegerType.get()),\n              optional(17, \"place\", Types.StringType.get()),\n              optional(18, \"details\", Types.StringType.get())\n          ))),\n      optional(6, \"current_address\", Types.StructType.of(\n          optional(19, \"street_address\", Types.StructType.of(\n              optional(22, \"street_number\", Types.IntegerType.get()),\n              optional(23, \"street_name\", Types.StringType.get()),\n              optional(24, \"street_type\", Types.StringType.get())\n          )),\n          optional(20, \"country\", Types.StringType.get()),\n          optional(21, \"postal_code\", Types.StringType.get())\n      ))\n  );\n\n  private static final Set<String> IGNORED_PARAMS =\n      ImmutableSet.of(\"bucketing_version\", StatsSetupConst.ROW_COUNT,\n          StatsSetupConst.RAW_DATA_SIZE, StatsSetupConst.TOTAL_SIZE, StatsSetupConst.NUM_FILES, \"numFilesErasureCoded\");\n\n  @Parameters(name = \"catalog={0}\")\n  public static Collection<Object[]> parameters() {\n    Collection<Object[]> testParams = new ArrayList<>();\n    for (TestTables.TestTableType testTableType : TestTables.ALL_TABLE_TYPES) {\n      testParams.add(new Object[] {testTableType});\n    }\n\n    return testParams;\n  }\n\n  private static TestHiveShell shell;\n\n  private TestTables testTables;\n\n  @Parameter(0)\n  public TestTables.TestTableType testTableType;\n\n  @Rule\n  public TemporaryFolder temp = new TemporaryFolder();\n\n  @BeforeClass\n  public static void beforeClass() {\n    shell = HiveIcebergStorageHandlerTestUtils.shell();\n  }\n\n  @AfterClass\n  public static void afterClass() {\n    shell.stop();\n  }\n\n  @Before\n  public void before() throws IOException {\n    testTables = HiveIcebergStorageHandlerTestUtils.testTables(shell, testTableType, temp);\n    // Uses spark as an engine so we can detect if we unintentionally try to use any execution engines\n    HiveIcebergStorageHandlerTestUtils.init(shell, testTables, temp, \"spark\");\n  }\n\n  @After\n  public void after() throws Exception {\n    HiveIcebergStorageHandlerTestUtils.close(shell);\n  }\n\n  @Test\n  public void testCreateDropTable() throws TException, IOException, InterruptedException {\n    TableIdentifier identifier = TableIdentifier.of(\"default\", \"customers\");\n\n    shell.executeStatement(\"CREATE EXTERNAL TABLE customers \" +\n        \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n        testTables.locationForCreateTableSQL(identifier) +\n        \"TBLPROPERTIES ('\" + InputFormatConfig.TABLE_SCHEMA + \"'='\" +\n        SchemaParser.toJson(HiveIcebergStorageHandlerTestUtils.CUSTOMER_SCHEMA) + \"', \" +\n        \"'\" + InputFormatConfig.PARTITION_SPEC + \"'='\" +\n        PartitionSpecParser.toJson(PartitionSpec.unpartitioned()) + \"', \" +\n        \"'dummy'='test')\");\n\n    // Check the Iceberg table data\n    org.apache.iceberg.Table icebergTable = testTables.loadTable(identifier);\n    Assert.assertEquals(HiveIcebergStorageHandlerTestUtils.CUSTOMER_SCHEMA.asStruct(),\n        icebergTable.schema().asStruct());\n    Assert.assertEquals(PartitionSpec.unpartitioned(), icebergTable.spec());\n\n    if (!Catalogs.hiveCatalog(shell.getHiveConf())) {\n      shell.executeStatement(\"DROP TABLE customers\");\n\n      // Check if the table was really dropped even from the Catalog\n      AssertHelpers.assertThrows(\"should throw exception\", NoSuchTableException.class,\n          \"Table does not exist\", () -> {\n            testTables.loadTable(identifier);\n          }\n      );\n    } else {\n      org.apache.hadoop.hive.metastore.api.Table hmsTable = shell.metastore().getTable(\"default\", \"customers\");\n      Path hmsTableLocation = new Path(hmsTable.getSd().getLocation());\n\n      // Drop the table\n      shell.executeStatement(\"DROP TABLE customers\");\n\n      // Check if we drop an exception when trying to load the table\n      AssertHelpers.assertThrows(\"should throw exception\", NoSuchTableException.class,\n          \"Table does not exist\", () -> {\n            testTables.loadTable(identifier);\n          }\n      );\n\n      // Check if the files are removed\n      FileSystem fs = Util.getFs(hmsTableLocation, shell.getHiveConf());\n      if (fs.exists(hmsTableLocation)) {\n        // if table directory has been deleted, we're good. This is the expected behavior in Hive4.\n        // if table directory exists, its contents should have been cleaned up, save for an empty metadata dir (Hive3).\n        Assert.assertEquals(1, fs.listStatus(hmsTableLocation).length);\n        Assert.assertEquals(0, fs.listStatus(new Path(hmsTableLocation, \"metadata\")).length);\n      }\n    }\n  }\n\n  @Test\n  public void testCreateTableWithoutSpec() {\n    TableIdentifier identifier = TableIdentifier.of(\"default\", \"customers\");\n\n    shell.executeStatement(\"CREATE EXTERNAL TABLE customers \" +\n        \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n        testTables.locationForCreateTableSQL(identifier) +\n        \"TBLPROPERTIES ('\" + InputFormatConfig.TABLE_SCHEMA + \"'='\" +\n        SchemaParser.toJson(HiveIcebergStorageHandlerTestUtils.CUSTOMER_SCHEMA) + \"')\");\n\n    // Check the Iceberg table partition data\n    org.apache.iceberg.Table icebergTable = testTables.loadTable(identifier);\n    Assert.assertEquals(PartitionSpec.unpartitioned(), icebergTable.spec());\n  }\n\n  @Test\n  public void testCreateTableWithUnpartitionedSpec() {\n    TableIdentifier identifier = TableIdentifier.of(\"default\", \"customers\");\n\n    // We need the location for HadoopTable based tests only\n    shell.executeStatement(\"CREATE EXTERNAL TABLE customers \" +\n        \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n        testTables.locationForCreateTableSQL(identifier) +\n        \"TBLPROPERTIES ('\" + InputFormatConfig.TABLE_SCHEMA + \"'='\" +\n        SchemaParser.toJson(HiveIcebergStorageHandlerTestUtils.CUSTOMER_SCHEMA) + \"', \" +\n        \"'\" + InputFormatConfig.PARTITION_SPEC + \"'='\" +\n        PartitionSpecParser.toJson(PartitionSpec.unpartitioned()) + \"')\");\n\n    // Check the Iceberg table partition data\n    org.apache.iceberg.Table icebergTable = testTables.loadTable(identifier);\n    Assert.assertEquals(SPEC, icebergTable.spec());\n  }\n\n  @Test\n  public void testDeleteBackingTable() throws TException, IOException, InterruptedException {\n    TableIdentifier identifier = TableIdentifier.of(\"default\", \"customers\");\n\n    shell.executeStatement(\"CREATE EXTERNAL TABLE customers \" +\n        \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n        testTables.locationForCreateTableSQL(identifier) +\n        \"TBLPROPERTIES ('\" + InputFormatConfig.TABLE_SCHEMA + \"'='\" +\n        SchemaParser.toJson(HiveIcebergStorageHandlerTestUtils.CUSTOMER_SCHEMA) + \"', \" +\n        \"'\" + InputFormatConfig.EXTERNAL_TABLE_PURGE + \"'='FALSE')\");\n\n    if (!Catalogs.hiveCatalog(shell.getHiveConf())) {\n      shell.executeStatement(\"DROP TABLE customers\");\n\n      // Check if the table remains\n      testTables.loadTable(identifier);\n    } else {\n      // Check the HMS table parameters\n      org.apache.hadoop.hive.metastore.api.Table hmsTable = shell.metastore().getTable(\"default\", \"customers\");\n      Path hmsTableLocation = new Path(hmsTable.getSd().getLocation());\n\n      // Drop the table\n      shell.executeStatement(\"DROP TABLE customers\");\n\n      // Check if we drop an exception when trying to drop the table\n      AssertHelpers.assertThrows(\"should throw exception\", NoSuchTableException.class,\n          \"Table does not exist\", () -> {\n            testTables.loadTable(identifier);\n          }\n      );\n\n      // Check if the files are kept\n      FileSystem fs = Util.getFs(hmsTableLocation, shell.getHiveConf());\n      Assert.assertEquals(1, fs.listStatus(hmsTableLocation).length);\n      Assert.assertEquals(1, fs.listStatus(new Path(hmsTableLocation, \"metadata\")).length);\n    }\n  }\n\n  @Test\n  public void testCreateTableError() {\n    TableIdentifier identifier = TableIdentifier.of(\"default\", \"withShell2\");\n\n    // Wrong schema\n    AssertHelpers.assertThrows(\"should throw exception\", IllegalArgumentException.class,\n        \"Unrecognized token 'WrongSchema'\", () -> {\n          shell.executeStatement(\"CREATE EXTERNAL TABLE withShell2 \" +\n              \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n              testTables.locationForCreateTableSQL(identifier) +\n              \"TBLPROPERTIES ('\" + InputFormatConfig.TABLE_SCHEMA + \"'='WrongSchema')\");\n        }\n    );\n\n    // Missing schema, we try to get the schema from the table and fail\n    AssertHelpers.assertThrows(\"should throw exception\", IllegalArgumentException.class,\n        \"Please provide \", () -> {\n          shell.executeStatement(\"CREATE EXTERNAL TABLE withShell2 \" +\n              \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n              testTables.locationForCreateTableSQL(identifier));\n        }\n    );\n\n    if (!testTables.locationForCreateTableSQL(identifier).isEmpty()) {\n      // Only test this if the location is required\n      AssertHelpers.assertThrows(\"should throw exception\", IllegalArgumentException.class,\n          \"Table location not set\", () -> {\n            shell.executeStatement(\"CREATE EXTERNAL TABLE withShell2 \" +\n                \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n                \"TBLPROPERTIES ('\" + InputFormatConfig.TABLE_SCHEMA + \"'='\" +\n                SchemaParser.toJson(HiveIcebergStorageHandlerTestUtils.CUSTOMER_SCHEMA) + \"')\");\n          }\n      );\n    }\n  }\n\n  @Test\n  public void testCreateTableAboveExistingTable() throws IOException {\n    // Create the Iceberg table\n    testTables.createIcebergTable(shell.getHiveConf(), \"customers\", COMPLEX_SCHEMA, FileFormat.PARQUET,\n        Collections.emptyList());\n\n    if (Catalogs.hiveCatalog(shell.getHiveConf())) {\n      // In HiveCatalog we just expect an exception since the table is already exists\n      AssertHelpers.assertThrows(\"should throw exception\", IllegalArgumentException.class,\n          \"customers already exists\", () -> {\n            shell.executeStatement(\"CREATE EXTERNAL TABLE customers \" +\n                \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n                \"TBLPROPERTIES ('\" + InputFormatConfig.TABLE_SCHEMA + \"'='\" +\n                SchemaParser.toJson(HiveIcebergStorageHandlerTestUtils.CUSTOMER_SCHEMA) + \"')\");\n          }\n      );\n    } else {\n      // With other catalogs, table creation should succeed\n      shell.executeStatement(\"CREATE EXTERNAL TABLE customers \" +\n          \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n          testTables.locationForCreateTableSQL(TableIdentifier.of(\"default\", \"customers\")));\n    }\n  }\n\n  @Test\n  public void testCreatePartitionedTableWithPropertiesAndWithColumnSpecification() {\n    PartitionSpec spec =\n        PartitionSpec.builderFor(HiveIcebergStorageHandlerTestUtils.CUSTOMER_SCHEMA).identity(\"last_name\").build();\n\n    AssertHelpers.assertThrows(\"should throw exception\", IllegalArgumentException.class,\n        \"Provide only one of the following\", () -> {\n          shell.executeStatement(\"CREATE EXTERNAL TABLE customers (customer_id BIGINT) \" +\n              \"PARTITIONED BY (first_name STRING) \" +\n              \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n              testTables.locationForCreateTableSQL(TableIdentifier.of(\"default\", \"customers\")) +\n              \" TBLPROPERTIES ('\" + InputFormatConfig.PARTITION_SPEC + \"'='\" +\n              PartitionSpecParser.toJson(spec) + \"')\");\n        }\n    );\n  }\n\n  @Test\n  public void testCreateTableWithColumnSpecificationHierarchy() {\n    TableIdentifier identifier = TableIdentifier.of(\"default\", \"customers\");\n\n    shell.executeStatement(\"CREATE EXTERNAL TABLE customers (\" +\n        \"id BIGINT, name STRING, \" +\n        \"employee_info STRUCT < employer: STRING, id: BIGINT, address: STRING >, \" +\n        \"places_lived ARRAY < STRUCT <street: STRING, city: STRING, country: STRING >>, \" +\n        \"memorable_moments MAP < STRING, STRUCT < year: INT, place: STRING, details: STRING >>, \" +\n        \"current_address STRUCT < street_address: STRUCT \" +\n        \"<street_number: INT, street_name: STRING, street_type: STRING>, country: STRING, postal_code: STRING >) \" +\n        \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n        testTables.locationForCreateTableSQL(identifier));\n\n    // Check the Iceberg table data\n    org.apache.iceberg.Table icebergTable = testTables.loadTable(identifier);\n    Assert.assertEquals(COMPLEX_SCHEMA.asStruct(), icebergTable.schema().asStruct());\n  }\n\n  @Test\n  public void testCreateTableWithAllSupportedTypes() {\n    TableIdentifier identifier = TableIdentifier.of(\"default\", \"all_types\");\n    Schema allSupportedSchema = new Schema(\n        optional(1, \"t_float\", Types.FloatType.get()),\n        optional(2, \"t_double\", Types.DoubleType.get()),\n        optional(3, \"t_boolean\", Types.BooleanType.get()),\n        optional(4, \"t_int\", Types.IntegerType.get()),\n        optional(5, \"t_bigint\", Types.LongType.get()),\n        optional(6, \"t_binary\", Types.BinaryType.get()),\n        optional(7, \"t_string\", Types.StringType.get()),\n        optional(8, \"t_timestamp\", Types.TimestampType.withoutZone()),\n        optional(9, \"t_date\", Types.DateType.get()),\n        optional(10, \"t_decimal\", Types.DecimalType.of(3, 2))\n    );\n\n    // Intentionally adding some mixed letters to test that we handle them correctly\n    shell.executeStatement(\"CREATE EXTERNAL TABLE all_types (\" +\n        \"t_Float FLOaT, t_dOuble DOUBLE, t_boolean BOOLEAN, t_int INT, t_bigint BIGINT, t_binary BINARY, \" +\n        \"t_string STRING, t_timestamp TIMESTAMP, t_date DATE, t_decimal DECIMAL(3,2)) \" +\n        \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n        testTables.locationForCreateTableSQL(identifier));\n\n    // Check the Iceberg table data\n    org.apache.iceberg.Table icebergTable = testTables.loadTable(identifier);\n    Assert.assertEquals(allSupportedSchema.asStruct(), icebergTable.schema().asStruct());\n  }\n\n  @Test\n  public void testCreateTableWithNotSupportedTypes() {\n    TableIdentifier identifier = TableIdentifier.of(\"default\", \"not_supported_types\");\n    // Can not create INTERVAL types from normal create table, so leave them out from this test\n    Map<String, Type> notSupportedTypes = ImmutableMap.of(\n        \"TINYINT\", Types.IntegerType.get(),\n        \"SMALLINT\", Types.IntegerType.get(),\n        \"VARCHAR(1)\", Types.StringType.get(),\n        \"CHAR(1)\", Types.StringType.get());\n\n    for (String notSupportedType : notSupportedTypes.keySet()) {\n      AssertHelpers.assertThrows(\"should throw exception\", IllegalArgumentException.class,\n          \"Unsupported Hive type\", () -> {\n            shell.executeStatement(\"CREATE EXTERNAL TABLE not_supported_types \" +\n                \"(not_supported \" + notSupportedType + \") \" +\n                \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n                testTables.locationForCreateTableSQL(identifier));\n          }\n      );\n    }\n  }\n\n  @Test\n  public void testCreateTableWithNotSupportedTypesWithAutoConversion() {\n    TableIdentifier identifier = TableIdentifier.of(\"default\", \"not_supported_types\");\n    // Can not create INTERVAL types from normal create table, so leave them out from this test\n    Map<String, Type> notSupportedTypes = ImmutableMap.of(\n        \"TINYINT\", Types.IntegerType.get(),\n        \"SMALLINT\", Types.IntegerType.get(),\n        \"VARCHAR(1)\", Types.StringType.get(),\n         \"CHAR(1)\", Types.StringType.get());\n\n    shell.setHiveSessionValue(InputFormatConfig.SCHEMA_AUTO_CONVERSION, \"true\");\n\n    for (String notSupportedType : notSupportedTypes.keySet()) {\n      shell.executeStatement(\"CREATE EXTERNAL TABLE not_supported_types (not_supported \" + notSupportedType + \") \" +\n              \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n              testTables.locationForCreateTableSQL(identifier));\n\n      org.apache.iceberg.Table icebergTable = testTables.loadTable(identifier);\n      Assert.assertEquals(notSupportedTypes.get(notSupportedType), icebergTable.schema().columns().get(0).type());\n      shell.executeStatement(\"DROP TABLE not_supported_types\");\n    }\n  }\n\n  @Test\n  public void testCreateTableWithColumnComments() {\n    TableIdentifier identifier = TableIdentifier.of(\"default\", \"comment_table\");\n    shell.executeStatement(\"CREATE EXTERNAL TABLE comment_table (\" +\n        \"t_int INT COMMENT 'int column',  \" +\n        \"t_string STRING COMMENT 'string column') \" +\n        \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n        testTables.locationForCreateTableSQL(identifier));\n    org.apache.iceberg.Table icebergTable = testTables.loadTable(identifier);\n\n    List<Object[]> rows = shell.executeStatement(\"DESCRIBE default.comment_table\");\n    Assert.assertEquals(icebergTable.schema().columns().size(), rows.size());\n    for (int i = 0; i < icebergTable.schema().columns().size(); i++) {\n      Types.NestedField field = icebergTable.schema().columns().get(i);\n      Assert.assertArrayEquals(new Object[] {field.name(), HiveSchemaUtil.convert(field.type()).getTypeName(),\n          field.doc()}, rows.get(i));\n    }\n  }\n\n  @Test\n  public void testCreateTableWithoutColumnComments() {\n    TableIdentifier identifier = TableIdentifier.of(\"default\", \"without_comment_table\");\n    shell.executeStatement(\"CREATE EXTERNAL TABLE without_comment_table (\" +\n            \"t_int INT,  \" +\n            \"t_string STRING) \" +\n            \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n            testTables.locationForCreateTableSQL(identifier));\n    org.apache.iceberg.Table icebergTable = testTables.loadTable(identifier);\n\n    List<Object[]> rows = shell.executeStatement(\"DESCRIBE default.without_comment_table\");\n    Assert.assertEquals(icebergTable.schema().columns().size(), rows.size());\n    for (int i = 0; i < icebergTable.schema().columns().size(); i++) {\n      Types.NestedField field = icebergTable.schema().columns().get(i);\n      Assert.assertNull(field.doc());\n      Assert.assertArrayEquals(new Object[] {field.name(), HiveSchemaUtil.convert(field.type()).getTypeName(),\n          \"from deserializer\"}, rows.get(i));\n    }\n  }\n\n  @Test\n  public void testIcebergAndHmsTableProperties() throws TException, InterruptedException {\n    TableIdentifier identifier = TableIdentifier.of(\"default\", \"customers\");\n\n    shell.executeStatement(String.format(\"CREATE EXTERNAL TABLE default.customers \" +\n        \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' %s\" +\n        \"TBLPROPERTIES ('%s'='%s', '%s'='%s', '%s'='%s')\",\n        testTables.locationForCreateTableSQL(identifier), // we need the location for HadoopTable based tests only\n        InputFormatConfig.TABLE_SCHEMA, SchemaParser.toJson(HiveIcebergStorageHandlerTestUtils.CUSTOMER_SCHEMA),\n        InputFormatConfig.PARTITION_SPEC, PartitionSpecParser.toJson(SPEC),\n        \"custom_property\", \"initial_val\"));\n\n\n    // Check the Iceberg table parameters\n    org.apache.iceberg.Table icebergTable = testTables.loadTable(identifier);\n\n    Map<String, String> expectedIcebergProperties = new HashMap<>();\n    expectedIcebergProperties.put(\"custom_property\", \"initial_val\");\n    expectedIcebergProperties.put(\"EXTERNAL\", \"TRUE\");\n    expectedIcebergProperties.put(\"storage_handler\", HiveIcebergStorageHandler.class.getName());\n    if (Catalogs.hiveCatalog(shell.getHiveConf())) {\n      expectedIcebergProperties.put(TableProperties.ENGINE_HIVE_ENABLED, \"true\");\n    }\n    if (MetastoreUtil.hive3PresentOnClasspath()) {\n      expectedIcebergProperties.put(\"bucketing_version\", \"2\");\n    }\n    Assert.assertEquals(expectedIcebergProperties, icebergTable.properties());\n\n    // Check the HMS table parameters\n    org.apache.hadoop.hive.metastore.api.Table hmsTable = shell.metastore().getTable(\"default\", \"customers\");\n    Map<String, String> hmsParams = hmsTable.getParameters()\n        .entrySet().stream()\n        .filter(e -> !IGNORED_PARAMS.contains(e.getKey()))\n        .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));\n\n    if (Catalogs.hiveCatalog(shell.getHiveConf())) {\n      Assert.assertEquals(9, hmsParams.size());\n      Assert.assertEquals(\"initial_val\", hmsParams.get(\"custom_property\"));\n      Assert.assertEquals(\"TRUE\", hmsParams.get(InputFormatConfig.EXTERNAL_TABLE_PURGE));\n      Assert.assertEquals(\"TRUE\", hmsParams.get(\"EXTERNAL\"));\n      Assert.assertEquals(\"true\", hmsParams.get(TableProperties.ENGINE_HIVE_ENABLED));\n      Assert.assertEquals(HiveIcebergStorageHandler.class.getName(),\n          hmsParams.get(hive_metastoreConstants.META_TABLE_STORAGE));\n      Assert.assertEquals(BaseMetastoreTableOperations.ICEBERG_TABLE_TYPE_VALUE.toUpperCase(),\n          hmsParams.get(BaseMetastoreTableOperations.TABLE_TYPE_PROP));\n      Assert.assertEquals(hmsParams.get(BaseMetastoreTableOperations.METADATA_LOCATION_PROP),\n              getCurrentSnapshotForHiveCatalogTable(icebergTable));\n      Assert.assertNull(hmsParams.get(BaseMetastoreTableOperations.PREVIOUS_METADATA_LOCATION_PROP));\n      Assert.assertNotNull(hmsParams.get(hive_metastoreConstants.DDL_TIME));\n    } else {\n      Assert.assertEquals(7, hmsParams.size());\n      Assert.assertNull(hmsParams.get(TableProperties.ENGINE_HIVE_ENABLED));\n    }\n\n    // Check HMS inputformat/outputformat/serde\n    Assert.assertEquals(HiveIcebergInputFormat.class.getName(), hmsTable.getSd().getInputFormat());\n    Assert.assertEquals(HiveIcebergOutputFormat.class.getName(), hmsTable.getSd().getOutputFormat());\n    Assert.assertEquals(HiveIcebergSerDe.class.getName(), hmsTable.getSd().getSerdeInfo().getSerializationLib());\n\n    // Add two new properties to the Iceberg table and update an existing one\n    icebergTable.updateProperties()\n        .set(\"new_prop_1\", \"true\")\n        .set(\"new_prop_2\", \"false\")\n        .set(\"custom_property\", \"new_val\")\n        .commit();\n\n    // Refresh the HMS table to see if new Iceberg properties got synced into HMS\n    hmsParams = shell.metastore().getTable(\"default\", \"customers\").getParameters()\n        .entrySet().stream()\n        .filter(e -> !IGNORED_PARAMS.contains(e.getKey()))\n        .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));\n\n    if (Catalogs.hiveCatalog(shell.getHiveConf())) {\n      Assert.assertEquals(12, hmsParams.size()); // 2 newly-added properties + previous_metadata_location prop\n      Assert.assertEquals(\"true\", hmsParams.get(\"new_prop_1\"));\n      Assert.assertEquals(\"false\", hmsParams.get(\"new_prop_2\"));\n      Assert.assertEquals(\"new_val\", hmsParams.get(\"custom_property\"));\n      String prevSnapshot = getCurrentSnapshotForHiveCatalogTable(icebergTable);\n      icebergTable.refresh();\n      String newSnapshot = getCurrentSnapshotForHiveCatalogTable(icebergTable);\n      Assert.assertEquals(hmsParams.get(BaseMetastoreTableOperations.PREVIOUS_METADATA_LOCATION_PROP), prevSnapshot);\n      Assert.assertEquals(hmsParams.get(BaseMetastoreTableOperations.METADATA_LOCATION_PROP), newSnapshot);\n    } else {\n      Assert.assertEquals(7, hmsParams.size());\n    }\n  }\n\n  private String getCurrentSnapshotForHiveCatalogTable(org.apache.iceberg.Table icebergTable) {\n    return ((BaseMetastoreTableOperations) ((BaseTable) icebergTable).operations()).currentMetadataLocation();\n  }\n}\n", "idx": 2, "id": 32962, "msg": "", "proj": "apache-iceberg", "lang": "java"}
{"patch": "@@ -80,6 +80,8 @@ namespace OpenTelemetry.Trace\n         /// </summary>\n         /// <param name=\"activity\">Activity instance.</param>\n         /// <param name=\"kind\">Activity execution kind.</param>\n+        /// <remarks>This is required for instrumentations which are dealing with \"legacy\" activities which has\n+        /// the default 'internal' kind, and must be changed to right one.</remarks>\n         [MethodImpl(MethodImplOptions.AggressiveInlining)]\n         public static void SetKind(this Activity activity, ActivityKind kind)\n         {", "y": 1, "oldf": "\ufeff// <copyright file=\"ActivityExtensions.cs\" company=\"OpenTelemetry Authors\">\n// Copyright The OpenTelemetry Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n// </copyright>\n\nusing System;\nusing System.Diagnostics;\nusing System.Linq;\nusing System.Linq.Expressions;\nusing System.Runtime.CompilerServices;\nusing OpenTelemetry.Internal;\n\nnamespace OpenTelemetry.Trace\n{\n    /// <summary>\n    /// Extension methods on Activity.\n    /// </summary>\n    public static class ActivityExtensions\n    {\n        /// <summary>\n        /// Sets the status of activity execution.\n        /// Activity class in .NET does not support 'Status'.\n        /// This extension provides a workaround to store Status as special tags with key name of otel.status_code and otel.status_description.\n        /// Read more about SetStatus here https://github.com/open-telemetry/opentelemetry-specification/blob/master/specification/trace/api.md#set-status.\n        /// </summary>\n        /// <param name=\"activity\">Activity instance.</param>\n        /// <param name=\"status\">Activity execution status.</param>\n        [MethodImpl(MethodImplOptions.AggressiveInlining)]\n        [System.Diagnostics.CodeAnalysis.SuppressMessage(\"Design\", \"CA1062:Validate arguments of public methods\", Justification = \"ActivityProcessor is hot path\")]\n        public static void SetStatus(this Activity activity, Status status)\n        {\n            Debug.Assert(activity != null, \"Activity should not be null\");\n\n            activity.SetTag(SpanAttributeConstants.StatusCodeKey, SpanHelper.GetCachedCanonicalCodeString(status.CanonicalCode));\n            if (!string.IsNullOrEmpty(status.Description))\n            {\n                activity.SetTag(SpanAttributeConstants.StatusDescriptionKey, status.Description);\n            }\n        }\n\n        /// <summary>\n        /// Gets the status of activity execution.\n        /// Activity class in .NET does not support 'Status'.\n        /// This extension provides a workaround to retrieve Status from special tags with key name otel.status_code and otel.status_description.\n        /// </summary>\n        /// <param name=\"activity\">Activity instance.</param>\n        /// <returns>Activity execution status.</returns>\n        [MethodImpl(MethodImplOptions.AggressiveInlining)]\n        [System.Diagnostics.CodeAnalysis.SuppressMessage(\"Design\", \"CA1062:Validate arguments of public methods\", Justification = \"ActivityProcessor is hot path\")]\n        public static Status GetStatus(this Activity activity)\n        {\n            Debug.Assert(activity != null, \"Activity should not be null\");\n\n            var statusCanonicalCode = activity.Tags.FirstOrDefault(k => k.Key == SpanAttributeConstants.StatusCodeKey).Value;\n            var statusDescription = activity.Tags.FirstOrDefault(d => d.Key == SpanAttributeConstants.StatusDescriptionKey).Value;\n\n            var status = SpanHelper.ResolveCanonicalCodeToStatus(statusCanonicalCode);\n\n            if (status.IsValid && !string.IsNullOrEmpty(statusDescription))\n            {\n                return status.WithDescription(statusDescription);\n            }\n\n            return status;\n        }\n\n        /// <summary>\n        /// Sets the kind of activity execution.\n        /// </summary>\n        /// <param name=\"activity\">Activity instance.</param>\n        /// <param name=\"kind\">Activity execution kind.</param>\n        [MethodImpl(MethodImplOptions.AggressiveInlining)]\n        public static void SetKind(this Activity activity, ActivityKind kind)\n        {\n            Debug.Assert(activity != null, \"Activity should not be null\");\n            SetKindProperty(activity, kind);\n        }\n\n        /// <summary>\n        /// Record Exception.\n        /// </summary>\n        /// <param name=\"activity\">Activity instance.</param>\n        /// <param name=\"ex\">Exception to be recorded.</param>\n        [MethodImpl(MethodImplOptions.AggressiveInlining)]\n        public static void RecordException(this Activity activity, Exception ex)\n        {\n            if (ex == null)\n            {\n                return;\n            }\n\n            var tagsCollection = new ActivityTagsCollection\n            {\n                { SemanticConventions.AttributeExceptionType, ex.GetType().Name },\n                { SemanticConventions.AttributeExceptionStacktrace, ex.ToInvariantString() },\n            };\n\n            if (!string.IsNullOrWhiteSpace(ex.Message))\n            {\n                tagsCollection.Add(SemanticConventions.AttributeExceptionMessage, ex.Message);\n            }\n\n            activity?.AddEvent(new ActivityEvent(SemanticConventions.AttributeExceptionEventName, default, tagsCollection));\n        }\n\n#pragma warning disable SA1201 // Elements should appear in the correct order\n        private static readonly Action<Activity, ActivityKind> SetKindProperty = CreateActivityKindSetter();\n#pragma warning restore SA1201 // Elements should appear in the correct order\n\n        private static Action<Activity, ActivityKind> CreateActivityKindSetter()\n        {\n            ParameterExpression instance = Expression.Parameter(typeof(Activity), \"instance\");\n            ParameterExpression propertyValue = Expression.Parameter(typeof(ActivityKind), \"propertyValue\");\n            var body = Expression.Assign(Expression.Property(instance, \"Kind\"), propertyValue);\n            return Expression.Lambda<Action<Activity, ActivityKind>>(body, instance, propertyValue).Compile();\n        }\n    }\n}\n", "idx": 1, "id": 16702, "msg": "I'm thinking people may not know what we mean by \"legacy\". Suggestion: \"This extension method should only be used on Activity instances that were created via older means that predate ActivitySource.\"", "proj": "open-telemetry-opentelemetry-dotnet", "lang": ".cs"}
{"patch": "@@ -180,9 +180,12 @@ def get_feedback_for_recordings_for_user(user_name):\n \n     recordings = request.args.get('recordings')\n \n+    if not recordings:\n+        log_raise_400(\"'recordings' has no valid recording MSID.\")\n+\n     recording_list = parse_param_list(recordings)\n     if not len(recording_list):\n-        raise APIBadRequest(\"'recordings' has no valid recording_msid.\")\n+        raise APIBadRequest(\"'recordings' has no valid recording MSID.\")\n \n     user = db_user.get_by_mb_id(user_name)\n     if user is None:", "y": 1, "oldf": "import ujson\nimport listenbrainz.db.user as db_user\nimport listenbrainz.db.feedback as db_feedback\n\nfrom flask import Blueprint, current_app, jsonify, request\nfrom listenbrainz.webserver.decorators import crossdomain\nfrom listenbrainz.webserver.errors import (APIBadRequest,\n                                           APIInternalServerError, APINotFound,\n                                           APIServiceUnavailable,\n                                           APIUnauthorized)\nfrom listenbrainz.webserver.rate_limiter import ratelimit\nfrom listenbrainz.webserver.views.api import _validate_auth_header, _parse_int_arg\nfrom listenbrainz.webserver.views.api_tools import log_raise_400, is_valid_uuid,\\\n    DEFAULT_ITEMS_PER_GET, MAX_ITEMS_PER_GET, _get_non_negative_param, parse_param_list\nfrom listenbrainz.db.model.feedback import Feedback\nfrom pydantic import ValidationError\n\nfeedback_api_bp = Blueprint('feedback_api_v1', __name__)\n\n\n@feedback_api_bp.route(\"recording-feedback\", methods=[\"POST\", \"OPTIONS\"])\n@crossdomain(headers=\"Authorization, Content-Type\")\n@ratelimit()\ndef recording_feedback():\n    \"\"\"\n    Submit recording feedback (love/hate) to the server. A user token (found on  https://listenbrainz.org/profile/ )\n    must be provided in the Authorization header! Each request should contain only one feedback in the payload.\n\n    For complete details on the format of the JSON to be POSTed to this endpoint, see :ref:`feedback-json-doc`.\n\n    :reqheader Authorization: Token <user token>\n    :statuscode 200: feedback accepted.\n    :statuscode 400: invalid JSON sent, see error message for details.\n    :statuscode 401: invalid authorization. See error message for details.\n    :resheader Content-Type: *application/json*\n    \"\"\"\n    user = _validate_auth_header()\n\n    data = request.json\n\n    if 'recording_msid' not in data or 'score' not in data:\n        log_raise_400(\"JSON document must contain recording_msid and \"\n                      \"score top level keys\", data)\n\n    if 'recording_msid' in data and 'score' in data and len(data) > 2:\n        log_raise_400(\"JSON document may only contain recording_msid and \"\n                      \"score top level keys\", data)\n\n    try:\n        feedback = Feedback(user_id=user[\"id\"], recording_msid=data[\"recording_msid\"], score=data[\"score\"])\n    except ValidationError as e:\n        # Validation errors from the Pydantic model are multi-line. While passing it as a response the new lines\n        # are displayed as \\n. str.replace() to tidy up the error message so that it becomes a good one line error message.\n        log_raise_400(\"Invalid JSON document submitted: %s\" % str(e).replace(\"\\n \", \":\").replace(\"\\n\", \" \"),\n                      data)\n    try:\n        if feedback.score == 0:\n            db_feedback.delete(feedback)\n        else:\n            db_feedback.insert(feedback)\n    except Exception as e:\n        current_app.logger.error(\"Error while inserting recording feedback: {}\".format(e))\n        raise APIInternalServerError(\"Something went wrong. Please try again.\")\n\n    return jsonify({'status': 'ok'})\n\n\n@feedback_api_bp.route(\"/user/<user_name>/get-feedback\", methods=[\"GET\"])\n@crossdomain()\n@ratelimit()\ndef get_feedback_for_user(user_name):\n    \"\"\"\n    Get feedback given by user ``user_name``. The format for the JSON returned is defined in our :ref:`feedback-json-doc`.\n\n    If the optional argument ``score`` is not given, this endpoint will return all the feedback submitted by the user.\n    Otherwise filters the feedback to be returned by score.\n\n    :param score: Optional, If 1 then returns the loved recordings, if -1 returns hated recordings.\n    :type score: ``int``\n    :param count: Optional, number of feedback items to return, Default: :data:`~webserver.views.api.DEFAULT_ITEMS_PER_GET`\n        Max: :data:`~webserver.views.api.MAX_ITEMS_PER_GET`.\n    :type count: ``int``\n    :param offset: Optional, number of feedback items to skip from the beginning, for pagination.\n        Ex. An offset of 5 means the top 5 feedback will be skipped, defaults to 0.\n    :type offset: ``int``\n    :statuscode 200: Yay, you have data!\n    :resheader Content-Type: *application/json*\n    \"\"\"\n\n    score = _parse_int_arg('score')\n\n    offset = _get_non_negative_param('offset', default=0)\n    count = _get_non_negative_param('count', default=DEFAULT_ITEMS_PER_GET)\n\n    count = min(count, MAX_ITEMS_PER_GET)\n\n    user = db_user.get_by_mb_id(user_name)\n    if user is None:\n        raise APINotFound(\"Cannot find user: %s\" % user_name)\n\n    if score:\n        if score not in [-1, 1]:\n            log_raise_400(\"Score can have a value of 1 or -1.\", request.args)\n\n    feedback = db_feedback.get_feedback_for_user(user_id=user[\"id\"], limit=count, offset=offset, score=score)\n    total_count = db_feedback.get_feedback_count_for_user(user[\"id\"])\n\n    feedback = [_feedback_to_api(fb) for fb in feedback]\n\n    return jsonify({\n        \"feedback\": feedback,\n        \"count\": len(feedback),\n        \"total_count\": total_count,\n        \"offset\": offset\n    })\n\n\n@feedback_api_bp.route(\"/recording/<recording_msid>/get-feedback\", methods=[\"GET\"])\n@crossdomain()\n@ratelimit()\ndef get_feedback_for_recording(recording_msid):\n    \"\"\"\n    Get feedback for recording with given ``recording_msid``. The format for the JSON returned\n    is defined in our :ref:`feedback-json-doc`.\n\n    :param score: Optional, If 1 then returns the loved recordings, if -1 returns hated recordings.\n    :type score: ``int``\n    :param count: Optional, number of feedback items to return, Default: :data:`~webserver.views.api.DEFAULT_ITEMS_PER_GET`\n        Max: :data:`~webserver.views.api.MAX_ITEMS_PER_GET`.\n    :type count: ``int``\n    :param offset: Optional, number of feedback items to skip from the beginning, for pagination.\n        Ex. An offset of 5 means the top 5 feedback will be skipped, defaults to 0.\n    :type offset: ``int``\n    :statuscode 200: Yay, you have data!\n    :resheader Content-Type: *application/json*\n    \"\"\"\n\n    if not is_valid_uuid(recording_msid):\n        log_raise_400(\"%s MSID format invalid.\" % recording_msid)\n\n    score = _parse_int_arg('score')\n\n    offset = _get_non_negative_param('offset', default=0)\n    count = _get_non_negative_param('count', default=DEFAULT_ITEMS_PER_GET)\n\n    count = min(count, MAX_ITEMS_PER_GET)\n\n    if score:\n        if score not in [-1, 1]:\n            log_raise_400(\"Score can have a value of 1 or -1.\", request.args)\n\n    feedback = db_feedback.get_feedback_for_recording(recording_msid=recording_msid, limit=count, offset=offset, score=score)\n    total_count = db_feedback.get_feedback_count_for_recording(recording_msid)\n\n    feedback = [_feedback_to_api(fb) for fb in feedback]\n\n    return jsonify({\n        \"feedback\": feedback,\n        \"count\": len(feedback),\n        \"total_count\": total_count,\n        \"offset\": offset\n    })\n\n\n@feedback_api_bp.route(\"/user/<user_name>/get-feedback-for-recordings\", methods=[\"GET\"])\n@crossdomain()\n@ratelimit()\ndef get_feedback_for_recordings_for_user(user_name):\n    \"\"\"\n    Get feedback given by user ``user_name`` for the list of recordings supplied. The format for the JSON returned\n    is defined in our :ref:`feedback-json-doc`.\n\n    If the feedback for given recording MSID doesn't exist then a score 0 is returned for that recording.\n\n    :param recordings: comma separated list of recording_msids for which feedback records are to be fetched.\n    :type score: ``str``\n    :statuscode 200: Yay, you have data!\n    :resheader Content-Type: *application/json*\n    \"\"\"\n\n    recordings = request.args.get('recordings')\n\n    recording_list = parse_param_list(recordings)\n    if not len(recording_list):\n        raise APIBadRequest(\"'recordings' has no valid recording_msid.\")\n\n    user = db_user.get_by_mb_id(user_name)\n    if user is None:\n        raise APINotFound(\"Cannot find user: %s\" % user_name)\n\n    try:\n        feedback = db_feedback.get_feedback_for_multiple_recordings_for_user(user_id=user[\"id\"], recording_list=recording_list)\n    except ValidationError as e:\n        # Validation errors from the Pydantic model are multi-line. While passing it as a response the new lines\n        # are displayed as \\n. str.replace() to tidy up the error message so that it becomes a good one line error message.\n        log_raise_400(\"Invalid JSON document submitted: %s\" % str(e).replace(\"\\n \", \":\").replace(\"\\n\", \" \"),\n                      request.args)\n\n    feedback = [_feedback_to_api(fb) for fb in feedback]\n\n    return jsonify({\n        \"feedback\": feedback,\n    })\n\n\ndef _feedback_to_api(fb: Feedback) -> dict:\n    fb.user_id = fb.user_name\n    del fb.user_name\n\n    return fb.dict()\n", "idx": 1, "id": 17507, "msg": "You should also check if passed recording msids are valid uuids.", "proj": "metabrainz-listenbrainz-server", "lang": "py"}
{"patch": "@@ -125,11 +125,13 @@ TEST_F(IndexTest, TagIndex) {\n         std::string query = \"SHOW TAG INDEX STATUS\";\n         auto code = client->execute(query, resp);\n         ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n-        std::vector<uniform_tuple_t<std::string, 2>> expected{\n-            {\"single_person_index\", \"SUCCEEDED\"},\n-            {\"multi_person_index\",  \"SUCCEEDED\"},\n-        };\n-        ASSERT_TRUE(verifyResult(resp, expected));\n+        /*\n+         * Currently , expected the index status is \"RUNNING\" or \"SUCCEEDED\"\n+         */\n+        for (auto& row : *resp.get_rows()) {\n+            const auto &columns = row.get_columns();\n+            ASSERT_NE(\"FAILED\", columns[1].get_str());\n+        }\n     }\n     {\n         cpp2::ExecutionResponse resp;", "y": 1, "oldf": "/* Copyright (c) 2018 vesoft inc. All rights reserved.\n *\n * This source code is licensed under Apache 2.0 License,\n * attached with Common Clause Condition 1.0, found in the LICENSES directory.\n */\n\n#include \"base/Base.h\"\n#include \"graph/test/TestEnv.h\"\n#include \"graph/test/TestBase.h\"\n\nDECLARE_int32(heartbeat_interval_secs);\n\nnamespace nebula {\nnamespace graph {\n\nclass IndexTest : public TestBase {\nprotected:\n    void SetUp() override {\n        TestBase::SetUp();\n        // ...\n    }\n\n    void TearDown() override {\n        // ...\n        TestBase::TearDown();\n    }\n};\n\nTEST_F(IndexTest, TagIndex) {\n    auto client = gEnv->getClient();\n    ASSERT_NE(nullptr, client);\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE SPACE tag_index_space(partition_num=1, replica_factor=1)\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n\n        query = \"USE tag_index_space\";\n        code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n\n        query = \"CREATE TAG person(name string, age int, gender string, email string)\";\n        code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n\n        query = \"CREATE TAG course(teacher string, score double)\";\n        code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    sleep(FLAGS_heartbeat_interval_secs + 1);\n    // Single Tag Single Field\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE TAG INDEX single_person_index ON person(name)\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Tag not exist\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE TAG INDEX single_person_index ON student(name)\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::E_EXECUTION_ERROR, code);\n    }\n    // Property not exist\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE TAG INDEX single_person_index ON person(phone)\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::E_EXECUTION_ERROR, code);\n    }\n    // Property is empty\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE TAG INDEX single_person_index ON person()\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::E_SYNTAX_ERROR, code);\n    }\n    // Single Tag Multi Field\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE TAG INDEX multi_person_index ON person(name, email)\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    {\n        cpp2::ExecutionResponse resp;\n        auto query = \"INSERT VERTEX person(name, age, gender, email) VALUES \"\n                     \"uuid(\\\"Tim\\\"):  (\\\"Tim\\\",  18, \\\"M\\\", \\\"tim@ve.com\\\"), \"\n                     \"uuid(\\\"Tony\\\"): (\\\"Tony\\\", 18, \\\"M\\\", \\\"tony@ve.com\\\"), \"\n                     \"uuid(\\\"May\\\"):  (\\\"May\\\",  18, \\\"F\\\", \\\"may@ve.com\\\"), \"\n                     \"uuid(\\\"Tom\\\"):  (\\\"Tom\\\",  18, \\\"M\\\", \\\"tom@ve.com\\\")\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    sleep(FLAGS_heartbeat_interval_secs + 1);\n    // Rebuild Tag Index\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"REBUILD TAG INDEX single_person_index OFFLINE\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"REBUILD TAG INDEX single_person_index\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::E_EXECUTION_ERROR, code);\n    }\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"REBUILD TAG INDEX multi_person_index OFFLINE\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"REBUILD TAG INDEX multi_person_index\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::E_EXECUTION_ERROR, code);\n    }\n    // Show Tag Index Status\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"SHOW TAG INDEX STATUS\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n        std::vector<uniform_tuple_t<std::string, 2>> expected{\n            {\"single_person_index\", \"SUCCEEDED\"},\n            {\"multi_person_index\",  \"SUCCEEDED\"},\n        };\n        ASSERT_TRUE(verifyResult(resp, expected));\n    }\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE TAG INDEX duplicate_index ON person(name, name)\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::E_EXECUTION_ERROR, code);\n    }\n    // Describe Tag Index\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"DESCRIBE TAG INDEX multi_person_index\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n        query = \"DESC TAG INDEX multi_person_index\";\n        code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n        std::vector<uniform_tuple_t<std::string, 2>> expected{\n            {\"name\",  \"string\"},\n            {\"email\", \"string\"},\n        };\n        ASSERT_TRUE(verifyResult(resp, expected));\n    }\n    // Show Create Tag Indexes\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"SHOW CREATE TAG INDEX multi_person_index\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n        std::string createTagIndex = \"CREATE TAG INDEX multi_person_index ON person(name, email)\";\n        std::vector<std::tuple<std::string, std::string>> expected{\n            {\"multi_person_index\", createTagIndex},\n        };\n        ASSERT_TRUE(verifyResult(resp, expected));\n    }\n    // List Tag Indexes\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"Show TAG INDEXES\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n        std::vector<std::tuple<int32_t, std::string>> expected{\n            {4, \"single_person_index\"},\n            {5, \"multi_person_index\"},\n        };\n        ASSERT_TRUE(verifyResult(resp, expected));\n    }\n    // Drop Tag Index\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"DROP TAG INDEX multi_person_index\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n        query = \"DESCRIBE TAG INDEX multi_person_index\";\n        code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::E_EXECUTION_ERROR, code);\n    }\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"DROP TAG INDEX not_exists_tag_index\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::E_EXECUTION_ERROR, code);\n    }\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"DROP TAG INDEX IF EXISTS not_exists_tag_index\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"DROP SPACE tag_index_space\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n}\n\n\nTEST_F(IndexTest, EdgeIndex) {\n    auto client = gEnv->getClient();\n    ASSERT_NE(nullptr, client);\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE SPACE edge_index_space(partition_num=1, replica_factor=1)\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n\n        query = \"USE edge_index_space\";\n        code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n\n        query = \"CREATE EDGE friend(degree string, start_time int)\";\n        code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n\n        query = \"CREATE EDGE transfer(amount double, bank string)\";\n        code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    sleep(FLAGS_heartbeat_interval_secs + 1);\n    // Single Edge Single Field\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE EDGE INDEX single_friend_index ON friend(degree)\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Edge not exist\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE EDGE INDEX single_friend_index ON friendship(name)\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::E_EXECUTION_ERROR, code);\n    }\n    // Property not exist\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE EDGE INDEX single_friend_index ON friend(startTime)\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::E_EXECUTION_ERROR, code);\n    }\n    // Property is empty\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE EDGE INDEX single_friend_index ON friend()\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::E_SYNTAX_ERROR, code);\n    }\n    // Single EDGE Multi Field\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE EDGE INDEX multi_friend_index ON friend(degree, start_time)\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    {\n        cpp2::ExecutionResponse resp;\n        auto query = \"INSERT EDGE friend(degree, start_time) VALUES \"\n                     \"uuid(\\\"Tim\\\")  -> uuid(\\\"May\\\"):  (\\\"Good\\\", 18), \"\n                     \"uuid(\\\"Tim\\\")  -> uuid(\\\"Tony\\\"): (\\\"Good\\\", 18), \"\n                     \"uuid(\\\"Tony\\\") -> uuid(\\\"May\\\"):  (\\\"Like\\\", 18), \"\n                     \"uuid(\\\"May\\\")  -> uuid(\\\"Tim\\\"):  (\\\"Like\\\", 18)\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    sleep(FLAGS_heartbeat_interval_secs + 1);\n    // Rebuild EDGE Index\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"REBUILD EDGE INDEX single_friend_index OFFLINE\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"REBUILD EDGE INDEX single_friend_index\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::E_EXECUTION_ERROR, code);\n    }\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"REBUILD EDGE INDEX multi_friend_index OFFLINE\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"REBUILD EDGE INDEX multi_friend_index\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::E_EXECUTION_ERROR, code);\n    }\n    // Show EDGE Index Status\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"SHOW EDGE INDEX STATUS\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n        std::vector<uniform_tuple_t<std::string, 2>> expected{\n            {\"single_friend_index\", \"SUCCEEDED\"},\n            {\"multi_friend_index\",  \"SUCCEEDED\"},\n        };\n        ASSERT_TRUE(verifyResult(resp, expected));\n    }\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE EDGE INDEX duplicate_index ON friend(degree, degree)\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::E_EXECUTION_ERROR, code);\n    }\n    // Describe Edge Index\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"DESCRIBE EDGE INDEX multi_friend_index\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n        query = \"DESC EDGE INDEX multi_friend_index\";\n        code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n        std::vector<uniform_tuple_t<std::string, 2>> expected{\n            {\"degree\",     \"string\"},\n            {\"start_time\", \"int\"},\n        };\n        ASSERT_TRUE(verifyResult(resp, expected));\n    }\n    // Show Create Edge Index\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"SHOW CREATE EDGE INDEX multi_friend_index\";\n        auto code = client->execute(query, resp);\n        std::string createTagIndex = \"CREATE EDGE INDEX multi_friend_index ON \"\n                                     \"friend(degree, start_time)\";\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n        std::vector<std::tuple<std::string, std::string>> expected{\n            {\"multi_friend_index\", createTagIndex},\n        };\n        ASSERT_TRUE(verifyResult(resp, expected));\n    }\n    // List Edge Indexes\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"SHOW EDGE INDEXES\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n        std::vector<std::tuple<int32_t, std::string>> expected{\n            {9, \"single_friend_index\"},\n            {10, \"multi_friend_index\"},\n        };\n        ASSERT_TRUE(verifyResult(resp, expected));\n    }\n    // Drop Edge Index\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"DROP EDGE INDEX multi_friend_index\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n        query = \"DESCRIBE EDGE INDEX multi_friend_index\";\n        code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::E_EXECUTION_ERROR, code);\n    }\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"DROP EDGE INDEX not_exists_edge_index\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::E_EXECUTION_ERROR, code);\n    }\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"DROP EDGE INDEX IF EXISTS not_exists_edge_index\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"DROP SPACE edge_index_space\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n}\n\n\nTEST_F(IndexTest, TagIndexTTL) {\n    auto client = gEnv->getClient();\n    ASSERT_NE(nullptr, client);\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE SPACE tag_ttl_index_space(partition_num=1, replica_factor=1)\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n\n        query = \"USE tag_ttl_index_space\";\n        code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n\n        query = \"CREATE TAG person_ttl(name string, age int, gender int, email string)\";\n        code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Single Tag Single Field\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE TAG INDEX single_person_ttl_index ON person_ttl(age)\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Alter tag add ttl property on index col, failed\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"ALTER TAG person_ttl ttl_duration = 100, ttl_col = \\\"age\\\"\";\n        auto code = client->execute(query, resp);\n        ASSERT_NE(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Alter tag add ttl property on not index col, failed\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"ALTER TAG person_ttl ttl_duration = 100, ttl_col = \\\"gender\\\"\";\n        auto code = client->execute(query, resp);\n        ASSERT_NE(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Drop index\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"DROP TAG INDEX single_person_ttl_index\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Alter tag add ttl property on index col, succeed\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"ALTER TAG person_ttl ttl_duration = 100, ttl_col = \\\"age\\\"\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Alter tag add ttl property on not index col, succeed\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"ALTER TAG person_ttl ttl_duration = 100, ttl_col = \\\"gender\\\"\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Tag with ttl to create index on ttl col, failed\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE TAG INDEX single_person_ttl_index_second ON person_ttl(gender)\";\n        auto code = client->execute(query, resp);\n        ASSERT_NE(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Tag with ttl to create index on not ttl col, failed\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE TAG INDEX single_person_ttl_index_second ON person_ttl(age)\";\n        auto code = client->execute(query, resp);\n        ASSERT_NE(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Drop ttl propery\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"ALTER TAG person_ttl  ttl_col = \\\"\\\"\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Tag with ttl to create index, succeed\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE TAG INDEX single_person_ttl_index_second ON person_ttl(age)\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n     {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"DROP TAG INDEX single_person_ttl_index_second\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE TAG person_ttl_2(name string, age int, gender string) \"\n                            \"ttl_duration = 200, ttl_col = \\\"age\\\"\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Tag with ttl cannot create index on not ttl col\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE TAG INDEX person_ttl_2_index ON person_ttl_2(name)\";\n        auto code = client->execute(query, resp);\n        ASSERT_NE(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Tag with ttl cannot create index on ttl col\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE TAG INDEX person_ttl_2_index ON person_ttl_2(age)\";\n        auto code = client->execute(query, resp);\n        ASSERT_NE(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Drop ttl col\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"ALTER TAG person_ttl_2 DROP (age)\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Create index, succeed\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE TAG INDEX person_ttl_2_index ON person_ttl_2(name)\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"DROP TAG INDEX person_ttl_2_index\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"DROP SPACE tag_ttl_index_space\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n}\n\n\nTEST_F(IndexTest, EdgeIndexTTL) {\n    auto client = gEnv->getClient();\n    ASSERT_NE(nullptr, client);\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE SPACE edge_ttl_index_space(partition_num=1, replica_factor=1)\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n\n        query = \"USE edge_ttl_index_space\";\n        code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n\n        query = \"CREATE EDGE friend_ttl(degree int, start_time int)\";\n        code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Single Edge Single Field\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE EDGE INDEX single_friend_ttl_index ON friend_ttl(start_time)\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Alter edge add ttl property on index col, failed\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"ALTER edge friend_ttl ttl_duration = 100, ttl_col = \\\"start_time\\\"\";\n        auto code = client->execute(query, resp);\n        ASSERT_NE(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Alter edge add ttl property on not index col, failed\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"ALTER edge friend_ttl ttl_duration = 100, ttl_col = \\\"degree\\\"\";\n        auto code = client->execute(query, resp);\n        ASSERT_NE(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Drop index\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"DROP EDGE INDEX single_friend_ttl_index\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Alter edge add ttl property on index col, succeed\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"ALTER edge friend_ttl ttl_duration = 100, ttl_col = \\\"start_time\\\"\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Alter edge add ttl property on not index col, succeed\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"ALTER edge friend_ttl ttl_duration = 100, ttl_col = \\\"degree\\\"\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Edge with ttl to create index on ttl col, failed\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE EDGE INDEX friend_ttl_index_second ON friend_ttl(degree)\";\n        auto code = client->execute(query, resp);\n        ASSERT_NE(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Edge with ttl to create index on no ttl col, failed\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE EDGE INDEX friend_ttl_index_second ON friend_ttl(start_time)\";\n        auto code = client->execute(query, resp);\n        ASSERT_NE(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Drop ttl propery\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"ALTER EDGE friend_ttl ttl_col = \\\"\\\"\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Edge without ttl to create index, succeed\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE EDGE INDEX friend_ttl_index_second ON friend_ttl(start_time)\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Drop index\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"DROP EDGE INDEX friend_ttl_index_second\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE EDGE friend_ttl_2(degree int, start_time int) \"\n                            \"ttl_duration = 200, ttl_col = \\\"start_time\\\"\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Edge with ttl cannot create index on not ttl col\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE EDGE INDEX friend_ttl_index_2 ON friend_ttl_2(degree)\";\n        auto code = client->execute(query, resp);\n        ASSERT_NE(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Edge with ttl cannot create index on ttl col\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE EDGE INDEX friend_ttl_index_2 ON friend_ttl_2(start_time)\";\n        auto code = client->execute(query, resp);\n        ASSERT_NE(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Drop ttl col\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"ALTER EDGE friend_ttl_2 DROP (start_time)\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    // Create index, succeed\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"CREATE EDGE INDEX friend_ttl_index_2 ON friend_ttl_2(degree)\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    {\n    // Drop index\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"DROP EDGE INDEX friend_ttl_index_2\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n        cpp2::ExecutionResponse resp;\n        std::string query = \"DROP EDGE friend_ttl_2\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n    {\n        cpp2::ExecutionResponse resp;\n        std::string query = \"DROP SPACE edge_ttl_index_space\";\n        auto code = client->execute(query, resp);\n        ASSERT_EQ(cpp2::ErrorCode::SUCCEEDED, code);\n    }\n}\n\n}   // namespace graph\n}   // namespace nebula\n\n", "idx": 1, "id": 28787, "msg": "I think you can try 3 time checking.", "proj": "vesoft-inc-nebula", "lang": "cpp"}
{"patch": "@@ -85,21 +85,18 @@ define(['appSettings', 'userSettings', 'playbackManager', 'connectionManager', '\n     };\n \n     /**\n-     * Initialize Cast media player \n+     * Initialize Cast media player\n      * Initializes the API. Note that either successCallback and errorCallback will be\n-     * invoked once the API has finished initialization. The sessionListener and \n-     * receiverListener may be invoked at any time afterwards, and possibly more than once. \n+     * invoked once the API has finished initialization. The sessionListener and\n+     * receiverListener may be invoked at any time afterwards, and possibly more than once.\n      */\n     CastPlayer.prototype.initializeCastPlayer = function () {\n-\n         var chrome = window.chrome;\n-\n         if (!chrome) {\n             return;\n         }\n \n         if (!chrome.cast || !chrome.cast.isAvailable) {\n-\n             setTimeout(this.initializeCastPlayer.bind(this), 1000);\n             return;\n         }", "y": 0, "oldf": "define(['appSettings', 'userSettings', 'playbackManager', 'connectionManager', 'globalize', 'events', 'require', 'castSenderApiLoader'], function (appSettings, userSettings, playbackManager, connectionManager, globalize, events, require, castSenderApiLoader) {\n    'use strict';\n\n    // Based on https://github.com/googlecast/CastVideos-chrome/blob/master/CastVideos.js\n    var currentResolve;\n    var currentReject;\n\n    var PlayerName = 'Chromecast';\n\n    function sendConnectionResult(isOk) {\n\n        var resolve = currentResolve;\n        var reject = currentReject;\n\n        currentResolve = null;\n        currentReject = null;\n\n        if (isOk) {\n            if (resolve) {\n                resolve();\n            }\n        } else {\n            if (reject) {\n                reject();\n            } else {\n                playbackManager.removeActivePlayer(PlayerName);\n            }\n        }\n    }\n\n    /**\n     * Constants of states for Chromecast device \n     **/\n    var DEVICE_STATE = {\n        'IDLE': 0,\n        'ACTIVE': 1,\n        'WARNING': 2,\n        'ERROR': 3\n    };\n\n    /**\n     * Constants of states for CastPlayer \n     **/\n    var PLAYER_STATE = {\n        'IDLE': 'IDLE',\n        'LOADING': 'LOADING',\n        'LOADED': 'LOADED',\n        'PLAYING': 'PLAYING',\n        'PAUSED': 'PAUSED',\n        'STOPPED': 'STOPPED',\n        'SEEKING': 'SEEKING',\n        'ERROR': 'ERROR'\n    };\n\n    var applicationID = \"F007D354\";\n\n    // This is the beta version used for testing new changes\n\n    //applicationID = '27C4EB5B';\n\n    var messageNamespace = 'urn:x-cast:com.connectsdk';\n\n    var CastPlayer = function () {\n\n        /* device variables */\n        // @type {DEVICE_STATE} A state for device\n        this.deviceState = DEVICE_STATE.IDLE;\n\n        /* Cast player variables */\n        // @type {Object} a chrome.cast.media.Media object\n        this.currentMediaSession = null;\n\n        // @type {string} a chrome.cast.Session object\n        this.session = null;\n        // @type {PLAYER_STATE} A state for Cast media player\n        this.castPlayerState = PLAYER_STATE.IDLE;\n\n        this.hasReceivers = false;\n\n        // bind once - commit 2ebffc2271da0bc5e8b13821586aee2a2e3c7753\n        this.errorHandler = this.onError.bind(this);\n        this.mediaStatusUpdateHandler = this.onMediaStatusUpdate.bind(this);\n\n        this.initializeCastPlayer();\n    };\n\n    /**\n     * Initialize Cast media player \n     * Initializes the API. Note that either successCallback and errorCallback will be\n     * invoked once the API has finished initialization. The sessionListener and \n     * receiverListener may be invoked at any time afterwards, and possibly more than once. \n     */\n    CastPlayer.prototype.initializeCastPlayer = function () {\n\n        var chrome = window.chrome;\n\n        if (!chrome) {\n            return;\n        }\n\n        if (!chrome.cast || !chrome.cast.isAvailable) {\n\n            setTimeout(this.initializeCastPlayer.bind(this), 1000);\n            return;\n        }\n\n        // request session\n        var sessionRequest = new chrome.cast.SessionRequest(applicationID);\n        var apiConfig = new chrome.cast.ApiConfig(sessionRequest,\n            this.sessionListener.bind(this),\n            this.receiverListener.bind(this),\n            \"origin_scoped\");\n\n        console.log('chromecast.initialize');\n\n        chrome.cast.initialize(apiConfig, this.onInitSuccess.bind(this), this.errorHandler);\n\n    };\n\n    /**\n     * Callback function for init success \n     */\n    CastPlayer.prototype.onInitSuccess = function () {\n        this.isInitialized = true;\n        console.log(\"chromecast init success\");\n    };\n\n    /**\n     * Generic error callback function \n     */\n    CastPlayer.prototype.onError = function () {\n        console.log(\"chromecast error\");\n    };\n\n    /**\n     * @param {!Object} e A new session\n     * This handles auto-join when a page is reloaded\n     * When active session is detected, playback will automatically\n     * join existing session and occur in Cast mode and media\n     * status gets synced up with current media of the session \n     */\n    CastPlayer.prototype.sessionListener = function (e) {\n\n        this.session = e;\n        if (this.session) {\n\n            //console.log('sessionListener ' + JSON.stringify(e));\n\n            if (this.session.media[0]) {\n                this.onMediaDiscovered('activeSession', this.session.media[0]);\n            }\n\n            this.onSessionConnected(e);\n        }\n    };\n\n    function alertText(text, title) {\n        require(['alert'], function (alert) {\n            alert({\n                text: text,\n                title: title\n            });\n        });\n    }\n\n    CastPlayer.prototype.messageListener = function (namespace, message) {\n\n        if (typeof (message) === 'string') {\n            message = JSON.parse(message);\n        }\n\n        if (message.type === 'playbackerror') {\n\n            var errorCode = message.data;\n\n            setTimeout(function () {\n                alertText(globalize.translate('MessagePlaybackError' + errorCode), globalize.translate('HeaderPlaybackError'));\n            }, 300);\n\n        }\n        else if (message.type === 'connectionerror') {\n\n            setTimeout(function () {\n                alertText(globalize.translate('MessageChromecastConnectionError'), globalize.translate('HeaderError'));\n            }, 300);\n\n        }\n        else if (message.type) {\n            events.trigger(this, message.type, [message.data]);\n        }\n    };\n\n    /**\n     * @param {string} e Receiver availability\n     * This indicates availability of receivers but\n     * does not provide a list of device IDs\n     */\n    CastPlayer.prototype.receiverListener = function (e) {\n\n        if (e === 'available') {\n            //console.log(\"chromecast receiver found\");\n            this.hasReceivers = true;\n        }\n        else {\n            //console.log(\"chromecast receiver list empty\");\n            this.hasReceivers = false;\n        }\n    };\n\n    /**\n     * session update listener\n     */\n    CastPlayer.prototype.sessionUpdateListener = function (isAlive) {\n\n        //console.log('sessionUpdateListener alive: ' + isAlive);\n\n        if (isAlive) {\n        }\n        else {\n            this.session = null;\n            this.deviceState = DEVICE_STATE.IDLE;\n            this.castPlayerState = PLAYER_STATE.IDLE;\n            document.removeEventListener(\"volumeupbutton\", onVolumeUpKeyDown, false);\n            document.removeEventListener(\"volumedownbutton\", onVolumeDownKeyDown, false);\n    \n            //console.log('sessionUpdateListener: setting currentMediaSession to null');\n            this.currentMediaSession = null;\n\n            sendConnectionResult(false);\n        }\n    };\n\n    /**\n     * Requests that a receiver application session be created or joined. By default, the SessionRequest\n     * passed to the API at initialization time is used; this may be overridden by passing a different\n     * session request in opt_sessionRequest. \n     */\n    CastPlayer.prototype.launchApp = function () {\n        //console.log(\"chromecast launching app...\");\n        chrome.cast.requestSession(this.onRequestSessionSuccess.bind(this), this.onLaunchError.bind(this));\n    };\n\n    /**\n     * Callback function for request session success \n     * @param {Object} e A chrome.cast.Session object\n     */\n    CastPlayer.prototype.onRequestSessionSuccess = function (e) {\n\n        //console.log(\"chromecast session success: \" + e.sessionId);\n        this.onSessionConnected(e);\n    };\n\n    CastPlayer.prototype.onSessionConnected = function (session) {\n\n        this.session = session;\n\n        this.deviceState = DEVICE_STATE.ACTIVE;\n\n        this.session.addMessageListener(messageNamespace, this.messageListener.bind(this));\n        this.session.addMediaListener(this.sessionMediaListener.bind(this));\n        this.session.addUpdateListener(this.sessionUpdateListener.bind(this));\n\n        document.addEventListener(\"volumeupbutton\", onVolumeUpKeyDown, false);\n        document.addEventListener(\"volumedownbutton\", onVolumeDownKeyDown, false);\n\n        events.trigger(this, 'connect');\n\n        this.sendMessage({\n            options: {},\n            command: 'Identify'\n        });\n    };\n\n    function onVolumeUpKeyDown() {\n        playbackManager.volumeUp();\n    }\n    \n    function onVolumeDownKeyDown() {\n        playbackManager.volumeDown();\n    }\n\n    /**\n     * session update listener\n     */\n    CastPlayer.prototype.sessionMediaListener = function (e) {\n\n        //console.log('sessionMediaListener');\n        this.currentMediaSession = e;\n        this.currentMediaSession.addUpdateListener(this.mediaStatusUpdateHandler);\n    };\n\n    /**\n     * Callback function for launch error\n     */\n    CastPlayer.prototype.onLaunchError = function () {\n        //console.log(\"chromecast launch error\");\n        this.deviceState = DEVICE_STATE.ERROR;\n\n        sendConnectionResult(false);\n    };\n\n    /**\n     * Stops the running receiver application associated with the session.\n     */\n    CastPlayer.prototype.stopApp = function () {\n\n        if (this.session) {\n            this.session.stop(this.onStopAppSuccess.bind(this, 'Session stopped'),\n                this.errorHandler);\n        }\n\n    };\n\n    /**\n     * Callback function for stop app success \n     */\n    CastPlayer.prototype.onStopAppSuccess = function (message) {\n        //console.log(message);\n        this.deviceState = DEVICE_STATE.IDLE;\n        this.castPlayerState = PLAYER_STATE.IDLE;\n        document.removeEventListener(\"volumeupbutton\", onVolumeUpKeyDown, false);\n        document.removeEventListener(\"volumedownbutton\", onVolumeDownKeyDown, false);\n\n        //console.log('onStopAppSuccess: setting currentMediaSession to null');\n        this.currentMediaSession = null;\n    };\n\n    /**\n     * Loads media into a running receiver application\n     * @param {Number} mediaIndex An index number to indicate current media content\n     */\n    CastPlayer.prototype.loadMedia = function (options, command) {\n\n        if (!this.session) {\n            //console.log(\"no session\");\n            return Promise.reject();\n        }\n\n        // Convert the items to smaller stubs to send the minimal amount of information\n        options.items = options.items.map(function (i) {\n\n            return {\n                Id: i.Id,\n                ServerId: i.ServerId,\n                Name: i.Name,\n                Type: i.Type,\n                MediaType: i.MediaType,\n                IsFolder: i.IsFolder\n            };\n        });\n\n        return this.sendMessage({\n            options: options,\n            command: command\n        });\n    };\n\n    CastPlayer.prototype.sendMessage = function (message) {\n\n        var player = this;\n\n        var receiverName = null;\n\n        var session = player.session;\n\n        if (session && session.receiver && session.receiver.friendlyName) {\n            receiverName = session.receiver.friendlyName;\n        }\n\n        var apiClient;\n        if (message.options && message.options.ServerId) {\n            apiClient = connectionManager.getApiClient(message.options.ServerId);\n        } else if (message.options && message.options.items && message.options.items.length) {\n            apiClient = connectionManager.getApiClient(message.options.items[0].ServerId);\n        } else {\n            apiClient = connectionManager.currentApiClient();\n        }\n\n        message = Object.assign(message, {\n            userId: apiClient.getCurrentUserId(),\n            deviceId: apiClient.deviceId(),\n            accessToken: apiClient.accessToken(),\n            serverAddress: apiClient.serverAddress(),\n            serverId: apiClient.serverId(),\n            serverVersion: apiClient.serverVersion(),\n            receiverName: receiverName\n        });\n\n        var bitrateSetting = appSettings.maxChromecastBitrate();\n        if (bitrateSetting) {\n            message.maxBitrate = bitrateSetting;\n        }\n\n        if (message.options && message.options.items) {\n            message.subtitleAppearance = userSettings.getSubtitleAppearanceSettings();\n            message.subtitleBurnIn = appSettings.get('subtitleburnin') || '';\n        }\n\n        return new Promise(function (resolve, reject) {\n\n            require(['chromecastHelper'], function (chromecastHelper) {\n\n                chromecastHelper.getServerAddress(apiClient).then(function (serverAddress) {\n                    message.serverAddress = serverAddress;\n                    player.sendMessageInternal(message).then(resolve, reject);\n\n                }, reject);\n            });\n        });\n    };\n\n    CastPlayer.prototype.sendMessageInternal = function (message) {\n\n        message = JSON.stringify(message);\n        //console.log(message);\n\n        this.session.sendMessage(messageNamespace, message, this.onPlayCommandSuccess.bind(this), this.errorHandler);\n        return Promise.resolve();\n    };\n\n    CastPlayer.prototype.onPlayCommandSuccess = function () {\n        //console.log('Message was sent to receiver ok.');\n    };\n\n    /**\n     * Callback function for loadMedia success\n     * @param {Object} mediaSession A new media object.\n     */\n    CastPlayer.prototype.onMediaDiscovered = function (how, mediaSession) {\n\n        //console.log(\"chromecast new media session ID:\" + mediaSession.mediaSessionId + ' (' + how + ')');\n        this.currentMediaSession = mediaSession;\n\n        if (how === 'loadMedia') {\n            this.castPlayerState = PLAYER_STATE.PLAYING;\n        }\n\n        if (how === 'activeSession') {\n            this.castPlayerState = mediaSession.playerState;\n        }\n\n        this.currentMediaSession.addUpdateListener(this.mediaStatusUpdateHandler);\n    };\n\n    /**\n     * Callback function for media status update from receiver\n     * @param {!Boolean} e true/false\n     */\n    CastPlayer.prototype.onMediaStatusUpdate = function (e) {\n\n        if (e === false) {\n            this.castPlayerState = PLAYER_STATE.IDLE;\n        }\n        //console.log(\"chromecast updating media: \" + e);\n    };\n\n    /**\n     * Set media volume in Cast mode\n     * @param {Boolean} mute A boolean  \n     */\n    CastPlayer.prototype.setReceiverVolume = function (mute, vol) {\n\n        if (!this.currentMediaSession) {\n            //console.log('this.currentMediaSession is null');\n            return;\n        }\n\n        if (!mute) {\n\n            this.session.setReceiverVolumeLevel((vol || 1),\n                this.mediaCommandSuccessCallback.bind(this),\n                this.errorHandler);\n        }\n        else {\n            this.session.setReceiverMuted(true,\n                this.mediaCommandSuccessCallback.bind(this),\n                this.errorHandler);\n        }\n    };\n\n    /**\n     * Mute CC\n     */\n    CastPlayer.prototype.mute = function () {\n        this.setReceiverVolume(true);\n    };\n\n    /**\n     * Callback function for media command success \n     */\n    CastPlayer.prototype.mediaCommandSuccessCallback = function (info, e) {\n        //console.log(info);\n    };\n\n    function normalizeImages(state) {\n\n        if (state && state.NowPlayingItem) {\n\n            var item = state.NowPlayingItem;\n\n            if (!item.ImageTags || !item.ImageTags.Primary) {\n                if (item.PrimaryImageTag) {\n                    item.ImageTags = item.ImageTags || {};\n                    item.ImageTags.Primary = item.PrimaryImageTag;\n                }\n            }\n            if (item.BackdropImageTag && item.BackdropItemId === item.Id) {\n                item.BackdropImageTags = [item.BackdropImageTag];\n            }\n            if (item.BackdropImageTag && item.BackdropItemId !== item.Id) {\n                item.ParentBackdropImageTags = [item.BackdropImageTag];\n                item.ParentBackdropItemId = item.BackdropItemId;\n            }\n        }\n    }\n\n    function getItemsForPlayback(apiClient, query) {\n\n        var userId = apiClient.getCurrentUserId();\n\n        if (query.Ids && query.Ids.split(',').length === 1) {\n            return apiClient.getItem(userId, query.Ids.split(',')).then(function (item) {\n                return {\n                    Items: [item],\n                    TotalRecordCount: 1\n                };\n            });\n        }\n        else {\n\n            query.Limit = query.Limit || 100;\n            query.ExcludeLocationTypes = \"Virtual\";\n            query.EnableTotalRecordCount = false;\n\n            return apiClient.getItems(userId, query);\n        }\n    }\n\n    function bindEventForRelay(instance, eventName) {\n\n        events.on(instance._castPlayer, eventName, function (e, data) {\n\n            //console.log('cc: ' + eventName);\n            var state = instance.getPlayerStateInternal(data);\n\n            events.trigger(instance, eventName, [state]);\n        });\n    }\n\n    function initializeChromecast() {\n\n        var instance = this;\n        instance._castPlayer = new CastPlayer();\n\n        // To allow the native android app to override\n        document.dispatchEvent(new CustomEvent(\"chromecastloaded\", {\n            detail: {\n                player: instance\n            }\n        }));\n\n        events.on(instance._castPlayer, \"connect\", function (e) {\n\n            if (currentResolve) {\n                sendConnectionResult(true);\n            } else {\n                playbackManager.setActivePlayer(PlayerName, instance.getCurrentTargetInfo());\n            }\n\n            console.log('cc: connect');\n            // Reset this so that statechange will fire\n            instance.lastPlayerData = null;\n        });\n\n        events.on(instance._castPlayer, \"playbackstart\", function (e, data) {\n\n            console.log('cc: playbackstart');\n\n            instance._castPlayer.initializeCastPlayer();\n\n            var state = instance.getPlayerStateInternal(data);\n            events.trigger(instance, \"playbackstart\", [state]);\n        });\n\n        events.on(instance._castPlayer, \"playbackstop\", function (e, data) {\n\n            console.log('cc: playbackstop');\n            var state = instance.getPlayerStateInternal(data);\n\n            events.trigger(instance, \"playbackstop\", [state]);\n\n            var state = instance.lastPlayerData.PlayState || {};\n            var volume = state.VolumeLevel || 0.5;\n            var mute = state.IsMuted || false;\n\n            // Reset this so the next query doesn't make it appear like content is playing.\n            instance.lastPlayerData = {};\n            instance.lastPlayerData.PlayState = {};\n            instance.lastPlayerData.PlayState.VolumeLevel = volume;\n            instance.lastPlayerData.PlayState.IsMuted = mute;\n        });\n\n        events.on(instance._castPlayer, \"playbackprogress\", function (e, data) {\n\n            //console.log('cc: positionchange');\n            var state = instance.getPlayerStateInternal(data);\n\n            events.trigger(instance, \"timeupdate\", [state]);\n        });\n\n        bindEventForRelay(instance, 'timeupdate');\n        bindEventForRelay(instance, 'pause');\n        bindEventForRelay(instance, 'unpause');\n        bindEventForRelay(instance, 'volumechange');\n        bindEventForRelay(instance, 'repeatmodechange');\n\n        events.on(instance._castPlayer, \"playstatechange\", function (e, data) {\n\n            //console.log('cc: playstatechange');\n            var state = instance.getPlayerStateInternal(data);\n\n            events.trigger(instance, \"pause\", [state]);\n        });\n    }\n\n    function ChromecastPlayer() {\n\n        // playbackManager needs this\n        this.name = PlayerName;\n        this.type = 'mediaplayer';\n        this.id = 'chromecast';\n        this.isLocalPlayer = false;\n        this.lastPlayerData = {};\n\n        castSenderApiLoader.load().then(initializeChromecast.bind(this));\n    }\n\n    ChromecastPlayer.prototype.tryPair = function (target) {\n\n        var castPlayer = this._castPlayer;\n\n        if (castPlayer.deviceState !== DEVICE_STATE.ACTIVE && castPlayer.isInitialized) {\n\n            return new Promise(function (resolve, reject) {\n                currentResolve = resolve;\n                currentReject = reject;\n\n                castPlayer.launchApp();\n            });\n        } else {\n\n            currentResolve = null;\n            currentReject = null;\n\n            return Promise.reject();\n        }\n    };\n\n    ChromecastPlayer.prototype.getTargets = function () {\n\n        var targets = [];\n\n        if (this._castPlayer && this._castPlayer.hasReceivers) {\n            targets.push(this.getCurrentTargetInfo());\n        }\n\n        return Promise.resolve(targets);\n    };\n\n    // This is a privately used method\n    ChromecastPlayer.prototype.getCurrentTargetInfo = function () {\n\n        var appName = null;\n\n        var castPlayer = this._castPlayer;\n\n        if (castPlayer.session && castPlayer.session.receiver && castPlayer.session.receiver.friendlyName) {\n            appName = castPlayer.session.receiver.friendlyName;\n        }\n\n        return {\n            name: PlayerName,\n            id: PlayerName,\n            playerName: PlayerName,\n            playableMediaTypes: [\"Audio\", \"Video\"],\n            isLocalPlayer: false,\n            appName: PlayerName,\n            deviceName: appName,\n            supportedCommands: [\n                \"VolumeUp\",\n                \"VolumeDown\",\n                \"Mute\",\n                \"Unmute\",\n                \"ToggleMute\",\n                \"SetVolume\",\n                \"SetAudioStreamIndex\",\n                \"SetSubtitleStreamIndex\",\n                \"DisplayContent\",\n                \"SetRepeatMode\",\n                \"EndSession\",\n                \"PlayMediaSource\",\n                \"PlayTrailers\"\n            ]\n        };\n    };\n\n    ChromecastPlayer.prototype.getPlayerStateInternal = function (data) {\n\n        var triggerStateChange = false;\n        if (data && !this.lastPlayerData) {\n            triggerStateChange = true;\n        }\n\n        data = data || this.lastPlayerData;\n        this.lastPlayerData = data;\n\n        normalizeImages(data);\n\n        //console.log(JSON.stringify(data));\n\n        if (triggerStateChange) {\n            events.trigger(this, \"statechange\", [data]);\n        }\n\n        return data;\n    };\n\n    ChromecastPlayer.prototype.playWithCommand = function (options, command) {\n\n        if (!options.items) {\n            var apiClient = connectionManager.getApiClient(options.serverId);\n            var instance = this;\n\n            return apiClient.getItem(apiClient.getCurrentUserId(), options.ids[0]).then(function (item) {\n\n                options.items = [item];\n                return instance.playWithCommand(options, command);\n            });\n        }\n\n        return this._castPlayer.loadMedia(options, command);\n    };\n\n    ChromecastPlayer.prototype.seek = function (position) {\n\n        position = parseInt(position);\n\n        position = position / 10000000;\n\n        this._castPlayer.sendMessage({\n            options: {\n                position: position\n            },\n            command: 'Seek'\n        });\n    };\n\n    ChromecastPlayer.prototype.setAudioStreamIndex = function (index) {\n        this._castPlayer.sendMessage({\n            options: {\n                index: index\n            },\n            command: 'SetAudioStreamIndex'\n        });\n    };\n\n    ChromecastPlayer.prototype.setSubtitleStreamIndex = function (index) {\n        this._castPlayer.sendMessage({\n            options: {\n                index: index\n            },\n            command: 'SetSubtitleStreamIndex'\n        });\n    };\n\n    ChromecastPlayer.prototype.setMaxStreamingBitrate = function (options) {\n\n        this._castPlayer.sendMessage({\n            options: options,\n            command: 'SetMaxStreamingBitrate'\n        });\n    };\n\n    ChromecastPlayer.prototype.isFullscreen = function () {\n        var state = this.lastPlayerData || {};\n        state = state.PlayState || {};\n        return state.IsFullscreen;\n    };\n\n    ChromecastPlayer.prototype.nextTrack = function () {\n        this._castPlayer.sendMessage({\n            options: {},\n            command: 'NextTrack'\n        });\n    };\n\n    ChromecastPlayer.prototype.previousTrack = function () {\n        this._castPlayer.sendMessage({\n            options: {},\n            command: 'PreviousTrack'\n        });\n    };\n\n    ChromecastPlayer.prototype.volumeDown = function () {\n        var vol = this._castPlayer.session.receiver.volume.level;\n        if (vol == null)\n        {\n            vol = 0.5;\n        }\n        vol -= 0.05;\n        vol = Math.max(vol, 0);\n\n        this._castPlayer.session.setReceiverVolumeLevel(vol);\n\n    };\n\n    ChromecastPlayer.prototype.endSession = function () {\n\n        var instance = this;\n\n        this.stop().then(function () {\n            setTimeout(function () {\n                instance._castPlayer.stopApp();\n            }, 1000);\n        });\n    };\n\n    ChromecastPlayer.prototype.volumeUp = function () {\n        var vol = this._castPlayer.session.receiver.volume.level;\n        if (vol == null)\n        {\n            vol = 0.5;\n        }\n        vol += 0.05;\n        vol = Math.min(vol, 1);\n\n        this._castPlayer.session.setReceiverVolumeLevel(vol);\n    };\n\n    ChromecastPlayer.prototype.setVolume = function (vol) {\n\n        vol = Math.min(vol, 100);\n        vol = Math.max(vol, 0);\n        vol = vol / 100;\n        \n        this._castPlayer.session.setReceiverVolumeLevel(vol);\n    };\n\n    ChromecastPlayer.prototype.unpause = function () {\n        this._castPlayer.sendMessage({\n            options: {},\n            command: 'Unpause'\n        });\n    };\n\n    ChromecastPlayer.prototype.playPause = function () {\n        this._castPlayer.sendMessage({\n            options: {},\n            command: 'PlayPause'\n        });\n    };\n\n    ChromecastPlayer.prototype.pause = function () {\n        this._castPlayer.sendMessage({\n            options: {},\n            command: 'Pause'\n        });\n    };\n\n    ChromecastPlayer.prototype.stop = function () {\n        return this._castPlayer.sendMessage({\n            options: {},\n            command: 'Stop'\n        });\n    };\n\n    ChromecastPlayer.prototype.displayContent = function (options) {\n\n        this._castPlayer.sendMessage({\n            options: options,\n            command: 'DisplayContent'\n        });\n    };\n\n    ChromecastPlayer.prototype.setMute = function (isMuted) {\n\n        var castPlayer = this._castPlayer;\n\n        if (isMuted) {\n            castPlayer.sendMessage({\n                options: {},\n                command: 'Mute'\n            });\n        } else {\n            castPlayer.sendMessage({\n                options: {},\n                command: 'Unmute'\n            });\n        }\n    };\n\n    ChromecastPlayer.prototype.getRepeatMode = function () {\n        var state = this.lastPlayerData || {};\n        state = state.PlayState || {};\n        return state.RepeatMode;\n    };\n\n    ChromecastPlayer.prototype.playTrailers = function (item) {\n\n        this._castPlayer.sendMessage({\n            options: {\n                ItemId: item.Id,\n                ServerId: item.ServerId\n            },\n            command: 'PlayTrailers'\n        });\n    };\n\n    ChromecastPlayer.prototype.setRepeatMode = function (mode) {\n        this._castPlayer.sendMessage({\n            options: {\n                RepeatMode: mode\n            },\n            command: 'SetRepeatMode'\n        });\n    };\n\n    ChromecastPlayer.prototype.toggleMute = function () {\n\n        this._castPlayer.sendMessage({\n            options: {},\n            command: 'ToggleMute'\n        });\n    };\n\n    ChromecastPlayer.prototype.audioTracks = function () {\n        var state = this.lastPlayerData || {};\n        state = state.NowPlayingItem || {};\n        var streams = state.MediaStreams || [];\n        return streams.filter(function (s) {\n            return s.Type === 'Audio';\n        });\n    };\n\n    ChromecastPlayer.prototype.getAudioStreamIndex = function () {\n        var state = this.lastPlayerData || {};\n        state = state.PlayState || {};\n        return state.AudioStreamIndex;\n    };\n\n    ChromecastPlayer.prototype.subtitleTracks = function () {\n        var state = this.lastPlayerData || {};\n        state = state.NowPlayingItem || {};\n        var streams = state.MediaStreams || [];\n        return streams.filter(function (s) {\n            return s.Type === 'Subtitle';\n        });\n    };\n\n    ChromecastPlayer.prototype.getSubtitleStreamIndex = function () {\n        var state = this.lastPlayerData || {};\n        state = state.PlayState || {};\n        return state.SubtitleStreamIndex;\n    };\n\n    ChromecastPlayer.prototype.getMaxStreamingBitrate = function () {\n        var state = this.lastPlayerData || {};\n        state = state.PlayState || {};\n        return state.MaxStreamingBitrate;\n    };\n\n    ChromecastPlayer.prototype.getVolume = function () {\n\n        var state = this.lastPlayerData || {};\n        state = state.PlayState || {};\n\n        return state.VolumeLevel == null ? 100 : state.VolumeLevel;\n    };\n\n    ChromecastPlayer.prototype.isPlaying = function () {\n        var state = this.lastPlayerData || {};\n        return state.NowPlayingItem != null;\n    };\n\n    ChromecastPlayer.prototype.isPlayingVideo = function () {\n        var state = this.lastPlayerData || {};\n        state = state.NowPlayingItem || {};\n        return state.MediaType === 'Video';\n    };\n\n    ChromecastPlayer.prototype.isPlayingAudio = function () {\n        var state = this.lastPlayerData || {};\n        state = state.NowPlayingItem || {};\n        return state.MediaType === 'Audio';\n    };\n\n    ChromecastPlayer.prototype.currentTime = function (val) {\n\n        if (val != null) {\n            return this.seek(val);\n        }\n\n        var state = this.lastPlayerData || {};\n        state = state.PlayState || {};\n        return state.PositionTicks;\n    };\n\n    ChromecastPlayer.prototype.duration = function () {\n        var state = this.lastPlayerData || {};\n        state = state.NowPlayingItem || {};\n        return state.RunTimeTicks;\n    };\n\n    ChromecastPlayer.prototype.getBufferedRanges = function () {\n        var state = this.lastPlayerData || {};\n        state = state.PlayState || {};\n        return state.BufferedRanges || [];\n    };\n\n    ChromecastPlayer.prototype.paused = function () {\n        var state = this.lastPlayerData || {};\n        state = state.PlayState || {};\n\n        return state.IsPaused;\n    };\n\n    ChromecastPlayer.prototype.isMuted = function () {\n        var state = this.lastPlayerData || {};\n        state = state.PlayState || {};\n\n        return state.IsMuted;\n    };\n\n    ChromecastPlayer.prototype.shuffle = function (item) {\n\n        var apiClient = connectionManager.getApiClient(item.ServerId);\n        var userId = apiClient.getCurrentUserId();\n\n        var instance = this;\n\n        apiClient.getItem(userId, item.Id).then(function (item) {\n\n            instance.playWithCommand({\n\n                items: [item]\n\n            }, 'Shuffle');\n\n        });\n\n    };\n\n    ChromecastPlayer.prototype.instantMix = function (item) {\n\n        var apiClient = connectionManager.getApiClient(item.ServerId);\n        var userId = apiClient.getCurrentUserId();\n\n        var instance = this;\n\n        apiClient.getItem(userId, item.Id).then(function (item) {\n\n            instance.playWithCommand({\n\n                items: [item]\n\n            }, 'InstantMix');\n\n        });\n\n    };\n\n    ChromecastPlayer.prototype.canPlayMediaType = function (mediaType) {\n\n        mediaType = (mediaType || '').toLowerCase();\n        return mediaType === 'audio' || mediaType === 'video';\n    };\n\n    ChromecastPlayer.prototype.canQueueMediaType = function (mediaType) {\n        return this.canPlayMediaType(mediaType);\n    };\n\n    ChromecastPlayer.prototype.queue = function (options) {\n        this.playWithCommand(options, 'PlayLast');\n    };\n\n    ChromecastPlayer.prototype.queueNext = function (options) {\n        this.playWithCommand(options, 'PlayNext');\n    };\n\n    ChromecastPlayer.prototype.play = function (options) {\n\n        if (options.items) {\n\n            return this.playWithCommand(options, 'PlayNow');\n\n        } else {\n\n            if (!options.serverId) {\n                throw new Error('serverId required!');\n            }\n\n            var instance = this;\n            var apiClient = connectionManager.getApiClient(options.serverId);\n\n            return getItemsForPlayback(apiClient, {\n\n                Ids: options.ids.join(',')\n\n            }).then(function (result) {\n\n                options.items = result.Items;\n                return instance.playWithCommand(options, 'PlayNow');\n\n            });\n        }\n    };\n\n    ChromecastPlayer.prototype.toggleFullscreen = function () {\n        // not supported\n    };\n\n    ChromecastPlayer.prototype.beginPlayerUpdates = function () {\n        // Setup polling here\n    };\n\n    ChromecastPlayer.prototype.endPlayerUpdates = function () {\n        // Stop polling here\n    };\n\n    ChromecastPlayer.prototype.getPlaylist = function () {\n        return Promise.resolve([]);\n    };\n\n    ChromecastPlayer.prototype.getCurrentPlaylistItemId = function () {\n    };\n\n    ChromecastPlayer.prototype.setCurrentPlaylistItem = function (playlistItemId) {\n        return Promise.resolve();\n    };\n\n    ChromecastPlayer.prototype.removeFromPlaylist = function (playlistItemIds) {\n        return Promise.resolve();\n    };\n\n    ChromecastPlayer.prototype.getPlayerState = function () {\n\n        return this.getPlayerStateInternal() || {};\n    };\n\n    return ChromecastPlayer;\n});\n", "idx": 4, "id": 11428, "msg": "", "proj": "jellyfin-jellyfin-web", "lang": "js"}
{"patch": "@@ -9344,7 +9344,7 @@ namespace Microsoft.AspNetCore.Server.Kestrel.Internal.Http\n             \n             if (((_bits & 4194304L) != 0))\n             {\n-                _headers._ETag = default(StringValues);\n+                _headers._Location = default(StringValues);\n                 _bits &= ~4194304L;\n                 if(_bits == 0)\n                 {", "y": 0, "oldf": "// Copyright (c) .NET Foundation. All rights reserved.\n// Licensed under the Apache License, Version 2.0. See License.txt in the project root for license information.\n\nusing System;\nusing System.Collections.Generic;\nusing Microsoft.AspNetCore.Server.Kestrel.Internal.Infrastructure;\nusing Microsoft.Extensions.Primitives;\n\nnamespace Microsoft.AspNetCore.Server.Kestrel.Internal.Http\n{\n\n    public partial class FrameRequestHeaders\n    {\n\n        private long _bits = 0;\n        private HeaderReferences _headers;\n        \n        public StringValues HeaderCacheControl\n        {\n            get\n            {\n                if (((_bits & 1L) != 0))\n                {\n                    return _headers._CacheControl;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 1L;\n                _headers._CacheControl = value; \n            }\n        }\n        public StringValues HeaderConnection\n        {\n            get\n            {\n                if (((_bits & 2L) != 0))\n                {\n                    return _headers._Connection;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 2L;\n                _headers._Connection = value; \n            }\n        }\n        public StringValues HeaderDate\n        {\n            get\n            {\n                if (((_bits & 4L) != 0))\n                {\n                    return _headers._Date;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 4L;\n                _headers._Date = value; \n            }\n        }\n        public StringValues HeaderKeepAlive\n        {\n            get\n            {\n                if (((_bits & 8L) != 0))\n                {\n                    return _headers._KeepAlive;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 8L;\n                _headers._KeepAlive = value; \n            }\n        }\n        public StringValues HeaderPragma\n        {\n            get\n            {\n                if (((_bits & 16L) != 0))\n                {\n                    return _headers._Pragma;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 16L;\n                _headers._Pragma = value; \n            }\n        }\n        public StringValues HeaderTrailer\n        {\n            get\n            {\n                if (((_bits & 32L) != 0))\n                {\n                    return _headers._Trailer;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 32L;\n                _headers._Trailer = value; \n            }\n        }\n        public StringValues HeaderTransferEncoding\n        {\n            get\n            {\n                if (((_bits & 64L) != 0))\n                {\n                    return _headers._TransferEncoding;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 64L;\n                _headers._TransferEncoding = value; \n            }\n        }\n        public StringValues HeaderUpgrade\n        {\n            get\n            {\n                if (((_bits & 128L) != 0))\n                {\n                    return _headers._Upgrade;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 128L;\n                _headers._Upgrade = value; \n            }\n        }\n        public StringValues HeaderVia\n        {\n            get\n            {\n                if (((_bits & 256L) != 0))\n                {\n                    return _headers._Via;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 256L;\n                _headers._Via = value; \n            }\n        }\n        public StringValues HeaderWarning\n        {\n            get\n            {\n                if (((_bits & 512L) != 0))\n                {\n                    return _headers._Warning;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 512L;\n                _headers._Warning = value; \n            }\n        }\n        public StringValues HeaderAllow\n        {\n            get\n            {\n                if (((_bits & 1024L) != 0))\n                {\n                    return _headers._Allow;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 1024L;\n                _headers._Allow = value; \n            }\n        }\n        public StringValues HeaderContentLength\n        {\n            get\n            {\n                if (((_bits & 2048L) != 0))\n                {\n                    return _headers._ContentLength;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 2048L;\n                _headers._ContentLength = value; \n            }\n        }\n        public StringValues HeaderContentType\n        {\n            get\n            {\n                if (((_bits & 4096L) != 0))\n                {\n                    return _headers._ContentType;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 4096L;\n                _headers._ContentType = value; \n            }\n        }\n        public StringValues HeaderContentEncoding\n        {\n            get\n            {\n                if (((_bits & 8192L) != 0))\n                {\n                    return _headers._ContentEncoding;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 8192L;\n                _headers._ContentEncoding = value; \n            }\n        }\n        public StringValues HeaderContentLanguage\n        {\n            get\n            {\n                if (((_bits & 16384L) != 0))\n                {\n                    return _headers._ContentLanguage;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 16384L;\n                _headers._ContentLanguage = value; \n            }\n        }\n        public StringValues HeaderContentLocation\n        {\n            get\n            {\n                if (((_bits & 32768L) != 0))\n                {\n                    return _headers._ContentLocation;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 32768L;\n                _headers._ContentLocation = value; \n            }\n        }\n        public StringValues HeaderContentMD5\n        {\n            get\n            {\n                if (((_bits & 65536L) != 0))\n                {\n                    return _headers._ContentMD5;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 65536L;\n                _headers._ContentMD5 = value; \n            }\n        }\n        public StringValues HeaderContentRange\n        {\n            get\n            {\n                if (((_bits & 131072L) != 0))\n                {\n                    return _headers._ContentRange;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 131072L;\n                _headers._ContentRange = value; \n            }\n        }\n        public StringValues HeaderExpires\n        {\n            get\n            {\n                if (((_bits & 262144L) != 0))\n                {\n                    return _headers._Expires;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 262144L;\n                _headers._Expires = value; \n            }\n        }\n        public StringValues HeaderLastModified\n        {\n            get\n            {\n                if (((_bits & 524288L) != 0))\n                {\n                    return _headers._LastModified;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 524288L;\n                _headers._LastModified = value; \n            }\n        }\n        public StringValues HeaderAccept\n        {\n            get\n            {\n                if (((_bits & 1048576L) != 0))\n                {\n                    return _headers._Accept;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 1048576L;\n                _headers._Accept = value; \n            }\n        }\n        public StringValues HeaderAcceptCharset\n        {\n            get\n            {\n                if (((_bits & 2097152L) != 0))\n                {\n                    return _headers._AcceptCharset;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 2097152L;\n                _headers._AcceptCharset = value; \n            }\n        }\n        public StringValues HeaderAcceptEncoding\n        {\n            get\n            {\n                if (((_bits & 4194304L) != 0))\n                {\n                    return _headers._AcceptEncoding;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 4194304L;\n                _headers._AcceptEncoding = value; \n            }\n        }\n        public StringValues HeaderAcceptLanguage\n        {\n            get\n            {\n                if (((_bits & 8388608L) != 0))\n                {\n                    return _headers._AcceptLanguage;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 8388608L;\n                _headers._AcceptLanguage = value; \n            }\n        }\n        public StringValues HeaderAuthorization\n        {\n            get\n            {\n                if (((_bits & 16777216L) != 0))\n                {\n                    return _headers._Authorization;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 16777216L;\n                _headers._Authorization = value; \n            }\n        }\n        public StringValues HeaderCookie\n        {\n            get\n            {\n                if (((_bits & 33554432L) != 0))\n                {\n                    return _headers._Cookie;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 33554432L;\n                _headers._Cookie = value; \n            }\n        }\n        public StringValues HeaderExpect\n        {\n            get\n            {\n                if (((_bits & 67108864L) != 0))\n                {\n                    return _headers._Expect;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 67108864L;\n                _headers._Expect = value; \n            }\n        }\n        public StringValues HeaderFrom\n        {\n            get\n            {\n                if (((_bits & 134217728L) != 0))\n                {\n                    return _headers._From;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 134217728L;\n                _headers._From = value; \n            }\n        }\n        public StringValues HeaderHost\n        {\n            get\n            {\n                if (((_bits & 268435456L) != 0))\n                {\n                    return _headers._Host;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 268435456L;\n                _headers._Host = value; \n            }\n        }\n        public StringValues HeaderIfMatch\n        {\n            get\n            {\n                if (((_bits & 536870912L) != 0))\n                {\n                    return _headers._IfMatch;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 536870912L;\n                _headers._IfMatch = value; \n            }\n        }\n        public StringValues HeaderIfModifiedSince\n        {\n            get\n            {\n                if (((_bits & 1073741824L) != 0))\n                {\n                    return _headers._IfModifiedSince;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 1073741824L;\n                _headers._IfModifiedSince = value; \n            }\n        }\n        public StringValues HeaderIfNoneMatch\n        {\n            get\n            {\n                if (((_bits & 2147483648L) != 0))\n                {\n                    return _headers._IfNoneMatch;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 2147483648L;\n                _headers._IfNoneMatch = value; \n            }\n        }\n        public StringValues HeaderIfRange\n        {\n            get\n            {\n                if (((_bits & 4294967296L) != 0))\n                {\n                    return _headers._IfRange;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 4294967296L;\n                _headers._IfRange = value; \n            }\n        }\n        public StringValues HeaderIfUnmodifiedSince\n        {\n            get\n            {\n                if (((_bits & 8589934592L) != 0))\n                {\n                    return _headers._IfUnmodifiedSince;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 8589934592L;\n                _headers._IfUnmodifiedSince = value; \n            }\n        }\n        public StringValues HeaderMaxForwards\n        {\n            get\n            {\n                if (((_bits & 17179869184L) != 0))\n                {\n                    return _headers._MaxForwards;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 17179869184L;\n                _headers._MaxForwards = value; \n            }\n        }\n        public StringValues HeaderProxyAuthorization\n        {\n            get\n            {\n                if (((_bits & 34359738368L) != 0))\n                {\n                    return _headers._ProxyAuthorization;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 34359738368L;\n                _headers._ProxyAuthorization = value; \n            }\n        }\n        public StringValues HeaderReferer\n        {\n            get\n            {\n                if (((_bits & 68719476736L) != 0))\n                {\n                    return _headers._Referer;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 68719476736L;\n                _headers._Referer = value; \n            }\n        }\n        public StringValues HeaderRange\n        {\n            get\n            {\n                if (((_bits & 137438953472L) != 0))\n                {\n                    return _headers._Range;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 137438953472L;\n                _headers._Range = value; \n            }\n        }\n        public StringValues HeaderTE\n        {\n            get\n            {\n                if (((_bits & 274877906944L) != 0))\n                {\n                    return _headers._TE;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 274877906944L;\n                _headers._TE = value; \n            }\n        }\n        public StringValues HeaderTranslate\n        {\n            get\n            {\n                if (((_bits & 549755813888L) != 0))\n                {\n                    return _headers._Translate;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 549755813888L;\n                _headers._Translate = value; \n            }\n        }\n        public StringValues HeaderUserAgent\n        {\n            get\n            {\n                if (((_bits & 1099511627776L) != 0))\n                {\n                    return _headers._UserAgent;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 1099511627776L;\n                _headers._UserAgent = value; \n            }\n        }\n        public StringValues HeaderOrigin\n        {\n            get\n            {\n                if (((_bits & 2199023255552L) != 0))\n                {\n                    return _headers._Origin;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 2199023255552L;\n                _headers._Origin = value; \n            }\n        }\n        public StringValues HeaderAccessControlRequestMethod\n        {\n            get\n            {\n                if (((_bits & 4398046511104L) != 0))\n                {\n                    return _headers._AccessControlRequestMethod;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 4398046511104L;\n                _headers._AccessControlRequestMethod = value; \n            }\n        }\n        public StringValues HeaderAccessControlRequestHeaders\n        {\n            get\n            {\n                if (((_bits & 8796093022208L) != 0))\n                {\n                    return _headers._AccessControlRequestHeaders;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 8796093022208L;\n                _headers._AccessControlRequestHeaders = value; \n            }\n        }\n        \n        protected override int GetCountFast()\n        {\n            return BitCount(_bits) + (MaybeUnknown?.Count ?? 0);\n        }\n        protected override StringValues GetValueFast(string key)\n        {\n            switch (key.Length)\n            {\n                case 13:\n                    {\n                        if (\"Cache-Control\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1L) != 0))\n                            {\n                                return _headers._CacheControl;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Content-Range\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 131072L) != 0))\n                            {\n                                return _headers._ContentRange;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Last-Modified\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 524288L) != 0))\n                            {\n                                return _headers._LastModified;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Authorization\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 16777216L) != 0))\n                            {\n                                return _headers._Authorization;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"If-None-Match\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2147483648L) != 0))\n                            {\n                                return _headers._IfNoneMatch;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 10:\n                    {\n                        if (\"Connection\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2L) != 0))\n                            {\n                                return _headers._Connection;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Keep-Alive\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8L) != 0))\n                            {\n                                return _headers._KeepAlive;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"User-Agent\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1099511627776L) != 0))\n                            {\n                                return _headers._UserAgent;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 4:\n                    {\n                        if (\"Date\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4L) != 0))\n                            {\n                                return _headers._Date;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"From\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 134217728L) != 0))\n                            {\n                                return _headers._From;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Host\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 268435456L) != 0))\n                            {\n                                return _headers._Host;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 6:\n                    {\n                        if (\"Pragma\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 16L) != 0))\n                            {\n                                return _headers._Pragma;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Accept\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1048576L) != 0))\n                            {\n                                return _headers._Accept;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Cookie\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 33554432L) != 0))\n                            {\n                                return _headers._Cookie;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Expect\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 67108864L) != 0))\n                            {\n                                return _headers._Expect;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Origin\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2199023255552L) != 0))\n                            {\n                                return _headers._Origin;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 7:\n                    {\n                        if (\"Trailer\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 32L) != 0))\n                            {\n                                return _headers._Trailer;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Upgrade\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 128L) != 0))\n                            {\n                                return _headers._Upgrade;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Warning\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 512L) != 0))\n                            {\n                                return _headers._Warning;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Expires\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 262144L) != 0))\n                            {\n                                return _headers._Expires;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Referer\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 68719476736L) != 0))\n                            {\n                                return _headers._Referer;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 17:\n                    {\n                        if (\"Transfer-Encoding\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 64L) != 0))\n                            {\n                                return _headers._TransferEncoding;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"If-Modified-Since\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1073741824L) != 0))\n                            {\n                                return _headers._IfModifiedSince;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 3:\n                    {\n                        if (\"Via\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 256L) != 0))\n                            {\n                                return _headers._Via;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 5:\n                    {\n                        if (\"Allow\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1024L) != 0))\n                            {\n                                return _headers._Allow;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Range\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 137438953472L) != 0))\n                            {\n                                return _headers._Range;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 14:\n                    {\n                        if (\"Content-Length\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2048L) != 0))\n                            {\n                                return _headers._ContentLength;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Accept-Charset\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2097152L) != 0))\n                            {\n                                return _headers._AcceptCharset;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 12:\n                    {\n                        if (\"Content-Type\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4096L) != 0))\n                            {\n                                return _headers._ContentType;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Max-Forwards\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 17179869184L) != 0))\n                            {\n                                return _headers._MaxForwards;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 16:\n                    {\n                        if (\"Content-Encoding\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8192L) != 0))\n                            {\n                                return _headers._ContentEncoding;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Content-Language\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 16384L) != 0))\n                            {\n                                return _headers._ContentLanguage;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Content-Location\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 32768L) != 0))\n                            {\n                                return _headers._ContentLocation;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 11:\n                    {\n                        if (\"Content-MD5\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 65536L) != 0))\n                            {\n                                return _headers._ContentMD5;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 15:\n                    {\n                        if (\"Accept-Encoding\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4194304L) != 0))\n                            {\n                                return _headers._AcceptEncoding;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Accept-Language\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8388608L) != 0))\n                            {\n                                return _headers._AcceptLanguage;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 8:\n                    {\n                        if (\"If-Match\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 536870912L) != 0))\n                            {\n                                return _headers._IfMatch;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"If-Range\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4294967296L) != 0))\n                            {\n                                return _headers._IfRange;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 19:\n                    {\n                        if (\"If-Unmodified-Since\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8589934592L) != 0))\n                            {\n                                return _headers._IfUnmodifiedSince;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Proxy-Authorization\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 34359738368L) != 0))\n                            {\n                                return _headers._ProxyAuthorization;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 2:\n                    {\n                        if (\"TE\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 274877906944L) != 0))\n                            {\n                                return _headers._TE;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 9:\n                    {\n                        if (\"Translate\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 549755813888L) != 0))\n                            {\n                                return _headers._Translate;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 29:\n                    {\n                        if (\"Access-Control-Request-Method\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4398046511104L) != 0))\n                            {\n                                return _headers._AccessControlRequestMethod;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 30:\n                    {\n                        if (\"Access-Control-Request-Headers\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8796093022208L) != 0))\n                            {\n                                return _headers._AccessControlRequestHeaders;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n}\n            if (MaybeUnknown == null)\n            {\n                ThrowKeyNotFoundException();\n            }\n            return MaybeUnknown[key];\n        }\n        protected override bool TryGetValueFast(string key, out StringValues value)\n        {\n            switch (key.Length)\n            {\n                case 13:\n                    {\n                        if (\"Cache-Control\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1L) != 0))\n                            {\n                                value = _headers._CacheControl;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Content-Range\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 131072L) != 0))\n                            {\n                                value = _headers._ContentRange;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Last-Modified\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 524288L) != 0))\n                            {\n                                value = _headers._LastModified;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Authorization\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 16777216L) != 0))\n                            {\n                                value = _headers._Authorization;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"If-None-Match\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2147483648L) != 0))\n                            {\n                                value = _headers._IfNoneMatch;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 10:\n                    {\n                        if (\"Connection\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2L) != 0))\n                            {\n                                value = _headers._Connection;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Keep-Alive\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8L) != 0))\n                            {\n                                value = _headers._KeepAlive;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"User-Agent\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1099511627776L) != 0))\n                            {\n                                value = _headers._UserAgent;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 4:\n                    {\n                        if (\"Date\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4L) != 0))\n                            {\n                                value = _headers._Date;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"From\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 134217728L) != 0))\n                            {\n                                value = _headers._From;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Host\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 268435456L) != 0))\n                            {\n                                value = _headers._Host;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 6:\n                    {\n                        if (\"Pragma\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 16L) != 0))\n                            {\n                                value = _headers._Pragma;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Accept\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1048576L) != 0))\n                            {\n                                value = _headers._Accept;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Cookie\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 33554432L) != 0))\n                            {\n                                value = _headers._Cookie;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Expect\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 67108864L) != 0))\n                            {\n                                value = _headers._Expect;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Origin\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2199023255552L) != 0))\n                            {\n                                value = _headers._Origin;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 7:\n                    {\n                        if (\"Trailer\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 32L) != 0))\n                            {\n                                value = _headers._Trailer;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Upgrade\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 128L) != 0))\n                            {\n                                value = _headers._Upgrade;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Warning\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 512L) != 0))\n                            {\n                                value = _headers._Warning;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Expires\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 262144L) != 0))\n                            {\n                                value = _headers._Expires;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Referer\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 68719476736L) != 0))\n                            {\n                                value = _headers._Referer;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 17:\n                    {\n                        if (\"Transfer-Encoding\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 64L) != 0))\n                            {\n                                value = _headers._TransferEncoding;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"If-Modified-Since\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1073741824L) != 0))\n                            {\n                                value = _headers._IfModifiedSince;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 3:\n                    {\n                        if (\"Via\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 256L) != 0))\n                            {\n                                value = _headers._Via;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 5:\n                    {\n                        if (\"Allow\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1024L) != 0))\n                            {\n                                value = _headers._Allow;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Range\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 137438953472L) != 0))\n                            {\n                                value = _headers._Range;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 14:\n                    {\n                        if (\"Content-Length\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2048L) != 0))\n                            {\n                                value = _headers._ContentLength;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Accept-Charset\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2097152L) != 0))\n                            {\n                                value = _headers._AcceptCharset;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 12:\n                    {\n                        if (\"Content-Type\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4096L) != 0))\n                            {\n                                value = _headers._ContentType;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Max-Forwards\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 17179869184L) != 0))\n                            {\n                                value = _headers._MaxForwards;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 16:\n                    {\n                        if (\"Content-Encoding\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8192L) != 0))\n                            {\n                                value = _headers._ContentEncoding;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Content-Language\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 16384L) != 0))\n                            {\n                                value = _headers._ContentLanguage;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Content-Location\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 32768L) != 0))\n                            {\n                                value = _headers._ContentLocation;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 11:\n                    {\n                        if (\"Content-MD5\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 65536L) != 0))\n                            {\n                                value = _headers._ContentMD5;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 15:\n                    {\n                        if (\"Accept-Encoding\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4194304L) != 0))\n                            {\n                                value = _headers._AcceptEncoding;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Accept-Language\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8388608L) != 0))\n                            {\n                                value = _headers._AcceptLanguage;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 8:\n                    {\n                        if (\"If-Match\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 536870912L) != 0))\n                            {\n                                value = _headers._IfMatch;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"If-Range\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4294967296L) != 0))\n                            {\n                                value = _headers._IfRange;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 19:\n                    {\n                        if (\"If-Unmodified-Since\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8589934592L) != 0))\n                            {\n                                value = _headers._IfUnmodifiedSince;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Proxy-Authorization\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 34359738368L) != 0))\n                            {\n                                value = _headers._ProxyAuthorization;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 2:\n                    {\n                        if (\"TE\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 274877906944L) != 0))\n                            {\n                                value = _headers._TE;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 9:\n                    {\n                        if (\"Translate\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 549755813888L) != 0))\n                            {\n                                value = _headers._Translate;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 29:\n                    {\n                        if (\"Access-Control-Request-Method\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4398046511104L) != 0))\n                            {\n                                value = _headers._AccessControlRequestMethod;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 30:\n                    {\n                        if (\"Access-Control-Request-Headers\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8796093022208L) != 0))\n                            {\n                                value = _headers._AccessControlRequestHeaders;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n}\n            value = StringValues.Empty;\n            return MaybeUnknown?.TryGetValue(key, out value) ?? false;\n        }\n        protected override void SetValueFast(string key, StringValues value)\n        {\n            \n            switch (key.Length)\n            {\n                case 13:\n                    {\n                        if (\"Cache-Control\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 1L;\n                            _headers._CacheControl = value;\n                            return;\n                        }\n                    \n                        if (\"Content-Range\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 131072L;\n                            _headers._ContentRange = value;\n                            return;\n                        }\n                    \n                        if (\"Last-Modified\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 524288L;\n                            _headers._LastModified = value;\n                            return;\n                        }\n                    \n                        if (\"Authorization\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 16777216L;\n                            _headers._Authorization = value;\n                            return;\n                        }\n                    \n                        if (\"If-None-Match\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 2147483648L;\n                            _headers._IfNoneMatch = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 10:\n                    {\n                        if (\"Connection\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 2L;\n                            _headers._Connection = value;\n                            return;\n                        }\n                    \n                        if (\"Keep-Alive\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 8L;\n                            _headers._KeepAlive = value;\n                            return;\n                        }\n                    \n                        if (\"User-Agent\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 1099511627776L;\n                            _headers._UserAgent = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 4:\n                    {\n                        if (\"Date\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 4L;\n                            _headers._Date = value;\n                            return;\n                        }\n                    \n                        if (\"From\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 134217728L;\n                            _headers._From = value;\n                            return;\n                        }\n                    \n                        if (\"Host\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 268435456L;\n                            _headers._Host = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 6:\n                    {\n                        if (\"Pragma\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 16L;\n                            _headers._Pragma = value;\n                            return;\n                        }\n                    \n                        if (\"Accept\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 1048576L;\n                            _headers._Accept = value;\n                            return;\n                        }\n                    \n                        if (\"Cookie\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 33554432L;\n                            _headers._Cookie = value;\n                            return;\n                        }\n                    \n                        if (\"Expect\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 67108864L;\n                            _headers._Expect = value;\n                            return;\n                        }\n                    \n                        if (\"Origin\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 2199023255552L;\n                            _headers._Origin = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 7:\n                    {\n                        if (\"Trailer\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 32L;\n                            _headers._Trailer = value;\n                            return;\n                        }\n                    \n                        if (\"Upgrade\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 128L;\n                            _headers._Upgrade = value;\n                            return;\n                        }\n                    \n                        if (\"Warning\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 512L;\n                            _headers._Warning = value;\n                            return;\n                        }\n                    \n                        if (\"Expires\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 262144L;\n                            _headers._Expires = value;\n                            return;\n                        }\n                    \n                        if (\"Referer\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 68719476736L;\n                            _headers._Referer = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 17:\n                    {\n                        if (\"Transfer-Encoding\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 64L;\n                            _headers._TransferEncoding = value;\n                            return;\n                        }\n                    \n                        if (\"If-Modified-Since\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 1073741824L;\n                            _headers._IfModifiedSince = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 3:\n                    {\n                        if (\"Via\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 256L;\n                            _headers._Via = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 5:\n                    {\n                        if (\"Allow\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 1024L;\n                            _headers._Allow = value;\n                            return;\n                        }\n                    \n                        if (\"Range\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 137438953472L;\n                            _headers._Range = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 14:\n                    {\n                        if (\"Content-Length\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 2048L;\n                            _headers._ContentLength = value;\n                            return;\n                        }\n                    \n                        if (\"Accept-Charset\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 2097152L;\n                            _headers._AcceptCharset = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 12:\n                    {\n                        if (\"Content-Type\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 4096L;\n                            _headers._ContentType = value;\n                            return;\n                        }\n                    \n                        if (\"Max-Forwards\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 17179869184L;\n                            _headers._MaxForwards = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 16:\n                    {\n                        if (\"Content-Encoding\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 8192L;\n                            _headers._ContentEncoding = value;\n                            return;\n                        }\n                    \n                        if (\"Content-Language\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 16384L;\n                            _headers._ContentLanguage = value;\n                            return;\n                        }\n                    \n                        if (\"Content-Location\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 32768L;\n                            _headers._ContentLocation = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 11:\n                    {\n                        if (\"Content-MD5\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 65536L;\n                            _headers._ContentMD5 = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 15:\n                    {\n                        if (\"Accept-Encoding\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 4194304L;\n                            _headers._AcceptEncoding = value;\n                            return;\n                        }\n                    \n                        if (\"Accept-Language\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 8388608L;\n                            _headers._AcceptLanguage = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 8:\n                    {\n                        if (\"If-Match\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 536870912L;\n                            _headers._IfMatch = value;\n                            return;\n                        }\n                    \n                        if (\"If-Range\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 4294967296L;\n                            _headers._IfRange = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 19:\n                    {\n                        if (\"If-Unmodified-Since\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 8589934592L;\n                            _headers._IfUnmodifiedSince = value;\n                            return;\n                        }\n                    \n                        if (\"Proxy-Authorization\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 34359738368L;\n                            _headers._ProxyAuthorization = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 2:\n                    {\n                        if (\"TE\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 274877906944L;\n                            _headers._TE = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 9:\n                    {\n                        if (\"Translate\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 549755813888L;\n                            _headers._Translate = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 29:\n                    {\n                        if (\"Access-Control-Request-Method\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 4398046511104L;\n                            _headers._AccessControlRequestMethod = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 30:\n                    {\n                        if (\"Access-Control-Request-Headers\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 8796093022208L;\n                            _headers._AccessControlRequestHeaders = value;\n                            return;\n                        }\n                    }\n                    break;\n}\n            \n            Unknown[key] = value;\n        }\n        protected override void AddValueFast(string key, StringValues value)\n        {\n            \n            switch (key.Length)\n            {\n                case 13:\n                    {\n                        if (\"Cache-Control\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 1L;\n                            _headers._CacheControl = value;\n                            return;\n                        }\n                    \n                        if (\"Content-Range\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 131072L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 131072L;\n                            _headers._ContentRange = value;\n                            return;\n                        }\n                    \n                        if (\"Last-Modified\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 524288L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 524288L;\n                            _headers._LastModified = value;\n                            return;\n                        }\n                    \n                        if (\"Authorization\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 16777216L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 16777216L;\n                            _headers._Authorization = value;\n                            return;\n                        }\n                    \n                        if (\"If-None-Match\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2147483648L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 2147483648L;\n                            _headers._IfNoneMatch = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 10:\n                    {\n                        if (\"Connection\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 2L;\n                            _headers._Connection = value;\n                            return;\n                        }\n                    \n                        if (\"Keep-Alive\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 8L;\n                            _headers._KeepAlive = value;\n                            return;\n                        }\n                    \n                        if (\"User-Agent\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1099511627776L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 1099511627776L;\n                            _headers._UserAgent = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 4:\n                    {\n                        if (\"Date\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 4L;\n                            _headers._Date = value;\n                            return;\n                        }\n                    \n                        if (\"From\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 134217728L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 134217728L;\n                            _headers._From = value;\n                            return;\n                        }\n                    \n                        if (\"Host\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 268435456L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 268435456L;\n                            _headers._Host = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 6:\n                    {\n                        if (\"Pragma\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 16L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 16L;\n                            _headers._Pragma = value;\n                            return;\n                        }\n                    \n                        if (\"Accept\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1048576L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 1048576L;\n                            _headers._Accept = value;\n                            return;\n                        }\n                    \n                        if (\"Cookie\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 33554432L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 33554432L;\n                            _headers._Cookie = value;\n                            return;\n                        }\n                    \n                        if (\"Expect\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 67108864L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 67108864L;\n                            _headers._Expect = value;\n                            return;\n                        }\n                    \n                        if (\"Origin\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2199023255552L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 2199023255552L;\n                            _headers._Origin = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 7:\n                    {\n                        if (\"Trailer\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 32L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 32L;\n                            _headers._Trailer = value;\n                            return;\n                        }\n                    \n                        if (\"Upgrade\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 128L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 128L;\n                            _headers._Upgrade = value;\n                            return;\n                        }\n                    \n                        if (\"Warning\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 512L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 512L;\n                            _headers._Warning = value;\n                            return;\n                        }\n                    \n                        if (\"Expires\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 262144L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 262144L;\n                            _headers._Expires = value;\n                            return;\n                        }\n                    \n                        if (\"Referer\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 68719476736L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 68719476736L;\n                            _headers._Referer = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 17:\n                    {\n                        if (\"Transfer-Encoding\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 64L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 64L;\n                            _headers._TransferEncoding = value;\n                            return;\n                        }\n                    \n                        if (\"If-Modified-Since\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1073741824L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 1073741824L;\n                            _headers._IfModifiedSince = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 3:\n                    {\n                        if (\"Via\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 256L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 256L;\n                            _headers._Via = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 5:\n                    {\n                        if (\"Allow\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1024L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 1024L;\n                            _headers._Allow = value;\n                            return;\n                        }\n                    \n                        if (\"Range\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 137438953472L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 137438953472L;\n                            _headers._Range = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 14:\n                    {\n                        if (\"Content-Length\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2048L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 2048L;\n                            _headers._ContentLength = value;\n                            return;\n                        }\n                    \n                        if (\"Accept-Charset\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2097152L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 2097152L;\n                            _headers._AcceptCharset = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 12:\n                    {\n                        if (\"Content-Type\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4096L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 4096L;\n                            _headers._ContentType = value;\n                            return;\n                        }\n                    \n                        if (\"Max-Forwards\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 17179869184L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 17179869184L;\n                            _headers._MaxForwards = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 16:\n                    {\n                        if (\"Content-Encoding\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8192L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 8192L;\n                            _headers._ContentEncoding = value;\n                            return;\n                        }\n                    \n                        if (\"Content-Language\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 16384L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 16384L;\n                            _headers._ContentLanguage = value;\n                            return;\n                        }\n                    \n                        if (\"Content-Location\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 32768L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 32768L;\n                            _headers._ContentLocation = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 11:\n                    {\n                        if (\"Content-MD5\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 65536L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 65536L;\n                            _headers._ContentMD5 = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 15:\n                    {\n                        if (\"Accept-Encoding\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4194304L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 4194304L;\n                            _headers._AcceptEncoding = value;\n                            return;\n                        }\n                    \n                        if (\"Accept-Language\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8388608L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 8388608L;\n                            _headers._AcceptLanguage = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 8:\n                    {\n                        if (\"If-Match\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 536870912L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 536870912L;\n                            _headers._IfMatch = value;\n                            return;\n                        }\n                    \n                        if (\"If-Range\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4294967296L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 4294967296L;\n                            _headers._IfRange = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 19:\n                    {\n                        if (\"If-Unmodified-Since\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8589934592L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 8589934592L;\n                            _headers._IfUnmodifiedSince = value;\n                            return;\n                        }\n                    \n                        if (\"Proxy-Authorization\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 34359738368L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 34359738368L;\n                            _headers._ProxyAuthorization = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 2:\n                    {\n                        if (\"TE\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 274877906944L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 274877906944L;\n                            _headers._TE = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 9:\n                    {\n                        if (\"Translate\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 549755813888L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 549755813888L;\n                            _headers._Translate = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 29:\n                    {\n                        if (\"Access-Control-Request-Method\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4398046511104L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 4398046511104L;\n                            _headers._AccessControlRequestMethod = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 30:\n                    {\n                        if (\"Access-Control-Request-Headers\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8796093022208L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 8796093022208L;\n                            _headers._AccessControlRequestHeaders = value;\n                            return;\n                        }\n                    }\n                    break;\n            }\n            \n            Unknown.Add(key, value);\n        }\n        protected override bool RemoveFast(string key)\n        {\n            switch (key.Length)\n            {\n                case 13:\n                    {\n                        if (\"Cache-Control\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1L) != 0))\n                            {\n                                _bits &= ~1L;\n                                _headers._CacheControl = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Content-Range\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 131072L) != 0))\n                            {\n                                _bits &= ~131072L;\n                                _headers._ContentRange = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Last-Modified\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 524288L) != 0))\n                            {\n                                _bits &= ~524288L;\n                                _headers._LastModified = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Authorization\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 16777216L) != 0))\n                            {\n                                _bits &= ~16777216L;\n                                _headers._Authorization = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"If-None-Match\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2147483648L) != 0))\n                            {\n                                _bits &= ~2147483648L;\n                                _headers._IfNoneMatch = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 10:\n                    {\n                        if (\"Connection\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2L) != 0))\n                            {\n                                _bits &= ~2L;\n                                _headers._Connection = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Keep-Alive\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8L) != 0))\n                            {\n                                _bits &= ~8L;\n                                _headers._KeepAlive = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"User-Agent\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1099511627776L) != 0))\n                            {\n                                _bits &= ~1099511627776L;\n                                _headers._UserAgent = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 4:\n                    {\n                        if (\"Date\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4L) != 0))\n                            {\n                                _bits &= ~4L;\n                                _headers._Date = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"From\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 134217728L) != 0))\n                            {\n                                _bits &= ~134217728L;\n                                _headers._From = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Host\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 268435456L) != 0))\n                            {\n                                _bits &= ~268435456L;\n                                _headers._Host = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 6:\n                    {\n                        if (\"Pragma\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 16L) != 0))\n                            {\n                                _bits &= ~16L;\n                                _headers._Pragma = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Accept\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1048576L) != 0))\n                            {\n                                _bits &= ~1048576L;\n                                _headers._Accept = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Cookie\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 33554432L) != 0))\n                            {\n                                _bits &= ~33554432L;\n                                _headers._Cookie = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Expect\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 67108864L) != 0))\n                            {\n                                _bits &= ~67108864L;\n                                _headers._Expect = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Origin\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2199023255552L) != 0))\n                            {\n                                _bits &= ~2199023255552L;\n                                _headers._Origin = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 7:\n                    {\n                        if (\"Trailer\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 32L) != 0))\n                            {\n                                _bits &= ~32L;\n                                _headers._Trailer = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Upgrade\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 128L) != 0))\n                            {\n                                _bits &= ~128L;\n                                _headers._Upgrade = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Warning\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 512L) != 0))\n                            {\n                                _bits &= ~512L;\n                                _headers._Warning = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Expires\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 262144L) != 0))\n                            {\n                                _bits &= ~262144L;\n                                _headers._Expires = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Referer\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 68719476736L) != 0))\n                            {\n                                _bits &= ~68719476736L;\n                                _headers._Referer = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 17:\n                    {\n                        if (\"Transfer-Encoding\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 64L) != 0))\n                            {\n                                _bits &= ~64L;\n                                _headers._TransferEncoding = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"If-Modified-Since\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1073741824L) != 0))\n                            {\n                                _bits &= ~1073741824L;\n                                _headers._IfModifiedSince = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 3:\n                    {\n                        if (\"Via\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 256L) != 0))\n                            {\n                                _bits &= ~256L;\n                                _headers._Via = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 5:\n                    {\n                        if (\"Allow\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1024L) != 0))\n                            {\n                                _bits &= ~1024L;\n                                _headers._Allow = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Range\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 137438953472L) != 0))\n                            {\n                                _bits &= ~137438953472L;\n                                _headers._Range = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 14:\n                    {\n                        if (\"Content-Length\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2048L) != 0))\n                            {\n                                _bits &= ~2048L;\n                                _headers._ContentLength = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Accept-Charset\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2097152L) != 0))\n                            {\n                                _bits &= ~2097152L;\n                                _headers._AcceptCharset = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 12:\n                    {\n                        if (\"Content-Type\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4096L) != 0))\n                            {\n                                _bits &= ~4096L;\n                                _headers._ContentType = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Max-Forwards\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 17179869184L) != 0))\n                            {\n                                _bits &= ~17179869184L;\n                                _headers._MaxForwards = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 16:\n                    {\n                        if (\"Content-Encoding\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8192L) != 0))\n                            {\n                                _bits &= ~8192L;\n                                _headers._ContentEncoding = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Content-Language\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 16384L) != 0))\n                            {\n                                _bits &= ~16384L;\n                                _headers._ContentLanguage = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Content-Location\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 32768L) != 0))\n                            {\n                                _bits &= ~32768L;\n                                _headers._ContentLocation = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 11:\n                    {\n                        if (\"Content-MD5\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 65536L) != 0))\n                            {\n                                _bits &= ~65536L;\n                                _headers._ContentMD5 = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 15:\n                    {\n                        if (\"Accept-Encoding\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4194304L) != 0))\n                            {\n                                _bits &= ~4194304L;\n                                _headers._AcceptEncoding = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Accept-Language\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8388608L) != 0))\n                            {\n                                _bits &= ~8388608L;\n                                _headers._AcceptLanguage = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 8:\n                    {\n                        if (\"If-Match\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 536870912L) != 0))\n                            {\n                                _bits &= ~536870912L;\n                                _headers._IfMatch = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"If-Range\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4294967296L) != 0))\n                            {\n                                _bits &= ~4294967296L;\n                                _headers._IfRange = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 19:\n                    {\n                        if (\"If-Unmodified-Since\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8589934592L) != 0))\n                            {\n                                _bits &= ~8589934592L;\n                                _headers._IfUnmodifiedSince = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Proxy-Authorization\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 34359738368L) != 0))\n                            {\n                                _bits &= ~34359738368L;\n                                _headers._ProxyAuthorization = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 2:\n                    {\n                        if (\"TE\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 274877906944L) != 0))\n                            {\n                                _bits &= ~274877906944L;\n                                _headers._TE = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 9:\n                    {\n                        if (\"Translate\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 549755813888L) != 0))\n                            {\n                                _bits &= ~549755813888L;\n                                _headers._Translate = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 29:\n                    {\n                        if (\"Access-Control-Request-Method\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4398046511104L) != 0))\n                            {\n                                _bits &= ~4398046511104L;\n                                _headers._AccessControlRequestMethod = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 30:\n                    {\n                        if (\"Access-Control-Request-Headers\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8796093022208L) != 0))\n                            {\n                                _bits &= ~8796093022208L;\n                                _headers._AccessControlRequestHeaders = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            }\n            return MaybeUnknown?.Remove(key) ?? false;\n        }\n        protected override void ClearFast()\n        {            \n            MaybeUnknown?.Clear();\n            \n            if(FrameHeaders.BitCount(_bits) > 12)\n            {\n                _headers = default(HeaderReferences);\n                _bits = 0;\n                return;\n            }\n            \n            if (((_bits & 1048576L) != 0))\n            {\n                _headers._Accept = default(StringValues);\n                _bits &= ~1048576L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 268435456L) != 0))\n            {\n                _headers._Host = default(StringValues);\n                _bits &= ~268435456L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 1099511627776L) != 0))\n            {\n                _headers._UserAgent = default(StringValues);\n                _bits &= ~1099511627776L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 1L) != 0))\n            {\n                _headers._CacheControl = default(StringValues);\n                _bits &= ~1L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 2L) != 0))\n            {\n                _headers._Connection = default(StringValues);\n                _bits &= ~2L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 4L) != 0))\n            {\n                _headers._Date = default(StringValues);\n                _bits &= ~4L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 8L) != 0))\n            {\n                _headers._KeepAlive = default(StringValues);\n                _bits &= ~8L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 16L) != 0))\n            {\n                _headers._Pragma = default(StringValues);\n                _bits &= ~16L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 32L) != 0))\n            {\n                _headers._Trailer = default(StringValues);\n                _bits &= ~32L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 64L) != 0))\n            {\n                _headers._TransferEncoding = default(StringValues);\n                _bits &= ~64L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 128L) != 0))\n            {\n                _headers._Upgrade = default(StringValues);\n                _bits &= ~128L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 256L) != 0))\n            {\n                _headers._Via = default(StringValues);\n                _bits &= ~256L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 512L) != 0))\n            {\n                _headers._Warning = default(StringValues);\n                _bits &= ~512L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 1024L) != 0))\n            {\n                _headers._Allow = default(StringValues);\n                _bits &= ~1024L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 2048L) != 0))\n            {\n                _headers._ContentLength = default(StringValues);\n                _bits &= ~2048L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 4096L) != 0))\n            {\n                _headers._ContentType = default(StringValues);\n                _bits &= ~4096L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 8192L) != 0))\n            {\n                _headers._ContentEncoding = default(StringValues);\n                _bits &= ~8192L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 16384L) != 0))\n            {\n                _headers._ContentLanguage = default(StringValues);\n                _bits &= ~16384L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 32768L) != 0))\n            {\n                _headers._ContentLocation = default(StringValues);\n                _bits &= ~32768L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 65536L) != 0))\n            {\n                _headers._ContentMD5 = default(StringValues);\n                _bits &= ~65536L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 131072L) != 0))\n            {\n                _headers._ContentRange = default(StringValues);\n                _bits &= ~131072L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 262144L) != 0))\n            {\n                _headers._Expires = default(StringValues);\n                _bits &= ~262144L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 524288L) != 0))\n            {\n                _headers._LastModified = default(StringValues);\n                _bits &= ~524288L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 2097152L) != 0))\n            {\n                _headers._AcceptCharset = default(StringValues);\n                _bits &= ~2097152L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 4194304L) != 0))\n            {\n                _headers._AcceptEncoding = default(StringValues);\n                _bits &= ~4194304L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 8388608L) != 0))\n            {\n                _headers._AcceptLanguage = default(StringValues);\n                _bits &= ~8388608L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 16777216L) != 0))\n            {\n                _headers._Authorization = default(StringValues);\n                _bits &= ~16777216L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 33554432L) != 0))\n            {\n                _headers._Cookie = default(StringValues);\n                _bits &= ~33554432L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 67108864L) != 0))\n            {\n                _headers._Expect = default(StringValues);\n                _bits &= ~67108864L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 134217728L) != 0))\n            {\n                _headers._From = default(StringValues);\n                _bits &= ~134217728L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 536870912L) != 0))\n            {\n                _headers._IfMatch = default(StringValues);\n                _bits &= ~536870912L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 1073741824L) != 0))\n            {\n                _headers._IfModifiedSince = default(StringValues);\n                _bits &= ~1073741824L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 2147483648L) != 0))\n            {\n                _headers._IfNoneMatch = default(StringValues);\n                _bits &= ~2147483648L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 4294967296L) != 0))\n            {\n                _headers._IfRange = default(StringValues);\n                _bits &= ~4294967296L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 8589934592L) != 0))\n            {\n                _headers._IfUnmodifiedSince = default(StringValues);\n                _bits &= ~8589934592L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 17179869184L) != 0))\n            {\n                _headers._MaxForwards = default(StringValues);\n                _bits &= ~17179869184L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 34359738368L) != 0))\n            {\n                _headers._ProxyAuthorization = default(StringValues);\n                _bits &= ~34359738368L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 68719476736L) != 0))\n            {\n                _headers._Referer = default(StringValues);\n                _bits &= ~68719476736L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 137438953472L) != 0))\n            {\n                _headers._Range = default(StringValues);\n                _bits &= ~137438953472L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 274877906944L) != 0))\n            {\n                _headers._TE = default(StringValues);\n                _bits &= ~274877906944L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 549755813888L) != 0))\n            {\n                _headers._Translate = default(StringValues);\n                _bits &= ~549755813888L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 2199023255552L) != 0))\n            {\n                _headers._Origin = default(StringValues);\n                _bits &= ~2199023255552L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 4398046511104L) != 0))\n            {\n                _headers._AccessControlRequestMethod = default(StringValues);\n                _bits &= ~4398046511104L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 8796093022208L) != 0))\n            {\n                _headers._AccessControlRequestHeaders = default(StringValues);\n                _bits &= ~8796093022208L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n        }\n\n        protected override void CopyToFast(KeyValuePair<string, StringValues>[] array, int arrayIndex)\n        {\n            if (arrayIndex < 0)\n            {\n                ThrowArgumentException();\n            }\n            \n                if (((_bits & 1L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Cache-Control\", _headers._CacheControl);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 2L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Connection\", _headers._Connection);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 4L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Date\", _headers._Date);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 8L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Keep-Alive\", _headers._KeepAlive);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 16L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Pragma\", _headers._Pragma);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 32L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Trailer\", _headers._Trailer);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 64L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Transfer-Encoding\", _headers._TransferEncoding);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 128L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Upgrade\", _headers._Upgrade);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 256L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Via\", _headers._Via);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 512L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Warning\", _headers._Warning);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 1024L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Allow\", _headers._Allow);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 2048L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Content-Length\", _headers._ContentLength);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 4096L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Content-Type\", _headers._ContentType);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 8192L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Content-Encoding\", _headers._ContentEncoding);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 16384L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Content-Language\", _headers._ContentLanguage);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 32768L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Content-Location\", _headers._ContentLocation);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 65536L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Content-MD5\", _headers._ContentMD5);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 131072L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Content-Range\", _headers._ContentRange);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 262144L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Expires\", _headers._Expires);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 524288L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Last-Modified\", _headers._LastModified);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 1048576L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Accept\", _headers._Accept);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 2097152L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Accept-Charset\", _headers._AcceptCharset);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 4194304L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Accept-Encoding\", _headers._AcceptEncoding);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 8388608L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Accept-Language\", _headers._AcceptLanguage);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 16777216L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Authorization\", _headers._Authorization);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 33554432L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Cookie\", _headers._Cookie);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 67108864L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Expect\", _headers._Expect);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 134217728L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"From\", _headers._From);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 268435456L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Host\", _headers._Host);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 536870912L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"If-Match\", _headers._IfMatch);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 1073741824L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"If-Modified-Since\", _headers._IfModifiedSince);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 2147483648L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"If-None-Match\", _headers._IfNoneMatch);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 4294967296L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"If-Range\", _headers._IfRange);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 8589934592L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"If-Unmodified-Since\", _headers._IfUnmodifiedSince);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 17179869184L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Max-Forwards\", _headers._MaxForwards);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 34359738368L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Proxy-Authorization\", _headers._ProxyAuthorization);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 68719476736L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Referer\", _headers._Referer);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 137438953472L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Range\", _headers._Range);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 274877906944L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"TE\", _headers._TE);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 549755813888L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Translate\", _headers._Translate);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 1099511627776L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"User-Agent\", _headers._UserAgent);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 2199023255552L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Origin\", _headers._Origin);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 4398046511104L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Access-Control-Request-Method\", _headers._AccessControlRequestMethod);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 8796093022208L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Access-Control-Request-Headers\", _headers._AccessControlRequestHeaders);\n                    ++arrayIndex;\n                }\n            \n            ((ICollection<KeyValuePair<string, StringValues>>)MaybeUnknown)?.CopyTo(array, arrayIndex);\n        }\n        \n        \n        public unsafe void Append(byte[] keyBytes, int keyOffset, int keyLength, string value)\n        {\n            fixed (byte* ptr = &keyBytes[keyOffset])\n            {\n                var pUB = ptr;\n                var pUL = (ulong*)pUB;\n                var pUI = (uint*)pUB;\n                var pUS = (ushort*)pUB;\n                switch (keyLength)\n                {\n                    case 6:\n                        {\n                            if ((((pUI[0] & 3755991007u) == 1162036033u) && ((pUS[2] & 57311u) == 21584u)))\n                            {\n                                if (((_bits & 1048576L) != 0))\n                                {\n                                    _headers._Accept = AppendValue(_headers._Accept, value);\n                                }\n                                else\n                                {\n                                    _bits |= 1048576L;\n                                    _headers._Accept = new StringValues(value);\n                                }\n                                return;\n                            }\n                        }\n                        break;\n                \n                    case 4:\n                        {\n                            if ((((pUI[0] & 3755991007u) == 1414745928u)))\n                            {\n                                if (((_bits & 268435456L) != 0))\n                                {\n                                    _headers._Host = AppendValue(_headers._Host, value);\n                                }\n                                else\n                                {\n                                    _bits |= 268435456L;\n                                    _headers._Host = new StringValues(value);\n                                }\n                                return;\n                            }\n                        }\n                        break;\n                \n                    case 10:\n                        {\n                            if ((((pUL[0] & 16131858680330051551uL) == 4992030374873092949uL) && ((pUS[4] & 57311u) == 21582u)))\n                            {\n                                if (((_bits & 1099511627776L) != 0))\n                                {\n                                    _headers._UserAgent = AppendValue(_headers._UserAgent, value);\n                                }\n                                else\n                                {\n                                    _bits |= 1099511627776L;\n                                    _headers._UserAgent = new StringValues(value);\n                                }\n                                return;\n                            }\n                        }\n                        break;\n                }\n\n                \n            }\n            \n            AppendNonPrimaryHeaders(keyBytes, keyOffset, keyLength, value);\n        }\n        \n        private unsafe void AppendNonPrimaryHeaders(byte[] keyBytes, int keyOffset, int keyLength, string value)\n        {\n            string key;\n            fixed (byte* ptr = &keyBytes[keyOffset])\n            {\n                var pUB = ptr;\n                var pUL = (ulong*)pUB;\n                var pUI = (uint*)pUB;\n                var pUS = (ushort*)pUB;\n                switch (keyLength)\n                {\n                    case 13:\n                        {\n                            if ((((pUL[0] & 16131893727263186911uL) == 5711458528024281411uL) && ((pUI[2] & 3755991007u) == 1330795598u) && ((pUB[12] & 223u) == 76u)))\n                            {\n                                if (((_bits & 1L) != 0))\n                                {\n                                    _headers._CacheControl = AppendValue(_headers._CacheControl, value);\n                                }\n                                else\n                                {\n                                    _bits |= 1L;\n                                    _headers._CacheControl = new StringValues(value);\n                                }\n                                return;\n                            }\n                        \n                            if ((((pUL[0] & 18437701552104792031uL) == 3266321689424580419uL) && ((pUI[2] & 3755991007u) == 1196310866u) && ((pUB[12] & 223u) == 69u)))\n                            {\n                                if (((_bits & 131072L) != 0))\n                                {\n                                    _headers._ContentRange = AppendValue(_headers._ContentRange, value);\n                                }\n                                else\n                                {\n                                    _bits |= 131072L;\n                                    _headers._ContentRange = new StringValues(value);\n                                }\n                                return;\n                            }\n                        \n                            if ((((pUL[0] & 16131858680330051551uL) == 4922237774822850892uL) && ((pUI[2] & 3755991007u) == 1162430025u) && ((pUB[12] & 223u) == 68u)))\n                            {\n                                if (((_bits & 524288L) != 0))\n                                {\n                                    _headers._LastModified = AppendValue(_headers._LastModified, value);\n                                }\n                                else\n                                {\n                                    _bits |= 524288L;\n                                    _headers._LastModified = new StringValues(value);\n                                }\n                                return;\n                            }\n                        \n                            if ((((pUL[0] & 16131858542891098079uL) == 6505821637182772545uL) && ((pUI[2] & 3755991007u) == 1330205761u) && ((pUB[12] & 223u) == 78u)))\n                            {\n                                if (((_bits & 16777216L) != 0))\n                                {\n                                    _headers._Authorization = AppendValue(_headers._Authorization, value);\n                                }\n                                else\n                                {\n                                    _bits |= 16777216L;\n                                    _headers._Authorization = new StringValues(value);\n                                }\n                                return;\n                            }\n                        \n                            if ((((pUL[0] & 18437701552106889183uL) == 3262099607620765257uL) && ((pUI[2] & 3755991007u) == 1129595213u) && ((pUB[12] & 223u) == 72u)))\n                            {\n                                if (((_bits & 2147483648L) != 0))\n                                {\n                                    _headers._IfNoneMatch = AppendValue(_headers._IfNoneMatch, value);\n                                }\n                                else\n                                {\n                                    _bits |= 2147483648L;\n                                    _headers._IfNoneMatch = new StringValues(value);\n                                }\n                                return;\n                            }\n                        }\n                        break;\n                \n                    case 10:\n                        {\n                            if ((((pUL[0] & 16131858542891098079uL) == 5283922227757993795uL) && ((pUS[4] & 57311u) == 20047u)))\n                            {\n                                if (((_bits & 2L) != 0))\n                                {\n                                    _headers._Connection = AppendValue(_headers._Connection, value);\n                                }\n                                else\n                                {\n                                    _bits |= 2L;\n                                    _headers._Connection = new StringValues(value);\n                                }\n                                return;\n                            }\n                        \n                            if ((((pUL[0] & 16131858680330051551uL) == 5281668125874799947uL) && ((pUS[4] & 57311u) == 17750u)))\n                            {\n                                if (((_bits & 8L) != 0))\n                                {\n                                    _headers._KeepAlive = AppendValue(_headers._KeepAlive, value);\n                                }\n                                else\n                                {\n                                    _bits |= 8L;\n                                    _headers._KeepAlive = new StringValues(value);\n                                }\n                                return;\n                            }\n                        }\n                        break;\n                \n                    case 4:\n                        {\n                            if ((((pUI[0] & 3755991007u) == 1163149636u)))\n                            {\n                                if (((_bits & 4L) != 0))\n                                {\n                                    _headers._Date = AppendValue(_headers._Date, value);\n                                }\n                                else\n                                {\n                                    _bits |= 4L;\n                                    _headers._Date = new StringValues(value);\n                                }\n                                return;\n                            }\n                        \n                            if ((((pUI[0] & 3755991007u) == 1297044038u)))\n                            {\n                                if (((_bits & 134217728L) != 0))\n                                {\n                                    _headers._From = AppendValue(_headers._From, value);\n                                }\n                                else\n                                {\n                                    _bits |= 134217728L;\n                                    _headers._From = new StringValues(value);\n                                }\n                                return;\n                            }\n                        }\n                        break;\n                \n                    case 6:\n                        {\n                            if ((((pUI[0] & 3755991007u) == 1195463248u) && ((pUS[2] & 57311u) == 16717u)))\n                            {\n                                if (((_bits & 16L) != 0))\n                                {\n                                    _headers._Pragma = AppendValue(_headers._Pragma, value);\n                                }\n                                else\n                                {\n                                    _bits |= 16L;\n                                    _headers._Pragma = new StringValues(value);\n                                }\n                                return;\n                            }\n                        \n                            if ((((pUI[0] & 3755991007u) == 1263488835u) && ((pUS[2] & 57311u) == 17737u)))\n                            {\n                                if (((_bits & 33554432L) != 0))\n                                {\n                                    _headers._Cookie = AppendValue(_headers._Cookie, value);\n                                }\n                                else\n                                {\n                                    _bits |= 33554432L;\n                                    _headers._Cookie = new StringValues(value);\n                                }\n                                return;\n                            }\n                        \n                            if ((((pUI[0] & 3755991007u) == 1162893381u) && ((pUS[2] & 57311u) == 21571u)))\n                            {\n                                if (((_bits & 67108864L) != 0))\n                                {\n                                    _headers._Expect = AppendValue(_headers._Expect, value);\n                                }\n                                else\n                                {\n                                    _bits |= 67108864L;\n                                    _headers._Expect = new StringValues(value);\n                                }\n                                return;\n                            }\n                        \n                            if ((((pUI[0] & 3755991007u) == 1195987535u) && ((pUS[2] & 57311u) == 20041u)))\n                            {\n                                if (((_bits & 2199023255552L) != 0))\n                                {\n                                    _headers._Origin = AppendValue(_headers._Origin, value);\n                                }\n                                else\n                                {\n                                    _bits |= 2199023255552L;\n                                    _headers._Origin = new StringValues(value);\n                                }\n                                return;\n                            }\n                        }\n                        break;\n                \n                    case 7:\n                        {\n                            if ((((pUI[0] & 3755991007u) == 1229017684u) && ((pUS[2] & 57311u) == 17740u) && ((pUB[6] & 223u) == 82u)))\n                            {\n                                if (((_bits & 32L) != 0))\n                                {\n                                    _headers._Trailer = AppendValue(_headers._Trailer, value);\n                                }\n                                else\n                                {\n                                    _bits |= 32L;\n                                    _headers._Trailer = new StringValues(value);\n                                }\n                                return;\n                            }\n                        \n                            if ((((pUI[0] & 3755991007u) == 1380405333u) && ((pUS[2] & 57311u) == 17473u) && ((pUB[6] & 223u) == 69u)))\n                            {\n                                if (((_bits & 128L) != 0))\n                                {\n                                    _headers._Upgrade = AppendValue(_headers._Upgrade, value);\n                                }\n                                else\n                                {\n                                    _bits |= 128L;\n                                    _headers._Upgrade = new StringValues(value);\n                                }\n                                return;\n                            }\n                        \n                            if ((((pUI[0] & 3755991007u) == 1314013527u) && ((pUS[2] & 57311u) == 20041u) && ((pUB[6] & 223u) == 71u)))\n                            {\n                                if (((_bits & 512L) != 0))\n                                {\n                                    _headers._Warning = AppendValue(_headers._Warning, value);\n                                }\n                                else\n                                {\n                                    _bits |= 512L;\n                                    _headers._Warning = new StringValues(value);\n                                }\n                                return;\n                            }\n                        \n                            if ((((pUI[0] & 3755991007u) == 1230002245u) && ((pUS[2] & 57311u) == 17746u) && ((pUB[6] & 223u) == 83u)))\n                            {\n                                if (((_bits & 262144L) != 0))\n                                {\n                                    _headers._Expires = AppendValue(_headers._Expires, value);\n                                }\n                                else\n                                {\n                                    _bits |= 262144L;\n                                    _headers._Expires = new StringValues(value);\n                                }\n                                return;\n                            }\n                        \n                            if ((((pUI[0] & 3755991007u) == 1162233170u) && ((pUS[2] & 57311u) == 17746u) && ((pUB[6] & 223u) == 82u)))\n                            {\n                                if (((_bits & 68719476736L) != 0))\n                                {\n                                    _headers._Referer = AppendValue(_headers._Referer, value);\n                                }\n                                else\n                                {\n                                    _bits |= 68719476736L;\n                                    _headers._Referer = new StringValues(value);\n                                }\n                                return;\n                            }\n                        }\n                        break;\n                \n                    case 17:\n                        {\n                            if ((((pUL[0] & 16131858542891098079uL) == 5928221808112259668uL) && ((pUL[1] & 16131858542891098111uL) == 5641115115480565037uL) && ((pUB[16] & 223u) == 71u)))\n                            {\n                                if (((_bits & 64L) != 0))\n                                {\n                                    _headers._TransferEncoding = AppendValue(_headers._TransferEncoding, value);\n                                }\n                                else\n                                {\n                                    _bits |= 64L;\n                                    _headers._TransferEncoding = new StringValues(value);\n                                }\n                                return;\n                            }\n                        \n                            if ((((pUL[0] & 16131858542893195231uL) == 5064654363342751305uL) && ((pUL[1] & 16131858543427968991uL) == 4849894470315165001uL) && ((pUB[16] & 223u) == 69u)))\n                            {\n                                if (((_bits & 1073741824L) != 0))\n                                {\n                                    _headers._IfModifiedSince = AppendValue(_headers._IfModifiedSince, value);\n                                }\n                                else\n                                {\n                                    _bits |= 1073741824L;\n                                    _headers._IfModifiedSince = new StringValues(value);\n                                }\n                                return;\n                            }\n                        }\n                        break;\n                \n                    case 3:\n                        {\n                            if ((((pUS[0] & 57311u) == 18774u) && ((pUB[2] & 223u) == 65u)))\n                            {\n                                if (((_bits & 256L) != 0))\n                                {\n                                    _headers._Via = AppendValue(_headers._Via, value);\n                                }\n                                else\n                                {\n                                    _bits |= 256L;\n                                    _headers._Via = new StringValues(value);\n                                }\n                                return;\n                            }\n                        }\n                        break;\n                \n                    case 5:\n                        {\n                            if ((((pUI[0] & 3755991007u) == 1330400321u) && ((pUB[4] & 223u) == 87u)))\n                            {\n                                if (((_bits & 1024L) != 0))\n                                {\n                                    _headers._Allow = AppendValue(_headers._Allow, value);\n                                }\n                                else\n                                {\n                                    _bits |= 1024L;\n                                    _headers._Allow = new StringValues(value);\n                                }\n                                return;\n                            }\n                        \n                            if ((((pUI[0] & 3755991007u) == 1196310866u) && ((pUB[4] & 223u) == 69u)))\n                            {\n                                if (((_bits & 137438953472L) != 0))\n                                {\n                                    _headers._Range = AppendValue(_headers._Range, value);\n                                }\n                                else\n                                {\n                                    _bits |= 137438953472L;\n                                    _headers._Range = new StringValues(value);\n                                }\n                                return;\n                            }\n                        }\n                        break;\n                \n                    case 14:\n                        {\n                            if ((((pUL[0] & 18437701552104792031uL) == 3266321689424580419uL) && ((pUI[2] & 3755991007u) == 1196311884u) && ((pUS[6] & 57311u) == 18516u)))\n                            {\n                                if (((_bits & 2048L) != 0))\n                                {\n                                    _headers._ContentLength = AppendValue(_headers._ContentLength, value);\n                                }\n                                else\n                                {\n                                    _bits |= 2048L;\n                                    _headers._ContentLength = new StringValues(value);\n                                }\n                                return;\n                            }\n                        \n                            if ((((pUL[0] & 16140865742145839071uL) == 4840617878229304129uL) && ((pUI[2] & 3755991007u) == 1397899592u) && ((pUS[6] & 57311u) == 21573u)))\n                            {\n                                if (((_bits & 2097152L) != 0))\n                                {\n                                    _headers._AcceptCharset = AppendValue(_headers._AcceptCharset, value);\n                                }\n                                else\n                                {\n                                    _bits |= 2097152L;\n                                    _headers._AcceptCharset = new StringValues(value);\n                                }\n                                return;\n                            }\n                        }\n                        break;\n                \n                    case 12:\n                        {\n                            if ((((pUL[0] & 18437701552104792031uL) == 3266321689424580419uL) && ((pUI[2] & 3755991007u) == 1162893652u)))\n                            {\n                                if (((_bits & 4096L) != 0))\n                                {\n                                    _headers._ContentType = AppendValue(_headers._ContentType, value);\n                                }\n                                else\n                                {\n                                    _bits |= 4096L;\n                                    _headers._ContentType = new StringValues(value);\n                                }\n                                return;\n                            }\n                        \n                            if ((((pUL[0] & 16131858543427968991uL) == 6292178792217067853uL) && ((pUI[2] & 3755991007u) == 1396986433u)))\n                            {\n                                if (((_bits & 17179869184L) != 0))\n                                {\n                                    _headers._MaxForwards = AppendValue(_headers._MaxForwards, value);\n                                }\n                                else\n                                {\n                                    _bits |= 17179869184L;\n                                    _headers._MaxForwards = new StringValues(value);\n                                }\n                                return;\n                            }\n                        }\n                        break;\n                \n                    case 16:\n                        {\n                            if ((((pUL[0] & 18437701552104792031uL) == 3266321689424580419uL) && ((pUL[1] & 16131858542891098079uL) == 5138124782612729413uL)))\n                            {\n                                if (((_bits & 8192L) != 0))\n                                {\n                                    _headers._ContentEncoding = AppendValue(_headers._ContentEncoding, value);\n                                }\n                                else\n                                {\n                                    _bits |= 8192L;\n                                    _headers._ContentEncoding = new StringValues(value);\n                                }\n                                return;\n                            }\n                        \n                            if ((((pUL[0] & 18437701552104792031uL) == 3266321689424580419uL) && ((pUL[1] & 16131858542891098079uL) == 4992030546487820620uL)))\n                            {\n                                if (((_bits & 16384L) != 0))\n                                {\n                                    _headers._ContentLanguage = AppendValue(_headers._ContentLanguage, value);\n                                }\n                                else\n                                {\n                                    _bits |= 16384L;\n                                    _headers._ContentLanguage = new StringValues(value);\n                                }\n                                return;\n                            }\n                        \n                            if ((((pUL[0] & 18437701552104792031uL) == 3266321689424580419uL) && ((pUL[1] & 16131858542891098079uL) == 5642809484339531596uL)))\n                            {\n                                if (((_bits & 32768L) != 0))\n                                {\n                                    _headers._ContentLocation = AppendValue(_headers._ContentLocation, value);\n                                }\n                                else\n                                {\n                                    _bits |= 32768L;\n                                    _headers._ContentLocation = new StringValues(value);\n                                }\n                                return;\n                            }\n                        }\n                        break;\n                \n                    case 11:\n                        {\n                            if ((((pUL[0] & 18437701552104792031uL) == 3266321689424580419uL) && ((pUS[4] & 57311u) == 17485u) && ((pUB[10] & 255u) == 53u)))\n                            {\n                                if (((_bits & 65536L) != 0))\n                                {\n                                    _headers._ContentMD5 = AppendValue(_headers._ContentMD5, value);\n                                }\n                                else\n                                {\n                                    _bits |= 65536L;\n                                    _headers._ContentMD5 = new StringValues(value);\n                                }\n                                return;\n                            }\n                        }\n                        break;\n                \n                    case 15:\n                        {\n                            if ((((pUL[0] & 16140865742145839071uL) == 4984733066305160001uL) && ((pUI[2] & 3755991007u) == 1146045262u) && ((pUS[6] & 57311u) == 20041u) && ((pUB[14] & 223u) == 71u)))\n                            {\n                                if (((_bits & 4194304L) != 0))\n                                {\n                                    _headers._AcceptEncoding = AppendValue(_headers._AcceptEncoding, value);\n                                }\n                                else\n                                {\n                                    _bits |= 4194304L;\n                                    _headers._AcceptEncoding = new StringValues(value);\n                                }\n                                return;\n                            }\n                        \n                            if ((((pUL[0] & 16140865742145839071uL) == 5489136224570655553uL) && ((pUI[2] & 3755991007u) == 1430736449u) && ((pUS[6] & 57311u) == 18241u) && ((pUB[14] & 223u) == 69u)))\n                            {\n                                if (((_bits & 8388608L) != 0))\n                                {\n                                    _headers._AcceptLanguage = AppendValue(_headers._AcceptLanguage, value);\n                                }\n                                else\n                                {\n                                    _bits |= 8388608L;\n                                    _headers._AcceptLanguage = new StringValues(value);\n                                }\n                                return;\n                            }\n                        }\n                        break;\n                \n                    case 8:\n                        {\n                            if ((((pUL[0] & 16131858542893195231uL) == 5207098233614845513uL)))\n                            {\n                                if (((_bits & 536870912L) != 0))\n                                {\n                                    _headers._IfMatch = AppendValue(_headers._IfMatch, value);\n                                }\n                                else\n                                {\n                                    _bits |= 536870912L;\n                                    _headers._IfMatch = new StringValues(value);\n                                }\n                                return;\n                            }\n                        \n                            if ((((pUL[0] & 16131858542893195231uL) == 4992044754422023753uL)))\n                            {\n                                if (((_bits & 4294967296L) != 0))\n                                {\n                                    _headers._IfRange = AppendValue(_headers._IfRange, value);\n                                }\n                                else\n                                {\n                                    _bits |= 4294967296L;\n                                    _headers._IfRange = new StringValues(value);\n                                }\n                                return;\n                            }\n                        }\n                        break;\n                \n                    case 19:\n                        {\n                            if ((((pUL[0] & 16131858542893195231uL) == 4922237916571059785uL) && ((pUL[1] & 16131893727263186911uL) == 5283616559079179849uL) && ((pUS[8] & 57311u) == 17230u) && ((pUB[18] & 223u) == 69u)))\n                            {\n                                if (((_bits & 8589934592L) != 0))\n                                {\n                                    _headers._IfUnmodifiedSince = AppendValue(_headers._IfUnmodifiedSince, value);\n                                }\n                                else\n                                {\n                                    _bits |= 8589934592L;\n                                    _headers._IfUnmodifiedSince = new StringValues(value);\n                                }\n                                return;\n                            }\n                        \n                            if ((((pUL[0] & 16131893727263186911uL) == 6143241228466999888uL) && ((pUL[1] & 16131858542891098079uL) == 6071233043632179284uL) && ((pUS[8] & 57311u) == 20297u) && ((pUB[18] & 223u) == 78u)))\n                            {\n                                if (((_bits & 34359738368L) != 0))\n                                {\n                                    _headers._ProxyAuthorization = AppendValue(_headers._ProxyAuthorization, value);\n                                }\n                                else\n                                {\n                                    _bits |= 34359738368L;\n                                    _headers._ProxyAuthorization = new StringValues(value);\n                                }\n                                return;\n                            }\n                        }\n                        break;\n                \n                    case 2:\n                        {\n                            if ((((pUS[0] & 57311u) == 17748u)))\n                            {\n                                if (((_bits & 274877906944L) != 0))\n                                {\n                                    _headers._TE = AppendValue(_headers._TE, value);\n                                }\n                                else\n                                {\n                                    _bits |= 274877906944L;\n                                    _headers._TE = new StringValues(value);\n                                }\n                                return;\n                            }\n                        }\n                        break;\n                \n                    case 9:\n                        {\n                            if ((((pUL[0] & 16131858542891098079uL) == 6071217693351039572uL) && ((pUB[8] & 223u) == 69u)))\n                            {\n                                if (((_bits & 549755813888L) != 0))\n                                {\n                                    _headers._Translate = AppendValue(_headers._Translate, value);\n                                }\n                                else\n                                {\n                                    _bits |= 549755813888L;\n                                    _headers._Translate = new StringValues(value);\n                                }\n                                return;\n                            }\n                        }\n                        break;\n                \n                    case 29:\n                        {\n                            if ((((pUL[0] & 16140865742145839071uL) == 4840616791602578241uL) && ((pUL[1] & 16140865742145839071uL) == 5921472988629454415uL) && ((pUL[2] & 16140865742145839071uL) == 5561193831494668613uL) && ((pUI[6] & 3755991007u) == 1330140229u) && ((pUB[28] & 223u) == 68u)))\n                            {\n                                if (((_bits & 4398046511104L) != 0))\n                                {\n                                    _headers._AccessControlRequestMethod = AppendValue(_headers._AccessControlRequestMethod, value);\n                                }\n                                else\n                                {\n                                    _bits |= 4398046511104L;\n                                    _headers._AccessControlRequestMethod = new StringValues(value);\n                                }\n                                return;\n                            }\n                        }\n                        break;\n                \n                    case 30:\n                        {\n                            if ((((pUL[0] & 16140865742145839071uL) == 4840616791602578241uL) && ((pUL[1] & 16140865742145839071uL) == 5921472988629454415uL) && ((pUL[2] & 16140865742145839071uL) == 5200905861305028933uL) && ((pUI[6] & 3755991007u) == 1162101061u) && ((pUS[14] & 57311u) == 21330u)))\n                            {\n                                if (((_bits & 8796093022208L) != 0))\n                                {\n                                    _headers._AccessControlRequestHeaders = AppendValue(_headers._AccessControlRequestHeaders, value);\n                                }\n                                else\n                                {\n                                    _bits |= 8796093022208L;\n                                    _headers._AccessControlRequestHeaders = new StringValues(value);\n                                }\n                                return;\n                            }\n                        }\n                        break;\n                }\n\n                \n                    key = new string('\\0', keyLength);\n                    fixed(char *keyBuffer = key)\n                    {\n                        if (!AsciiUtilities.TryGetAsciiString(ptr, keyBuffer, keyLength))\n                        {\n                            throw BadHttpRequestException.GetException(RequestRejectionReason.InvalidCharactersInHeaderName);\n                        }\n                    }\n                \n            }\n\n            StringValues existing;\n            Unknown.TryGetValue(key, out existing);\n            Unknown[key] = AppendValue(existing, value);\n        }\n        private struct HeaderReferences\n        {\n            public StringValues _CacheControl;\n            public StringValues _Connection;\n            public StringValues _Date;\n            public StringValues _KeepAlive;\n            public StringValues _Pragma;\n            public StringValues _Trailer;\n            public StringValues _TransferEncoding;\n            public StringValues _Upgrade;\n            public StringValues _Via;\n            public StringValues _Warning;\n            public StringValues _Allow;\n            public StringValues _ContentLength;\n            public StringValues _ContentType;\n            public StringValues _ContentEncoding;\n            public StringValues _ContentLanguage;\n            public StringValues _ContentLocation;\n            public StringValues _ContentMD5;\n            public StringValues _ContentRange;\n            public StringValues _Expires;\n            public StringValues _LastModified;\n            public StringValues _Accept;\n            public StringValues _AcceptCharset;\n            public StringValues _AcceptEncoding;\n            public StringValues _AcceptLanguage;\n            public StringValues _Authorization;\n            public StringValues _Cookie;\n            public StringValues _Expect;\n            public StringValues _From;\n            public StringValues _Host;\n            public StringValues _IfMatch;\n            public StringValues _IfModifiedSince;\n            public StringValues _IfNoneMatch;\n            public StringValues _IfRange;\n            public StringValues _IfUnmodifiedSince;\n            public StringValues _MaxForwards;\n            public StringValues _ProxyAuthorization;\n            public StringValues _Referer;\n            public StringValues _Range;\n            public StringValues _TE;\n            public StringValues _Translate;\n            public StringValues _UserAgent;\n            public StringValues _Origin;\n            public StringValues _AccessControlRequestMethod;\n            public StringValues _AccessControlRequestHeaders;\n            \n        }\n\n        public partial struct Enumerator\n        {\n            public bool MoveNext()\n            {\n                switch (_state)\n                {\n                    \n                        case 0:\n                            goto state0;\n                    \n                        case 1:\n                            goto state1;\n                    \n                        case 2:\n                            goto state2;\n                    \n                        case 3:\n                            goto state3;\n                    \n                        case 4:\n                            goto state4;\n                    \n                        case 5:\n                            goto state5;\n                    \n                        case 6:\n                            goto state6;\n                    \n                        case 7:\n                            goto state7;\n                    \n                        case 8:\n                            goto state8;\n                    \n                        case 9:\n                            goto state9;\n                    \n                        case 10:\n                            goto state10;\n                    \n                        case 11:\n                            goto state11;\n                    \n                        case 12:\n                            goto state12;\n                    \n                        case 13:\n                            goto state13;\n                    \n                        case 14:\n                            goto state14;\n                    \n                        case 15:\n                            goto state15;\n                    \n                        case 16:\n                            goto state16;\n                    \n                        case 17:\n                            goto state17;\n                    \n                        case 18:\n                            goto state18;\n                    \n                        case 19:\n                            goto state19;\n                    \n                        case 20:\n                            goto state20;\n                    \n                        case 21:\n                            goto state21;\n                    \n                        case 22:\n                            goto state22;\n                    \n                        case 23:\n                            goto state23;\n                    \n                        case 24:\n                            goto state24;\n                    \n                        case 25:\n                            goto state25;\n                    \n                        case 26:\n                            goto state26;\n                    \n                        case 27:\n                            goto state27;\n                    \n                        case 28:\n                            goto state28;\n                    \n                        case 29:\n                            goto state29;\n                    \n                        case 30:\n                            goto state30;\n                    \n                        case 31:\n                            goto state31;\n                    \n                        case 32:\n                            goto state32;\n                    \n                        case 33:\n                            goto state33;\n                    \n                        case 34:\n                            goto state34;\n                    \n                        case 35:\n                            goto state35;\n                    \n                        case 36:\n                            goto state36;\n                    \n                        case 37:\n                            goto state37;\n                    \n                        case 38:\n                            goto state38;\n                    \n                        case 39:\n                            goto state39;\n                    \n                        case 40:\n                            goto state40;\n                    \n                        case 41:\n                            goto state41;\n                    \n                        case 42:\n                            goto state42;\n                    \n                        case 43:\n                            goto state43;\n                    \n                    default:\n                        goto state_default;\n                }\n                \n                state0:\n                    if (((_bits & 1L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Cache-Control\", _collection._headers._CacheControl);\n                        _state = 1;\n                        return true;\n                    }\n                \n                state1:\n                    if (((_bits & 2L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Connection\", _collection._headers._Connection);\n                        _state = 2;\n                        return true;\n                    }\n                \n                state2:\n                    if (((_bits & 4L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Date\", _collection._headers._Date);\n                        _state = 3;\n                        return true;\n                    }\n                \n                state3:\n                    if (((_bits & 8L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Keep-Alive\", _collection._headers._KeepAlive);\n                        _state = 4;\n                        return true;\n                    }\n                \n                state4:\n                    if (((_bits & 16L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Pragma\", _collection._headers._Pragma);\n                        _state = 5;\n                        return true;\n                    }\n                \n                state5:\n                    if (((_bits & 32L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Trailer\", _collection._headers._Trailer);\n                        _state = 6;\n                        return true;\n                    }\n                \n                state6:\n                    if (((_bits & 64L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Transfer-Encoding\", _collection._headers._TransferEncoding);\n                        _state = 7;\n                        return true;\n                    }\n                \n                state7:\n                    if (((_bits & 128L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Upgrade\", _collection._headers._Upgrade);\n                        _state = 8;\n                        return true;\n                    }\n                \n                state8:\n                    if (((_bits & 256L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Via\", _collection._headers._Via);\n                        _state = 9;\n                        return true;\n                    }\n                \n                state9:\n                    if (((_bits & 512L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Warning\", _collection._headers._Warning);\n                        _state = 10;\n                        return true;\n                    }\n                \n                state10:\n                    if (((_bits & 1024L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Allow\", _collection._headers._Allow);\n                        _state = 11;\n                        return true;\n                    }\n                \n                state11:\n                    if (((_bits & 2048L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Content-Length\", _collection._headers._ContentLength);\n                        _state = 12;\n                        return true;\n                    }\n                \n                state12:\n                    if (((_bits & 4096L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Content-Type\", _collection._headers._ContentType);\n                        _state = 13;\n                        return true;\n                    }\n                \n                state13:\n                    if (((_bits & 8192L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Content-Encoding\", _collection._headers._ContentEncoding);\n                        _state = 14;\n                        return true;\n                    }\n                \n                state14:\n                    if (((_bits & 16384L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Content-Language\", _collection._headers._ContentLanguage);\n                        _state = 15;\n                        return true;\n                    }\n                \n                state15:\n                    if (((_bits & 32768L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Content-Location\", _collection._headers._ContentLocation);\n                        _state = 16;\n                        return true;\n                    }\n                \n                state16:\n                    if (((_bits & 65536L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Content-MD5\", _collection._headers._ContentMD5);\n                        _state = 17;\n                        return true;\n                    }\n                \n                state17:\n                    if (((_bits & 131072L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Content-Range\", _collection._headers._ContentRange);\n                        _state = 18;\n                        return true;\n                    }\n                \n                state18:\n                    if (((_bits & 262144L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Expires\", _collection._headers._Expires);\n                        _state = 19;\n                        return true;\n                    }\n                \n                state19:\n                    if (((_bits & 524288L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Last-Modified\", _collection._headers._LastModified);\n                        _state = 20;\n                        return true;\n                    }\n                \n                state20:\n                    if (((_bits & 1048576L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Accept\", _collection._headers._Accept);\n                        _state = 21;\n                        return true;\n                    }\n                \n                state21:\n                    if (((_bits & 2097152L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Accept-Charset\", _collection._headers._AcceptCharset);\n                        _state = 22;\n                        return true;\n                    }\n                \n                state22:\n                    if (((_bits & 4194304L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Accept-Encoding\", _collection._headers._AcceptEncoding);\n                        _state = 23;\n                        return true;\n                    }\n                \n                state23:\n                    if (((_bits & 8388608L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Accept-Language\", _collection._headers._AcceptLanguage);\n                        _state = 24;\n                        return true;\n                    }\n                \n                state24:\n                    if (((_bits & 16777216L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Authorization\", _collection._headers._Authorization);\n                        _state = 25;\n                        return true;\n                    }\n                \n                state25:\n                    if (((_bits & 33554432L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Cookie\", _collection._headers._Cookie);\n                        _state = 26;\n                        return true;\n                    }\n                \n                state26:\n                    if (((_bits & 67108864L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Expect\", _collection._headers._Expect);\n                        _state = 27;\n                        return true;\n                    }\n                \n                state27:\n                    if (((_bits & 134217728L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"From\", _collection._headers._From);\n                        _state = 28;\n                        return true;\n                    }\n                \n                state28:\n                    if (((_bits & 268435456L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Host\", _collection._headers._Host);\n                        _state = 29;\n                        return true;\n                    }\n                \n                state29:\n                    if (((_bits & 536870912L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"If-Match\", _collection._headers._IfMatch);\n                        _state = 30;\n                        return true;\n                    }\n                \n                state30:\n                    if (((_bits & 1073741824L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"If-Modified-Since\", _collection._headers._IfModifiedSince);\n                        _state = 31;\n                        return true;\n                    }\n                \n                state31:\n                    if (((_bits & 2147483648L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"If-None-Match\", _collection._headers._IfNoneMatch);\n                        _state = 32;\n                        return true;\n                    }\n                \n                state32:\n                    if (((_bits & 4294967296L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"If-Range\", _collection._headers._IfRange);\n                        _state = 33;\n                        return true;\n                    }\n                \n                state33:\n                    if (((_bits & 8589934592L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"If-Unmodified-Since\", _collection._headers._IfUnmodifiedSince);\n                        _state = 34;\n                        return true;\n                    }\n                \n                state34:\n                    if (((_bits & 17179869184L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Max-Forwards\", _collection._headers._MaxForwards);\n                        _state = 35;\n                        return true;\n                    }\n                \n                state35:\n                    if (((_bits & 34359738368L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Proxy-Authorization\", _collection._headers._ProxyAuthorization);\n                        _state = 36;\n                        return true;\n                    }\n                \n                state36:\n                    if (((_bits & 68719476736L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Referer\", _collection._headers._Referer);\n                        _state = 37;\n                        return true;\n                    }\n                \n                state37:\n                    if (((_bits & 137438953472L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Range\", _collection._headers._Range);\n                        _state = 38;\n                        return true;\n                    }\n                \n                state38:\n                    if (((_bits & 274877906944L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"TE\", _collection._headers._TE);\n                        _state = 39;\n                        return true;\n                    }\n                \n                state39:\n                    if (((_bits & 549755813888L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Translate\", _collection._headers._Translate);\n                        _state = 40;\n                        return true;\n                    }\n                \n                state40:\n                    if (((_bits & 1099511627776L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"User-Agent\", _collection._headers._UserAgent);\n                        _state = 41;\n                        return true;\n                    }\n                \n                state41:\n                    if (((_bits & 2199023255552L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Origin\", _collection._headers._Origin);\n                        _state = 42;\n                        return true;\n                    }\n                \n                state42:\n                    if (((_bits & 4398046511104L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Access-Control-Request-Method\", _collection._headers._AccessControlRequestMethod);\n                        _state = 43;\n                        return true;\n                    }\n                \n                state43:\n                    if (((_bits & 8796093022208L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Access-Control-Request-Headers\", _collection._headers._AccessControlRequestHeaders);\n                        _state = 44;\n                        return true;\n                    }\n                \n                state_default:\n                    if (!_hasUnknown || !_unknownEnumerator.MoveNext())\n                    {\n                        _current = default(KeyValuePair<string, StringValues>);\n                        return false;\n                    }\n                    _current = _unknownEnumerator.Current;\n                    return true;\n            }\n        }\n    }\n\n    public partial class FrameResponseHeaders\n    {\n        private static byte[] _headerBytes = new byte[]\n        {\n            13,10,67,97,99,104,101,45,67,111,110,116,114,111,108,58,32,13,10,67,111,110,110,101,99,116,105,111,110,58,32,13,10,68,97,116,101,58,32,13,10,75,101,101,112,45,65,108,105,118,101,58,32,13,10,80,114,97,103,109,97,58,32,13,10,84,114,97,105,108,101,114,58,32,13,10,84,114,97,110,115,102,101,114,45,69,110,99,111,100,105,110,103,58,32,13,10,85,112,103,114,97,100,101,58,32,13,10,86,105,97,58,32,13,10,87,97,114,110,105,110,103,58,32,13,10,65,108,108,111,119,58,32,13,10,67,111,110,116,101,110,116,45,76,101,110,103,116,104,58,32,13,10,67,111,110,116,101,110,116,45,84,121,112,101,58,32,13,10,67,111,110,116,101,110,116,45,69,110,99,111,100,105,110,103,58,32,13,10,67,111,110,116,101,110,116,45,76,97,110,103,117,97,103,101,58,32,13,10,67,111,110,116,101,110,116,45,76,111,99,97,116,105,111,110,58,32,13,10,67,111,110,116,101,110,116,45,77,68,53,58,32,13,10,67,111,110,116,101,110,116,45,82,97,110,103,101,58,32,13,10,69,120,112,105,114,101,115,58,32,13,10,76,97,115,116,45,77,111,100,105,102,105,101,100,58,32,13,10,65,99,99,101,112,116,45,82,97,110,103,101,115,58,32,13,10,65,103,101,58,32,13,10,69,84,97,103,58,32,13,10,76,111,99,97,116,105,111,110,58,32,13,10,80,114,111,120,121,45,65,117,116,104,101,110,116,105,99,97,116,101,58,32,13,10,82,101,116,114,121,45,65,102,116,101,114,58,32,13,10,83,101,114,118,101,114,58,32,13,10,83,101,116,45,67,111,111,107,105,101,58,32,13,10,86,97,114,121,58,32,13,10,87,87,87,45,65,117,116,104,101,110,116,105,99,97,116,101,58,32,13,10,65,99,99,101,115,115,45,67,111,110,116,114,111,108,45,65,108,108,111,119,45,67,114,101,100,101,110,116,105,97,108,115,58,32,13,10,65,99,99,101,115,115,45,67,111,110,116,114,111,108,45,65,108,108,111,119,45,72,101,97,100,101,114,115,58,32,13,10,65,99,99,101,115,115,45,67,111,110,116,114,111,108,45,65,108,108,111,119,45,77,101,116,104,111,100,115,58,32,13,10,65,99,99,101,115,115,45,67,111,110,116,114,111,108,45,65,108,108,111,119,45,79,114,105,103,105,110,58,32,13,10,65,99,99,101,115,115,45,67,111,110,116,114,111,108,45,69,120,112,111,115,101,45,72,101,97,100,101,114,115,58,32,13,10,65,99,99,101,115,115,45,67,111,110,116,114,111,108,45,77,97,120,45,65,103,101,58,32,\n        };\n\n        private long _bits = 0;\n        private HeaderReferences _headers;\n        \n        public StringValues HeaderCacheControl\n        {\n            get\n            {\n                if (((_bits & 1L) != 0))\n                {\n                    return _headers._CacheControl;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 1L;\n                _headers._CacheControl = value; \n            }\n        }\n        public StringValues HeaderConnection\n        {\n            get\n            {\n                if (((_bits & 2L) != 0))\n                {\n                    return _headers._Connection;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 2L;\n                _headers._Connection = value; \n                _headers._rawConnection = null;\n            }\n        }\n        public StringValues HeaderDate\n        {\n            get\n            {\n                if (((_bits & 4L) != 0))\n                {\n                    return _headers._Date;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 4L;\n                _headers._Date = value; \n                _headers._rawDate = null;\n            }\n        }\n        public StringValues HeaderKeepAlive\n        {\n            get\n            {\n                if (((_bits & 8L) != 0))\n                {\n                    return _headers._KeepAlive;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 8L;\n                _headers._KeepAlive = value; \n            }\n        }\n        public StringValues HeaderPragma\n        {\n            get\n            {\n                if (((_bits & 16L) != 0))\n                {\n                    return _headers._Pragma;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 16L;\n                _headers._Pragma = value; \n            }\n        }\n        public StringValues HeaderTrailer\n        {\n            get\n            {\n                if (((_bits & 32L) != 0))\n                {\n                    return _headers._Trailer;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 32L;\n                _headers._Trailer = value; \n            }\n        }\n        public StringValues HeaderTransferEncoding\n        {\n            get\n            {\n                if (((_bits & 64L) != 0))\n                {\n                    return _headers._TransferEncoding;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 64L;\n                _headers._TransferEncoding = value; \n                _headers._rawTransferEncoding = null;\n            }\n        }\n        public StringValues HeaderUpgrade\n        {\n            get\n            {\n                if (((_bits & 128L) != 0))\n                {\n                    return _headers._Upgrade;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 128L;\n                _headers._Upgrade = value; \n            }\n        }\n        public StringValues HeaderVia\n        {\n            get\n            {\n                if (((_bits & 256L) != 0))\n                {\n                    return _headers._Via;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 256L;\n                _headers._Via = value; \n            }\n        }\n        public StringValues HeaderWarning\n        {\n            get\n            {\n                if (((_bits & 512L) != 0))\n                {\n                    return _headers._Warning;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 512L;\n                _headers._Warning = value; \n            }\n        }\n        public StringValues HeaderAllow\n        {\n            get\n            {\n                if (((_bits & 1024L) != 0))\n                {\n                    return _headers._Allow;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 1024L;\n                _headers._Allow = value; \n            }\n        }\n        public StringValues HeaderContentLength\n        {\n            get\n            {\n                if (((_bits & 2048L) != 0))\n                {\n                    return _headers._ContentLength;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _contentLength = ParseContentLength(value);\n                _bits |= 2048L;\n                _headers._ContentLength = value; \n                _headers._rawContentLength = null;\n            }\n        }\n        public StringValues HeaderContentType\n        {\n            get\n            {\n                if (((_bits & 4096L) != 0))\n                {\n                    return _headers._ContentType;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 4096L;\n                _headers._ContentType = value; \n            }\n        }\n        public StringValues HeaderContentEncoding\n        {\n            get\n            {\n                if (((_bits & 8192L) != 0))\n                {\n                    return _headers._ContentEncoding;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 8192L;\n                _headers._ContentEncoding = value; \n            }\n        }\n        public StringValues HeaderContentLanguage\n        {\n            get\n            {\n                if (((_bits & 16384L) != 0))\n                {\n                    return _headers._ContentLanguage;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 16384L;\n                _headers._ContentLanguage = value; \n            }\n        }\n        public StringValues HeaderContentLocation\n        {\n            get\n            {\n                if (((_bits & 32768L) != 0))\n                {\n                    return _headers._ContentLocation;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 32768L;\n                _headers._ContentLocation = value; \n            }\n        }\n        public StringValues HeaderContentMD5\n        {\n            get\n            {\n                if (((_bits & 65536L) != 0))\n                {\n                    return _headers._ContentMD5;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 65536L;\n                _headers._ContentMD5 = value; \n            }\n        }\n        public StringValues HeaderContentRange\n        {\n            get\n            {\n                if (((_bits & 131072L) != 0))\n                {\n                    return _headers._ContentRange;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 131072L;\n                _headers._ContentRange = value; \n            }\n        }\n        public StringValues HeaderExpires\n        {\n            get\n            {\n                if (((_bits & 262144L) != 0))\n                {\n                    return _headers._Expires;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 262144L;\n                _headers._Expires = value; \n            }\n        }\n        public StringValues HeaderLastModified\n        {\n            get\n            {\n                if (((_bits & 524288L) != 0))\n                {\n                    return _headers._LastModified;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 524288L;\n                _headers._LastModified = value; \n            }\n        }\n        public StringValues HeaderAcceptRanges\n        {\n            get\n            {\n                if (((_bits & 1048576L) != 0))\n                {\n                    return _headers._AcceptRanges;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 1048576L;\n                _headers._AcceptRanges = value; \n            }\n        }\n        public StringValues HeaderAge\n        {\n            get\n            {\n                if (((_bits & 2097152L) != 0))\n                {\n                    return _headers._Age;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 2097152L;\n                _headers._Age = value; \n            }\n        }\n        public StringValues HeaderETag\n        {\n            get\n            {\n                if (((_bits & 4194304L) != 0))\n                {\n                    return _headers._ETag;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 4194304L;\n                _headers._ETag = value; \n            }\n        }\n        public StringValues HeaderLocation\n        {\n            get\n            {\n                if (((_bits & 8388608L) != 0))\n                {\n                    return _headers._Location;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 8388608L;\n                _headers._Location = value; \n            }\n        }\n        public StringValues HeaderProxyAuthenticate\n        {\n            get\n            {\n                if (((_bits & 16777216L) != 0))\n                {\n                    return _headers._ProxyAuthenticate;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 16777216L;\n                _headers._ProxyAuthenticate = value; \n            }\n        }\n        public StringValues HeaderRetryAfter\n        {\n            get\n            {\n                if (((_bits & 33554432L) != 0))\n                {\n                    return _headers._RetryAfter;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 33554432L;\n                _headers._RetryAfter = value; \n            }\n        }\n        public StringValues HeaderServer\n        {\n            get\n            {\n                if (((_bits & 67108864L) != 0))\n                {\n                    return _headers._Server;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 67108864L;\n                _headers._Server = value; \n                _headers._rawServer = null;\n            }\n        }\n        public StringValues HeaderSetCookie\n        {\n            get\n            {\n                if (((_bits & 134217728L) != 0))\n                {\n                    return _headers._SetCookie;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 134217728L;\n                _headers._SetCookie = value; \n            }\n        }\n        public StringValues HeaderVary\n        {\n            get\n            {\n                if (((_bits & 268435456L) != 0))\n                {\n                    return _headers._Vary;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 268435456L;\n                _headers._Vary = value; \n            }\n        }\n        public StringValues HeaderWWWAuthenticate\n        {\n            get\n            {\n                if (((_bits & 536870912L) != 0))\n                {\n                    return _headers._WWWAuthenticate;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 536870912L;\n                _headers._WWWAuthenticate = value; \n            }\n        }\n        public StringValues HeaderAccessControlAllowCredentials\n        {\n            get\n            {\n                if (((_bits & 1073741824L) != 0))\n                {\n                    return _headers._AccessControlAllowCredentials;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 1073741824L;\n                _headers._AccessControlAllowCredentials = value; \n            }\n        }\n        public StringValues HeaderAccessControlAllowHeaders\n        {\n            get\n            {\n                if (((_bits & 2147483648L) != 0))\n                {\n                    return _headers._AccessControlAllowHeaders;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 2147483648L;\n                _headers._AccessControlAllowHeaders = value; \n            }\n        }\n        public StringValues HeaderAccessControlAllowMethods\n        {\n            get\n            {\n                if (((_bits & 4294967296L) != 0))\n                {\n                    return _headers._AccessControlAllowMethods;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 4294967296L;\n                _headers._AccessControlAllowMethods = value; \n            }\n        }\n        public StringValues HeaderAccessControlAllowOrigin\n        {\n            get\n            {\n                if (((_bits & 8589934592L) != 0))\n                {\n                    return _headers._AccessControlAllowOrigin;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 8589934592L;\n                _headers._AccessControlAllowOrigin = value; \n            }\n        }\n        public StringValues HeaderAccessControlExposeHeaders\n        {\n            get\n            {\n                if (((_bits & 17179869184L) != 0))\n                {\n                    return _headers._AccessControlExposeHeaders;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 17179869184L;\n                _headers._AccessControlExposeHeaders = value; \n            }\n        }\n        public StringValues HeaderAccessControlMaxAge\n        {\n            get\n            {\n                if (((_bits & 34359738368L) != 0))\n                {\n                    return _headers._AccessControlMaxAge;\n                }\n                return StringValues.Empty;\n            }\n            set\n            {\n                _bits |= 34359738368L;\n                _headers._AccessControlMaxAge = value; \n            }\n        }\n        \n        public void SetRawConnection(StringValues value, byte[] raw)\n        {\n            _bits |= 2L;\n            _headers._Connection = value;\n            _headers._rawConnection = raw;\n        }\n        public void SetRawDate(StringValues value, byte[] raw)\n        {\n            _bits |= 4L;\n            _headers._Date = value;\n            _headers._rawDate = raw;\n        }\n        public void SetRawTransferEncoding(StringValues value, byte[] raw)\n        {\n            _bits |= 64L;\n            _headers._TransferEncoding = value;\n            _headers._rawTransferEncoding = raw;\n        }\n        public void SetRawContentLength(StringValues value, byte[] raw)\n        {\n            _contentLength = ParseContentLength(value);\n            _bits |= 2048L;\n            _headers._ContentLength = value;\n            _headers._rawContentLength = raw;\n        }\n        public void SetRawServer(StringValues value, byte[] raw)\n        {\n            _bits |= 67108864L;\n            _headers._Server = value;\n            _headers._rawServer = raw;\n        }\n        protected override int GetCountFast()\n        {\n            return BitCount(_bits) + (MaybeUnknown?.Count ?? 0);\n        }\n        protected override StringValues GetValueFast(string key)\n        {\n            switch (key.Length)\n            {\n                case 13:\n                    {\n                        if (\"Cache-Control\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1L) != 0))\n                            {\n                                return _headers._CacheControl;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Content-Range\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 131072L) != 0))\n                            {\n                                return _headers._ContentRange;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Last-Modified\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 524288L) != 0))\n                            {\n                                return _headers._LastModified;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Accept-Ranges\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1048576L) != 0))\n                            {\n                                return _headers._AcceptRanges;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 10:\n                    {\n                        if (\"Connection\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2L) != 0))\n                            {\n                                return _headers._Connection;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Keep-Alive\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8L) != 0))\n                            {\n                                return _headers._KeepAlive;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Set-Cookie\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 134217728L) != 0))\n                            {\n                                return _headers._SetCookie;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 4:\n                    {\n                        if (\"Date\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4L) != 0))\n                            {\n                                return _headers._Date;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"ETag\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4194304L) != 0))\n                            {\n                                return _headers._ETag;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Vary\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 268435456L) != 0))\n                            {\n                                return _headers._Vary;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 6:\n                    {\n                        if (\"Pragma\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 16L) != 0))\n                            {\n                                return _headers._Pragma;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Server\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 67108864L) != 0))\n                            {\n                                return _headers._Server;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 7:\n                    {\n                        if (\"Trailer\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 32L) != 0))\n                            {\n                                return _headers._Trailer;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Upgrade\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 128L) != 0))\n                            {\n                                return _headers._Upgrade;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Warning\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 512L) != 0))\n                            {\n                                return _headers._Warning;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Expires\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 262144L) != 0))\n                            {\n                                return _headers._Expires;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 17:\n                    {\n                        if (\"Transfer-Encoding\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 64L) != 0))\n                            {\n                                return _headers._TransferEncoding;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 3:\n                    {\n                        if (\"Via\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 256L) != 0))\n                            {\n                                return _headers._Via;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Age\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2097152L) != 0))\n                            {\n                                return _headers._Age;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 5:\n                    {\n                        if (\"Allow\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1024L) != 0))\n                            {\n                                return _headers._Allow;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 14:\n                    {\n                        if (\"Content-Length\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2048L) != 0))\n                            {\n                                return _headers._ContentLength;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 12:\n                    {\n                        if (\"Content-Type\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4096L) != 0))\n                            {\n                                return _headers._ContentType;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 16:\n                    {\n                        if (\"Content-Encoding\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8192L) != 0))\n                            {\n                                return _headers._ContentEncoding;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Content-Language\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 16384L) != 0))\n                            {\n                                return _headers._ContentLanguage;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Content-Location\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 32768L) != 0))\n                            {\n                                return _headers._ContentLocation;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"WWW-Authenticate\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 536870912L) != 0))\n                            {\n                                return _headers._WWWAuthenticate;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 11:\n                    {\n                        if (\"Content-MD5\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 65536L) != 0))\n                            {\n                                return _headers._ContentMD5;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Retry-After\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 33554432L) != 0))\n                            {\n                                return _headers._RetryAfter;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 8:\n                    {\n                        if (\"Location\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8388608L) != 0))\n                            {\n                                return _headers._Location;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 18:\n                    {\n                        if (\"Proxy-Authenticate\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 16777216L) != 0))\n                            {\n                                return _headers._ProxyAuthenticate;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 32:\n                    {\n                        if (\"Access-Control-Allow-Credentials\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1073741824L) != 0))\n                            {\n                                return _headers._AccessControlAllowCredentials;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 28:\n                    {\n                        if (\"Access-Control-Allow-Headers\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2147483648L) != 0))\n                            {\n                                return _headers._AccessControlAllowHeaders;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    \n                        if (\"Access-Control-Allow-Methods\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4294967296L) != 0))\n                            {\n                                return _headers._AccessControlAllowMethods;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 27:\n                    {\n                        if (\"Access-Control-Allow-Origin\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8589934592L) != 0))\n                            {\n                                return _headers._AccessControlAllowOrigin;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 29:\n                    {\n                        if (\"Access-Control-Expose-Headers\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 17179869184L) != 0))\n                            {\n                                return _headers._AccessControlExposeHeaders;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n\n                case 22:\n                    {\n                        if (\"Access-Control-Max-Age\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 34359738368L) != 0))\n                            {\n                                return _headers._AccessControlMaxAge;\n                            }\n                            else\n                            {\n                                ThrowKeyNotFoundException();\n                            }\n                        }\n                    }\n                    break;\n}\n            if (MaybeUnknown == null)\n            {\n                ThrowKeyNotFoundException();\n            }\n            return MaybeUnknown[key];\n        }\n        protected override bool TryGetValueFast(string key, out StringValues value)\n        {\n            switch (key.Length)\n            {\n                case 13:\n                    {\n                        if (\"Cache-Control\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1L) != 0))\n                            {\n                                value = _headers._CacheControl;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Content-Range\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 131072L) != 0))\n                            {\n                                value = _headers._ContentRange;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Last-Modified\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 524288L) != 0))\n                            {\n                                value = _headers._LastModified;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Accept-Ranges\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1048576L) != 0))\n                            {\n                                value = _headers._AcceptRanges;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 10:\n                    {\n                        if (\"Connection\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2L) != 0))\n                            {\n                                value = _headers._Connection;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Keep-Alive\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8L) != 0))\n                            {\n                                value = _headers._KeepAlive;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Set-Cookie\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 134217728L) != 0))\n                            {\n                                value = _headers._SetCookie;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 4:\n                    {\n                        if (\"Date\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4L) != 0))\n                            {\n                                value = _headers._Date;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"ETag\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4194304L) != 0))\n                            {\n                                value = _headers._ETag;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Vary\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 268435456L) != 0))\n                            {\n                                value = _headers._Vary;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 6:\n                    {\n                        if (\"Pragma\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 16L) != 0))\n                            {\n                                value = _headers._Pragma;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Server\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 67108864L) != 0))\n                            {\n                                value = _headers._Server;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 7:\n                    {\n                        if (\"Trailer\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 32L) != 0))\n                            {\n                                value = _headers._Trailer;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Upgrade\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 128L) != 0))\n                            {\n                                value = _headers._Upgrade;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Warning\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 512L) != 0))\n                            {\n                                value = _headers._Warning;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Expires\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 262144L) != 0))\n                            {\n                                value = _headers._Expires;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 17:\n                    {\n                        if (\"Transfer-Encoding\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 64L) != 0))\n                            {\n                                value = _headers._TransferEncoding;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 3:\n                    {\n                        if (\"Via\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 256L) != 0))\n                            {\n                                value = _headers._Via;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Age\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2097152L) != 0))\n                            {\n                                value = _headers._Age;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 5:\n                    {\n                        if (\"Allow\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1024L) != 0))\n                            {\n                                value = _headers._Allow;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 14:\n                    {\n                        if (\"Content-Length\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2048L) != 0))\n                            {\n                                value = _headers._ContentLength;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 12:\n                    {\n                        if (\"Content-Type\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4096L) != 0))\n                            {\n                                value = _headers._ContentType;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 16:\n                    {\n                        if (\"Content-Encoding\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8192L) != 0))\n                            {\n                                value = _headers._ContentEncoding;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Content-Language\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 16384L) != 0))\n                            {\n                                value = _headers._ContentLanguage;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Content-Location\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 32768L) != 0))\n                            {\n                                value = _headers._ContentLocation;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"WWW-Authenticate\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 536870912L) != 0))\n                            {\n                                value = _headers._WWWAuthenticate;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 11:\n                    {\n                        if (\"Content-MD5\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 65536L) != 0))\n                            {\n                                value = _headers._ContentMD5;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Retry-After\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 33554432L) != 0))\n                            {\n                                value = _headers._RetryAfter;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 8:\n                    {\n                        if (\"Location\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8388608L) != 0))\n                            {\n                                value = _headers._Location;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 18:\n                    {\n                        if (\"Proxy-Authenticate\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 16777216L) != 0))\n                            {\n                                value = _headers._ProxyAuthenticate;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 32:\n                    {\n                        if (\"Access-Control-Allow-Credentials\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1073741824L) != 0))\n                            {\n                                value = _headers._AccessControlAllowCredentials;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 28:\n                    {\n                        if (\"Access-Control-Allow-Headers\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2147483648L) != 0))\n                            {\n                                value = _headers._AccessControlAllowHeaders;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Access-Control-Allow-Methods\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4294967296L) != 0))\n                            {\n                                value = _headers._AccessControlAllowMethods;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 27:\n                    {\n                        if (\"Access-Control-Allow-Origin\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8589934592L) != 0))\n                            {\n                                value = _headers._AccessControlAllowOrigin;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 29:\n                    {\n                        if (\"Access-Control-Expose-Headers\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 17179869184L) != 0))\n                            {\n                                value = _headers._AccessControlExposeHeaders;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n\n                case 22:\n                    {\n                        if (\"Access-Control-Max-Age\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 34359738368L) != 0))\n                            {\n                                value = _headers._AccessControlMaxAge;\n                                return true;\n                            }\n                            else\n                            {\n                                value = StringValues.Empty;\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n}\n            value = StringValues.Empty;\n            return MaybeUnknown?.TryGetValue(key, out value) ?? false;\n        }\n        protected override void SetValueFast(string key, StringValues value)\n        {\n            ValidateHeaderCharacters(value);\n            switch (key.Length)\n            {\n                case 13:\n                    {\n                        if (\"Cache-Control\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 1L;\n                            _headers._CacheControl = value;\n                            return;\n                        }\n                    \n                        if (\"Content-Range\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 131072L;\n                            _headers._ContentRange = value;\n                            return;\n                        }\n                    \n                        if (\"Last-Modified\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 524288L;\n                            _headers._LastModified = value;\n                            return;\n                        }\n                    \n                        if (\"Accept-Ranges\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 1048576L;\n                            _headers._AcceptRanges = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 10:\n                    {\n                        if (\"Connection\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 2L;\n                            _headers._Connection = value;\n                            _headers._rawConnection = null;\n                            return;\n                        }\n                    \n                        if (\"Keep-Alive\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 8L;\n                            _headers._KeepAlive = value;\n                            return;\n                        }\n                    \n                        if (\"Set-Cookie\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 134217728L;\n                            _headers._SetCookie = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 4:\n                    {\n                        if (\"Date\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 4L;\n                            _headers._Date = value;\n                            _headers._rawDate = null;\n                            return;\n                        }\n                    \n                        if (\"ETag\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 4194304L;\n                            _headers._ETag = value;\n                            return;\n                        }\n                    \n                        if (\"Vary\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 268435456L;\n                            _headers._Vary = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 6:\n                    {\n                        if (\"Pragma\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 16L;\n                            _headers._Pragma = value;\n                            return;\n                        }\n                    \n                        if (\"Server\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 67108864L;\n                            _headers._Server = value;\n                            _headers._rawServer = null;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 7:\n                    {\n                        if (\"Trailer\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 32L;\n                            _headers._Trailer = value;\n                            return;\n                        }\n                    \n                        if (\"Upgrade\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 128L;\n                            _headers._Upgrade = value;\n                            return;\n                        }\n                    \n                        if (\"Warning\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 512L;\n                            _headers._Warning = value;\n                            return;\n                        }\n                    \n                        if (\"Expires\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 262144L;\n                            _headers._Expires = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 17:\n                    {\n                        if (\"Transfer-Encoding\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 64L;\n                            _headers._TransferEncoding = value;\n                            _headers._rawTransferEncoding = null;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 3:\n                    {\n                        if (\"Via\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 256L;\n                            _headers._Via = value;\n                            return;\n                        }\n                    \n                        if (\"Age\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 2097152L;\n                            _headers._Age = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 5:\n                    {\n                        if (\"Allow\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 1024L;\n                            _headers._Allow = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 14:\n                    {\n                        if (\"Content-Length\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _contentLength = ParseContentLength(value);\n                            _bits |= 2048L;\n                            _headers._ContentLength = value;\n                            _headers._rawContentLength = null;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 12:\n                    {\n                        if (\"Content-Type\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 4096L;\n                            _headers._ContentType = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 16:\n                    {\n                        if (\"Content-Encoding\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 8192L;\n                            _headers._ContentEncoding = value;\n                            return;\n                        }\n                    \n                        if (\"Content-Language\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 16384L;\n                            _headers._ContentLanguage = value;\n                            return;\n                        }\n                    \n                        if (\"Content-Location\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 32768L;\n                            _headers._ContentLocation = value;\n                            return;\n                        }\n                    \n                        if (\"WWW-Authenticate\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 536870912L;\n                            _headers._WWWAuthenticate = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 11:\n                    {\n                        if (\"Content-MD5\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 65536L;\n                            _headers._ContentMD5 = value;\n                            return;\n                        }\n                    \n                        if (\"Retry-After\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 33554432L;\n                            _headers._RetryAfter = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 8:\n                    {\n                        if (\"Location\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 8388608L;\n                            _headers._Location = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 18:\n                    {\n                        if (\"Proxy-Authenticate\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 16777216L;\n                            _headers._ProxyAuthenticate = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 32:\n                    {\n                        if (\"Access-Control-Allow-Credentials\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 1073741824L;\n                            _headers._AccessControlAllowCredentials = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 28:\n                    {\n                        if (\"Access-Control-Allow-Headers\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 2147483648L;\n                            _headers._AccessControlAllowHeaders = value;\n                            return;\n                        }\n                    \n                        if (\"Access-Control-Allow-Methods\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 4294967296L;\n                            _headers._AccessControlAllowMethods = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 27:\n                    {\n                        if (\"Access-Control-Allow-Origin\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 8589934592L;\n                            _headers._AccessControlAllowOrigin = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 29:\n                    {\n                        if (\"Access-Control-Expose-Headers\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 17179869184L;\n                            _headers._AccessControlExposeHeaders = value;\n                            return;\n                        }\n                    }\n                    break;\n\n                case 22:\n                    {\n                        if (\"Access-Control-Max-Age\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            _bits |= 34359738368L;\n                            _headers._AccessControlMaxAge = value;\n                            return;\n                        }\n                    }\n                    break;\n}\n            ValidateHeaderCharacters(key);\n            Unknown[key] = value;\n        }\n        protected override void AddValueFast(string key, StringValues value)\n        {\n            ValidateHeaderCharacters(value);\n            switch (key.Length)\n            {\n                case 13:\n                    {\n                        if (\"Cache-Control\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 1L;\n                            _headers._CacheControl = value;\n                            return;\n                        }\n                    \n                        if (\"Content-Range\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 131072L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 131072L;\n                            _headers._ContentRange = value;\n                            return;\n                        }\n                    \n                        if (\"Last-Modified\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 524288L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 524288L;\n                            _headers._LastModified = value;\n                            return;\n                        }\n                    \n                        if (\"Accept-Ranges\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1048576L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 1048576L;\n                            _headers._AcceptRanges = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 10:\n                    {\n                        if (\"Connection\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 2L;\n                            _headers._Connection = value;\n                            _headers._rawConnection = null;\n                            return;\n                        }\n                    \n                        if (\"Keep-Alive\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 8L;\n                            _headers._KeepAlive = value;\n                            return;\n                        }\n                    \n                        if (\"Set-Cookie\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 134217728L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 134217728L;\n                            _headers._SetCookie = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 4:\n                    {\n                        if (\"Date\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 4L;\n                            _headers._Date = value;\n                            _headers._rawDate = null;\n                            return;\n                        }\n                    \n                        if (\"ETag\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4194304L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 4194304L;\n                            _headers._ETag = value;\n                            return;\n                        }\n                    \n                        if (\"Vary\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 268435456L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 268435456L;\n                            _headers._Vary = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 6:\n                    {\n                        if (\"Pragma\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 16L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 16L;\n                            _headers._Pragma = value;\n                            return;\n                        }\n                    \n                        if (\"Server\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 67108864L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 67108864L;\n                            _headers._Server = value;\n                            _headers._rawServer = null;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 7:\n                    {\n                        if (\"Trailer\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 32L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 32L;\n                            _headers._Trailer = value;\n                            return;\n                        }\n                    \n                        if (\"Upgrade\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 128L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 128L;\n                            _headers._Upgrade = value;\n                            return;\n                        }\n                    \n                        if (\"Warning\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 512L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 512L;\n                            _headers._Warning = value;\n                            return;\n                        }\n                    \n                        if (\"Expires\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 262144L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 262144L;\n                            _headers._Expires = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 17:\n                    {\n                        if (\"Transfer-Encoding\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 64L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 64L;\n                            _headers._TransferEncoding = value;\n                            _headers._rawTransferEncoding = null;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 3:\n                    {\n                        if (\"Via\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 256L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 256L;\n                            _headers._Via = value;\n                            return;\n                        }\n                    \n                        if (\"Age\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2097152L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 2097152L;\n                            _headers._Age = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 5:\n                    {\n                        if (\"Allow\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1024L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 1024L;\n                            _headers._Allow = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 14:\n                    {\n                        if (\"Content-Length\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2048L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _contentLength = ParseContentLength(value);\n                            _bits |= 2048L;\n                            _headers._ContentLength = value;\n                            _headers._rawContentLength = null;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 12:\n                    {\n                        if (\"Content-Type\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4096L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 4096L;\n                            _headers._ContentType = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 16:\n                    {\n                        if (\"Content-Encoding\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8192L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 8192L;\n                            _headers._ContentEncoding = value;\n                            return;\n                        }\n                    \n                        if (\"Content-Language\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 16384L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 16384L;\n                            _headers._ContentLanguage = value;\n                            return;\n                        }\n                    \n                        if (\"Content-Location\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 32768L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 32768L;\n                            _headers._ContentLocation = value;\n                            return;\n                        }\n                    \n                        if (\"WWW-Authenticate\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 536870912L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 536870912L;\n                            _headers._WWWAuthenticate = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 11:\n                    {\n                        if (\"Content-MD5\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 65536L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 65536L;\n                            _headers._ContentMD5 = value;\n                            return;\n                        }\n                    \n                        if (\"Retry-After\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 33554432L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 33554432L;\n                            _headers._RetryAfter = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 8:\n                    {\n                        if (\"Location\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8388608L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 8388608L;\n                            _headers._Location = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 18:\n                    {\n                        if (\"Proxy-Authenticate\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 16777216L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 16777216L;\n                            _headers._ProxyAuthenticate = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 32:\n                    {\n                        if (\"Access-Control-Allow-Credentials\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1073741824L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 1073741824L;\n                            _headers._AccessControlAllowCredentials = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 28:\n                    {\n                        if (\"Access-Control-Allow-Headers\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2147483648L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 2147483648L;\n                            _headers._AccessControlAllowHeaders = value;\n                            return;\n                        }\n                    \n                        if (\"Access-Control-Allow-Methods\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4294967296L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 4294967296L;\n                            _headers._AccessControlAllowMethods = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 27:\n                    {\n                        if (\"Access-Control-Allow-Origin\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8589934592L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 8589934592L;\n                            _headers._AccessControlAllowOrigin = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 29:\n                    {\n                        if (\"Access-Control-Expose-Headers\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 17179869184L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 17179869184L;\n                            _headers._AccessControlExposeHeaders = value;\n                            return;\n                        }\n                    }\n                    break;\n            \n                case 22:\n                    {\n                        if (\"Access-Control-Max-Age\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 34359738368L) != 0))\n                            {\n                                ThrowDuplicateKeyException();\n                            }\n                            _bits |= 34359738368L;\n                            _headers._AccessControlMaxAge = value;\n                            return;\n                        }\n                    }\n                    break;\n            }\n            ValidateHeaderCharacters(key);\n            Unknown.Add(key, value);\n        }\n        protected override bool RemoveFast(string key)\n        {\n            switch (key.Length)\n            {\n                case 13:\n                    {\n                        if (\"Cache-Control\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1L) != 0))\n                            {\n                                _bits &= ~1L;\n                                _headers._CacheControl = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Content-Range\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 131072L) != 0))\n                            {\n                                _bits &= ~131072L;\n                                _headers._ContentRange = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Last-Modified\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 524288L) != 0))\n                            {\n                                _bits &= ~524288L;\n                                _headers._LastModified = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Accept-Ranges\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1048576L) != 0))\n                            {\n                                _bits &= ~1048576L;\n                                _headers._AcceptRanges = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 10:\n                    {\n                        if (\"Connection\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2L) != 0))\n                            {\n                                _bits &= ~2L;\n                                _headers._Connection = StringValues.Empty;\n                                _headers._rawConnection = null;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Keep-Alive\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8L) != 0))\n                            {\n                                _bits &= ~8L;\n                                _headers._KeepAlive = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Set-Cookie\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 134217728L) != 0))\n                            {\n                                _bits &= ~134217728L;\n                                _headers._SetCookie = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 4:\n                    {\n                        if (\"Date\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4L) != 0))\n                            {\n                                _bits &= ~4L;\n                                _headers._Date = StringValues.Empty;\n                                _headers._rawDate = null;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"ETag\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4194304L) != 0))\n                            {\n                                _bits &= ~4194304L;\n                                _headers._ETag = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Vary\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 268435456L) != 0))\n                            {\n                                _bits &= ~268435456L;\n                                _headers._Vary = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 6:\n                    {\n                        if (\"Pragma\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 16L) != 0))\n                            {\n                                _bits &= ~16L;\n                                _headers._Pragma = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Server\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 67108864L) != 0))\n                            {\n                                _bits &= ~67108864L;\n                                _headers._Server = StringValues.Empty;\n                                _headers._rawServer = null;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 7:\n                    {\n                        if (\"Trailer\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 32L) != 0))\n                            {\n                                _bits &= ~32L;\n                                _headers._Trailer = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Upgrade\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 128L) != 0))\n                            {\n                                _bits &= ~128L;\n                                _headers._Upgrade = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Warning\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 512L) != 0))\n                            {\n                                _bits &= ~512L;\n                                _headers._Warning = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Expires\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 262144L) != 0))\n                            {\n                                _bits &= ~262144L;\n                                _headers._Expires = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 17:\n                    {\n                        if (\"Transfer-Encoding\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 64L) != 0))\n                            {\n                                _bits &= ~64L;\n                                _headers._TransferEncoding = StringValues.Empty;\n                                _headers._rawTransferEncoding = null;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 3:\n                    {\n                        if (\"Via\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 256L) != 0))\n                            {\n                                _bits &= ~256L;\n                                _headers._Via = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Age\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2097152L) != 0))\n                            {\n                                _bits &= ~2097152L;\n                                _headers._Age = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 5:\n                    {\n                        if (\"Allow\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1024L) != 0))\n                            {\n                                _bits &= ~1024L;\n                                _headers._Allow = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 14:\n                    {\n                        if (\"Content-Length\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2048L) != 0))\n                            {\n                                _contentLength = null;\n                                _bits &= ~2048L;\n                                _headers._ContentLength = StringValues.Empty;\n                                _headers._rawContentLength = null;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 12:\n                    {\n                        if (\"Content-Type\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4096L) != 0))\n                            {\n                                _bits &= ~4096L;\n                                _headers._ContentType = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 16:\n                    {\n                        if (\"Content-Encoding\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8192L) != 0))\n                            {\n                                _bits &= ~8192L;\n                                _headers._ContentEncoding = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Content-Language\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 16384L) != 0))\n                            {\n                                _bits &= ~16384L;\n                                _headers._ContentLanguage = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Content-Location\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 32768L) != 0))\n                            {\n                                _bits &= ~32768L;\n                                _headers._ContentLocation = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"WWW-Authenticate\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 536870912L) != 0))\n                            {\n                                _bits &= ~536870912L;\n                                _headers._WWWAuthenticate = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 11:\n                    {\n                        if (\"Content-MD5\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 65536L) != 0))\n                            {\n                                _bits &= ~65536L;\n                                _headers._ContentMD5 = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Retry-After\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 33554432L) != 0))\n                            {\n                                _bits &= ~33554432L;\n                                _headers._RetryAfter = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 8:\n                    {\n                        if (\"Location\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8388608L) != 0))\n                            {\n                                _bits &= ~8388608L;\n                                _headers._Location = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 18:\n                    {\n                        if (\"Proxy-Authenticate\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 16777216L) != 0))\n                            {\n                                _bits &= ~16777216L;\n                                _headers._ProxyAuthenticate = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 32:\n                    {\n                        if (\"Access-Control-Allow-Credentials\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 1073741824L) != 0))\n                            {\n                                _bits &= ~1073741824L;\n                                _headers._AccessControlAllowCredentials = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 28:\n                    {\n                        if (\"Access-Control-Allow-Headers\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 2147483648L) != 0))\n                            {\n                                _bits &= ~2147483648L;\n                                _headers._AccessControlAllowHeaders = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    \n                        if (\"Access-Control-Allow-Methods\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 4294967296L) != 0))\n                            {\n                                _bits &= ~4294967296L;\n                                _headers._AccessControlAllowMethods = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 27:\n                    {\n                        if (\"Access-Control-Allow-Origin\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 8589934592L) != 0))\n                            {\n                                _bits &= ~8589934592L;\n                                _headers._AccessControlAllowOrigin = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 29:\n                    {\n                        if (\"Access-Control-Expose-Headers\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 17179869184L) != 0))\n                            {\n                                _bits &= ~17179869184L;\n                                _headers._AccessControlExposeHeaders = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            \n                case 22:\n                    {\n                        if (\"Access-Control-Max-Age\".Equals(key, StringComparison.OrdinalIgnoreCase))\n                        {\n                            if (((_bits & 34359738368L) != 0))\n                            {\n                                _bits &= ~34359738368L;\n                                _headers._AccessControlMaxAge = StringValues.Empty;\n                                return true;\n                            }\n                            else\n                            {\n                                return false;\n                            }\n                        }\n                    }\n                    break;\n            }\n            return MaybeUnknown?.Remove(key) ?? false;\n        }\n        protected override void ClearFast()\n        {            \n            MaybeUnknown?.Clear();\n            _contentLength = null;\n            if(FrameHeaders.BitCount(_bits) > 12)\n            {\n                _headers = default(HeaderReferences);\n                _bits = 0;\n                return;\n            }\n            \n            if (((_bits & 2L) != 0))\n            {\n                _headers._Connection = default(StringValues);\n                _bits &= ~2L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 4L) != 0))\n            {\n                _headers._Date = default(StringValues);\n                _bits &= ~4L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 2048L) != 0))\n            {\n                _headers._ContentLength = default(StringValues);\n                _bits &= ~2048L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 4096L) != 0))\n            {\n                _headers._ContentType = default(StringValues);\n                _bits &= ~4096L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 67108864L) != 0))\n            {\n                _headers._Server = default(StringValues);\n                _bits &= ~67108864L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 1L) != 0))\n            {\n                _headers._CacheControl = default(StringValues);\n                _bits &= ~1L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 8L) != 0))\n            {\n                _headers._KeepAlive = default(StringValues);\n                _bits &= ~8L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 16L) != 0))\n            {\n                _headers._Pragma = default(StringValues);\n                _bits &= ~16L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 32L) != 0))\n            {\n                _headers._Trailer = default(StringValues);\n                _bits &= ~32L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 64L) != 0))\n            {\n                _headers._TransferEncoding = default(StringValues);\n                _bits &= ~64L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 128L) != 0))\n            {\n                _headers._Upgrade = default(StringValues);\n                _bits &= ~128L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 256L) != 0))\n            {\n                _headers._Via = default(StringValues);\n                _bits &= ~256L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 512L) != 0))\n            {\n                _headers._Warning = default(StringValues);\n                _bits &= ~512L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 1024L) != 0))\n            {\n                _headers._Allow = default(StringValues);\n                _bits &= ~1024L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 8192L) != 0))\n            {\n                _headers._ContentEncoding = default(StringValues);\n                _bits &= ~8192L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 16384L) != 0))\n            {\n                _headers._ContentLanguage = default(StringValues);\n                _bits &= ~16384L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 32768L) != 0))\n            {\n                _headers._ContentLocation = default(StringValues);\n                _bits &= ~32768L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 65536L) != 0))\n            {\n                _headers._ContentMD5 = default(StringValues);\n                _bits &= ~65536L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 131072L) != 0))\n            {\n                _headers._ContentRange = default(StringValues);\n                _bits &= ~131072L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 262144L) != 0))\n            {\n                _headers._Expires = default(StringValues);\n                _bits &= ~262144L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 524288L) != 0))\n            {\n                _headers._LastModified = default(StringValues);\n                _bits &= ~524288L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 1048576L) != 0))\n            {\n                _headers._AcceptRanges = default(StringValues);\n                _bits &= ~1048576L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 2097152L) != 0))\n            {\n                _headers._Age = default(StringValues);\n                _bits &= ~2097152L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 4194304L) != 0))\n            {\n                _headers._ETag = default(StringValues);\n                _bits &= ~4194304L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 8388608L) != 0))\n            {\n                _headers._Location = default(StringValues);\n                _bits &= ~8388608L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 16777216L) != 0))\n            {\n                _headers._ProxyAuthenticate = default(StringValues);\n                _bits &= ~16777216L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 33554432L) != 0))\n            {\n                _headers._RetryAfter = default(StringValues);\n                _bits &= ~33554432L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 134217728L) != 0))\n            {\n                _headers._SetCookie = default(StringValues);\n                _bits &= ~134217728L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 268435456L) != 0))\n            {\n                _headers._Vary = default(StringValues);\n                _bits &= ~268435456L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 536870912L) != 0))\n            {\n                _headers._WWWAuthenticate = default(StringValues);\n                _bits &= ~536870912L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 1073741824L) != 0))\n            {\n                _headers._AccessControlAllowCredentials = default(StringValues);\n                _bits &= ~1073741824L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 2147483648L) != 0))\n            {\n                _headers._AccessControlAllowHeaders = default(StringValues);\n                _bits &= ~2147483648L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 4294967296L) != 0))\n            {\n                _headers._AccessControlAllowMethods = default(StringValues);\n                _bits &= ~4294967296L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 8589934592L) != 0))\n            {\n                _headers._AccessControlAllowOrigin = default(StringValues);\n                _bits &= ~8589934592L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 17179869184L) != 0))\n            {\n                _headers._AccessControlExposeHeaders = default(StringValues);\n                _bits &= ~17179869184L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n            if (((_bits & 34359738368L) != 0))\n            {\n                _headers._AccessControlMaxAge = default(StringValues);\n                _bits &= ~34359738368L;\n                if(_bits == 0)\n                {\n                    return;\n                }\n            }\n            \n        }\n\n        protected override void CopyToFast(KeyValuePair<string, StringValues>[] array, int arrayIndex)\n        {\n            if (arrayIndex < 0)\n            {\n                ThrowArgumentException();\n            }\n            \n                if (((_bits & 1L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Cache-Control\", _headers._CacheControl);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 2L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Connection\", _headers._Connection);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 4L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Date\", _headers._Date);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 8L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Keep-Alive\", _headers._KeepAlive);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 16L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Pragma\", _headers._Pragma);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 32L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Trailer\", _headers._Trailer);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 64L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Transfer-Encoding\", _headers._TransferEncoding);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 128L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Upgrade\", _headers._Upgrade);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 256L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Via\", _headers._Via);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 512L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Warning\", _headers._Warning);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 1024L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Allow\", _headers._Allow);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 2048L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Content-Length\", _headers._ContentLength);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 4096L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Content-Type\", _headers._ContentType);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 8192L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Content-Encoding\", _headers._ContentEncoding);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 16384L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Content-Language\", _headers._ContentLanguage);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 32768L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Content-Location\", _headers._ContentLocation);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 65536L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Content-MD5\", _headers._ContentMD5);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 131072L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Content-Range\", _headers._ContentRange);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 262144L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Expires\", _headers._Expires);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 524288L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Last-Modified\", _headers._LastModified);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 1048576L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Accept-Ranges\", _headers._AcceptRanges);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 2097152L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Age\", _headers._Age);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 4194304L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"ETag\", _headers._ETag);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 8388608L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Location\", _headers._Location);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 16777216L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Proxy-Authenticate\", _headers._ProxyAuthenticate);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 33554432L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Retry-After\", _headers._RetryAfter);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 67108864L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Server\", _headers._Server);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 134217728L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Set-Cookie\", _headers._SetCookie);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 268435456L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Vary\", _headers._Vary);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 536870912L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"WWW-Authenticate\", _headers._WWWAuthenticate);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 1073741824L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Access-Control-Allow-Credentials\", _headers._AccessControlAllowCredentials);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 2147483648L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Access-Control-Allow-Headers\", _headers._AccessControlAllowHeaders);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 4294967296L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Access-Control-Allow-Methods\", _headers._AccessControlAllowMethods);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 8589934592L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Access-Control-Allow-Origin\", _headers._AccessControlAllowOrigin);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 17179869184L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Access-Control-Expose-Headers\", _headers._AccessControlExposeHeaders);\n                    ++arrayIndex;\n                }\n            \n                if (((_bits & 34359738368L) != 0))\n                {\n                    if (arrayIndex == array.Length)\n                    {\n                        ThrowArgumentException();\n                    }\n\n                    array[arrayIndex] = new KeyValuePair<string, StringValues>(\"Access-Control-Max-Age\", _headers._AccessControlMaxAge);\n                    ++arrayIndex;\n                }\n            \n            ((ICollection<KeyValuePair<string, StringValues>>)MaybeUnknown)?.CopyTo(array, arrayIndex);\n        }\n        \n        protected void CopyToFast(ref MemoryPoolIterator output)\n        {\n            var tempBits = _bits;\n            \n                if (((_bits & 2L) != 0))\n                { \n                    if (_headers._rawConnection != null)\n                    {\n                        output.CopyFrom(_headers._rawConnection, 0, _headers._rawConnection.Length);\n                    }\n                    else \n                    {\n                        var valueCount = _headers._Connection.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._Connection[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 17, 14);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~2L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 4L) != 0))\n                { \n                    if (_headers._rawDate != null)\n                    {\n                        output.CopyFrom(_headers._rawDate, 0, _headers._rawDate.Length);\n                    }\n                    else \n                    {\n                        var valueCount = _headers._Date.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._Date[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 31, 8);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~4L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 2048L) != 0))\n                { \n                    if (_headers._rawContentLength != null)\n                    {\n                        output.CopyFrom(_headers._rawContentLength, 0, _headers._rawContentLength.Length);\n                    }\n                    else \n                    {\n                        var valueCount = _headers._ContentLength.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._ContentLength[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 133, 18);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~2048L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 4096L) != 0))\n                { \n                    {\n                        var valueCount = _headers._ContentType.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._ContentType[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 151, 16);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~4096L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 67108864L) != 0))\n                { \n                    if (_headers._rawServer != null)\n                    {\n                        output.CopyFrom(_headers._rawServer, 0, _headers._rawServer.Length);\n                    }\n                    else \n                    {\n                        var valueCount = _headers._Server.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._Server[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 368, 10);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~67108864L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 1L) != 0))\n                { \n                    {\n                        var valueCount = _headers._CacheControl.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._CacheControl[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 0, 17);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~1L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 8L) != 0))\n                { \n                    {\n                        var valueCount = _headers._KeepAlive.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._KeepAlive[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 39, 14);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~8L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 16L) != 0))\n                { \n                    {\n                        var valueCount = _headers._Pragma.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._Pragma[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 53, 10);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~16L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 32L) != 0))\n                { \n                    {\n                        var valueCount = _headers._Trailer.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._Trailer[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 63, 11);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~32L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 64L) != 0))\n                { \n                    if (_headers._rawTransferEncoding != null)\n                    {\n                        output.CopyFrom(_headers._rawTransferEncoding, 0, _headers._rawTransferEncoding.Length);\n                    }\n                    else \n                    {\n                        var valueCount = _headers._TransferEncoding.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._TransferEncoding[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 74, 21);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~64L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 128L) != 0))\n                { \n                    {\n                        var valueCount = _headers._Upgrade.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._Upgrade[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 95, 11);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~128L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 256L) != 0))\n                { \n                    {\n                        var valueCount = _headers._Via.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._Via[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 106, 7);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~256L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 512L) != 0))\n                { \n                    {\n                        var valueCount = _headers._Warning.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._Warning[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 113, 11);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~512L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 1024L) != 0))\n                { \n                    {\n                        var valueCount = _headers._Allow.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._Allow[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 124, 9);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~1024L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 8192L) != 0))\n                { \n                    {\n                        var valueCount = _headers._ContentEncoding.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._ContentEncoding[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 167, 20);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~8192L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 16384L) != 0))\n                { \n                    {\n                        var valueCount = _headers._ContentLanguage.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._ContentLanguage[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 187, 20);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~16384L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 32768L) != 0))\n                { \n                    {\n                        var valueCount = _headers._ContentLocation.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._ContentLocation[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 207, 20);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~32768L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 65536L) != 0))\n                { \n                    {\n                        var valueCount = _headers._ContentMD5.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._ContentMD5[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 227, 15);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~65536L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 131072L) != 0))\n                { \n                    {\n                        var valueCount = _headers._ContentRange.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._ContentRange[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 242, 17);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~131072L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 262144L) != 0))\n                { \n                    {\n                        var valueCount = _headers._Expires.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._Expires[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 259, 11);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~262144L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 524288L) != 0))\n                { \n                    {\n                        var valueCount = _headers._LastModified.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._LastModified[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 270, 17);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~524288L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 1048576L) != 0))\n                { \n                    {\n                        var valueCount = _headers._AcceptRanges.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._AcceptRanges[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 287, 17);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~1048576L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 2097152L) != 0))\n                { \n                    {\n                        var valueCount = _headers._Age.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._Age[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 304, 7);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~2097152L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 4194304L) != 0))\n                { \n                    {\n                        var valueCount = _headers._ETag.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._ETag[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 311, 8);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~4194304L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 8388608L) != 0))\n                { \n                    {\n                        var valueCount = _headers._Location.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._Location[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 319, 12);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~8388608L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 16777216L) != 0))\n                { \n                    {\n                        var valueCount = _headers._ProxyAuthenticate.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._ProxyAuthenticate[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 331, 22);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~16777216L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 33554432L) != 0))\n                { \n                    {\n                        var valueCount = _headers._RetryAfter.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._RetryAfter[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 353, 15);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~33554432L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 134217728L) != 0))\n                { \n                    {\n                        var valueCount = _headers._SetCookie.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._SetCookie[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 378, 14);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~134217728L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 268435456L) != 0))\n                { \n                    {\n                        var valueCount = _headers._Vary.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._Vary[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 392, 8);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~268435456L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 536870912L) != 0))\n                { \n                    {\n                        var valueCount = _headers._WWWAuthenticate.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._WWWAuthenticate[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 400, 20);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~536870912L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 1073741824L) != 0))\n                { \n                    {\n                        var valueCount = _headers._AccessControlAllowCredentials.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._AccessControlAllowCredentials[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 420, 36);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~1073741824L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 2147483648L) != 0))\n                { \n                    {\n                        var valueCount = _headers._AccessControlAllowHeaders.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._AccessControlAllowHeaders[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 456, 32);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~2147483648L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 4294967296L) != 0))\n                { \n                    {\n                        var valueCount = _headers._AccessControlAllowMethods.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._AccessControlAllowMethods[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 488, 32);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~4294967296L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 8589934592L) != 0))\n                { \n                    {\n                        var valueCount = _headers._AccessControlAllowOrigin.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._AccessControlAllowOrigin[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 520, 31);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~8589934592L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 17179869184L) != 0))\n                { \n                    {\n                        var valueCount = _headers._AccessControlExposeHeaders.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._AccessControlExposeHeaders[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 551, 33);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~17179869184L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n                if (((_bits & 34359738368L) != 0))\n                { \n                    {\n                        var valueCount = _headers._AccessControlMaxAge.Count; \n                        for (var i = 0; i < valueCount; i++) \n                        {\n                            var value = _headers._AccessControlMaxAge[i]; \n                            if (value != null)\n                            {\n                                output.CopyFrom(_headerBytes, 584, 26);\n                                output.CopyFromAscii(value);\n                            }\n                        }\n                    }\n\n                    tempBits &= ~34359738368L;\n                    if(tempBits == 0)\n                    {\n                        return;\n                    }\n                }\n            \n        }\n        \n        \n        \n        private struct HeaderReferences\n        {\n            public StringValues _CacheControl;\n            public StringValues _Connection;\n            public StringValues _Date;\n            public StringValues _KeepAlive;\n            public StringValues _Pragma;\n            public StringValues _Trailer;\n            public StringValues _TransferEncoding;\n            public StringValues _Upgrade;\n            public StringValues _Via;\n            public StringValues _Warning;\n            public StringValues _Allow;\n            public StringValues _ContentLength;\n            public StringValues _ContentType;\n            public StringValues _ContentEncoding;\n            public StringValues _ContentLanguage;\n            public StringValues _ContentLocation;\n            public StringValues _ContentMD5;\n            public StringValues _ContentRange;\n            public StringValues _Expires;\n            public StringValues _LastModified;\n            public StringValues _AcceptRanges;\n            public StringValues _Age;\n            public StringValues _ETag;\n            public StringValues _Location;\n            public StringValues _ProxyAuthenticate;\n            public StringValues _RetryAfter;\n            public StringValues _Server;\n            public StringValues _SetCookie;\n            public StringValues _Vary;\n            public StringValues _WWWAuthenticate;\n            public StringValues _AccessControlAllowCredentials;\n            public StringValues _AccessControlAllowHeaders;\n            public StringValues _AccessControlAllowMethods;\n            public StringValues _AccessControlAllowOrigin;\n            public StringValues _AccessControlExposeHeaders;\n            public StringValues _AccessControlMaxAge;\n            \n            public byte[] _rawConnection;\n            public byte[] _rawDate;\n            public byte[] _rawTransferEncoding;\n            public byte[] _rawContentLength;\n            public byte[] _rawServer;\n        }\n\n        public partial struct Enumerator\n        {\n            public bool MoveNext()\n            {\n                switch (_state)\n                {\n                    \n                        case 0:\n                            goto state0;\n                    \n                        case 1:\n                            goto state1;\n                    \n                        case 2:\n                            goto state2;\n                    \n                        case 3:\n                            goto state3;\n                    \n                        case 4:\n                            goto state4;\n                    \n                        case 5:\n                            goto state5;\n                    \n                        case 6:\n                            goto state6;\n                    \n                        case 7:\n                            goto state7;\n                    \n                        case 8:\n                            goto state8;\n                    \n                        case 9:\n                            goto state9;\n                    \n                        case 10:\n                            goto state10;\n                    \n                        case 11:\n                            goto state11;\n                    \n                        case 12:\n                            goto state12;\n                    \n                        case 13:\n                            goto state13;\n                    \n                        case 14:\n                            goto state14;\n                    \n                        case 15:\n                            goto state15;\n                    \n                        case 16:\n                            goto state16;\n                    \n                        case 17:\n                            goto state17;\n                    \n                        case 18:\n                            goto state18;\n                    \n                        case 19:\n                            goto state19;\n                    \n                        case 20:\n                            goto state20;\n                    \n                        case 21:\n                            goto state21;\n                    \n                        case 22:\n                            goto state22;\n                    \n                        case 23:\n                            goto state23;\n                    \n                        case 24:\n                            goto state24;\n                    \n                        case 25:\n                            goto state25;\n                    \n                        case 26:\n                            goto state26;\n                    \n                        case 27:\n                            goto state27;\n                    \n                        case 28:\n                            goto state28;\n                    \n                        case 29:\n                            goto state29;\n                    \n                        case 30:\n                            goto state30;\n                    \n                        case 31:\n                            goto state31;\n                    \n                        case 32:\n                            goto state32;\n                    \n                        case 33:\n                            goto state33;\n                    \n                        case 34:\n                            goto state34;\n                    \n                        case 35:\n                            goto state35;\n                    \n                    default:\n                        goto state_default;\n                }\n                \n                state0:\n                    if (((_bits & 1L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Cache-Control\", _collection._headers._CacheControl);\n                        _state = 1;\n                        return true;\n                    }\n                \n                state1:\n                    if (((_bits & 2L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Connection\", _collection._headers._Connection);\n                        _state = 2;\n                        return true;\n                    }\n                \n                state2:\n                    if (((_bits & 4L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Date\", _collection._headers._Date);\n                        _state = 3;\n                        return true;\n                    }\n                \n                state3:\n                    if (((_bits & 8L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Keep-Alive\", _collection._headers._KeepAlive);\n                        _state = 4;\n                        return true;\n                    }\n                \n                state4:\n                    if (((_bits & 16L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Pragma\", _collection._headers._Pragma);\n                        _state = 5;\n                        return true;\n                    }\n                \n                state5:\n                    if (((_bits & 32L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Trailer\", _collection._headers._Trailer);\n                        _state = 6;\n                        return true;\n                    }\n                \n                state6:\n                    if (((_bits & 64L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Transfer-Encoding\", _collection._headers._TransferEncoding);\n                        _state = 7;\n                        return true;\n                    }\n                \n                state7:\n                    if (((_bits & 128L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Upgrade\", _collection._headers._Upgrade);\n                        _state = 8;\n                        return true;\n                    }\n                \n                state8:\n                    if (((_bits & 256L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Via\", _collection._headers._Via);\n                        _state = 9;\n                        return true;\n                    }\n                \n                state9:\n                    if (((_bits & 512L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Warning\", _collection._headers._Warning);\n                        _state = 10;\n                        return true;\n                    }\n                \n                state10:\n                    if (((_bits & 1024L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Allow\", _collection._headers._Allow);\n                        _state = 11;\n                        return true;\n                    }\n                \n                state11:\n                    if (((_bits & 2048L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Content-Length\", _collection._headers._ContentLength);\n                        _state = 12;\n                        return true;\n                    }\n                \n                state12:\n                    if (((_bits & 4096L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Content-Type\", _collection._headers._ContentType);\n                        _state = 13;\n                        return true;\n                    }\n                \n                state13:\n                    if (((_bits & 8192L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Content-Encoding\", _collection._headers._ContentEncoding);\n                        _state = 14;\n                        return true;\n                    }\n                \n                state14:\n                    if (((_bits & 16384L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Content-Language\", _collection._headers._ContentLanguage);\n                        _state = 15;\n                        return true;\n                    }\n                \n                state15:\n                    if (((_bits & 32768L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Content-Location\", _collection._headers._ContentLocation);\n                        _state = 16;\n                        return true;\n                    }\n                \n                state16:\n                    if (((_bits & 65536L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Content-MD5\", _collection._headers._ContentMD5);\n                        _state = 17;\n                        return true;\n                    }\n                \n                state17:\n                    if (((_bits & 131072L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Content-Range\", _collection._headers._ContentRange);\n                        _state = 18;\n                        return true;\n                    }\n                \n                state18:\n                    if (((_bits & 262144L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Expires\", _collection._headers._Expires);\n                        _state = 19;\n                        return true;\n                    }\n                \n                state19:\n                    if (((_bits & 524288L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Last-Modified\", _collection._headers._LastModified);\n                        _state = 20;\n                        return true;\n                    }\n                \n                state20:\n                    if (((_bits & 1048576L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Accept-Ranges\", _collection._headers._AcceptRanges);\n                        _state = 21;\n                        return true;\n                    }\n                \n                state21:\n                    if (((_bits & 2097152L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Age\", _collection._headers._Age);\n                        _state = 22;\n                        return true;\n                    }\n                \n                state22:\n                    if (((_bits & 4194304L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"ETag\", _collection._headers._ETag);\n                        _state = 23;\n                        return true;\n                    }\n                \n                state23:\n                    if (((_bits & 8388608L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Location\", _collection._headers._Location);\n                        _state = 24;\n                        return true;\n                    }\n                \n                state24:\n                    if (((_bits & 16777216L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Proxy-Authenticate\", _collection._headers._ProxyAuthenticate);\n                        _state = 25;\n                        return true;\n                    }\n                \n                state25:\n                    if (((_bits & 33554432L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Retry-After\", _collection._headers._RetryAfter);\n                        _state = 26;\n                        return true;\n                    }\n                \n                state26:\n                    if (((_bits & 67108864L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Server\", _collection._headers._Server);\n                        _state = 27;\n                        return true;\n                    }\n                \n                state27:\n                    if (((_bits & 134217728L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Set-Cookie\", _collection._headers._SetCookie);\n                        _state = 28;\n                        return true;\n                    }\n                \n                state28:\n                    if (((_bits & 268435456L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Vary\", _collection._headers._Vary);\n                        _state = 29;\n                        return true;\n                    }\n                \n                state29:\n                    if (((_bits & 536870912L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"WWW-Authenticate\", _collection._headers._WWWAuthenticate);\n                        _state = 30;\n                        return true;\n                    }\n                \n                state30:\n                    if (((_bits & 1073741824L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Access-Control-Allow-Credentials\", _collection._headers._AccessControlAllowCredentials);\n                        _state = 31;\n                        return true;\n                    }\n                \n                state31:\n                    if (((_bits & 2147483648L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Access-Control-Allow-Headers\", _collection._headers._AccessControlAllowHeaders);\n                        _state = 32;\n                        return true;\n                    }\n                \n                state32:\n                    if (((_bits & 4294967296L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Access-Control-Allow-Methods\", _collection._headers._AccessControlAllowMethods);\n                        _state = 33;\n                        return true;\n                    }\n                \n                state33:\n                    if (((_bits & 8589934592L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Access-Control-Allow-Origin\", _collection._headers._AccessControlAllowOrigin);\n                        _state = 34;\n                        return true;\n                    }\n                \n                state34:\n                    if (((_bits & 17179869184L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Access-Control-Expose-Headers\", _collection._headers._AccessControlExposeHeaders);\n                        _state = 35;\n                        return true;\n                    }\n                \n                state35:\n                    if (((_bits & 34359738368L) != 0))\n                    {\n                        _current = new KeyValuePair<string, StringValues>(\"Access-Control-Max-Age\", _collection._headers._AccessControlMaxAge);\n                        _state = 36;\n                        return true;\n                    }\n                \n                state_default:\n                    if (!_hasUnknown || !_unknownEnumerator.MoveNext())\n                    {\n                        _current = default(KeyValuePair<string, StringValues>);\n                        return false;\n                    }\n                    _current = _unknownEnumerator.Current;\n                    return true;\n            }\n        }\n    }\n}", "idx": 512, "id": 11303, "msg": "", "proj": "aspnet-KestrelHttpServer", "lang": ".cs"}
{"patch": "@@ -355,14 +355,14 @@ if __name__ == '__main__':\n   qBounds = [[], [], [], [], [2, 4]]\n   varNames = ['foo1', 'foo2', 'foo3', 'foo4', 'res']\n   ptNames = ['p1', 'p2', 'p3', 'p4', 'p5']\n-  set = MLDataSet(examples, qBounds=qBounds)\n-  DataUtils.WritePickledData('test_data/test.dat.pkl', set)\n-  print('nVars:', set.GetNVars())\n-  print('nPts:', set.GetNPts())\n-  print('nPoss:', set.GetNPossibleVals())\n-  print('qBounds:', set.GetQuantBounds())\n-  print('data:', set.GetAllData())\n-  print('Input data:', set.GetInputData())\n-  print('results:', set.GetResults())\n-\n-  print('nameddata:', set.GetNamedData())\n+  dataset = MLDataSet(examples, qBounds=qBounds)\n+  DataUtils.WritePickledData('test_data/test.dat.pkl', dataset)\n+  print('nVars:', dataset.GetNVars())\n+  print('nPts:', dataset.GetNPts())\n+  print('nPoss:', dataset.GetNPossibleVals())\n+  print('qBounds:', dataset.GetQuantBounds())\n+  print('data:', dataset.GetAllData())\n+  print('Input data:', dataset.GetInputData())\n+  print('results:', dataset.GetResults())\n+\n+  print('nameddata:', dataset.GetNamedData())", "y": 0, "oldf": "#\n#  Copyright (C) 2000-2008  greg Landrum and Rational Discovery LLC\n#    All Rights Reserved\n#\n\"\"\" classes to be used to help work with data sets\n\n\"\"\"\nfrom __future__ import print_function\nimport numpy\nimport math\nimport copy, types\nfrom rdkit import six\nfrom rdkit.six.moves import xrange\n\nnumericTypes = [int, float]\nif six.PY2:\n  numericTypes.append(long)\n\n\nclass MLDataSet(object):\n  \"\"\" A data set for holding general data (floats, ints, and strings)\n\n   **Note**\n     this is intended to be a read-only data structure\n     (i.e. after calling the constructor you cannot touch it)\n  \"\"\"\n\n  def __init__(self, data, nVars=None, nPts=None, nPossibleVals=None, qBounds=None, varNames=None,\n               ptNames=None, nResults=1):\n    \"\"\" Constructor\n\n      **Arguments**\n\n        - data: a list of lists containing the data. The data are copied, so don't worry\n              about us overwriting them.\n\n        - nVars: the number of variables\n\n        - nPts: the number of points\n\n        - nPossibleVals: an list containing the number of possible values\n                       for each variable (should contain 0 when not relevant)\n                       This is _nVars_ long\n\n        - qBounds: a list of lists containing quantization bounds for variables\n                 which are to be quantized (note, this class does not quantize\n                 the variables itself, it merely stores quantization bounds.\n                 an empty sublist indicates no quantization for a given variable\n                 This is _nVars_ long\n\n        - varNames: a list of the names of the variables.\n                 This is _nVars_ long\n\n        - ptNames: the names (labels) of the individual data points\n           This is _nPts_ long\n           \n        - nResults: the number of results columns in the data lists.  This is usually\n                    1, but can be higher.\n    \"\"\"\n    self.data = [x[:] for x in data]\n    self.nResults = nResults\n    if nVars is None:\n      nVars = len(self.data[0]) - self.nResults\n    self.nVars = nVars\n    if nPts is None:\n      nPts = len(data)\n    self.nPts = nPts\n    if qBounds is None:\n      qBounds = [[]] * len(self.data[0])\n    self.qBounds = qBounds\n    if nPossibleVals is None:\n      nPossibleVals = self._CalcNPossible(self.data)\n    self.nPossibleVals = nPossibleVals\n    if varNames is None:\n      varNames = [''] * self.nVars\n    self.varNames = varNames\n    if ptNames is None:\n      ptNames = [''] * self.nPts\n    self.ptNames = ptNames\n\n  def _CalcNPossible(self, data):\n    \"\"\"calculates the number of possible values of each variable (where possible)\n\n      **Arguments**\n\n         -data: a list of examples to be used\n\n      **Returns**\n\n         a list of nPossible values for each variable\n\n    \"\"\"\n    nVars = self.GetNVars() + self.nResults\n    nPossible = [-1] * nVars\n    cols = list(xrange(nVars))\n    for i, bounds in enumerate(self.qBounds):\n      if len(bounds) > 0:\n        nPossible[i] = len(bounds)\n        cols.remove(i)\n\n    nPts = self.GetNPts()\n    for i, pt in enumerate(self.data):\n      for col in cols[:]:\n        d = pt[col]\n        if type(d) in numericTypes:\n          if math.floor(d) == d:\n            nPossible[col] = max(math.floor(d), nPossible[col])\n          else:\n            nPossible[col] = -1\n            cols.remove(col)\n        else:\n          nPossible[col] = -1\n          cols.remove(col)\n    return [int(x) + 1 for x in nPossible]\n\n  def GetNResults(self):\n    return self.nResults\n\n  def GetNVars(self):\n    return self.nVars\n\n  def GetNPts(self):\n    return self.nPts\n\n  def GetNPossibleVals(self):\n    return self.nPossibleVals\n\n  def GetQuantBounds(self):\n    return self.qBounds\n\n  def __getitem__(self, idx):\n    res = [self.ptNames[idx]] + self.data[idx][:]\n    return res\n\n  def __setitem__(self, idx, val):\n    if len(val) != self.GetNVars() + self.GetNResults() + 1:\n      raise ValueError('bad value in assignment')\n    self.ptNames[idx] = val[0]\n    self.data[idx] = val[1:]\n    return val\n\n  def GetNamedData(self):\n    \"\"\" returns a list of named examples\n\n     **Note**\n\n       a named example is the result of prepending the example\n        name to the data list\n        \n    \"\"\"\n    res = [None] * self.nPts\n    for i in xrange(self.nPts):\n      res[i] = [self.ptNames[i]] + self.data[i][:]\n    return res\n\n  def GetAllData(self):\n    \"\"\" returns a *copy* of the data\n\n    \"\"\"\n    return copy.deepcopy(self.data)\n\n  def GetInputData(self):\n    \"\"\" returns the input data\n\n     **Note**\n\n       _inputData_ means the examples without their result fields\n        (the last _NResults_ entries)\n\n    \"\"\"\n    v = self.GetNResults()\n    return [x[:-v] for x in self.data]\n\n  def GetResults(self):\n    \"\"\" Returns the result fields from each example\n\n    \"\"\"\n    if self.GetNResults() > 1:\n      v = self.GetNResults()\n      res = [x[-v:] for x in self.data]\n    else:\n      res = [x[-1] for x in self.data]\n    return res\n\n  def GetVarNames(self):\n    return self.varNames\n\n  def GetPtNames(self):\n    return self.ptNames\n\n  def AddPoint(self, pt):\n    self.data.append(pt[1:])\n    self.ptNames.append(pt[0])\n    self.nPts += 1\n\n  def AddPoints(self, pts, names):\n    if len(pts) != len(names):\n      raise ValueError(\"input length mismatch\")\n    self.data += pts\n    self.ptNames += names\n    self.nPts = len(self.data)\n\n\nclass MLQuantDataSet(MLDataSet):\n  \"\"\" a data set for holding quantized data\n\n\n    **Note**\n\n      this is intended to be a read-only data structure\n      (i.e. after calling the constructor you cannot touch it)\n\n    **Big differences to MLDataSet**\n\n      1) data are stored in a numpy array since they are homogenous\n\n      2) results are assumed to be quantized (i.e. no qBounds entry is required)\n\n  \"\"\"\n\n  def _CalcNPossible(self, data):\n    \"\"\"calculates the number of possible values of each variable\n\n      **Arguments**\n\n         -data: a list of examples to be used\n\n      **Returns**\n\n         a list of nPossible values for each variable\n\n    \"\"\"\n    return [max(x) + 1 for x in numpy.transpose(data)]\n\n  def GetNamedData(self):\n    \"\"\" returns a list of named examples\n\n     **Note**\n\n       a named example is the result of prepending the example\n        name to the data list\n        \n    \"\"\"\n    res = [None] * self.nPts\n    for i in xrange(self.nPts):\n      res[i] = [self.ptNames[i]] + self.data[i].tolist()\n    return res\n\n  def GetAllData(self):\n    \"\"\" returns a *copy* of the data\n\n    \"\"\"\n    return self.data.tolist()\n\n  def GetInputData(self):\n    \"\"\" returns the input data\n\n     **Note**\n\n       _inputData_ means the examples without their result fields\n        (the last _NResults_ entries)\n\n    \"\"\"\n    return (self.data[:, :-self.nResults]).tolist()\n\n  def GetResults(self):\n    \"\"\" Returns the result fields from each example\n\n    \"\"\"\n    if self.GetNResults() > 1:\n      v = self.GetNResults()\n      res = [x[-v:] for x in self.data]\n    else:\n      res = [x[-1] for x in self.data]\n    return res\n\n  def __init__(self, data, nVars=None, nPts=None, nPossibleVals=None, qBounds=None, varNames=None,\n               ptNames=None, nResults=1):\n    \"\"\" Constructor\n\n      **Arguments**\n\n        - data: a list of lists containing the data. The data are copied, so don't worry\n              about us overwriting them.\n\n        - nVars: the number of variables\n\n        - nPts: the number of points\n\n        - nPossibleVals: an list containing the number of possible values\n                       for each variable (should contain 0 when not relevant)\n                       This is _nVars_ long\n\n        - qBounds: a list of lists containing quantization bounds for variables\n                 which are to be quantized (note, this class does not quantize\n                 the variables itself, it merely stores quantization bounds.\n                 an empty sublist indicates no quantization for a given variable\n                 This is _nVars_ long\n\n        - varNames: a list of the names of the variables.\n                 This is _nVars_ long\n\n        - ptNames: the names (labels) of the individual data points\n           This is _nPts_ long\n           \n        - nResults: the number of results columns in the data lists.  This is usually\n                    1, but can be higher.\n    \"\"\"\n    self.data = numpy.array(data)\n    self.nResults = nResults\n    if nVars is None:\n      nVars = len(data[0]) - self.nResults\n    self.nVars = nVars\n    if nPts is None:\n      nPts = len(data)\n    self.nPts = nPts\n    if qBounds is None:\n      qBounds = [[]] * self.nVars\n    self.qBounds = qBounds\n    if nPossibleVals is None:\n      nPossibleVals = self._CalcNPossible(data)\n    self.nPossibleVals = nPossibleVals\n    if varNames is None:\n      varNames = [''] * self.nVars\n    self.varNames = varNames\n    if ptNames is None:\n      ptNames = [''] * self.nPts\n    self.ptNames = ptNames\n\n\nif __name__ == '__main__':\n  import DataUtils\n  examples = [[0, 0, 0, 0, 0], [0, 0, 0, 1, 0], [1, 0, 0, 0, 1], [2, 1, 0, 0, 1], [2, 2, 1, 0, 1]]\n  varNames = ['foo1', 'foo2', 'foo3', 'foo4', 'res']\n  ptNames = ['p1', 'p2', 'p3', 'p4', 'p5']\n  set = MLQuantDataSet(examples, varNames=varNames, ptNames=ptNames)\n  DataUtils.WritePickledData('test_data/test.qdat.pkl', set)\n  print('nVars:', set.GetNVars())\n  print('nPts:', set.GetNPts())\n  print('nPoss:', set.GetNPossibleVals())\n  print('qBounds:', set.GetQuantBounds())\n  print('data:', set.GetAllData())\n  print('Input data:', set.GetInputData())\n  print('results:', set.GetResults())\n\n  print('nameddata:', set.GetNamedData())\n\n  examples = [\n    ['foo', 1, 1.0, 1, 1.1],\n    ['foo', 2, 1.0, 1, 2.1],\n    ['foo', 3, 1.2, 1.1, 3.1],\n    ['foo', 4, 1.0, 1, 4.1],\n    ['foo', 5, 1.1, 1, 5.1],\n  ]\n  qBounds = [[], [], [], [], [2, 4]]\n  varNames = ['foo1', 'foo2', 'foo3', 'foo4', 'res']\n  ptNames = ['p1', 'p2', 'p3', 'p4', 'p5']\n  set = MLDataSet(examples, qBounds=qBounds)\n  DataUtils.WritePickledData('test_data/test.dat.pkl', set)\n  print('nVars:', set.GetNVars())\n  print('nPts:', set.GetNPts())\n  print('nPoss:', set.GetNPossibleVals())\n  print('qBounds:', set.GetQuantBounds())\n  print('data:', set.GetAllData())\n  print('Input data:', set.GetInputData())\n  print('results:', set.GetResults())\n\n  print('nameddata:', set.GetNamedData())\n", "idx": 8, "id": 15821, "msg": "", "proj": "rdkit-rdkit", "lang": "cpp"}
{"patch": "@@ -658,17 +658,21 @@ namespace Microsoft.AspNetCore.Server.Kestrel.Core.Tests\n         {\n             _http1Connection.ResponseHeaders[\"Content-Length\"] = \"12\";\n \n-            // Need to compare WaitHandle ref since CancellationToken is struct\n-            var original = _http1Connection.RequestAborted.WaitHandle;\n+            var original = _http1Connection.RequestAborted;\n \n             foreach (var ch in \"hello, worl\")\n             {\n                 await _http1Connection.WriteAsync(new ArraySegment<byte>(new[] { (byte)ch }), default(CancellationToken));\n-                Assert.Same(original, _http1Connection.RequestAborted.WaitHandle);\n+                Assert.Equal(original, _http1Connection.RequestAborted);\n             }\n \n             await _http1Connection.WriteAsync(new ArraySegment<byte>(new[] { (byte)'d' }), default(CancellationToken));\n-            Assert.NotSame(original, _http1Connection.RequestAborted.WaitHandle);\n+            Assert.NotEqual(original, _http1Connection.RequestAborted);\n+\n+            _http1Connection.Abort(new ConnectionAbortedException());\n+\n+            Assert.False(original.IsCancellationRequested);\n+            Assert.False(_http1Connection.RequestAborted.IsCancellationRequested);\n         }\n \n         [Fact]", "y": 0, "oldf": "// Copyright (c) .NET Foundation. All rights reserved.\n// Licensed under the Apache License, Version 2.0. See License.txt in the project root for license information.\n\nusing System;\nusing System.Buffers;\nusing System.Collections;\nusing System.Collections.Generic;\nusing System.IO;\nusing System.IO.Pipelines;\nusing System.Linq;\nusing System.Text;\nusing System.Threading;\nusing System.Threading.Tasks;\nusing Microsoft.AspNetCore.Connections;\nusing Microsoft.AspNetCore.Connections.Features;\nusing Microsoft.AspNetCore.Http;\nusing Microsoft.AspNetCore.Http.Features;\nusing Microsoft.AspNetCore.Server.Kestrel.Core.Features;\nusing Microsoft.AspNetCore.Server.Kestrel.Core.Internal;\nusing Microsoft.AspNetCore.Server.Kestrel.Core.Internal.Http;\nusing Microsoft.AspNetCore.Server.Kestrel.Core.Internal.Infrastructure;\nusing Microsoft.AspNetCore.Server.Kestrel.Transport.Abstractions.Internal;\nusing Microsoft.AspNetCore.Testing;\nusing Microsoft.Extensions.Logging;\nusing Microsoft.Extensions.Primitives;\nusing Microsoft.Net.Http.Headers;\nusing Moq;\nusing Xunit;\n\nnamespace Microsoft.AspNetCore.Server.Kestrel.Core.Tests\n{\n    public class Http1ConnectionTests : IDisposable\n    {\n        private readonly IDuplexPipe _transport;\n        private readonly IDuplexPipe _application;\n        private readonly TestHttp1Connection _http1Connection;\n        private readonly ServiceContext _serviceContext;\n        private readonly HttpConnectionContext _http1ConnectionContext;\n        private readonly MemoryPool<byte> _pipelineFactory;\n        private SequencePosition _consumed;\n        private SequencePosition _examined;\n        private Mock<ITimeoutControl> _timeoutControl;\n\n        public Http1ConnectionTests()\n        {\n            _pipelineFactory = KestrelMemoryPool.Create();\n            var options = new PipeOptions(_pipelineFactory, readerScheduler: PipeScheduler.Inline, writerScheduler: PipeScheduler.Inline, useSynchronizationContext: false);\n            var pair = DuplexPipe.CreateConnectionPair(options, options);\n\n            _transport = pair.Transport;\n            _application = pair.Application;\n\n            var connectionFeatures = new FeatureCollection();\n            connectionFeatures.Set(Mock.Of<IConnectionLifetimeFeature>());\n\n            _serviceContext = new TestServiceContext();\n            _timeoutControl = new Mock<ITimeoutControl>();\n            _http1ConnectionContext = new HttpConnectionContext\n            {\n                ServiceContext = _serviceContext,\n                ConnectionContext = Mock.Of<ConnectionContext>(),\n                ConnectionFeatures = connectionFeatures,\n                MemoryPool = _pipelineFactory,\n                TimeoutControl = _timeoutControl.Object,\n                Transport = pair.Transport\n            };\n\n            _http1Connection = new TestHttp1Connection(_http1ConnectionContext);\n            _http1Connection.Reset();\n        }\n\n        public void Dispose()\n        {\n            _transport.Input.Complete();\n            _transport.Output.Complete();\n\n            _application.Input.Complete();\n            _application.Output.Complete();\n\n            _pipelineFactory.Dispose();\n        }\n\n        [Fact]\n        public async Task TakeMessageHeadersSucceedsWhenHeaderValueContainsUTF8()\n        {\n            var headerName = \"Header\";\n            var headerValueBytes = new byte[] { 0x46, 0x72, 0x61, 0x6e, 0xc3, 0xa7, 0x6f, 0x69, 0x73 };\n            var headerValue = Encoding.UTF8.GetString(headerValueBytes);\n            _http1Connection.Reset();\n\n            await _application.Output.WriteAsync(Encoding.UTF8.GetBytes($\"{headerName}: \"));\n            await _application.Output.WriteAsync(headerValueBytes);\n            await _application.Output.WriteAsync(Encoding.UTF8.GetBytes(\"\\r\\n\\r\\n\"));\n            var readableBuffer = (await _transport.Input.ReadAsync()).Buffer;\n\n            _http1Connection.TakeMessageHeaders(readableBuffer, out _consumed, out _examined);\n            _transport.Input.AdvanceTo(_consumed, _examined);\n\n            Assert.Equal(headerValue, _http1Connection.RequestHeaders[headerName]);\n        }\n\n        [Fact]\n        public async Task TakeMessageHeadersThrowsWhenHeaderValueContainsExtendedASCII()\n        {\n            var extendedAsciiEncoding = Encoding.GetEncoding(\"ISO-8859-1\");\n            var headerName = \"Header\";\n            var headerValueBytes = new byte[] { 0x46, 0x72, 0x61, 0x6e, 0xe7, 0x6f, 0x69, 0x73 };\n            _http1Connection.Reset();\n\n            await _application.Output.WriteAsync(extendedAsciiEncoding.GetBytes($\"{headerName}: \"));\n            await _application.Output.WriteAsync(headerValueBytes);\n            await _application.Output.WriteAsync(extendedAsciiEncoding.GetBytes(\"\\r\\n\\r\\n\"));\n            var readableBuffer = (await _transport.Input.ReadAsync()).Buffer;\n\n            var exception = Assert.Throws<InvalidOperationException>(() => _http1Connection.TakeMessageHeaders(readableBuffer, out _consumed, out _examined));\n        }\n\n        [Fact]\n        public async Task TakeMessageHeadersThrowsWhenHeadersExceedTotalSizeLimit()\n        {\n            const string headerLine = \"Header: value\\r\\n\";\n            _serviceContext.ServerOptions.Limits.MaxRequestHeadersTotalSize = headerLine.Length - 1;\n            _http1Connection.Reset();\n\n            await _application.Output.WriteAsync(Encoding.ASCII.GetBytes($\"{headerLine}\\r\\n\"));\n            var readableBuffer = (await _transport.Input.ReadAsync()).Buffer;\n\n            var exception = Assert.Throws<BadHttpRequestException>(() => _http1Connection.TakeMessageHeaders(readableBuffer, out _consumed, out _examined));\n            _transport.Input.AdvanceTo(_consumed, _examined);\n\n            Assert.Equal(CoreStrings.BadRequest_HeadersExceedMaxTotalSize, exception.Message);\n            Assert.Equal(StatusCodes.Status431RequestHeaderFieldsTooLarge, exception.StatusCode);\n        }\n\n        [Fact]\n        public async Task TakeMessageHeadersThrowsWhenHeadersExceedCountLimit()\n        {\n            const string headerLines = \"Header-1: value1\\r\\nHeader-2: value2\\r\\n\";\n            _serviceContext.ServerOptions.Limits.MaxRequestHeaderCount = 1;\n\n            await _application.Output.WriteAsync(Encoding.ASCII.GetBytes($\"{headerLines}\\r\\n\"));\n            var readableBuffer = (await _transport.Input.ReadAsync()).Buffer;\n\n            var exception = Assert.Throws<BadHttpRequestException>(() => _http1Connection.TakeMessageHeaders(readableBuffer, out _consumed, out _examined));\n            _transport.Input.AdvanceTo(_consumed, _examined);\n\n            Assert.Equal(CoreStrings.BadRequest_TooManyHeaders, exception.Message);\n            Assert.Equal(StatusCodes.Status431RequestHeaderFieldsTooLarge, exception.StatusCode);\n        }\n\n        [Fact]\n        public void ResetResetsScheme()\n        {\n            _http1Connection.Scheme = \"https\";\n\n            // Act\n            _http1Connection.Reset();\n\n            // Assert\n            Assert.Equal(\"http\", ((IFeatureCollection)_http1Connection).Get<IHttpRequestFeature>().Scheme);\n        }\n\n        [Fact]\n        public void ResetResetsTraceIdentifier()\n        {\n            _http1Connection.TraceIdentifier = \"xyz\";\n\n            _http1Connection.Reset();\n\n            var nextId = ((IFeatureCollection)_http1Connection).Get<IHttpRequestIdentifierFeature>().TraceIdentifier;\n            Assert.NotEqual(\"xyz\", nextId);\n\n            _http1Connection.Reset();\n            var secondId = ((IFeatureCollection)_http1Connection).Get<IHttpRequestIdentifierFeature>().TraceIdentifier;\n            Assert.NotEqual(nextId, secondId);\n        }\n\n        [Fact]\n        public void ResetResetsMinRequestBodyDataRate()\n        {\n            _http1Connection.MinRequestBodyDataRate = new MinDataRate(bytesPerSecond: 1, gracePeriod: TimeSpan.MaxValue);\n\n            _http1Connection.Reset();\n\n            Assert.Same(_serviceContext.ServerOptions.Limits.MinRequestBodyDataRate, _http1Connection.MinRequestBodyDataRate);\n        }\n\n        [Fact]\n        public void ResetResetsMinResponseDataRate()\n        {\n            _http1Connection.MinResponseDataRate = new MinDataRate(bytesPerSecond: 1, gracePeriod: TimeSpan.MaxValue);\n\n            _http1Connection.Reset();\n\n            Assert.Same(_serviceContext.ServerOptions.Limits.MinResponseDataRate, _http1Connection.MinResponseDataRate);\n        }\n\n        [Fact]\n        public void TraceIdentifierCountsRequestsPerHttp1Connection()\n        {\n            var connectionId = _http1ConnectionContext.ConnectionId;\n            var feature = ((IFeatureCollection)_http1Connection).Get<IHttpRequestIdentifierFeature>();\n            // Reset() is called once in the test ctor\n            var count = 1;\n            void Reset()\n            {\n                _http1Connection.Reset();\n                count++;\n            }\n\n            var nextId = feature.TraceIdentifier;\n            Assert.Equal($\"{connectionId}:00000001\", nextId);\n\n            Reset();\n            var secondId = feature.TraceIdentifier;\n            Assert.Equal($\"{connectionId}:00000002\", secondId);\n\n            var big = 1_000_000;\n            while (big-- > 0) Reset();\n            Assert.Equal($\"{connectionId}:{count:X8}\", feature.TraceIdentifier);\n        }\n\n        [Fact]\n        public void TraceIdentifierGeneratesWhenNull()\n        {\n            _http1Connection.TraceIdentifier = null;\n            var id = _http1Connection.TraceIdentifier;\n            Assert.NotNull(id);\n            Assert.Equal(id, _http1Connection.TraceIdentifier);\n\n            _http1Connection.Reset();\n            Assert.NotEqual(id, _http1Connection.TraceIdentifier);\n        }\n\n        [Fact]\n        public async Task ResetResetsHeaderLimits()\n        {\n            const string headerLine1 = \"Header-1: value1\\r\\n\";\n            const string headerLine2 = \"Header-2: value2\\r\\n\";\n\n            var options = new KestrelServerOptions();\n            options.Limits.MaxRequestHeadersTotalSize = headerLine1.Length;\n            options.Limits.MaxRequestHeaderCount = 1;\n            _serviceContext.ServerOptions = options;\n\n            await _application.Output.WriteAsync(Encoding.ASCII.GetBytes($\"{headerLine1}\\r\\n\"));\n            var readableBuffer = (await _transport.Input.ReadAsync()).Buffer;\n\n            var takeMessageHeaders = _http1Connection.TakeMessageHeaders(readableBuffer, out _consumed, out _examined);\n            _transport.Input.AdvanceTo(_consumed, _examined);\n\n            Assert.True(takeMessageHeaders);\n            Assert.Equal(1, _http1Connection.RequestHeaders.Count);\n            Assert.Equal(\"value1\", _http1Connection.RequestHeaders[\"Header-1\"]);\n\n            _http1Connection.Reset();\n\n            await _application.Output.WriteAsync(Encoding.ASCII.GetBytes($\"{headerLine2}\\r\\n\"));\n            readableBuffer = (await _transport.Input.ReadAsync()).Buffer;\n\n            takeMessageHeaders = _http1Connection.TakeMessageHeaders(readableBuffer, out _consumed, out _examined);\n            _transport.Input.AdvanceTo(_consumed, _examined);\n\n            Assert.True(takeMessageHeaders);\n            Assert.Equal(1, _http1Connection.RequestHeaders.Count);\n            Assert.Equal(\"value2\", _http1Connection.RequestHeaders[\"Header-2\"]);\n        }\n\n        [Fact]\n        public async Task ThrowsWhenStatusCodeIsSetAfterResponseStarted()\n        {\n            // Act\n            await _http1Connection.WriteAsync(new ArraySegment<byte>(new byte[1]));\n\n            // Assert\n            Assert.True(_http1Connection.HasResponseStarted);\n            Assert.Throws<InvalidOperationException>(() => ((IHttpResponseFeature)_http1Connection).StatusCode = StatusCodes.Status404NotFound);\n        }\n\n        [Fact]\n        public async Task ThrowsWhenReasonPhraseIsSetAfterResponseStarted()\n        {\n            // Act\n            await _http1Connection.WriteAsync(new ArraySegment<byte>(new byte[1]));\n\n            // Assert\n            Assert.True(_http1Connection.HasResponseStarted);\n            Assert.Throws<InvalidOperationException>(() => ((IHttpResponseFeature)_http1Connection).ReasonPhrase = \"Reason phrase\");\n        }\n\n        [Fact]\n        public async Task ThrowsWhenOnStartingIsSetAfterResponseStarted()\n        {\n            await _http1Connection.WriteAsync(new ArraySegment<byte>(new byte[1]));\n\n            // Act/Assert\n            Assert.True(_http1Connection.HasResponseStarted);\n            Assert.Throws<InvalidOperationException>(() => ((IHttpResponseFeature)_http1Connection).OnStarting(_ => Task.CompletedTask, null));\n        }\n\n        [Theory]\n        [MemberData(nameof(MinDataRateData))]\n        public void ConfiguringIHttpMinRequestBodyDataRateFeatureSetsMinRequestBodyDataRate(MinDataRate minDataRate)\n        {\n            ((IFeatureCollection)_http1Connection).Get<IHttpMinRequestBodyDataRateFeature>().MinDataRate = minDataRate;\n\n            Assert.Same(minDataRate, _http1Connection.MinRequestBodyDataRate);\n        }\n\n        [Theory]\n        [MemberData(nameof(MinDataRateData))]\n        public void ConfiguringIHttpMinResponseDataRateFeatureSetsMinResponseDataRate(MinDataRate minDataRate)\n        {\n            ((IFeatureCollection)_http1Connection).Get<IHttpMinResponseDataRateFeature>().MinDataRate = minDataRate;\n\n            Assert.Same(minDataRate, _http1Connection.MinResponseDataRate);\n        }\n\n        [Fact]\n        public void ResetResetsRequestHeaders()\n        {\n            // Arrange\n            var originalRequestHeaders = _http1Connection.RequestHeaders;\n            _http1Connection.RequestHeaders = new HttpRequestHeaders();\n\n            // Act\n            _http1Connection.Reset();\n\n            // Assert\n            Assert.Same(originalRequestHeaders, _http1Connection.RequestHeaders);\n        }\n\n        [Fact]\n        public void ResetResetsResponseHeaders()\n        {\n            // Arrange\n            var originalResponseHeaders = _http1Connection.ResponseHeaders;\n            _http1Connection.ResponseHeaders = new HttpResponseHeaders();\n\n            // Act\n            _http1Connection.Reset();\n\n            // Assert\n            Assert.Same(originalResponseHeaders, _http1Connection.ResponseHeaders);\n        }\n\n        [Fact]\n        public void InitializeStreamsResetsStreams()\n        {\n            // Arrange\n            var messageBody = Http1MessageBody.For(Kestrel.Core.Internal.Http.HttpVersion.Http11, (HttpRequestHeaders)_http1Connection.RequestHeaders, _http1Connection);\n            _http1Connection.InitializeStreams(messageBody);\n\n            var originalRequestBody = _http1Connection.RequestBody;\n            var originalResponseBody = _http1Connection.ResponseBody;\n            _http1Connection.RequestBody = new MemoryStream();\n            _http1Connection.ResponseBody = new MemoryStream();\n\n            // Act\n            _http1Connection.InitializeStreams(messageBody);\n\n            // Assert\n            Assert.Same(originalRequestBody, _http1Connection.RequestBody);\n            Assert.Same(originalResponseBody, _http1Connection.ResponseBody);\n        }\n\n        [Theory]\n        [MemberData(nameof(RequestLineValidData))]\n        public async Task TakeStartLineSetsHttpProtocolProperties(\n            string requestLine,\n            string expectedMethod,\n            string expectedRawTarget,\n            // This warns that theory methods should use all of their parameters,\n            // but this method is using a shared data collection with HttpParserTests.ParsesRequestLine and others.\n#pragma warning disable xUnit1026\n            string expectedRawPath,\n#pragma warning restore xUnit1026\n            string expectedDecodedPath,\n            string expectedQueryString,\n            string expectedHttpVersion)\n        {\n            var requestLineBytes = Encoding.ASCII.GetBytes(requestLine);\n            await _application.Output.WriteAsync(requestLineBytes);\n            var readableBuffer = (await _transport.Input.ReadAsync()).Buffer;\n\n            var returnValue = _http1Connection.TakeStartLine(readableBuffer, out _consumed, out _examined);\n            _transport.Input.AdvanceTo(_consumed, _examined);\n\n            Assert.True(returnValue);\n            Assert.Equal(expectedMethod, ((IHttpRequestFeature)_http1Connection).Method);\n            Assert.Equal(expectedRawTarget, _http1Connection.RawTarget);\n            Assert.Equal(expectedDecodedPath, _http1Connection.Path);\n            Assert.Equal(expectedQueryString, _http1Connection.QueryString);\n            Assert.Equal(expectedHttpVersion, _http1Connection.HttpVersion);\n        }\n\n        [Theory]\n        [MemberData(nameof(RequestLineDotSegmentData))]\n        public async Task TakeStartLineRemovesDotSegmentsFromTarget(\n            string requestLine,\n            string expectedRawTarget,\n            string expectedDecodedPath,\n            string expectedQueryString)\n        {\n            var requestLineBytes = Encoding.ASCII.GetBytes(requestLine);\n            await _application.Output.WriteAsync(requestLineBytes);\n            var readableBuffer = (await _transport.Input.ReadAsync()).Buffer;\n\n            var returnValue = _http1Connection.TakeStartLine(readableBuffer, out _consumed, out _examined);\n            _transport.Input.AdvanceTo(_consumed, _examined);\n\n            Assert.True(returnValue);\n            Assert.Equal(expectedRawTarget, _http1Connection.RawTarget);\n            Assert.Equal(expectedDecodedPath, _http1Connection.Path);\n            Assert.Equal(expectedQueryString, _http1Connection.QueryString);\n        }\n\n        [Fact]\n        public async Task ParseRequestStartsRequestHeadersTimeoutOnFirstByteAvailable()\n        {\n            await _application.Output.WriteAsync(Encoding.ASCII.GetBytes(\"G\"));\n\n            _http1Connection.ParseRequest((await _transport.Input.ReadAsync()).Buffer, out _consumed, out _examined);\n            _transport.Input.AdvanceTo(_consumed, _examined);\n\n            var expectedRequestHeadersTimeout = _serviceContext.ServerOptions.Limits.RequestHeadersTimeout.Ticks;\n            _timeoutControl.Verify(cc => cc.ResetTimeout(expectedRequestHeadersTimeout, TimeoutReason.RequestHeaders));\n        }\n\n        [Fact]\n        public async Task TakeStartLineThrowsWhenTooLong()\n        {\n            _serviceContext.ServerOptions.Limits.MaxRequestLineSize = \"GET / HTTP/1.1\\r\\n\".Length;\n\n            var requestLineBytes = Encoding.ASCII.GetBytes(\"GET /a HTTP/1.1\\r\\n\");\n            await _application.Output.WriteAsync(requestLineBytes);\n\n            var readableBuffer = (await _transport.Input.ReadAsync()).Buffer;\n            var exception = Assert.Throws<BadHttpRequestException>(() => _http1Connection.TakeStartLine(readableBuffer, out _consumed, out _examined));\n            _transport.Input.AdvanceTo(_consumed, _examined);\n\n            Assert.Equal(CoreStrings.BadRequest_RequestLineTooLong, exception.Message);\n            Assert.Equal(StatusCodes.Status414UriTooLong, exception.StatusCode);\n        }\n\n        [Theory]\n        [MemberData(nameof(TargetWithEncodedNullCharData))]\n        public async Task TakeStartLineThrowsOnEncodedNullCharInTarget(string target)\n        {\n            await _application.Output.WriteAsync(Encoding.ASCII.GetBytes($\"GET {target} HTTP/1.1\\r\\n\"));\n            var readableBuffer = (await _transport.Input.ReadAsync()).Buffer;\n\n            var exception = Assert.Throws<BadHttpRequestException>(() =>\n                _http1Connection.TakeStartLine(readableBuffer, out _consumed, out _examined));\n            _transport.Input.AdvanceTo(_consumed, _examined);\n\n            Assert.Equal(CoreStrings.FormatBadRequest_InvalidRequestTarget_Detail(target), exception.Message);\n        }\n\n        [Theory]\n        [MemberData(nameof(TargetWithNullCharData))]\n        public async Task TakeStartLineThrowsOnNullCharInTarget(string target)\n        {\n            await _application.Output.WriteAsync(Encoding.ASCII.GetBytes($\"GET {target} HTTP/1.1\\r\\n\"));\n            var readableBuffer = (await _transport.Input.ReadAsync()).Buffer;\n\n            var exception = Assert.Throws<BadHttpRequestException>(() =>\n                _http1Connection.TakeStartLine(readableBuffer, out _consumed, out _examined));\n            _transport.Input.AdvanceTo(_consumed, _examined);\n\n            Assert.Equal(CoreStrings.FormatBadRequest_InvalidRequestTarget_Detail(target.EscapeNonPrintable()), exception.Message);\n        }\n\n        [Theory]\n        [MemberData(nameof(MethodWithNullCharData))]\n        public async Task TakeStartLineThrowsOnNullCharInMethod(string method)\n        {\n            var requestLine = $\"{method} / HTTP/1.1\\r\\n\";\n\n            await _application.Output.WriteAsync(Encoding.ASCII.GetBytes(requestLine));\n            var readableBuffer = (await _transport.Input.ReadAsync()).Buffer;\n\n            var exception = Assert.Throws<BadHttpRequestException>(() =>\n                _http1Connection.TakeStartLine(readableBuffer, out _consumed, out _examined));\n            _transport.Input.AdvanceTo(_consumed, _examined);\n\n            Assert.Equal(CoreStrings.FormatBadRequest_InvalidRequestLine_Detail(requestLine.EscapeNonPrintable()), exception.Message);\n        }\n\n        [Theory]\n        [MemberData(nameof(QueryStringWithNullCharData))]\n        public async Task TakeStartLineThrowsOnNullCharInQueryString(string queryString)\n        {\n            var target = $\"/{queryString}\";\n\n            await _application.Output.WriteAsync(Encoding.ASCII.GetBytes($\"GET {target} HTTP/1.1\\r\\n\"));\n            var readableBuffer = (await _transport.Input.ReadAsync()).Buffer;\n\n            var exception = Assert.Throws<BadHttpRequestException>(() =>\n                _http1Connection.TakeStartLine(readableBuffer, out _consumed, out _examined));\n            _transport.Input.AdvanceTo(_consumed, _examined);\n\n            Assert.Equal(CoreStrings.FormatBadRequest_InvalidRequestTarget_Detail(target.EscapeNonPrintable()), exception.Message);\n        }\n\n        [Theory]\n        [MemberData(nameof(TargetInvalidData))]\n        public async Task TakeStartLineThrowsWhenRequestTargetIsInvalid(string method, string target)\n        {\n            var requestLine = $\"{method} {target} HTTP/1.1\\r\\n\";\n\n            await _application.Output.WriteAsync(Encoding.ASCII.GetBytes(requestLine));\n            var readableBuffer = (await _transport.Input.ReadAsync()).Buffer;\n\n            var exception = Assert.Throws<BadHttpRequestException>(() =>\n                _http1Connection.TakeStartLine(readableBuffer, out _consumed, out _examined));\n            _transport.Input.AdvanceTo(_consumed, _examined);\n\n            Assert.Equal(CoreStrings.FormatBadRequest_InvalidRequestTarget_Detail(target.EscapeNonPrintable()), exception.Message);\n        }\n\n        [Theory]\n        [MemberData(nameof(MethodNotAllowedTargetData))]\n        public async Task TakeStartLineThrowsWhenMethodNotAllowed(string requestLine, HttpMethod allowedMethod)\n        {\n            await _application.Output.WriteAsync(Encoding.ASCII.GetBytes(requestLine));\n            var readableBuffer = (await _transport.Input.ReadAsync()).Buffer;\n\n            var exception = Assert.Throws<BadHttpRequestException>(() =>\n                _http1Connection.TakeStartLine(readableBuffer, out _consumed, out _examined));\n            _transport.Input.AdvanceTo(_consumed, _examined);\n\n            Assert.Equal(405, exception.StatusCode);\n            Assert.Equal(CoreStrings.BadRequest_MethodNotAllowed, exception.Message);\n            Assert.Equal(HttpUtilities.MethodToString(allowedMethod), exception.AllowedHeader);\n        }\n\n        [Fact]\n        public void ProcessRequestsAsyncEnablesKeepAliveTimeout()\n        {\n            var requestProcessingTask = _http1Connection.ProcessRequestsAsync<object>(null);\n\n            var expectedKeepAliveTimeout = _serviceContext.ServerOptions.Limits.KeepAliveTimeout.Ticks;\n            _timeoutControl.Verify(cc => cc.SetTimeout(expectedKeepAliveTimeout, TimeoutReason.KeepAlive));\n\n            _http1Connection.StopProcessingNextRequest();\n            _application.Output.Complete();\n\n            requestProcessingTask.Wait();\n        }\n\n        [Fact]\n        public async Task WriteThrowsForNonBodyResponse()\n        {\n            // Arrange\n            ((IHttpResponseFeature)_http1Connection).StatusCode = StatusCodes.Status304NotModified;\n\n            // Act/Assert\n            await Assert.ThrowsAsync<InvalidOperationException>(() => _http1Connection.WriteAsync(new ArraySegment<byte>(new byte[1])));\n        }\n\n        [Fact]\n        public async Task WriteAsyncThrowsForNonBodyResponse()\n        {\n            // Arrange\n            _http1Connection.HttpVersion = \"HTTP/1.1\";\n            ((IHttpResponseFeature)_http1Connection).StatusCode = StatusCodes.Status304NotModified;\n\n            // Act/Assert\n            await Assert.ThrowsAsync<InvalidOperationException>(() => _http1Connection.WriteAsync(new ArraySegment<byte>(new byte[1]), default(CancellationToken)));\n        }\n\n        [Fact]\n        public async Task WriteDoesNotThrowForHeadResponse()\n        {\n            // Arrange\n            _http1Connection.HttpVersion = \"HTTP/1.1\";\n            _http1Connection.Method = HttpMethod.Head;\n\n            // Act/Assert\n            await _http1Connection.WriteAsync(new ArraySegment<byte>(new byte[1]));\n        }\n\n        [Fact]\n        public async Task WriteAsyncDoesNotThrowForHeadResponse()\n        {\n            // Arrange\n            _http1Connection.HttpVersion = \"HTTP/1.1\";\n            _http1Connection.Method = HttpMethod.Head;\n\n            // Act/Assert\n            await _http1Connection.WriteAsync(new ArraySegment<byte>(new byte[1]), default(CancellationToken));\n        }\n\n        [Fact]\n        public async Task ManuallySettingTransferEncodingThrowsForHeadResponse()\n        {\n            // Arrange\n            _http1Connection.HttpVersion = \"HTTP/1.1\";\n            _http1Connection.Method = HttpMethod.Head;\n\n            // Act\n            _http1Connection.ResponseHeaders.Add(\"Transfer-Encoding\", \"chunked\");\n\n            // Assert\n            await Assert.ThrowsAsync<InvalidOperationException>(() => _http1Connection.FlushAsync());\n        }\n\n        [Fact]\n        public async Task ManuallySettingTransferEncodingThrowsForNoBodyResponse()\n        {\n            // Arrange\n            _http1Connection.HttpVersion = \"HTTP/1.1\";\n            ((IHttpResponseFeature)_http1Connection).StatusCode = StatusCodes.Status304NotModified;\n\n            // Act\n            _http1Connection.ResponseHeaders.Add(\"Transfer-Encoding\", \"chunked\");\n\n            // Assert\n            await Assert.ThrowsAsync<InvalidOperationException>(() => _http1Connection.FlushAsync());\n        }\n\n        [Fact]\n        public async Task RequestProcessingTaskIsUnwrapped()\n        {\n            var requestProcessingTask = _http1Connection.ProcessRequestsAsync<object>(null);\n\n            var data = Encoding.ASCII.GetBytes(\"GET / HTTP/1.1\\r\\nHost:\\r\\n\\r\\n\");\n            await _application.Output.WriteAsync(data);\n\n            _http1Connection.StopProcessingNextRequest();\n            Assert.IsNotType<Task<Task>>(requestProcessingTask);\n\n            await requestProcessingTask.DefaultTimeout();\n            _application.Output.Complete();\n        }\n\n        [Fact]\n        public async Task RequestAbortedTokenIsResetBeforeLastWriteWithContentLength()\n        {\n            _http1Connection.ResponseHeaders[\"Content-Length\"] = \"12\";\n\n            // Need to compare WaitHandle ref since CancellationToken is struct\n            var original = _http1Connection.RequestAborted.WaitHandle;\n\n            foreach (var ch in \"hello, worl\")\n            {\n                await _http1Connection.WriteAsync(new ArraySegment<byte>(new[] { (byte)ch }));\n                Assert.Same(original, _http1Connection.RequestAborted.WaitHandle);\n            }\n\n            await _http1Connection.WriteAsync(new ArraySegment<byte>(new[] { (byte)'d' }));\n            Assert.NotSame(original, _http1Connection.RequestAborted.WaitHandle);\n        }\n\n        [Fact]\n        public async Task RequestAbortedTokenIsResetBeforeLastWriteAsyncWithContentLength()\n        {\n            _http1Connection.ResponseHeaders[\"Content-Length\"] = \"12\";\n\n            // Need to compare WaitHandle ref since CancellationToken is struct\n            var original = _http1Connection.RequestAborted.WaitHandle;\n\n            foreach (var ch in \"hello, worl\")\n            {\n                await _http1Connection.WriteAsync(new ArraySegment<byte>(new[] { (byte)ch }), default(CancellationToken));\n                Assert.Same(original, _http1Connection.RequestAborted.WaitHandle);\n            }\n\n            await _http1Connection.WriteAsync(new ArraySegment<byte>(new[] { (byte)'d' }), default(CancellationToken));\n            Assert.NotSame(original, _http1Connection.RequestAborted.WaitHandle);\n        }\n\n        [Fact]\n        public async Task RequestAbortedTokenIsResetBeforeLastWriteAsyncAwaitedWithContentLength()\n        {\n            _http1Connection.ResponseHeaders[\"Content-Length\"] = \"12\";\n\n            // Need to compare WaitHandle ref since CancellationToken is struct\n            var original = _http1Connection.RequestAborted.WaitHandle;\n\n            // Only first write can be WriteAsyncAwaited\n            var startingTask = _http1Connection.InitializeResponseAwaited(Task.CompletedTask, 1);\n            await _http1Connection.WriteAsyncAwaited(startingTask, new ArraySegment<byte>(new[] { (byte)'h' }), default(CancellationToken));\n            Assert.Same(original, _http1Connection.RequestAborted.WaitHandle);\n\n            foreach (var ch in \"ello, worl\")\n            {\n                await _http1Connection.WriteAsync(new ArraySegment<byte>(new[] { (byte)ch }), default(CancellationToken));\n                Assert.Same(original, _http1Connection.RequestAborted.WaitHandle);\n            }\n\n            await _http1Connection.WriteAsync(new ArraySegment<byte>(new[] { (byte)'d' }), default(CancellationToken));\n            Assert.NotSame(original, _http1Connection.RequestAborted.WaitHandle);\n        }\n\n        [Fact]\n        public async Task RequestAbortedTokenIsResetBeforeLastWriteWithChunkedEncoding()\n        {\n            // Need to compare WaitHandle ref since CancellationToken is struct\n            var original = _http1Connection.RequestAborted.WaitHandle;\n\n            _http1Connection.HttpVersion = \"HTTP/1.1\";\n            await _http1Connection.WriteAsync(new ArraySegment<byte>(Encoding.ASCII.GetBytes(\"hello, world\")), default(CancellationToken));\n            Assert.Same(original, _http1Connection.RequestAborted.WaitHandle);\n\n            await _http1Connection.ProduceEndAsync();\n            Assert.NotSame(original, _http1Connection.RequestAborted.WaitHandle);\n        }\n\n        [Fact]\n        public async Task ExceptionDetailNotIncludedWhenLogLevelInformationNotEnabled()\n        {\n            var previousLog = _serviceContext.Log;\n\n            try\n            {\n                var mockTrace = new Mock<IKestrelTrace>();\n                mockTrace\n                    .Setup(trace => trace.IsEnabled(LogLevel.Information))\n                    .Returns(false);\n\n                _serviceContext.Log = mockTrace.Object;\n\n                await _application.Output.WriteAsync(Encoding.ASCII.GetBytes($\"GET /%00 HTTP/1.1\\r\\n\"));\n                var readableBuffer = (await _transport.Input.ReadAsync()).Buffer;\n\n                var exception = Assert.Throws<BadHttpRequestException>(() =>\n                    _http1Connection.TakeStartLine(readableBuffer, out _consumed, out _examined));\n                _transport.Input.AdvanceTo(_consumed, _examined);\n\n                Assert.Equal(CoreStrings.FormatBadRequest_InvalidRequestTarget_Detail(string.Empty), exception.Message);\n                Assert.Equal(StatusCodes.Status400BadRequest, exception.StatusCode);\n            }\n            finally\n            {\n                _serviceContext.Log = previousLog;\n            }\n        }\n\n        [Theory]\n        [InlineData(1, 1)]\n        [InlineData(5, 5)]\n        [InlineData(100, 100)]\n        [InlineData(600, 100)]\n        [InlineData(700, 1)]\n        [InlineData(1, 700)]\n        public async Task AcceptsHeadersAcrossSends(int header0Count, int header1Count)\n        {\n            _serviceContext.ServerOptions.Limits.MaxRequestHeaderCount = header0Count + header1Count;\n\n            var headers0 = MakeHeaders(header0Count);\n            var headers1 = MakeHeaders(header1Count, header0Count);\n\n            var requestProcessingTask = _http1Connection.ProcessRequestsAsync<object>(null);\n\n            await _application.Output.WriteAsync(Encoding.ASCII.GetBytes(\"GET / HTTP/1.0\\r\\n\"));\n            await WaitForCondition(TestConstants.DefaultTimeout, () => _http1Connection.RequestHeaders != null);\n            Assert.Equal(0, _http1Connection.RequestHeaders.Count);\n\n            await _application.Output.WriteAsync(Encoding.ASCII.GetBytes(headers0));\n            await WaitForCondition(TestConstants.DefaultTimeout, () => _http1Connection.RequestHeaders.Count >= header0Count);\n            Assert.Equal(header0Count, _http1Connection.RequestHeaders.Count);\n\n            await _application.Output.WriteAsync(Encoding.ASCII.GetBytes(headers1));\n            await WaitForCondition(TestConstants.DefaultTimeout, () => _http1Connection.RequestHeaders.Count >= header0Count + header1Count);\n            Assert.Equal(header0Count + header1Count, _http1Connection.RequestHeaders.Count);\n\n            await _application.Output.WriteAsync(Encoding.ASCII.GetBytes(\"\\r\\n\"));\n            await requestProcessingTask.DefaultTimeout();\n        }\n\n        [Theory]\n        [InlineData(1, 1)]\n        [InlineData(5, 5)]\n        [InlineData(100, 100)]\n        [InlineData(600, 100)]\n        [InlineData(700, 1)]\n        [InlineData(1, 700)]\n        public async Task KeepsSameHeaderCollectionAcrossSends(int header0Count, int header1Count)\n        {\n            _serviceContext.ServerOptions.Limits.MaxRequestHeaderCount = header0Count + header1Count;\n\n            var headers0 = MakeHeaders(header0Count);\n            var headers1 = MakeHeaders(header1Count, header0Count);\n\n            var requestProcessingTask = _http1Connection.ProcessRequestsAsync<object>(null);\n\n            await _application.Output.WriteAsync(Encoding.ASCII.GetBytes(\"GET / HTTP/1.0\\r\\n\"));\n            await WaitForCondition(TestConstants.DefaultTimeout, () => _http1Connection.RequestHeaders != null);\n            Assert.Equal(0, _http1Connection.RequestHeaders.Count);\n\n            var newRequestHeaders = new RequestHeadersWrapper(_http1Connection.RequestHeaders);\n            _http1Connection.RequestHeaders = newRequestHeaders;\n            Assert.Same(newRequestHeaders, _http1Connection.RequestHeaders);\n\n            await _application.Output.WriteAsync(Encoding.ASCII.GetBytes(headers0));\n            await WaitForCondition(TestConstants.DefaultTimeout, () => _http1Connection.RequestHeaders.Count >= header0Count);\n            Assert.Same(newRequestHeaders, _http1Connection.RequestHeaders);\n            Assert.Equal(header0Count, _http1Connection.RequestHeaders.Count);\n\n            await _application.Output.WriteAsync(Encoding.ASCII.GetBytes(headers1));\n            await WaitForCondition(TestConstants.DefaultTimeout, () => _http1Connection.RequestHeaders.Count >= header0Count + header1Count);\n            Assert.Same(newRequestHeaders, _http1Connection.RequestHeaders);\n            Assert.Equal(header0Count + header1Count, _http1Connection.RequestHeaders.Count);\n\n            await _application.Output.WriteAsync(Encoding.ASCII.GetBytes(\"\\r\\n\"));\n            await requestProcessingTask.TimeoutAfter(TimeSpan.FromSeconds(10));\n        }\n\n        [Fact]\n        public void ThrowsWhenMaxRequestBodySizeIsSetAfterReadingFromRequestBody()\n        {\n            // Act\n            // This would normally be set by the MessageBody during the first read.\n            _http1Connection.HasStartedConsumingRequestBody = true;\n\n            // Assert\n            Assert.True(((IHttpMaxRequestBodySizeFeature)_http1Connection).IsReadOnly);\n            var ex = Assert.Throws<InvalidOperationException>(() => ((IHttpMaxRequestBodySizeFeature)_http1Connection).MaxRequestBodySize = 1);\n            Assert.Equal(CoreStrings.MaxRequestBodySizeCannotBeModifiedAfterRead, ex.Message);\n        }\n\n        [Fact]\n        public void ThrowsWhenMaxRequestBodySizeIsSetToANegativeValue()\n        {\n            // Assert\n            var ex = Assert.Throws<ArgumentOutOfRangeException>(() => ((IHttpMaxRequestBodySizeFeature)_http1Connection).MaxRequestBodySize = -1);\n            Assert.StartsWith(CoreStrings.NonNegativeNumberOrNullRequired, ex.Message);\n        }\n\n        [Fact]\n        public async Task ConsumesRequestWhenApplicationDoesNotConsumeIt()\n        {\n            var httpApplication = new DummyApplication(async context =>\n            {\n                var buffer = new byte[10];\n                await context.Response.Body.WriteAsync(buffer, 0, 10);\n            });\n            var mockMessageBody = new Mock<MessageBody>(null);\n            _http1Connection.NextMessageBody = mockMessageBody.Object;\n\n            var requestProcessingTask = _http1Connection.ProcessRequestsAsync(httpApplication);\n\n            var data = Encoding.ASCII.GetBytes(\"POST / HTTP/1.1\\r\\nHost:\\r\\nConnection: close\\r\\ncontent-length: 1\\r\\n\\r\\n\");\n            await _application.Output.WriteAsync(data);\n            await requestProcessingTask.DefaultTimeout();\n\n            mockMessageBody.Verify(body => body.ConsumeAsync(), Times.Once);\n        }\n\n        [Fact]\n        public void Http10HostHeaderNotRequired()\n        {\n            _http1Connection.HttpVersion = \"HTTP/1.0\";\n            _http1Connection.EnsureHostHeaderExists();\n        }\n\n        [Fact]\n        public void Http10HostHeaderAllowed()\n        {\n            _http1Connection.HttpVersion = \"HTTP/1.0\";\n            _http1Connection.RequestHeaders[HeaderNames.Host] = \"localhost:5000\";\n            _http1Connection.EnsureHostHeaderExists();\n        }\n\n        [Fact]\n        public void Http11EmptyHostHeaderAccepted()\n        {\n            _http1Connection.HttpVersion = \"HTTP/1.1\";\n            _http1Connection.RequestHeaders[HeaderNames.Host] = \"\";\n            _http1Connection.EnsureHostHeaderExists();\n        }\n\n        [Fact]\n        public void Http11ValidHostHeadersAccepted()\n        {\n            _http1Connection.HttpVersion = \"HTTP/1.1\";\n            _http1Connection.RequestHeaders[HeaderNames.Host] = \"localhost:5000\";\n            _http1Connection.EnsureHostHeaderExists();\n        }\n\n        [Fact]\n        public void BadRequestFor10BadHostHeaderFormat()\n        {\n            _http1Connection.HttpVersion = \"HTTP/1.0\";\n            _http1Connection.RequestHeaders[HeaderNames.Host] = \"a=b\";\n            var ex = Assert.Throws<BadHttpRequestException>(() => _http1Connection.EnsureHostHeaderExists());\n            Assert.Equal(CoreStrings.FormatBadRequest_InvalidHostHeader_Detail(\"a=b\"), ex.Message);\n        }\n\n        [Fact]\n        public void BadRequestFor11BadHostHeaderFormat()\n        {\n            _http1Connection.HttpVersion = \"HTTP/1.1\";\n            _http1Connection.RequestHeaders[HeaderNames.Host] = \"a=b\";\n            var ex = Assert.Throws<BadHttpRequestException>(() => _http1Connection.EnsureHostHeaderExists());\n            Assert.Equal(CoreStrings.FormatBadRequest_InvalidHostHeader_Detail(\"a=b\"), ex.Message);\n        }\n\n        private static async Task WaitForCondition(TimeSpan timeout, Func<bool> condition)\n        {\n            const int MaxWaitLoop = 150;\n\n            var delay = (int)Math.Ceiling(timeout.TotalMilliseconds / MaxWaitLoop);\n\n            var waitLoop = 0;\n            while (waitLoop < MaxWaitLoop && !condition())\n            {\n                // Wait for parsing condition to trigger\n                await Task.Delay(delay);\n                waitLoop++;\n            }\n        }\n\n        private static string MakeHeaders(int count, int startAt = 0)\n        {\n            return string.Join(\"\", Enumerable\n                .Range(0, count)\n                .Select(i => $\"Header-{startAt + i}: value{startAt + i}\\r\\n\"));\n        }\n\n        public static IEnumerable<object[]> RequestLineValidData => HttpParsingData.RequestLineValidData;\n\n        public static IEnumerable<object[]> RequestLineDotSegmentData => HttpParsingData.RequestLineDotSegmentData;\n\n        public static TheoryData<string> TargetWithEncodedNullCharData\n        {\n            get\n            {\n                var data = new TheoryData<string>();\n\n                foreach (var target in HttpParsingData.TargetWithEncodedNullCharData)\n                {\n                    data.Add(target);\n                }\n\n                return data;\n            }\n        }\n\n        public static TheoryData<string, string> TargetInvalidData\n            => HttpParsingData.TargetInvalidData;\n\n        public static TheoryData<string, HttpMethod> MethodNotAllowedTargetData\n            => HttpParsingData.MethodNotAllowedRequestLine;\n\n        public static TheoryData<string> TargetWithNullCharData\n        {\n            get\n            {\n                var data = new TheoryData<string>();\n\n                foreach (var target in HttpParsingData.TargetWithNullCharData)\n                {\n                    data.Add(target);\n                }\n\n                return data;\n            }\n        }\n\n        public static TheoryData<string> MethodWithNullCharData\n        {\n            get\n            {\n                var data = new TheoryData<string>();\n\n                foreach (var target in HttpParsingData.MethodWithNullCharData)\n                {\n                    data.Add(target);\n                }\n\n                return data;\n            }\n        }\n\n        public static TheoryData<string> QueryStringWithNullCharData\n        {\n            get\n            {\n                var data = new TheoryData<string>();\n\n                foreach (var target in HttpParsingData.QueryStringWithNullCharData)\n                {\n                    data.Add(target);\n                }\n\n                return data;\n            }\n        }\n\n        public static TheoryData<MinDataRate> MinDataRateData => new TheoryData<MinDataRate>\n        {\n            null,\n            new MinDataRate(bytesPerSecond: 1, gracePeriod: TimeSpan.MaxValue)\n        };\n\n        private class RequestHeadersWrapper : IHeaderDictionary\n        {\n            IHeaderDictionary _innerHeaders;\n\n            public RequestHeadersWrapper(IHeaderDictionary headers)\n            {\n                _innerHeaders = headers;\n            }\n\n            public StringValues this[string key] { get => _innerHeaders[key]; set => _innerHeaders[key] = value; }\n            public long? ContentLength { get => _innerHeaders.ContentLength; set => _innerHeaders.ContentLength = value; }\n            public ICollection<string> Keys => _innerHeaders.Keys;\n            public ICollection<StringValues> Values => _innerHeaders.Values;\n            public int Count => _innerHeaders.Count;\n            public bool IsReadOnly => _innerHeaders.IsReadOnly;\n            public void Add(string key, StringValues value) => _innerHeaders.Add(key, value);\n            public void Add(KeyValuePair<string, StringValues> item) => _innerHeaders.Add(item);\n            public void Clear() => _innerHeaders.Clear();\n            public bool Contains(KeyValuePair<string, StringValues> item) => _innerHeaders.Contains(item);\n            public bool ContainsKey(string key) => _innerHeaders.ContainsKey(key);\n            public void CopyTo(KeyValuePair<string, StringValues>[] array, int arrayIndex) => _innerHeaders.CopyTo(array, arrayIndex);\n            public IEnumerator<KeyValuePair<string, StringValues>> GetEnumerator() => _innerHeaders.GetEnumerator();\n            public bool Remove(string key) => _innerHeaders.Remove(key);\n            public bool Remove(KeyValuePair<string, StringValues> item) => _innerHeaders.Remove(item);\n            public bool TryGetValue(string key, out StringValues value) => _innerHeaders.TryGetValue(key, out value);\n            IEnumerator IEnumerable.GetEnumerator() => _innerHeaders.GetEnumerator();\n        }\n    }\n}\n", "idx": 2, "id": 16795, "msg": "", "proj": "aspnet-KestrelHttpServer", "lang": ".cs"}
{"patch": "@@ -326,10 +326,21 @@ public abstract class TopFieldCollector extends TopDocsCollector<Entry> {\n   }\n \n   protected void updateMinCompetitiveScore(Scorable scorer) throws IOException {\n-    if (canSetMinScore && hitsThresholdChecker.isThresholdReached() && queueFull) {\n-      assert bottom != null && firstComparator != null;\n-      float minScore = firstComparator.value(bottom.slot);\n-      scorer.setMinCompetitiveScore(minScore);\n+    if (canSetMinScore && hitsThresholdChecker.isThresholdReached()\n+          && (queueFull || (bottomValueChecker != null && bottomValueChecker.getBottomValue() > 0f))) {\n+      float maxMinScore = Float.NEGATIVE_INFINITY;\n+      if (queueFull) {\n+        assert bottom != null && firstComparator != null;\n+        maxMinScore = firstComparator.value(bottom.slot);\n+        if (bottomValueChecker != null) {\n+          bottomValueChecker.updateThreadLocalBottomValue(maxMinScore);\n+        }\n+      }\n+      if (bottomValueChecker != null) {\n+        maxMinScore = Math.max(maxMinScore, bottomValueChecker.getBottomValue());\n+      }\n+      assert maxMinScore > 0f;\n+      scorer.setMinCompetitiveScore(maxMinScore);\n       totalHitsRelation = TotalHits.Relation.GREATER_THAN_OR_EQUAL_TO;\n     }\n   }", "y": 0, "oldf": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.apache.lucene.search;\n\n\nimport java.io.IOException;\nimport java.util.Arrays;\nimport java.util.Collection;\nimport java.util.Comparator;\nimport java.util.List;\nimport java.util.Objects;\n\nimport org.apache.lucene.index.LeafReaderContext;\nimport org.apache.lucene.index.ReaderUtil;\nimport org.apache.lucene.search.FieldValueHitQueue.Entry;\nimport org.apache.lucene.search.TotalHits.Relation;\n\n/**\n * A {@link Collector} that sorts by {@link SortField} using\n * {@link FieldComparator}s.\n * <p>\n * See the {@link #create(org.apache.lucene.search.Sort, int, int)} method\n * for instantiating a TopFieldCollector.\n *\n * @lucene.experimental\n */\npublic abstract class TopFieldCollector extends TopDocsCollector<Entry> {\n\n  // TODO: one optimization we could do is to pre-fill\n  // the queue with sentinel value that guaranteed to\n  // always compare lower than a real hit; this would\n  // save having to check queueFull on each insert\n\n  private static abstract class MultiComparatorLeafCollector implements LeafCollector {\n\n    final LeafFieldComparator comparator;\n    final int reverseMul;\n    Scorable scorer;\n\n    MultiComparatorLeafCollector(LeafFieldComparator[] comparators, int[] reverseMul) {\n      if (comparators.length == 1) {\n        this.reverseMul = reverseMul[0];\n        this.comparator = comparators[0];\n      } else {\n        this.reverseMul = 1;\n        this.comparator = new MultiLeafFieldComparator(comparators, reverseMul);\n      }\n    }\n\n    @Override\n    public void setScorer(Scorable scorer) throws IOException {\n      comparator.setScorer(scorer);\n      this.scorer = scorer;\n    }\n  }\n\n  static boolean canEarlyTerminate(Sort searchSort, Sort indexSort) {\n    return canEarlyTerminateOnDocId(searchSort) ||\n           canEarlyTerminateOnPrefix(searchSort, indexSort);\n  }\n\n  private static boolean canEarlyTerminateOnDocId(Sort searchSort) {\n    final SortField[] fields1 = searchSort.getSort();\n    return SortField.FIELD_DOC.equals(fields1[0]);\n  }\n\n  private static boolean canEarlyTerminateOnPrefix(Sort searchSort, Sort indexSort) {\n    if (indexSort != null) {\n      final SortField[] fields1 = searchSort.getSort();\n      final SortField[] fields2 = indexSort.getSort();\n      // early termination is possible if fields1 is a prefix of fields2\n      if (fields1.length > fields2.length) {\n        return false;\n      }\n      return Arrays.asList(fields1).equals(Arrays.asList(fields2).subList(0, fields1.length));\n    } else {\n      return false;\n    }\n  }\n\n  /*\n   * Implements a TopFieldCollector over one SortField criteria, with tracking\n   * document scores and maxScore.\n   */\n  private static class SimpleFieldCollector extends TopFieldCollector {\n    final Sort sort;\n    final FieldValueHitQueue<Entry> queue;\n\n    public SimpleFieldCollector(Sort sort, FieldValueHitQueue<Entry> queue, int numHits,\n                                HitsThresholdChecker hitsThresholdChecker) {\n      super(queue, numHits, hitsThresholdChecker, sort.needsScores());\n      this.sort = sort;\n      this.queue = queue;\n    }\n\n    @Override\n    public LeafCollector getLeafCollector(LeafReaderContext context) throws IOException {\n      docBase = context.docBase;\n\n      final LeafFieldComparator[] comparators = queue.getComparators(context);\n      final int[] reverseMul = queue.getReverseMul();\n      final Sort indexSort = context.reader().getMetaData().getSort();\n      final boolean canEarlyTerminate = canEarlyTerminate(sort, indexSort);\n\n      return new MultiComparatorLeafCollector(comparators, reverseMul) {\n\n        boolean collectedAllCompetitiveHits = false;\n\n        @Override\n        public void setScorer(Scorable scorer) throws IOException {\n          super.setScorer(scorer);\n          updateMinCompetitiveScore(scorer);\n        }\n\n        @Override\n        public void collect(int doc) throws IOException {\n          ++totalHits;\n          hitsThresholdChecker.incrementHitCount();\n          if (queueFull) {\n            if (collectedAllCompetitiveHits || reverseMul * comparator.compareBottom(doc) <= 0) {\n              // since docs are visited in doc Id order, if compare is 0, it means\n              // this document is largest than anything else in the queue, and\n              // therefore not competitive.\n              if (canEarlyTerminate) {\n                if (hitsThresholdChecker.isThresholdReached()) {\n                  totalHitsRelation = Relation.GREATER_THAN_OR_EQUAL_TO;\n                  throw new CollectionTerminatedException();\n                } else {\n                  collectedAllCompetitiveHits = true;\n                }\n              } else if (totalHitsRelation == Relation.EQUAL_TO) {\n                // we just reached totalHitsThreshold, we can start setting the min\n                // competitive score now\n                updateMinCompetitiveScore(scorer);\n              }\n              return;\n            }\n\n            // This hit is competitive - replace bottom element in queue & adjustTop\n            comparator.copy(bottom.slot, doc);\n            updateBottom(doc);\n            comparator.setBottom(bottom.slot);\n            updateMinCompetitiveScore(scorer);\n          } else {\n            // Startup transient: queue hasn't gathered numHits yet\n            final int slot = totalHits - 1;\n\n            // Copy hit into queue\n            comparator.copy(slot, doc);\n            add(slot, doc);\n            if (queueFull) {\n              comparator.setBottom(bottom.slot);\n              updateMinCompetitiveScore(scorer);\n            }\n          }\n        }\n\n      };\n    }\n\n  }\n\n  /*\n   * Implements a TopFieldCollector when after != null.\n   */\n  private final static class PagingFieldCollector extends TopFieldCollector {\n\n    final Sort sort;\n    int collectedHits;\n    final FieldValueHitQueue<Entry> queue;\n    final FieldDoc after;\n\n    public PagingFieldCollector(Sort sort, FieldValueHitQueue<Entry> queue, FieldDoc after, int numHits,\n                                HitsThresholdChecker hitsThresholdChecker) {\n      super(queue, numHits, hitsThresholdChecker, sort.needsScores());\n      this.sort = sort;\n      this.queue = queue;\n      this.after = after;\n\n      FieldComparator<?>[] comparators = queue.comparators;\n      // Tell all comparators their top value:\n      for(int i=0;i<comparators.length;i++) {\n        @SuppressWarnings(\"unchecked\")\n        FieldComparator<Object> comparator = (FieldComparator<Object>) comparators[i];\n        comparator.setTopValue(after.fields[i]);\n      }\n    }\n\n    @Override\n    public LeafCollector getLeafCollector(LeafReaderContext context) throws IOException {\n      docBase = context.docBase;\n      final int afterDoc = after.doc - docBase;\n      final Sort indexSort = context.reader().getMetaData().getSort();\n      final boolean canEarlyTerminate = canEarlyTerminate(sort, indexSort);\n      return new MultiComparatorLeafCollector(queue.getComparators(context), queue.getReverseMul()) {\n\n        boolean collectedAllCompetitiveHits = false;\n\n        @Override\n        public void setScorer(Scorable scorer) throws IOException {\n          super.setScorer(scorer);\n          updateMinCompetitiveScore(scorer);\n        }\n\n        @Override\n        public void collect(int doc) throws IOException {\n          //System.out.println(\"  collect doc=\" + doc);\n\n          totalHits++;\n          hitsThresholdChecker.incrementHitCount();\n\n          if (queueFull) {\n            // Fastmatch: return if this hit is no better than\n            // the worst hit currently in the queue:\n            if (collectedAllCompetitiveHits || reverseMul * comparator.compareBottom(doc) <= 0) {\n              // since docs are visited in doc Id order, if compare is 0, it means\n              // this document is largest than anything else in the queue, and\n              // therefore not competitive.\n              if (canEarlyTerminate) {\n                if (hitsThresholdChecker.isThresholdReached()) {\n                  totalHitsRelation = Relation.GREATER_THAN_OR_EQUAL_TO;\n                  throw new CollectionTerminatedException();\n                } else {\n                  collectedAllCompetitiveHits = true;\n                }\n              } else if (totalHitsRelation == Relation.GREATER_THAN_OR_EQUAL_TO) {\n                  updateMinCompetitiveScore(scorer);\n              }\n              return;\n            }\n          }\n\n          final int topCmp = reverseMul * comparator.compareTop(doc);\n          if (topCmp > 0 || (topCmp == 0 && doc <= afterDoc)) {\n            // Already collected on a previous page\n            return;\n          }\n\n          if (queueFull) {\n            // This hit is competitive - replace bottom element in queue & adjustTop\n            comparator.copy(bottom.slot, doc);\n\n            updateBottom(doc);\n\n            comparator.setBottom(bottom.slot);\n            updateMinCompetitiveScore(scorer);\n          } else {\n            collectedHits++;\n\n            // Startup transient: queue hasn't gathered numHits yet\n            final int slot = collectedHits - 1;\n            //System.out.println(\"    slot=\" + slot);\n            // Copy hit into queue\n            comparator.copy(slot, doc);\n\n            bottom = pq.add(new Entry(slot, docBase + doc));\n            queueFull = collectedHits == numHits;\n            if (queueFull) {\n              comparator.setBottom(bottom.slot);\n              updateMinCompetitiveScore(scorer);\n            }\n          }\n        }\n      };\n    }\n\n  }\n\n  private static final ScoreDoc[] EMPTY_SCOREDOCS = new ScoreDoc[0];\n\n  final int numHits;\n  final HitsThresholdChecker hitsThresholdChecker;\n  final FieldComparator.RelevanceComparator firstComparator;\n  final boolean canSetMinScore;\n  final int numComparators;\n  FieldValueHitQueue.Entry bottom = null;\n  boolean queueFull;\n  int docBase;\n  final boolean needsScores;\n  final ScoreMode scoreMode;\n\n  // Declaring the constructor private prevents extending this class by anyone\n  // else. Note that the class cannot be final since it's extended by the\n  // internal versions. If someone will define a constructor with any other\n  // visibility, then anyone will be able to extend the class, which is not what\n  // we want.\n  private TopFieldCollector(FieldValueHitQueue<Entry> pq, int numHits,\n                            HitsThresholdChecker hitsThresholdChecker, boolean needsScores) {\n    super(pq);\n    this.needsScores = needsScores;\n    this.numHits = numHits;\n    this.hitsThresholdChecker = hitsThresholdChecker;\n    this.numComparators = pq.getComparators().length;\n    FieldComparator<?> fieldComparator = pq.getComparators()[0];\n    int reverseMul = pq.reverseMul[0];\n    if (fieldComparator.getClass().equals(FieldComparator.RelevanceComparator.class)\n          && reverseMul == 1 // if the natural sort is preserved (sort by descending relevance)\n          && hitsThresholdChecker.getHitsThreshold() != Integer.MAX_VALUE) {\n      firstComparator = (FieldComparator.RelevanceComparator) fieldComparator;\n      scoreMode = ScoreMode.TOP_SCORES;\n      canSetMinScore = true;\n    } else {\n      firstComparator = null;\n      scoreMode = needsScores ? ScoreMode.COMPLETE : ScoreMode.COMPLETE_NO_SCORES;\n      canSetMinScore = false;\n    }\n  }\n\n  @Override\n  public ScoreMode scoreMode() {\n    return scoreMode;\n  }\n\n  protected void updateMinCompetitiveScore(Scorable scorer) throws IOException {\n    if (canSetMinScore && hitsThresholdChecker.isThresholdReached() && queueFull) {\n      assert bottom != null && firstComparator != null;\n      float minScore = firstComparator.value(bottom.slot);\n      scorer.setMinCompetitiveScore(minScore);\n      totalHitsRelation = TotalHits.Relation.GREATER_THAN_OR_EQUAL_TO;\n    }\n  }\n\n  /**\n   * Creates a new {@link TopFieldCollector} from the given\n   * arguments.\n   *\n   * <p><b>NOTE</b>: The instances returned by this method\n   * pre-allocate a full array of length\n   * <code>numHits</code>.\n   *\n   * @param sort\n   *          the sort criteria (SortFields).\n   * @param numHits\n   *          the number of results to collect.\n   * @param totalHitsThreshold\n   *          the number of docs to count accurately. If the query matches more than\n   *          {@code totalHitsThreshold} hits then its hit count will be a\n   *          lower bound. On the other hand if the query matches less than or exactly\n   *          {@code totalHitsThreshold} hits then the hit count of the result will\n   *          be accurate. {@link Integer#MAX_VALUE} may be used to make the hit\n   *          count accurate, but this will also make query processing slower.\n   * @return a {@link TopFieldCollector} instance which will sort the results by\n   *         the sort criteria.\n   */\n  public static TopFieldCollector create(Sort sort, int numHits, int totalHitsThreshold) {\n    return create(sort, numHits, null, totalHitsThreshold);\n  }\n\n  /**\n   * Creates a new {@link TopFieldCollector} from the given\n   * arguments.\n   *\n   * <p><b>NOTE</b>: The instances returned by this method\n   * pre-allocate a full array of length\n   * <code>numHits</code>.\n   *\n   * @param sort\n   *          the sort criteria (SortFields).\n   * @param numHits\n   *          the number of results to collect.\n   * @param after\n   *          only hits after this FieldDoc will be collected\n   * @param totalHitsThreshold\n   *          the number of docs to count accurately. If the query matches more than\n   *          {@code totalHitsThreshold} hits then its hit count will be a\n   *          lower bound. On the other hand if the query matches less than or exactly\n   *          {@code totalHitsThreshold} hits then the hit count of the result will\n   *          be accurate. {@link Integer#MAX_VALUE} may be used to make the hit\n   *          count accurate, but this will also make query processing slower.\n   * @return a {@link TopFieldCollector} instance which will sort the results by\n   *         the sort criteria.\n   */\n  public static TopFieldCollector create(Sort sort, int numHits, FieldDoc after, int totalHitsThreshold) {\n    if (totalHitsThreshold < 0) {\n      throw new IllegalArgumentException(\"totalHitsThreshold must be >= 0, got \" + totalHitsThreshold);\n    }\n\n    return create(sort, numHits, after, HitsThresholdChecker.create(totalHitsThreshold));\n  }\n\n  /**\n   * Same as above with an additional parameter to allow passing in the threshold checker\n   */\n  static TopFieldCollector create(Sort sort, int numHits, FieldDoc after,\n                                         HitsThresholdChecker hitsThresholdChecker) {\n\n    if (sort.fields.length == 0) {\n      throw new IllegalArgumentException(\"Sort must contain at least one field\");\n    }\n\n    if (numHits <= 0) {\n      throw new IllegalArgumentException(\"numHits must be > 0; please use TotalHitCountCollector if you just need the total hit count\");\n    }\n\n    if (hitsThresholdChecker == null) {\n      throw new IllegalArgumentException(\"hitsThresholdChecker should not be null\");\n    }\n\n    FieldValueHitQueue<Entry> queue = FieldValueHitQueue.create(sort.fields, numHits);\n\n    if (after == null) {\n      return new SimpleFieldCollector(sort, queue, numHits, hitsThresholdChecker);\n    } else {\n      if (after.fields == null) {\n        throw new IllegalArgumentException(\"after.fields wasn't set; you must pass fillFields=true for the previous search\");\n      }\n\n      if (after.fields.length != sort.getSort().length) {\n        throw new IllegalArgumentException(\"after.fields has \" + after.fields.length + \" values but sort has \" + sort.getSort().length);\n      }\n\n      return new PagingFieldCollector(sort, queue, after, numHits, hitsThresholdChecker);\n    }\n  }\n\n  /**\n   * Create a CollectorManager which uses a shared hit counter to maintain number of hits\n   */\n  public static CollectorManager<TopFieldCollector, TopFieldDocs> createSharedManager(Sort sort, int numHits, FieldDoc after,\n                                                                                 int totalHitsThreshold) {\n    return new CollectorManager<>() {\n\n      private final HitsThresholdChecker hitsThresholdChecker = HitsThresholdChecker.createShared(totalHitsThreshold);\n\n      @Override\n      public TopFieldCollector newCollector() throws IOException {\n        return create(sort, numHits, after, hitsThresholdChecker);\n      }\n\n      @Override\n      public TopFieldDocs reduce(Collection<TopFieldCollector> collectors) throws IOException {\n        final TopFieldDocs[] topDocs = new TopFieldDocs[collectors.size()];\n        int i = 0;\n        for (TopFieldCollector collector : collectors) {\n          topDocs[i++] = collector.topDocs();\n        }\n        return TopDocs.merge(sort, 0, numHits, topDocs);\n      }\n    };\n  }\n\n  /**\n   * Populate {@link ScoreDoc#score scores} of the given {@code topDocs}.\n   * @param topDocs   the top docs to populate\n   * @param searcher  the index searcher that has been used to compute {@code topDocs}\n   * @param query     the query that has been used to compute {@code topDocs}\n   * @throws IllegalArgumentException if there is evidence that {@code topDocs}\n   *             have been computed against a different searcher or a different query.\n   * @lucene.experimental\n   */\n  public static void populateScores(ScoreDoc[] topDocs, IndexSearcher searcher, Query query) throws IOException {\n    // Get the score docs sorted in doc id order\n    topDocs = topDocs.clone();\n    Arrays.sort(topDocs, Comparator.comparingInt(scoreDoc -> scoreDoc.doc));\n\n    final Weight weight = searcher.createWeight(searcher.rewrite(query), ScoreMode.COMPLETE, 1);\n    List<LeafReaderContext> contexts = searcher.getIndexReader().leaves();\n    LeafReaderContext currentContext = null;\n    Scorer currentScorer = null;\n    for (ScoreDoc scoreDoc : topDocs) {\n      if (currentContext == null || scoreDoc.doc >= currentContext.docBase + currentContext.reader().maxDoc()) {\n        Objects.checkIndex(scoreDoc.doc, searcher.getIndexReader().maxDoc());\n        int newContextIndex = ReaderUtil.subIndex(scoreDoc.doc, contexts);\n        currentContext = contexts.get(newContextIndex);\n        final ScorerSupplier scorerSupplier = weight.scorerSupplier(currentContext);\n        if (scorerSupplier == null) {\n          throw new IllegalArgumentException(\"Doc id \" + scoreDoc.doc + \" doesn't match the query\");\n        }\n        currentScorer = scorerSupplier.get(1); // random-access\n      }\n      final int leafDoc = scoreDoc.doc - currentContext.docBase;\n      assert leafDoc >= 0;\n      final int advanced = currentScorer.iterator().advance(leafDoc);\n      if (leafDoc != advanced) {\n        throw new IllegalArgumentException(\"Doc id \" + scoreDoc.doc + \" doesn't match the query\");\n      }\n      scoreDoc.score = currentScorer.score();\n    }\n  }\n\n  final void add(int slot, int doc) {\n    bottom = pq.add(new Entry(slot, docBase + doc));\n    queueFull = totalHits == numHits;\n  }\n\n  final void updateBottom(int doc) {\n    // bottom.score is already set to Float.NaN in add().\n    bottom.doc = docBase + doc;\n    bottom = pq.updateTop();\n  }\n\n  /*\n   * Only the following callback methods need to be overridden since\n   * topDocs(int, int) calls them to return the results.\n   */\n\n  @Override\n  protected void populateResults(ScoreDoc[] results, int howMany) {\n    // avoid casting if unnecessary.\n    FieldValueHitQueue<Entry> queue = (FieldValueHitQueue<Entry>) pq;\n    for (int i = howMany - 1; i >= 0; i--) {\n      results[i] = queue.fillFields(queue.pop());\n    }\n  }\n\n  @Override\n  protected TopDocs newTopDocs(ScoreDoc[] results, int start) {\n    if (results == null) {\n      results = EMPTY_SCOREDOCS;\n    }\n\n    // If this is a maxScoring tracking collector and there were no results,\n    return new TopFieldDocs(new TotalHits(totalHits, totalHitsRelation), results, ((FieldValueHitQueue<Entry>) pq).getFields());\n  }\n\n  @Override\n  public TopFieldDocs topDocs() {\n    return (TopFieldDocs) super.topDocs();\n  }\n\n  /** Return whether collection terminated early. */\n  public boolean isEarlyTerminated() {\n    return totalHitsRelation == Relation.GREATER_THAN_OR_EQUAL_TO;\n  }\n}\n", "idx": 7, "id": 30565, "msg": "", "proj": "apache-lucene-solr", "lang": "java"}
{"patch": "@@ -20,10 +20,17 @@ import (\n \n \t\"github.com/aws/aws-sdk-go/aws/credentials\"\n \t\"github.com/aws/aws-sdk-go/aws/signer/v4\"\n+\t\"github.com/cihub/seelog\"\n+\t\"github.com/pkg/errors\"\n )\n \n // SignHTTPRequest signs an http.Request struct with authv4 using the given region, service, and credentials.\n-func SignHTTPRequest(req *http.Request, region, service string, creds *credentials.Credentials, body io.ReadSeeker) {\n+func SignHTTPRequest(req *http.Request, region, service string, creds *credentials.Credentials, body io.ReadSeeker) error {\n \tsigner := v4.NewSigner(creds)\n-\tsigner.Sign(req, body, service, region, time.Now())\n+\t_, err := signer.Sign(req, body, service, region, time.Now())\n+\tif err != nil {\n+\t\tseelog.Warnf(\"Signing HTTP request failed: %v\", err)\n+\t\treturn errors.Wrap(err, \"aws sdk http signer: failed to sign http request\")\n+\t}\n+\treturn nil\n }", "y": 1, "oldf": "// Copyright 2014-2015 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\"). You may\n// not use this file except in compliance with the License. A copy of the\n// License is located at\n//\n//\thttp://aws.amazon.com/apache2.0/\n//\n// or in the \"license\" file accompanying this file. This file is distributed\n// on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n// express or implied. See the License for the specific language governing\n// permissions and limitations under the License.\n\npackage utils\n\nimport (\n\t\"io\"\n\t\"net/http\"\n\t\"time\"\n\n\t\"github.com/aws/aws-sdk-go/aws/credentials\"\n\t\"github.com/aws/aws-sdk-go/aws/signer/v4\"\n)\n\n// SignHTTPRequest signs an http.Request struct with authv4 using the given region, service, and credentials.\nfunc SignHTTPRequest(req *http.Request, region, service string, creds *credentials.Credentials, body io.ReadSeeker) {\n\tsigner := v4.NewSigner(creds)\n\tsigner.Sign(req, body, service, region, time.Now())\n}\n", "idx": 1, "id": 20071, "msg": "nit: `errors.Wrap()` should suffice here.", "proj": "aws-amazon-ecs-agent", "lang": "go"}
{"patch": "@@ -342,18 +342,6 @@ public class SolrDispatchFilter extends BaseSolrFilter {\n         }\n       }\n \n-      AtomicReference<HttpServletRequest> wrappedRequest = new AtomicReference<>();\n-      if (!authenticateRequest(request, response, wrappedRequest)) { // the response and status code have already been sent\n-        return;\n-      }\n-      if (wrappedRequest.get() != null) {\n-        request = wrappedRequest.get();\n-      }\n-\n-      if (cores.getAuthenticationPlugin() != null) {\n-        log.debug(\"User principal: {}\", request.getUserPrincipal());\n-      }\n-\n       // No need to even create the HttpSolrCall object if this path is excluded.\n       if (excludePatterns != null) {\n         String requestPath = request.getServletPath();", "y": 1, "oldf": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.apache.solr.servlet;\n\nimport javax.servlet.FilterChain;\nimport javax.servlet.FilterConfig;\nimport javax.servlet.ReadListener;\nimport javax.servlet.ServletException;\nimport javax.servlet.ServletInputStream;\nimport javax.servlet.ServletOutputStream;\nimport javax.servlet.ServletRequest;\nimport javax.servlet.ServletResponse;\nimport javax.servlet.UnavailableException;\nimport javax.servlet.WriteListener;\nimport javax.servlet.http.HttpServletRequest;\nimport javax.servlet.http.HttpServletRequestWrapper;\nimport javax.servlet.http.HttpServletResponse;\nimport javax.servlet.http.HttpServletResponseWrapper;\nimport java.io.ByteArrayInputStream;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.OutputStream;\nimport java.lang.invoke.MethodHandles;\nimport java.nio.file.Path;\nimport java.nio.file.Paths;\nimport java.time.Instant;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.Locale;\nimport java.util.Properties;\nimport java.util.Set;\nimport java.util.concurrent.CountDownLatch;\nimport java.util.concurrent.atomic.AtomicBoolean;\nimport java.util.concurrent.atomic.AtomicReference;\nimport java.util.regex.Matcher;\nimport java.util.regex.Pattern;\n\nimport com.codahale.metrics.jvm.ClassLoadingGaugeSet;\nimport com.codahale.metrics.jvm.GarbageCollectorMetricSet;\nimport com.codahale.metrics.jvm.MemoryUsageGaugeSet;\nimport com.codahale.metrics.jvm.ThreadStatesGaugeSet;\nimport org.apache.commons.io.FileCleaningTracker;\nimport org.apache.commons.lang.StringUtils;\nimport org.apache.http.client.HttpClient;\nimport org.apache.lucene.util.Version;\nimport org.apache.solr.api.V2HttpCall;\nimport org.apache.solr.common.SolrException;\nimport org.apache.solr.common.SolrException.ErrorCode;\nimport org.apache.solr.common.cloud.SolrZkClient;\nimport org.apache.solr.common.util.ExecutorUtil;\nimport org.apache.solr.core.CoreContainer;\nimport org.apache.solr.core.NodeConfig;\nimport org.apache.solr.core.SolrCore;\nimport org.apache.solr.core.SolrInfoBean;\nimport org.apache.solr.core.SolrResourceLoader;\nimport org.apache.solr.core.SolrXmlConfig;\nimport org.apache.solr.metrics.AltBufferPoolMetricSet;\nimport org.apache.solr.metrics.MetricsMap;\nimport org.apache.solr.metrics.OperatingSystemMetricSet;\nimport org.apache.solr.metrics.SolrMetricManager;\nimport org.apache.solr.request.SolrRequestInfo;\nimport org.apache.solr.security.AuthenticationPlugin;\nimport org.apache.solr.security.PKIAuthenticationPlugin;\nimport org.apache.solr.security.PublicKeyHandler;\nimport org.apache.solr.util.SolrFileCleaningTracker;\nimport org.apache.solr.util.StartupLoggingUtils;\nimport org.apache.solr.util.configuration.SSLConfigurationsFactory;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\n/**\n * This filter looks at the incoming URL maps them to handlers defined in solrconfig.xml\n *\n * @since solr 1.2\n */\npublic class SolrDispatchFilter extends BaseSolrFilter {\n  private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n\n  protected volatile CoreContainer cores;\n  protected final CountDownLatch init = new CountDownLatch(1);\n\n  protected String abortErrorMessage = null;\n  protected HttpClient httpClient;\n  private ArrayList<Pattern> excludePatterns;\n  \n  private boolean isV2Enabled = !\"true\".equals(System.getProperty(\"disable.v2.api\", \"false\"));\n\n  private final String metricTag = Integer.toHexString(hashCode());\n  private SolrMetricManager metricManager;\n  private String registryName;\n\n  /**\n   * Enum to define action that needs to be processed.\n   * PASSTHROUGH: Pass through to Restlet via webapp.\n   * FORWARD: Forward rewritten URI (without path prefix and core/collection name) to Restlet\n   * RETURN: Returns the control, and no further specific processing is needed.\n   *  This is generally when an error is set and returned.\n   * RETRY:Retry the request. In cases when a core isn't found to work with, this is set.\n   */\n  public enum Action {\n    PASSTHROUGH, FORWARD, RETURN, RETRY, ADMIN, REMOTEQUERY, PROCESS\n  }\n  \n  public SolrDispatchFilter() {\n  }\n\n  public static final String PROPERTIES_ATTRIBUTE = \"solr.properties\";\n\n  public static final String SOLRHOME_ATTRIBUTE = \"solr.solr.home\";\n\n  public static final String SOLR_INSTALL_DIR_ATTRIBUTE = \"solr.install.dir\";\n\n  public static final String SOLR_DEFAULT_CONFDIR_ATTRIBUTE = \"solr.default.confdir\";\n\n  public static final String SOLR_LOG_MUTECONSOLE = \"solr.log.muteconsole\";\n\n  public static final String SOLR_LOG_LEVEL = \"solr.log.level\";\n\n  @Override\n  public void init(FilterConfig config) throws ServletException\n  {\n    SSLConfigurationsFactory.current().init();\n    log.trace(\"SolrDispatchFilter.init(): {}\", this.getClass().getClassLoader());\n    CoreContainer coresInit = null;\n    try{\n\n    SolrRequestParsers.fileCleaningTracker = new SolrFileCleaningTracker();\n\n    StartupLoggingUtils.checkLogDir();\n    log.info(\"Using logger factory {}\", StartupLoggingUtils.getLoggerImplStr());\n    logWelcomeBanner();\n    String muteConsole = System.getProperty(SOLR_LOG_MUTECONSOLE);\n    if (muteConsole != null && !Arrays.asList(\"false\",\"0\",\"off\",\"no\").contains(muteConsole.toLowerCase(Locale.ROOT))) {\n      StartupLoggingUtils.muteConsole();\n    }\n    String logLevel = System.getProperty(SOLR_LOG_LEVEL);\n    if (logLevel != null) {\n      log.info(\"Log level override, property solr.log.level=\" + logLevel);\n      StartupLoggingUtils.changeLogLevel(logLevel);\n    }\n\n    String exclude = config.getInitParameter(\"excludePatterns\");\n    if(exclude != null) {\n      String[] excludeArray = exclude.split(\",\");\n      excludePatterns = new ArrayList<>();\n      for (String element : excludeArray) {\n        excludePatterns.add(Pattern.compile(element));\n      }\n    }\n    try {\n      Properties extraProperties = (Properties) config.getServletContext().getAttribute(PROPERTIES_ATTRIBUTE);\n      if (extraProperties == null)\n        extraProperties = new Properties();\n\n      String solrHome = (String) config.getServletContext().getAttribute(SOLRHOME_ATTRIBUTE);\n      ExecutorUtil.addThreadLocalProvider(SolrRequestInfo.getInheritableThreadLocalProvider());\n\n      coresInit = createCoreContainer(solrHome == null ? SolrResourceLoader.locateSolrHome() : Paths.get(solrHome),\n                                       extraProperties);\n      this.httpClient = coresInit.getUpdateShardHandler().getDefaultHttpClient();\n      setupJvmMetrics(coresInit);\n      log.debug(\"user.dir=\" + System.getProperty(\"user.dir\"));\n    }\n    catch( Throwable t ) {\n      // catch this so our filter still works\n      log.error( \"Could not start Solr. Check solr/home property and the logs\");\n      SolrCore.log( t );\n      if (t instanceof Error) {\n        throw (Error) t;\n      }\n    }\n\n    }finally{\n      log.trace(\"SolrDispatchFilter.init() done\");\n      this.cores = coresInit; // crucially final assignment \n      init.countDown();\n    }\n  }\n\n  private void setupJvmMetrics(CoreContainer coresInit)  {\n    metricManager = coresInit.getMetricManager();\n    registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.jvm);\n    final Set<String> hiddenSysProps = coresInit.getConfig().getMetricsConfig().getHiddenSysProps();\n    try {\n      metricManager.registerAll(registryName, new AltBufferPoolMetricSet(), true, \"buffers\");\n      metricManager.registerAll(registryName, new ClassLoadingGaugeSet(), true, \"classes\");\n      metricManager.registerAll(registryName, new OperatingSystemMetricSet(), true, \"os\");\n      metricManager.registerAll(registryName, new GarbageCollectorMetricSet(), true, \"gc\");\n      metricManager.registerAll(registryName, new MemoryUsageGaugeSet(), true, \"memory\");\n      metricManager.registerAll(registryName, new ThreadStatesGaugeSet(), true, \"threads\"); // todo should we use CachedThreadStatesGaugeSet instead?\n      MetricsMap sysprops = new MetricsMap((detailed, map) -> {\n        System.getProperties().forEach((k, v) -> {\n          if (!hiddenSysProps.contains(k)) {\n            map.put(String.valueOf(k), v);\n          }\n        });\n      });\n      metricManager.registerGauge(null, registryName, sysprops, metricTag, true, \"properties\", \"system\");\n    } catch (Exception e) {\n      log.warn(\"Error registering JVM metrics\", e);\n    }\n  }\n\n  private void logWelcomeBanner() {\n    log.info(\" ___      _       Welcome to Apache Solr\u2122 version {}\", solrVersion());\n    log.info(\"/ __| ___| |_ _   Starting in {} mode on port {}\", isCloudMode() ? \"cloud\" : \"standalone\", getSolrPort());\n    log.info(\"\\\\__ \\\\/ _ \\\\ | '_|  Install dir: {}\", System.getProperty(SOLR_INSTALL_DIR_ATTRIBUTE));\n    log.info(\"|___/\\\\___/_|_|    Start time: {}\", Instant.now().toString());\n  }\n\n  private String solrVersion() {\n    String specVer = Version.LATEST.toString();\n    try {\n      String implVer = SolrCore.class.getPackage().getImplementationVersion();\n      return (specVer.equals(implVer.split(\" \")[0])) ? specVer : implVer;\n    } catch (Exception e) {\n      return specVer;\n    }\n  }\n\n  private String getSolrPort() {\n    return System.getProperty(\"jetty.port\");\n  }\n\n  /* We are in cloud mode if Java option zkRun exists OR zkHost exists and is non-empty */\n  private boolean isCloudMode() {\n    return ((System.getProperty(\"zkHost\") != null && !StringUtils.isEmpty(System.getProperty(\"zkHost\")))\n    || System.getProperty(\"zkRun\") != null);\n  }\n\n  /**\n   * Override this to change CoreContainer initialization\n   * @return a CoreContainer to hold this server's cores\n   */\n  protected CoreContainer createCoreContainer(Path solrHome, Properties extraProperties) {\n    NodeConfig nodeConfig = loadNodeConfig(solrHome, extraProperties);\n    final CoreContainer coreContainer = new CoreContainer(nodeConfig, extraProperties, true);\n    coreContainer.load();\n    return coreContainer;\n  }\n\n  /**\n   * Get the NodeConfig whether stored on disk, in ZooKeeper, etc.\n   * This may also be used by custom filters to load relevant configuration.\n   * @return the NodeConfig\n   */\n  public static NodeConfig loadNodeConfig(Path solrHome, Properties nodeProperties) {\n    NodeConfig cfg = null;\n    try (SolrResourceLoader loader = new SolrResourceLoader(solrHome, SolrDispatchFilter.class.getClassLoader(), nodeProperties)) {\n      if (!StringUtils.isEmpty(System.getProperty(\"solr.solrxml.location\"))) {\n        log.warn(\"Solr property solr.solrxml.location is no longer supported. \" +\n            \"Will automatically load solr.xml from ZooKeeper if it exists\");\n      }\n\n      String zkHost = System.getProperty(\"zkHost\");\n      if (!StringUtils.isEmpty(zkHost)) {\n        int startUpZkTimeOut = Integer.getInteger(\"waitForZk\", 30);\n        startUpZkTimeOut *= 1000;\n        try (SolrZkClient zkClient = new SolrZkClient(zkHost, startUpZkTimeOut)) {\n          if (zkClient.exists(\"/solr.xml\", true)) {\n            log.info(\"solr.xml found in ZooKeeper. Loading...\");\n            byte[] data = zkClient.getData(\"/solr.xml\", null, null, true);\n            return SolrXmlConfig.fromInputStream(loader, new ByteArrayInputStream(data));\n          }\n        } catch (Exception e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Error occurred while loading solr.xml from zookeeper\", e);\n        }\n        log.info(\"Loading solr.xml from SolrHome (not found in ZooKeeper)\");\n      }\n      cfg = SolrXmlConfig.fromSolrHome(loader, loader.getInstancePath());\n    } catch (IOException e) {\n      // do nothing.\n    }\n    return cfg;\n  }\n  \n  public CoreContainer getCores() {\n    return cores;\n  }\n  \n  @Override\n  public void destroy() {\n    try {\n      FileCleaningTracker fileCleaningTracker = SolrRequestParsers.fileCleaningTracker;\n      if (fileCleaningTracker != null) {\n        fileCleaningTracker.exitWhenFinished();\n      }\n    } catch (Exception e) {\n      log.warn(\"Exception closing FileCleaningTracker\", e);\n    } finally {\n      SolrRequestParsers.fileCleaningTracker = null;\n    }\n\n    if (metricManager != null) {\n      metricManager.unregisterGauges(registryName, metricTag);\n    }\n\n    if (cores != null) {\n      try {\n        cores.shutdown();\n      } finally {\n        cores = null;\n      }\n    }\n  }\n  \n  @Override\n  public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {\n    doFilter(request, response, chain, false);\n  }\n  \n  public void doFilter(ServletRequest _request, ServletResponse _response, FilterChain chain, boolean retry) throws IOException, ServletException {\n    if (!(_request instanceof HttpServletRequest)) return;\n    HttpServletRequest request = closeShield((HttpServletRequest)_request, retry);\n    HttpServletResponse response = closeShield((HttpServletResponse)_response, retry);\n    \n    try {\n\n      if (cores == null || cores.isShutDown()) {\n        try {\n          init.await();\n        } catch (InterruptedException e) { //well, no wait then\n        }\n        final String msg = \"Error processing the request. CoreContainer is either not initialized or shutting down.\";\n        if (cores == null || cores.isShutDown()) {\n          log.error(msg);\n          throw new UnavailableException(msg);\n        }\n      }\n\n      AtomicReference<HttpServletRequest> wrappedRequest = new AtomicReference<>();\n      if (!authenticateRequest(request, response, wrappedRequest)) { // the response and status code have already been sent\n        return;\n      }\n      if (wrappedRequest.get() != null) {\n        request = wrappedRequest.get();\n      }\n\n      if (cores.getAuthenticationPlugin() != null) {\n        log.debug(\"User principal: {}\", request.getUserPrincipal());\n      }\n\n      // No need to even create the HttpSolrCall object if this path is excluded.\n      if (excludePatterns != null) {\n        String requestPath = request.getServletPath();\n        String extraPath = request.getPathInfo();\n        if (extraPath != null) {\n          // In embedded mode, servlet path is empty - include all post-context path here for testing\n          requestPath += extraPath;\n        }\n        for (Pattern p : excludePatterns) {\n          Matcher matcher = p.matcher(requestPath);\n          if (matcher.lookingAt()) {\n            chain.doFilter(request, response);\n            return;\n          }\n        }\n      }\n\n      HttpSolrCall call = getHttpSolrCall(request, response, retry);\n      ExecutorUtil.setServerThreadFlag(Boolean.TRUE);\n      try {\n        Action result = call.call();\n        switch (result) {\n          case PASSTHROUGH:\n            chain.doFilter(request, response);\n            break;\n          case RETRY:\n            doFilter(request, response, chain, true); // RECURSION\n            break;\n          case FORWARD:\n            request.getRequestDispatcher(call.getPath()).forward(request, response);\n            break;\n          case ADMIN:\n          case PROCESS:\n          case REMOTEQUERY:\n          case RETURN:\n            break;\n        }\n      } finally {\n        call.destroy();\n        ExecutorUtil.setServerThreadFlag(null);\n      }\n    } finally {\n      consumeInputFully(request);\n    }\n  }\n  \n  // we make sure we read the full client request so that the client does\n  // not hit a connection reset and we can reuse the \n  // connection - see SOLR-8453 and SOLR-8683\n  private void consumeInputFully(HttpServletRequest req) {\n    try {\n      ServletInputStream is = req.getInputStream();\n      while (!is.isFinished() && is.read() != -1) {}\n    } catch (IOException e) {\n      log.info(\"Could not consume full client request\", e);\n    }\n  }\n  \n  /**\n   * Allow a subclass to modify the HttpSolrCall.  In particular, subclasses may\n   * want to add attributes to the request and send errors differently\n   */\n  protected HttpSolrCall getHttpSolrCall(HttpServletRequest request, HttpServletResponse response, boolean retry) {\n    String path = request.getServletPath();\n    if (request.getPathInfo() != null) {\n      // this lets you handle /update/commit when /update is a servlet\n      path += request.getPathInfo();\n    }\n\n    if (isV2Enabled && (path.startsWith(\"/____v2/\") || path.equals(\"/____v2\"))) {\n      return new V2HttpCall(this, cores, request, response, false);\n    } else {\n      return new HttpSolrCall(this, cores, request, response, retry);\n    }\n  }\n\n  private boolean authenticateRequest(HttpServletRequest request, HttpServletResponse response, final AtomicReference<HttpServletRequest> wrappedRequest) throws IOException {\n    boolean requestContinues = false;\n    final AtomicBoolean isAuthenticated = new AtomicBoolean(false);\n    AuthenticationPlugin authenticationPlugin = cores.getAuthenticationPlugin();\n    if (authenticationPlugin == null) {\n      return true;\n    } else {\n      // /admin/info/key must be always open. see SOLR-9188\n      // tests work only w/ getPathInfo\n      //otherwise it's just enough to have getServletPath()\n      if (PublicKeyHandler.PATH.equals(request.getServletPath()) ||\n          PublicKeyHandler.PATH.equals(request.getPathInfo())) return true;\n      String header = request.getHeader(PKIAuthenticationPlugin.HEADER);\n      if (header != null && cores.getPkiAuthenticationPlugin() != null)\n        authenticationPlugin = cores.getPkiAuthenticationPlugin();\n      try {\n        log.debug(\"Request to authenticate: {}, domain: {}, port: {}\", request, request.getLocalName(), request.getLocalPort());\n        // upon successful authentication, this should call the chain's next filter.\n        requestContinues = authenticationPlugin.doAuthenticate(request, response, (req, rsp) -> {\n          isAuthenticated.set(true);\n          wrappedRequest.set((HttpServletRequest) req);\n        });\n      } catch (Exception e) {\n        log.info(\"Error authenticating\", e);\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Error during request authentication, \", e);\n      }\n    }\n    // requestContinues is an optional short circuit, thus we still need to check isAuthenticated.\n    // This is because the AuthenticationPlugin doesn't always have enough information to determine if\n    // it should short circuit, e.g. the Kerberos Authentication Filter will send an error and not\n    // call later filters in chain, but doesn't throw an exception.  We could force each Plugin\n    // to implement isAuthenticated to simplify the check here, but that just moves the complexity to\n    // multiple code paths.\n    if (!requestContinues || !isAuthenticated.get()) {\n      response.flushBuffer();\n      return false;\n    }\n    return true;\n  }\n  \n  public static class ClosedServletInputStream extends ServletInputStream {\n    \n    public static final ClosedServletInputStream CLOSED_SERVLET_INPUT_STREAM = new ClosedServletInputStream();\n\n    @Override\n    public int read() {\n      return -1;\n    }\n\n    @Override\n    public boolean isFinished() {\n      return false;\n    }\n\n    @Override\n    public boolean isReady() {\n      return false;\n    }\n\n    @Override\n    public void setReadListener(ReadListener arg0) {}\n  }\n  \n  public static class ClosedServletOutputStream extends ServletOutputStream {\n    \n    public static final ClosedServletOutputStream CLOSED_SERVLET_OUTPUT_STREAM = new ClosedServletOutputStream();\n    \n    @Override\n    public void write(final int b) throws IOException {\n      throw new IOException(\"write(\" + b + \") failed: stream is closed\");\n    }\n    \n    @Override\n    public void flush() throws IOException {\n      throw new IOException(\"flush() failed: stream is closed\");\n    }\n\n    @Override\n    public boolean isReady() {\n      return false;\n    }\n\n    @Override\n    public void setWriteListener(WriteListener arg0) {\n      throw new RuntimeException(\"setWriteListener() failed: stream is closed\");\n    }\n  }\n\n  private static String CLOSE_STREAM_MSG = \"Attempted close of http request or response stream - in general you should not do this, \"\n      + \"you may spoil connection reuse and possibly disrupt a client. If you must close without actually needing to close, \"\n      + \"use a CloseShield*Stream. Closing or flushing the response stream commits the response and prevents us from modifying it. \"\n      + \"Closing the request stream prevents us from gauranteeing ourselves that streams are fully read for proper connection reuse.\"\n      + \"Let the container manage the lifecycle of these streams when possible.\";\n \n  /**\n   * Wrap the request's input stream with a close shield. If this is a\n   * retry, we will assume that the stream has already been wrapped and do nothing.\n   *\n   * Only the container should ever actually close the servlet output stream.\n   *\n   * @param request The request to wrap.\n   * @param retry If this is an original request or a retry.\n   * @return A request object with an {@link InputStream} that will ignore calls to close.\n   */\n  public static HttpServletRequest closeShield(HttpServletRequest request, boolean retry) {\n    if (!retry) {\n      return new HttpServletRequestWrapper(request) {\n\n        @Override\n        public ServletInputStream getInputStream() throws IOException {\n\n          return new ServletInputStreamWrapper(super.getInputStream()) {\n            @Override\n            public void close() {\n              // even though we skip closes, we let local tests know not to close so that a full understanding can take\n              // place\n              assert Thread.currentThread().getStackTrace()[2].getClassName().matches(\n                  \"org\\\\.apache\\\\.(?:solr|lucene).*\") ? false : true : CLOSE_STREAM_MSG;\n              this.stream = ClosedServletInputStream.CLOSED_SERVLET_INPUT_STREAM;\n            }\n          };\n\n        }\n      };\n    } else {\n      return request;\n    }\n  }\n  \n  /**\n   * Wrap the response's output stream with a close shield. If this is a\n   * retry, we will assume that the stream has already been wrapped and do nothing.\n   *\n   * Only the container should ever actually close the servlet request stream.\n   *\n   * @param response The response to wrap.\n   * @param retry If this response corresponds to an original request or a retry.\n   * @return A response object with an {@link OutputStream} that will ignore calls to close.\n   */\n  public static HttpServletResponse closeShield(HttpServletResponse response, boolean retry) {\n    if (!retry) {\n      return new HttpServletResponseWrapper(response) {\n\n        @Override\n        public ServletOutputStream getOutputStream() throws IOException {\n\n          return new ServletOutputStreamWrapper(super.getOutputStream()) {\n            @Override\n            public void close() {\n              // even though we skip closes, we let local tests know not to close so that a full understanding can take\n              // place\n              assert Thread.currentThread().getStackTrace()[2].getClassName().matches(\n                  \"org\\\\.apache\\\\.(?:solr|lucene).*\") ? false\n                      : true : CLOSE_STREAM_MSG;\n              stream = ClosedServletOutputStream.CLOSED_SERVLET_OUTPUT_STREAM;\n            }\n          };\n        }\n\n      };\n    } else {\n      return response;\n    }\n  }\n}\n", "idx": 1, "id": 27813, "msg": "In order to load static Admin UI without auth prompt, we need to move auth below check for `excludePatterns`.", "proj": "apache-lucene-solr", "lang": "java"}
{"patch": "@@ -54,18 +54,39 @@ const table_metadata& table::get_metadata() const {\n     return impl_->get_metadata();\n }\n \n+int64_t table::get_kind() const {\n+    return impl_->get_kind();\n+}\n+\n void table::init_impl(detail::table_impl_iface* impl) {\n     impl_ = pimpl { impl };\n }\n \n+int64_t homogen_table::kind() {\n+    return 1;\n+}\n+\n+homogen_table::homogen_table()\n+    : homogen_table(backend::homogen_table_impl{}) {}\n+\n template <typename DataType>\n homogen_table::homogen_table(int64_t row_count, int64_t column_count,\n                              const DataType* data_pointer,\n-                             data_layout layout)\n+                             homogen_data_layout layout)\n     : homogen_table(backend::homogen_table_impl(row_count, column_count, data_pointer, layout)) {}\n \n-template homogen_table::homogen_table(int64_t, int64_t, const float*, data_layout);\n-template homogen_table::homogen_table(int64_t, int64_t, const double*, data_layout);\n-template homogen_table::homogen_table(int64_t, int64_t, const std::int32_t*, data_layout);\n+const homogen_table_metadata& homogen_table::get_metadata() const {\n+    const auto& impl = detail::get_impl<detail::homogen_table_impl_iface>(*this);\n+    return impl.get_metadata();\n+}\n+\n+const void* homogen_table::get_data() const {\n+    const auto& impl = detail::get_impl<detail::homogen_table_impl_iface>(*this);\n+    return impl.get_data();\n+}\n+\n+template homogen_table::homogen_table(int64_t, int64_t, const float*, homogen_data_layout);\n+template homogen_table::homogen_table(int64_t, int64_t, const double*, homogen_data_layout);\n+template homogen_table::homogen_table(int64_t, int64_t, const std::int32_t*, homogen_data_layout);\n \n } // namespace oneapi::dal", "y": 1, "oldf": "/*******************************************************************************\n* Copyright 2020 Intel Corporation\n*\n* Licensed under the Apache License, Version 2.0 (the \"License\");\n* you may not use this file except in compliance with the License.\n* You may obtain a copy of the License at\n*\n*     http://www.apache.org/licenses/LICENSE-2.0\n*\n* Unless required by applicable law or agreed to in writing, software\n* distributed under the License is distributed on an \"AS IS\" BASIS,\n* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n* See the License for the specific language governing permissions and\n* limitations under the License.\n*******************************************************************************/\n\n#include \"oneapi/dal/data/backend/empty_table_impl.hpp\"\n#include \"oneapi/dal/data/backend/homogen_table_impl.hpp\"\n#include \"oneapi/dal/data/table.hpp\"\n\nusing std::int64_t;\n\nnamespace oneapi::dal {\n\ntable::table()\n    : table(backend::empty_table_impl{}) {}\n\ntable::table(table&& t)\n    : impl_(std::move(t.impl_)) {\n    using wrapper = detail::table_impl_wrapper<backend::empty_table_impl>;\n    using wrapper_ptr = detail::shared<wrapper>;\n\n    t.impl_ = wrapper_ptr(new wrapper(backend::empty_table_impl{}));\n}\n\ntable& table::operator=(table&& t) {\n    this->impl_.swap(t.impl_);\n    return *this;\n}\n\nbool table::has_data() const noexcept {\n    return impl_->get_column_count() > 0 && impl_->get_row_count() > 0;\n}\n\nint64_t table::get_column_count() const {\n    return impl_->get_column_count();\n}\n\nint64_t table::get_row_count() const {\n    return impl_->get_row_count();\n}\n\nconst table_metadata& table::get_metadata() const {\n    return impl_->get_metadata();\n}\n\nvoid table::init_impl(detail::table_impl_iface* impl) {\n    impl_ = pimpl { impl };\n}\n\ntemplate <typename DataType>\nhomogen_table::homogen_table(int64_t row_count, int64_t column_count,\n                             const DataType* data_pointer,\n                             data_layout layout)\n    : homogen_table(backend::homogen_table_impl(row_count, column_count, data_pointer, layout)) {}\n\ntemplate homogen_table::homogen_table(int64_t, int64_t, const float*, data_layout);\ntemplate homogen_table::homogen_table(int64_t, int64_t, const double*, data_layout);\ntemplate homogen_table::homogen_table(int64_t, int64_t, const std::int32_t*, data_layout);\n\n} // namespace oneapi::dal\n", "idx": 1, "id": 22326, "msg": "Current DAAL tables only support `int` for integer type. Does it mean that when used with DAAL, there will be full copying to the desired type?", "proj": "oneapi-src-oneDAL", "lang": "cpp"}
{"patch": "@@ -51,7 +51,7 @@ goog.require('goog.string');\n  * @param {?string} prototypeName Name of the language object containing\n  *     type-specific functions for this block.\n  * @param {string=} opt_id Optional ID.  Use this ID if provided, otherwise\n- *     create a new id.\n+ *     create a new ID.\n  * @constructor\n  */\n Blockly.Block = function(workspace, prototypeName, opt_id) {", "y": 0, "oldf": "/**\n * @license\n * Visual Blocks Editor\n *\n * Copyright 2011 Google Inc.\n * https://developers.google.com/blockly/\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * @fileoverview The class representing one block.\n * @author fraser@google.com (Neil Fraser)\n */\n'use strict';\n\ngoog.provide('Blockly.Block');\n\ngoog.require('Blockly.Blocks');\ngoog.require('Blockly.Colours');\ngoog.require('Blockly.Comment');\ngoog.require('Blockly.Connection');\ngoog.require('Blockly.Extensions');\ngoog.require('Blockly.FieldLabelSerializable');\ngoog.require('Blockly.FieldVariableGetter');\ngoog.require('Blockly.Input');\ngoog.require('Blockly.Mutator');\ngoog.require('Blockly.Warning');\ngoog.require('Blockly.Workspace');\ngoog.require('Blockly.Xml');\ngoog.require('goog.array');\ngoog.require('goog.asserts');\ngoog.require('goog.math.Coordinate');\ngoog.require('goog.string');\n\n\n/**\n * Class for one block.\n * Not normally called directly, workspace.newBlock() is preferred.\n * @param {!Blockly.Workspace} workspace The block's workspace.\n * @param {?string} prototypeName Name of the language object containing\n *     type-specific functions for this block.\n * @param {string=} opt_id Optional ID.  Use this ID if provided, otherwise\n *     create a new id.\n * @constructor\n */\nBlockly.Block = function(workspace, prototypeName, opt_id) {\n  var flyoutWorkspace = workspace && workspace.getFlyout && workspace.getFlyout() ?\n     workspace.getFlyout().getWorkspace() : null;\n  /** @type {string} */\n  this.id = (opt_id && !workspace.getBlockById(opt_id) &&\n      (!flyoutWorkspace || !flyoutWorkspace.getBlockById(opt_id))) ?\n      opt_id : Blockly.utils.genUid();\n  workspace.blockDB_[this.id] = this;\n  /** @type {Blockly.Connection} */\n  this.outputConnection = null;\n  /** @type {Blockly.Connection} */\n  this.nextConnection = null;\n  /** @type {Blockly.Connection} */\n  this.previousConnection = null;\n  /** @type {!Array.<!Blockly.Input>} */\n  this.inputList = [];\n  /** @type {boolean|undefined} */\n  this.inputsInline = true;\n  /** @type {boolean} */\n  this.disabled = false;\n  /** @type {string|!Function} */\n  this.tooltip = '';\n  /** @type {boolean} */\n  this.contextMenu = true;\n\n  /**\n   * @type {Blockly.Block}\n   * @protected\n   */\n  this.parentBlock_ = null;\n\n  /**\n   * @type {!Array.<!Blockly.Block>}\n   * @protected\n   */\n  this.childBlocks_ = [];\n\n  /**\n   * @type {boolean}\n   * @private\n   */\n  this.deletable_ = true;\n\n  /**\n   * @type {boolean}\n   * @private\n   */\n  this.movable_ = true;\n\n  /**\n   * @type {boolean}\n   * @private\n   */\n  this.editable_ = true;\n\n  /**\n   * @type {boolean}\n   * @private\n   */\n  this.isShadow_ = false;\n\n  /**\n   * @type {boolean}\n   * @protected\n   */\n  this.collapsed_ = false;\n\n  /**\n   * @type {boolean}\n   * @private\n   */\n  this.checkboxInFlyout_ = false;\n\n  /** @type {string|Blockly.Comment} */\n  this.comment = null;\n\n  /**\n   * @type {?number}\n   * @private\n   */\n  this.outputShape_ = null;\n\n  /**\n   * @type {?string}\n   * @private\n   */\n  this.category_ = null;\n\n  /**\n   * The block's position in workspace units.  (0, 0) is at the workspace's\n   * origin; scale does not change this value.\n   * @type {!goog.math.Coordinate}\n   * @private\n   */\n  this.xy_ = new goog.math.Coordinate(0, 0);\n\n  /** @type {!Blockly.Workspace} */\n  this.workspace = workspace;\n  /** @type {boolean} */\n  this.isInFlyout = workspace.isFlyout;\n  /** @type {boolean} */\n  this.isInMutator = workspace.isMutator;\n\n  /** @type {boolean} */\n  this.RTL = workspace.RTL;\n\n  /** @type {boolean} */\n  this.isInsertionMarker_ = false;\n\n  // Copy the type-specific functions and data from the prototype.\n  if (prototypeName) {\n    /** @type {string} */\n    this.type = prototypeName;\n    var prototype = Blockly.Blocks[prototypeName];\n    goog.asserts.assertObject(prototype,\n        'Error: Unknown block type \"%s\".', prototypeName);\n    goog.mixin(this, prototype);\n  }\n\n  workspace.addTopBlock(this);\n\n  // Call an initialization function, if it exists.\n  if (goog.isFunction(this.init)) {\n    this.init();\n  }\n  // Record initial inline state.\n  /** @type {boolean|undefined} */\n  this.inputsInlineDefault = this.inputsInline;\n\n  // Fire a create event.\n  if (Blockly.Events.isEnabled()) {\n    var existingGroup = Blockly.Events.getGroup();\n    if (!existingGroup) {\n      Blockly.Events.setGroup(true);\n    }\n    try {\n      Blockly.Events.fire(new Blockly.Events.BlockCreate(this));\n    } finally {\n      if (!existingGroup) {\n        Blockly.Events.setGroup(false);\n      }\n    }\n\n  }\n  // Bind an onchange function, if it exists.\n  if (goog.isFunction(this.onchange)) {\n    this.setOnChange(this.onchange);\n  }\n};\n\n/**\n * Optional text data that round-trips beween blocks and XML.\n * Has no effect. May be used by 3rd parties for meta information.\n * @type {?string}\n */\nBlockly.Block.prototype.data = null;\n\n/**\n * Colour of the block in '#RRGGBB' format.\n * @type {string}\n * @private\n */\nBlockly.Block.prototype.colour_ = '#FF0000';\n\n/**\n * Secondary colour of the block in '#RRGGBB' format.\n * @type {string}\n * @private\n */\nBlockly.Block.prototype.colourSecondary_ = '#FF0000';\n\n/**\n * Tertiary colour of the block in '#RRGGBB' format.\n * @type {string}\n * @private\n */\nBlockly.Block.prototype.colourTertiary_ = '#FF0000';\n\n/**\n * Dispose of this block.\n * @param {boolean} healStack If true, then try to heal any gap by connecting\n *     the next statement with the previous statement.  Otherwise, dispose of\n *     all children of this block.\n */\nBlockly.Block.prototype.dispose = function(healStack) {\n  if (!this.workspace) {\n    // Already deleted.\n    return;\n  }\n  // Terminate onchange event calls.\n  if (this.onchangeWrapper_) {\n    this.workspace.removeChangeListener(this.onchangeWrapper_);\n  }\n  this.unplug(healStack);\n  if (Blockly.Events.isEnabled()) {\n    Blockly.Events.fire(new Blockly.Events.BlockDelete(this));\n  }\n  Blockly.Events.disable();\n\n  try {\n    // This block is now at the top of the workspace.\n    // Remove this block from the workspace's list of top-most blocks.\n    if (this.workspace) {\n      this.workspace.removeTopBlock(this);\n      // Remove from block database.\n      delete this.workspace.blockDB_[this.id];\n      this.workspace = null;\n    }\n\n    // Just deleting this block from the DOM would result in a memory leak as\n    // well as corruption of the connection database.  Therefore we must\n    // methodically step through the blocks and carefully disassemble them.\n\n    if (Blockly.selected == this) {\n      Blockly.selected = null;\n    }\n\n    // First, dispose of all my children.\n    for (var i = this.childBlocks_.length - 1; i >= 0; i--) {\n      this.childBlocks_[i].dispose(false);\n    }\n    // Then dispose of myself.\n    // Dispose of all inputs and their fields.\n    for (var i = 0, input; input = this.inputList[i]; i++) {\n      input.dispose();\n    }\n    this.inputList.length = 0;\n    // Dispose of any remaining connections (next/previous/output).\n    var connections = this.getConnections_(true);\n    for (var i = 0; i < connections.length; i++) {\n      var connection = connections[i];\n      if (connection.isConnected()) {\n        connection.disconnect();\n      }\n      connections[i].dispose();\n    }\n  } finally {\n    Blockly.Events.enable();\n  }\n};\n\n/**\n * Call initModel on all fields on the block.\n * May be called more than once.\n * Either initModel or initSvg must be called after creating a block and before\n * the first interaction with it.  Interactions include UI actions\n * (e.g. clicking and dragging) and firing events (e.g. create, delete, and\n * change).\n * @public\n */\nBlockly.Block.prototype.initModel = function() {\n  for (var i = 0, input; input = this.inputList[i]; i++) {\n    for (var j = 0, field; field = input.fieldRow[j]; j++) {\n      if (field.initModel) {\n        field.initModel();\n      }\n    }\n  }\n};\n\n/**\n * Unplug this block from its superior block.  If this block is a statement,\n * optionally reconnect the block underneath with the block on top.\n * @param {boolean=} opt_healStack Disconnect child statement and reconnect\n *   stack.  Defaults to false.\n */\nBlockly.Block.prototype.unplug = function(opt_healStack) {\n  if (this.outputConnection) {\n    if (this.outputConnection.isConnected()) {\n      // Disconnect from any superior block.\n      this.outputConnection.disconnect();\n    }\n  } else if (this.previousConnection) {\n    var previousTarget = null;\n    if (this.previousConnection.isConnected()) {\n      // Remember the connection that any next statements need to connect to.\n      previousTarget = this.previousConnection.targetConnection;\n      // Detach this block from the parent's tree.\n      this.previousConnection.disconnect();\n    }\n    var nextBlock = this.getNextBlock();\n    if (opt_healStack && nextBlock) {\n      // Disconnect the next statement.\n      var nextTarget = this.nextConnection.targetConnection;\n      nextTarget.disconnect();\n      if (previousTarget && previousTarget.checkType_(nextTarget)) {\n        // Attach the next statement to the previous statement.\n        previousTarget.connect(nextTarget);\n      }\n    }\n  }\n};\n\n/**\n * Returns all connections originating from this block.\n * @return {!Array.<!Blockly.Connection>} Array of connections.\n * @private\n */\nBlockly.Block.prototype.getConnections_ = function() {\n  var myConnections = [];\n  if (this.outputConnection) {\n    myConnections.push(this.outputConnection);\n  }\n  if (this.previousConnection) {\n    myConnections.push(this.previousConnection);\n  }\n  if (this.nextConnection) {\n    myConnections.push(this.nextConnection);\n  }\n  for (var i = 0, input; input = this.inputList[i]; i++) {\n    if (input.connection) {\n      myConnections.push(input.connection);\n    }\n  }\n  return myConnections;\n};\n\n/**\n * Walks down a stack of blocks and finds the last next connection on the stack.\n * @return {Blockly.Connection} The last next connection on the stack, or null.\n * @package\n */\nBlockly.Block.prototype.lastConnectionInStack = function() {\n  var nextConnection = this.nextConnection;\n  while (nextConnection) {\n    var nextBlock = nextConnection.targetBlock();\n    if (!nextBlock) {\n      // Found a next connection with nothing on the other side.\n      return nextConnection;\n    }\n    nextConnection = nextBlock.nextConnection;\n  }\n  // Ran out of next connections.\n  return null;\n};\n\n/**\n * Bump unconnected blocks out of alignment.  Two blocks which aren't actually\n * connected should not coincidentally line up on screen.\n * @protected\n */\nBlockly.Block.prototype.bumpNeighbours_ = function() {\n  console.warn('Not expected to reach this bumpNeighbours_ function. The ' +\n    'BlockSvg function for bumpNeighbours_ was expected to be called instead.');\n};\n\n/**\n * Return the parent block or null if this block is at the top level.\n * @return {Blockly.Block} The block that holds the current block.\n */\nBlockly.Block.prototype.getParent = function() {\n  // Look at the DOM to see if we are nested in another block.\n  return this.parentBlock_;\n};\n\n/**\n * Return the input that connects to the specified block.\n * @param {!Blockly.Block} block A block connected to an input on this block.\n * @return {Blockly.Input} The input that connects to the specified block.\n */\nBlockly.Block.prototype.getInputWithBlock = function(block) {\n  for (var i = 0, input; input = this.inputList[i]; i++) {\n    if (input.connection && input.connection.targetBlock() == block) {\n      return input;\n    }\n  }\n  return null;\n};\n\n/**\n * Return the input that contains the specified connection\n * @param {!Blockly.Connection} conn A connection on this block.\n * @return {Blockly.Input} The input that contains the specified connection.\n */\nBlockly.Block.prototype.getInputWithConnection = function(conn) {\n  for (var i = 0, input; input = this.inputList[i]; i++) {\n    if (input.connection == conn) {\n      return input;\n    }\n  }\n  return null;\n};\n\n/**\n * Return the parent block that surrounds the current block, or null if this\n * block has no surrounding block.  A parent block might just be the previous\n * statement, whereas the surrounding block is an if statement, while loop, etc.\n * @return {Blockly.Block} The block that surrounds the current block.\n */\nBlockly.Block.prototype.getSurroundParent = function() {\n  var block = this;\n  do {\n    var prevBlock = block;\n    block = block.getParent();\n    if (!block) {\n      // Ran off the top.\n      return null;\n    }\n  } while (block.getNextBlock() == prevBlock);\n  // This block is an enclosing parent, not just a statement in a stack.\n  return block;\n};\n\n/**\n * Return the next statement block directly connected to this block.\n * @return {Blockly.Block} The next statement block or null.\n */\nBlockly.Block.prototype.getNextBlock = function() {\n  return this.nextConnection && this.nextConnection.targetBlock();\n};\n\n/**\n * Return the previous statement block directly connected to this block.\n * @return {Blockly.Block} The previous statement block or null.\n */\nBlockly.Block.prototype.getPreviousBlock = function() {\n  return this.previousConnection && this.previousConnection.targetBlock();\n};\n\n/**\n * Return the connection on the first statement input on this block, or null if\n * there are none.\n * @return {Blockly.Connection} The first statement connection or null.\n */\nBlockly.Block.prototype.getFirstStatementConnection = function() {\n  for (var i = 0, input; input = this.inputList[i]; i++) {\n    if (input.connection && input.connection.type == Blockly.NEXT_STATEMENT) {\n      return input.connection;\n    }\n  }\n  return null;\n};\n\n/**\n * Return the top-most block in this block's tree.\n * This will return itself if this block is at the top level.\n * @return {!Blockly.Block} The root block.\n */\nBlockly.Block.prototype.getRootBlock = function() {\n  var rootBlock;\n  var block = this;\n  do {\n    rootBlock = block;\n    block = rootBlock.parentBlock_;\n  } while (block);\n  return rootBlock;\n};\n\n/**\n * Find all the blocks that are directly nested inside this one.\n * Includes value and block inputs, as well as any following statement.\n * Excludes any connection on an output tab or any preceding statement.\n * @return {!Array.<!Blockly.Block>} Array of blocks.\n */\nBlockly.Block.prototype.getChildren = function() {\n  return this.childBlocks_;\n};\n\n/**\n * Set parent of this block to be a new block or null.\n * @param {Blockly.Block} newParent New parent block.\n */\nBlockly.Block.prototype.setParent = function(newParent) {\n  if (newParent == this.parentBlock_) {\n    return;\n  }\n  if (this.parentBlock_) {\n    // Remove this block from the old parent's child list.\n    goog.array.remove(this.parentBlock_.childBlocks_, this);\n\n    // Disconnect from superior blocks.\n    if (this.previousConnection && this.previousConnection.isConnected()) {\n      throw 'Still connected to previous block.';\n    }\n    if (this.outputConnection && this.outputConnection.isConnected()) {\n      throw 'Still connected to parent block.';\n    }\n    this.parentBlock_ = null;\n    // This block hasn't actually moved on-screen, so there's no need to update\n    // its connection locations.\n  } else {\n    // Remove this block from the workspace's list of top-most blocks.\n    this.workspace.removeTopBlock(this);\n  }\n\n  this.parentBlock_ = newParent;\n  if (newParent) {\n    // Add this block to the new parent's child list.\n    newParent.childBlocks_.push(this);\n  } else {\n    this.workspace.addTopBlock(this);\n  }\n};\n\n/**\n * Find all the blocks that are directly or indirectly nested inside this one.\n * Includes this block in the list.\n * Includes value and block inputs, as well as any following statements.\n * Excludes any connection on an output tab or any preceding statements.\n * @param {boolean=} opt_ignoreShadows If set, don't include shadow blocks.\n * @return {!Array.<!Blockly.Block>} Flattened array of blocks.\n */\nBlockly.Block.prototype.getDescendants = function(opt_ignoreShadows) {\n  var blocks = [this];\n  for (var child, x = 0; child = this.childBlocks_[x]; x++) {\n    if (!opt_ignoreShadows || !child.isShadow_) {\n      blocks.push.apply(blocks, child.getDescendants(opt_ignoreShadows));\n    }\n  }\n  return blocks;\n};\n\n/**\n * Get whether this block is deletable or not.\n * @return {boolean} True if deletable.\n */\nBlockly.Block.prototype.isDeletable = function() {\n  return this.deletable_ && !this.isShadow_ &&\n      !(this.workspace && this.workspace.options.readOnly);\n};\n\n/**\n * Set whether this block is deletable or not.\n * @param {boolean} deletable True if deletable.\n */\nBlockly.Block.prototype.setDeletable = function(deletable) {\n  this.deletable_ = deletable;\n};\n\n/**\n * Get whether this block is movable or not.\n * @return {boolean} True if movable.\n */\nBlockly.Block.prototype.isMovable = function() {\n  return this.movable_ && !this.isShadow_ &&\n      !(this.workspace && this.workspace.options.readOnly);\n};\n\n/**\n * Set whether this block is movable or not.\n * @param {boolean} movable True if movable.\n */\nBlockly.Block.prototype.setMovable = function(movable) {\n  this.movable_ = movable;\n};\n\n/**\n * Get whether this block is a shadow block or not.\n * @return {boolean} True if a shadow.\n */\nBlockly.Block.prototype.isShadow = function() {\n  return this.isShadow_;\n};\n\n/**\n * Set whether this block is a shadow block or not.\n * @param {boolean} shadow True if a shadow.\n */\nBlockly.Block.prototype.setShadow = function(shadow) {\n  this.isShadow_ = shadow;\n};\n\n/**\n * Get whether this block is an insertion marker block or not.\n * @return {boolean} True if an insertion marker.\n */\nBlockly.Block.prototype.isInsertionMarker = function() {\n  return this.isInsertionMarker_;\n};\n\n/**\n * Set whether this block is an insertion marker block or not.\n * @param {boolean} insertionMarker True if an insertion marker.\n */\nBlockly.Block.prototype.setInsertionMarker = function(insertionMarker) {\n  if (this.isInsertionMarker_ == insertionMarker) {\n    return;  // No change.\n  }\n  this.isInsertionMarker_ = insertionMarker;\n  // TODO: handle removing insertion marker status.\n  if (this.isInsertionMarker_) {\n    this.setColour(Blockly.Colours.insertionMarker);\n    this.setOpacity(Blockly.Colours.insertionMarkerOpacity);\n    Blockly.utils.addClass(/** @type {!Element} */ (this.svgGroup_),\n        'blocklyInsertionMarker');\n  }\n};\n\n/**\n * Get whether this block is editable or not.\n * @return {boolean} True if editable.\n */\nBlockly.Block.prototype.isEditable = function() {\n  return this.editable_ && !(this.workspace && this.workspace.options.readOnly);\n};\n\n/**\n * Set whether this block is editable or not.\n * @param {boolean} editable True if editable.\n */\nBlockly.Block.prototype.setEditable = function(editable) {\n  this.editable_ = editable;\n  for (var i = 0, input; input = this.inputList[i]; i++) {\n    for (var j = 0, field; field = input.fieldRow[j]; j++) {\n      field.updateEditable();\n    }\n  }\n};\n\n/**\n * Set whether the connections are hidden (not tracked in a database) or not.\n * Recursively walk down all child blocks (except collapsed blocks).\n * @param {boolean} hidden True if connections are hidden.\n */\nBlockly.Block.prototype.setConnectionsHidden = function(hidden) {\n  if (!hidden && this.isCollapsed()) {\n    if (this.outputConnection) {\n      this.outputConnection.setHidden(hidden);\n    }\n    if (this.previousConnection) {\n      this.previousConnection.setHidden(hidden);\n    }\n    if (this.nextConnection) {\n      this.nextConnection.setHidden(hidden);\n      var child = this.nextConnection.targetBlock();\n      if (child) {\n        child.setConnectionsHidden(hidden);\n      }\n    }\n  } else {\n    var myConnections = this.getConnections_(true);\n    for (var i = 0, connection; connection = myConnections[i]; i++) {\n      connection.setHidden(hidden);\n      if (connection.isSuperior()) {\n        var child = connection.targetBlock();\n        if (child) {\n          child.setConnectionsHidden(hidden);\n        }\n      }\n    }\n  }\n};\n\n/**\n * Find the connection on this block that corresponds to the given connection\n * on the other block.\n * Used to match connections between a block and its insertion marker.\n * @param {!Blockly.Block} otherBlock The other block to match against.\n * @param {!Blockly.Connection} conn The other connection to match.\n * @return {Blockly.Connection} the matching connection on this block, or null.\n */\nBlockly.Block.prototype.getMatchingConnection = function(otherBlock, conn) {\n  var connections = this.getConnections_(true);\n  var otherConnections = otherBlock.getConnections_(true);\n  if (connections.length != otherConnections.length) {\n    throw \"Connection lists did not match in length.\";\n  }\n  for (var i = 0; i < otherConnections.length; i++) {\n    if (otherConnections[i] == conn) {\n      return connections[i];\n    }\n  }\n  return null;\n};\n\n/**\n * Set the URL of this block's help page.\n * @param {string|Function} url URL string for block help, or function that\n *     returns a URL.  Null for no help.\n */\nBlockly.Block.prototype.setHelpUrl = function(url) {\n  this.helpUrl = url;\n};\n\n/**\n * Change the tooltip text for a block.\n * @param {string|!Function} newTip Text for tooltip or a parent element to\n *     link to for its tooltip.  May be a function that returns a string.\n */\nBlockly.Block.prototype.setTooltip = function(newTip) {\n  this.tooltip = newTip;\n};\n\n/**\n * Get the colour of a block.\n * @return {string} #RRGGBB string.\n */\nBlockly.Block.prototype.getColour = function() {\n  return this.colour_;\n};\n\n/**\n * Get the secondary colour of a block.\n * @return {string} #RRGGBB string.\n */\nBlockly.Block.prototype.getColourSecondary = function() {\n  return this.colourSecondary_;\n};\n\n/**\n * Get the tertiary colour of a block.\n * @return {string} #RRGGBB string.\n */\nBlockly.Block.prototype.getColourTertiary = function() {\n  return this.colourTertiary_;\n};\n\n/**\n* Create an #RRGGBB string colour from a colour HSV hue value or #RRGGBB string.\n* @param {number|string} colour HSV hue value, or #RRGGBB string.\n* @return {string} #RRGGBB string.\n* @private\n*/\nBlockly.Block.prototype.makeColour_ = function(colour) {\n  var hue = Number(colour);\n  if (!isNaN(hue)) {\n    return Blockly.hueToRgb(hue);\n  } else if (goog.isString(colour) && colour.match(/^#[0-9a-fA-F]{6}$/)) {\n    return colour;\n  } else {\n    throw 'Invalid colour: ' + colour;\n  }\n};\n\n/**\n * Change the colour of a block, and optional secondary/teriarty colours.\n * @param {number|string} colour HSV hue value, or #RRGGBB string.\n * @param {number|string} colourSecondary HSV hue value, or #RRGGBB string.\n * @param {number|string} colourTertiary HSV hue value, or #RRGGBB string.\n */\nBlockly.Block.prototype.setColour = function(colour, colourSecondary, colourTertiary) {\n  this.colour_ = this.makeColour_(colour);\n  if (colourSecondary !== undefined) {\n    this.colourSecondary_ = this.makeColour_(colourSecondary);\n  } else {\n    this.colourSecondary_ = goog.color.rgbArrayToHex(\n        goog.color.darken(goog.color.hexToRgb(this.colour_),\n        0.1));\n  }\n  if (colourTertiary !== undefined) {\n    this.colourTertiary_ = this.makeColour_(colourTertiary);\n  } else {\n    this.colourTertiary_ = goog.color.rgbArrayToHex(\n        goog.color.darken(goog.color.hexToRgb(this.colour_),\n        0.2));\n  }\n  if (this.rendered) {\n    this.updateColour();\n  }\n};\n\n/**\n * Sets a callback function to use whenever the block's parent workspace\n * changes, replacing any prior onchange handler. This is usually only called\n * from the constructor, the block type initializer function, or an extension\n * initializer function.\n * @param {function(Blockly.Events.Abstract)} onchangeFn The callback to call\n *     when the block's workspace changes.\n * @throws {Error} if onchangeFn is not falsey or a function.\n */\nBlockly.Block.prototype.setOnChange = function(onchangeFn) {\n  if (onchangeFn && !goog.isFunction(onchangeFn)) {\n    throw new Error(\"onchange must be a function.\");\n  }\n  if (this.onchangeWrapper_) {\n    this.workspace.removeChangeListener(this.onchangeWrapper_);\n  }\n  this.onchange = onchangeFn;\n  if (this.onchange) {\n    this.onchangeWrapper_ = onchangeFn.bind(this);\n    this.workspace.addChangeListener(this.onchangeWrapper_);\n  }\n};\n\n/**\n * Returns the named field from a block.\n * @param {string} name The name of the field.\n * @return {Blockly.Field} Named field, or null if field does not exist.\n */\nBlockly.Block.prototype.getField = function(name) {\n  for (var i = 0, input; input = this.inputList[i]; i++) {\n    for (var j = 0, field; field = input.fieldRow[j]; j++) {\n      if (field.name === name) {\n        return field;\n      }\n    }\n  }\n  return null;\n};\n\n/**\n * Return all variables referenced by this block.\n * @return {!Array.<string>} List of variable names.\n * @package\n */\nBlockly.Block.prototype.getVars = function() {\n  var vars = [];\n  for (var i = 0, input; input = this.inputList[i]; i++) {\n    for (var j = 0, field; field = input.fieldRow[j]; j++) {\n      if (field.referencesVariables()) {\n        vars.push(field.getValue());\n      }\n    }\n  }\n  return vars;\n};\n\n/**\n * Return all variables referenced by this block.\n * @return {!Array.<!Blockly.VariableModel>} List of variable models.\n * @package\n */\nBlockly.Block.prototype.getVarModels = function() {\n  var vars = [];\n  for (var i = 0, input; input = this.inputList[i]; i++) {\n    for (var j = 0, field; field = input.fieldRow[j]; j++) {\n      if (field.referencesVariables()) {\n        var model = this.workspace.getVariableById(field.getValue());\n        // Check if the variable actually exists (and isn't just a potential\n        // variable).\n        if (model) {\n          vars.push(model);\n        }\n      }\n    }\n  }\n  return vars;\n};\n\n/**\n * Notification that a variable is renaming but keeping the same ID.  If the\n * variable is in use on this block, rerender to show the new name.\n * @param {!Blockly.VariableModel} variable The variable being renamed.\n * @package\n */\nBlockly.Block.prototype.updateVarName = function(variable) {\n  for (var i = 0, input; input = this.inputList[i]; i++) {\n    for (var j = 0, field; field = input.fieldRow[j]; j++) {\n      if (field.referencesVariables() &&\n          variable.getId() == field.getValue()) {\n        field.setText(variable.name);\n      }\n    }\n  }\n};\n\n/**\n * Notification that a variable is renaming.\n * If the ID matches one of this block's variables, rename it.\n * @param {string} oldId ID of variable to rename.\n * @param {string} newId ID of new variable.  May be the same as oldId, but with\n *     an updated name.\n */\nBlockly.Block.prototype.renameVarById = function(oldId, newId) {\n  for (var i = 0, input; input = this.inputList[i]; i++) {\n    for (var j = 0, field; field = input.fieldRow[j]; j++) {\n      if (field.referencesVariables() &&\n          oldId == field.getValue()) {\n        field.setValue(newId);\n      }\n    }\n  }\n};\n\n/**\n * Returns the language-neutral value from the field of a block.\n * @param {string} name The name of the field.\n * @return {?string} Value from the field or null if field does not exist.\n */\nBlockly.Block.prototype.getFieldValue = function(name) {\n  var field = this.getField(name);\n  if (field) {\n    return field.getValue();\n  }\n  return null;\n};\n\n/**\n * Change the field value for a block (e.g. 'CHOOSE' or 'REMOVE').\n * @param {string} newValue Value to be the new field.\n * @param {string} name The name of the field.\n */\nBlockly.Block.prototype.setFieldValue = function(newValue, name) {\n  var field = this.getField(name);\n  goog.asserts.assertObject(field, 'Field \"%s\" not found.', name);\n  field.setValue(newValue);\n};\n\n/**\n * Set whether this block can chain onto the bottom of another block.\n * @param {boolean} newBoolean True if there can be a previous statement.\n * @param {(string|Array.<string>|null)=} opt_check Statement type or\n *     list of statement types.  Null/undefined if any type could be connected.\n */\nBlockly.Block.prototype.setPreviousStatement = function(newBoolean, opt_check) {\n  if (newBoolean) {\n    if (opt_check === undefined) {\n      opt_check = null;\n    }\n    if (!this.previousConnection) {\n      goog.asserts.assert(!this.outputConnection,\n          'Remove output connection prior to adding previous connection.');\n      this.previousConnection =\n          this.makeConnection_(Blockly.PREVIOUS_STATEMENT);\n    }\n    this.previousConnection.setCheck(opt_check);\n  } else {\n    if (this.previousConnection) {\n      goog.asserts.assert(!this.previousConnection.isConnected(),\n          'Must disconnect previous statement before removing connection.');\n      this.previousConnection.dispose();\n      this.previousConnection = null;\n    }\n  }\n};\n\n/**\n * Set whether another block can chain onto the bottom of this block.\n * @param {boolean} newBoolean True if there can be a next statement.\n * @param {(string|Array.<string>|null)=} opt_check Statement type or\n *     list of statement types.  Null/undefined if any type could be connected.\n */\nBlockly.Block.prototype.setNextStatement = function(newBoolean, opt_check) {\n  if (newBoolean) {\n    if (opt_check === undefined) {\n      opt_check = null;\n    }\n    if (!this.nextConnection) {\n      this.nextConnection = this.makeConnection_(Blockly.NEXT_STATEMENT);\n    }\n    this.nextConnection.setCheck(opt_check);\n  } else {\n    if (this.nextConnection) {\n      goog.asserts.assert(!this.nextConnection.isConnected(),\n          'Must disconnect next statement before removing connection.');\n      this.nextConnection.dispose();\n      this.nextConnection = null;\n    }\n  }\n};\n\n/**\n * Set whether this block returns a value.\n * @param {boolean} newBoolean True if there is an output.\n * @param {(string|Array.<string>|null)=} opt_check Returned type or list\n *     of returned types.  Null or undefined if any type could be returned\n *     (e.g. variable get).\n */\nBlockly.Block.prototype.setOutput = function(newBoolean, opt_check) {\n  if (newBoolean) {\n    if (opt_check === undefined) {\n      opt_check = null;\n    }\n    if (!this.outputConnection) {\n      goog.asserts.assert(!this.previousConnection,\n          'Remove previous connection prior to adding output connection.');\n      this.outputConnection = this.makeConnection_(Blockly.OUTPUT_VALUE);\n    }\n    this.outputConnection.setCheck(opt_check);\n  } else {\n    if (this.outputConnection) {\n      goog.asserts.assert(!this.outputConnection.isConnected(),\n          'Must disconnect output value before removing connection.');\n      this.outputConnection.dispose();\n      this.outputConnection = null;\n    }\n  }\n};\n\n/**\n * Set whether value inputs are arranged horizontally or vertically.\n * @param {boolean} newBoolean True if inputs are horizontal.\n */\nBlockly.Block.prototype.setInputsInline = function(newBoolean) {\n  if (this.inputsInline != newBoolean) {\n    Blockly.Events.fire(new Blockly.Events.BlockChange(\n        this, 'inline', null, this.inputsInline, newBoolean));\n    this.inputsInline = newBoolean;\n  }\n};\n\n/**\n * Get whether value inputs are arranged horizontally or vertically.\n * @return {boolean} True if inputs are horizontal.\n */\nBlockly.Block.prototype.getInputsInline = function() {\n  if (this.inputsInline != undefined) {\n    // Set explicitly.\n    return this.inputsInline;\n  }\n  // Not defined explicitly.  Figure out what would look best.\n  for (var i = 1; i < this.inputList.length; i++) {\n    if (this.inputList[i - 1].type == Blockly.DUMMY_INPUT &&\n        this.inputList[i].type == Blockly.DUMMY_INPUT) {\n      // Two dummy inputs in a row.  Don't inline them.\n      return false;\n    }\n  }\n  for (var i = 1; i < this.inputList.length; i++) {\n    if (this.inputList[i - 1].type == Blockly.INPUT_VALUE &&\n        this.inputList[i].type == Blockly.DUMMY_INPUT) {\n      // Dummy input after a value input.  Inline them.\n      return true;\n    }\n  }\n  return false;\n};\n\n/**\n * Set whether the block is disabled or not.\n * @param {boolean} disabled True if disabled.\n */\nBlockly.Block.prototype.setDisabled = function(disabled) {\n  if (this.disabled != disabled) {\n    Blockly.Events.fire(new Blockly.Events.BlockChange(\n        this, 'disabled', null, this.disabled, disabled));\n    this.disabled = disabled;\n  }\n};\n\n/**\n * Get whether the block is disabled or not due to parents.\n * The block's own disabled property is not considered.\n * @return {boolean} True if disabled.\n */\nBlockly.Block.prototype.getInheritedDisabled = function() {\n  var ancestor = this.getSurroundParent();\n  while (ancestor) {\n    if (ancestor.disabled) {\n      return true;\n    }\n    ancestor = ancestor.getSurroundParent();\n  }\n  // Ran off the top.\n  return false;\n};\n\n/**\n * Get whether the block is collapsed or not.\n * @return {boolean} True if collapsed.\n */\nBlockly.Block.prototype.isCollapsed = function() {\n  return this.collapsed_;\n};\n\n/**\n * Set whether the block is collapsed or not.\n * @param {boolean} collapsed True if collapsed.\n */\nBlockly.Block.prototype.setCollapsed = function(collapsed) {\n  if (this.collapsed_ != collapsed) {\n    Blockly.Events.fire(new Blockly.Events.BlockChange(\n        this, 'collapsed', null, this.collapsed_, collapsed));\n    this.collapsed_ = collapsed;\n  }\n};\n\n/**\n * Create a human-readable text representation of this block and any children.\n * @param {number=} opt_maxLength Truncate the string to this length.\n * @param {string=} opt_emptyToken The placeholder string used to denote an\n *     empty field. If not specified, '?' is used.\n * @return {string} Text of block.\n */\nBlockly.Block.prototype.toString = function(opt_maxLength, opt_emptyToken) {\n  var text = [];\n  var emptyFieldPlaceholder = opt_emptyToken || '?';\n  if (this.collapsed_) {\n    text.push(this.getInput('_TEMP_COLLAPSED_INPUT').fieldRow[0].text_);\n  } else {\n    for (var i = 0, input; input = this.inputList[i]; i++) {\n      for (var j = 0, field; field = input.fieldRow[j]; j++) {\n        if (field instanceof Blockly.FieldDropdown && !field.getValue()) {\n          text.push(emptyFieldPlaceholder);\n        } else {\n          text.push(field.getText());\n        }\n      }\n      if (input.connection) {\n        var child = input.connection.targetBlock();\n        if (child) {\n          text.push(child.toString(undefined, opt_emptyToken));\n        } else {\n          text.push(emptyFieldPlaceholder);\n        }\n      }\n    }\n  }\n  text = goog.string.trim(text.join(' ')) || '???';\n  if (opt_maxLength) {\n    // TODO: Improve truncation so that text from this block is given priority.\n    // E.g. \"1+2+3+4+5+6+7+8+9=0\" should be \"...6+7+8+9=0\", not \"1+2+3+4+5...\".\n    // E.g. \"1+2+3+4+5=6+7+8+9+0\" should be \"...4+5=6+7...\".\n    text = goog.string.truncate(text, opt_maxLength);\n  }\n  return text;\n};\n\n/**\n * Shortcut for appending a value input row.\n * @param {string} name Language-neutral identifier which may used to find this\n *     input again.  Should be unique to this block.\n * @return {!Blockly.Input} The input object created.\n */\nBlockly.Block.prototype.appendValueInput = function(name) {\n  return this.appendInput_(Blockly.INPUT_VALUE, name);\n};\n\n/**\n * Shortcut for appending a statement input row.\n * @param {string} name Language-neutral identifier which may used to find this\n *     input again.  Should be unique to this block.\n * @return {!Blockly.Input} The input object created.\n */\nBlockly.Block.prototype.appendStatementInput = function(name) {\n  return this.appendInput_(Blockly.NEXT_STATEMENT, name);\n};\n\n/**\n * Shortcut for appending a dummy input row.\n * @param {string=} opt_name Language-neutral identifier which may used to find\n *     this input again.  Should be unique to this block.\n * @return {!Blockly.Input} The input object created.\n */\nBlockly.Block.prototype.appendDummyInput = function(opt_name) {\n  return this.appendInput_(Blockly.DUMMY_INPUT, opt_name || '');\n};\n\n/**\n * Initialize this block using a cross-platform, internationalization-friendly\n * JSON description.\n * @param {!Object} json Structured data describing the block.\n */\nBlockly.Block.prototype.jsonInit = function(json) {\n\n  // Validate inputs.\n  goog.asserts.assert(json['output'] == undefined ||\n      json['previousStatement'] == undefined,\n      'Must not have both an output and a previousStatement.');\n\n  // Set basic properties of block.\n  if (json['colour'] !== undefined) {\n    this.setColourFromJson_(json);\n  }\n\n  // Interpolate the message blocks.\n  var i = 0;\n  while (json['message' + i] !== undefined) {\n    this.interpolate_(json['message' + i], json['args' + i] || [],\n        json['lastDummyAlign' + i]);\n    i++;\n  }\n\n  if (json['inputsInline'] !== undefined) {\n    this.setInputsInline(json['inputsInline']);\n  }\n  // Set output and previous/next connections.\n  if (json['output'] !== undefined) {\n    this.setOutput(true, json['output']);\n  }\n  if (json['previousStatement'] !== undefined) {\n    this.setPreviousStatement(true, json['previousStatement']);\n  }\n  if (json['nextStatement'] !== undefined) {\n    this.setNextStatement(true, json['nextStatement']);\n  }\n  if (json['tooltip'] !== undefined) {\n    var rawValue = json['tooltip'];\n    var localizedText = Blockly.utils.replaceMessageReferences(rawValue);\n    this.setTooltip(localizedText);\n  }\n  if (json['enableContextMenu'] !== undefined) {\n    var rawValue = json['enableContextMenu'];\n    this.contextMenu = !!rawValue;\n  }\n  if (json['helpUrl'] !== undefined) {\n    var rawValue = json['helpUrl'];\n    var localizedValue = Blockly.utils.replaceMessageReferences(rawValue);\n    this.setHelpUrl(localizedValue);\n  }\n  if (goog.isString(json['extensions'])) {\n    console.warn('JSON attribute \\'extensions\\' should be an array of ' +\n      'strings. Found raw string in JSON for \\'' + json['type'] + '\\' block.');\n    json['extensions'] = [json['extensions']];  // Correct and continue.\n  }\n\n  // Add the mutator to the block\n  if (json['mutator'] !== undefined) {\n    Blockly.Extensions.apply(json['mutator'], this, true);\n  }\n\n  if (Array.isArray(json['extensions'])) {\n    var extensionNames = json['extensions'];\n    for (var i = 0; i < extensionNames.length; ++i) {\n      var extensionName = extensionNames[i];\n      Blockly.Extensions.apply(extensionName, this, false);\n    }\n  }\n  if (json['outputShape'] !== undefined) {\n    this.setOutputShape(json['outputShape']);\n  }\n  if (json['checkboxInFlyout'] !== undefined) {\n    this.setCheckboxInFlyout(json['checkboxInFlyout']);\n  }\n  if (json['category'] !== undefined) {\n    this.setCategory(json['category']);\n  }\n};\n\n/**\n * Add key/values from mixinObj to this block object. By default, this method\n * will check that the keys in mixinObj will not overwrite existing values in\n * the block, including prototype values. This provides some insurance against\n * mixin / extension incompatibilities with future block features. This check\n * can be disabled by passing true as the second argument.\n * @param {!Object} mixinObj The key/values pairs to add to this block object.\n * @param {boolean=} opt_disableCheck Option flag to disable overwrite checks.\n */\nBlockly.Block.prototype.mixin = function(mixinObj, opt_disableCheck) {\n  if (goog.isDef(opt_disableCheck) && !goog.isBoolean(opt_disableCheck)) {\n    throw new Error(\"opt_disableCheck must be a boolean if provided\");\n  }\n  if (!opt_disableCheck) {\n    var overwrites = [];\n    for (var key in mixinObj) {\n      if (this[key] !== undefined) {\n        overwrites.push(key);\n      }\n    }\n    if (overwrites.length) {\n      throw new Error('Mixin will overwrite block members: ' +\n        JSON.stringify(overwrites));\n    }\n  }\n  goog.mixin(this, mixinObj);\n};\n\n/**\n * Set the colour of the block from strings or string table references.\n * @param {string|?} primary Primary colour, which may be a string that contains\n *     string table references.\n * @param {string|?} secondary Secondary colour, which may be a string that\n *     contains string table references.\n * @param {string|?} tertiary Tertiary colour, which may be a string that\n *     contains string table references.\n * @private\n */\nBlockly.Block.prototype.setColourFromRawValues_ = function(primary, secondary,\n    tertiary) {\n  primary = goog.isString(primary) ?\n      Blockly.utils.replaceMessageReferences(primary) : primary;\n  secondary = goog.isString(secondary) ?\n      Blockly.utils.replaceMessageReferences(secondary) : secondary;\n  tertiary = goog.isString(tertiary) ?\n      Blockly.utils.replaceMessageReferences(tertiary) : tertiary;\n\n  this.setColour(primary, secondary, tertiary);\n};\n\n/**\n * Set the colour of the block from JSON, replacing message references as\n * needed.\n * @param {!Object} json Structured data describing the block.\n * @private\n */\nBlockly.Block.prototype.setColourFromJson_ = function(json) {\n  this.setColourFromRawValues_(json['colour'], json['colourSecondary'],\n      json['colourTertiary']);\n};\n\n/**\n * Interpolate a message description onto the block.\n * @param {string} message Text contains interpolation tokens (%1, %2, ...)\n *     that match with fields or inputs defined in the args array.\n * @param {!Array} args Array of arguments to be interpolated.\n * @param {string=} lastDummyAlign If a dummy input is added at the end,\n *     how should it be aligned?\n * @private\n */\nBlockly.Block.prototype.interpolate_ = function(message, args, lastDummyAlign) {\n  var tokens = Blockly.utils.tokenizeInterpolation(message);\n  // Interpolate the arguments.  Build a list of elements.\n  var indexDup = [];\n  var indexCount = 0;\n  var elements = [];\n  for (var i = 0; i < tokens.length; i++) {\n    var token = tokens[i];\n    if (typeof token == 'number') {\n      if (token <= 0 || token > args.length) {\n        throw new Error('Block \\\"' + this.type + '\\\": ' +\n            'Message index %' + token + ' out of range.');\n      }\n      if (indexDup[token]) {\n        throw new Error('Block \\\"' + this.type + '\\\": ' +\n            'Message index %' + token + ' duplicated.');\n      }\n      indexDup[token] = true;\n      indexCount++;\n      elements.push(args[token - 1]);\n    } else {\n      token = token.trim();\n      if (token) {\n        elements.push(token);\n      }\n    }\n  }\n  if(indexCount != args.length) {\n    throw new Error('Block \\\"' + this.type + '\\\": ' +\n        'Message does not reference all ' + args.length + ' arg(s).');\n  }\n  // Add last dummy input if needed.\n  if (elements.length && (typeof elements[elements.length - 1] == 'string' ||\n      goog.string.startsWith(elements[elements.length - 1]['type'],\n                             'field_'))) {\n    var dummyInput = {type: 'input_dummy'};\n    if (lastDummyAlign) {\n      dummyInput['align'] = lastDummyAlign;\n    }\n    elements.push(dummyInput);\n  }\n  // Lookup of alignment constants.\n  var alignmentLookup = {\n    'LEFT': Blockly.ALIGN_LEFT,\n    'RIGHT': Blockly.ALIGN_RIGHT,\n    'CENTRE': Blockly.ALIGN_CENTRE\n  };\n  // Populate block with inputs and fields.\n  var fieldStack = [];\n  for (var i = 0; i < elements.length; i++) {\n    var element = elements[i];\n    if (typeof element == 'string') {\n      fieldStack.push([element, undefined]);\n    } else {\n      var field = null;\n      var input = null;\n      do {\n        var altRepeat = false;\n        if (typeof element == 'string') {\n          field = new Blockly.FieldLabel(element);\n        } else {\n          switch (element['type']) {\n            case 'input_value':\n              input = this.appendValueInput(element['name']);\n              break;\n            case 'input_statement':\n              input = this.appendStatementInput(element['name']);\n              break;\n            case 'input_dummy':\n              input = this.appendDummyInput(element['name']);\n              break;\n            default:\n              field = Blockly.Field.fromJson(element);\n\n              // Unknown field.\n              if (!field) {\n                if (element['alt']) {\n                  element = element['alt'];\n                  altRepeat = true;\n                } else {\n                  console.warn('Blockly could not create a field of type ' +\n                      element['type'] +\n                      '. You may need to register your custom field.  See ' +\n                      'github.com/google/blockly/issues/1584');\n                }\n              }\n          }\n        }\n      } while (altRepeat);\n      if (field) {\n        fieldStack.push([field, element['name']]);\n      } else if (input) {\n        if (element['check']) {\n          input.setCheck(element['check']);\n        }\n        if (element['align']) {\n          input.setAlign(alignmentLookup[element['align']]);\n        }\n        for (var j = 0; j < fieldStack.length; j++) {\n          input.appendField(fieldStack[j][0], fieldStack[j][1]);\n        }\n        fieldStack.length = 0;\n      }\n    }\n  }\n};\n\n/**\n * Add a value input, statement input or local variable to this block.\n * @param {number} type Either Blockly.INPUT_VALUE or Blockly.NEXT_STATEMENT or\n *     Blockly.DUMMY_INPUT.\n * @param {string} name Language-neutral identifier which may used to find this\n *     input again.  Should be unique to this block.\n * @return {!Blockly.Input} The input object created.\n * @protected\n */\nBlockly.Block.prototype.appendInput_ = function(type, name) {\n  var connection = null;\n  if (type == Blockly.INPUT_VALUE || type == Blockly.NEXT_STATEMENT) {\n    connection = this.makeConnection_(type);\n  }\n  var input = new Blockly.Input(type, name, this, connection);\n  // Append input to list.\n  this.inputList.push(input);\n  return input;\n};\n\n/**\n * Move a named input to a different location on this block.\n * @param {string} name The name of the input to move.\n * @param {?string} refName Name of input that should be after the moved input,\n *   or null to be the input at the end.\n */\nBlockly.Block.prototype.moveInputBefore = function(name, refName) {\n  if (name == refName) {\n    return;\n  }\n  // Find both inputs.\n  var inputIndex = -1;\n  var refIndex = refName ? -1 : this.inputList.length;\n  for (var i = 0, input; input = this.inputList[i]; i++) {\n    if (input.name == name) {\n      inputIndex = i;\n      if (refIndex != -1) {\n        break;\n      }\n    } else if (refName && input.name == refName) {\n      refIndex = i;\n      if (inputIndex != -1) {\n        break;\n      }\n    }\n  }\n  goog.asserts.assert(inputIndex != -1, 'Named input \"%s\" not found.', name);\n  goog.asserts.assert(refIndex != -1, 'Reference input \"%s\" not found.',\n                      refName);\n  this.moveNumberedInputBefore(inputIndex, refIndex);\n};\n\n/**\n * Move a numbered input to a different location on this block.\n * @param {number} inputIndex Index of the input to move.\n * @param {number} refIndex Index of input that should be after the moved input.\n */\nBlockly.Block.prototype.moveNumberedInputBefore = function(\n    inputIndex, refIndex) {\n  // Validate arguments.\n  goog.asserts.assert(inputIndex != refIndex, 'Can\\'t move input to itself.');\n  goog.asserts.assert(inputIndex < this.inputList.length,\n                      'Input index ' + inputIndex + ' out of bounds.');\n  goog.asserts.assert(refIndex <= this.inputList.length,\n                      'Reference input ' + refIndex + ' out of bounds.');\n  // Remove input.\n  var input = this.inputList[inputIndex];\n  this.inputList.splice(inputIndex, 1);\n  if (inputIndex < refIndex) {\n    refIndex--;\n  }\n  // Reinsert input.\n  this.inputList.splice(refIndex, 0, input);\n};\n\n/**\n * Remove an input from this block.\n * @param {string} name The name of the input.\n * @param {boolean=} opt_quiet True to prevent error if input is not present.\n * @throws {goog.asserts.AssertionError} if the input is not present and\n *     opt_quiet is not true.\n */\nBlockly.Block.prototype.removeInput = function(name, opt_quiet) {\n  for (var i = 0, input; input = this.inputList[i]; i++) {\n    if (input.name == name) {\n      if (input.connection && input.connection.isConnected()) {\n        input.connection.setShadowDom(null);\n        var block = input.connection.targetBlock();\n        if (block.isShadow()) {\n          // Destroy any attached shadow block.\n          block.dispose();\n        } else {\n          // Disconnect any attached normal block.\n          block.unplug();\n        }\n      }\n      input.dispose();\n      this.inputList.splice(i, 1);\n      return;\n    }\n  }\n  if (!opt_quiet) {\n    goog.asserts.fail('Input \"%s\" not found.', name);\n  }\n};\n\n/**\n * Fetches the named input object.\n * @param {string} name The name of the input.\n * @return {Blockly.Input} The input object, or null if input does not exist.\n */\nBlockly.Block.prototype.getInput = function(name) {\n  for (var i = 0, input; input = this.inputList[i]; i++) {\n    if (input.name == name) {\n      return input;\n    }\n  }\n  // This input does not exist.\n  return null;\n};\n\n/**\n * Fetches the block attached to the named input.\n * @param {string} name The name of the input.\n * @return {Blockly.Block} The attached value block, or null if the input is\n *     either disconnected or if the input does not exist.\n */\nBlockly.Block.prototype.getInputTargetBlock = function(name) {\n  var input = this.getInput(name);\n  return input && input.connection && input.connection.targetBlock();\n};\n\n/**\n * Returns the comment on this block (or '' if none).\n * @return {string} Block's comment.\n */\nBlockly.Block.prototype.getCommentText = function() {\n  return this.comment || '';\n};\n\n/**\n * Set this block's comment text.\n * @param {?string} text The text, or null to delete.\n */\nBlockly.Block.prototype.setCommentText = function(text) {\n  if (this.comment != text) {\n    Blockly.Events.fire(new Blockly.Events.BlockChange(\n        this, 'comment', null, this.comment, text || ''));\n    this.comment = text;\n  }\n};\n\n/**\n * Set this block's output shape.\n * e.g., null, OUTPUT_SHAPE_HEXAGONAL, OUTPUT_SHAPE_ROUND, OUTPUT_SHAPE_SQUARE.\n * @param {?number} outputShape Value representing output shape\n *     (see constants.js).\n */\nBlockly.Block.prototype.setOutputShape = function(outputShape) {\n  this.outputShape_ = outputShape;\n};\n\n/**\n * Get this block's output shape.\n * @return {?number} Value representing output shape (see constants.js).\n */\nBlockly.Block.prototype.getOutputShape = function() {\n  return this.outputShape_;\n};\n\n/**\n * Set this block's category (for styling purposes)\n * @param {?string} category The block's category (see constants.js).\n */\nBlockly.Block.prototype.setCategory = function(category) {\n  this.category_ = category;\n};\n\n/**\n * Get this block's category (for styling purposes)\n * @return {?string} category The block's category (see constants.js).\n */\nBlockly.Block.prototype.getCategory = function() {\n  return this.category_;\n};\n\n/**\n * Set whether this block has a checkbox next to it in the flyout.\n * @param {boolean} hasCheckbox True if this block should have a checkbox.\n */\nBlockly.Block.prototype.setCheckboxInFlyout = function(hasCheckbox) {\n  this.checkboxInFlyout_ = hasCheckbox;\n};\n\n/**\n * Get whether this block has a checkbox next to it in the flyout.\n * @return {boolean} True if this block should have a checkbox.\n */\nBlockly.Block.prototype.hasCheckboxInFlyout = function() {\n  return this.checkboxInFlyout_;\n};\n\n/**\n * Set this block's warning text.\n * @param {?string} text The text, or null to delete.\n * @abstract\n */\nBlockly.Block.prototype.setWarningText = function(/* text */) {\n  // NOP.\n};\n\n/**\n * Give this block a mutator dialog.\n * @param {Blockly.Mutator} mutator A mutator dialog instance or null to remove.\n * @abstract\n */\nBlockly.Block.prototype.setMutator = function(/* mutator */) {\n  // NOP.\n};\n\n/**\n * Return the coordinates of the top-left corner of this block relative to the\n * drawing surface's origin (0,0), in workspace units.\n * @return {!goog.math.Coordinate} Object with .x and .y properties.\n */\nBlockly.Block.prototype.getRelativeToSurfaceXY = function() {\n  return this.xy_;\n};\n\n/**\n * Move a block by a relative offset.\n * @param {number} dx Horizontal offset, in workspace units.\n * @param {number} dy Vertical offset, in workspace units.\n */\nBlockly.Block.prototype.moveBy = function(dx, dy) {\n  goog.asserts.assert(!this.parentBlock_, 'Block has parent.');\n  var event = new Blockly.Events.BlockMove(this);\n  this.xy_.translate(dx, dy);\n  event.recordNew();\n  Blockly.Events.fire(event);\n};\n\n/**\n * Create a connection of the specified type.\n * @param {number} type The type of the connection to create.\n * @return {!Blockly.Connection} A new connection of the specified type.\n * @private\n */\nBlockly.Block.prototype.makeConnection_ = function(type) {\n  return new Blockly.Connection(this, type);\n};\n\n/**\n * Recursively checks whether all statement and value inputs are filled with\n * blocks. Also checks all following statement blocks in this stack.\n * @param {boolean=} opt_shadowBlocksAreFilled An optional argument controlling\n *     whether shadow blocks are counted as filled. Defaults to true.\n * @return {boolean} True if all inputs are filled, false otherwise.\n */\nBlockly.Block.prototype.allInputsFilled = function(opt_shadowBlocksAreFilled) {\n  // Account for the shadow block filledness toggle.\n  if (opt_shadowBlocksAreFilled === undefined) {\n    opt_shadowBlocksAreFilled = true;\n  }\n  if (!opt_shadowBlocksAreFilled && this.isShadow()) {\n    return false;\n  }\n\n  // Recursively check each input block of the current block.\n  for (var i = 0, input; input = this.inputList[i]; i++) {\n    if (!input.connection) {\n      continue;\n    }\n    var target = input.connection.targetBlock();\n    if (!target || !target.allInputsFilled(opt_shadowBlocksAreFilled)) {\n      return false;\n    }\n  }\n\n  // Recursively check the next block after the current block.\n  var next = this.getNextBlock();\n  if (next) {\n    return next.allInputsFilled(opt_shadowBlocksAreFilled);\n  }\n\n  return true;\n};\n\n/**\n * This method returns a string describing this Block in developer terms (type\n * name and ID; English only).\n *\n * Intended to on be used in console logs and errors. If you need a string that\n * uses the user's native language (including block text, field values, and\n * child blocks), use [toString()]{@link Blockly.Block#toString}.\n * @return {string} The description.\n */\nBlockly.Block.prototype.toDevString = function() {\n  var msg = this.type ? '\"' + this.type + '\" block' : 'Block';\n  if (this.id) {\n    msg += ' (id=\"' + this.id + '\")';\n  }\n  return msg;\n};\n", "idx": 1, "id": 9268, "msg": "", "proj": "LLK-scratch-blocks", "lang": "js"}
{"patch": "@@ -165,6 +165,54 @@ public class ParquetValueWriters {\n     }\n   }\n \n+  private static class FloatWriter extends UnboxedWriter<Float> {\n+    private final int id;\n+    private long nanCount;\n+\n+    private FloatWriter(ColumnDescriptor desc) {\n+      super(desc);\n+      this.id = desc.getPrimitiveType().getId().intValue();\n+      this.nanCount = 0;\n+    }\n+\n+    @Override\n+    public void write(int repetitionLevel, Float value) {\n+      writeFloat(repetitionLevel, value);\n+      if (Float.isNaN(value)) {\n+        nanCount++;\n+      }\n+    }\n+\n+    @Override\n+    public Stream<FieldMetrics> metrics() {\n+      return Stream.of(new ParquetFieldMetrics(id, nanCount));\n+    }\n+  }\n+\n+  private static class DoubleWriter extends UnboxedWriter<Double> {\n+    private final int id;\n+    private long nanCount;\n+\n+    private DoubleWriter(ColumnDescriptor desc) {\n+      super(desc);\n+      this.id = desc.getPrimitiveType().getId().intValue();\n+      this.nanCount = 0;\n+    }\n+\n+    @Override\n+    public void write(int repetitionLevel, Double value) {\n+      writeDouble(repetitionLevel, value);\n+      if (Double.isNaN(value)) {\n+        nanCount++;\n+      }\n+    }\n+\n+    @Override\n+    public Stream<FieldMetrics> metrics() {\n+      return Stream.of(new ParquetFieldMetrics(id, nanCount));\n+    }\n+  }\n+\n   private static class ByteWriter extends UnboxedWriter<Byte> {\n     private ByteWriter(ColumnDescriptor desc) {\n       super(desc);", "y": 0, "oldf": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\n\npackage org.apache.iceberg.parquet;\n\nimport java.lang.reflect.Array;\nimport java.math.BigDecimal;\nimport java.nio.ByteBuffer;\nimport java.util.Arrays;\nimport java.util.Collection;\nimport java.util.Iterator;\nimport java.util.List;\nimport java.util.Map;\nimport org.apache.avro.util.Utf8;\nimport org.apache.iceberg.deletes.PositionDelete;\nimport org.apache.iceberg.relocated.com.google.common.base.Preconditions;\nimport org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\nimport org.apache.iceberg.types.TypeUtil;\nimport org.apache.iceberg.util.DecimalUtil;\nimport org.apache.parquet.column.ColumnDescriptor;\nimport org.apache.parquet.column.ColumnWriteStore;\nimport org.apache.parquet.io.api.Binary;\nimport org.apache.parquet.schema.Type;\n\npublic class ParquetValueWriters {\n  private ParquetValueWriters() {\n  }\n\n  public static <T> ParquetValueWriter<T> option(Type type,\n                                                 int definitionLevel,\n                                                 ParquetValueWriter<T> writer) {\n    if (type.isRepetition(Type.Repetition.OPTIONAL)) {\n      return new OptionWriter<>(definitionLevel, writer);\n    }\n\n    return writer;\n  }\n\n  public static UnboxedWriter<Boolean> booleans(ColumnDescriptor desc) {\n    return new UnboxedWriter<>(desc);\n  }\n\n  public static UnboxedWriter<Byte> tinyints(ColumnDescriptor desc) {\n    return new ByteWriter(desc);\n  }\n\n  public static UnboxedWriter<Short> shorts(ColumnDescriptor desc) {\n    return new ShortWriter(desc);\n  }\n\n  public static UnboxedWriter<Integer> ints(ColumnDescriptor desc) {\n    return new UnboxedWriter<>(desc);\n  }\n\n  public static UnboxedWriter<Long> longs(ColumnDescriptor desc) {\n    return new UnboxedWriter<>(desc);\n  }\n\n  public static UnboxedWriter<Float> floats(ColumnDescriptor desc) {\n    return new UnboxedWriter<>(desc);\n  }\n\n  public static UnboxedWriter<Double> doubles(ColumnDescriptor desc) {\n    return new UnboxedWriter<>(desc);\n  }\n\n  public static PrimitiveWriter<CharSequence> strings(ColumnDescriptor desc) {\n    return new StringWriter(desc);\n  }\n\n  public static PrimitiveWriter<BigDecimal> decimalAsInteger(ColumnDescriptor desc,\n                                                             int precision, int scale) {\n    return new IntegerDecimalWriter(desc, precision, scale);\n  }\n\n  public static PrimitiveWriter<BigDecimal> decimalAsLong(ColumnDescriptor desc,\n                                                          int precision, int scale) {\n    return new LongDecimalWriter(desc, precision, scale);\n  }\n\n  public static PrimitiveWriter<BigDecimal> decimalAsFixed(ColumnDescriptor desc,\n                                                           int precision, int scale) {\n    return new FixedDecimalWriter(desc, precision, scale);\n  }\n\n  public static PrimitiveWriter<ByteBuffer> byteBuffers(ColumnDescriptor desc) {\n    return new BytesWriter(desc);\n  }\n\n  public static <E> CollectionWriter<E> collections(int dl, int rl, ParquetValueWriter<E> writer) {\n    return new CollectionWriter<>(dl, rl, writer);\n  }\n\n  public static <K, V> MapWriter<K, V> maps(int dl, int rl,\n                                            ParquetValueWriter<K> keyWriter,\n                                            ParquetValueWriter<V> valueWriter) {\n    return new MapWriter<>(dl, rl, keyWriter, valueWriter);\n  }\n\n  public abstract static class PrimitiveWriter<T> implements ParquetValueWriter<T> {\n    @SuppressWarnings(\"checkstyle:VisibilityModifier\")\n    protected final ColumnWriter<T> column;\n    private final List<TripleWriter<?>> children;\n\n    protected PrimitiveWriter(ColumnDescriptor desc) {\n      this.column = ColumnWriter.newWriter(desc);\n      this.children = ImmutableList.of(column);\n    }\n\n    @Override\n    public void write(int repetitionLevel, T value) {\n      column.write(repetitionLevel, value);\n    }\n\n    @Override\n    public List<TripleWriter<?>> columns() {\n      return children;\n    }\n\n    @Override\n    public void setColumnStore(ColumnWriteStore columnStore) {\n      this.column.setColumnStore(columnStore);\n    }\n  }\n\n  private static class UnboxedWriter<T> extends PrimitiveWriter<T> {\n    private UnboxedWriter(ColumnDescriptor desc) {\n      super(desc);\n    }\n\n    public void writeBoolean(int repetitionLevel, boolean value) {\n      column.writeBoolean(repetitionLevel, value);\n    }\n\n    public void writeInteger(int repetitionLevel, int value) {\n      column.writeInteger(repetitionLevel, value);\n    }\n\n    public void writeLong(int repetitionLevel, long  value) {\n      column.writeLong(repetitionLevel, value);\n    }\n\n    public void writeFloat(int repetitionLevel, float value) {\n      column.writeFloat(repetitionLevel, value);\n    }\n\n    public void writeDouble(int repetitionLevel, double value) {\n      column.writeDouble(repetitionLevel, value);\n    }\n  }\n\n  private static class ByteWriter extends UnboxedWriter<Byte> {\n    private ByteWriter(ColumnDescriptor desc) {\n      super(desc);\n    }\n\n    @Override\n    public void write(int repetitionLevel, Byte value) {\n      writeInteger(repetitionLevel, value.intValue());\n    }\n  }\n\n  private static class ShortWriter extends UnboxedWriter<Short> {\n    private ShortWriter(ColumnDescriptor desc) {\n      super(desc);\n    }\n\n    @Override\n    public void write(int repetitionLevel, Short value) {\n      writeInteger(repetitionLevel, value.intValue());\n    }\n  }\n\n  private static class IntegerDecimalWriter extends PrimitiveWriter<BigDecimal> {\n    private final int precision;\n    private final int scale;\n\n    private IntegerDecimalWriter(ColumnDescriptor desc, int precision, int scale) {\n      super(desc);\n      this.precision = precision;\n      this.scale = scale;\n    }\n\n    @Override\n    public void write(int repetitionLevel, BigDecimal decimal) {\n      Preconditions.checkArgument(decimal.scale() == scale,\n          \"Cannot write value as decimal(%s,%s), wrong scale: %s\", precision, scale, decimal);\n      Preconditions.checkArgument(decimal.precision() <= precision,\n          \"Cannot write value as decimal(%s,%s), too large: %s\", precision, scale, decimal);\n\n      column.writeInteger(repetitionLevel, decimal.unscaledValue().intValue());\n    }\n  }\n\n  private static class LongDecimalWriter extends PrimitiveWriter<BigDecimal> {\n    private final int precision;\n    private final int scale;\n\n    private LongDecimalWriter(ColumnDescriptor desc, int precision, int scale) {\n      super(desc);\n      this.precision = precision;\n      this.scale = scale;\n    }\n\n    @Override\n    public void write(int repetitionLevel, BigDecimal decimal) {\n      Preconditions.checkArgument(decimal.scale() == scale,\n          \"Cannot write value as decimal(%s,%s), wrong scale: %s\", precision, scale, decimal);\n      Preconditions.checkArgument(decimal.precision() <= precision,\n          \"Cannot write value as decimal(%s,%s), too large: %s\", precision, scale, decimal);\n\n      column.writeLong(repetitionLevel, decimal.unscaledValue().longValue());\n    }\n  }\n\n  private static class FixedDecimalWriter extends PrimitiveWriter<BigDecimal> {\n    private final int precision;\n    private final int scale;\n    private final ThreadLocal<byte[]> bytes;\n\n    private FixedDecimalWriter(ColumnDescriptor desc, int precision, int scale) {\n      super(desc);\n      this.precision = precision;\n      this.scale = scale;\n      this.bytes = ThreadLocal.withInitial(() -> new byte[TypeUtil.decimalRequiredBytes(precision)]);\n    }\n\n    @Override\n    public void write(int repetitionLevel, BigDecimal decimal) {\n      byte[] binary = DecimalUtil.toReusedFixLengthBytes(precision, scale, decimal, bytes.get());\n      column.writeBinary(repetitionLevel, Binary.fromReusedByteArray(binary));\n    }\n  }\n\n  private static class BytesWriter extends PrimitiveWriter<ByteBuffer> {\n    private BytesWriter(ColumnDescriptor desc) {\n      super(desc);\n    }\n\n    @Override\n    public void write(int repetitionLevel, ByteBuffer buffer) {\n      column.writeBinary(repetitionLevel, Binary.fromReusedByteBuffer(buffer));\n    }\n  }\n\n  private static class StringWriter extends PrimitiveWriter<CharSequence> {\n    private StringWriter(ColumnDescriptor desc) {\n      super(desc);\n    }\n\n    @Override\n    public void write(int repetitionLevel, CharSequence value) {\n      if (value instanceof Utf8) {\n        Utf8 utf8 = (Utf8) value;\n        column.writeBinary(repetitionLevel,\n            Binary.fromReusedByteArray(utf8.getBytes(), 0, utf8.getByteLength()));\n      } else {\n        column.writeBinary(repetitionLevel, Binary.fromString(value.toString()));\n      }\n    }\n  }\n\n  static class OptionWriter<T> implements ParquetValueWriter<T> {\n    private final int definitionLevel;\n    private final ParquetValueWriter<T> writer;\n    private final List<TripleWriter<?>> children;\n\n    OptionWriter(int definitionLevel, ParquetValueWriter<T> writer) {\n      this.definitionLevel = definitionLevel;\n      this.writer = writer;\n      this.children = writer.columns();\n    }\n\n    @Override\n    public void write(int repetitionLevel, T value) {\n      if (value != null) {\n        writer.write(repetitionLevel, value);\n\n      } else {\n        for (TripleWriter<?> column : children) {\n          column.writeNull(repetitionLevel, definitionLevel - 1);\n        }\n      }\n    }\n\n    @Override\n    public List<TripleWriter<?>> columns() {\n      return children;\n    }\n\n    @Override\n    public void setColumnStore(ColumnWriteStore columnStore) {\n      writer.setColumnStore(columnStore);\n    }\n  }\n\n  public abstract static class RepeatedWriter<L, E> implements ParquetValueWriter<L> {\n    private final int definitionLevel;\n    private final int repetitionLevel;\n    private final ParquetValueWriter<E> writer;\n    private final List<TripleWriter<?>> children;\n\n    protected RepeatedWriter(int definitionLevel, int repetitionLevel,\n                             ParquetValueWriter<E> writer) {\n      this.definitionLevel = definitionLevel;\n      this.repetitionLevel = repetitionLevel;\n      this.writer = writer;\n      this.children = writer.columns();\n    }\n\n    @Override\n    public void write(int parentRepetition, L value) {\n      Iterator<E> elements = elements(value);\n\n      if (!elements.hasNext()) {\n        // write the empty list to each column\n        // TODO: make sure this definition level is correct\n        for (TripleWriter<?> column : children) {\n          column.writeNull(parentRepetition, definitionLevel - 1);\n        }\n\n      } else {\n        boolean first = true;\n        while (elements.hasNext()) {\n          E element = elements.next();\n\n          int rl = repetitionLevel;\n          if (first) {\n            rl = parentRepetition;\n            first = false;\n          }\n\n          writer.write(rl, element);\n        }\n      }\n    }\n\n    @Override\n    public List<TripleWriter<?>> columns() {\n      return children;\n    }\n\n    @Override\n    public void setColumnStore(ColumnWriteStore columnStore) {\n      writer.setColumnStore(columnStore);\n    }\n\n    protected abstract Iterator<E> elements(L value);\n  }\n\n  private static class CollectionWriter<E> extends RepeatedWriter<Collection<E>, E> {\n    private CollectionWriter(int definitionLevel, int repetitionLevel,\n                             ParquetValueWriter<E> writer) {\n      super(definitionLevel, repetitionLevel, writer);\n    }\n\n    @Override\n    protected Iterator<E> elements(Collection<E> list) {\n      return list.iterator();\n    }\n  }\n\n  public abstract static class RepeatedKeyValueWriter<M, K, V> implements ParquetValueWriter<M> {\n    private final int definitionLevel;\n    private final int repetitionLevel;\n    private final ParquetValueWriter<K> keyWriter;\n    private final ParquetValueWriter<V> valueWriter;\n    private final List<TripleWriter<?>> children;\n\n    protected RepeatedKeyValueWriter(int definitionLevel, int repetitionLevel,\n                                     ParquetValueWriter<K> keyWriter,\n                                     ParquetValueWriter<V> valueWriter) {\n      this.definitionLevel = definitionLevel;\n      this.repetitionLevel = repetitionLevel;\n      this.keyWriter = keyWriter;\n      this.valueWriter = valueWriter;\n      this.children = ImmutableList.<TripleWriter<?>>builder()\n          .addAll(keyWriter.columns())\n          .addAll(valueWriter.columns())\n          .build();\n    }\n\n    @Override\n    public void write(int parentRepetition, M value) {\n      Iterator<Map.Entry<K, V>> pairs = pairs(value);\n\n      if (!pairs.hasNext()) {\n        // write the empty map to each column\n        for (TripleWriter<?> column : children) {\n          column.writeNull(parentRepetition, definitionLevel - 1);\n        }\n\n      } else {\n        boolean first = true;\n        while (pairs.hasNext()) {\n          Map.Entry<K, V> pair = pairs.next();\n\n          int rl = repetitionLevel;\n          if (first) {\n            rl = parentRepetition;\n            first = false;\n          }\n\n          keyWriter.write(rl, pair.getKey());\n          valueWriter.write(rl, pair.getValue());\n        }\n      }\n    }\n\n    @Override\n    public List<TripleWriter<?>> columns() {\n      return children;\n    }\n\n    @Override\n    public void setColumnStore(ColumnWriteStore columnStore) {\n      keyWriter.setColumnStore(columnStore);\n      valueWriter.setColumnStore(columnStore);\n    }\n\n    protected abstract Iterator<Map.Entry<K, V>> pairs(M value);\n  }\n\n  private static class MapWriter<K, V> extends RepeatedKeyValueWriter<Map<K, V>, K, V> {\n    private MapWriter(int definitionLevel, int repetitionLevel,\n                      ParquetValueWriter<K> keyWriter, ParquetValueWriter<V> valueWriter) {\n      super(definitionLevel, repetitionLevel, keyWriter, valueWriter);\n    }\n\n    @Override\n    protected Iterator<Map.Entry<K, V>> pairs(Map<K, V> map) {\n      return map.entrySet().iterator();\n    }\n  }\n\n  public abstract static class StructWriter<S> implements ParquetValueWriter<S> {\n    private final ParquetValueWriter<Object>[] writers;\n    private final List<TripleWriter<?>> children;\n\n    @SuppressWarnings(\"unchecked\")\n    protected StructWriter(List<ParquetValueWriter<?>> writers) {\n      this.writers = (ParquetValueWriter<Object>[]) Array.newInstance(\n          ParquetValueWriter.class, writers.size());\n\n      ImmutableList.Builder<TripleWriter<?>> columnsBuilder = ImmutableList.builder();\n      for (int i = 0; i < writers.size(); i += 1) {\n        ParquetValueWriter<?> writer = writers.get(i);\n        this.writers[i] = (ParquetValueWriter<Object>) writer;\n        columnsBuilder.addAll(writer.columns());\n      }\n\n      this.children = columnsBuilder.build();\n    }\n\n    @Override\n    public void write(int repetitionLevel, S value) {\n      for (int i = 0; i < writers.length; i += 1) {\n        Object fieldValue = get(value, i);\n        writers[i].write(repetitionLevel, fieldValue);\n      }\n    }\n\n    @Override\n    public List<TripleWriter<?>> columns() {\n      return children;\n    }\n\n    @Override\n    public void setColumnStore(ColumnWriteStore columnStore) {\n      for (ParquetValueWriter<?> writer : writers) {\n        writer.setColumnStore(columnStore);\n      }\n    }\n\n    protected abstract Object get(S struct, int index);\n  }\n\n  public static class PositionDeleteStructWriter<R> extends StructWriter<PositionDelete<R>> {\n    public PositionDeleteStructWriter(StructWriter<?> replacedWriter) {\n      super(Arrays.asList(replacedWriter.writers));\n    }\n\n    @Override\n    protected Object get(PositionDelete<R> delete, int index) {\n      switch (index) {\n        case 0:\n          return delete.path();\n        case 1:\n          return delete.pos();\n        case 2:\n          return delete.row();\n      }\n      throw new IllegalArgumentException(\"Cannot get value for invalid index: \" + index);\n    }\n  }\n}\n", "idx": 4, "id": 27007, "msg": "", "proj": "apache-iceberg", "lang": "java"}
{"patch": "@@ -7750,13 +7750,13 @@ int LuaScriptInterface::luaCreatureGetPathTo(lua_State* L)\n \tfpp.clearSight = getBoolean(L, 6, fpp.clearSight);\n \tfpp.maxSearchDist = getNumber<int32_t>(L, 7, fpp.maxSearchDist);\n \n-\tstd::forward_list<Direction> dirList;\n+\tstd::vector<Direction> dirList;\n \tif (creature->getPathTo(position, dirList, fpp)) {\n \t\tlua_newtable(L);\n \n \t\tint index = 0;\n-\t\tfor (Direction dir : dirList) {\n-\t\t\tlua_pushnumber(L, dir);\n+\t\tfor (auto it = dirList.rbegin(); it != dirList.rend(); ++it) {\n+\t\t\tlua_pushnumber(L, *it);\n \t\t\tlua_rawseti(L, -2, ++index);\n \t\t}\n \t} else {", "y": 0, "oldf": "/**\n * The Forgotten Server - a free and open-source MMORPG server emulator\n * Copyright (C) 2019  Mark Samman <mark.samman@gmail.com>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation; either version 2 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License along\n * with this program; if not, write to the Free Software Foundation, Inc.,\n * 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.\n */\n\n#include \"otpch.h\"\n\n#include <boost/range/adaptor/reversed.hpp>\n\n#include \"luascript.h\"\n#include \"chat.h\"\n#include \"player.h\"\n#include \"game.h\"\n#include \"protocolstatus.h\"\n#include \"spells.h\"\n#include \"iologindata.h\"\n#include \"configmanager.h\"\n#include \"teleport.h\"\n#include \"databasemanager.h\"\n#include \"bed.h\"\n#include \"monster.h\"\n#include \"scheduler.h\"\n#include \"databasetasks.h\"\n#include \"events.h\"\n#include \"movement.h\"\n#include \"globalevent.h\"\n#include \"script.h\"\n#include \"weapons.h\"\n\nextern Chat* g_chat;\nextern Game g_game;\nextern Monsters g_monsters;\nextern ConfigManager g_config;\nextern Vocations g_vocations;\nextern Spells* g_spells;\nextern Events* g_events;\nextern Actions* g_actions;\nextern TalkActions* g_talkActions;\nextern CreatureEvents* g_creatureEvents;\nextern MoveEvents* g_moveEvents;\nextern GlobalEvents* g_globalEvents;\nextern Scripts* g_scripts;\nextern Weapons* g_weapons;\n\nScriptEnvironment::DBResultMap ScriptEnvironment::tempResults;\nuint32_t ScriptEnvironment::lastResultId = 0;\n\nstd::multimap<ScriptEnvironment*, Item*> ScriptEnvironment::tempItems;\n\nLuaEnvironment g_luaEnvironment;\n\nScriptEnvironment::ScriptEnvironment()\n{\n\tresetEnv();\n}\n\nScriptEnvironment::~ScriptEnvironment()\n{\n\tresetEnv();\n}\n\nvoid ScriptEnvironment::resetEnv()\n{\n\tscriptId = 0;\n\tcallbackId = 0;\n\ttimerEvent = false;\n\tinterface = nullptr;\n\tlocalMap.clear();\n\ttempResults.clear();\n\n\tauto pair = tempItems.equal_range(this);\n\tauto it = pair.first;\n\twhile (it != pair.second) {\n\t\tItem* item = it->second;\n\t\tif (item->getParent() == VirtualCylinder::virtualCylinder) {\n\t\t\tg_game.ReleaseItem(item);\n\t\t}\n\t\tit = tempItems.erase(it);\n\t}\n}\n\nbool ScriptEnvironment::setCallbackId(int32_t callbackId, LuaScriptInterface* scriptInterface)\n{\n\tif (this->callbackId != 0) {\n\t\t//nested callbacks are not allowed\n\t\tif (interface) {\n\t\t\tinterface->reportErrorFunc(\"Nested callbacks!\");\n\t\t}\n\t\treturn false;\n\t}\n\n\tthis->callbackId = callbackId;\n\tinterface = scriptInterface;\n\treturn true;\n}\n\nvoid ScriptEnvironment::getEventInfo(int32_t& scriptId, LuaScriptInterface*& scriptInterface, int32_t& callbackId, bool& timerEvent) const\n{\n\tscriptId = this->scriptId;\n\tscriptInterface = interface;\n\tcallbackId = this->callbackId;\n\ttimerEvent = this->timerEvent;\n}\n\nuint32_t ScriptEnvironment::addThing(Thing* thing)\n{\n\tif (!thing || thing->isRemoved()) {\n\t\treturn 0;\n\t}\n\n\tCreature* creature = thing->getCreature();\n\tif (creature) {\n\t\treturn creature->getID();\n\t}\n\n\tItem* item = thing->getItem();\n\tif (item && item->hasAttribute(ITEM_ATTRIBUTE_UNIQUEID)) {\n\t\treturn item->getUniqueId();\n\t}\n\n\tfor (const auto& it : localMap) {\n\t\tif (it.second == item) {\n\t\t\treturn it.first;\n\t\t}\n\t}\n\n\tlocalMap[++lastUID] = item;\n\treturn lastUID;\n}\n\nvoid ScriptEnvironment::insertItem(uint32_t uid, Item* item)\n{\n\tauto result = localMap.emplace(uid, item);\n\tif (!result.second) {\n\t\tstd::cout << std::endl << \"Lua Script Error: Thing uid already taken.\";\n\t}\n}\n\nThing* ScriptEnvironment::getThingByUID(uint32_t uid)\n{\n\tif (uid >= 0x10000000) {\n\t\treturn g_game.getCreatureByID(uid);\n\t}\n\n\tif (uid <= std::numeric_limits<uint16_t>::max()) {\n\t\tItem* item = g_game.getUniqueItem(uid);\n\t\tif (item && !item->isRemoved()) {\n\t\t\treturn item;\n\t\t}\n\t\treturn nullptr;\n\t}\n\n\tauto it = localMap.find(uid);\n\tif (it != localMap.end()) {\n\t\tItem* item = it->second;\n\t\tif (!item->isRemoved()) {\n\t\t\treturn item;\n\t\t}\n\t}\n\treturn nullptr;\n}\n\nItem* ScriptEnvironment::getItemByUID(uint32_t uid)\n{\n\tThing* thing = getThingByUID(uid);\n\tif (!thing) {\n\t\treturn nullptr;\n\t}\n\treturn thing->getItem();\n}\n\nContainer* ScriptEnvironment::getContainerByUID(uint32_t uid)\n{\n\tItem* item = getItemByUID(uid);\n\tif (!item) {\n\t\treturn nullptr;\n\t}\n\treturn item->getContainer();\n}\n\nvoid ScriptEnvironment::removeItemByUID(uint32_t uid)\n{\n\tif (uid <= std::numeric_limits<uint16_t>::max()) {\n\t\tg_game.removeUniqueItem(uid);\n\t\treturn;\n\t}\n\n\tauto it = localMap.find(uid);\n\tif (it != localMap.end()) {\n\t\tlocalMap.erase(it);\n\t}\n}\n\nvoid ScriptEnvironment::addTempItem(Item* item)\n{\n\ttempItems.emplace(this, item);\n}\n\nvoid ScriptEnvironment::removeTempItem(Item* item)\n{\n\tfor (auto it = tempItems.begin(), end = tempItems.end(); it != end; ++it) {\n\t\tif (it->second == item) {\n\t\t\ttempItems.erase(it);\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nuint32_t ScriptEnvironment::addResult(DBResult_ptr res)\n{\n\ttempResults[++lastResultId] = res;\n\treturn lastResultId;\n}\n\nbool ScriptEnvironment::removeResult(uint32_t id)\n{\n\tauto it = tempResults.find(id);\n\tif (it == tempResults.end()) {\n\t\treturn false;\n\t}\n\n\ttempResults.erase(it);\n\treturn true;\n}\n\nDBResult_ptr ScriptEnvironment::getResultByID(uint32_t id)\n{\n\tauto it = tempResults.find(id);\n\tif (it == tempResults.end()) {\n\t\treturn nullptr;\n\t}\n\treturn it->second;\n}\n\nstd::string LuaScriptInterface::getErrorDesc(ErrorCode_t code)\n{\n\tswitch (code) {\n\t\tcase LUA_ERROR_PLAYER_NOT_FOUND: return \"Player not found\";\n\t\tcase LUA_ERROR_CREATURE_NOT_FOUND: return \"Creature not found\";\n\t\tcase LUA_ERROR_ITEM_NOT_FOUND: return \"Item not found\";\n\t\tcase LUA_ERROR_THING_NOT_FOUND: return \"Thing not found\";\n\t\tcase LUA_ERROR_TILE_NOT_FOUND: return \"Tile not found\";\n\t\tcase LUA_ERROR_HOUSE_NOT_FOUND: return \"House not found\";\n\t\tcase LUA_ERROR_COMBAT_NOT_FOUND: return \"Combat not found\";\n\t\tcase LUA_ERROR_CONDITION_NOT_FOUND: return \"Condition not found\";\n\t\tcase LUA_ERROR_AREA_NOT_FOUND: return \"Area not found\";\n\t\tcase LUA_ERROR_CONTAINER_NOT_FOUND: return \"Container not found\";\n\t\tcase LUA_ERROR_VARIANT_NOT_FOUND: return \"Variant not found\";\n\t\tcase LUA_ERROR_VARIANT_UNKNOWN: return \"Unknown variant type\";\n\t\tcase LUA_ERROR_SPELL_NOT_FOUND: return \"Spell not found\";\n\t\tdefault: return \"Bad error code\";\n\t}\n}\n\nScriptEnvironment LuaScriptInterface::scriptEnv[16];\nint32_t LuaScriptInterface::scriptEnvIndex = -1;\n\nLuaScriptInterface::LuaScriptInterface(std::string interfaceName) : interfaceName(std::move(interfaceName))\n{\n\tif (!g_luaEnvironment.getLuaState()) {\n\t\tg_luaEnvironment.initState();\n\t}\n}\n\nLuaScriptInterface::~LuaScriptInterface()\n{\n\tcloseState();\n}\n\nbool LuaScriptInterface::reInitState()\n{\n\tg_luaEnvironment.clearCombatObjects(this);\n\tg_luaEnvironment.clearAreaObjects(this);\n\n\tcloseState();\n\treturn initState();\n}\n\n/// Same as lua_pcall, but adds stack trace to error strings in called function.\nint LuaScriptInterface::protectedCall(lua_State* L, int nargs, int nresults)\n{\n\tint error_index = lua_gettop(L) - nargs;\n\tlua_pushcfunction(L, luaErrorHandler);\n\tlua_insert(L, error_index);\n\n\tint ret = lua_pcall(L, nargs, nresults, error_index);\n\tlua_remove(L, error_index);\n\treturn ret;\n}\n\nint32_t LuaScriptInterface::loadFile(const std::string& file, Npc* npc /* = nullptr*/)\n{\n\t//loads file as a chunk at stack top\n\tint ret = luaL_loadfile(luaState, file.c_str());\n\tif (ret != 0) {\n\t\tlastLuaError = popString(luaState);\n\t\treturn -1;\n\t}\n\n\t//check that it is loaded as a function\n\tif (!isFunction(luaState, -1)) {\n\t\treturn -1;\n\t}\n\n\tloadingFile = file;\n\n\tif (!reserveScriptEnv()) {\n\t\treturn -1;\n\t}\n\n\tScriptEnvironment* env = getScriptEnv();\n\tenv->setScriptId(EVENT_ID_LOADING, this);\n\tenv->setNpc(npc);\n\n\t//execute it\n\tret = protectedCall(luaState, 0, 0);\n\tif (ret != 0) {\n\t\treportError(nullptr, popString(luaState));\n\t\tresetScriptEnv();\n\t\treturn -1;\n\t}\n\n\tresetScriptEnv();\n\treturn 0;\n}\n\nint32_t LuaScriptInterface::getEvent(const std::string& eventName)\n{\n\t//get our events table\n\tlua_rawgeti(luaState, LUA_REGISTRYINDEX, eventTableRef);\n\tif (!isTable(luaState, -1)) {\n\t\tlua_pop(luaState, 1);\n\t\treturn -1;\n\t}\n\n\t//get current event function pointer\n\tlua_getglobal(luaState, eventName.c_str());\n\tif (!isFunction(luaState, -1)) {\n\t\tlua_pop(luaState, 2);\n\t\treturn -1;\n\t}\n\n\t//save in our events table\n\tlua_pushvalue(luaState, -1);\n\tlua_rawseti(luaState, -3, runningEventId);\n\tlua_pop(luaState, 2);\n\n\t//reset global value of this event\n\tlua_pushnil(luaState);\n\tlua_setglobal(luaState, eventName.c_str());\n\n\tcacheFiles[runningEventId] = loadingFile + \":\" + eventName;\n\treturn runningEventId++;\n}\n\nint32_t LuaScriptInterface::getEvent()\n{\n\t//check if function is on the stack\n\tif (!isFunction(luaState, -1)) {\n\t\treturn -1;\n\t}\n\n\t//get our events table\n\tlua_rawgeti(luaState, LUA_REGISTRYINDEX, eventTableRef);\n\tif (!isTable(luaState, -1)) {\n\t\tlua_pop(luaState, 1);\n\t\treturn -1;\n\t}\n\n\t//save in our events table\n\tlua_pushvalue(luaState, -2);\n\tlua_rawseti(luaState, -2, runningEventId);\n\tlua_pop(luaState, 2);\n\n\tcacheFiles[runningEventId] = loadingFile + \":callback\";\n\treturn runningEventId++;\n}\n\nint32_t LuaScriptInterface::getMetaEvent(const std::string& globalName, const std::string& eventName)\n{\n\t//get our events table\n\tlua_rawgeti(luaState, LUA_REGISTRYINDEX, eventTableRef);\n\tif (!isTable(luaState, -1)) {\n\t\tlua_pop(luaState, 1);\n\t\treturn -1;\n\t}\n\n\t//get current event function pointer\n\tlua_getglobal(luaState, globalName.c_str());\n\tlua_getfield(luaState, -1, eventName.c_str());\n\tif (!isFunction(luaState, -1)) {\n\t\tlua_pop(luaState, 3);\n\t\treturn -1;\n\t}\n\n\t//save in our events table\n\tlua_pushvalue(luaState, -1);\n\tlua_rawseti(luaState, -4, runningEventId);\n\tlua_pop(luaState, 1);\n\n\t//reset global value of this event\n\tlua_pushnil(luaState);\n\tlua_setfield(luaState, -2, eventName.c_str());\n\tlua_pop(luaState, 2);\n\n\tcacheFiles[runningEventId] = loadingFile + \":\" + globalName + \"@\" + eventName;\n\treturn runningEventId++;\n}\n\nconst std::string& LuaScriptInterface::getFileById(int32_t scriptId)\n{\n\tif (scriptId == EVENT_ID_LOADING) {\n\t\treturn loadingFile;\n\t}\n\n\tauto it = cacheFiles.find(scriptId);\n\tif (it == cacheFiles.end()) {\n\t\tstatic const std::string& unk = \"(Unknown scriptfile)\";\n\t\treturn unk;\n\t}\n\treturn it->second;\n}\n\nstd::string LuaScriptInterface::getStackTrace(const std::string& error_desc)\n{\n\tlua_getglobal(luaState, \"debug\");\n\tif (!isTable(luaState, -1)) {\n\t\tlua_pop(luaState, 1);\n\t\treturn error_desc;\n\t}\n\n\tlua_getfield(luaState, -1, \"traceback\");\n\tif (!isFunction(luaState, -1)) {\n\t\tlua_pop(luaState, 2);\n\t\treturn error_desc;\n\t}\n\n\tlua_replace(luaState, -2);\n\tpushString(luaState, error_desc);\n\tlua_call(luaState, 1, 1);\n\treturn popString(luaState);\n}\n\nvoid LuaScriptInterface::reportError(const char* function, const std::string& error_desc, bool stack_trace/* = false*/)\n{\n\tint32_t scriptId;\n\tint32_t callbackId;\n\tbool timerEvent;\n\tLuaScriptInterface* scriptInterface;\n\tgetScriptEnv()->getEventInfo(scriptId, scriptInterface, callbackId, timerEvent);\n\n\tstd::cout << std::endl << \"Lua Script Error: \";\n\n\tif (scriptInterface) {\n\t\tstd::cout << '[' << scriptInterface->getInterfaceName() << \"] \" << std::endl;\n\n\t\tif (timerEvent) {\n\t\t\tstd::cout << \"in a timer event called from: \" << std::endl;\n\t\t}\n\n\t\tif (callbackId) {\n\t\t\tstd::cout << \"in callback: \" << scriptInterface->getFileById(callbackId) << std::endl;\n\t\t}\n\n\t\tstd::cout << scriptInterface->getFileById(scriptId) << std::endl;\n\t}\n\n\tif (function) {\n\t\tstd::cout << function << \"(). \";\n\t}\n\n\tif (stack_trace && scriptInterface) {\n\t\tstd::cout << scriptInterface->getStackTrace(error_desc) << std::endl;\n\t} else {\n\t\tstd::cout << error_desc << std::endl;\n\t}\n}\n\nbool LuaScriptInterface::pushFunction(int32_t functionId)\n{\n\tlua_rawgeti(luaState, LUA_REGISTRYINDEX, eventTableRef);\n\tif (!isTable(luaState, -1)) {\n\t\treturn false;\n\t}\n\n\tlua_rawgeti(luaState, -1, functionId);\n\tlua_replace(luaState, -2);\n\treturn isFunction(luaState, -1);\n}\n\nbool LuaScriptInterface::initState()\n{\n\tluaState = g_luaEnvironment.getLuaState();\n\tif (!luaState) {\n\t\treturn false;\n\t}\n\n\tlua_newtable(luaState);\n\teventTableRef = luaL_ref(luaState, LUA_REGISTRYINDEX);\n\trunningEventId = EVENT_ID_USER;\n\treturn true;\n}\n\nbool LuaScriptInterface::closeState()\n{\n\tif (!g_luaEnvironment.getLuaState() || !luaState) {\n\t\treturn false;\n\t}\n\n\tcacheFiles.clear();\n\tif (eventTableRef != -1) {\n\t\tluaL_unref(luaState, LUA_REGISTRYINDEX, eventTableRef);\n\t\teventTableRef = -1;\n\t}\n\n\tluaState = nullptr;\n\treturn true;\n}\n\nint LuaScriptInterface::luaErrorHandler(lua_State* L)\n{\n\tconst std::string& errorMessage = popString(L);\n\tauto interface = getScriptEnv()->getScriptInterface();\n\tassert(interface); //This fires if the ScriptEnvironment hasn't been setup\n\tpushString(L, interface->getStackTrace(errorMessage));\n\treturn 1;\n}\n\nbool LuaScriptInterface::callFunction(int params)\n{\n\tbool result = false;\n\tint size = lua_gettop(luaState);\n\tif (protectedCall(luaState, params, 1) != 0) {\n\t\tLuaScriptInterface::reportError(nullptr, LuaScriptInterface::getString(luaState, -1));\n\t} else {\n\t\tresult = LuaScriptInterface::getBoolean(luaState, -1);\n\t}\n\n\tlua_pop(luaState, 1);\n\tif ((lua_gettop(luaState) + params + 1) != size) {\n\t\tLuaScriptInterface::reportError(nullptr, \"Stack size changed!\");\n\t}\n\n\tresetScriptEnv();\n\treturn result;\n}\n\nvoid LuaScriptInterface::callVoidFunction(int params)\n{\n\tint size = lua_gettop(luaState);\n\tif (protectedCall(luaState, params, 0) != 0) {\n\t\tLuaScriptInterface::reportError(nullptr, LuaScriptInterface::popString(luaState));\n\t}\n\n\tif ((lua_gettop(luaState) + params + 1) != size) {\n\t\tLuaScriptInterface::reportError(nullptr, \"Stack size changed!\");\n\t}\n\n\tresetScriptEnv();\n}\n\nvoid LuaScriptInterface::pushVariant(lua_State* L, const LuaVariant& var)\n{\n\tlua_createtable(L, 0, 2);\n\tsetField(L, \"type\", var.type);\n\tswitch (var.type) {\n\t\tcase VARIANT_NUMBER:\n\t\t\tsetField(L, \"number\", var.number);\n\t\t\tbreak;\n\t\tcase VARIANT_STRING:\n\t\t\tsetField(L, \"string\", var.text);\n\t\t\tbreak;\n\t\tcase VARIANT_TARGETPOSITION:\n\t\tcase VARIANT_POSITION: {\n\t\t\tpushPosition(L, var.pos);\n\t\t\tlua_setfield(L, -2, \"pos\");\n\t\t\tbreak;\n\t\t}\n\t\tdefault:\n\t\t\tbreak;\n\t}\n\tsetMetatable(L, -1, \"Variant\");\n}\n\nvoid LuaScriptInterface::pushThing(lua_State* L, Thing* thing)\n{\n\tif (!thing) {\n\t\tlua_createtable(L, 0, 4);\n\t\tsetField(L, \"uid\", 0);\n\t\tsetField(L, \"itemid\", 0);\n\t\tsetField(L, \"actionid\", 0);\n\t\tsetField(L, \"type\", 0);\n\t\treturn;\n\t}\n\n\tif (Item* item = thing->getItem()) {\n\t\tpushUserdata<Item>(L, item);\n\t\tsetItemMetatable(L, -1, item);\n\t} else if (Creature* creature = thing->getCreature()) {\n\t\tpushUserdata<Creature>(L, creature);\n\t\tsetCreatureMetatable(L, -1, creature);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n}\n\nvoid LuaScriptInterface::pushCylinder(lua_State* L, Cylinder* cylinder)\n{\n\tif (Creature* creature = cylinder->getCreature()) {\n\t\tpushUserdata<Creature>(L, creature);\n\t\tsetCreatureMetatable(L, -1, creature);\n\t} else if (Item* parentItem = cylinder->getItem()) {\n\t\tpushUserdata<Item>(L, parentItem);\n\t\tsetItemMetatable(L, -1, parentItem);\n\t} else if (Tile* tile = cylinder->getTile()) {\n\t\tpushUserdata<Tile>(L, tile);\n\t\tsetMetatable(L, -1, \"Tile\");\n\t} else if (cylinder == VirtualCylinder::virtualCylinder) {\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n}\n\nvoid LuaScriptInterface::pushString(lua_State* L, const std::string& value)\n{\n\tlua_pushlstring(L, value.c_str(), value.length());\n}\n\nvoid LuaScriptInterface::pushCallback(lua_State* L, int32_t callback)\n{\n\tlua_rawgeti(L, LUA_REGISTRYINDEX, callback);\n}\n\nstd::string LuaScriptInterface::popString(lua_State* L)\n{\n\tif (lua_gettop(L) == 0) {\n\t\treturn std::string();\n\t}\n\n\tstd::string str(getString(L, -1));\n\tlua_pop(L, 1);\n\treturn str;\n}\n\nint32_t LuaScriptInterface::popCallback(lua_State* L)\n{\n\treturn luaL_ref(L, LUA_REGISTRYINDEX);\n}\n\n// Metatables\nvoid LuaScriptInterface::setMetatable(lua_State* L, int32_t index, const std::string& name)\n{\n\tluaL_getmetatable(L, name.c_str());\n\tlua_setmetatable(L, index - 1);\n}\n\nvoid LuaScriptInterface::setWeakMetatable(lua_State* L, int32_t index, const std::string& name)\n{\n\tstatic std::set<std::string> weakObjectTypes;\n\tconst std::string& weakName = name + \"_weak\";\n\n\tauto result = weakObjectTypes.emplace(name);\n\tif (result.second) {\n\t\tluaL_getmetatable(L, name.c_str());\n\t\tint childMetatable = lua_gettop(L);\n\n\t\tluaL_newmetatable(L, weakName.c_str());\n\t\tint metatable = lua_gettop(L);\n\n\t\tstatic const std::vector<std::string> methodKeys = {\"__index\", \"__metatable\", \"__eq\"};\n\t\tfor (const std::string& metaKey : methodKeys) {\n\t\t\tlua_getfield(L, childMetatable, metaKey.c_str());\n\t\t\tlua_setfield(L, metatable, metaKey.c_str());\n\t\t}\n\n\t\tstatic const std::vector<int> methodIndexes = {'h', 'p', 't'};\n\t\tfor (int metaIndex : methodIndexes) {\n\t\t\tlua_rawgeti(L, childMetatable, metaIndex);\n\t\t\tlua_rawseti(L, metatable, metaIndex);\n\t\t}\n\n\t\tlua_pushnil(L);\n\t\tlua_setfield(L, metatable, \"__gc\");\n\n\t\tlua_remove(L, childMetatable);\n\t} else {\n\t\tluaL_getmetatable(L, weakName.c_str());\n\t}\n\tlua_setmetatable(L, index - 1);\n}\n\nvoid LuaScriptInterface::setItemMetatable(lua_State* L, int32_t index, const Item* item)\n{\n\tif (item->getContainer()) {\n\t\tluaL_getmetatable(L, \"Container\");\n\t} else if (item->getTeleport()) {\n\t\tluaL_getmetatable(L, \"Teleport\");\n\t} else {\n\t\tluaL_getmetatable(L, \"Item\");\n\t}\n\tlua_setmetatable(L, index - 1);\n}\n\nvoid LuaScriptInterface::setCreatureMetatable(lua_State* L, int32_t index, const Creature* creature)\n{\n\tif (creature->getPlayer()) {\n\t\tluaL_getmetatable(L, \"Player\");\n\t} else if (creature->getMonster()) {\n\t\tluaL_getmetatable(L, \"Monster\");\n\t} else {\n\t\tluaL_getmetatable(L, \"Npc\");\n\t}\n\tlua_setmetatable(L, index - 1);\n}\n\n// Get\nstd::string LuaScriptInterface::getString(lua_State* L, int32_t arg)\n{\n\tsize_t len;\n\tconst char* c_str = lua_tolstring(L, arg, &len);\n\tif (!c_str || len == 0) {\n\t\treturn std::string();\n\t}\n\treturn std::string(c_str, len);\n}\n\nPosition LuaScriptInterface::getPosition(lua_State* L, int32_t arg, int32_t& stackpos)\n{\n\tPosition position;\n\tposition.x = getField<uint16_t>(L, arg, \"x\");\n\tposition.y = getField<uint16_t>(L, arg, \"y\");\n\tposition.z = getField<uint8_t>(L, arg, \"z\");\n\n\tlua_getfield(L, arg, \"stackpos\");\n\tif (lua_isnil(L, -1) == 1) {\n\t\tstackpos = 0;\n\t} else {\n\t\tstackpos = getNumber<int32_t>(L, -1);\n\t}\n\n\tlua_pop(L, 4);\n\treturn position;\n}\n\nPosition LuaScriptInterface::getPosition(lua_State* L, int32_t arg)\n{\n\tPosition position;\n\tposition.x = getField<uint16_t>(L, arg, \"x\");\n\tposition.y = getField<uint16_t>(L, arg, \"y\");\n\tposition.z = getField<uint8_t>(L, arg, \"z\");\n\n\tlua_pop(L, 3);\n\treturn position;\n}\n\nOutfit_t LuaScriptInterface::getOutfit(lua_State* L, int32_t arg)\n{\n\tOutfit_t outfit;\n\toutfit.lookMount = getField<uint16_t>(L, arg, \"lookMount\");\n\toutfit.lookAddons = getField<uint8_t>(L, arg, \"lookAddons\");\n\n\toutfit.lookFeet = getField<uint8_t>(L, arg, \"lookFeet\");\n\toutfit.lookLegs = getField<uint8_t>(L, arg, \"lookLegs\");\n\toutfit.lookBody = getField<uint8_t>(L, arg, \"lookBody\");\n\toutfit.lookHead = getField<uint8_t>(L, arg, \"lookHead\");\n\n\toutfit.lookTypeEx = getField<uint16_t>(L, arg, \"lookTypeEx\");\n\toutfit.lookType = getField<uint16_t>(L, arg, \"lookType\");\n\n\tlua_pop(L, 8);\n\treturn outfit;\n}\n\nOutfit LuaScriptInterface::getOutfitClass(lua_State* L, int32_t arg)\n{\n\tuint16_t lookType = getField<uint16_t>(L, arg, \"lookType\");\n\tconst std::string& name = getFieldString(L, arg, \"name\");\n\tbool premium = getField<uint8_t>(L, arg, \"premium\") == 1;\n\tbool unlocked = getField<uint8_t>(L, arg, \"unlocked\") == 1;\n\tlua_pop(L, 4);\n\treturn Outfit(name, lookType, premium, unlocked);\n}\n\nLuaVariant LuaScriptInterface::getVariant(lua_State* L, int32_t arg)\n{\n\tLuaVariant var;\n\tswitch (var.type = getField<LuaVariantType_t>(L, arg, \"type\")) {\n\t\tcase VARIANT_NUMBER: {\n\t\t\tvar.number = getField<uint32_t>(L, arg, \"number\");\n\t\t\tlua_pop(L, 2);\n\t\t\tbreak;\n\t\t}\n\n\t\tcase VARIANT_STRING: {\n\t\t\tvar.text = getFieldString(L, arg, \"string\");\n\t\t\tlua_pop(L, 2);\n\t\t\tbreak;\n\t\t}\n\n\t\tcase VARIANT_POSITION:\n\t\tcase VARIANT_TARGETPOSITION: {\n\t\t\tlua_getfield(L, arg, \"pos\");\n\t\t\tvar.pos = getPosition(L, lua_gettop(L));\n\t\t\tlua_pop(L, 2);\n\t\t\tbreak;\n\t\t}\n\n\t\tdefault: {\n\t\t\tvar.type = VARIANT_NONE;\n\t\t\tlua_pop(L, 1);\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn var;\n}\n\nInstantSpell* LuaScriptInterface::getInstantSpell(lua_State* L, int32_t arg)\n{\n\tInstantSpell* spell = g_spells->getInstantSpellByName(getFieldString(L, arg, \"name\"));\n\tlua_pop(L, 1);\n\treturn spell;\n}\n\nThing* LuaScriptInterface::getThing(lua_State* L, int32_t arg)\n{\n\tThing* thing;\n\tif (lua_getmetatable(L, arg) != 0) {\n\t\tlua_rawgeti(L, -1, 't');\n\t\tswitch(getNumber<uint32_t>(L, -1)) {\n\t\t\tcase LuaData_Item:\n\t\t\t\tthing = getUserdata<Item>(L, arg);\n\t\t\t\tbreak;\n\t\t\tcase LuaData_Container:\n\t\t\t\tthing = getUserdata<Container>(L, arg);\n\t\t\t\tbreak;\n\t\t\tcase LuaData_Teleport:\n\t\t\t\tthing = getUserdata<Teleport>(L, arg);\n\t\t\t\tbreak;\n\t\t\tcase LuaData_Player:\n\t\t\t\tthing = getUserdata<Player>(L, arg);\n\t\t\t\tbreak;\n\t\t\tcase LuaData_Monster:\n\t\t\t\tthing = getUserdata<Monster>(L, arg);\n\t\t\t\tbreak;\n\t\t\tcase LuaData_Npc:\n\t\t\t\tthing = getUserdata<Npc>(L, arg);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tthing = nullptr;\n\t\t\t\tbreak;\n\t\t}\n\t\tlua_pop(L, 2);\n\t} else {\n\t\tthing = getScriptEnv()->getThingByUID(getNumber<uint32_t>(L, arg));\n\t}\n\treturn thing;\n}\n\nCreature* LuaScriptInterface::getCreature(lua_State* L, int32_t arg)\n{\n\tif (isUserdata(L, arg)) {\n\t\treturn getUserdata<Creature>(L, arg);\n\t}\n\treturn g_game.getCreatureByID(getNumber<uint32_t>(L, arg));\n}\n\nPlayer* LuaScriptInterface::getPlayer(lua_State* L, int32_t arg)\n{\n\tif (isUserdata(L, arg)) {\n\t\treturn getUserdata<Player>(L, arg);\n\t}\n\treturn g_game.getPlayerByID(getNumber<uint32_t>(L, arg));\n}\n\nstd::string LuaScriptInterface::getFieldString(lua_State* L, int32_t arg, const std::string& key)\n{\n\tlua_getfield(L, arg, key.c_str());\n\treturn getString(L, -1);\n}\n\nLuaDataType LuaScriptInterface::getUserdataType(lua_State* L, int32_t arg)\n{\n\tif (lua_getmetatable(L, arg) == 0) {\n\t\treturn LuaData_Unknown;\n\t}\n\tlua_rawgeti(L, -1, 't');\n\n\tLuaDataType type = getNumber<LuaDataType>(L, -1);\n\tlua_pop(L, 2);\n\n\treturn type;\n}\n\n// Push\nvoid LuaScriptInterface::pushBoolean(lua_State* L, bool value)\n{\n\tlua_pushboolean(L, value ? 1 : 0);\n}\n\nvoid LuaScriptInterface::pushCombatDamage(lua_State* L, const CombatDamage& damage)\n{\n\tlua_pushnumber(L, damage.primary.value);\n\tlua_pushnumber(L, damage.primary.type);\n\tlua_pushnumber(L, damage.secondary.value);\n\tlua_pushnumber(L, damage.secondary.type);\n\tlua_pushnumber(L, damage.origin);\n}\n\nvoid LuaScriptInterface::pushInstantSpell(lua_State* L, const InstantSpell& spell)\n{\n\tlua_createtable(L, 0, 6);\n\n\tsetField(L, \"name\", spell.getName());\n\tsetField(L, \"words\", spell.getWords().front());\n\tsetField(L, \"level\", spell.getLevel());\n\tsetField(L, \"mlevel\", spell.getMagicLevel());\n\tsetField(L, \"mana\", spell.getMana());\n\tsetField(L, \"manapercent\", spell.getManaPercent());\n\n\tsetMetatable(L, -1, \"Spell\");\n}\n\nvoid LuaScriptInterface::pushPosition(lua_State* L, const Position& position, int32_t stackpos/* = 0*/)\n{\n\tlua_createtable(L, 0, 4);\n\n\tsetField(L, \"x\", position.x);\n\tsetField(L, \"y\", position.y);\n\tsetField(L, \"z\", position.z);\n\tsetField(L, \"stackpos\", stackpos);\n\n\tsetMetatable(L, -1, \"Position\");\n}\n\nvoid LuaScriptInterface::pushOutfit(lua_State* L, const Outfit_t& outfit)\n{\n\tlua_createtable(L, 0, 8);\n\tsetField(L, \"lookType\", outfit.lookType);\n\tsetField(L, \"lookTypeEx\", outfit.lookTypeEx);\n\tsetField(L, \"lookHead\", outfit.lookHead);\n\tsetField(L, \"lookBody\", outfit.lookBody);\n\tsetField(L, \"lookLegs\", outfit.lookLegs);\n\tsetField(L, \"lookFeet\", outfit.lookFeet);\n\tsetField(L, \"lookAddons\", outfit.lookAddons);\n\tsetField(L, \"lookMount\", outfit.lookMount);\n}\n\nvoid LuaScriptInterface::pushOutfit(lua_State* L, const Outfit* outfit)\n{\n\tlua_createtable(L, 0, 4);\n\tsetField(L, \"lookType\", outfit->lookType);\n\tsetField(L, \"name\", outfit->name);\n\tsetField(L, \"premium\", outfit->premium);\n\tsetField(L, \"unlocked\", outfit->unlocked);\n\tsetMetatable(L, -1, \"Outfit\");\n}\n\nvoid LuaScriptInterface::pushLoot(lua_State* L, const std::vector<LootBlock>& lootList)\n{\n\tlua_createtable(L, lootList.size(), 0);\n\n\tint index = 0;\n\tfor (const auto& lootBlock : lootList) {\n\t\tlua_createtable(L, 0, 7);\n\n\t\tsetField(L, \"itemId\", lootBlock.id);\n\t\tsetField(L, \"chance\", lootBlock.chance);\n\t\tsetField(L, \"subType\", lootBlock.subType);\n\t\tsetField(L, \"maxCount\", lootBlock.countmax);\n\t\tsetField(L, \"actionId\", lootBlock.actionId);\n\t\tsetField(L, \"text\", lootBlock.text);\n\n\t\tpushLoot(L, lootBlock.childLoot);\n\t\tlua_setfield(L, -2, \"childLoot\");\n\n\t\tlua_rawseti(L, -2, ++index);\n\t}\n}\n\n#define registerEnum(value) { std::string enumName = #value; registerGlobalVariable(enumName.substr(enumName.find_last_of(':') + 1), value); }\n#define registerEnumIn(tableName, value) { std::string enumName = #value; registerVariable(tableName, enumName.substr(enumName.find_last_of(':') + 1), value); }\n\nvoid LuaScriptInterface::registerFunctions()\n{\n\t//doPlayerAddItem(uid, itemid, <optional: default: 1> count/subtype)\n\t//doPlayerAddItem(cid, itemid, <optional: default: 1> count, <optional: default: 1> canDropOnMap, <optional: default: 1>subtype)\n\t//Returns uid of the created item\n\tlua_register(luaState, \"doPlayerAddItem\", LuaScriptInterface::luaDoPlayerAddItem);\n\n\t//isValidUID(uid)\n\tlua_register(luaState, \"isValidUID\", LuaScriptInterface::luaIsValidUID);\n\n\t//isDepot(uid)\n\tlua_register(luaState, \"isDepot\", LuaScriptInterface::luaIsDepot);\n\n\t//isMovable(uid)\n\tlua_register(luaState, \"isMovable\", LuaScriptInterface::luaIsMoveable);\n\n\t//doAddContainerItem(uid, itemid, <optional> count/subtype)\n\tlua_register(luaState, \"doAddContainerItem\", LuaScriptInterface::luaDoAddContainerItem);\n\n\t//getDepotId(uid)\n\tlua_register(luaState, \"getDepotId\", LuaScriptInterface::luaGetDepotId);\n\n\t//getWorldTime()\n\tlua_register(luaState, \"getWorldTime\", LuaScriptInterface::luaGetWorldTime);\n\n\t//getWorldLight()\n\tlua_register(luaState, \"getWorldLight\", LuaScriptInterface::luaGetWorldLight);\n\n\t//getWorldUpTime()\n\tlua_register(luaState, \"getWorldUpTime\", LuaScriptInterface::luaGetWorldUpTime);\n\n\t//createCombatArea( {area}, <optional> {extArea} )\n\tlua_register(luaState, \"createCombatArea\", LuaScriptInterface::luaCreateCombatArea);\n\n\t//doAreaCombat(cid, type, pos, area, min, max, effect)\n\tlua_register(luaState, \"doAreaCombat\", LuaScriptInterface::luaDoAreaCombat);\n\n\t//doTargetCombat(cid, target, type, min, max, effect)\n\tlua_register(luaState, \"doTargetCombat\", LuaScriptInterface::luaDoTargetCombat);\n\n\t//doChallengeCreature(cid, target)\n\tlua_register(luaState, \"doChallengeCreature\", LuaScriptInterface::luaDoChallengeCreature);\n\n\t//addEvent(callback, delay, ...)\n\tlua_register(luaState, \"addEvent\", LuaScriptInterface::luaAddEvent);\n\n\t//stopEvent(eventid)\n\tlua_register(luaState, \"stopEvent\", LuaScriptInterface::luaStopEvent);\n\n\t//saveServer()\n\tlua_register(luaState, \"saveServer\", LuaScriptInterface::luaSaveServer);\n\n\t//cleanMap()\n\tlua_register(luaState, \"cleanMap\", LuaScriptInterface::luaCleanMap);\n\n\t//debugPrint(text)\n\tlua_register(luaState, \"debugPrint\", LuaScriptInterface::luaDebugPrint);\n\n\t//isInWar(cid, target)\n\tlua_register(luaState, \"isInWar\", LuaScriptInterface::luaIsInWar);\n\n\t//getWaypointPosition(name)\n\tlua_register(luaState, \"getWaypointPositionByName\", LuaScriptInterface::luaGetWaypointPositionByName);\n\n\t//sendChannelMessage(channelId, type, message)\n\tlua_register(luaState, \"sendChannelMessage\", LuaScriptInterface::luaSendChannelMessage);\n\n\t//sendGuildChannelMessage(guildId, type, message)\n\tlua_register(luaState, \"sendGuildChannelMessage\", LuaScriptInterface::luaSendGuildChannelMessage);\n\n\t//isScriptsInterface()\n\tlua_register(luaState, \"isScriptsInterface\", LuaScriptInterface::luaIsScriptsInterface);\n\n#ifndef LUAJIT_VERSION\n\t//bit operations for Lua, based on bitlib project release 24\n\t//bit.bnot, bit.band, bit.bor, bit.bxor, bit.lshift, bit.rshift\n\tluaL_register(luaState, \"bit\", LuaScriptInterface::luaBitReg);\n#endif\n\n\t//configManager table\n\tluaL_register(luaState, \"configManager\", LuaScriptInterface::luaConfigManagerTable);\n\n\t//db table\n\tluaL_register(luaState, \"db\", LuaScriptInterface::luaDatabaseTable);\n\n\t//result table\n\tluaL_register(luaState, \"result\", LuaScriptInterface::luaResultTable);\n\n\t/* New functions */\n\t//registerClass(className, baseClass, newFunction)\n\t//registerTable(tableName)\n\t//registerMethod(className, functionName, function)\n\t//registerMetaMethod(className, functionName, function)\n\t//registerGlobalMethod(functionName, function)\n\t//registerVariable(tableName, name, value)\n\t//registerGlobalVariable(name, value)\n\t//registerEnum(value)\n\t//registerEnumIn(tableName, value)\n\n\t// Enums\n\tregisterEnum(ACCOUNT_TYPE_NORMAL)\n\tregisterEnum(ACCOUNT_TYPE_TUTOR)\n\tregisterEnum(ACCOUNT_TYPE_SENIORTUTOR)\n\tregisterEnum(ACCOUNT_TYPE_GAMEMASTER)\n\tregisterEnum(ACCOUNT_TYPE_GOD)\n\n\tregisterEnum(BUG_CATEGORY_MAP)\n\tregisterEnum(BUG_CATEGORY_TYPO)\n\tregisterEnum(BUG_CATEGORY_TECHNICAL)\n\tregisterEnum(BUG_CATEGORY_OTHER)\n\n\tregisterEnum(CALLBACK_PARAM_LEVELMAGICVALUE)\n\tregisterEnum(CALLBACK_PARAM_SKILLVALUE)\n\tregisterEnum(CALLBACK_PARAM_TARGETTILE)\n\tregisterEnum(CALLBACK_PARAM_TARGETCREATURE)\n\n\tregisterEnum(COMBAT_FORMULA_UNDEFINED)\n\tregisterEnum(COMBAT_FORMULA_LEVELMAGIC)\n\tregisterEnum(COMBAT_FORMULA_SKILL)\n\tregisterEnum(COMBAT_FORMULA_DAMAGE)\n\n\tregisterEnum(DIRECTION_NORTH)\n\tregisterEnum(DIRECTION_EAST)\n\tregisterEnum(DIRECTION_SOUTH)\n\tregisterEnum(DIRECTION_WEST)\n\tregisterEnum(DIRECTION_SOUTHWEST)\n\tregisterEnum(DIRECTION_SOUTHEAST)\n\tregisterEnum(DIRECTION_NORTHWEST)\n\tregisterEnum(DIRECTION_NORTHEAST)\n\n\tregisterEnum(COMBAT_NONE)\n\tregisterEnum(COMBAT_PHYSICALDAMAGE)\n\tregisterEnum(COMBAT_ENERGYDAMAGE)\n\tregisterEnum(COMBAT_EARTHDAMAGE)\n\tregisterEnum(COMBAT_FIREDAMAGE)\n\tregisterEnum(COMBAT_UNDEFINEDDAMAGE)\n\tregisterEnum(COMBAT_LIFEDRAIN)\n\tregisterEnum(COMBAT_MANADRAIN)\n\tregisterEnum(COMBAT_HEALING)\n\tregisterEnum(COMBAT_DROWNDAMAGE)\n\tregisterEnum(COMBAT_ICEDAMAGE)\n\tregisterEnum(COMBAT_HOLYDAMAGE)\n\tregisterEnum(COMBAT_DEATHDAMAGE)\n\n\tregisterEnum(COMBAT_PARAM_TYPE)\n\tregisterEnum(COMBAT_PARAM_EFFECT)\n\tregisterEnum(COMBAT_PARAM_DISTANCEEFFECT)\n\tregisterEnum(COMBAT_PARAM_BLOCKSHIELD)\n\tregisterEnum(COMBAT_PARAM_BLOCKARMOR)\n\tregisterEnum(COMBAT_PARAM_TARGETCASTERORTOPMOST)\n\tregisterEnum(COMBAT_PARAM_CREATEITEM)\n\tregisterEnum(COMBAT_PARAM_AGGRESSIVE)\n\tregisterEnum(COMBAT_PARAM_DISPEL)\n\tregisterEnum(COMBAT_PARAM_USECHARGES)\n\n\tregisterEnum(CONDITION_NONE)\n\tregisterEnum(CONDITION_POISON)\n\tregisterEnum(CONDITION_FIRE)\n\tregisterEnum(CONDITION_ENERGY)\n\tregisterEnum(CONDITION_BLEEDING)\n\tregisterEnum(CONDITION_HASTE)\n\tregisterEnum(CONDITION_PARALYZE)\n\tregisterEnum(CONDITION_OUTFIT)\n\tregisterEnum(CONDITION_INVISIBLE)\n\tregisterEnum(CONDITION_LIGHT)\n\tregisterEnum(CONDITION_MANASHIELD)\n\tregisterEnum(CONDITION_INFIGHT)\n\tregisterEnum(CONDITION_DRUNK)\n\tregisterEnum(CONDITION_EXHAUST_WEAPON)\n\tregisterEnum(CONDITION_REGENERATION)\n\tregisterEnum(CONDITION_SOUL)\n\tregisterEnum(CONDITION_DROWN)\n\tregisterEnum(CONDITION_MUTED)\n\tregisterEnum(CONDITION_CHANNELMUTEDTICKS)\n\tregisterEnum(CONDITION_YELLTICKS)\n\tregisterEnum(CONDITION_ATTRIBUTES)\n\tregisterEnum(CONDITION_FREEZING)\n\tregisterEnum(CONDITION_DAZZLED)\n\tregisterEnum(CONDITION_CURSED)\n\tregisterEnum(CONDITION_EXHAUST_COMBAT)\n\tregisterEnum(CONDITION_EXHAUST_HEAL)\n\tregisterEnum(CONDITION_PACIFIED)\n\tregisterEnum(CONDITION_SPELLCOOLDOWN)\n\tregisterEnum(CONDITION_SPELLGROUPCOOLDOWN)\n\n\tregisterEnum(CONDITIONID_DEFAULT)\n\tregisterEnum(CONDITIONID_COMBAT)\n\tregisterEnum(CONDITIONID_HEAD)\n\tregisterEnum(CONDITIONID_NECKLACE)\n\tregisterEnum(CONDITIONID_BACKPACK)\n\tregisterEnum(CONDITIONID_ARMOR)\n\tregisterEnum(CONDITIONID_RIGHT)\n\tregisterEnum(CONDITIONID_LEFT)\n\tregisterEnum(CONDITIONID_LEGS)\n\tregisterEnum(CONDITIONID_FEET)\n\tregisterEnum(CONDITIONID_RING)\n\tregisterEnum(CONDITIONID_AMMO)\n\n\tregisterEnum(CONDITION_PARAM_OWNER)\n\tregisterEnum(CONDITION_PARAM_TICKS)\n\tregisterEnum(CONDITION_PARAM_HEALTHGAIN)\n\tregisterEnum(CONDITION_PARAM_HEALTHTICKS)\n\tregisterEnum(CONDITION_PARAM_MANAGAIN)\n\tregisterEnum(CONDITION_PARAM_MANATICKS)\n\tregisterEnum(CONDITION_PARAM_DELAYED)\n\tregisterEnum(CONDITION_PARAM_SPEED)\n\tregisterEnum(CONDITION_PARAM_LIGHT_LEVEL)\n\tregisterEnum(CONDITION_PARAM_LIGHT_COLOR)\n\tregisterEnum(CONDITION_PARAM_SOULGAIN)\n\tregisterEnum(CONDITION_PARAM_SOULTICKS)\n\tregisterEnum(CONDITION_PARAM_MINVALUE)\n\tregisterEnum(CONDITION_PARAM_MAXVALUE)\n\tregisterEnum(CONDITION_PARAM_STARTVALUE)\n\tregisterEnum(CONDITION_PARAM_TICKINTERVAL)\n\tregisterEnum(CONDITION_PARAM_FORCEUPDATE)\n\tregisterEnum(CONDITION_PARAM_SKILL_MELEE)\n\tregisterEnum(CONDITION_PARAM_SKILL_FIST)\n\tregisterEnum(CONDITION_PARAM_SKILL_CLUB)\n\tregisterEnum(CONDITION_PARAM_SKILL_SWORD)\n\tregisterEnum(CONDITION_PARAM_SKILL_AXE)\n\tregisterEnum(CONDITION_PARAM_SKILL_DISTANCE)\n\tregisterEnum(CONDITION_PARAM_SKILL_SHIELD)\n\tregisterEnum(CONDITION_PARAM_SKILL_FISHING)\n\tregisterEnum(CONDITION_PARAM_STAT_MAXHITPOINTS)\n\tregisterEnum(CONDITION_PARAM_STAT_MAXMANAPOINTS)\n\tregisterEnum(CONDITION_PARAM_STAT_MAGICPOINTS)\n\tregisterEnum(CONDITION_PARAM_STAT_MAXHITPOINTSPERCENT)\n\tregisterEnum(CONDITION_PARAM_STAT_MAXMANAPOINTSPERCENT)\n\tregisterEnum(CONDITION_PARAM_STAT_MAGICPOINTSPERCENT)\n\tregisterEnum(CONDITION_PARAM_PERIODICDAMAGE)\n\tregisterEnum(CONDITION_PARAM_SKILL_MELEEPERCENT)\n\tregisterEnum(CONDITION_PARAM_SKILL_FISTPERCENT)\n\tregisterEnum(CONDITION_PARAM_SKILL_CLUBPERCENT)\n\tregisterEnum(CONDITION_PARAM_SKILL_SWORDPERCENT)\n\tregisterEnum(CONDITION_PARAM_SKILL_AXEPERCENT)\n\tregisterEnum(CONDITION_PARAM_SKILL_DISTANCEPERCENT)\n\tregisterEnum(CONDITION_PARAM_SKILL_SHIELDPERCENT)\n\tregisterEnum(CONDITION_PARAM_SKILL_FISHINGPERCENT)\n\tregisterEnum(CONDITION_PARAM_BUFF_SPELL)\n\tregisterEnum(CONDITION_PARAM_SUBID)\n\tregisterEnum(CONDITION_PARAM_FIELD)\n\tregisterEnum(CONDITION_PARAM_DISABLE_DEFENSE)\n\tregisterEnum(CONDITION_PARAM_SPECIALSKILL_CRITICALHITCHANCE)\n\tregisterEnum(CONDITION_PARAM_SPECIALSKILL_CRITICALHITAMOUNT)\n\tregisterEnum(CONDITION_PARAM_SPECIALSKILL_LIFELEECHCHANCE)\n\tregisterEnum(CONDITION_PARAM_SPECIALSKILL_LIFELEECHAMOUNT)\n\tregisterEnum(CONDITION_PARAM_SPECIALSKILL_MANALEECHCHANCE)\n\tregisterEnum(CONDITION_PARAM_SPECIALSKILL_MANALEECHAMOUNT)\n\tregisterEnum(CONDITION_PARAM_AGGRESSIVE)\n\n\tregisterEnum(CONST_ME_NONE)\n\tregisterEnum(CONST_ME_DRAWBLOOD)\n\tregisterEnum(CONST_ME_LOSEENERGY)\n\tregisterEnum(CONST_ME_POFF)\n\tregisterEnum(CONST_ME_BLOCKHIT)\n\tregisterEnum(CONST_ME_EXPLOSIONAREA)\n\tregisterEnum(CONST_ME_EXPLOSIONHIT)\n\tregisterEnum(CONST_ME_FIREAREA)\n\tregisterEnum(CONST_ME_YELLOW_RINGS)\n\tregisterEnum(CONST_ME_GREEN_RINGS)\n\tregisterEnum(CONST_ME_HITAREA)\n\tregisterEnum(CONST_ME_TELEPORT)\n\tregisterEnum(CONST_ME_ENERGYHIT)\n\tregisterEnum(CONST_ME_MAGIC_BLUE)\n\tregisterEnum(CONST_ME_MAGIC_RED)\n\tregisterEnum(CONST_ME_MAGIC_GREEN)\n\tregisterEnum(CONST_ME_HITBYFIRE)\n\tregisterEnum(CONST_ME_HITBYPOISON)\n\tregisterEnum(CONST_ME_MORTAREA)\n\tregisterEnum(CONST_ME_SOUND_GREEN)\n\tregisterEnum(CONST_ME_SOUND_RED)\n\tregisterEnum(CONST_ME_POISONAREA)\n\tregisterEnum(CONST_ME_SOUND_YELLOW)\n\tregisterEnum(CONST_ME_SOUND_PURPLE)\n\tregisterEnum(CONST_ME_SOUND_BLUE)\n\tregisterEnum(CONST_ME_SOUND_WHITE)\n\tregisterEnum(CONST_ME_BUBBLES)\n\tregisterEnum(CONST_ME_CRAPS)\n\tregisterEnum(CONST_ME_GIFT_WRAPS)\n\tregisterEnum(CONST_ME_FIREWORK_YELLOW)\n\tregisterEnum(CONST_ME_FIREWORK_RED)\n\tregisterEnum(CONST_ME_FIREWORK_BLUE)\n\tregisterEnum(CONST_ME_STUN)\n\tregisterEnum(CONST_ME_SLEEP)\n\tregisterEnum(CONST_ME_WATERCREATURE)\n\tregisterEnum(CONST_ME_GROUNDSHAKER)\n\tregisterEnum(CONST_ME_HEARTS)\n\tregisterEnum(CONST_ME_FIREATTACK)\n\tregisterEnum(CONST_ME_ENERGYAREA)\n\tregisterEnum(CONST_ME_SMALLCLOUDS)\n\tregisterEnum(CONST_ME_HOLYDAMAGE)\n\tregisterEnum(CONST_ME_BIGCLOUDS)\n\tregisterEnum(CONST_ME_ICEAREA)\n\tregisterEnum(CONST_ME_ICETORNADO)\n\tregisterEnum(CONST_ME_ICEATTACK)\n\tregisterEnum(CONST_ME_STONES)\n\tregisterEnum(CONST_ME_SMALLPLANTS)\n\tregisterEnum(CONST_ME_CARNIPHILA)\n\tregisterEnum(CONST_ME_PURPLEENERGY)\n\tregisterEnum(CONST_ME_YELLOWENERGY)\n\tregisterEnum(CONST_ME_HOLYAREA)\n\tregisterEnum(CONST_ME_BIGPLANTS)\n\tregisterEnum(CONST_ME_CAKE)\n\tregisterEnum(CONST_ME_GIANTICE)\n\tregisterEnum(CONST_ME_WATERSPLASH)\n\tregisterEnum(CONST_ME_PLANTATTACK)\n\tregisterEnum(CONST_ME_TUTORIALARROW)\n\tregisterEnum(CONST_ME_TUTORIALSQUARE)\n\tregisterEnum(CONST_ME_MIRRORHORIZONTAL)\n\tregisterEnum(CONST_ME_MIRRORVERTICAL)\n\tregisterEnum(CONST_ME_SKULLHORIZONTAL)\n\tregisterEnum(CONST_ME_SKULLVERTICAL)\n\tregisterEnum(CONST_ME_ASSASSIN)\n\tregisterEnum(CONST_ME_STEPSHORIZONTAL)\n\tregisterEnum(CONST_ME_BLOODYSTEPS)\n\tregisterEnum(CONST_ME_STEPSVERTICAL)\n\tregisterEnum(CONST_ME_YALAHARIGHOST)\n\tregisterEnum(CONST_ME_BATS)\n\tregisterEnum(CONST_ME_SMOKE)\n\tregisterEnum(CONST_ME_INSECTS)\n\tregisterEnum(CONST_ME_DRAGONHEAD)\n\tregisterEnum(CONST_ME_ORCSHAMAN)\n\tregisterEnum(CONST_ME_ORCSHAMAN_FIRE)\n\tregisterEnum(CONST_ME_THUNDER)\n\tregisterEnum(CONST_ME_FERUMBRAS)\n\tregisterEnum(CONST_ME_CONFETTI_HORIZONTAL)\n\tregisterEnum(CONST_ME_CONFETTI_VERTICAL)\n\tregisterEnum(CONST_ME_BLACKSMOKE)\n\tregisterEnum(CONST_ME_REDSMOKE)\n\tregisterEnum(CONST_ME_YELLOWSMOKE)\n\tregisterEnum(CONST_ME_GREENSMOKE)\n\tregisterEnum(CONST_ME_PURPLESMOKE)\n\tregisterEnum(CONST_ME_EARLY_THUNDER)\n\tregisterEnum(CONST_ME_RAGIAZ_BONECAPSULE)\n\tregisterEnum(CONST_ME_CRITICAL_DAMAGE)\n\tregisterEnum(CONST_ME_PLUNGING_FISH)\n\n\tregisterEnum(CONST_ANI_NONE)\n\tregisterEnum(CONST_ANI_SPEAR)\n\tregisterEnum(CONST_ANI_BOLT)\n\tregisterEnum(CONST_ANI_ARROW)\n\tregisterEnum(CONST_ANI_FIRE)\n\tregisterEnum(CONST_ANI_ENERGY)\n\tregisterEnum(CONST_ANI_POISONARROW)\n\tregisterEnum(CONST_ANI_BURSTARROW)\n\tregisterEnum(CONST_ANI_THROWINGSTAR)\n\tregisterEnum(CONST_ANI_THROWINGKNIFE)\n\tregisterEnum(CONST_ANI_SMALLSTONE)\n\tregisterEnum(CONST_ANI_DEATH)\n\tregisterEnum(CONST_ANI_LARGEROCK)\n\tregisterEnum(CONST_ANI_SNOWBALL)\n\tregisterEnum(CONST_ANI_POWERBOLT)\n\tregisterEnum(CONST_ANI_POISON)\n\tregisterEnum(CONST_ANI_INFERNALBOLT)\n\tregisterEnum(CONST_ANI_HUNTINGSPEAR)\n\tregisterEnum(CONST_ANI_ENCHANTEDSPEAR)\n\tregisterEnum(CONST_ANI_REDSTAR)\n\tregisterEnum(CONST_ANI_GREENSTAR)\n\tregisterEnum(CONST_ANI_ROYALSPEAR)\n\tregisterEnum(CONST_ANI_SNIPERARROW)\n\tregisterEnum(CONST_ANI_ONYXARROW)\n\tregisterEnum(CONST_ANI_PIERCINGBOLT)\n\tregisterEnum(CONST_ANI_WHIRLWINDSWORD)\n\tregisterEnum(CONST_ANI_WHIRLWINDAXE)\n\tregisterEnum(CONST_ANI_WHIRLWINDCLUB)\n\tregisterEnum(CONST_ANI_ETHEREALSPEAR)\n\tregisterEnum(CONST_ANI_ICE)\n\tregisterEnum(CONST_ANI_EARTH)\n\tregisterEnum(CONST_ANI_HOLY)\n\tregisterEnum(CONST_ANI_SUDDENDEATH)\n\tregisterEnum(CONST_ANI_FLASHARROW)\n\tregisterEnum(CONST_ANI_FLAMMINGARROW)\n\tregisterEnum(CONST_ANI_SHIVERARROW)\n\tregisterEnum(CONST_ANI_ENERGYBALL)\n\tregisterEnum(CONST_ANI_SMALLICE)\n\tregisterEnum(CONST_ANI_SMALLHOLY)\n\tregisterEnum(CONST_ANI_SMALLEARTH)\n\tregisterEnum(CONST_ANI_EARTHARROW)\n\tregisterEnum(CONST_ANI_EXPLOSION)\n\tregisterEnum(CONST_ANI_CAKE)\n\tregisterEnum(CONST_ANI_TARSALARROW)\n\tregisterEnum(CONST_ANI_VORTEXBOLT)\n\tregisterEnum(CONST_ANI_PRISMATICBOLT)\n\tregisterEnum(CONST_ANI_CRYSTALLINEARROW)\n\tregisterEnum(CONST_ANI_DRILLBOLT)\n\tregisterEnum(CONST_ANI_ENVENOMEDARROW)\n\tregisterEnum(CONST_ANI_GLOOTHSPEAR)\n\tregisterEnum(CONST_ANI_SIMPLEARROW)\n\tregisterEnum(CONST_ANI_WEAPONTYPE)\n\n\tregisterEnum(CONST_PROP_BLOCKSOLID)\n\tregisterEnum(CONST_PROP_HASHEIGHT)\n\tregisterEnum(CONST_PROP_BLOCKPROJECTILE)\n\tregisterEnum(CONST_PROP_BLOCKPATH)\n\tregisterEnum(CONST_PROP_ISVERTICAL)\n\tregisterEnum(CONST_PROP_ISHORIZONTAL)\n\tregisterEnum(CONST_PROP_MOVEABLE)\n\tregisterEnum(CONST_PROP_IMMOVABLEBLOCKSOLID)\n\tregisterEnum(CONST_PROP_IMMOVABLEBLOCKPATH)\n\tregisterEnum(CONST_PROP_IMMOVABLENOFIELDBLOCKPATH)\n\tregisterEnum(CONST_PROP_NOFIELDBLOCKPATH)\n\tregisterEnum(CONST_PROP_SUPPORTHANGABLE)\n\n\tregisterEnum(CONST_SLOT_HEAD)\n\tregisterEnum(CONST_SLOT_NECKLACE)\n\tregisterEnum(CONST_SLOT_BACKPACK)\n\tregisterEnum(CONST_SLOT_ARMOR)\n\tregisterEnum(CONST_SLOT_RIGHT)\n\tregisterEnum(CONST_SLOT_LEFT)\n\tregisterEnum(CONST_SLOT_LEGS)\n\tregisterEnum(CONST_SLOT_FEET)\n\tregisterEnum(CONST_SLOT_RING)\n\tregisterEnum(CONST_SLOT_AMMO)\n\n\tregisterEnum(CREATURE_EVENT_NONE)\n\tregisterEnum(CREATURE_EVENT_LOGIN)\n\tregisterEnum(CREATURE_EVENT_LOGOUT)\n\tregisterEnum(CREATURE_EVENT_THINK)\n\tregisterEnum(CREATURE_EVENT_PREPAREDEATH)\n\tregisterEnum(CREATURE_EVENT_DEATH)\n\tregisterEnum(CREATURE_EVENT_KILL)\n\tregisterEnum(CREATURE_EVENT_ADVANCE)\n\tregisterEnum(CREATURE_EVENT_MODALWINDOW)\n\tregisterEnum(CREATURE_EVENT_TEXTEDIT)\n\tregisterEnum(CREATURE_EVENT_HEALTHCHANGE)\n\tregisterEnum(CREATURE_EVENT_MANACHANGE)\n\tregisterEnum(CREATURE_EVENT_EXTENDED_OPCODE)\n\n\tregisterEnum(GAME_STATE_STARTUP)\n\tregisterEnum(GAME_STATE_INIT)\n\tregisterEnum(GAME_STATE_NORMAL)\n\tregisterEnum(GAME_STATE_CLOSED)\n\tregisterEnum(GAME_STATE_SHUTDOWN)\n\tregisterEnum(GAME_STATE_CLOSING)\n\tregisterEnum(GAME_STATE_MAINTAIN)\n\n\tregisterEnum(MESSAGE_STATUS_CONSOLE_BLUE)\n\tregisterEnum(MESSAGE_STATUS_CONSOLE_RED)\n\tregisterEnum(MESSAGE_STATUS_DEFAULT)\n\tregisterEnum(MESSAGE_STATUS_WARNING)\n\tregisterEnum(MESSAGE_EVENT_ADVANCE)\n\tregisterEnum(MESSAGE_STATUS_SMALL)\n\tregisterEnum(MESSAGE_INFO_DESCR)\n\tregisterEnum(MESSAGE_DAMAGE_DEALT)\n\tregisterEnum(MESSAGE_DAMAGE_RECEIVED)\n\tregisterEnum(MESSAGE_HEALED)\n\tregisterEnum(MESSAGE_EXPERIENCE)\n\tregisterEnum(MESSAGE_DAMAGE_OTHERS)\n\tregisterEnum(MESSAGE_HEALED_OTHERS)\n\tregisterEnum(MESSAGE_EXPERIENCE_OTHERS)\n\tregisterEnum(MESSAGE_EVENT_DEFAULT)\n\tregisterEnum(MESSAGE_GUILD)\n\tregisterEnum(MESSAGE_PARTY_MANAGEMENT)\n\tregisterEnum(MESSAGE_PARTY)\n\tregisterEnum(MESSAGE_EVENT_ORANGE)\n\tregisterEnum(MESSAGE_STATUS_CONSOLE_ORANGE)\n\tregisterEnum(MESSAGE_LOOT)\n\n\tregisterEnum(CREATURETYPE_PLAYER)\n\tregisterEnum(CREATURETYPE_MONSTER)\n\tregisterEnum(CREATURETYPE_NPC)\n\tregisterEnum(CREATURETYPE_SUMMON_OWN)\n\tregisterEnum(CREATURETYPE_SUMMON_OTHERS)\n\n\tregisterEnum(CLIENTOS_LINUX)\n\tregisterEnum(CLIENTOS_WINDOWS)\n\tregisterEnum(CLIENTOS_FLASH)\n\tregisterEnum(CLIENTOS_OTCLIENT_LINUX)\n\tregisterEnum(CLIENTOS_OTCLIENT_WINDOWS)\n\tregisterEnum(CLIENTOS_OTCLIENT_MAC)\n\n\tregisterEnum(FIGHTMODE_ATTACK)\n\tregisterEnum(FIGHTMODE_BALANCED)\n\tregisterEnum(FIGHTMODE_DEFENSE)\n\n\tregisterEnum(ITEM_ATTRIBUTE_NONE)\n\tregisterEnum(ITEM_ATTRIBUTE_ACTIONID)\n\tregisterEnum(ITEM_ATTRIBUTE_UNIQUEID)\n\tregisterEnum(ITEM_ATTRIBUTE_DESCRIPTION)\n\tregisterEnum(ITEM_ATTRIBUTE_TEXT)\n\tregisterEnum(ITEM_ATTRIBUTE_DATE)\n\tregisterEnum(ITEM_ATTRIBUTE_WRITER)\n\tregisterEnum(ITEM_ATTRIBUTE_NAME)\n\tregisterEnum(ITEM_ATTRIBUTE_ARTICLE)\n\tregisterEnum(ITEM_ATTRIBUTE_PLURALNAME)\n\tregisterEnum(ITEM_ATTRIBUTE_WEIGHT)\n\tregisterEnum(ITEM_ATTRIBUTE_ATTACK)\n\tregisterEnum(ITEM_ATTRIBUTE_DEFENSE)\n\tregisterEnum(ITEM_ATTRIBUTE_EXTRADEFENSE)\n\tregisterEnum(ITEM_ATTRIBUTE_ARMOR)\n\tregisterEnum(ITEM_ATTRIBUTE_HITCHANCE)\n\tregisterEnum(ITEM_ATTRIBUTE_SHOOTRANGE)\n\tregisterEnum(ITEM_ATTRIBUTE_OWNER)\n\tregisterEnum(ITEM_ATTRIBUTE_DURATION)\n\tregisterEnum(ITEM_ATTRIBUTE_DECAYSTATE)\n\tregisterEnum(ITEM_ATTRIBUTE_CORPSEOWNER)\n\tregisterEnum(ITEM_ATTRIBUTE_CHARGES)\n\tregisterEnum(ITEM_ATTRIBUTE_FLUIDTYPE)\n\tregisterEnum(ITEM_ATTRIBUTE_DOORID)\n\n\tregisterEnum(ITEM_TYPE_DEPOT)\n\tregisterEnum(ITEM_TYPE_MAILBOX)\n\tregisterEnum(ITEM_TYPE_TRASHHOLDER)\n\tregisterEnum(ITEM_TYPE_CONTAINER)\n\tregisterEnum(ITEM_TYPE_DOOR)\n\tregisterEnum(ITEM_TYPE_MAGICFIELD)\n\tregisterEnum(ITEM_TYPE_TELEPORT)\n\tregisterEnum(ITEM_TYPE_BED)\n\tregisterEnum(ITEM_TYPE_KEY)\n\tregisterEnum(ITEM_TYPE_RUNE)\n\n\tregisterEnum(ITEM_BAG)\n\tregisterEnum(ITEM_SHOPPING_BAG)\n\tregisterEnum(ITEM_GOLD_COIN)\n\tregisterEnum(ITEM_PLATINUM_COIN)\n\tregisterEnum(ITEM_CRYSTAL_COIN)\n\tregisterEnum(ITEM_AMULETOFLOSS)\n\tregisterEnum(ITEM_PARCEL)\n\tregisterEnum(ITEM_LABEL)\n\tregisterEnum(ITEM_FIREFIELD_PVP_FULL)\n\tregisterEnum(ITEM_FIREFIELD_PVP_MEDIUM)\n\tregisterEnum(ITEM_FIREFIELD_PVP_SMALL)\n\tregisterEnum(ITEM_FIREFIELD_PERSISTENT_FULL)\n\tregisterEnum(ITEM_FIREFIELD_PERSISTENT_MEDIUM)\n\tregisterEnum(ITEM_FIREFIELD_PERSISTENT_SMALL)\n\tregisterEnum(ITEM_FIREFIELD_NOPVP)\n\tregisterEnum(ITEM_POISONFIELD_PVP)\n\tregisterEnum(ITEM_POISONFIELD_PERSISTENT)\n\tregisterEnum(ITEM_POISONFIELD_NOPVP)\n\tregisterEnum(ITEM_ENERGYFIELD_PVP)\n\tregisterEnum(ITEM_ENERGYFIELD_PERSISTENT)\n\tregisterEnum(ITEM_ENERGYFIELD_NOPVP)\n\tregisterEnum(ITEM_MAGICWALL)\n\tregisterEnum(ITEM_MAGICWALL_PERSISTENT)\n\tregisterEnum(ITEM_MAGICWALL_SAFE)\n\tregisterEnum(ITEM_WILDGROWTH)\n\tregisterEnum(ITEM_WILDGROWTH_PERSISTENT)\n\tregisterEnum(ITEM_WILDGROWTH_SAFE)\n\n\tregisterEnum(PlayerFlag_CannotUseCombat)\n\tregisterEnum(PlayerFlag_CannotAttackPlayer)\n\tregisterEnum(PlayerFlag_CannotAttackMonster)\n\tregisterEnum(PlayerFlag_CannotBeAttacked)\n\tregisterEnum(PlayerFlag_CanConvinceAll)\n\tregisterEnum(PlayerFlag_CanSummonAll)\n\tregisterEnum(PlayerFlag_CanIllusionAll)\n\tregisterEnum(PlayerFlag_CanSenseInvisibility)\n\tregisterEnum(PlayerFlag_IgnoredByMonsters)\n\tregisterEnum(PlayerFlag_NotGainInFight)\n\tregisterEnum(PlayerFlag_HasInfiniteMana)\n\tregisterEnum(PlayerFlag_HasInfiniteSoul)\n\tregisterEnum(PlayerFlag_HasNoExhaustion)\n\tregisterEnum(PlayerFlag_CannotUseSpells)\n\tregisterEnum(PlayerFlag_CannotPickupItem)\n\tregisterEnum(PlayerFlag_CanAlwaysLogin)\n\tregisterEnum(PlayerFlag_CanBroadcast)\n\tregisterEnum(PlayerFlag_CanEditHouses)\n\tregisterEnum(PlayerFlag_CannotBeBanned)\n\tregisterEnum(PlayerFlag_CannotBePushed)\n\tregisterEnum(PlayerFlag_HasInfiniteCapacity)\n\tregisterEnum(PlayerFlag_CanPushAllCreatures)\n\tregisterEnum(PlayerFlag_CanTalkRedPrivate)\n\tregisterEnum(PlayerFlag_CanTalkRedChannel)\n\tregisterEnum(PlayerFlag_TalkOrangeHelpChannel)\n\tregisterEnum(PlayerFlag_NotGainExperience)\n\tregisterEnum(PlayerFlag_NotGainMana)\n\tregisterEnum(PlayerFlag_NotGainHealth)\n\tregisterEnum(PlayerFlag_NotGainSkill)\n\tregisterEnum(PlayerFlag_SetMaxSpeed)\n\tregisterEnum(PlayerFlag_SpecialVIP)\n\tregisterEnum(PlayerFlag_NotGenerateLoot)\n\tregisterEnum(PlayerFlag_IgnoreProtectionZone)\n\tregisterEnum(PlayerFlag_IgnoreSpellCheck)\n\tregisterEnum(PlayerFlag_IgnoreWeaponCheck)\n\tregisterEnum(PlayerFlag_CannotBeMuted)\n\tregisterEnum(PlayerFlag_IsAlwaysPremium)\n\n\tregisterEnum(PLAYERSEX_FEMALE)\n\tregisterEnum(PLAYERSEX_MALE)\n\n\tregisterEnum(REPORT_REASON_NAMEINAPPROPRIATE)\n\tregisterEnum(REPORT_REASON_NAMEPOORFORMATTED)\n\tregisterEnum(REPORT_REASON_NAMEADVERTISING)\n\tregisterEnum(REPORT_REASON_NAMEUNFITTING)\n\tregisterEnum(REPORT_REASON_NAMERULEVIOLATION)\n\tregisterEnum(REPORT_REASON_INSULTINGSTATEMENT)\n\tregisterEnum(REPORT_REASON_SPAMMING)\n\tregisterEnum(REPORT_REASON_ADVERTISINGSTATEMENT)\n\tregisterEnum(REPORT_REASON_UNFITTINGSTATEMENT)\n\tregisterEnum(REPORT_REASON_LANGUAGESTATEMENT)\n\tregisterEnum(REPORT_REASON_DISCLOSURE)\n\tregisterEnum(REPORT_REASON_RULEVIOLATION)\n\tregisterEnum(REPORT_REASON_STATEMENT_BUGABUSE)\n\tregisterEnum(REPORT_REASON_UNOFFICIALSOFTWARE)\n\tregisterEnum(REPORT_REASON_PRETENDING)\n\tregisterEnum(REPORT_REASON_HARASSINGOWNERS)\n\tregisterEnum(REPORT_REASON_FALSEINFO)\n\tregisterEnum(REPORT_REASON_ACCOUNTSHARING)\n\tregisterEnum(REPORT_REASON_STEALINGDATA)\n\tregisterEnum(REPORT_REASON_SERVICEATTACKING)\n\tregisterEnum(REPORT_REASON_SERVICEAGREEMENT)\n\n\tregisterEnum(REPORT_TYPE_NAME)\n\tregisterEnum(REPORT_TYPE_STATEMENT)\n\tregisterEnum(REPORT_TYPE_BOT)\n\n\tregisterEnum(VOCATION_NONE)\n\n\tregisterEnum(SKILL_FIST)\n\tregisterEnum(SKILL_CLUB)\n\tregisterEnum(SKILL_SWORD)\n\tregisterEnum(SKILL_AXE)\n\tregisterEnum(SKILL_DISTANCE)\n\tregisterEnum(SKILL_SHIELD)\n\tregisterEnum(SKILL_FISHING)\n\tregisterEnum(SKILL_MAGLEVEL)\n\tregisterEnum(SKILL_LEVEL)\n\n\tregisterEnum(SPECIALSKILL_CRITICALHITCHANCE)\n\tregisterEnum(SPECIALSKILL_CRITICALHITAMOUNT)\n\tregisterEnum(SPECIALSKILL_LIFELEECHCHANCE)\n\tregisterEnum(SPECIALSKILL_LIFELEECHAMOUNT)\n\tregisterEnum(SPECIALSKILL_MANALEECHCHANCE)\n\tregisterEnum(SPECIALSKILL_MANALEECHAMOUNT)\n\n\tregisterEnum(SKULL_NONE)\n\tregisterEnum(SKULL_YELLOW)\n\tregisterEnum(SKULL_GREEN)\n\tregisterEnum(SKULL_WHITE)\n\tregisterEnum(SKULL_RED)\n\tregisterEnum(SKULL_BLACK)\n\tregisterEnum(SKULL_ORANGE)\n\n\tregisterEnum(TALKTYPE_SAY)\n\tregisterEnum(TALKTYPE_WHISPER)\n\tregisterEnum(TALKTYPE_YELL)\n\tregisterEnum(TALKTYPE_PRIVATE_FROM)\n\tregisterEnum(TALKTYPE_PRIVATE_TO)\n\tregisterEnum(TALKTYPE_CHANNEL_Y)\n\tregisterEnum(TALKTYPE_CHANNEL_O)\n\tregisterEnum(TALKTYPE_PRIVATE_NP)\n\tregisterEnum(TALKTYPE_PRIVATE_PN)\n\tregisterEnum(TALKTYPE_BROADCAST)\n\tregisterEnum(TALKTYPE_CHANNEL_R1)\n\tregisterEnum(TALKTYPE_PRIVATE_RED_FROM)\n\tregisterEnum(TALKTYPE_PRIVATE_RED_TO)\n\tregisterEnum(TALKTYPE_MONSTER_SAY)\n\tregisterEnum(TALKTYPE_MONSTER_YELL)\n\n\tregisterEnum(TEXTCOLOR_BLUE)\n\tregisterEnum(TEXTCOLOR_LIGHTGREEN)\n\tregisterEnum(TEXTCOLOR_LIGHTBLUE)\n\tregisterEnum(TEXTCOLOR_MAYABLUE)\n\tregisterEnum(TEXTCOLOR_DARKRED)\n\tregisterEnum(TEXTCOLOR_LIGHTGREY)\n\tregisterEnum(TEXTCOLOR_SKYBLUE)\n\tregisterEnum(TEXTCOLOR_PURPLE)\n\tregisterEnum(TEXTCOLOR_ELECTRICPURPLE)\n\tregisterEnum(TEXTCOLOR_RED)\n\tregisterEnum(TEXTCOLOR_PASTELRED)\n\tregisterEnum(TEXTCOLOR_ORANGE)\n\tregisterEnum(TEXTCOLOR_YELLOW)\n\tregisterEnum(TEXTCOLOR_WHITE_EXP)\n\tregisterEnum(TEXTCOLOR_NONE)\n\n\tregisterEnum(TILESTATE_NONE)\n\tregisterEnum(TILESTATE_PROTECTIONZONE)\n\tregisterEnum(TILESTATE_NOPVPZONE)\n\tregisterEnum(TILESTATE_NOLOGOUT)\n\tregisterEnum(TILESTATE_PVPZONE)\n\tregisterEnum(TILESTATE_FLOORCHANGE)\n\tregisterEnum(TILESTATE_FLOORCHANGE_DOWN)\n\tregisterEnum(TILESTATE_FLOORCHANGE_NORTH)\n\tregisterEnum(TILESTATE_FLOORCHANGE_SOUTH)\n\tregisterEnum(TILESTATE_FLOORCHANGE_EAST)\n\tregisterEnum(TILESTATE_FLOORCHANGE_WEST)\n\tregisterEnum(TILESTATE_TELEPORT)\n\tregisterEnum(TILESTATE_MAGICFIELD)\n\tregisterEnum(TILESTATE_MAILBOX)\n\tregisterEnum(TILESTATE_TRASHHOLDER)\n\tregisterEnum(TILESTATE_BED)\n\tregisterEnum(TILESTATE_DEPOT)\n\tregisterEnum(TILESTATE_BLOCKSOLID)\n\tregisterEnum(TILESTATE_BLOCKPATH)\n\tregisterEnum(TILESTATE_IMMOVABLEBLOCKSOLID)\n\tregisterEnum(TILESTATE_IMMOVABLEBLOCKPATH)\n\tregisterEnum(TILESTATE_IMMOVABLENOFIELDBLOCKPATH)\n\tregisterEnum(TILESTATE_NOFIELDBLOCKPATH)\n\tregisterEnum(TILESTATE_FLOORCHANGE_SOUTH_ALT)\n\tregisterEnum(TILESTATE_FLOORCHANGE_EAST_ALT)\n\tregisterEnum(TILESTATE_SUPPORTS_HANGABLE)\n\n\tregisterEnum(WEAPON_NONE)\n\tregisterEnum(WEAPON_SWORD)\n\tregisterEnum(WEAPON_CLUB)\n\tregisterEnum(WEAPON_AXE)\n\tregisterEnum(WEAPON_SHIELD)\n\tregisterEnum(WEAPON_DISTANCE)\n\tregisterEnum(WEAPON_WAND)\n\tregisterEnum(WEAPON_AMMO)\n\n\tregisterEnum(WORLD_TYPE_NO_PVP)\n\tregisterEnum(WORLD_TYPE_PVP)\n\tregisterEnum(WORLD_TYPE_PVP_ENFORCED)\n\n\t// Use with container:addItem, container:addItemEx and possibly other functions.\n\tregisterEnum(FLAG_NOLIMIT)\n\tregisterEnum(FLAG_IGNOREBLOCKITEM)\n\tregisterEnum(FLAG_IGNOREBLOCKCREATURE)\n\tregisterEnum(FLAG_CHILDISOWNER)\n\tregisterEnum(FLAG_PATHFINDING)\n\tregisterEnum(FLAG_IGNOREFIELDDAMAGE)\n\tregisterEnum(FLAG_IGNORENOTMOVEABLE)\n\tregisterEnum(FLAG_IGNOREAUTOSTACK)\n\n\t// Use with itemType:getSlotPosition\n\tregisterEnum(SLOTP_WHEREEVER)\n\tregisterEnum(SLOTP_HEAD)\n\tregisterEnum(SLOTP_NECKLACE)\n\tregisterEnum(SLOTP_BACKPACK)\n\tregisterEnum(SLOTP_ARMOR)\n\tregisterEnum(SLOTP_RIGHT)\n\tregisterEnum(SLOTP_LEFT)\n\tregisterEnum(SLOTP_LEGS)\n\tregisterEnum(SLOTP_FEET)\n\tregisterEnum(SLOTP_RING)\n\tregisterEnum(SLOTP_AMMO)\n\tregisterEnum(SLOTP_DEPOT)\n\tregisterEnum(SLOTP_TWO_HAND)\n\n\t// Use with combat functions\n\tregisterEnum(ORIGIN_NONE)\n\tregisterEnum(ORIGIN_CONDITION)\n\tregisterEnum(ORIGIN_SPELL)\n\tregisterEnum(ORIGIN_MELEE)\n\tregisterEnum(ORIGIN_RANGED)\n\n\t// Use with house:getAccessList, house:setAccessList\n\tregisterEnum(GUEST_LIST)\n\tregisterEnum(SUBOWNER_LIST)\n\n\t// Use with npc:setSpeechBubble\n\tregisterEnum(SPEECHBUBBLE_NONE)\n\tregisterEnum(SPEECHBUBBLE_NORMAL)\n\tregisterEnum(SPEECHBUBBLE_TRADE)\n\tregisterEnum(SPEECHBUBBLE_QUEST)\n\tregisterEnum(SPEECHBUBBLE_QUESTTRADER)\n\n\t// Use with player:addMapMark\n\tregisterEnum(MAPMARK_TICK)\n\tregisterEnum(MAPMARK_QUESTION)\n\tregisterEnum(MAPMARK_EXCLAMATION)\n\tregisterEnum(MAPMARK_STAR)\n\tregisterEnum(MAPMARK_CROSS)\n\tregisterEnum(MAPMARK_TEMPLE)\n\tregisterEnum(MAPMARK_KISS)\n\tregisterEnum(MAPMARK_SHOVEL)\n\tregisterEnum(MAPMARK_SWORD)\n\tregisterEnum(MAPMARK_FLAG)\n\tregisterEnum(MAPMARK_LOCK)\n\tregisterEnum(MAPMARK_BAG)\n\tregisterEnum(MAPMARK_SKULL)\n\tregisterEnum(MAPMARK_DOLLAR)\n\tregisterEnum(MAPMARK_REDNORTH)\n\tregisterEnum(MAPMARK_REDSOUTH)\n\tregisterEnum(MAPMARK_REDEAST)\n\tregisterEnum(MAPMARK_REDWEST)\n\tregisterEnum(MAPMARK_GREENNORTH)\n\tregisterEnum(MAPMARK_GREENSOUTH)\n\n\t// Use with Game.getReturnMessage\n\tregisterEnum(RETURNVALUE_NOERROR)\n\tregisterEnum(RETURNVALUE_NOTPOSSIBLE)\n\tregisterEnum(RETURNVALUE_NOTENOUGHROOM)\n\tregisterEnum(RETURNVALUE_PLAYERISPZLOCKED)\n\tregisterEnum(RETURNVALUE_PLAYERISNOTINVITED)\n\tregisterEnum(RETURNVALUE_CANNOTTHROW)\n\tregisterEnum(RETURNVALUE_THEREISNOWAY)\n\tregisterEnum(RETURNVALUE_DESTINATIONOUTOFREACH)\n\tregisterEnum(RETURNVALUE_CREATUREBLOCK)\n\tregisterEnum(RETURNVALUE_NOTMOVEABLE)\n\tregisterEnum(RETURNVALUE_DROPTWOHANDEDITEM)\n\tregisterEnum(RETURNVALUE_BOTHHANDSNEEDTOBEFREE)\n\tregisterEnum(RETURNVALUE_CANONLYUSEONEWEAPON)\n\tregisterEnum(RETURNVALUE_NEEDEXCHANGE)\n\tregisterEnum(RETURNVALUE_CANNOTBEDRESSED)\n\tregisterEnum(RETURNVALUE_PUTTHISOBJECTINYOURHAND)\n\tregisterEnum(RETURNVALUE_PUTTHISOBJECTINBOTHHANDS)\n\tregisterEnum(RETURNVALUE_TOOFARAWAY)\n\tregisterEnum(RETURNVALUE_FIRSTGODOWNSTAIRS)\n\tregisterEnum(RETURNVALUE_FIRSTGOUPSTAIRS)\n\tregisterEnum(RETURNVALUE_CONTAINERNOTENOUGHROOM)\n\tregisterEnum(RETURNVALUE_NOTENOUGHCAPACITY)\n\tregisterEnum(RETURNVALUE_CANNOTPICKUP)\n\tregisterEnum(RETURNVALUE_THISISIMPOSSIBLE)\n\tregisterEnum(RETURNVALUE_DEPOTISFULL)\n\tregisterEnum(RETURNVALUE_CREATUREDOESNOTEXIST)\n\tregisterEnum(RETURNVALUE_CANNOTUSETHISOBJECT)\n\tregisterEnum(RETURNVALUE_PLAYERWITHTHISNAMEISNOTONLINE)\n\tregisterEnum(RETURNVALUE_NOTREQUIREDLEVELTOUSERUNE)\n\tregisterEnum(RETURNVALUE_YOUAREALREADYTRADING)\n\tregisterEnum(RETURNVALUE_THISPLAYERISALREADYTRADING)\n\tregisterEnum(RETURNVALUE_YOUMAYNOTLOGOUTDURINGAFIGHT)\n\tregisterEnum(RETURNVALUE_DIRECTPLAYERSHOOT)\n\tregisterEnum(RETURNVALUE_NOTENOUGHLEVEL)\n\tregisterEnum(RETURNVALUE_NOTENOUGHMAGICLEVEL)\n\tregisterEnum(RETURNVALUE_NOTENOUGHMANA)\n\tregisterEnum(RETURNVALUE_NOTENOUGHSOUL)\n\tregisterEnum(RETURNVALUE_YOUAREEXHAUSTED)\n\tregisterEnum(RETURNVALUE_YOUCANNOTUSEOBJECTSTHATFAST)\n\tregisterEnum(RETURNVALUE_PLAYERISNOTREACHABLE)\n\tregisterEnum(RETURNVALUE_CANONLYUSETHISRUNEONCREATURES)\n\tregisterEnum(RETURNVALUE_ACTIONNOTPERMITTEDINPROTECTIONZONE)\n\tregisterEnum(RETURNVALUE_YOUMAYNOTATTACKTHISPLAYER)\n\tregisterEnum(RETURNVALUE_YOUMAYNOTATTACKAPERSONINPROTECTIONZONE)\n\tregisterEnum(RETURNVALUE_YOUMAYNOTATTACKAPERSONWHILEINPROTECTIONZONE)\n\tregisterEnum(RETURNVALUE_YOUMAYNOTATTACKTHISCREATURE)\n\tregisterEnum(RETURNVALUE_YOUCANONLYUSEITONCREATURES)\n\tregisterEnum(RETURNVALUE_CREATUREISNOTREACHABLE)\n\tregisterEnum(RETURNVALUE_TURNSECUREMODETOATTACKUNMARKEDPLAYERS)\n\tregisterEnum(RETURNVALUE_YOUNEEDPREMIUMACCOUNT)\n\tregisterEnum(RETURNVALUE_YOUNEEDTOLEARNTHISSPELL)\n\tregisterEnum(RETURNVALUE_YOURVOCATIONCANNOTUSETHISSPELL)\n\tregisterEnum(RETURNVALUE_YOUNEEDAWEAPONTOUSETHISSPELL)\n\tregisterEnum(RETURNVALUE_PLAYERISPZLOCKEDLEAVEPVPZONE)\n\tregisterEnum(RETURNVALUE_PLAYERISPZLOCKEDENTERPVPZONE)\n\tregisterEnum(RETURNVALUE_ACTIONNOTPERMITTEDINANOPVPZONE)\n\tregisterEnum(RETURNVALUE_YOUCANNOTLOGOUTHERE)\n\tregisterEnum(RETURNVALUE_YOUNEEDAMAGICITEMTOCASTSPELL)\n\tregisterEnum(RETURNVALUE_CANNOTCONJUREITEMHERE)\n\tregisterEnum(RETURNVALUE_YOUNEEDTOSPLITYOURSPEARS)\n\tregisterEnum(RETURNVALUE_NAMEISTOOAMBIGUOUS)\n\tregisterEnum(RETURNVALUE_CANONLYUSEONESHIELD)\n\tregisterEnum(RETURNVALUE_NOPARTYMEMBERSINRANGE)\n\tregisterEnum(RETURNVALUE_YOUARENOTTHEOWNER)\n\tregisterEnum(RETURNVALUE_TRADEPLAYERFARAWAY)\n\tregisterEnum(RETURNVALUE_YOUDONTOWNTHISHOUSE)\n\tregisterEnum(RETURNVALUE_TRADEPLAYERALREADYOWNSAHOUSE)\n\tregisterEnum(RETURNVALUE_TRADEPLAYERHIGHESTBIDDER)\n\tregisterEnum(RETURNVALUE_YOUCANNOTTRADETHISHOUSE)\n\tregisterEnum(RETURNVALUE_YOUDONTHAVEREQUIREDPROFESSION)\n\n\tregisterEnum(RELOAD_TYPE_ALL)\n\tregisterEnum(RELOAD_TYPE_ACTIONS)\n\tregisterEnum(RELOAD_TYPE_CHAT)\n\tregisterEnum(RELOAD_TYPE_CONFIG)\n\tregisterEnum(RELOAD_TYPE_CREATURESCRIPTS)\n\tregisterEnum(RELOAD_TYPE_EVENTS)\n\tregisterEnum(RELOAD_TYPE_GLOBAL)\n\tregisterEnum(RELOAD_TYPE_GLOBALEVENTS)\n\tregisterEnum(RELOAD_TYPE_ITEMS)\n\tregisterEnum(RELOAD_TYPE_MONSTERS)\n\tregisterEnum(RELOAD_TYPE_MOUNTS)\n\tregisterEnum(RELOAD_TYPE_MOVEMENTS)\n\tregisterEnum(RELOAD_TYPE_NPCS)\n\tregisterEnum(RELOAD_TYPE_QUESTS)\n\tregisterEnum(RELOAD_TYPE_RAIDS)\n\tregisterEnum(RELOAD_TYPE_SCRIPTS)\n\tregisterEnum(RELOAD_TYPE_SPELLS)\n\tregisterEnum(RELOAD_TYPE_TALKACTIONS)\n\tregisterEnum(RELOAD_TYPE_WEAPONS)\n\n\tregisterEnum(ZONE_PROTECTION)\n\tregisterEnum(ZONE_NOPVP)\n\tregisterEnum(ZONE_PVP)\n\tregisterEnum(ZONE_NOLOGOUT)\n\tregisterEnum(ZONE_NORMAL)\n\n\tregisterEnum(MAX_LOOTCHANCE)\n\n\tregisterEnum(SPELL_INSTANT)\n\tregisterEnum(SPELL_RUNE)\n\n\tregisterEnum(MONSTERS_EVENT_THINK)\n\tregisterEnum(MONSTERS_EVENT_APPEAR)\n\tregisterEnum(MONSTERS_EVENT_DISAPPEAR)\n\tregisterEnum(MONSTERS_EVENT_MOVE)\n\tregisterEnum(MONSTERS_EVENT_SAY)\n\n\t// _G\n\tregisterGlobalVariable(\"INDEX_WHEREEVER\", INDEX_WHEREEVER);\n\tregisterGlobalBoolean(\"VIRTUAL_PARENT\", true);\n\n\tregisterGlobalMethod(\"isType\", LuaScriptInterface::luaIsType);\n\tregisterGlobalMethod(\"rawgetmetatable\", LuaScriptInterface::luaRawGetMetatable);\n\n\t// configKeys\n\tregisterTable(\"configKeys\");\n\n\tregisterEnumIn(\"configKeys\", ConfigManager::ALLOW_CHANGEOUTFIT)\n\tregisterEnumIn(\"configKeys\", ConfigManager::ONE_PLAYER_ON_ACCOUNT)\n\tregisterEnumIn(\"configKeys\", ConfigManager::AIMBOT_HOTKEY_ENABLED)\n\tregisterEnumIn(\"configKeys\", ConfigManager::REMOVE_RUNE_CHARGES)\n\tregisterEnumIn(\"configKeys\", ConfigManager::REMOVE_WEAPON_AMMO)\n\tregisterEnumIn(\"configKeys\", ConfigManager::REMOVE_WEAPON_CHARGES)\n\tregisterEnumIn(\"configKeys\", ConfigManager::REMOVE_POTION_CHARGES)\n\tregisterEnumIn(\"configKeys\", ConfigManager::EXPERIENCE_FROM_PLAYERS)\n\tregisterEnumIn(\"configKeys\", ConfigManager::FREE_PREMIUM)\n\tregisterEnumIn(\"configKeys\", ConfigManager::REPLACE_KICK_ON_LOGIN)\n\tregisterEnumIn(\"configKeys\", ConfigManager::ALLOW_CLONES)\n\tregisterEnumIn(\"configKeys\", ConfigManager::BIND_ONLY_GLOBAL_ADDRESS)\n\tregisterEnumIn(\"configKeys\", ConfigManager::OPTIMIZE_DATABASE)\n\tregisterEnumIn(\"configKeys\", ConfigManager::MARKET_PREMIUM)\n\tregisterEnumIn(\"configKeys\", ConfigManager::EMOTE_SPELLS)\n\tregisterEnumIn(\"configKeys\", ConfigManager::STAMINA_SYSTEM)\n\tregisterEnumIn(\"configKeys\", ConfigManager::WARN_UNSAFE_SCRIPTS)\n\tregisterEnumIn(\"configKeys\", ConfigManager::CONVERT_UNSAFE_SCRIPTS)\n\tregisterEnumIn(\"configKeys\", ConfigManager::CLASSIC_EQUIPMENT_SLOTS)\n\tregisterEnumIn(\"configKeys\", ConfigManager::CLASSIC_ATTACK_SPEED)\n\tregisterEnumIn(\"configKeys\", ConfigManager::SERVER_SAVE_NOTIFY_MESSAGE)\n\tregisterEnumIn(\"configKeys\", ConfigManager::SERVER_SAVE_NOTIFY_DURATION)\n\tregisterEnumIn(\"configKeys\", ConfigManager::SERVER_SAVE_CLEAN_MAP)\n\tregisterEnumIn(\"configKeys\", ConfigManager::SERVER_SAVE_CLOSE)\n\tregisterEnumIn(\"configKeys\", ConfigManager::SERVER_SAVE_SHUTDOWN)\n\tregisterEnumIn(\"configKeys\", ConfigManager::ONLINE_OFFLINE_CHARLIST)\n\n\tregisterEnumIn(\"configKeys\", ConfigManager::MAP_NAME)\n\tregisterEnumIn(\"configKeys\", ConfigManager::HOUSE_RENT_PERIOD)\n\tregisterEnumIn(\"configKeys\", ConfigManager::SERVER_NAME)\n\tregisterEnumIn(\"configKeys\", ConfigManager::OWNER_NAME)\n\tregisterEnumIn(\"configKeys\", ConfigManager::OWNER_EMAIL)\n\tregisterEnumIn(\"configKeys\", ConfigManager::URL)\n\tregisterEnumIn(\"configKeys\", ConfigManager::LOCATION)\n\tregisterEnumIn(\"configKeys\", ConfigManager::IP)\n\tregisterEnumIn(\"configKeys\", ConfigManager::MOTD)\n\tregisterEnumIn(\"configKeys\", ConfigManager::WORLD_TYPE)\n\tregisterEnumIn(\"configKeys\", ConfigManager::MYSQL_HOST)\n\tregisterEnumIn(\"configKeys\", ConfigManager::MYSQL_USER)\n\tregisterEnumIn(\"configKeys\", ConfigManager::MYSQL_PASS)\n\tregisterEnumIn(\"configKeys\", ConfigManager::MYSQL_DB)\n\tregisterEnumIn(\"configKeys\", ConfigManager::MYSQL_SOCK)\n\tregisterEnumIn(\"configKeys\", ConfigManager::DEFAULT_PRIORITY)\n\tregisterEnumIn(\"configKeys\", ConfigManager::MAP_AUTHOR)\n\n\tregisterEnumIn(\"configKeys\", ConfigManager::SQL_PORT)\n\tregisterEnumIn(\"configKeys\", ConfigManager::MAX_PLAYERS)\n\tregisterEnumIn(\"configKeys\", ConfigManager::PZ_LOCKED)\n\tregisterEnumIn(\"configKeys\", ConfigManager::DEFAULT_DESPAWNRANGE)\n\tregisterEnumIn(\"configKeys\", ConfigManager::DEFAULT_DESPAWNRADIUS)\n\tregisterEnumIn(\"configKeys\", ConfigManager::RATE_EXPERIENCE)\n\tregisterEnumIn(\"configKeys\", ConfigManager::RATE_SKILL)\n\tregisterEnumIn(\"configKeys\", ConfigManager::RATE_LOOT)\n\tregisterEnumIn(\"configKeys\", ConfigManager::RATE_MAGIC)\n\tregisterEnumIn(\"configKeys\", ConfigManager::RATE_SPAWN)\n\tregisterEnumIn(\"configKeys\", ConfigManager::HOUSE_PRICE)\n\tregisterEnumIn(\"configKeys\", ConfigManager::KILLS_TO_RED)\n\tregisterEnumIn(\"configKeys\", ConfigManager::KILLS_TO_BLACK)\n\tregisterEnumIn(\"configKeys\", ConfigManager::MAX_MESSAGEBUFFER)\n\tregisterEnumIn(\"configKeys\", ConfigManager::ACTIONS_DELAY_INTERVAL)\n\tregisterEnumIn(\"configKeys\", ConfigManager::EX_ACTIONS_DELAY_INTERVAL)\n\tregisterEnumIn(\"configKeys\", ConfigManager::KICK_AFTER_MINUTES)\n\tregisterEnumIn(\"configKeys\", ConfigManager::PROTECTION_LEVEL)\n\tregisterEnumIn(\"configKeys\", ConfigManager::DEATH_LOSE_PERCENT)\n\tregisterEnumIn(\"configKeys\", ConfigManager::STATUSQUERY_TIMEOUT)\n\tregisterEnumIn(\"configKeys\", ConfigManager::FRAG_TIME)\n\tregisterEnumIn(\"configKeys\", ConfigManager::WHITE_SKULL_TIME)\n\tregisterEnumIn(\"configKeys\", ConfigManager::GAME_PORT)\n\tregisterEnumIn(\"configKeys\", ConfigManager::LOGIN_PORT)\n\tregisterEnumIn(\"configKeys\", ConfigManager::STATUS_PORT)\n\tregisterEnumIn(\"configKeys\", ConfigManager::STAIRHOP_DELAY)\n\tregisterEnumIn(\"configKeys\", ConfigManager::MARKET_OFFER_DURATION)\n\tregisterEnumIn(\"configKeys\", ConfigManager::CHECK_EXPIRED_MARKET_OFFERS_EACH_MINUTES)\n\tregisterEnumIn(\"configKeys\", ConfigManager::MAX_MARKET_OFFERS_AT_A_TIME_PER_PLAYER)\n\tregisterEnumIn(\"configKeys\", ConfigManager::EXP_FROM_PLAYERS_LEVEL_RANGE)\n\tregisterEnumIn(\"configKeys\", ConfigManager::MAX_PACKETS_PER_SECOND)\n\n\t// os\n\tregisterMethod(\"os\", \"mtime\", LuaScriptInterface::luaSystemTime);\n\n\t// table\n\tregisterMethod(\"table\", \"create\", LuaScriptInterface::luaTableCreate);\n\n\t// Game\n\tregisterTable(\"Game\");\n\n\tregisterMethod(\"Game\", \"getSpectators\", LuaScriptInterface::luaGameGetSpectators);\n\tregisterMethod(\"Game\", \"getPlayers\", LuaScriptInterface::luaGameGetPlayers);\n\tregisterMethod(\"Game\", \"loadMap\", LuaScriptInterface::luaGameLoadMap);\n\n\tregisterMethod(\"Game\", \"getExperienceStage\", LuaScriptInterface::luaGameGetExperienceStage);\n\tregisterMethod(\"Game\", \"getMonsterCount\", LuaScriptInterface::luaGameGetMonsterCount);\n\tregisterMethod(\"Game\", \"getPlayerCount\", LuaScriptInterface::luaGameGetPlayerCount);\n\tregisterMethod(\"Game\", \"getNpcCount\", LuaScriptInterface::luaGameGetNpcCount);\n\tregisterMethod(\"Game\", \"getMonsterTypes\", LuaScriptInterface::luaGameGetMonsterTypes);\n\n\tregisterMethod(\"Game\", \"getTowns\", LuaScriptInterface::luaGameGetTowns);\n\tregisterMethod(\"Game\", \"getHouses\", LuaScriptInterface::luaGameGetHouses);\n\n\tregisterMethod(\"Game\", \"getGameState\", LuaScriptInterface::luaGameGetGameState);\n\tregisterMethod(\"Game\", \"setGameState\", LuaScriptInterface::luaGameSetGameState);\n\n\tregisterMethod(\"Game\", \"getWorldType\", LuaScriptInterface::luaGameGetWorldType);\n\tregisterMethod(\"Game\", \"setWorldType\", LuaScriptInterface::luaGameSetWorldType);\n\n\tregisterMethod(\"Game\", \"getReturnMessage\", LuaScriptInterface::luaGameGetReturnMessage);\n\n\tregisterMethod(\"Game\", \"createItem\", LuaScriptInterface::luaGameCreateItem);\n\tregisterMethod(\"Game\", \"createContainer\", LuaScriptInterface::luaGameCreateContainer);\n\tregisterMethod(\"Game\", \"createMonster\", LuaScriptInterface::luaGameCreateMonster);\n\tregisterMethod(\"Game\", \"createNpc\", LuaScriptInterface::luaGameCreateNpc);\n\tregisterMethod(\"Game\", \"createTile\", LuaScriptInterface::luaGameCreateTile);\n\tregisterMethod(\"Game\", \"createMonsterType\", LuaScriptInterface::luaGameCreateMonsterType);\n\n\tregisterMethod(\"Game\", \"startRaid\", LuaScriptInterface::luaGameStartRaid);\n\n\tregisterMethod(\"Game\", \"getClientVersion\", LuaScriptInterface::luaGameGetClientVersion);\n\n\tregisterMethod(\"Game\", \"reload\", LuaScriptInterface::luaGameReload);\n\n\t// Variant\n\tregisterClass(\"Variant\", \"\", LuaScriptInterface::luaVariantCreate);\n\n\tregisterMethod(\"Variant\", \"getNumber\", LuaScriptInterface::luaVariantGetNumber);\n\tregisterMethod(\"Variant\", \"getString\", LuaScriptInterface::luaVariantGetString);\n\tregisterMethod(\"Variant\", \"getPosition\", LuaScriptInterface::luaVariantGetPosition);\n\n\t// Position\n\tregisterClass(\"Position\", \"\", LuaScriptInterface::luaPositionCreate);\n\tregisterMetaMethod(\"Position\", \"__add\", LuaScriptInterface::luaPositionAdd);\n\tregisterMetaMethod(\"Position\", \"__sub\", LuaScriptInterface::luaPositionSub);\n\tregisterMetaMethod(\"Position\", \"__eq\", LuaScriptInterface::luaPositionCompare);\n\n\tregisterMethod(\"Position\", \"getDistance\", LuaScriptInterface::luaPositionGetDistance);\n\tregisterMethod(\"Position\", \"isSightClear\", LuaScriptInterface::luaPositionIsSightClear);\n\n\tregisterMethod(\"Position\", \"sendMagicEffect\", LuaScriptInterface::luaPositionSendMagicEffect);\n\tregisterMethod(\"Position\", \"sendDistanceEffect\", LuaScriptInterface::luaPositionSendDistanceEffect);\n\n\t// Tile\n\tregisterClass(\"Tile\", \"\", LuaScriptInterface::luaTileCreate);\n\tregisterMetaMethod(\"Tile\", \"__eq\", LuaScriptInterface::luaUserdataCompare);\n\n\tregisterMethod(\"Tile\", \"remove\", LuaScriptInterface::luaTileRemove);\n\n\tregisterMethod(\"Tile\", \"getPosition\", LuaScriptInterface::luaTileGetPosition);\n\tregisterMethod(\"Tile\", \"getGround\", LuaScriptInterface::luaTileGetGround);\n\tregisterMethod(\"Tile\", \"getThing\", LuaScriptInterface::luaTileGetThing);\n\tregisterMethod(\"Tile\", \"getThingCount\", LuaScriptInterface::luaTileGetThingCount);\n\tregisterMethod(\"Tile\", \"getTopVisibleThing\", LuaScriptInterface::luaTileGetTopVisibleThing);\n\n\tregisterMethod(\"Tile\", \"getTopTopItem\", LuaScriptInterface::luaTileGetTopTopItem);\n\tregisterMethod(\"Tile\", \"getTopDownItem\", LuaScriptInterface::luaTileGetTopDownItem);\n\tregisterMethod(\"Tile\", \"getFieldItem\", LuaScriptInterface::luaTileGetFieldItem);\n\n\tregisterMethod(\"Tile\", \"getItemById\", LuaScriptInterface::luaTileGetItemById);\n\tregisterMethod(\"Tile\", \"getItemByType\", LuaScriptInterface::luaTileGetItemByType);\n\tregisterMethod(\"Tile\", \"getItemByTopOrder\", LuaScriptInterface::luaTileGetItemByTopOrder);\n\tregisterMethod(\"Tile\", \"getItemCountById\", LuaScriptInterface::luaTileGetItemCountById);\n\n\tregisterMethod(\"Tile\", \"getBottomCreature\", LuaScriptInterface::luaTileGetBottomCreature);\n\tregisterMethod(\"Tile\", \"getTopCreature\", LuaScriptInterface::luaTileGetTopCreature);\n\tregisterMethod(\"Tile\", \"getBottomVisibleCreature\", LuaScriptInterface::luaTileGetBottomVisibleCreature);\n\tregisterMethod(\"Tile\", \"getTopVisibleCreature\", LuaScriptInterface::luaTileGetTopVisibleCreature);\n\n\tregisterMethod(\"Tile\", \"getItems\", LuaScriptInterface::luaTileGetItems);\n\tregisterMethod(\"Tile\", \"getItemCount\", LuaScriptInterface::luaTileGetItemCount);\n\tregisterMethod(\"Tile\", \"getDownItemCount\", LuaScriptInterface::luaTileGetDownItemCount);\n\tregisterMethod(\"Tile\", \"getTopItemCount\", LuaScriptInterface::luaTileGetTopItemCount);\n\n\tregisterMethod(\"Tile\", \"getCreatures\", LuaScriptInterface::luaTileGetCreatures);\n\tregisterMethod(\"Tile\", \"getCreatureCount\", LuaScriptInterface::luaTileGetCreatureCount);\n\n\tregisterMethod(\"Tile\", \"getThingIndex\", LuaScriptInterface::luaTileGetThingIndex);\n\n\tregisterMethod(\"Tile\", \"hasProperty\", LuaScriptInterface::luaTileHasProperty);\n\tregisterMethod(\"Tile\", \"hasFlag\", LuaScriptInterface::luaTileHasFlag);\n\n\tregisterMethod(\"Tile\", \"queryAdd\", LuaScriptInterface::luaTileQueryAdd);\n\tregisterMethod(\"Tile\", \"addItem\", LuaScriptInterface::luaTileAddItem);\n\tregisterMethod(\"Tile\", \"addItemEx\", LuaScriptInterface::luaTileAddItemEx);\n\n\tregisterMethod(\"Tile\", \"getHouse\", LuaScriptInterface::luaTileGetHouse);\n\n\t// NetworkMessage\n\tregisterClass(\"NetworkMessage\", \"\", LuaScriptInterface::luaNetworkMessageCreate);\n\tregisterMetaMethod(\"NetworkMessage\", \"__eq\", LuaScriptInterface::luaUserdataCompare);\n\tregisterMetaMethod(\"NetworkMessage\", \"__gc\", LuaScriptInterface::luaNetworkMessageDelete);\n\tregisterMethod(\"NetworkMessage\", \"delete\", LuaScriptInterface::luaNetworkMessageDelete);\n\n\tregisterMethod(\"NetworkMessage\", \"getByte\", LuaScriptInterface::luaNetworkMessageGetByte);\n\tregisterMethod(\"NetworkMessage\", \"getU16\", LuaScriptInterface::luaNetworkMessageGetU16);\n\tregisterMethod(\"NetworkMessage\", \"getU32\", LuaScriptInterface::luaNetworkMessageGetU32);\n\tregisterMethod(\"NetworkMessage\", \"getU64\", LuaScriptInterface::luaNetworkMessageGetU64);\n\tregisterMethod(\"NetworkMessage\", \"getString\", LuaScriptInterface::luaNetworkMessageGetString);\n\tregisterMethod(\"NetworkMessage\", \"getPosition\", LuaScriptInterface::luaNetworkMessageGetPosition);\n\n\tregisterMethod(\"NetworkMessage\", \"addByte\", LuaScriptInterface::luaNetworkMessageAddByte);\n\tregisterMethod(\"NetworkMessage\", \"addU16\", LuaScriptInterface::luaNetworkMessageAddU16);\n\tregisterMethod(\"NetworkMessage\", \"addU32\", LuaScriptInterface::luaNetworkMessageAddU32);\n\tregisterMethod(\"NetworkMessage\", \"addU64\", LuaScriptInterface::luaNetworkMessageAddU64);\n\tregisterMethod(\"NetworkMessage\", \"addString\", LuaScriptInterface::luaNetworkMessageAddString);\n\tregisterMethod(\"NetworkMessage\", \"addPosition\", LuaScriptInterface::luaNetworkMessageAddPosition);\n\tregisterMethod(\"NetworkMessage\", \"addDouble\", LuaScriptInterface::luaNetworkMessageAddDouble);\n\tregisterMethod(\"NetworkMessage\", \"addItem\", LuaScriptInterface::luaNetworkMessageAddItem);\n\tregisterMethod(\"NetworkMessage\", \"addItemId\", LuaScriptInterface::luaNetworkMessageAddItemId);\n\n\tregisterMethod(\"NetworkMessage\", \"reset\", LuaScriptInterface::luaNetworkMessageReset);\n\tregisterMethod(\"NetworkMessage\", \"skipBytes\", LuaScriptInterface::luaNetworkMessageSkipBytes);\n\tregisterMethod(\"NetworkMessage\", \"sendToPlayer\", LuaScriptInterface::luaNetworkMessageSendToPlayer);\n\n\t// ModalWindow\n\tregisterClass(\"ModalWindow\", \"\", LuaScriptInterface::luaModalWindowCreate);\n\tregisterMetaMethod(\"ModalWindow\", \"__eq\", LuaScriptInterface::luaUserdataCompare);\n\tregisterMetaMethod(\"ModalWindow\", \"__gc\", LuaScriptInterface::luaModalWindowDelete);\n\tregisterMethod(\"ModalWindow\", \"delete\", LuaScriptInterface::luaModalWindowDelete);\n\n\tregisterMethod(\"ModalWindow\", \"getId\", LuaScriptInterface::luaModalWindowGetId);\n\tregisterMethod(\"ModalWindow\", \"getTitle\", LuaScriptInterface::luaModalWindowGetTitle);\n\tregisterMethod(\"ModalWindow\", \"getMessage\", LuaScriptInterface::luaModalWindowGetMessage);\n\n\tregisterMethod(\"ModalWindow\", \"setTitle\", LuaScriptInterface::luaModalWindowSetTitle);\n\tregisterMethod(\"ModalWindow\", \"setMessage\", LuaScriptInterface::luaModalWindowSetMessage);\n\n\tregisterMethod(\"ModalWindow\", \"getButtonCount\", LuaScriptInterface::luaModalWindowGetButtonCount);\n\tregisterMethod(\"ModalWindow\", \"getChoiceCount\", LuaScriptInterface::luaModalWindowGetChoiceCount);\n\n\tregisterMethod(\"ModalWindow\", \"addButton\", LuaScriptInterface::luaModalWindowAddButton);\n\tregisterMethod(\"ModalWindow\", \"addChoice\", LuaScriptInterface::luaModalWindowAddChoice);\n\n\tregisterMethod(\"ModalWindow\", \"getDefaultEnterButton\", LuaScriptInterface::luaModalWindowGetDefaultEnterButton);\n\tregisterMethod(\"ModalWindow\", \"setDefaultEnterButton\", LuaScriptInterface::luaModalWindowSetDefaultEnterButton);\n\n\tregisterMethod(\"ModalWindow\", \"getDefaultEscapeButton\", LuaScriptInterface::luaModalWindowGetDefaultEscapeButton);\n\tregisterMethod(\"ModalWindow\", \"setDefaultEscapeButton\", LuaScriptInterface::luaModalWindowSetDefaultEscapeButton);\n\n\tregisterMethod(\"ModalWindow\", \"hasPriority\", LuaScriptInterface::luaModalWindowHasPriority);\n\tregisterMethod(\"ModalWindow\", \"setPriority\", LuaScriptInterface::luaModalWindowSetPriority);\n\n\tregisterMethod(\"ModalWindow\", \"sendToPlayer\", LuaScriptInterface::luaModalWindowSendToPlayer);\n\n\t// Item\n\tregisterClass(\"Item\", \"\", LuaScriptInterface::luaItemCreate);\n\tregisterMetaMethod(\"Item\", \"__eq\", LuaScriptInterface::luaUserdataCompare);\n\n\tregisterMethod(\"Item\", \"isItem\", LuaScriptInterface::luaItemIsItem);\n\n\tregisterMethod(\"Item\", \"getParent\", LuaScriptInterface::luaItemGetParent);\n\tregisterMethod(\"Item\", \"getTopParent\", LuaScriptInterface::luaItemGetTopParent);\n\n\tregisterMethod(\"Item\", \"getId\", LuaScriptInterface::luaItemGetId);\n\n\tregisterMethod(\"Item\", \"clone\", LuaScriptInterface::luaItemClone);\n\tregisterMethod(\"Item\", \"split\", LuaScriptInterface::luaItemSplit);\n\tregisterMethod(\"Item\", \"remove\", LuaScriptInterface::luaItemRemove);\n\n\tregisterMethod(\"Item\", \"getUniqueId\", LuaScriptInterface::luaItemGetUniqueId);\n\tregisterMethod(\"Item\", \"getActionId\", LuaScriptInterface::luaItemGetActionId);\n\tregisterMethod(\"Item\", \"setActionId\", LuaScriptInterface::luaItemSetActionId);\n\n\tregisterMethod(\"Item\", \"getCount\", LuaScriptInterface::luaItemGetCount);\n\tregisterMethod(\"Item\", \"getCharges\", LuaScriptInterface::luaItemGetCharges);\n\tregisterMethod(\"Item\", \"getFluidType\", LuaScriptInterface::luaItemGetFluidType);\n\tregisterMethod(\"Item\", \"getWeight\", LuaScriptInterface::luaItemGetWeight);\n\n\tregisterMethod(\"Item\", \"getSubType\", LuaScriptInterface::luaItemGetSubType);\n\n\tregisterMethod(\"Item\", \"getName\", LuaScriptInterface::luaItemGetName);\n\tregisterMethod(\"Item\", \"getPluralName\", LuaScriptInterface::luaItemGetPluralName);\n\tregisterMethod(\"Item\", \"getArticle\", LuaScriptInterface::luaItemGetArticle);\n\n\tregisterMethod(\"Item\", \"getPosition\", LuaScriptInterface::luaItemGetPosition);\n\tregisterMethod(\"Item\", \"getTile\", LuaScriptInterface::luaItemGetTile);\n\n\tregisterMethod(\"Item\", \"hasAttribute\", LuaScriptInterface::luaItemHasAttribute);\n\tregisterMethod(\"Item\", \"getAttribute\", LuaScriptInterface::luaItemGetAttribute);\n\tregisterMethod(\"Item\", \"setAttribute\", LuaScriptInterface::luaItemSetAttribute);\n\tregisterMethod(\"Item\", \"removeAttribute\", LuaScriptInterface::luaItemRemoveAttribute);\n\tregisterMethod(\"Item\", \"getCustomAttribute\", LuaScriptInterface::luaItemGetCustomAttribute);\n\tregisterMethod(\"Item\", \"setCustomAttribute\", LuaScriptInterface::luaItemSetCustomAttribute);\n\tregisterMethod(\"Item\", \"removeCustomAttribute\", LuaScriptInterface::luaItemRemoveCustomAttribute);\n\n\tregisterMethod(\"Item\", \"moveTo\", LuaScriptInterface::luaItemMoveTo);\n\tregisterMethod(\"Item\", \"transform\", LuaScriptInterface::luaItemTransform);\n\tregisterMethod(\"Item\", \"decay\", LuaScriptInterface::luaItemDecay);\n\n\tregisterMethod(\"Item\", \"getDescription\", LuaScriptInterface::luaItemGetDescription);\n\n\tregisterMethod(\"Item\", \"hasProperty\", LuaScriptInterface::luaItemHasProperty);\n\tregisterMethod(\"Item\", \"isLoadedFromMap\", LuaScriptInterface::luaItemIsLoadedFromMap);\n\n\tregisterMethod(\"Item\", \"setStoreItem\", LuaScriptInterface::luaItemSetStoreItem);\n\tregisterMethod(\"Item\", \"isStoreItem\", LuaScriptInterface::luaItemIsStoreItem);\n\n\t// Container\n\tregisterClass(\"Container\", \"Item\", LuaScriptInterface::luaContainerCreate);\n\tregisterMetaMethod(\"Container\", \"__eq\", LuaScriptInterface::luaUserdataCompare);\n\n\tregisterMethod(\"Container\", \"getSize\", LuaScriptInterface::luaContainerGetSize);\n\tregisterMethod(\"Container\", \"getCapacity\", LuaScriptInterface::luaContainerGetCapacity);\n\tregisterMethod(\"Container\", \"getEmptySlots\", LuaScriptInterface::luaContainerGetEmptySlots);\n\tregisterMethod(\"Container\", \"getContentDescription\", LuaScriptInterface::luaContainerGetContentDescription);\n\tregisterMethod(\"Container\", \"getItems\", LuaScriptInterface::luaContainerGetItems);\n\tregisterMethod(\"Container\", \"getItemHoldingCount\", LuaScriptInterface::luaContainerGetItemHoldingCount);\n\tregisterMethod(\"Container\", \"getItemCountById\", LuaScriptInterface::luaContainerGetItemCountById);\n\n\tregisterMethod(\"Container\", \"getItem\", LuaScriptInterface::luaContainerGetItem);\n\tregisterMethod(\"Container\", \"hasItem\", LuaScriptInterface::luaContainerHasItem);\n\tregisterMethod(\"Container\", \"addItem\", LuaScriptInterface::luaContainerAddItem);\n\tregisterMethod(\"Container\", \"addItemEx\", LuaScriptInterface::luaContainerAddItemEx);\n\tregisterMethod(\"Container\", \"getCorpseOwner\", LuaScriptInterface::luaContainerGetCorpseOwner);\n\n\t// Teleport\n\tregisterClass(\"Teleport\", \"Item\", LuaScriptInterface::luaTeleportCreate);\n\tregisterMetaMethod(\"Teleport\", \"__eq\", LuaScriptInterface::luaUserdataCompare);\n\n\tregisterMethod(\"Teleport\", \"getDestination\", LuaScriptInterface::luaTeleportGetDestination);\n\tregisterMethod(\"Teleport\", \"setDestination\", LuaScriptInterface::luaTeleportSetDestination);\n\n\t// Creature\n\tregisterClass(\"Creature\", \"\", LuaScriptInterface::luaCreatureCreate);\n\tregisterMetaMethod(\"Creature\", \"__eq\", LuaScriptInterface::luaUserdataCompare);\n\n\tregisterMethod(\"Creature\", \"getEvents\", LuaScriptInterface::luaCreatureGetEvents);\n\tregisterMethod(\"Creature\", \"registerEvent\", LuaScriptInterface::luaCreatureRegisterEvent);\n\tregisterMethod(\"Creature\", \"unregisterEvent\", LuaScriptInterface::luaCreatureUnregisterEvent);\n\n\tregisterMethod(\"Creature\", \"isRemoved\", LuaScriptInterface::luaCreatureIsRemoved);\n\tregisterMethod(\"Creature\", \"isCreature\", LuaScriptInterface::luaCreatureIsCreature);\n\tregisterMethod(\"Creature\", \"isInGhostMode\", LuaScriptInterface::luaCreatureIsInGhostMode);\n\tregisterMethod(\"Creature\", \"isHealthHidden\", LuaScriptInterface::luaCreatureIsHealthHidden);\n\tregisterMethod(\"Creature\", \"isImmune\", LuaScriptInterface::luaCreatureIsImmune);\n\n\tregisterMethod(\"Creature\", \"canSee\", LuaScriptInterface::luaCreatureCanSee);\n\tregisterMethod(\"Creature\", \"canSeeCreature\", LuaScriptInterface::luaCreatureCanSeeCreature);\n\n\tregisterMethod(\"Creature\", \"getParent\", LuaScriptInterface::luaCreatureGetParent);\n\n\tregisterMethod(\"Creature\", \"getId\", LuaScriptInterface::luaCreatureGetId);\n\tregisterMethod(\"Creature\", \"getName\", LuaScriptInterface::luaCreatureGetName);\n\n\tregisterMethod(\"Creature\", \"getTarget\", LuaScriptInterface::luaCreatureGetTarget);\n\tregisterMethod(\"Creature\", \"setTarget\", LuaScriptInterface::luaCreatureSetTarget);\n\n\tregisterMethod(\"Creature\", \"getFollowCreature\", LuaScriptInterface::luaCreatureGetFollowCreature);\n\tregisterMethod(\"Creature\", \"setFollowCreature\", LuaScriptInterface::luaCreatureSetFollowCreature);\n\n\tregisterMethod(\"Creature\", \"getMaster\", LuaScriptInterface::luaCreatureGetMaster);\n\tregisterMethod(\"Creature\", \"setMaster\", LuaScriptInterface::luaCreatureSetMaster);\n\n\tregisterMethod(\"Creature\", \"getLight\", LuaScriptInterface::luaCreatureGetLight);\n\tregisterMethod(\"Creature\", \"setLight\", LuaScriptInterface::luaCreatureSetLight);\n\n\tregisterMethod(\"Creature\", \"getSpeed\", LuaScriptInterface::luaCreatureGetSpeed);\n\tregisterMethod(\"Creature\", \"getBaseSpeed\", LuaScriptInterface::luaCreatureGetBaseSpeed);\n\tregisterMethod(\"Creature\", \"changeSpeed\", LuaScriptInterface::luaCreatureChangeSpeed);\n\n\tregisterMethod(\"Creature\", \"setDropLoot\", LuaScriptInterface::luaCreatureSetDropLoot);\n\tregisterMethod(\"Creature\", \"setSkillLoss\", LuaScriptInterface::luaCreatureSetSkillLoss);\n\n\tregisterMethod(\"Creature\", \"getPosition\", LuaScriptInterface::luaCreatureGetPosition);\n\tregisterMethod(\"Creature\", \"getTile\", LuaScriptInterface::luaCreatureGetTile);\n\tregisterMethod(\"Creature\", \"getDirection\", LuaScriptInterface::luaCreatureGetDirection);\n\tregisterMethod(\"Creature\", \"setDirection\", LuaScriptInterface::luaCreatureSetDirection);\n\n\tregisterMethod(\"Creature\", \"getHealth\", LuaScriptInterface::luaCreatureGetHealth);\n\tregisterMethod(\"Creature\", \"setHealth\", LuaScriptInterface::luaCreatureSetHealth);\n\tregisterMethod(\"Creature\", \"addHealth\", LuaScriptInterface::luaCreatureAddHealth);\n\tregisterMethod(\"Creature\", \"getMaxHealth\", LuaScriptInterface::luaCreatureGetMaxHealth);\n\tregisterMethod(\"Creature\", \"setMaxHealth\", LuaScriptInterface::luaCreatureSetMaxHealth);\n\tregisterMethod(\"Creature\", \"setHiddenHealth\", LuaScriptInterface::luaCreatureSetHiddenHealth);\n\n\tregisterMethod(\"Creature\", \"getSkull\", LuaScriptInterface::luaCreatureGetSkull);\n\tregisterMethod(\"Creature\", \"setSkull\", LuaScriptInterface::luaCreatureSetSkull);\n\n\tregisterMethod(\"Creature\", \"getOutfit\", LuaScriptInterface::luaCreatureGetOutfit);\n\tregisterMethod(\"Creature\", \"setOutfit\", LuaScriptInterface::luaCreatureSetOutfit);\n\n\tregisterMethod(\"Creature\", \"getCondition\", LuaScriptInterface::luaCreatureGetCondition);\n\tregisterMethod(\"Creature\", \"addCondition\", LuaScriptInterface::luaCreatureAddCondition);\n\tregisterMethod(\"Creature\", \"removeCondition\", LuaScriptInterface::luaCreatureRemoveCondition);\n\tregisterMethod(\"Creature\", \"hasCondition\", LuaScriptInterface::luaCreatureHasCondition);\n\n\tregisterMethod(\"Creature\", \"remove\", LuaScriptInterface::luaCreatureRemove);\n\tregisterMethod(\"Creature\", \"teleportTo\", LuaScriptInterface::luaCreatureTeleportTo);\n\tregisterMethod(\"Creature\", \"say\", LuaScriptInterface::luaCreatureSay);\n\n\tregisterMethod(\"Creature\", \"getDamageMap\", LuaScriptInterface::luaCreatureGetDamageMap);\n\n\tregisterMethod(\"Creature\", \"getSummons\", LuaScriptInterface::luaCreatureGetSummons);\n\n\tregisterMethod(\"Creature\", \"getDescription\", LuaScriptInterface::luaCreatureGetDescription);\n\n\tregisterMethod(\"Creature\", \"getPathTo\", LuaScriptInterface::luaCreatureGetPathTo);\n\tregisterMethod(\"Creature\", \"move\", LuaScriptInterface::luaCreatureMove);\n\n\tregisterMethod(\"Creature\", \"getZone\", LuaScriptInterface::luaCreatureGetZone);\n\n\t// Player\n\tregisterClass(\"Player\", \"Creature\", LuaScriptInterface::luaPlayerCreate);\n\tregisterMetaMethod(\"Player\", \"__eq\", LuaScriptInterface::luaUserdataCompare);\n\n\tregisterMethod(\"Player\", \"isPlayer\", LuaScriptInterface::luaPlayerIsPlayer);\n\n\tregisterMethod(\"Player\", \"getGuid\", LuaScriptInterface::luaPlayerGetGuid);\n\tregisterMethod(\"Player\", \"getIp\", LuaScriptInterface::luaPlayerGetIp);\n\tregisterMethod(\"Player\", \"getAccountId\", LuaScriptInterface::luaPlayerGetAccountId);\n\tregisterMethod(\"Player\", \"getLastLoginSaved\", LuaScriptInterface::luaPlayerGetLastLoginSaved);\n\tregisterMethod(\"Player\", \"getLastLogout\", LuaScriptInterface::luaPlayerGetLastLogout);\n\n\tregisterMethod(\"Player\", \"getAccountType\", LuaScriptInterface::luaPlayerGetAccountType);\n\tregisterMethod(\"Player\", \"setAccountType\", LuaScriptInterface::luaPlayerSetAccountType);\n\n\tregisterMethod(\"Player\", \"getCapacity\", LuaScriptInterface::luaPlayerGetCapacity);\n\tregisterMethod(\"Player\", \"setCapacity\", LuaScriptInterface::luaPlayerSetCapacity);\n\n\tregisterMethod(\"Player\", \"getFreeCapacity\", LuaScriptInterface::luaPlayerGetFreeCapacity);\n\n\tregisterMethod(\"Player\", \"getDepotChest\", LuaScriptInterface::luaPlayerGetDepotChest);\n\tregisterMethod(\"Player\", \"getInbox\", LuaScriptInterface::luaPlayerGetInbox);\n\n\tregisterMethod(\"Player\", \"getSkullTime\", LuaScriptInterface::luaPlayerGetSkullTime);\n\tregisterMethod(\"Player\", \"setSkullTime\", LuaScriptInterface::luaPlayerSetSkullTime);\n\tregisterMethod(\"Player\", \"getDeathPenalty\", LuaScriptInterface::luaPlayerGetDeathPenalty);\n\n\tregisterMethod(\"Player\", \"getExperience\", LuaScriptInterface::luaPlayerGetExperience);\n\tregisterMethod(\"Player\", \"addExperience\", LuaScriptInterface::luaPlayerAddExperience);\n\tregisterMethod(\"Player\", \"removeExperience\", LuaScriptInterface::luaPlayerRemoveExperience);\n\tregisterMethod(\"Player\", \"getLevel\", LuaScriptInterface::luaPlayerGetLevel);\n\n\tregisterMethod(\"Player\", \"getMagicLevel\", LuaScriptInterface::luaPlayerGetMagicLevel);\n\tregisterMethod(\"Player\", \"getBaseMagicLevel\", LuaScriptInterface::luaPlayerGetBaseMagicLevel);\n\tregisterMethod(\"Player\", \"getMana\", LuaScriptInterface::luaPlayerGetMana);\n\tregisterMethod(\"Player\", \"addMana\", LuaScriptInterface::luaPlayerAddMana);\n\tregisterMethod(\"Player\", \"getMaxMana\", LuaScriptInterface::luaPlayerGetMaxMana);\n\tregisterMethod(\"Player\", \"setMaxMana\", LuaScriptInterface::luaPlayerSetMaxMana);\n\tregisterMethod(\"Player\", \"getManaSpent\", LuaScriptInterface::luaPlayerGetManaSpent);\n\tregisterMethod(\"Player\", \"addManaSpent\", LuaScriptInterface::luaPlayerAddManaSpent);\n\n\tregisterMethod(\"Player\", \"getBaseMaxHealth\", LuaScriptInterface::luaPlayerGetBaseMaxHealth);\n\tregisterMethod(\"Player\", \"getBaseMaxMana\", LuaScriptInterface::luaPlayerGetBaseMaxMana);\n\n\tregisterMethod(\"Player\", \"getSkillLevel\", LuaScriptInterface::luaPlayerGetSkillLevel);\n\tregisterMethod(\"Player\", \"getEffectiveSkillLevel\", LuaScriptInterface::luaPlayerGetEffectiveSkillLevel);\n\tregisterMethod(\"Player\", \"getSkillPercent\", LuaScriptInterface::luaPlayerGetSkillPercent);\n\tregisterMethod(\"Player\", \"getSkillTries\", LuaScriptInterface::luaPlayerGetSkillTries);\n\tregisterMethod(\"Player\", \"addSkillTries\", LuaScriptInterface::luaPlayerAddSkillTries);\n\tregisterMethod(\"Player\", \"getSpecialSkill\", LuaScriptInterface::luaPlayerGetSpecialSkill);\n\tregisterMethod(\"Player\", \"addSpecialSkill\", LuaScriptInterface::luaPlayerAddSpecialSkill);\n\n\tregisterMethod(\"Player\", \"addOfflineTrainingTime\", LuaScriptInterface::luaPlayerAddOfflineTrainingTime);\n\tregisterMethod(\"Player\", \"getOfflineTrainingTime\", LuaScriptInterface::luaPlayerGetOfflineTrainingTime);\n\tregisterMethod(\"Player\", \"removeOfflineTrainingTime\", LuaScriptInterface::luaPlayerRemoveOfflineTrainingTime);\n\n\tregisterMethod(\"Player\", \"addOfflineTrainingTries\", LuaScriptInterface::luaPlayerAddOfflineTrainingTries);\n\n\tregisterMethod(\"Player\", \"getOfflineTrainingSkill\", LuaScriptInterface::luaPlayerGetOfflineTrainingSkill);\n\tregisterMethod(\"Player\", \"setOfflineTrainingSkill\", LuaScriptInterface::luaPlayerSetOfflineTrainingSkill);\n\n\tregisterMethod(\"Player\", \"getItemCount\", LuaScriptInterface::luaPlayerGetItemCount);\n\tregisterMethod(\"Player\", \"getItemById\", LuaScriptInterface::luaPlayerGetItemById);\n\n\tregisterMethod(\"Player\", \"getVocation\", LuaScriptInterface::luaPlayerGetVocation);\n\tregisterMethod(\"Player\", \"setVocation\", LuaScriptInterface::luaPlayerSetVocation);\n\n\tregisterMethod(\"Player\", \"getSex\", LuaScriptInterface::luaPlayerGetSex);\n\tregisterMethod(\"Player\", \"setSex\", LuaScriptInterface::luaPlayerSetSex);\n\n\tregisterMethod(\"Player\", \"getTown\", LuaScriptInterface::luaPlayerGetTown);\n\tregisterMethod(\"Player\", \"setTown\", LuaScriptInterface::luaPlayerSetTown);\n\n\tregisterMethod(\"Player\", \"getGuild\", LuaScriptInterface::luaPlayerGetGuild);\n\tregisterMethod(\"Player\", \"setGuild\", LuaScriptInterface::luaPlayerSetGuild);\n\n\tregisterMethod(\"Player\", \"getGuildLevel\", LuaScriptInterface::luaPlayerGetGuildLevel);\n\tregisterMethod(\"Player\", \"setGuildLevel\", LuaScriptInterface::luaPlayerSetGuildLevel);\n\n\tregisterMethod(\"Player\", \"getGuildNick\", LuaScriptInterface::luaPlayerGetGuildNick);\n\tregisterMethod(\"Player\", \"setGuildNick\", LuaScriptInterface::luaPlayerSetGuildNick);\n\n\tregisterMethod(\"Player\", \"getGroup\", LuaScriptInterface::luaPlayerGetGroup);\n\tregisterMethod(\"Player\", \"setGroup\", LuaScriptInterface::luaPlayerSetGroup);\n\n\tregisterMethod(\"Player\", \"getStamina\", LuaScriptInterface::luaPlayerGetStamina);\n\tregisterMethod(\"Player\", \"setStamina\", LuaScriptInterface::luaPlayerSetStamina);\n\n\tregisterMethod(\"Player\", \"getSoul\", LuaScriptInterface::luaPlayerGetSoul);\n\tregisterMethod(\"Player\", \"addSoul\", LuaScriptInterface::luaPlayerAddSoul);\n\tregisterMethod(\"Player\", \"getMaxSoul\", LuaScriptInterface::luaPlayerGetMaxSoul);\n\n\tregisterMethod(\"Player\", \"getBankBalance\", LuaScriptInterface::luaPlayerGetBankBalance);\n\tregisterMethod(\"Player\", \"setBankBalance\", LuaScriptInterface::luaPlayerSetBankBalance);\n\n\tregisterMethod(\"Player\", \"getStorageValue\", LuaScriptInterface::luaPlayerGetStorageValue);\n\tregisterMethod(\"Player\", \"setStorageValue\", LuaScriptInterface::luaPlayerSetStorageValue);\n\n\tregisterMethod(\"Player\", \"addItem\", LuaScriptInterface::luaPlayerAddItem);\n\tregisterMethod(\"Player\", \"addItemEx\", LuaScriptInterface::luaPlayerAddItemEx);\n\tregisterMethod(\"Player\", \"removeItem\", LuaScriptInterface::luaPlayerRemoveItem);\n\n\tregisterMethod(\"Player\", \"getMoney\", LuaScriptInterface::luaPlayerGetMoney);\n\tregisterMethod(\"Player\", \"addMoney\", LuaScriptInterface::luaPlayerAddMoney);\n\tregisterMethod(\"Player\", \"removeMoney\", LuaScriptInterface::luaPlayerRemoveMoney);\n\n\tregisterMethod(\"Player\", \"showTextDialog\", LuaScriptInterface::luaPlayerShowTextDialog);\n\n\tregisterMethod(\"Player\", \"sendTextMessage\", LuaScriptInterface::luaPlayerSendTextMessage);\n\tregisterMethod(\"Player\", \"sendChannelMessage\", LuaScriptInterface::luaPlayerSendChannelMessage);\n\tregisterMethod(\"Player\", \"sendPrivateMessage\", LuaScriptInterface::luaPlayerSendPrivateMessage);\n\tregisterMethod(\"Player\", \"channelSay\", LuaScriptInterface::luaPlayerChannelSay);\n\tregisterMethod(\"Player\", \"openChannel\", LuaScriptInterface::luaPlayerOpenChannel);\n\n\tregisterMethod(\"Player\", \"getSlotItem\", LuaScriptInterface::luaPlayerGetSlotItem);\n\n\tregisterMethod(\"Player\", \"getParty\", LuaScriptInterface::luaPlayerGetParty);\n\n\tregisterMethod(\"Player\", \"addOutfit\", LuaScriptInterface::luaPlayerAddOutfit);\n\tregisterMethod(\"Player\", \"addOutfitAddon\", LuaScriptInterface::luaPlayerAddOutfitAddon);\n\tregisterMethod(\"Player\", \"removeOutfit\", LuaScriptInterface::luaPlayerRemoveOutfit);\n\tregisterMethod(\"Player\", \"removeOutfitAddon\", LuaScriptInterface::luaPlayerRemoveOutfitAddon);\n\tregisterMethod(\"Player\", \"hasOutfit\", LuaScriptInterface::luaPlayerHasOutfit);\n\tregisterMethod(\"Player\", \"canWearOutfit\", LuaScriptInterface::luaPlayerCanWearOutfit);\n\tregisterMethod(\"Player\", \"sendOutfitWindow\", LuaScriptInterface::luaPlayerSendOutfitWindow);\n\n\tregisterMethod(\"Player\", \"addMount\", LuaScriptInterface::luaPlayerAddMount);\n\tregisterMethod(\"Player\", \"removeMount\", LuaScriptInterface::luaPlayerRemoveMount);\n\tregisterMethod(\"Player\", \"hasMount\", LuaScriptInterface::luaPlayerHasMount);\n\n\tregisterMethod(\"Player\", \"getPremiumEndsAt\", LuaScriptInterface::luaPlayerGetPremiumEndsAt);\n\tregisterMethod(\"Player\", \"setPremiumEndsAt\", LuaScriptInterface::luaPlayerSetPremiumEndsAt);\n\n\tregisterMethod(\"Player\", \"hasBlessing\", LuaScriptInterface::luaPlayerHasBlessing);\n\tregisterMethod(\"Player\", \"addBlessing\", LuaScriptInterface::luaPlayerAddBlessing);\n\tregisterMethod(\"Player\", \"removeBlessing\", LuaScriptInterface::luaPlayerRemoveBlessing);\n\n\tregisterMethod(\"Player\", \"canLearnSpell\", LuaScriptInterface::luaPlayerCanLearnSpell);\n\tregisterMethod(\"Player\", \"learnSpell\", LuaScriptInterface::luaPlayerLearnSpell);\n\tregisterMethod(\"Player\", \"forgetSpell\", LuaScriptInterface::luaPlayerForgetSpell);\n\tregisterMethod(\"Player\", \"hasLearnedSpell\", LuaScriptInterface::luaPlayerHasLearnedSpell);\n\n\tregisterMethod(\"Player\", \"sendTutorial\", LuaScriptInterface::luaPlayerSendTutorial);\n\tregisterMethod(\"Player\", \"addMapMark\", LuaScriptInterface::luaPlayerAddMapMark);\n\n\tregisterMethod(\"Player\", \"save\", LuaScriptInterface::luaPlayerSave);\n\tregisterMethod(\"Player\", \"popupFYI\", LuaScriptInterface::luaPlayerPopupFYI);\n\n\tregisterMethod(\"Player\", \"isPzLocked\", LuaScriptInterface::luaPlayerIsPzLocked);\n\n\tregisterMethod(\"Player\", \"getClient\", LuaScriptInterface::luaPlayerGetClient);\n\n\tregisterMethod(\"Player\", \"getHouse\", LuaScriptInterface::luaPlayerGetHouse);\n\tregisterMethod(\"Player\", \"sendHouseWindow\", LuaScriptInterface::luaPlayerSendHouseWindow);\n\tregisterMethod(\"Player\", \"setEditHouse\", LuaScriptInterface::luaPlayerSetEditHouse);\n\n\tregisterMethod(\"Player\", \"setGhostMode\", LuaScriptInterface::luaPlayerSetGhostMode);\n\n\tregisterMethod(\"Player\", \"getContainerId\", LuaScriptInterface::luaPlayerGetContainerId);\n\tregisterMethod(\"Player\", \"getContainerById\", LuaScriptInterface::luaPlayerGetContainerById);\n\tregisterMethod(\"Player\", \"getContainerIndex\", LuaScriptInterface::luaPlayerGetContainerIndex);\n\n\tregisterMethod(\"Player\", \"getInstantSpells\", LuaScriptInterface::luaPlayerGetInstantSpells);\n\tregisterMethod(\"Player\", \"canCast\", LuaScriptInterface::luaPlayerCanCast);\n\n\tregisterMethod(\"Player\", \"hasChaseMode\", LuaScriptInterface::luaPlayerHasChaseMode);\n\tregisterMethod(\"Player\", \"hasSecureMode\", LuaScriptInterface::luaPlayerHasSecureMode);\n\tregisterMethod(\"Player\", \"getFightMode\", LuaScriptInterface::luaPlayerGetFightMode);\n\n\tregisterMethod(\"Player\", \"getStoreInbox\", LuaScriptInterface::luaPlayerGetStoreInbox);\n\n\t// Monster\n\tregisterClass(\"Monster\", \"Creature\", LuaScriptInterface::luaMonsterCreate);\n\tregisterMetaMethod(\"Monster\", \"__eq\", LuaScriptInterface::luaUserdataCompare);\n\n\tregisterMethod(\"Monster\", \"isMonster\", LuaScriptInterface::luaMonsterIsMonster);\n\n\tregisterMethod(\"Monster\", \"getType\", LuaScriptInterface::luaMonsterGetType);\n\n\tregisterMethod(\"Monster\", \"getSpawnPosition\", LuaScriptInterface::luaMonsterGetSpawnPosition);\n\tregisterMethod(\"Monster\", \"isInSpawnRange\", LuaScriptInterface::luaMonsterIsInSpawnRange);\n\n\tregisterMethod(\"Monster\", \"isIdle\", LuaScriptInterface::luaMonsterIsIdle);\n\tregisterMethod(\"Monster\", \"setIdle\", LuaScriptInterface::luaMonsterSetIdle);\n\n\tregisterMethod(\"Monster\", \"isTarget\", LuaScriptInterface::luaMonsterIsTarget);\n\tregisterMethod(\"Monster\", \"isOpponent\", LuaScriptInterface::luaMonsterIsOpponent);\n\tregisterMethod(\"Monster\", \"isFriend\", LuaScriptInterface::luaMonsterIsFriend);\n\n\tregisterMethod(\"Monster\", \"addFriend\", LuaScriptInterface::luaMonsterAddFriend);\n\tregisterMethod(\"Monster\", \"removeFriend\", LuaScriptInterface::luaMonsterRemoveFriend);\n\tregisterMethod(\"Monster\", \"getFriendList\", LuaScriptInterface::luaMonsterGetFriendList);\n\tregisterMethod(\"Monster\", \"getFriendCount\", LuaScriptInterface::luaMonsterGetFriendCount);\n\n\tregisterMethod(\"Monster\", \"addTarget\", LuaScriptInterface::luaMonsterAddTarget);\n\tregisterMethod(\"Monster\", \"removeTarget\", LuaScriptInterface::luaMonsterRemoveTarget);\n\tregisterMethod(\"Monster\", \"getTargetList\", LuaScriptInterface::luaMonsterGetTargetList);\n\tregisterMethod(\"Monster\", \"getTargetCount\", LuaScriptInterface::luaMonsterGetTargetCount);\n\n\tregisterMethod(\"Monster\", \"selectTarget\", LuaScriptInterface::luaMonsterSelectTarget);\n\tregisterMethod(\"Monster\", \"searchTarget\", LuaScriptInterface::luaMonsterSearchTarget);\n\n\t// Npc\n\tregisterClass(\"Npc\", \"Creature\", LuaScriptInterface::luaNpcCreate);\n\tregisterMetaMethod(\"Npc\", \"__eq\", LuaScriptInterface::luaUserdataCompare);\n\n\tregisterMethod(\"Npc\", \"isNpc\", LuaScriptInterface::luaNpcIsNpc);\n\n\tregisterMethod(\"Npc\", \"setMasterPos\", LuaScriptInterface::luaNpcSetMasterPos);\n\n\tregisterMethod(\"Npc\", \"getSpeechBubble\", LuaScriptInterface::luaNpcGetSpeechBubble);\n\tregisterMethod(\"Npc\", \"setSpeechBubble\", LuaScriptInterface::luaNpcSetSpeechBubble);\n\n\t// Guild\n\tregisterClass(\"Guild\", \"\", LuaScriptInterface::luaGuildCreate);\n\tregisterMetaMethod(\"Guild\", \"__eq\", LuaScriptInterface::luaUserdataCompare);\n\n\tregisterMethod(\"Guild\", \"getId\", LuaScriptInterface::luaGuildGetId);\n\tregisterMethod(\"Guild\", \"getName\", LuaScriptInterface::luaGuildGetName);\n\tregisterMethod(\"Guild\", \"getMembersOnline\", LuaScriptInterface::luaGuildGetMembersOnline);\n\n\tregisterMethod(\"Guild\", \"addRank\", LuaScriptInterface::luaGuildAddRank);\n\tregisterMethod(\"Guild\", \"getRankById\", LuaScriptInterface::luaGuildGetRankById);\n\tregisterMethod(\"Guild\", \"getRankByLevel\", LuaScriptInterface::luaGuildGetRankByLevel);\n\n\tregisterMethod(\"Guild\", \"getMotd\", LuaScriptInterface::luaGuildGetMotd);\n\tregisterMethod(\"Guild\", \"setMotd\", LuaScriptInterface::luaGuildSetMotd);\n\n\t// Group\n\tregisterClass(\"Group\", \"\", LuaScriptInterface::luaGroupCreate);\n\tregisterMetaMethod(\"Group\", \"__eq\", LuaScriptInterface::luaUserdataCompare);\n\n\tregisterMethod(\"Group\", \"getId\", LuaScriptInterface::luaGroupGetId);\n\tregisterMethod(\"Group\", \"getName\", LuaScriptInterface::luaGroupGetName);\n\tregisterMethod(\"Group\", \"getFlags\", LuaScriptInterface::luaGroupGetFlags);\n\tregisterMethod(\"Group\", \"getAccess\", LuaScriptInterface::luaGroupGetAccess);\n\tregisterMethod(\"Group\", \"getMaxDepotItems\", LuaScriptInterface::luaGroupGetMaxDepotItems);\n\tregisterMethod(\"Group\", \"getMaxVipEntries\", LuaScriptInterface::luaGroupGetMaxVipEntries);\n\tregisterMethod(\"Group\", \"hasFlag\", LuaScriptInterface::luaGroupHasFlag);\n\n\t// Vocation\n\tregisterClass(\"Vocation\", \"\", LuaScriptInterface::luaVocationCreate);\n\tregisterMetaMethod(\"Vocation\", \"__eq\", LuaScriptInterface::luaUserdataCompare);\n\n\tregisterMethod(\"Vocation\", \"getId\", LuaScriptInterface::luaVocationGetId);\n\tregisterMethod(\"Vocation\", \"getClientId\", LuaScriptInterface::luaVocationGetClientId);\n\tregisterMethod(\"Vocation\", \"getName\", LuaScriptInterface::luaVocationGetName);\n\tregisterMethod(\"Vocation\", \"getDescription\", LuaScriptInterface::luaVocationGetDescription);\n\n\tregisterMethod(\"Vocation\", \"getRequiredSkillTries\", LuaScriptInterface::luaVocationGetRequiredSkillTries);\n\tregisterMethod(\"Vocation\", \"getRequiredManaSpent\", LuaScriptInterface::luaVocationGetRequiredManaSpent);\n\n\tregisterMethod(\"Vocation\", \"getCapacityGain\", LuaScriptInterface::luaVocationGetCapacityGain);\n\n\tregisterMethod(\"Vocation\", \"getHealthGain\", LuaScriptInterface::luaVocationGetHealthGain);\n\tregisterMethod(\"Vocation\", \"getHealthGainTicks\", LuaScriptInterface::luaVocationGetHealthGainTicks);\n\tregisterMethod(\"Vocation\", \"getHealthGainAmount\", LuaScriptInterface::luaVocationGetHealthGainAmount);\n\n\tregisterMethod(\"Vocation\", \"getManaGain\", LuaScriptInterface::luaVocationGetManaGain);\n\tregisterMethod(\"Vocation\", \"getManaGainTicks\", LuaScriptInterface::luaVocationGetManaGainTicks);\n\tregisterMethod(\"Vocation\", \"getManaGainAmount\", LuaScriptInterface::luaVocationGetManaGainAmount);\n\n\tregisterMethod(\"Vocation\", \"getMaxSoul\", LuaScriptInterface::luaVocationGetMaxSoul);\n\tregisterMethod(\"Vocation\", \"getSoulGainTicks\", LuaScriptInterface::luaVocationGetSoulGainTicks);\n\n\tregisterMethod(\"Vocation\", \"getAttackSpeed\", LuaScriptInterface::luaVocationGetAttackSpeed);\n\tregisterMethod(\"Vocation\", \"getBaseSpeed\", LuaScriptInterface::luaVocationGetBaseSpeed);\n\n\tregisterMethod(\"Vocation\", \"getDemotion\", LuaScriptInterface::luaVocationGetDemotion);\n\tregisterMethod(\"Vocation\", \"getPromotion\", LuaScriptInterface::luaVocationGetPromotion);\n\n\t// Town\n\tregisterClass(\"Town\", \"\", LuaScriptInterface::luaTownCreate);\n\tregisterMetaMethod(\"Town\", \"__eq\", LuaScriptInterface::luaUserdataCompare);\n\n\tregisterMethod(\"Town\", \"getId\", LuaScriptInterface::luaTownGetId);\n\tregisterMethod(\"Town\", \"getName\", LuaScriptInterface::luaTownGetName);\n\tregisterMethod(\"Town\", \"getTemplePosition\", LuaScriptInterface::luaTownGetTemplePosition);\n\n\t// House\n\tregisterClass(\"House\", \"\", LuaScriptInterface::luaHouseCreate);\n\tregisterMetaMethod(\"House\", \"__eq\", LuaScriptInterface::luaUserdataCompare);\n\n\tregisterMethod(\"House\", \"getId\", LuaScriptInterface::luaHouseGetId);\n\tregisterMethod(\"House\", \"getName\", LuaScriptInterface::luaHouseGetName);\n\tregisterMethod(\"House\", \"getTown\", LuaScriptInterface::luaHouseGetTown);\n\tregisterMethod(\"House\", \"getExitPosition\", LuaScriptInterface::luaHouseGetExitPosition);\n\tregisterMethod(\"House\", \"getRent\", LuaScriptInterface::luaHouseGetRent);\n\n\tregisterMethod(\"House\", \"getOwnerGuid\", LuaScriptInterface::luaHouseGetOwnerGuid);\n\tregisterMethod(\"House\", \"setOwnerGuid\", LuaScriptInterface::luaHouseSetOwnerGuid);\n\tregisterMethod(\"House\", \"startTrade\", LuaScriptInterface::luaHouseStartTrade);\n\n\tregisterMethod(\"House\", \"getBeds\", LuaScriptInterface::luaHouseGetBeds);\n\tregisterMethod(\"House\", \"getBedCount\", LuaScriptInterface::luaHouseGetBedCount);\n\n\tregisterMethod(\"House\", \"getDoors\", LuaScriptInterface::luaHouseGetDoors);\n\tregisterMethod(\"House\", \"getDoorCount\", LuaScriptInterface::luaHouseGetDoorCount);\n\tregisterMethod(\"House\", \"getDoorIdByPosition\", LuaScriptInterface::luaHouseGetDoorIdByPosition);\n\n\tregisterMethod(\"House\", \"getTiles\", LuaScriptInterface::luaHouseGetTiles);\n\tregisterMethod(\"House\", \"getItems\", LuaScriptInterface::luaHouseGetItems);\n\tregisterMethod(\"House\", \"getTileCount\", LuaScriptInterface::luaHouseGetTileCount);\n\n\tregisterMethod(\"House\", \"canEditAccessList\", LuaScriptInterface::luaHouseCanEditAccessList);\n\tregisterMethod(\"House\", \"getAccessList\", LuaScriptInterface::luaHouseGetAccessList);\n\tregisterMethod(\"House\", \"setAccessList\", LuaScriptInterface::luaHouseSetAccessList);\n\n\tregisterMethod(\"House\", \"kickPlayer\", LuaScriptInterface::luaHouseKickPlayer);\n\n\t// ItemType\n\tregisterClass(\"ItemType\", \"\", LuaScriptInterface::luaItemTypeCreate);\n\tregisterMetaMethod(\"ItemType\", \"__eq\", LuaScriptInterface::luaUserdataCompare);\n\n\tregisterMethod(\"ItemType\", \"isCorpse\", LuaScriptInterface::luaItemTypeIsCorpse);\n\tregisterMethod(\"ItemType\", \"isDoor\", LuaScriptInterface::luaItemTypeIsDoor);\n\tregisterMethod(\"ItemType\", \"isContainer\", LuaScriptInterface::luaItemTypeIsContainer);\n\tregisterMethod(\"ItemType\", \"isFluidContainer\", LuaScriptInterface::luaItemTypeIsFluidContainer);\n\tregisterMethod(\"ItemType\", \"isMovable\", LuaScriptInterface::luaItemTypeIsMovable);\n\tregisterMethod(\"ItemType\", \"isRune\", LuaScriptInterface::luaItemTypeIsRune);\n\tregisterMethod(\"ItemType\", \"isStackable\", LuaScriptInterface::luaItemTypeIsStackable);\n\tregisterMethod(\"ItemType\", \"isReadable\", LuaScriptInterface::luaItemTypeIsReadable);\n\tregisterMethod(\"ItemType\", \"isWritable\", LuaScriptInterface::luaItemTypeIsWritable);\n\tregisterMethod(\"ItemType\", \"isBlocking\", LuaScriptInterface::luaItemTypeIsBlocking);\n\tregisterMethod(\"ItemType\", \"isGroundTile\", LuaScriptInterface::luaItemTypeIsGroundTile);\n\tregisterMethod(\"ItemType\", \"isMagicField\", LuaScriptInterface::luaItemTypeIsMagicField);\n\tregisterMethod(\"ItemType\", \"isUseable\", LuaScriptInterface::luaItemTypeIsUseable);\n\tregisterMethod(\"ItemType\", \"isPickupable\", LuaScriptInterface::luaItemTypeIsPickupable);\n\n\tregisterMethod(\"ItemType\", \"getType\", LuaScriptInterface::luaItemTypeGetType);\n\tregisterMethod(\"ItemType\", \"getId\", LuaScriptInterface::luaItemTypeGetId);\n\tregisterMethod(\"ItemType\", \"getClientId\", LuaScriptInterface::luaItemTypeGetClientId);\n\tregisterMethod(\"ItemType\", \"getName\", LuaScriptInterface::luaItemTypeGetName);\n\tregisterMethod(\"ItemType\", \"getPluralName\", LuaScriptInterface::luaItemTypeGetPluralName);\n\tregisterMethod(\"ItemType\", \"getArticle\", LuaScriptInterface::luaItemTypeGetArticle);\n\tregisterMethod(\"ItemType\", \"getDescription\", LuaScriptInterface::luaItemTypeGetDescription);\n\tregisterMethod(\"ItemType\", \"getSlotPosition\", LuaScriptInterface::luaItemTypeGetSlotPosition);\n\n\tregisterMethod(\"ItemType\", \"getCharges\", LuaScriptInterface::luaItemTypeGetCharges);\n\tregisterMethod(\"ItemType\", \"getFluidSource\", LuaScriptInterface::luaItemTypeGetFluidSource);\n\tregisterMethod(\"ItemType\", \"getCapacity\", LuaScriptInterface::luaItemTypeGetCapacity);\n\tregisterMethod(\"ItemType\", \"getWeight\", LuaScriptInterface::luaItemTypeGetWeight);\n\n\tregisterMethod(\"ItemType\", \"getHitChance\", LuaScriptInterface::luaItemTypeGetHitChance);\n\tregisterMethod(\"ItemType\", \"getShootRange\", LuaScriptInterface::luaItemTypeGetShootRange);\n\n\tregisterMethod(\"ItemType\", \"getAttack\", LuaScriptInterface::luaItemTypeGetAttack);\n\tregisterMethod(\"ItemType\", \"getDefense\", LuaScriptInterface::luaItemTypeGetDefense);\n\tregisterMethod(\"ItemType\", \"getExtraDefense\", LuaScriptInterface::luaItemTypeGetExtraDefense);\n\tregisterMethod(\"ItemType\", \"getArmor\", LuaScriptInterface::luaItemTypeGetArmor);\n\tregisterMethod(\"ItemType\", \"getWeaponType\", LuaScriptInterface::luaItemTypeGetWeaponType);\n\n\tregisterMethod(\"ItemType\", \"getElementType\", LuaScriptInterface::luaItemTypeGetElementType);\n\tregisterMethod(\"ItemType\", \"getElementDamage\", LuaScriptInterface::luaItemTypeGetElementDamage);\n\n\tregisterMethod(\"ItemType\", \"getTransformEquipId\", LuaScriptInterface::luaItemTypeGetTransformEquipId);\n\tregisterMethod(\"ItemType\", \"getTransformDeEquipId\", LuaScriptInterface::luaItemTypeGetTransformDeEquipId);\n\tregisterMethod(\"ItemType\", \"getDestroyId\", LuaScriptInterface::luaItemTypeGetDestroyId);\n\tregisterMethod(\"ItemType\", \"getDecayId\", LuaScriptInterface::luaItemTypeGetDecayId);\n\tregisterMethod(\"ItemType\", \"getRequiredLevel\", LuaScriptInterface::luaItemTypeGetRequiredLevel);\n\tregisterMethod(\"ItemType\", \"getAmmoType\", LuaScriptInterface::luaItemTypeGetAmmoType);\n\tregisterMethod(\"ItemType\", \"getCorpseType\", LuaScriptInterface::luaItemTypeGetCorpseType);\n\n\tregisterMethod(\"ItemType\", \"hasSubType\", LuaScriptInterface::luaItemTypeHasSubType);\n\n\tregisterMethod(\"ItemType\", \"isStoreItem\", LuaScriptInterface::luaItemIsStoreItem);\n\n\t// Combat\n\tregisterClass(\"Combat\", \"\", LuaScriptInterface::luaCombatCreate);\n\tregisterMetaMethod(\"Combat\", \"__eq\", LuaScriptInterface::luaUserdataCompare);\n\n\tregisterMethod(\"Combat\", \"setParameter\", LuaScriptInterface::luaCombatSetParameter);\n\tregisterMethod(\"Combat\", \"setFormula\", LuaScriptInterface::luaCombatSetFormula);\n\n\tregisterMethod(\"Combat\", \"setArea\", LuaScriptInterface::luaCombatSetArea);\n\tregisterMethod(\"Combat\", \"addCondition\", LuaScriptInterface::luaCombatAddCondition);\n\tregisterMethod(\"Combat\", \"clearConditions\", LuaScriptInterface::luaCombatClearConditions);\n\tregisterMethod(\"Combat\", \"setCallback\", LuaScriptInterface::luaCombatSetCallback);\n\tregisterMethod(\"Combat\", \"setOrigin\", LuaScriptInterface::luaCombatSetOrigin);\n\n\tregisterMethod(\"Combat\", \"execute\", LuaScriptInterface::luaCombatExecute);\n\n\t// Condition\n\tregisterClass(\"Condition\", \"\", LuaScriptInterface::luaConditionCreate);\n\tregisterMetaMethod(\"Condition\", \"__eq\", LuaScriptInterface::luaUserdataCompare);\n\tregisterMetaMethod(\"Condition\", \"__gc\", LuaScriptInterface::luaConditionDelete);\n\tregisterMethod(\"Condition\", \"delete\", LuaScriptInterface::luaConditionDelete);\n\n\tregisterMethod(\"Condition\", \"getId\", LuaScriptInterface::luaConditionGetId);\n\tregisterMethod(\"Condition\", \"getSubId\", LuaScriptInterface::luaConditionGetSubId);\n\tregisterMethod(\"Condition\", \"getType\", LuaScriptInterface::luaConditionGetType);\n\tregisterMethod(\"Condition\", \"getIcons\", LuaScriptInterface::luaConditionGetIcons);\n\tregisterMethod(\"Condition\", \"getEndTime\", LuaScriptInterface::luaConditionGetEndTime);\n\n\tregisterMethod(\"Condition\", \"clone\", LuaScriptInterface::luaConditionClone);\n\n\tregisterMethod(\"Condition\", \"getTicks\", LuaScriptInterface::luaConditionGetTicks);\n\tregisterMethod(\"Condition\", \"setTicks\", LuaScriptInterface::luaConditionSetTicks);\n\n\tregisterMethod(\"Condition\", \"setParameter\", LuaScriptInterface::luaConditionSetParameter);\n\tregisterMethod(\"Condition\", \"setFormula\", LuaScriptInterface::luaConditionSetFormula);\n\tregisterMethod(\"Condition\", \"setOutfit\", LuaScriptInterface::luaConditionSetOutfit);\n\n\tregisterMethod(\"Condition\", \"addDamage\", LuaScriptInterface::luaConditionAddDamage);\n\n\t// Outfit\n\tregisterClass(\"Outfit\", \"\", LuaScriptInterface::luaOutfitCreate);\n\tregisterMetaMethod(\"Outfit\", \"__eq\", LuaScriptInterface::luaOutfitCompare);\n\n\t// MonsterType\n\tregisterClass(\"MonsterType\", \"\", LuaScriptInterface::luaMonsterTypeCreate);\n\tregisterMetaMethod(\"MonsterType\", \"__eq\", LuaScriptInterface::luaUserdataCompare);\n\n\tregisterMethod(\"MonsterType\", \"isAttackable\", LuaScriptInterface::luaMonsterTypeIsAttackable);\n\tregisterMethod(\"MonsterType\", \"isConvinceable\", LuaScriptInterface::luaMonsterTypeIsConvinceable);\n\tregisterMethod(\"MonsterType\", \"isSummonable\", LuaScriptInterface::luaMonsterTypeIsSummonable);\n\tregisterMethod(\"MonsterType\", \"isIllusionable\", LuaScriptInterface::luaMonsterTypeIsIllusionable);\n\tregisterMethod(\"MonsterType\", \"isHostile\", LuaScriptInterface::luaMonsterTypeIsHostile);\n\tregisterMethod(\"MonsterType\", \"isPushable\", LuaScriptInterface::luaMonsterTypeIsPushable);\n\tregisterMethod(\"MonsterType\", \"isHealthHidden\", LuaScriptInterface::luaMonsterTypeIsHealthHidden);\n\tregisterMethod(\"MonsterType\", \"isBoss\", LuaScriptInterface::luaMonsterTypeIsBoss);\n\n\tregisterMethod(\"MonsterType\", \"canPushItems\", LuaScriptInterface::luaMonsterTypeCanPushItems);\n\tregisterMethod(\"MonsterType\", \"canPushCreatures\", LuaScriptInterface::luaMonsterTypeCanPushCreatures);\n\n\tregisterMethod(\"MonsterType\", \"name\", LuaScriptInterface::luaMonsterTypeName);\n\n\tregisterMethod(\"MonsterType\", \"nameDescription\", LuaScriptInterface::luaMonsterTypeNameDescription);\n\n\tregisterMethod(\"MonsterType\", \"health\", LuaScriptInterface::luaMonsterTypeHealth);\n\tregisterMethod(\"MonsterType\", \"maxHealth\", LuaScriptInterface::luaMonsterTypeMaxHealth);\n\tregisterMethod(\"MonsterType\", \"runHealth\", LuaScriptInterface::luaMonsterTypeRunHealth);\n\tregisterMethod(\"MonsterType\", \"experience\", LuaScriptInterface::luaMonsterTypeExperience);\n\tregisterMethod(\"MonsterType\", \"skull\", LuaScriptInterface::luaMonsterTypeSkull);\n\n\tregisterMethod(\"MonsterType\", \"combatImmunities\", LuaScriptInterface::luaMonsterTypeCombatImmunities);\n\tregisterMethod(\"MonsterType\", \"conditionImmunities\", LuaScriptInterface::luaMonsterTypeConditionImmunities);\n\n\tregisterMethod(\"MonsterType\", \"getAttackList\", LuaScriptInterface::luaMonsterTypeGetAttackList);\n\tregisterMethod(\"MonsterType\", \"addAttack\", LuaScriptInterface::luaMonsterTypeAddAttack);\n\n\tregisterMethod(\"MonsterType\", \"getDefenseList\", LuaScriptInterface::luaMonsterTypeGetDefenseList);\n\tregisterMethod(\"MonsterType\", \"addDefense\", LuaScriptInterface::luaMonsterTypeAddDefense);\n\n\tregisterMethod(\"MonsterType\", \"getElementList\", LuaScriptInterface::luaMonsterTypeGetElementList);\n\tregisterMethod(\"MonsterType\", \"addElement\", LuaScriptInterface::luaMonsterTypeAddElement);\n\n\tregisterMethod(\"MonsterType\", \"getVoices\", LuaScriptInterface::luaMonsterTypeGetVoices);\n\tregisterMethod(\"MonsterType\", \"addVoice\", LuaScriptInterface::luaMonsterTypeAddVoice);\n\n\tregisterMethod(\"MonsterType\", \"getLoot\", LuaScriptInterface::luaMonsterTypeGetLoot);\n\tregisterMethod(\"MonsterType\", \"addLoot\", LuaScriptInterface::luaMonsterTypeAddLoot);\n\n\tregisterMethod(\"MonsterType\", \"getCreatureEvents\", LuaScriptInterface::luaMonsterTypeGetCreatureEvents);\n\tregisterMethod(\"MonsterType\", \"registerEvent\", LuaScriptInterface::luaMonsterTypeRegisterEvent);\n\n\tregisterMethod(\"MonsterType\", \"eventType\", LuaScriptInterface::luaMonsterTypeEventType);\n\tregisterMethod(\"MonsterType\", \"onThink\", LuaScriptInterface::luaMonsterTypeEventOnCallback);\n\tregisterMethod(\"MonsterType\", \"onAppear\", LuaScriptInterface::luaMonsterTypeEventOnCallback);\n\tregisterMethod(\"MonsterType\", \"onDisappear\", LuaScriptInterface::luaMonsterTypeEventOnCallback);\n\tregisterMethod(\"MonsterType\", \"onMove\", LuaScriptInterface::luaMonsterTypeEventOnCallback);\n\tregisterMethod(\"MonsterType\", \"onSay\", LuaScriptInterface::luaMonsterTypeEventOnCallback);\n\n\tregisterMethod(\"MonsterType\", \"getSummonList\", LuaScriptInterface::luaMonsterTypeGetSummonList);\n\tregisterMethod(\"MonsterType\", \"addSummon\", LuaScriptInterface::luaMonsterTypeAddSummon);\n\n\tregisterMethod(\"MonsterType\", \"maxSummons\", LuaScriptInterface::luaMonsterTypeMaxSummons);\n\n\tregisterMethod(\"MonsterType\", \"armor\", LuaScriptInterface::luaMonsterTypeArmor);\n\tregisterMethod(\"MonsterType\", \"defense\", LuaScriptInterface::luaMonsterTypeDefense);\n\tregisterMethod(\"MonsterType\", \"outfit\", LuaScriptInterface::luaMonsterTypeOutfit);\n\tregisterMethod(\"MonsterType\", \"race\", LuaScriptInterface::luaMonsterTypeRace);\n\tregisterMethod(\"MonsterType\", \"corpseId\", LuaScriptInterface::luaMonsterTypeCorpseId);\n\tregisterMethod(\"MonsterType\", \"manaCost\", LuaScriptInterface::luaMonsterTypeManaCost);\n\tregisterMethod(\"MonsterType\", \"baseSpeed\", LuaScriptInterface::luaMonsterTypeBaseSpeed);\n\tregisterMethod(\"MonsterType\", \"light\", LuaScriptInterface::luaMonsterTypeLight);\n\n\tregisterMethod(\"MonsterType\", \"staticAttackChance\", LuaScriptInterface::luaMonsterTypeStaticAttackChance);\n\tregisterMethod(\"MonsterType\", \"targetDistance\", LuaScriptInterface::luaMonsterTypeTargetDistance);\n\tregisterMethod(\"MonsterType\", \"yellChance\", LuaScriptInterface::luaMonsterTypeYellChance);\n\tregisterMethod(\"MonsterType\", \"yellSpeedTicks\", LuaScriptInterface::luaMonsterTypeYellSpeedTicks);\n\tregisterMethod(\"MonsterType\", \"changeTargetChance\", LuaScriptInterface::luaMonsterTypeChangeTargetChance);\n\tregisterMethod(\"MonsterType\", \"changeTargetSpeed\", LuaScriptInterface::luaMonsterTypeChangeTargetSpeed);\n\n\t// Loot\n\tregisterClass(\"Loot\", \"\", LuaScriptInterface::luaCreateLoot);\n\tregisterMetaMethod(\"Loot\", \"__gc\", LuaScriptInterface::luaDeleteLoot);\n\tregisterMethod(\"Loot\", \"delete\", LuaScriptInterface::luaDeleteLoot);\n\n\tregisterMethod(\"Loot\", \"setId\", LuaScriptInterface::luaLootSetId);\n\tregisterMethod(\"Loot\", \"setMaxCount\", LuaScriptInterface::luaLootSetMaxCount);\n\tregisterMethod(\"Loot\", \"setSubType\", LuaScriptInterface::luaLootSetSubType);\n\tregisterMethod(\"Loot\", \"setChance\", LuaScriptInterface::luaLootSetChance);\n\tregisterMethod(\"Loot\", \"setActionId\", LuaScriptInterface::luaLootSetActionId);\n\tregisterMethod(\"Loot\", \"setDescription\", LuaScriptInterface::luaLootSetDescription);\n\tregisterMethod(\"Loot\", \"addChildLoot\", LuaScriptInterface::luaLootAddChildLoot);\n\n\t// MonsterSpell\n\tregisterClass(\"MonsterSpell\", \"\", LuaScriptInterface::luaCreateMonsterSpell);\n\tregisterMetaMethod(\"MonsterSpell\", \"__gc\", LuaScriptInterface::luaDeleteMonsterSpell);\n\tregisterMethod(\"MonsterSpell\", \"delete\", LuaScriptInterface::luaDeleteMonsterSpell);\n\n\tregisterMethod(\"MonsterSpell\", \"setType\", LuaScriptInterface::luaMonsterSpellSetType);\n\tregisterMethod(\"MonsterSpell\", \"setScriptName\", LuaScriptInterface::luaMonsterSpellSetScriptName);\n\tregisterMethod(\"MonsterSpell\", \"setChance\", LuaScriptInterface::luaMonsterSpellSetChance);\n\tregisterMethod(\"MonsterSpell\", \"setInterval\", LuaScriptInterface::luaMonsterSpellSetInterval);\n\tregisterMethod(\"MonsterSpell\", \"setRange\", LuaScriptInterface::luaMonsterSpellSetRange);\n\tregisterMethod(\"MonsterSpell\", \"setCombatValue\", LuaScriptInterface::luaMonsterSpellSetCombatValue);\n\tregisterMethod(\"MonsterSpell\", \"setCombatType\", LuaScriptInterface::luaMonsterSpellSetCombatType);\n\tregisterMethod(\"MonsterSpell\", \"setAttackValue\", LuaScriptInterface::luaMonsterSpellSetAttackValue);\n\tregisterMethod(\"MonsterSpell\", \"setNeedTarget\", LuaScriptInterface::luaMonsterSpellSetNeedTarget);\n\tregisterMethod(\"MonsterSpell\", \"setCombatLength\", LuaScriptInterface::luaMonsterSpellSetCombatLength);\n\tregisterMethod(\"MonsterSpell\", \"setCombatSpread\", LuaScriptInterface::luaMonsterSpellSetCombatSpread);\n\tregisterMethod(\"MonsterSpell\", \"setCombatRadius\", LuaScriptInterface::luaMonsterSpellSetCombatRadius);\n\tregisterMethod(\"MonsterSpell\", \"setConditionType\", LuaScriptInterface::luaMonsterSpellSetConditionType);\n\tregisterMethod(\"MonsterSpell\", \"setConditionDamage\", LuaScriptInterface::luaMonsterSpellSetConditionDamage);\n\tregisterMethod(\"MonsterSpell\", \"setConditionSpeedChange\", LuaScriptInterface::luaMonsterSpellSetConditionSpeedChange);\n\tregisterMethod(\"MonsterSpell\", \"setConditionDuration\", LuaScriptInterface::luaMonsterSpellSetConditionDuration);\n\tregisterMethod(\"MonsterSpell\", \"setConditionTickInterval\", LuaScriptInterface::luaMonsterSpellSetConditionTickInterval);\n\tregisterMethod(\"MonsterSpell\", \"setCombatShootEffect\", LuaScriptInterface::luaMonsterSpellSetCombatShootEffect);\n\tregisterMethod(\"MonsterSpell\", \"setCombatEffect\", LuaScriptInterface::luaMonsterSpellSetCombatEffect);\n\n\t// Party\n\tregisterClass(\"Party\", \"\", LuaScriptInterface::luaPartyCreate);\n\tregisterMetaMethod(\"Party\", \"__eq\", LuaScriptInterface::luaUserdataCompare);\n\n\tregisterMethod(\"Party\", \"disband\", LuaScriptInterface::luaPartyDisband);\n\n\tregisterMethod(\"Party\", \"getLeader\", LuaScriptInterface::luaPartyGetLeader);\n\tregisterMethod(\"Party\", \"setLeader\", LuaScriptInterface::luaPartySetLeader);\n\n\tregisterMethod(\"Party\", \"getMembers\", LuaScriptInterface::luaPartyGetMembers);\n\tregisterMethod(\"Party\", \"getMemberCount\", LuaScriptInterface::luaPartyGetMemberCount);\n\n\tregisterMethod(\"Party\", \"getInvitees\", LuaScriptInterface::luaPartyGetInvitees);\n\tregisterMethod(\"Party\", \"getInviteeCount\", LuaScriptInterface::luaPartyGetInviteeCount);\n\n\tregisterMethod(\"Party\", \"addInvite\", LuaScriptInterface::luaPartyAddInvite);\n\tregisterMethod(\"Party\", \"removeInvite\", LuaScriptInterface::luaPartyRemoveInvite);\n\n\tregisterMethod(\"Party\", \"addMember\", LuaScriptInterface::luaPartyAddMember);\n\tregisterMethod(\"Party\", \"removeMember\", LuaScriptInterface::luaPartyRemoveMember);\n\n\tregisterMethod(\"Party\", \"isSharedExperienceActive\", LuaScriptInterface::luaPartyIsSharedExperienceActive);\n\tregisterMethod(\"Party\", \"isSharedExperienceEnabled\", LuaScriptInterface::luaPartyIsSharedExperienceEnabled);\n\tregisterMethod(\"Party\", \"shareExperience\", LuaScriptInterface::luaPartyShareExperience);\n\tregisterMethod(\"Party\", \"setSharedExperience\", LuaScriptInterface::luaPartySetSharedExperience);\n\n\t// Spells\n\tregisterClass(\"Spell\", \"\", LuaScriptInterface::luaSpellCreate);\n\tregisterMetaMethod(\"Spell\", \"__eq\", LuaScriptInterface::luaUserdataCompare);\n\n\tregisterMethod(\"Spell\", \"onCastSpell\", LuaScriptInterface::luaSpellOnCastSpell);\n\tregisterMethod(\"Spell\", \"register\", LuaScriptInterface::luaSpellRegister);\n\tregisterMethod(\"Spell\", \"name\", LuaScriptInterface::luaSpellName);\n\tregisterMethod(\"Spell\", \"id\", LuaScriptInterface::luaSpellId);\n\tregisterMethod(\"Spell\", \"group\", LuaScriptInterface::luaSpellGroup);\n\tregisterMethod(\"Spell\", \"cooldown\", LuaScriptInterface::luaSpellCooldown);\n\tregisterMethod(\"Spell\", \"groupCooldown\", LuaScriptInterface::luaSpellGroupCooldown);\n\tregisterMethod(\"Spell\", \"level\", LuaScriptInterface::luaSpellLevel);\n\tregisterMethod(\"Spell\", \"magicLevel\", LuaScriptInterface::luaSpellMagicLevel);\n\tregisterMethod(\"Spell\", \"mana\", LuaScriptInterface::luaSpellMana);\n\tregisterMethod(\"Spell\", \"manaPercent\", LuaScriptInterface::luaSpellManaPercent);\n\tregisterMethod(\"Spell\", \"soul\", LuaScriptInterface::luaSpellSoul);\n\tregisterMethod(\"Spell\", \"range\", LuaScriptInterface::luaSpellRange);\n\tregisterMethod(\"Spell\", \"isPremium\", LuaScriptInterface::luaSpellPremium);\n\tregisterMethod(\"Spell\", \"isEnabled\", LuaScriptInterface::luaSpellEnabled);\n\tregisterMethod(\"Spell\", \"needTarget\", LuaScriptInterface::luaSpellNeedTarget);\n\tregisterMethod(\"Spell\", \"needWeapon\", LuaScriptInterface::luaSpellNeedWeapon);\n\tregisterMethod(\"Spell\", \"needLearn\", LuaScriptInterface::luaSpellNeedLearn);\n\tregisterMethod(\"Spell\", \"isSelfTarget\", LuaScriptInterface::luaSpellSelfTarget);\n\tregisterMethod(\"Spell\", \"isBlocking\", LuaScriptInterface::luaSpellBlocking);\n\tregisterMethod(\"Spell\", \"isAggressive\", LuaScriptInterface::luaSpellAggressive);\n\tregisterMethod(\"Spell\", \"vocation\", LuaScriptInterface::luaSpellVocation);\n\n\t// only for InstantSpell\n\tregisterMethod(\"Spell\", \"words\", LuaScriptInterface::luaSpellWords);\n\tregisterMethod(\"Spell\", \"needDirection\", LuaScriptInterface::luaSpellNeedDirection);\n\tregisterMethod(\"Spell\", \"hasParams\", LuaScriptInterface::luaSpellHasParams);\n\tregisterMethod(\"Spell\", \"hasPlayerNameParam\", LuaScriptInterface::luaSpellHasPlayerNameParam);\n\tregisterMethod(\"Spell\", \"needCasterTargetOrDirection\", LuaScriptInterface::luaSpellNeedCasterTargetOrDirection);\n\tregisterMethod(\"Spell\", \"isBlockingWalls\", LuaScriptInterface::luaSpellIsBlockingWalls);\n\n\t// only for RuneSpells\n\tregisterMethod(\"Spell\", \"runeId\", LuaScriptInterface::luaSpellRuneId);\n\tregisterMethod(\"Spell\", \"charges\", LuaScriptInterface::luaSpellCharges);\n\tregisterMethod(\"Spell\", \"allowFarUse\", LuaScriptInterface::luaSpellAllowFarUse);\n\tregisterMethod(\"Spell\", \"blockWalls\", LuaScriptInterface::luaSpellBlockWalls);\n\tregisterMethod(\"Spell\", \"checkFloor\", LuaScriptInterface::luaSpellCheckFloor);\n\n\t// Action\n\tregisterClass(\"Action\", \"\", LuaScriptInterface::luaCreateAction);\n\tregisterMethod(\"Action\", \"onUse\", LuaScriptInterface::luaActionOnUse);\n\tregisterMethod(\"Action\", \"register\", LuaScriptInterface::luaActionRegister);\n\tregisterMethod(\"Action\", \"id\", LuaScriptInterface::luaActionItemId);\n\tregisterMethod(\"Action\", \"aid\", LuaScriptInterface::luaActionActionId);\n\tregisterMethod(\"Action\", \"uid\", LuaScriptInterface::luaActionUniqueId);\n\tregisterMethod(\"Action\", \"allowFarUse\", LuaScriptInterface::luaActionAllowFarUse);\n\tregisterMethod(\"Action\", \"blockWalls\", LuaScriptInterface::luaActionBlockWalls);\n\tregisterMethod(\"Action\", \"checkFloor\", LuaScriptInterface::luaActionCheckFloor);\n\n\t// TalkAction\n\tregisterClass(\"TalkAction\", \"\", LuaScriptInterface::luaCreateTalkaction);\n\tregisterMethod(\"TalkAction\", \"onSay\", LuaScriptInterface::luaTalkactionOnSay);\n\tregisterMethod(\"TalkAction\", \"register\", LuaScriptInterface::luaTalkactionRegister);\n\tregisterMethod(\"TalkAction\", \"separator\", LuaScriptInterface::luaTalkactionSeparator);\n\n\t// CreatureEvent\n\tregisterClass(\"CreatureEvent\", \"\", LuaScriptInterface::luaCreateCreatureEvent);\n\tregisterMethod(\"CreatureEvent\", \"type\", LuaScriptInterface::luaCreatureEventType);\n\tregisterMethod(\"CreatureEvent\", \"register\", LuaScriptInterface::luaCreatureEventRegister);\n\tregisterMethod(\"CreatureEvent\", \"onLogin\", LuaScriptInterface::luaCreatureEventOnCallback);\n\tregisterMethod(\"CreatureEvent\", \"onLogout\", LuaScriptInterface::luaCreatureEventOnCallback);\n\tregisterMethod(\"CreatureEvent\", \"onThink\", LuaScriptInterface::luaCreatureEventOnCallback);\n\tregisterMethod(\"CreatureEvent\", \"onPrepareDeath\", LuaScriptInterface::luaCreatureEventOnCallback);\n\tregisterMethod(\"CreatureEvent\", \"onDeath\", LuaScriptInterface::luaCreatureEventOnCallback);\n\tregisterMethod(\"CreatureEvent\", \"onKill\", LuaScriptInterface::luaCreatureEventOnCallback);\n\tregisterMethod(\"CreatureEvent\", \"onAdvance\", LuaScriptInterface::luaCreatureEventOnCallback);\n\tregisterMethod(\"CreatureEvent\", \"onModalWindow\", LuaScriptInterface::luaCreatureEventOnCallback);\n\tregisterMethod(\"CreatureEvent\", \"onTextEdit\", LuaScriptInterface::luaCreatureEventOnCallback);\n\tregisterMethod(\"CreatureEvent\", \"onHealthChange\", LuaScriptInterface::luaCreatureEventOnCallback);\n\tregisterMethod(\"CreatureEvent\", \"onManaChange\", LuaScriptInterface::luaCreatureEventOnCallback);\n\tregisterMethod(\"CreatureEvent\", \"onExtendedOpcode\", LuaScriptInterface::luaCreatureEventOnCallback);\n\n\t// MoveEvent\n\tregisterClass(\"MoveEvent\", \"\", LuaScriptInterface::luaCreateMoveEvent);\n\tregisterMethod(\"MoveEvent\", \"type\", LuaScriptInterface::luaMoveEventType);\n\tregisterMethod(\"MoveEvent\", \"register\", LuaScriptInterface::luaMoveEventRegister);\n\tregisterMethod(\"MoveEvent\", \"level\", LuaScriptInterface::luaMoveEventLevel);\n\tregisterMethod(\"MoveEvent\", \"magicLevel\", LuaScriptInterface::luaMoveEventMagLevel);\n\tregisterMethod(\"MoveEvent\", \"slot\", LuaScriptInterface::luaMoveEventSlot);\n\tregisterMethod(\"MoveEvent\", \"id\", LuaScriptInterface::luaMoveEventItemId);\n\tregisterMethod(\"MoveEvent\", \"aid\", LuaScriptInterface::luaMoveEventActionId);\n\tregisterMethod(\"MoveEvent\", \"uid\", LuaScriptInterface::luaMoveEventUniqueId);\n\tregisterMethod(\"MoveEvent\", \"position\", LuaScriptInterface::luaMoveEventPosition);\n\tregisterMethod(\"MoveEvent\", \"premium\", LuaScriptInterface::luaMoveEventPremium);\n\tregisterMethod(\"MoveEvent\", \"vocation\", LuaScriptInterface::luaMoveEventVocation);\n\tregisterMethod(\"MoveEvent\", \"onEquip\", LuaScriptInterface::luaMoveEventOnCallback);\n\tregisterMethod(\"MoveEvent\", \"onDeEquip\", LuaScriptInterface::luaMoveEventOnCallback);\n\tregisterMethod(\"MoveEvent\", \"onStepIn\", LuaScriptInterface::luaMoveEventOnCallback);\n\tregisterMethod(\"MoveEvent\", \"onStepOut\", LuaScriptInterface::luaMoveEventOnCallback);\n\tregisterMethod(\"MoveEvent\", \"onAddItem\", LuaScriptInterface::luaMoveEventOnCallback);\n\tregisterMethod(\"MoveEvent\", \"onRemoveItem\", LuaScriptInterface::luaMoveEventOnCallback);\n\n\t// GlobalEvent\n\tregisterClass(\"GlobalEvent\", \"\", LuaScriptInterface::luaCreateGlobalEvent);\n\tregisterMethod(\"GlobalEvent\", \"type\", LuaScriptInterface::luaGlobalEventType);\n\tregisterMethod(\"GlobalEvent\", \"register\", LuaScriptInterface::luaGlobalEventRegister);\n\tregisterMethod(\"GlobalEvent\", \"time\", LuaScriptInterface::luaGlobalEventTime);\n\tregisterMethod(\"GlobalEvent\", \"interval\", LuaScriptInterface::luaGlobalEventInterval);\n\tregisterMethod(\"GlobalEvent\", \"onThink\", LuaScriptInterface::luaGlobalEventOnCallback);\n\tregisterMethod(\"GlobalEvent\", \"onTime\", LuaScriptInterface::luaGlobalEventOnCallback);\n\tregisterMethod(\"GlobalEvent\", \"onStartup\", LuaScriptInterface::luaGlobalEventOnCallback);\n\tregisterMethod(\"GlobalEvent\", \"onShutdown\", LuaScriptInterface::luaGlobalEventOnCallback);\n\tregisterMethod(\"GlobalEvent\", \"onRecord\", LuaScriptInterface::luaGlobalEventOnCallback);\n\n\t// Weapon\n\tregisterClass(\"Weapon\", \"\", LuaScriptInterface::luaCreateWeapon);\n\tregisterMethod(\"Weapon\", \"action\", LuaScriptInterface::luaWeaponAction);\n\tregisterMethod(\"Weapon\", \"register\", LuaScriptInterface::luaWeaponRegister);\n\tregisterMethod(\"Weapon\", \"id\", LuaScriptInterface::luaWeaponId);\n\tregisterMethod(\"Weapon\", \"level\", LuaScriptInterface::luaWeaponLevel);\n\tregisterMethod(\"Weapon\", \"magicLevel\", LuaScriptInterface::luaWeaponMagicLevel);\n\tregisterMethod(\"Weapon\", \"mana\", LuaScriptInterface::luaWeaponMana);\n\tregisterMethod(\"Weapon\", \"manaPercent\", LuaScriptInterface::luaWeaponManaPercent);\n\tregisterMethod(\"Weapon\", \"health\", LuaScriptInterface::luaWeaponHealth);\n\tregisterMethod(\"Weapon\", \"healthPercent\", LuaScriptInterface::luaWeaponHealthPercent);\n\tregisterMethod(\"Weapon\", \"soul\", LuaScriptInterface::luaWeaponSoul);\n\tregisterMethod(\"Weapon\", \"breakChance\", LuaScriptInterface::luaWeaponBreakChance);\n\tregisterMethod(\"Weapon\", \"premium\", LuaScriptInterface::luaWeaponPremium);\n\tregisterMethod(\"Weapon\", \"wieldUnproperly\", LuaScriptInterface::luaWeaponUnproperly);\n\tregisterMethod(\"Weapon\", \"vocation\", LuaScriptInterface::luaWeaponVocation);\n\tregisterMethod(\"Weapon\", \"onUseWeapon\", LuaScriptInterface::luaWeaponOnUseWeapon);\n\tregisterMethod(\"Weapon\", \"element\", LuaScriptInterface::luaWeaponElement);\n\tregisterMethod(\"Weapon\", \"attack\", LuaScriptInterface::luaWeaponAttack);\n\tregisterMethod(\"Weapon\", \"defense\", LuaScriptInterface::luaWeaponDefense);\n\tregisterMethod(\"Weapon\", \"range\", LuaScriptInterface::luaWeaponRange);\n\tregisterMethod(\"Weapon\", \"charges\", LuaScriptInterface::luaWeaponCharges);\n\tregisterMethod(\"Weapon\", \"duration\", LuaScriptInterface::luaWeaponDuration);\n\tregisterMethod(\"Weapon\", \"decayTo\", LuaScriptInterface::luaWeaponDecayTo);\n\tregisterMethod(\"Weapon\", \"transformEquipTo\", LuaScriptInterface::luaWeaponTransformEquipTo);\n\tregisterMethod(\"Weapon\", \"transformDeEquipTo\", LuaScriptInterface::luaWeaponTransformDeEquipTo);\n\tregisterMethod(\"Weapon\", \"slotType\", LuaScriptInterface::luaWeaponSlotType);\n\tregisterMethod(\"Weapon\", \"hitChance\", LuaScriptInterface::luaWeaponHitChance);\n\tregisterMethod(\"Weapon\", \"extraElement\", LuaScriptInterface::luaWeaponExtraElement);\n\n\t// exclusively for distance weapons\n\tregisterMethod(\"Weapon\", \"ammoType\", LuaScriptInterface::luaWeaponAmmoType);\n\tregisterMethod(\"Weapon\", \"maxHitChance\", LuaScriptInterface::luaWeaponMaxHitChance);\n\n\t// exclusively for wands\n\tregisterMethod(\"Weapon\", \"damage\", LuaScriptInterface::luaWeaponWandDamage);\n\n\t// exclusively for wands & distance weapons\n\tregisterMethod(\"Weapon\", \"shootType\", LuaScriptInterface::luaWeaponShootType);\n}\n\n#undef registerEnum\n#undef registerEnumIn\n\nvoid LuaScriptInterface::registerClass(const std::string& className, const std::string& baseClass, lua_CFunction newFunction/* = nullptr*/)\n{\n\t// className = {}\n\tlua_newtable(luaState);\n\tlua_pushvalue(luaState, -1);\n\tlua_setglobal(luaState, className.c_str());\n\tint methods = lua_gettop(luaState);\n\n\t// methodsTable = {}\n\tlua_newtable(luaState);\n\tint methodsTable = lua_gettop(luaState);\n\n\tif (newFunction) {\n\t\t// className.__call = newFunction\n\t\tlua_pushcfunction(luaState, newFunction);\n\t\tlua_setfield(luaState, methodsTable, \"__call\");\n\t}\n\n\tuint32_t parents = 0;\n\tif (!baseClass.empty()) {\n\t\tlua_getglobal(luaState, baseClass.c_str());\n\t\tlua_rawgeti(luaState, -1, 'p');\n\t\tparents = getNumber<uint32_t>(luaState, -1) + 1;\n\t\tlua_pop(luaState, 1);\n\t\tlua_setfield(luaState, methodsTable, \"__index\");\n\t}\n\n\t// setmetatable(className, methodsTable)\n\tlua_setmetatable(luaState, methods);\n\n\t// className.metatable = {}\n\tluaL_newmetatable(luaState, className.c_str());\n\tint metatable = lua_gettop(luaState);\n\n\t// className.metatable.__metatable = className\n\tlua_pushvalue(luaState, methods);\n\tlua_setfield(luaState, metatable, \"__metatable\");\n\n\t// className.metatable.__index = className\n\tlua_pushvalue(luaState, methods);\n\tlua_setfield(luaState, metatable, \"__index\");\n\n\t// className.metatable['h'] = hash\n\tlua_pushnumber(luaState, std::hash<std::string>()(className));\n\tlua_rawseti(luaState, metatable, 'h');\n\n\t// className.metatable['p'] = parents\n\tlua_pushnumber(luaState, parents);\n\tlua_rawseti(luaState, metatable, 'p');\n\n\t// className.metatable['t'] = type\n\tif (className == \"Item\") {\n\t\tlua_pushnumber(luaState, LuaData_Item);\n\t} else if (className == \"Container\") {\n\t\tlua_pushnumber(luaState, LuaData_Container);\n\t} else if (className == \"Teleport\") {\n\t\tlua_pushnumber(luaState, LuaData_Teleport);\n\t} else if (className == \"Player\") {\n\t\tlua_pushnumber(luaState, LuaData_Player);\n\t} else if (className == \"Monster\") {\n\t\tlua_pushnumber(luaState, LuaData_Monster);\n\t} else if (className == \"Npc\") {\n\t\tlua_pushnumber(luaState, LuaData_Npc);\n\t} else if (className == \"Tile\") {\n\t\tlua_pushnumber(luaState, LuaData_Tile);\n\t} else {\n\t\tlua_pushnumber(luaState, LuaData_Unknown);\n\t}\n\tlua_rawseti(luaState, metatable, 't');\n\n\t// pop className, className.metatable\n\tlua_pop(luaState, 2);\n}\n\nvoid LuaScriptInterface::registerTable(const std::string& tableName)\n{\n\t// _G[tableName] = {}\n\tlua_newtable(luaState);\n\tlua_setglobal(luaState, tableName.c_str());\n}\n\nvoid LuaScriptInterface::registerMethod(const std::string& globalName, const std::string& methodName, lua_CFunction func)\n{\n\t// globalName.methodName = func\n\tlua_getglobal(luaState, globalName.c_str());\n\tlua_pushcfunction(luaState, func);\n\tlua_setfield(luaState, -2, methodName.c_str());\n\n\t// pop globalName\n\tlua_pop(luaState, 1);\n}\n\nvoid LuaScriptInterface::registerMetaMethod(const std::string& className, const std::string& methodName, lua_CFunction func)\n{\n\t// className.metatable.methodName = func\n\tluaL_getmetatable(luaState, className.c_str());\n\tlua_pushcfunction(luaState, func);\n\tlua_setfield(luaState, -2, methodName.c_str());\n\n\t// pop className.metatable\n\tlua_pop(luaState, 1);\n}\n\nvoid LuaScriptInterface::registerGlobalMethod(const std::string& functionName, lua_CFunction func)\n{\n\t// _G[functionName] = func\n\tlua_pushcfunction(luaState, func);\n\tlua_setglobal(luaState, functionName.c_str());\n}\n\nvoid LuaScriptInterface::registerVariable(const std::string& tableName, const std::string& name, lua_Number value)\n{\n\t// tableName.name = value\n\tlua_getglobal(luaState, tableName.c_str());\n\tsetField(luaState, name.c_str(), value);\n\n\t// pop tableName\n\tlua_pop(luaState, 1);\n}\n\nvoid LuaScriptInterface::registerGlobalVariable(const std::string& name, lua_Number value)\n{\n\t// _G[name] = value\n\tlua_pushnumber(luaState, value);\n\tlua_setglobal(luaState, name.c_str());\n}\n\nvoid LuaScriptInterface::registerGlobalBoolean(const std::string& name, bool value)\n{\n\t// _G[name] = value\n\tpushBoolean(luaState, value);\n\tlua_setglobal(luaState, name.c_str());\n}\n\nint LuaScriptInterface::luaDoPlayerAddItem(lua_State* L)\n{\n\t//doPlayerAddItem(cid, itemid, <optional: default: 1> count/subtype, <optional: default: 1> canDropOnMap)\n\t//doPlayerAddItem(cid, itemid, <optional: default: 1> count, <optional: default: 1> canDropOnMap, <optional: default: 1>subtype)\n\tPlayer* player = getPlayer(L, 1);\n\tif (!player) {\n\t\treportErrorFunc(getErrorDesc(LUA_ERROR_PLAYER_NOT_FOUND));\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tuint16_t itemId = getNumber<uint16_t>(L, 2);\n\tint32_t count = getNumber<int32_t>(L, 3, 1);\n\tbool canDropOnMap = getBoolean(L, 4, true);\n\tuint16_t subType = getNumber<uint16_t>(L, 5, 1);\n\n\tconst ItemType& it = Item::items[itemId];\n\tint32_t itemCount;\n\n\tauto parameters = lua_gettop(L);\n\tif (parameters > 4) {\n\t\t//subtype already supplied, count then is the amount\n\t\titemCount = std::max<int32_t>(1, count);\n\t} else if (it.hasSubType()) {\n\t\tif (it.stackable) {\n\t\t\titemCount = static_cast<int32_t>(std::ceil(static_cast<float>(count) / 100));\n\t\t} else {\n\t\t\titemCount = 1;\n\t\t}\n\t\tsubType = count;\n\t} else {\n\t\titemCount = std::max<int32_t>(1, count);\n\t}\n\n\twhile (itemCount > 0) {\n\t\tuint16_t stackCount = subType;\n\t\tif (it.stackable && stackCount > 100) {\n\t\t\tstackCount = 100;\n\t\t}\n\n\t\tItem* newItem = Item::CreateItem(itemId, stackCount);\n\t\tif (!newItem) {\n\t\t\treportErrorFunc(getErrorDesc(LUA_ERROR_ITEM_NOT_FOUND));\n\t\t\tpushBoolean(L, false);\n\t\t\treturn 1;\n\t\t}\n\n\t\tif (it.stackable) {\n\t\t\tsubType -= stackCount;\n\t\t}\n\n\t\tReturnValue ret = g_game.internalPlayerAddItem(player, newItem, canDropOnMap);\n\t\tif (ret != RETURNVALUE_NOERROR) {\n\t\t\tdelete newItem;\n\t\t\tpushBoolean(L, false);\n\t\t\treturn 1;\n\t\t}\n\n\t\tif (--itemCount == 0) {\n\t\t\tif (newItem->getParent()) {\n\t\t\t\tuint32_t uid = getScriptEnv()->addThing(newItem);\n\t\t\t\tlua_pushnumber(L, uid);\n\t\t\t\treturn 1;\n\t\t\t} else {\n\t\t\t\t//stackable item stacked with existing object, newItem will be released\n\t\t\t\tpushBoolean(L, false);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}\n\t}\n\n\tpushBoolean(L, false);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaDebugPrint(lua_State* L)\n{\n\t//debugPrint(text)\n\treportErrorFunc(getString(L, -1));\n\treturn 0;\n}\n\nint LuaScriptInterface::luaGetWorldTime(lua_State* L)\n{\n\t//getWorldTime()\n\tuint32_t time = g_game.getLightHour();\n\tlua_pushnumber(L, time);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGetWorldLight(lua_State* L)\n{\n\t//getWorldLight()\n\tLightInfo lightInfo = g_game.getWorldLightInfo();\n\tlua_pushnumber(L, lightInfo.level);\n\tlua_pushnumber(L, lightInfo.color);\n\treturn 2;\n}\n\nint LuaScriptInterface::luaGetWorldUpTime(lua_State* L)\n{\n\t//getWorldUpTime()\n\tuint64_t uptime = (OTSYS_TIME() - ProtocolStatus::start) / 1000;\n\tlua_pushnumber(L, uptime);\n\treturn 1;\n}\n\nbool LuaScriptInterface::getArea(lua_State* L, std::list<uint32_t>& list, uint32_t& rows)\n{\n\tlua_pushnil(L);\n\tfor (rows = 0; lua_next(L, -2) != 0; ++rows) {\n\t\tif (!isTable(L, -1)) {\n\t\t\treturn false;\n\t\t}\n\n\t\tlua_pushnil(L);\n\t\twhile (lua_next(L, -2) != 0) {\n\t\t\tif (!isNumber(L, -1)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\tlist.push_back(getNumber<uint32_t>(L, -1));\n\t\t\tlua_pop(L, 1);\n\t\t}\n\n\t\tlua_pop(L, 1);\n\t}\n\n\tlua_pop(L, 1);\n\treturn (rows != 0);\n}\n\nint LuaScriptInterface::luaCreateCombatArea(lua_State* L)\n{\n\t//createCombatArea( {area}, <optional> {extArea} )\n\tScriptEnvironment* env = getScriptEnv();\n\tif (env->getScriptId() != EVENT_ID_LOADING) {\n\t\treportErrorFunc(\"This function can only be used while loading the script.\");\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tuint32_t areaId = g_luaEnvironment.createAreaObject(env->getScriptInterface());\n\tAreaCombat* area = g_luaEnvironment.getAreaObject(areaId);\n\n\tint parameters = lua_gettop(L);\n\tif (parameters >= 2) {\n\t\tuint32_t rowsExtArea;\n\t\tstd::list<uint32_t> listExtArea;\n\t\tif (!isTable(L, 2) || !getArea(L, listExtArea, rowsExtArea)) {\n\t\t\treportErrorFunc(\"Invalid extended area table.\");\n\t\t\tpushBoolean(L, false);\n\t\t\treturn 1;\n\t\t}\n\t\tarea->setupExtArea(listExtArea, rowsExtArea);\n\t}\n\n\tuint32_t rowsArea = 0;\n\tstd::list<uint32_t> listArea;\n\tif (!isTable(L, 1) || !getArea(L, listArea, rowsArea)) {\n\t\treportErrorFunc(\"Invalid area table.\");\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tarea->setupArea(listArea, rowsArea);\n\tlua_pushnumber(L, areaId);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaDoAreaCombat(lua_State* L)\n{\n\t//doAreaCombat(cid, type, pos, area, min, max, effect[, origin = ORIGIN_SPELL])\n\tCreature* creature = getCreature(L, 1);\n\tif (!creature && (!isNumber(L, 1) || getNumber<uint32_t>(L, 1) != 0)) {\n\t\treportErrorFunc(getErrorDesc(LUA_ERROR_CREATURE_NOT_FOUND));\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tuint32_t areaId = getNumber<uint32_t>(L, 4);\n\tconst AreaCombat* area = g_luaEnvironment.getAreaObject(areaId);\n\tif (area || areaId == 0) {\n\t\tCombatType_t combatType = getNumber<CombatType_t>(L, 2);\n\n\t\tCombatParams params;\n\t\tparams.combatType = combatType;\n\t\tparams.impactEffect = getNumber<uint8_t>(L, 7);\n\n\t\tCombatDamage damage;\n\t\tdamage.origin = getNumber<CombatOrigin>(L, 8, ORIGIN_SPELL);\n\t\tdamage.primary.type = combatType;\n\t\tdamage.primary.value = normal_random(getNumber<int32_t>(L, 6), getNumber<int32_t>(L, 5));\n\n\t\tCombat::doAreaCombat(creature, getPosition(L, 3), area, damage, params);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\treportErrorFunc(getErrorDesc(LUA_ERROR_AREA_NOT_FOUND));\n\t\tpushBoolean(L, false);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaDoTargetCombat(lua_State* L)\n{\n\t//doTargetCombat(cid, target, type, min, max, effect[, origin = ORIGIN_SPELL])\n\tCreature* creature = getCreature(L, 1);\n\tif (!creature && (!isNumber(L, 1) || getNumber<uint32_t>(L, 1) != 0)) {\n\t\treportErrorFunc(getErrorDesc(LUA_ERROR_CREATURE_NOT_FOUND));\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tCreature* target = getCreature(L, 2);\n\tif (!target) {\n\t\treportErrorFunc(getErrorDesc(LUA_ERROR_CREATURE_NOT_FOUND));\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tCombatType_t combatType = getNumber<CombatType_t>(L, 3);\n\n\tCombatParams params;\n\tparams.combatType = combatType;\n\tparams.impactEffect = getNumber<uint8_t>(L, 6);\n\n\tCombatDamage damage;\n\tdamage.origin = getNumber<CombatOrigin>(L, 7, ORIGIN_SPELL);\n\tdamage.primary.type = combatType;\n\tdamage.primary.value = normal_random(getNumber<int32_t>(L, 4), getNumber<int32_t>(L, 5));\n\n\tCombat::doTargetCombat(creature, target, damage, params);\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaDoChallengeCreature(lua_State* L)\n{\n\t//doChallengeCreature(cid, target)\n\tCreature* creature = getCreature(L, 1);\n\tif (!creature) {\n\t\treportErrorFunc(getErrorDesc(LUA_ERROR_CREATURE_NOT_FOUND));\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tCreature* target = getCreature(L, 2);\n\tif (!target) {\n\t\treportErrorFunc(getErrorDesc(LUA_ERROR_CREATURE_NOT_FOUND));\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\ttarget->challengeCreature(creature);\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaIsValidUID(lua_State* L)\n{\n\t//isValidUID(uid)\n\tpushBoolean(L, getScriptEnv()->getThingByUID(getNumber<uint32_t>(L, -1)) != nullptr);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaIsDepot(lua_State* L)\n{\n\t//isDepot(uid)\n\tContainer* container = getScriptEnv()->getContainerByUID(getNumber<uint32_t>(L, -1));\n\tpushBoolean(L, container && container->getDepotLocker());\n\treturn 1;\n}\n\nint LuaScriptInterface::luaIsMoveable(lua_State* L)\n{\n\t//isMoveable(uid)\n\t//isMovable(uid)\n\tThing* thing = getScriptEnv()->getThingByUID(getNumber<uint32_t>(L, -1));\n\tpushBoolean(L, thing && thing->isPushable());\n\treturn 1;\n}\n\nint LuaScriptInterface::luaDoAddContainerItem(lua_State* L)\n{\n\t//doAddContainerItem(uid, itemid, <optional> count/subtype)\n\tuint32_t uid = getNumber<uint32_t>(L, 1);\n\n\tScriptEnvironment* env = getScriptEnv();\n\tContainer* container = env->getContainerByUID(uid);\n\tif (!container) {\n\t\treportErrorFunc(getErrorDesc(LUA_ERROR_CONTAINER_NOT_FOUND));\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tuint16_t itemId = getNumber<uint16_t>(L, 2);\n\tconst ItemType& it = Item::items[itemId];\n\n\tint32_t itemCount = 1;\n\tint32_t subType = 1;\n\tuint32_t count = getNumber<uint32_t>(L, 3, 1);\n\n\tif (it.hasSubType()) {\n\t\tif (it.stackable) {\n\t\t\titemCount = static_cast<int32_t>(std::ceil(static_cast<float>(count) / 100));\n\t\t}\n\n\t\tsubType = count;\n\t} else {\n\t\titemCount = std::max<int32_t>(1, count);\n\t}\n\n\twhile (itemCount > 0) {\n\t\tint32_t stackCount = std::min<int32_t>(100, subType);\n\t\tItem* newItem = Item::CreateItem(itemId, stackCount);\n\t\tif (!newItem) {\n\t\t\treportErrorFunc(getErrorDesc(LUA_ERROR_ITEM_NOT_FOUND));\n\t\t\tpushBoolean(L, false);\n\t\t\treturn 1;\n\t\t}\n\n\t\tif (it.stackable) {\n\t\t\tsubType -= stackCount;\n\t\t}\n\n\t\tReturnValue ret = g_game.internalAddItem(container, newItem);\n\t\tif (ret != RETURNVALUE_NOERROR) {\n\t\t\tdelete newItem;\n\t\t\tpushBoolean(L, false);\n\t\t\treturn 1;\n\t\t}\n\n\t\tif (--itemCount == 0) {\n\t\t\tif (newItem->getParent()) {\n\t\t\t\tlua_pushnumber(L, env->addThing(newItem));\n\t\t\t} else {\n\t\t\t\t//stackable item stacked with existing object, newItem will be released\n\t\t\t\tpushBoolean(L, false);\n\t\t\t}\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tpushBoolean(L, false);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGetDepotId(lua_State* L)\n{\n\t//getDepotId(uid)\n\tuint32_t uid = getNumber<uint32_t>(L, -1);\n\n\tContainer* container = getScriptEnv()->getContainerByUID(uid);\n\tif (!container) {\n\t\treportErrorFunc(getErrorDesc(LUA_ERROR_CONTAINER_NOT_FOUND));\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tDepotLocker* depotLocker = container->getDepotLocker();\n\tif (!depotLocker) {\n\t\treportErrorFunc(\"Depot not found\");\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tlua_pushnumber(L, depotLocker->getDepotId());\n\treturn 1;\n}\n\nint LuaScriptInterface::luaAddEvent(lua_State* L)\n{\n\t//addEvent(callback, delay, ...)\n\tlua_State* globalState = g_luaEnvironment.getLuaState();\n\tif (!globalState) {\n\t\treportErrorFunc(\"No valid script interface!\");\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t} else if (globalState != L) {\n\t\tlua_xmove(L, globalState, lua_gettop(L));\n\t}\n\n\tint parameters = lua_gettop(globalState);\n\tif (!isFunction(globalState, -parameters)) { //-parameters means the first parameter from left to right\n\t\treportErrorFunc(\"callback parameter should be a function.\");\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tif (g_config.getBoolean(ConfigManager::WARN_UNSAFE_SCRIPTS) || g_config.getBoolean(ConfigManager::CONVERT_UNSAFE_SCRIPTS)) {\n\t\tstd::vector<std::pair<int32_t, LuaDataType>> indexes;\n\t\tfor (int i = 3; i <= parameters; ++i) {\n\t\t\tif (lua_getmetatable(globalState, i) == 0) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tlua_rawgeti(L, -1, 't');\n\n\t\t\tLuaDataType type = getNumber<LuaDataType>(L, -1);\n\t\t\tif (type != LuaData_Unknown && type != LuaData_Tile) {\n\t\t\t\tindexes.push_back({i, type});\n\t\t\t}\n\t\t\tlua_pop(globalState, 2);\n\t\t}\n\n\t\tif (!indexes.empty()) {\n\t\t\tif (g_config.getBoolean(ConfigManager::WARN_UNSAFE_SCRIPTS)) {\n\t\t\t\tbool plural = indexes.size() > 1;\n\n\t\t\t\tstd::string warningString = \"Argument\";\n\t\t\t\tif (plural) {\n\t\t\t\t\twarningString += 's';\n\t\t\t\t}\n\n\t\t\t\tfor (const auto& entry : indexes) {\n\t\t\t\t\tif (entry == indexes.front()) {\n\t\t\t\t\t\twarningString += ' ';\n\t\t\t\t\t} else if (entry == indexes.back()) {\n\t\t\t\t\t\twarningString += \" and \";\n\t\t\t\t\t} else {\n\t\t\t\t\t\twarningString += \", \";\n\t\t\t\t\t}\n\t\t\t\t\twarningString += '#';\n\t\t\t\t\twarningString += std::to_string(entry.first);\n\t\t\t\t}\n\n\t\t\t\tif (plural) {\n\t\t\t\t\twarningString += \" are unsafe\";\n\t\t\t\t} else {\n\t\t\t\t\twarningString += \" is unsafe\";\n\t\t\t\t}\n\n\t\t\t\treportErrorFunc(warningString);\n\t\t\t}\n\n\t\t\tif (g_config.getBoolean(ConfigManager::CONVERT_UNSAFE_SCRIPTS)) {\n\t\t\t\tfor (const auto& entry : indexes) {\n\t\t\t\t\tswitch (entry.second) {\n\t\t\t\t\t\tcase LuaData_Item:\n\t\t\t\t\t\tcase LuaData_Container:\n\t\t\t\t\t\tcase LuaData_Teleport: {\n\t\t\t\t\t\t\tlua_getglobal(globalState, \"Item\");\n\t\t\t\t\t\t\tlua_getfield(globalState, -1, \"getUniqueId\");\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcase LuaData_Player:\n\t\t\t\t\t\tcase LuaData_Monster:\n\t\t\t\t\t\tcase LuaData_Npc: {\n\t\t\t\t\t\t\tlua_getglobal(globalState, \"Creature\");\n\t\t\t\t\t\t\tlua_getfield(globalState, -1, \"getId\");\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tlua_replace(globalState, -2);\n\t\t\t\t\tlua_pushvalue(globalState, entry.first);\n\t\t\t\t\tlua_call(globalState, 1, 1);\n\t\t\t\t\tlua_replace(globalState, entry.first);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tLuaTimerEventDesc eventDesc;\n\tfor (int i = 0; i < parameters - 2; ++i) { //-2 because addEvent needs at least two parameters\n\t\teventDesc.parameters.push_back(luaL_ref(globalState, LUA_REGISTRYINDEX));\n\t}\n\n\tuint32_t delay = std::max<uint32_t>(100, getNumber<uint32_t>(globalState, 2));\n\tlua_pop(globalState, 1);\n\n\teventDesc.function = luaL_ref(globalState, LUA_REGISTRYINDEX);\n\teventDesc.scriptId = getScriptEnv()->getScriptId();\n\n\tauto& lastTimerEventId = g_luaEnvironment.lastEventTimerId;\n\teventDesc.eventId = g_scheduler.addEvent(createSchedulerTask(\n\t\tdelay, std::bind(&LuaEnvironment::executeTimerEvent, &g_luaEnvironment, lastTimerEventId)\n\t));\n\n\tg_luaEnvironment.timerEvents.emplace(lastTimerEventId, std::move(eventDesc));\n\tlua_pushnumber(L, lastTimerEventId++);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaStopEvent(lua_State* L)\n{\n\t//stopEvent(eventid)\n\tlua_State* globalState = g_luaEnvironment.getLuaState();\n\tif (!globalState) {\n\t\treportErrorFunc(\"No valid script interface!\");\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tuint32_t eventId = getNumber<uint32_t>(L, 1);\n\n\tauto& timerEvents = g_luaEnvironment.timerEvents;\n\tauto it = timerEvents.find(eventId);\n\tif (it == timerEvents.end()) {\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tLuaTimerEventDesc timerEventDesc = std::move(it->second);\n\ttimerEvents.erase(it);\n\n\tg_scheduler.stopEvent(timerEventDesc.eventId);\n\tluaL_unref(globalState, LUA_REGISTRYINDEX, timerEventDesc.function);\n\n\tfor (auto parameter : timerEventDesc.parameters) {\n\t\tluaL_unref(globalState, LUA_REGISTRYINDEX, parameter);\n\t}\n\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaSaveServer(lua_State* L)\n{\n\tg_game.saveGameState();\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCleanMap(lua_State* L)\n{\n\tlua_pushnumber(L, g_game.map.clean());\n\treturn 1;\n}\n\nint LuaScriptInterface::luaIsInWar(lua_State* L)\n{\n\t//isInWar(cid, target)\n\tPlayer* player = getPlayer(L, 1);\n\tif (!player) {\n\t\treportErrorFunc(getErrorDesc(LUA_ERROR_PLAYER_NOT_FOUND));\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tPlayer* targetPlayer = getPlayer(L, 2);\n\tif (!targetPlayer) {\n\t\treportErrorFunc(getErrorDesc(LUA_ERROR_PLAYER_NOT_FOUND));\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tpushBoolean(L, player->isInWar(targetPlayer));\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGetWaypointPositionByName(lua_State* L)\n{\n\t//getWaypointPositionByName(name)\n\tauto& waypoints = g_game.map.waypoints;\n\n\tauto it = waypoints.find(getString(L, -1));\n\tif (it != waypoints.end()) {\n\t\tpushPosition(L, it->second);\n\t} else {\n\t\tpushBoolean(L, false);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaSendChannelMessage(lua_State* L)\n{\n\t//sendChannelMessage(channelId, type, message)\n\tuint32_t channelId = getNumber<uint32_t>(L, 1);\n\tChatChannel* channel = g_chat->getChannelById(channelId);\n\tif (!channel) {\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tSpeakClasses type = getNumber<SpeakClasses>(L, 2);\n\tstd::string message = getString(L, 3);\n\tchannel->sendToAll(message, type);\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaSendGuildChannelMessage(lua_State* L)\n{\n\t//sendGuildChannelMessage(guildId, type, message)\n\tuint32_t guildId = getNumber<uint32_t>(L, 1);\n\tChatChannel* channel = g_chat->getGuildChannelById(guildId);\n\tif (!channel) {\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tSpeakClasses type = getNumber<SpeakClasses>(L, 2);\n\tstd::string message = getString(L, 3);\n\tchannel->sendToAll(message, type);\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaIsScriptsInterface(lua_State* L)\n{\n\t//isScriptsInterface()\n\tif (getScriptEnv()->getScriptInterface() == &g_scripts->getScriptInterface()) {\n\t\tpushBoolean(L, true);\n\t} else {\n\t\treportErrorFunc(\"EventCallback: can only be called inside (data/scripts/)\");\n\t\tpushBoolean(L, false);\n\t}\n\treturn 1;\n}\n\nstd::string LuaScriptInterface::escapeString(const std::string& string)\n{\n\tstd::string s = string;\n\treplaceString(s, \"\\\\\", \"\\\\\\\\\");\n\treplaceString(s, \"\\\"\", \"\\\\\\\"\");\n\treplaceString(s, \"'\", \"\\\\'\");\n\treplaceString(s, \"[[\", \"\\\\[[\");\n\treturn s;\n}\n\n#ifndef LUAJIT_VERSION\nconst luaL_Reg LuaScriptInterface::luaBitReg[] = {\n\t//{\"tobit\", LuaScriptInterface::luaBitToBit},\n\t{\"bnot\", LuaScriptInterface::luaBitNot},\n\t{\"band\", LuaScriptInterface::luaBitAnd},\n\t{\"bor\", LuaScriptInterface::luaBitOr},\n\t{\"bxor\", LuaScriptInterface::luaBitXor},\n\t{\"lshift\", LuaScriptInterface::luaBitLeftShift},\n\t{\"rshift\", LuaScriptInterface::luaBitRightShift},\n\t//{\"arshift\", LuaScriptInterface::luaBitArithmeticalRightShift},\n\t//{\"rol\", LuaScriptInterface::luaBitRotateLeft},\n\t//{\"ror\", LuaScriptInterface::luaBitRotateRight},\n\t//{\"bswap\", LuaScriptInterface::luaBitSwapEndian},\n\t//{\"tohex\", LuaScriptInterface::luaBitToHex},\n\t{nullptr, nullptr}\n};\n\nint LuaScriptInterface::luaBitNot(lua_State* L)\n{\n\tlua_pushnumber(L, ~getNumber<uint32_t>(L, -1));\n\treturn 1;\n}\n\n#define MULTIOP(name, op) \\\nint LuaScriptInterface::luaBit##name(lua_State* L) \\\n{ \\\n\tint n = lua_gettop(L); \\\n\tuint32_t w = getNumber<uint32_t>(L, -1); \\\n\tfor (int i = 1; i < n; ++i) \\\n\t\tw op getNumber<uint32_t>(L, i); \\\n\tlua_pushnumber(L, w); \\\n\treturn 1; \\\n}\n\nMULTIOP(And, &= )\nMULTIOP(Or, |= )\nMULTIOP(Xor, ^= )\n\n#define SHIFTOP(name, op) \\\nint LuaScriptInterface::luaBit##name(lua_State* L) \\\n{ \\\n\tuint32_t n1 = getNumber<uint32_t>(L, 1), n2 = getNumber<uint32_t>(L, 2); \\\n\tlua_pushnumber(L, (n1 op n2)); \\\n\treturn 1; \\\n}\n\nSHIFTOP(LeftShift, << )\nSHIFTOP(RightShift, >> )\n#endif\n\nconst luaL_Reg LuaScriptInterface::luaConfigManagerTable[] = {\n\t{\"getString\", LuaScriptInterface::luaConfigManagerGetString},\n\t{\"getNumber\", LuaScriptInterface::luaConfigManagerGetNumber},\n\t{\"getBoolean\", LuaScriptInterface::luaConfigManagerGetBoolean},\n\t{nullptr, nullptr}\n};\n\nint LuaScriptInterface::luaConfigManagerGetString(lua_State* L)\n{\n\tpushString(L, g_config.getString(getNumber<ConfigManager::string_config_t>(L, -1)));\n\treturn 1;\n}\n\nint LuaScriptInterface::luaConfigManagerGetNumber(lua_State* L)\n{\n\tlua_pushnumber(L, g_config.getNumber(getNumber<ConfigManager::integer_config_t>(L, -1)));\n\treturn 1;\n}\n\nint LuaScriptInterface::luaConfigManagerGetBoolean(lua_State* L)\n{\n\tpushBoolean(L, g_config.getBoolean(getNumber<ConfigManager::boolean_config_t>(L, -1)));\n\treturn 1;\n}\n\nconst luaL_Reg LuaScriptInterface::luaDatabaseTable[] = {\n\t{\"query\", LuaScriptInterface::luaDatabaseExecute},\n\t{\"asyncQuery\", LuaScriptInterface::luaDatabaseAsyncExecute},\n\t{\"storeQuery\", LuaScriptInterface::luaDatabaseStoreQuery},\n\t{\"asyncStoreQuery\", LuaScriptInterface::luaDatabaseAsyncStoreQuery},\n\t{\"escapeString\", LuaScriptInterface::luaDatabaseEscapeString},\n\t{\"escapeBlob\", LuaScriptInterface::luaDatabaseEscapeBlob},\n\t{\"lastInsertId\", LuaScriptInterface::luaDatabaseLastInsertId},\n\t{\"tableExists\", LuaScriptInterface::luaDatabaseTableExists},\n\t{nullptr, nullptr}\n};\n\nint LuaScriptInterface::luaDatabaseExecute(lua_State* L)\n{\n\tpushBoolean(L, Database::getInstance().executeQuery(getString(L, -1)));\n\treturn 1;\n}\n\nint LuaScriptInterface::luaDatabaseAsyncExecute(lua_State* L)\n{\n\tstd::function<void(DBResult_ptr, bool)> callback;\n\tif (lua_gettop(L) > 1) {\n\t\tint32_t ref = luaL_ref(L, LUA_REGISTRYINDEX);\n\t\tauto scriptId = getScriptEnv()->getScriptId();\n\t\tcallback = [ref, scriptId](DBResult_ptr, bool success) {\n\t\t\tlua_State* luaState = g_luaEnvironment.getLuaState();\n\t\t\tif (!luaState) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tif (!LuaScriptInterface::reserveScriptEnv()) {\n\t\t\t\tluaL_unref(luaState, LUA_REGISTRYINDEX, ref);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tlua_rawgeti(luaState, LUA_REGISTRYINDEX, ref);\n\t\t\tpushBoolean(luaState, success);\n\t\t\tauto env = getScriptEnv();\n\t\t\tenv->setScriptId(scriptId, &g_luaEnvironment);\n\t\t\tg_luaEnvironment.callFunction(1);\n\n\t\t\tluaL_unref(luaState, LUA_REGISTRYINDEX, ref);\n\t\t};\n\t}\n\tg_databaseTasks.addTask(getString(L, -1), callback);\n\treturn 0;\n}\n\nint LuaScriptInterface::luaDatabaseStoreQuery(lua_State* L)\n{\n\tif (DBResult_ptr res = Database::getInstance().storeQuery(getString(L, -1))) {\n\t\tlua_pushnumber(L, ScriptEnvironment::addResult(res));\n\t} else {\n\t\tpushBoolean(L, false);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaDatabaseAsyncStoreQuery(lua_State* L)\n{\n\tstd::function<void(DBResult_ptr, bool)> callback;\n\tif (lua_gettop(L) > 1) {\n\t\tint32_t ref = luaL_ref(L, LUA_REGISTRYINDEX);\n\t\tauto scriptId = getScriptEnv()->getScriptId();\n\t\tcallback = [ref, scriptId](DBResult_ptr result, bool) {\n\t\t\tlua_State* luaState = g_luaEnvironment.getLuaState();\n\t\t\tif (!luaState) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tif (!LuaScriptInterface::reserveScriptEnv()) {\n\t\t\t\tluaL_unref(luaState, LUA_REGISTRYINDEX, ref);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tlua_rawgeti(luaState, LUA_REGISTRYINDEX, ref);\n\t\t\tif (result) {\n\t\t\t\tlua_pushnumber(luaState, ScriptEnvironment::addResult(result));\n\t\t\t} else {\n\t\t\t\tpushBoolean(luaState, false);\n\t\t\t}\n\t\t\tauto env = getScriptEnv();\n\t\t\tenv->setScriptId(scriptId, &g_luaEnvironment);\n\t\t\tg_luaEnvironment.callFunction(1);\n\n\t\t\tluaL_unref(luaState, LUA_REGISTRYINDEX, ref);\n\t\t};\n\t}\n\tg_databaseTasks.addTask(getString(L, -1), callback, true);\n\treturn 0;\n}\n\nint LuaScriptInterface::luaDatabaseEscapeString(lua_State* L)\n{\n\tpushString(L, Database::getInstance().escapeString(getString(L, -1)));\n\treturn 1;\n}\n\nint LuaScriptInterface::luaDatabaseEscapeBlob(lua_State* L)\n{\n\tuint32_t length = getNumber<uint32_t>(L, 2);\n\tpushString(L, Database::getInstance().escapeBlob(getString(L, 1).c_str(), length));\n\treturn 1;\n}\n\nint LuaScriptInterface::luaDatabaseLastInsertId(lua_State* L)\n{\n\tlua_pushnumber(L, Database::getInstance().getLastInsertId());\n\treturn 1;\n}\n\nint LuaScriptInterface::luaDatabaseTableExists(lua_State* L)\n{\n\tpushBoolean(L, DatabaseManager::tableExists(getString(L, -1)));\n\treturn 1;\n}\n\nconst luaL_Reg LuaScriptInterface::luaResultTable[] = {\n\t{\"getNumber\", LuaScriptInterface::luaResultGetNumber},\n\t{\"getString\", LuaScriptInterface::luaResultGetString},\n\t{\"getStream\", LuaScriptInterface::luaResultGetStream},\n\t{\"next\", LuaScriptInterface::luaResultNext},\n\t{\"free\", LuaScriptInterface::luaResultFree},\n\t{nullptr, nullptr}\n};\n\nint LuaScriptInterface::luaResultGetNumber(lua_State* L)\n{\n\tDBResult_ptr res = ScriptEnvironment::getResultByID(getNumber<uint32_t>(L, 1));\n\tif (!res) {\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tconst std::string& s = getString(L, 2);\n\tlua_pushnumber(L, res->getNumber<int64_t>(s));\n\treturn 1;\n}\n\nint LuaScriptInterface::luaResultGetString(lua_State* L)\n{\n\tDBResult_ptr res = ScriptEnvironment::getResultByID(getNumber<uint32_t>(L, 1));\n\tif (!res) {\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tconst std::string& s = getString(L, 2);\n\tpushString(L, res->getString(s));\n\treturn 1;\n}\n\nint LuaScriptInterface::luaResultGetStream(lua_State* L)\n{\n\tDBResult_ptr res = ScriptEnvironment::getResultByID(getNumber<uint32_t>(L, 1));\n\tif (!res) {\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tunsigned long length;\n\tconst char* stream = res->getStream(getString(L, 2), length);\n\tlua_pushlstring(L, stream, length);\n\tlua_pushnumber(L, length);\n\treturn 2;\n}\n\nint LuaScriptInterface::luaResultNext(lua_State* L)\n{\n\tDBResult_ptr res = ScriptEnvironment::getResultByID(getNumber<uint32_t>(L, -1));\n\tif (!res) {\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tpushBoolean(L, res->next());\n\treturn 1;\n}\n\nint LuaScriptInterface::luaResultFree(lua_State* L)\n{\n\tpushBoolean(L, ScriptEnvironment::removeResult(getNumber<uint32_t>(L, -1)));\n\treturn 1;\n}\n\n// Userdata\nint LuaScriptInterface::luaUserdataCompare(lua_State* L)\n{\n\t// userdataA == userdataB\n\tpushBoolean(L, getUserdata<void>(L, 1) == getUserdata<void>(L, 2));\n\treturn 1;\n}\n\n// _G\nint LuaScriptInterface::luaIsType(lua_State* L)\n{\n\t// isType(derived, base)\n\tlua_getmetatable(L, -2);\n\tlua_getmetatable(L, -2);\n\n\tlua_rawgeti(L, -2, 'p');\n\tuint_fast8_t parentsB = getNumber<uint_fast8_t>(L, 1);\n\n\tlua_rawgeti(L, -3, 'h');\n\tsize_t hashB = getNumber<size_t>(L, 1);\n\n\tlua_rawgeti(L, -3, 'p');\n\tuint_fast8_t parentsA = getNumber<uint_fast8_t>(L, 1);\n\tfor (uint_fast8_t i = parentsA; i < parentsB; ++i) {\n\t\tlua_getfield(L, -3, \"__index\");\n\t\tlua_replace(L, -4);\n\t}\n\n\tlua_rawgeti(L, -4, 'h');\n\tsize_t hashA = getNumber<size_t>(L, 1);\n\n\tpushBoolean(L, hashA == hashB);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaRawGetMetatable(lua_State* L)\n{\n\t// rawgetmetatable(metatableName)\n\tluaL_getmetatable(L, getString(L, 1).c_str());\n\treturn 1;\n}\n\n// os\nint LuaScriptInterface::luaSystemTime(lua_State* L)\n{\n\t// os.mtime()\n\tlua_pushnumber(L, OTSYS_TIME());\n\treturn 1;\n}\n\n// table\nint LuaScriptInterface::luaTableCreate(lua_State* L)\n{\n\t// table.create(arrayLength, keyLength)\n\tlua_createtable(L, getNumber<int32_t>(L, 1), getNumber<int32_t>(L, 2));\n\treturn 1;\n}\n\n// Game\nint LuaScriptInterface::luaGameGetSpectators(lua_State* L)\n{\n\t// Game.getSpectators(position[, multifloor = false[, onlyPlayer = false[, minRangeX = 0[, maxRangeX = 0[, minRangeY = 0[, maxRangeY = 0]]]]]])\n\tconst Position& position = getPosition(L, 1);\n\tbool multifloor = getBoolean(L, 2, false);\n\tbool onlyPlayers = getBoolean(L, 3, false);\n\tint32_t minRangeX = getNumber<int32_t>(L, 4, 0);\n\tint32_t maxRangeX = getNumber<int32_t>(L, 5, 0);\n\tint32_t minRangeY = getNumber<int32_t>(L, 6, 0);\n\tint32_t maxRangeY = getNumber<int32_t>(L, 7, 0);\n\n\tSpectatorVec spectators;\n\tg_game.map.getSpectators(spectators, position, multifloor, onlyPlayers, minRangeX, maxRangeX, minRangeY, maxRangeY);\n\n\tlua_createtable(L, spectators.size(), 0);\n\n\tint index = 0;\n\tfor (Creature* creature : spectators) {\n\t\tpushUserdata<Creature>(L, creature);\n\t\tsetCreatureMetatable(L, -1, creature);\n\t\tlua_rawseti(L, -2, ++index);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGameGetPlayers(lua_State* L)\n{\n\t// Game.getPlayers()\n\tlua_createtable(L, g_game.getPlayersOnline(), 0);\n\n\tint index = 0;\n\tfor (const auto& playerEntry : g_game.getPlayers()) {\n\t\tpushUserdata<Player>(L, playerEntry.second);\n\t\tsetMetatable(L, -1, \"Player\");\n\t\tlua_rawseti(L, -2, ++index);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGameLoadMap(lua_State* L)\n{\n\t// Game.loadMap(path)\n\tconst std::string& path = getString(L, 1);\n\tg_dispatcher.addTask(createTask([path]() {\n\t\ttry {\n\t\t\tg_game.loadMap(path);\n\t\t} catch (const std::exception& e) {\n\t\t\t// FIXME: Should only catch some exceptions\n\t\t\tstd::cout << \"[Error - LuaScriptInterface::luaGameLoadMap] Failed to load map: \"\n\t\t\t\t<< e.what() << std::endl;\n\t\t}\n\t}));\n\treturn 0;\n}\n\nint LuaScriptInterface::luaGameGetExperienceStage(lua_State* L)\n{\n\t// Game.getExperienceStage(level)\n\tuint32_t level = getNumber<uint32_t>(L, 1);\n\tlua_pushnumber(L, g_game.getExperienceStage(level));\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGameGetMonsterCount(lua_State* L)\n{\n\t// Game.getMonsterCount()\n\tlua_pushnumber(L, g_game.getMonstersOnline());\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGameGetPlayerCount(lua_State* L)\n{\n\t// Game.getPlayerCount()\n\tlua_pushnumber(L, g_game.getPlayersOnline());\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGameGetNpcCount(lua_State* L)\n{\n\t// Game.getNpcCount()\n\tlua_pushnumber(L, g_game.getNpcsOnline());\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGameGetMonsterTypes(lua_State* L)\n{\n\t// Game.getMonsterTypes()\n\tauto& type = g_monsters.monsters;\n\tlua_createtable(L, type.size(), 0);\n\n\tfor (auto& mType : type) {\n\t\tpushUserdata<MonsterType>(L, &mType.second);\n\t\tsetMetatable(L, -1, \"MonsterType\");\n\t\tlua_setfield(L, -2, mType.first.c_str());\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGameGetTowns(lua_State* L)\n{\n\t// Game.getTowns()\n\tconst auto& towns = g_game.map.towns.getTowns();\n\tlua_createtable(L, towns.size(), 0);\n\n\tint index = 0;\n\tfor (auto townEntry : towns) {\n\t\tpushUserdata<Town>(L, townEntry.second);\n\t\tsetMetatable(L, -1, \"Town\");\n\t\tlua_rawseti(L, -2, ++index);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGameGetHouses(lua_State* L)\n{\n\t// Game.getHouses()\n\tconst auto& houses = g_game.map.houses.getHouses();\n\tlua_createtable(L, houses.size(), 0);\n\n\tint index = 0;\n\tfor (auto houseEntry : houses) {\n\t\tpushUserdata<House>(L, houseEntry.second);\n\t\tsetMetatable(L, -1, \"House\");\n\t\tlua_rawseti(L, -2, ++index);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGameGetGameState(lua_State* L)\n{\n\t// Game.getGameState()\n\tlua_pushnumber(L, g_game.getGameState());\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGameSetGameState(lua_State* L)\n{\n\t// Game.setGameState(state)\n\tGameState_t state = getNumber<GameState_t>(L, 1);\n\tg_game.setGameState(state);\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGameGetWorldType(lua_State* L)\n{\n\t// Game.getWorldType()\n\tlua_pushnumber(L, g_game.getWorldType());\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGameSetWorldType(lua_State* L)\n{\n\t// Game.setWorldType(type)\n\tWorldType_t type = getNumber<WorldType_t>(L, 1);\n\tg_game.setWorldType(type);\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGameGetReturnMessage(lua_State* L)\n{\n\t// Game.getReturnMessage(value)\n\tReturnValue value = getNumber<ReturnValue>(L, 1);\n\tpushString(L, getReturnMessage(value));\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGameCreateItem(lua_State* L)\n{\n\t// Game.createItem(itemId[, count[, position]])\n\tuint16_t count = getNumber<uint16_t>(L, 2, 1);\n\tuint16_t id;\n\tif (isNumber(L, 1)) {\n\t\tid = getNumber<uint16_t>(L, 1);\n\t} else {\n\t\tid = Item::items.getItemIdByName(getString(L, 1));\n\t\tif (id == 0) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tconst ItemType& it = Item::items[id];\n\tif (it.stackable) {\n\t\tcount = std::min<uint16_t>(count, 100);\n\t}\n\n\tItem* item = Item::CreateItem(id, count);\n\tif (!item) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tif (lua_gettop(L) >= 3) {\n\t\tconst Position& position = getPosition(L, 3);\n\t\tTile* tile = g_game.map.getTile(position);\n\t\tif (!tile) {\n\t\t\tdelete item;\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\n\t\tg_game.internalAddItem(tile, item, INDEX_WHEREEVER, FLAG_NOLIMIT);\n\t} else {\n\t\tgetScriptEnv()->addTempItem(item);\n\t\titem->setParent(VirtualCylinder::virtualCylinder);\n\t}\n\n\tpushUserdata<Item>(L, item);\n\tsetItemMetatable(L, -1, item);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGameCreateContainer(lua_State* L)\n{\n\t// Game.createContainer(itemId, size[, position])\n\tuint16_t size = getNumber<uint16_t>(L, 2);\n\tuint16_t id;\n\tif (isNumber(L, 1)) {\n\t\tid = getNumber<uint16_t>(L, 1);\n\t} else {\n\t\tid = Item::items.getItemIdByName(getString(L, 1));\n\t\tif (id == 0) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tContainer* container = Item::CreateItemAsContainer(id, size);\n\tif (!container) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tif (lua_gettop(L) >= 3) {\n\t\tconst Position& position = getPosition(L, 3);\n\t\tTile* tile = g_game.map.getTile(position);\n\t\tif (!tile) {\n\t\t\tdelete container;\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\n\t\tg_game.internalAddItem(tile, container, INDEX_WHEREEVER, FLAG_NOLIMIT);\n\t} else {\n\t\tgetScriptEnv()->addTempItem(container);\n\t\tcontainer->setParent(VirtualCylinder::virtualCylinder);\n\t}\n\n\tpushUserdata<Container>(L, container);\n\tsetMetatable(L, -1, \"Container\");\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGameCreateMonster(lua_State* L)\n{\n\t// Game.createMonster(monsterName, position[, extended = false[, force = false]])\n\tMonster* monster = Monster::createMonster(getString(L, 1));\n\tif (!monster) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tconst Position& position = getPosition(L, 2);\n\tbool extended = getBoolean(L, 3, false);\n\tbool force = getBoolean(L, 4, false);\n\tif (g_events->eventMonsterOnSpawn(monster, position, false, true) || force) {\n\t\tif (g_game.placeCreature(monster, position, extended, force)) {\n\t\t\tpushUserdata<Monster>(L, monster);\n\t\t\tsetMetatable(L, -1, \"Monster\");\n\t\t} else {\n\t\t\tdelete monster;\n\t\t\tlua_pushnil(L);\n\t\t}\n\t} else {\n\t\tdelete monster;\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGameCreateNpc(lua_State* L)\n{\n\t// Game.createNpc(npcName, position[, extended = false[, force = false]])\n\tNpc* npc = Npc::createNpc(getString(L, 1));\n\tif (!npc) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tconst Position& position = getPosition(L, 2);\n\tbool extended = getBoolean(L, 3, false);\n\tbool force = getBoolean(L, 4, false);\n\tif (g_game.placeCreature(npc, position, extended, force)) {\n\t\tpushUserdata<Npc>(L, npc);\n\t\tsetMetatable(L, -1, \"Npc\");\n\t} else {\n\t\tdelete npc;\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGameCreateTile(lua_State* L)\n{\n\t// Game.createTile(x, y, z[, isDynamic = false])\n\t// Game.createTile(position[, isDynamic = false])\n\tPosition position;\n\tbool isDynamic;\n\tif (isTable(L, 1)) {\n\t\tposition = getPosition(L, 1);\n\t\tisDynamic = getBoolean(L, 2, false);\n\t} else {\n\t\tposition.x = getNumber<uint16_t>(L, 1);\n\t\tposition.y = getNumber<uint16_t>(L, 2);\n\t\tposition.z = getNumber<uint16_t>(L, 3);\n\t\tisDynamic = getBoolean(L, 4, false);\n\t}\n\n\tTile* tile = g_game.map.getTile(position);\n\tif (!tile) {\n\t\tif (isDynamic) {\n\t\t\ttile = new DynamicTile(position.x, position.y, position.z);\n\t\t} else {\n\t\t\ttile = new StaticTile(position.x, position.y, position.z);\n\t\t}\n\n\t\tg_game.map.setTile(position, tile);\n\t}\n\n\tpushUserdata(L, tile);\n\tsetMetatable(L, -1, \"Tile\");\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGameCreateMonsterType(lua_State* L)\n{\n\t// Game.createMonsterType(name)\n\tif (getScriptEnv()->getScriptInterface() != &g_scripts->getScriptInterface()) {\n\t\treportErrorFunc(\"MonsterTypes can only be registered in the Scripts interface.\");\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tconst std::string& name = getString(L, 1);\n\tif (name.length() == 0) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tMonsterType* monsterType = g_monsters.getMonsterType(name, false);\n\tif (!monsterType) {\n\t\tmonsterType = &g_monsters.monsters[asLowerCaseString(name)];\n\t\tmonsterType->name = name;\n\t\tmonsterType->nameDescription = \"a \" + name;\n\t} else {\n\t\tmonsterType->info.lootItems.clear();\n\t\tmonsterType->info.attackSpells.clear();\n\t\tmonsterType->info.defenseSpells.clear();\n\t}\n\n\tpushUserdata<MonsterType>(L, monsterType);\n\tsetMetatable(L, -1, \"MonsterType\");\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGameStartRaid(lua_State* L)\n{\n\t// Game.startRaid(raidName)\n\tconst std::string& raidName = getString(L, 1);\n\n\tRaid* raid = g_game.raids.getRaidByName(raidName);\n\tif (!raid || !raid->isLoaded()) {\n\t\tlua_pushnumber(L, RETURNVALUE_NOSUCHRAIDEXISTS);\n\t\treturn 1;\n\t}\n\n\tif (g_game.raids.getRunning()) {\n\t\tlua_pushnumber(L, RETURNVALUE_ANOTHERRAIDISALREADYEXECUTING);\n\t\treturn 1;\n\t}\n\n\tg_game.raids.setRunning(raid);\n\traid->startRaid();\n\tlua_pushnumber(L, RETURNVALUE_NOERROR);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGameGetClientVersion(lua_State* L)\n{\n\t// Game.getClientVersion()\n\tlua_createtable(L, 0, 3);\n\tsetField(L, \"min\", CLIENT_VERSION_MIN);\n\tsetField(L, \"max\", CLIENT_VERSION_MAX);\n\tsetField(L, \"string\", CLIENT_VERSION_STR);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGameReload(lua_State* L)\n{\n\t// Game.reload(reloadType)\n\tReloadTypes_t reloadType = getNumber<ReloadTypes_t>(L, 1);\n\tif (reloadType == RELOAD_TYPE_GLOBAL) {\n\t\tpushBoolean(L, g_luaEnvironment.loadFile(\"data/global.lua\") == 0);\n\t\tpushBoolean(L, g_scripts->loadScripts(\"scripts/lib\", true, true));\n\t} else {\n\t\tpushBoolean(L, g_game.reload(reloadType));\n\t}\n\tlua_gc(g_luaEnvironment.getLuaState(), LUA_GCCOLLECT, 0);\n\treturn 1;\n}\n\n// Variant\nint LuaScriptInterface::luaVariantCreate(lua_State* L)\n{\n\t// Variant(number or string or position or thing)\n\tLuaVariant variant;\n\tif (isUserdata(L, 2)) {\n\t\tif (Thing* thing = getThing(L, 2)) {\n\t\t\tvariant.type = VARIANT_TARGETPOSITION;\n\t\t\tvariant.pos = thing->getPosition();\n\t\t}\n\t} else if (isTable(L, 2)) {\n\t\tvariant.type = VARIANT_POSITION;\n\t\tvariant.pos = getPosition(L, 2);\n\t} else if (isNumber(L, 2)) {\n\t\tvariant.type = VARIANT_NUMBER;\n\t\tvariant.number = getNumber<uint32_t>(L, 2);\n\t} else if (isString(L, 2)) {\n\t\tvariant.type = VARIANT_STRING;\n\t\tvariant.text = getString(L, 2);\n\t}\n\tpushVariant(L, variant);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaVariantGetNumber(lua_State* L)\n{\n\t// Variant:getNumber()\n\tconst LuaVariant& variant = getVariant(L, 1);\n\tif (variant.type == VARIANT_NUMBER) {\n\t\tlua_pushnumber(L, variant.number);\n\t} else {\n\t\tlua_pushnumber(L, 0);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaVariantGetString(lua_State* L)\n{\n\t// Variant:getString()\n\tconst LuaVariant& variant = getVariant(L, 1);\n\tif (variant.type == VARIANT_STRING) {\n\t\tpushString(L, variant.text);\n\t} else {\n\t\tpushString(L, std::string());\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaVariantGetPosition(lua_State* L)\n{\n\t// Variant:getPosition()\n\tconst LuaVariant& variant = getVariant(L, 1);\n\tif (variant.type == VARIANT_POSITION || variant.type == VARIANT_TARGETPOSITION) {\n\t\tpushPosition(L, variant.pos);\n\t} else {\n\t\tpushPosition(L, Position());\n\t}\n\treturn 1;\n}\n\n// Position\nint LuaScriptInterface::luaPositionCreate(lua_State* L)\n{\n\t// Position([x = 0[, y = 0[, z = 0[, stackpos = 0]]]])\n\t// Position([position])\n\tif (lua_gettop(L) <= 1) {\n\t\tpushPosition(L, Position());\n\t\treturn 1;\n\t}\n\n\tint32_t stackpos;\n\tif (isTable(L, 2)) {\n\t\tconst Position& position = getPosition(L, 2, stackpos);\n\t\tpushPosition(L, position, stackpos);\n\t} else {\n\t\tuint16_t x = getNumber<uint16_t>(L, 2, 0);\n\t\tuint16_t y = getNumber<uint16_t>(L, 3, 0);\n\t\tuint8_t z = getNumber<uint8_t>(L, 4, 0);\n\t\tstackpos = getNumber<int32_t>(L, 5, 0);\n\n\t\tpushPosition(L, Position(x, y, z), stackpos);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPositionAdd(lua_State* L)\n{\n\t// positionValue = position + positionEx\n\tint32_t stackpos;\n\tconst Position& position = getPosition(L, 1, stackpos);\n\n\tPosition positionEx;\n\tif (stackpos == 0) {\n\t\tpositionEx = getPosition(L, 2, stackpos);\n\t} else {\n\t\tpositionEx = getPosition(L, 2);\n\t}\n\n\tpushPosition(L, position + positionEx, stackpos);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPositionSub(lua_State* L)\n{\n\t// positionValue = position - positionEx\n\tint32_t stackpos;\n\tconst Position& position = getPosition(L, 1, stackpos);\n\n\tPosition positionEx;\n\tif (stackpos == 0) {\n\t\tpositionEx = getPosition(L, 2, stackpos);\n\t} else {\n\t\tpositionEx = getPosition(L, 2);\n\t}\n\n\tpushPosition(L, position - positionEx, stackpos);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPositionCompare(lua_State* L)\n{\n\t// position == positionEx\n\tconst Position& positionEx = getPosition(L, 2);\n\tconst Position& position = getPosition(L, 1);\n\tpushBoolean(L, position == positionEx);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPositionGetDistance(lua_State* L)\n{\n\t// position:getDistance(positionEx)\n\tconst Position& positionEx = getPosition(L, 2);\n\tconst Position& position = getPosition(L, 1);\n\tlua_pushnumber(L, std::max<int32_t>(\n\t\tstd::max<int32_t>(\n\t\t\tstd::abs(Position::getDistanceX(position, positionEx)),\n\t\t\tstd::abs(Position::getDistanceY(position, positionEx))\n\t\t),\n\t\tstd::abs(Position::getDistanceZ(position, positionEx))\n\t));\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPositionIsSightClear(lua_State* L)\n{\n\t// position:isSightClear(positionEx[, sameFloor = true])\n\tbool sameFloor = getBoolean(L, 3, true);\n\tconst Position& positionEx = getPosition(L, 2);\n\tconst Position& position = getPosition(L, 1);\n\tpushBoolean(L, g_game.isSightClear(position, positionEx, sameFloor));\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPositionSendMagicEffect(lua_State* L)\n{\n\t// position:sendMagicEffect(magicEffect[, player = nullptr])\n\tSpectatorVec spectators;\n\tif (lua_gettop(L) >= 3) {\n\t\tPlayer* player = getPlayer(L, 3);\n\t\tif (player) {\n\t\t\tspectators.emplace_back(player);\n\t\t}\n\t}\n\n\tMagicEffectClasses magicEffect = getNumber<MagicEffectClasses>(L, 2);\n\tconst Position& position = getPosition(L, 1);\n\tif (!spectators.empty()) {\n\t\tGame::addMagicEffect(spectators, position, magicEffect);\n\t} else {\n\t\tg_game.addMagicEffect(position, magicEffect);\n\t}\n\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPositionSendDistanceEffect(lua_State* L)\n{\n\t// position:sendDistanceEffect(positionEx, distanceEffect[, player = nullptr])\n\tSpectatorVec spectators;\n\tif (lua_gettop(L) >= 4) {\n\t\tPlayer* player = getPlayer(L, 4);\n\t\tif (player) {\n\t\t\tspectators.emplace_back(player);\n\t\t}\n\t}\n\n\tShootType_t distanceEffect = getNumber<ShootType_t>(L, 3);\n\tconst Position& positionEx = getPosition(L, 2);\n\tconst Position& position = getPosition(L, 1);\n\tif (!spectators.empty()) {\n\t\tGame::addDistanceEffect(spectators, position, positionEx, distanceEffect);\n\t} else {\n\t\tg_game.addDistanceEffect(position, positionEx, distanceEffect);\n\t}\n\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\n// Tile\nint LuaScriptInterface::luaTileCreate(lua_State* L)\n{\n\t// Tile(x, y, z)\n\t// Tile(position)\n\tTile* tile;\n\tif (isTable(L, 2)) {\n\t\ttile = g_game.map.getTile(getPosition(L, 2));\n\t} else {\n\t\tuint8_t z = getNumber<uint8_t>(L, 4);\n\t\tuint16_t y = getNumber<uint16_t>(L, 3);\n\t\tuint16_t x = getNumber<uint16_t>(L, 2);\n\t\ttile = g_game.map.getTile(x, y, z);\n\t}\n\n\tif (tile) {\n\t\tpushUserdata<Tile>(L, tile);\n\t\tsetMetatable(L, -1, \"Tile\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTileRemove(lua_State* L)\n{\n\t// tile:remove()\n\tTile* tile = getUserdata<Tile>(L, 1);\n\tif (!tile) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tg_game.map.removeTile(tile->getPosition());\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTileGetPosition(lua_State* L)\n{\n\t// tile:getPosition()\n\tTile* tile = getUserdata<Tile>(L, 1);\n\tif (tile) {\n\t\tpushPosition(L, tile->getPosition());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTileGetGround(lua_State* L)\n{\n\t// tile:getGround()\n\tTile* tile = getUserdata<Tile>(L, 1);\n\tif (tile && tile->getGround()) {\n\t\tpushUserdata<Item>(L, tile->getGround());\n\t\tsetItemMetatable(L, -1, tile->getGround());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTileGetThing(lua_State* L)\n{\n\t// tile:getThing(index)\n\tint32_t index = getNumber<int32_t>(L, 2);\n\tTile* tile = getUserdata<Tile>(L, 1);\n\tif (!tile) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tThing* thing = tile->getThing(index);\n\tif (!thing) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tif (Creature* creature = thing->getCreature()) {\n\t\tpushUserdata<Creature>(L, creature);\n\t\tsetCreatureMetatable(L, -1, creature);\n\t} else if (Item* item = thing->getItem()) {\n\t\tpushUserdata<Item>(L, item);\n\t\tsetItemMetatable(L, -1, item);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTileGetThingCount(lua_State* L)\n{\n\t// tile:getThingCount()\n\tTile* tile = getUserdata<Tile>(L, 1);\n\tif (tile) {\n\t\tlua_pushnumber(L, tile->getThingCount());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTileGetTopVisibleThing(lua_State* L)\n{\n\t// tile:getTopVisibleThing(creature)\n\tCreature* creature = getCreature(L, 2);\n\tTile* tile = getUserdata<Tile>(L, 1);\n\tif (!tile) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tThing* thing = tile->getTopVisibleThing(creature);\n\tif (!thing) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tif (Creature* visibleCreature = thing->getCreature()) {\n\t\tpushUserdata<Creature>(L, visibleCreature);\n\t\tsetCreatureMetatable(L, -1, visibleCreature);\n\t} else if (Item* visibleItem = thing->getItem()) {\n\t\tpushUserdata<Item>(L, visibleItem);\n\t\tsetItemMetatable(L, -1, visibleItem);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTileGetTopTopItem(lua_State* L)\n{\n\t// tile:getTopTopItem()\n\tTile* tile = getUserdata<Tile>(L, 1);\n\tif (!tile) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tItem* item = tile->getTopTopItem();\n\tif (item) {\n\t\tpushUserdata<Item>(L, item);\n\t\tsetItemMetatable(L, -1, item);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTileGetTopDownItem(lua_State* L)\n{\n\t// tile:getTopDownItem()\n\tTile* tile = getUserdata<Tile>(L, 1);\n\tif (!tile) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tItem* item = tile->getTopDownItem();\n\tif (item) {\n\t\tpushUserdata<Item>(L, item);\n\t\tsetItemMetatable(L, -1, item);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTileGetFieldItem(lua_State* L)\n{\n\t// tile:getFieldItem()\n\tTile* tile = getUserdata<Tile>(L, 1);\n\tif (!tile) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tItem* item = tile->getFieldItem();\n\tif (item) {\n\t\tpushUserdata<Item>(L, item);\n\t\tsetItemMetatable(L, -1, item);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTileGetItemById(lua_State* L)\n{\n\t// tile:getItemById(itemId[, subType = -1])\n\tTile* tile = getUserdata<Tile>(L, 1);\n\tif (!tile) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tuint16_t itemId;\n\tif (isNumber(L, 2)) {\n\t\titemId = getNumber<uint16_t>(L, 2);\n\t} else {\n\t\titemId = Item::items.getItemIdByName(getString(L, 2));\n\t\tif (itemId == 0) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\t}\n\tint32_t subType = getNumber<int32_t>(L, 3, -1);\n\n\tItem* item = g_game.findItemOfType(tile, itemId, false, subType);\n\tif (item) {\n\t\tpushUserdata<Item>(L, item);\n\t\tsetItemMetatable(L, -1, item);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTileGetItemByType(lua_State* L)\n{\n\t// tile:getItemByType(itemType)\n\tTile* tile = getUserdata<Tile>(L, 1);\n\tif (!tile) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tbool found;\n\n\tItemTypes_t itemType = getNumber<ItemTypes_t>(L, 2);\n\tswitch (itemType) {\n\t\tcase ITEM_TYPE_TELEPORT:\n\t\t\tfound = tile->hasFlag(TILESTATE_TELEPORT);\n\t\t\tbreak;\n\t\tcase ITEM_TYPE_MAGICFIELD:\n\t\t\tfound = tile->hasFlag(TILESTATE_MAGICFIELD);\n\t\t\tbreak;\n\t\tcase ITEM_TYPE_MAILBOX:\n\t\t\tfound = tile->hasFlag(TILESTATE_MAILBOX);\n\t\t\tbreak;\n\t\tcase ITEM_TYPE_TRASHHOLDER:\n\t\t\tfound = tile->hasFlag(TILESTATE_TRASHHOLDER);\n\t\t\tbreak;\n\t\tcase ITEM_TYPE_BED:\n\t\t\tfound = tile->hasFlag(TILESTATE_BED);\n\t\t\tbreak;\n\t\tcase ITEM_TYPE_DEPOT:\n\t\t\tfound = tile->hasFlag(TILESTATE_DEPOT);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tfound = true;\n\t\t\tbreak;\n\t}\n\n\tif (!found) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tif (Item* item = tile->getGround()) {\n\t\tconst ItemType& it = Item::items[item->getID()];\n\t\tif (it.type == itemType) {\n\t\t\tpushUserdata<Item>(L, item);\n\t\t\tsetItemMetatable(L, -1, item);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tif (const TileItemVector* items = tile->getItemList()) {\n\t\tfor (Item* item : *items) {\n\t\t\tconst ItemType& it = Item::items[item->getID()];\n\t\t\tif (it.type == itemType) {\n\t\t\t\tpushUserdata<Item>(L, item);\n\t\t\t\tsetItemMetatable(L, -1, item);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}\n\t}\n\n\tlua_pushnil(L);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTileGetItemByTopOrder(lua_State* L)\n{\n\t// tile:getItemByTopOrder(topOrder)\n\tTile* tile = getUserdata<Tile>(L, 1);\n\tif (!tile) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tint32_t topOrder = getNumber<int32_t>(L, 2);\n\n\tItem* item = tile->getItemByTopOrder(topOrder);\n\tif (!item) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tpushUserdata<Item>(L, item);\n\tsetItemMetatable(L, -1, item);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTileGetItemCountById(lua_State* L)\n{\n\t// tile:getItemCountById(itemId[, subType = -1])\n\tTile* tile = getUserdata<Tile>(L, 1);\n\tif (!tile) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tint32_t subType = getNumber<int32_t>(L, 3, -1);\n\n\tuint16_t itemId;\n\tif (isNumber(L, 2)) {\n\t\titemId = getNumber<uint16_t>(L, 2);\n\t} else {\n\t\titemId = Item::items.getItemIdByName(getString(L, 2));\n\t\tif (itemId == 0) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tlua_pushnumber(L, tile->getItemTypeCount(itemId, subType));\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTileGetBottomCreature(lua_State* L)\n{\n\t// tile:getBottomCreature()\n\tTile* tile = getUserdata<Tile>(L, 1);\n\tif (!tile) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tconst Creature* creature = tile->getBottomCreature();\n\tif (!creature) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tpushUserdata<const Creature>(L, creature);\n\tsetCreatureMetatable(L, -1, creature);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTileGetTopCreature(lua_State* L)\n{\n\t// tile:getTopCreature()\n\tTile* tile = getUserdata<Tile>(L, 1);\n\tif (!tile) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tCreature* creature = tile->getTopCreature();\n\tif (!creature) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tpushUserdata<Creature>(L, creature);\n\tsetCreatureMetatable(L, -1, creature);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTileGetBottomVisibleCreature(lua_State* L)\n{\n\t// tile:getBottomVisibleCreature(creature)\n\tTile* tile = getUserdata<Tile>(L, 1);\n\tif (!tile) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tCreature* creature = getCreature(L, 2);\n\tif (!creature) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tconst Creature* visibleCreature = tile->getBottomVisibleCreature(creature);\n\tif (visibleCreature) {\n\t\tpushUserdata<const Creature>(L, visibleCreature);\n\t\tsetCreatureMetatable(L, -1, visibleCreature);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTileGetTopVisibleCreature(lua_State* L)\n{\n\t// tile:getTopVisibleCreature(creature)\n\tTile* tile = getUserdata<Tile>(L, 1);\n\tif (!tile) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tCreature* creature = getCreature(L, 2);\n\tif (!creature) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tCreature* visibleCreature = tile->getTopVisibleCreature(creature);\n\tif (visibleCreature) {\n\t\tpushUserdata<Creature>(L, visibleCreature);\n\t\tsetCreatureMetatable(L, -1, visibleCreature);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTileGetItems(lua_State* L)\n{\n\t// tile:getItems()\n\tTile* tile = getUserdata<Tile>(L, 1);\n\tif (!tile) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tTileItemVector* itemVector = tile->getItemList();\n\tif (!itemVector) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tlua_createtable(L, itemVector->size(), 0);\n\n\tint index = 0;\n\tfor (Item* item : *itemVector) {\n\t\tpushUserdata<Item>(L, item);\n\t\tsetItemMetatable(L, -1, item);\n\t\tlua_rawseti(L, -2, ++index);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTileGetItemCount(lua_State* L)\n{\n\t// tile:getItemCount()\n\tTile* tile = getUserdata<Tile>(L, 1);\n\tif (!tile) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tlua_pushnumber(L, tile->getItemCount());\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTileGetDownItemCount(lua_State* L)\n{\n\t// tile:getDownItemCount()\n\tTile* tile = getUserdata<Tile>(L, 1);\n\tif (tile) {\n\t\tlua_pushnumber(L, tile->getDownItemCount());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTileGetTopItemCount(lua_State* L)\n{\n\t// tile:getTopItemCount()\n\tTile* tile = getUserdata<Tile>(L, 1);\n\tif (!tile) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tlua_pushnumber(L, tile->getTopItemCount());\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTileGetCreatures(lua_State* L)\n{\n\t// tile:getCreatures()\n\tTile* tile = getUserdata<Tile>(L, 1);\n\tif (!tile) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tCreatureVector* creatureVector = tile->getCreatures();\n\tif (!creatureVector) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tlua_createtable(L, creatureVector->size(), 0);\n\n\tint index = 0;\n\tfor (Creature* creature : *creatureVector) {\n\t\tpushUserdata<Creature>(L, creature);\n\t\tsetCreatureMetatable(L, -1, creature);\n\t\tlua_rawseti(L, -2, ++index);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTileGetCreatureCount(lua_State* L)\n{\n\t// tile:getCreatureCount()\n\tTile* tile = getUserdata<Tile>(L, 1);\n\tif (!tile) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tlua_pushnumber(L, tile->getCreatureCount());\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTileHasProperty(lua_State* L)\n{\n\t// tile:hasProperty(property[, item])\n\tTile* tile = getUserdata<Tile>(L, 1);\n\tif (!tile) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tItem* item;\n\tif (lua_gettop(L) >= 3) {\n\t\titem = getUserdata<Item>(L, 3);\n\t} else {\n\t\titem = nullptr;\n\t}\n\n\tITEMPROPERTY property = getNumber<ITEMPROPERTY>(L, 2);\n\tif (item) {\n\t\tpushBoolean(L, tile->hasProperty(item, property));\n\t} else {\n\t\tpushBoolean(L, tile->hasProperty(property));\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTileGetThingIndex(lua_State* L)\n{\n\t// tile:getThingIndex(thing)\n\tTile* tile = getUserdata<Tile>(L, 1);\n\tif (!tile) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tThing* thing = getThing(L, 2);\n\tif (thing) {\n\t\tlua_pushnumber(L, tile->getThingIndex(thing));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTileHasFlag(lua_State* L)\n{\n\t// tile:hasFlag(flag)\n\tTile* tile = getUserdata<Tile>(L, 1);\n\tif (tile) {\n\t\ttileflags_t flag = getNumber<tileflags_t>(L, 2);\n\t\tpushBoolean(L, tile->hasFlag(flag));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTileQueryAdd(lua_State* L)\n{\n\t// tile:queryAdd(thing[, flags])\n\tTile* tile = getUserdata<Tile>(L, 1);\n\tif (!tile) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tThing* thing = getThing(L, 2);\n\tif (thing) {\n\t\tuint32_t flags = getNumber<uint32_t>(L, 3, 0);\n\t\tlua_pushnumber(L, tile->queryAdd(0, *thing, 1, flags));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTileAddItem(lua_State* L)\n{\n\t// tile:addItem(itemId[, count/subType = 1[, flags = 0]])\n\tTile* tile = getUserdata<Tile>(L, 1);\n\tif (!tile) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tuint16_t itemId;\n\tif (isNumber(L, 2)) {\n\t\titemId = getNumber<uint16_t>(L, 2);\n\t} else {\n\t\titemId = Item::items.getItemIdByName(getString(L, 2));\n\t\tif (itemId == 0) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tuint32_t subType = getNumber<uint32_t>(L, 3, 1);\n\n\tItem* item = Item::CreateItem(itemId, std::min<uint32_t>(subType, 100));\n\tif (!item) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tuint32_t flags = getNumber<uint32_t>(L, 4, 0);\n\n\tReturnValue ret = g_game.internalAddItem(tile, item, INDEX_WHEREEVER, flags);\n\tif (ret == RETURNVALUE_NOERROR) {\n\t\tpushUserdata<Item>(L, item);\n\t\tsetItemMetatable(L, -1, item);\n\t} else {\n\t\tdelete item;\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTileAddItemEx(lua_State* L)\n{\n\t// tile:addItemEx(item[, flags = 0])\n\tItem* item = getUserdata<Item>(L, 2);\n\tif (!item) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tTile* tile = getUserdata<Tile>(L, 1);\n\tif (!tile) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tif (item->getParent() != VirtualCylinder::virtualCylinder) {\n\t\treportErrorFunc(\"Item already has a parent\");\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tuint32_t flags = getNumber<uint32_t>(L, 3, 0);\n\tReturnValue ret = g_game.internalAddItem(tile, item, INDEX_WHEREEVER, flags);\n\tif (ret == RETURNVALUE_NOERROR) {\n\t\tScriptEnvironment::removeTempItem(item);\n\t}\n\tlua_pushnumber(L, ret);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTileGetHouse(lua_State* L)\n{\n\t// tile:getHouse()\n\tTile* tile = getUserdata<Tile>(L, 1);\n\tif (!tile) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tif (HouseTile* houseTile = dynamic_cast<HouseTile*>(tile)) {\n\t\tpushUserdata<House>(L, houseTile->getHouse());\n\t\tsetMetatable(L, -1, \"House\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\n// NetworkMessage\nint LuaScriptInterface::luaNetworkMessageCreate(lua_State* L)\n{\n\t// NetworkMessage()\n\tpushUserdata<NetworkMessage>(L, new NetworkMessage);\n\tsetMetatable(L, -1, \"NetworkMessage\");\n\treturn 1;\n}\n\nint LuaScriptInterface::luaNetworkMessageDelete(lua_State* L)\n{\n\tNetworkMessage** messagePtr = getRawUserdata<NetworkMessage>(L, 1);\n\tif (messagePtr && *messagePtr) {\n\t\tdelete *messagePtr;\n\t\t*messagePtr = nullptr;\n\t}\n\treturn 0;\n}\n\nint LuaScriptInterface::luaNetworkMessageGetByte(lua_State* L)\n{\n\t// networkMessage:getByte()\n\tNetworkMessage* message = getUserdata<NetworkMessage>(L, 1);\n\tif (message) {\n\t\tlua_pushnumber(L, message->getByte());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaNetworkMessageGetU16(lua_State* L)\n{\n\t// networkMessage:getU16()\n\tNetworkMessage* message = getUserdata<NetworkMessage>(L, 1);\n\tif (message) {\n\t\tlua_pushnumber(L, message->get<uint16_t>());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaNetworkMessageGetU32(lua_State* L)\n{\n\t// networkMessage:getU32()\n\tNetworkMessage* message = getUserdata<NetworkMessage>(L, 1);\n\tif (message) {\n\t\tlua_pushnumber(L, message->get<uint32_t>());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaNetworkMessageGetU64(lua_State* L)\n{\n\t// networkMessage:getU64()\n\tNetworkMessage* message = getUserdata<NetworkMessage>(L, 1);\n\tif (message) {\n\t\tlua_pushnumber(L, message->get<uint64_t>());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaNetworkMessageGetString(lua_State* L)\n{\n\t// networkMessage:getString()\n\tNetworkMessage* message = getUserdata<NetworkMessage>(L, 1);\n\tif (message) {\n\t\tpushString(L, message->getString());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaNetworkMessageGetPosition(lua_State* L)\n{\n\t// networkMessage:getPosition()\n\tNetworkMessage* message = getUserdata<NetworkMessage>(L, 1);\n\tif (message) {\n\t\tpushPosition(L, message->getPosition());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaNetworkMessageAddByte(lua_State* L)\n{\n\t// networkMessage:addByte(number)\n\tuint8_t number = getNumber<uint8_t>(L, 2);\n\tNetworkMessage* message = getUserdata<NetworkMessage>(L, 1);\n\tif (message) {\n\t\tmessage->addByte(number);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaNetworkMessageAddU16(lua_State* L)\n{\n\t// networkMessage:addU16(number)\n\tuint16_t number = getNumber<uint16_t>(L, 2);\n\tNetworkMessage* message = getUserdata<NetworkMessage>(L, 1);\n\tif (message) {\n\t\tmessage->add<uint16_t>(number);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaNetworkMessageAddU32(lua_State* L)\n{\n\t// networkMessage:addU32(number)\n\tuint32_t number = getNumber<uint32_t>(L, 2);\n\tNetworkMessage* message = getUserdata<NetworkMessage>(L, 1);\n\tif (message) {\n\t\tmessage->add<uint32_t>(number);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaNetworkMessageAddU64(lua_State* L)\n{\n\t// networkMessage:addU64(number)\n\tuint64_t number = getNumber<uint64_t>(L, 2);\n\tNetworkMessage* message = getUserdata<NetworkMessage>(L, 1);\n\tif (message) {\n\t\tmessage->add<uint64_t>(number);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaNetworkMessageAddString(lua_State* L)\n{\n\t// networkMessage:addString(string)\n\tconst std::string& string = getString(L, 2);\n\tNetworkMessage* message = getUserdata<NetworkMessage>(L, 1);\n\tif (message) {\n\t\tmessage->addString(string);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaNetworkMessageAddPosition(lua_State* L)\n{\n\t// networkMessage:addPosition(position)\n\tconst Position& position = getPosition(L, 2);\n\tNetworkMessage* message = getUserdata<NetworkMessage>(L, 1);\n\tif (message) {\n\t\tmessage->addPosition(position);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaNetworkMessageAddDouble(lua_State* L)\n{\n\t// networkMessage:addDouble(number)\n\tdouble number = getNumber<double>(L, 2);\n\tNetworkMessage* message = getUserdata<NetworkMessage>(L, 1);\n\tif (message) {\n\t\tmessage->addDouble(number);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaNetworkMessageAddItem(lua_State* L)\n{\n\t// networkMessage:addItem(item)\n\tItem* item = getUserdata<Item>(L, 2);\n\tif (!item) {\n\t\treportErrorFunc(getErrorDesc(LUA_ERROR_ITEM_NOT_FOUND));\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tNetworkMessage* message = getUserdata<NetworkMessage>(L, 1);\n\tif (message) {\n\t\tmessage->addItem(item);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaNetworkMessageAddItemId(lua_State* L)\n{\n\t// networkMessage:addItemId(itemId)\n\tNetworkMessage* message = getUserdata<NetworkMessage>(L, 1);\n\tif (!message) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tuint16_t itemId;\n\tif (isNumber(L, 2)) {\n\t\titemId = getNumber<uint16_t>(L, 2);\n\t} else {\n\t\titemId = Item::items.getItemIdByName(getString(L, 2));\n\t\tif (itemId == 0) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tmessage->addItemId(itemId);\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaNetworkMessageReset(lua_State* L)\n{\n\t// networkMessage:reset()\n\tNetworkMessage* message = getUserdata<NetworkMessage>(L, 1);\n\tif (message) {\n\t\tmessage->reset();\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaNetworkMessageSkipBytes(lua_State* L)\n{\n\t// networkMessage:skipBytes(number)\n\tint16_t number = getNumber<int16_t>(L, 2);\n\tNetworkMessage* message = getUserdata<NetworkMessage>(L, 1);\n\tif (message) {\n\t\tmessage->skipBytes(number);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaNetworkMessageSendToPlayer(lua_State* L)\n{\n\t// networkMessage:sendToPlayer(player)\n\tNetworkMessage* message = getUserdata<NetworkMessage>(L, 1);\n\tif (!message) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tPlayer* player = getPlayer(L, 2);\n\tif (player) {\n\t\tplayer->sendNetworkMessage(*message);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\treportErrorFunc(getErrorDesc(LUA_ERROR_PLAYER_NOT_FOUND));\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\n// ModalWindow\nint LuaScriptInterface::luaModalWindowCreate(lua_State* L)\n{\n\t// ModalWindow(id, title, message)\n\tconst std::string& message = getString(L, 4);\n\tconst std::string& title = getString(L, 3);\n\tuint32_t id = getNumber<uint32_t>(L, 2);\n\n\tpushUserdata<ModalWindow>(L, new ModalWindow(id, title, message));\n\tsetMetatable(L, -1, \"ModalWindow\");\n\treturn 1;\n}\n\nint LuaScriptInterface::luaModalWindowDelete(lua_State* L)\n{\n\tModalWindow** windowPtr = getRawUserdata<ModalWindow>(L, 1);\n\tif (windowPtr && *windowPtr) {\n\t\tdelete *windowPtr;\n\t\t*windowPtr = nullptr;\n\t}\n\treturn 0;\n}\n\nint LuaScriptInterface::luaModalWindowGetId(lua_State* L)\n{\n\t// modalWindow:getId()\n\tModalWindow* window = getUserdata<ModalWindow>(L, 1);\n\tif (window) {\n\t\tlua_pushnumber(L, window->id);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaModalWindowGetTitle(lua_State* L)\n{\n\t// modalWindow:getTitle()\n\tModalWindow* window = getUserdata<ModalWindow>(L, 1);\n\tif (window) {\n\t\tpushString(L, window->title);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaModalWindowGetMessage(lua_State* L)\n{\n\t// modalWindow:getMessage()\n\tModalWindow* window = getUserdata<ModalWindow>(L, 1);\n\tif (window) {\n\t\tpushString(L, window->message);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaModalWindowSetTitle(lua_State* L)\n{\n\t// modalWindow:setTitle(text)\n\tconst std::string& text = getString(L, 2);\n\tModalWindow* window = getUserdata<ModalWindow>(L, 1);\n\tif (window) {\n\t\twindow->title = text;\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaModalWindowSetMessage(lua_State* L)\n{\n\t// modalWindow:setMessage(text)\n\tconst std::string& text = getString(L, 2);\n\tModalWindow* window = getUserdata<ModalWindow>(L, 1);\n\tif (window) {\n\t\twindow->message = text;\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaModalWindowGetButtonCount(lua_State* L)\n{\n\t// modalWindow:getButtonCount()\n\tModalWindow* window = getUserdata<ModalWindow>(L, 1);\n\tif (window) {\n\t\tlua_pushnumber(L, window->buttons.size());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaModalWindowGetChoiceCount(lua_State* L)\n{\n\t// modalWindow:getChoiceCount()\n\tModalWindow* window = getUserdata<ModalWindow>(L, 1);\n\tif (window) {\n\t\tlua_pushnumber(L, window->choices.size());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaModalWindowAddButton(lua_State* L)\n{\n\t// modalWindow:addButton(id, text)\n\tconst std::string& text = getString(L, 3);\n\tuint8_t id = getNumber<uint8_t>(L, 2);\n\tModalWindow* window = getUserdata<ModalWindow>(L, 1);\n\tif (window) {\n\t\twindow->buttons.emplace_back(text, id);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaModalWindowAddChoice(lua_State* L)\n{\n\t// modalWindow:addChoice(id, text)\n\tconst std::string& text = getString(L, 3);\n\tuint8_t id = getNumber<uint8_t>(L, 2);\n\tModalWindow* window = getUserdata<ModalWindow>(L, 1);\n\tif (window) {\n\t\twindow->choices.emplace_back(text, id);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaModalWindowGetDefaultEnterButton(lua_State* L)\n{\n\t// modalWindow:getDefaultEnterButton()\n\tModalWindow* window = getUserdata<ModalWindow>(L, 1);\n\tif (window) {\n\t\tlua_pushnumber(L, window->defaultEnterButton);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaModalWindowSetDefaultEnterButton(lua_State* L)\n{\n\t// modalWindow:setDefaultEnterButton(buttonId)\n\tModalWindow* window = getUserdata<ModalWindow>(L, 1);\n\tif (window) {\n\t\twindow->defaultEnterButton = getNumber<uint8_t>(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaModalWindowGetDefaultEscapeButton(lua_State* L)\n{\n\t// modalWindow:getDefaultEscapeButton()\n\tModalWindow* window = getUserdata<ModalWindow>(L, 1);\n\tif (window) {\n\t\tlua_pushnumber(L, window->defaultEscapeButton);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaModalWindowSetDefaultEscapeButton(lua_State* L)\n{\n\t// modalWindow:setDefaultEscapeButton(buttonId)\n\tModalWindow* window = getUserdata<ModalWindow>(L, 1);\n\tif (window) {\n\t\twindow->defaultEscapeButton = getNumber<uint8_t>(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaModalWindowHasPriority(lua_State* L)\n{\n\t// modalWindow:hasPriority()\n\tModalWindow* window = getUserdata<ModalWindow>(L, 1);\n\tif (window) {\n\t\tpushBoolean(L, window->priority);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaModalWindowSetPriority(lua_State* L)\n{\n\t// modalWindow:setPriority(priority)\n\tModalWindow* window = getUserdata<ModalWindow>(L, 1);\n\tif (window) {\n\t\twindow->priority = getBoolean(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaModalWindowSendToPlayer(lua_State* L)\n{\n\t// modalWindow:sendToPlayer(player)\n\tPlayer* player = getPlayer(L, 2);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tModalWindow* window = getUserdata<ModalWindow>(L, 1);\n\tif (window) {\n\t\tif (!player->hasModalWindowOpen(window->id)) {\n\t\t\tplayer->sendModalWindow(*window);\n\t\t}\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\n// Item\nint LuaScriptInterface::luaItemCreate(lua_State* L)\n{\n\t// Item(uid)\n\tuint32_t id = getNumber<uint32_t>(L, 2);\n\n\tItem* item = getScriptEnv()->getItemByUID(id);\n\tif (item) {\n\t\tpushUserdata<Item>(L, item);\n\t\tsetItemMetatable(L, -1, item);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemIsItem(lua_State* L)\n{\n\t// item:isItem()\n\tpushBoolean(L, getUserdata<const Item>(L, 1) != nullptr);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemGetParent(lua_State* L)\n{\n\t// item:getParent()\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (!item) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tCylinder* parent = item->getParent();\n\tif (!parent) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tpushCylinder(L, parent);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemGetTopParent(lua_State* L)\n{\n\t// item:getTopParent()\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (!item) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tCylinder* topParent = item->getTopParent();\n\tif (!topParent) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tpushCylinder(L, topParent);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemGetId(lua_State* L)\n{\n\t// item:getId()\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (item) {\n\t\tlua_pushnumber(L, item->getID());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemClone(lua_State* L)\n{\n\t// item:clone()\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (!item) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tItem* clone = item->clone();\n\tif (!clone) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tgetScriptEnv()->addTempItem(clone);\n\tclone->setParent(VirtualCylinder::virtualCylinder);\n\n\tpushUserdata<Item>(L, clone);\n\tsetItemMetatable(L, -1, clone);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemSplit(lua_State* L)\n{\n\t// item:split([count = 1])\n\tItem** itemPtr = getRawUserdata<Item>(L, 1);\n\tif (!itemPtr) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tItem* item = *itemPtr;\n\tif (!item || !item->isStackable()) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tuint16_t count = std::min<uint16_t>(getNumber<uint16_t>(L, 2, 1), item->getItemCount());\n\tuint16_t diff = item->getItemCount() - count;\n\n\tItem* splitItem = item->clone();\n\tif (!splitItem) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tsplitItem->setItemCount(count);\n\n\tScriptEnvironment* env = getScriptEnv();\n\tuint32_t uid = env->addThing(item);\n\n\tItem* newItem = g_game.transformItem(item, item->getID(), diff);\n\tif (item->isRemoved()) {\n\t\tenv->removeItemByUID(uid);\n\t}\n\n\tif (newItem && newItem != item) {\n\t\tenv->insertItem(uid, newItem);\n\t}\n\n\t*itemPtr = newItem;\n\n\tsplitItem->setParent(VirtualCylinder::virtualCylinder);\n\tenv->addTempItem(splitItem);\n\n\tpushUserdata<Item>(L, splitItem);\n\tsetItemMetatable(L, -1, splitItem);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemRemove(lua_State* L)\n{\n\t// item:remove([count = -1])\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (item) {\n\t\tint32_t count = getNumber<int32_t>(L, 2, -1);\n\t\tpushBoolean(L, g_game.internalRemoveItem(item, count) == RETURNVALUE_NOERROR);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemGetUniqueId(lua_State* L)\n{\n\t// item:getUniqueId()\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (item) {\n\t\tuint32_t uniqueId = item->getUniqueId();\n\t\tif (uniqueId == 0) {\n\t\t\tuniqueId = getScriptEnv()->addThing(item);\n\t\t}\n\t\tlua_pushnumber(L, uniqueId);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemGetActionId(lua_State* L)\n{\n\t// item:getActionId()\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (item) {\n\t\tlua_pushnumber(L, item->getActionId());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemSetActionId(lua_State* L)\n{\n\t// item:setActionId(actionId)\n\tuint16_t actionId = getNumber<uint16_t>(L, 2);\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (item) {\n\t\titem->setActionId(actionId);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemGetCount(lua_State* L)\n{\n\t// item:getCount()\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (item) {\n\t\tlua_pushnumber(L, item->getItemCount());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemGetCharges(lua_State* L)\n{\n\t// item:getCharges()\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (item) {\n\t\tlua_pushnumber(L, item->getCharges());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemGetFluidType(lua_State* L)\n{\n\t// item:getFluidType()\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (item) {\n\t\tlua_pushnumber(L, item->getFluidType());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemGetWeight(lua_State* L)\n{\n\t// item:getWeight()\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (item) {\n\t\tlua_pushnumber(L, item->getWeight());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemGetSubType(lua_State* L)\n{\n\t// item:getSubType()\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (item) {\n\t\tlua_pushnumber(L, item->getSubType());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemGetName(lua_State* L)\n{\n\t// item:getName()\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (item) {\n\t\tpushString(L, item->getName());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemGetPluralName(lua_State* L)\n{\n\t// item:getPluralName()\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (item) {\n\t\tpushString(L, item->getPluralName());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemGetArticle(lua_State* L)\n{\n\t// item:getArticle()\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (item) {\n\t\tpushString(L, item->getArticle());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemGetPosition(lua_State* L)\n{\n\t// item:getPosition()\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (item) {\n\t\tpushPosition(L, item->getPosition());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemGetTile(lua_State* L)\n{\n\t// item:getTile()\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (!item) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tTile* tile = item->getTile();\n\tif (tile) {\n\t\tpushUserdata<Tile>(L, tile);\n\t\tsetMetatable(L, -1, \"Tile\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemHasAttribute(lua_State* L)\n{\n\t// item:hasAttribute(key)\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (!item) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\titemAttrTypes attribute;\n\tif (isNumber(L, 2)) {\n\t\tattribute = getNumber<itemAttrTypes>(L, 2);\n\t} else if (isString(L, 2)) {\n\t\tattribute = stringToItemAttribute(getString(L, 2));\n\t} else {\n\t\tattribute = ITEM_ATTRIBUTE_NONE;\n\t}\n\n\tpushBoolean(L, item->hasAttribute(attribute));\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemGetAttribute(lua_State* L)\n{\n\t// item:getAttribute(key)\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (!item) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\titemAttrTypes attribute;\n\tif (isNumber(L, 2)) {\n\t\tattribute = getNumber<itemAttrTypes>(L, 2);\n\t} else if (isString(L, 2)) {\n\t\tattribute = stringToItemAttribute(getString(L, 2));\n\t} else {\n\t\tattribute = ITEM_ATTRIBUTE_NONE;\n\t}\n\n\tif (ItemAttributes::isIntAttrType(attribute)) {\n\t\tlua_pushnumber(L, item->getIntAttr(attribute));\n\t} else if (ItemAttributes::isStrAttrType(attribute)) {\n\t\tpushString(L, item->getStrAttr(attribute));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemSetAttribute(lua_State* L)\n{\n\t// item:setAttribute(key, value)\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (!item) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\titemAttrTypes attribute;\n\tif (isNumber(L, 2)) {\n\t\tattribute = getNumber<itemAttrTypes>(L, 2);\n\t} else if (isString(L, 2)) {\n\t\tattribute = stringToItemAttribute(getString(L, 2));\n\t} else {\n\t\tattribute = ITEM_ATTRIBUTE_NONE;\n\t}\n\n\tif (ItemAttributes::isIntAttrType(attribute)) {\n\t\tif (attribute == ITEM_ATTRIBUTE_UNIQUEID) {\n\t\t\treportErrorFunc(\"Attempt to set protected key \\\"uid\\\"\");\n\t\t\tpushBoolean(L, false);\n\t\t\treturn 1;\n\t\t}\n\n\t\titem->setIntAttr(attribute, getNumber<int32_t>(L, 3));\n\t\tpushBoolean(L, true);\n\t} else if (ItemAttributes::isStrAttrType(attribute)) {\n\t\titem->setStrAttr(attribute, getString(L, 3));\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemRemoveAttribute(lua_State* L)\n{\n\t// item:removeAttribute(key)\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (!item) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\titemAttrTypes attribute;\n\tif (isNumber(L, 2)) {\n\t\tattribute = getNumber<itemAttrTypes>(L, 2);\n\t} else if (isString(L, 2)) {\n\t\tattribute = stringToItemAttribute(getString(L, 2));\n\t} else {\n\t\tattribute = ITEM_ATTRIBUTE_NONE;\n\t}\n\n\tbool ret = attribute != ITEM_ATTRIBUTE_UNIQUEID;\n\tif (ret) {\n\t\titem->removeAttribute(attribute);\n\t} else {\n\t\treportErrorFunc(\"Attempt to erase protected key \\\"uid\\\"\");\n\t}\n\tpushBoolean(L, ret);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemGetCustomAttribute(lua_State* L) {\n\t// item:getCustomAttribute(key)\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (!item) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tconst ItemAttributes::CustomAttribute* attr;\n\tif (isNumber(L, 2)) {\n\t\tattr = item->getCustomAttribute(getNumber<int64_t>(L, 2));\n\t} else if (isString(L, 2)) {\n\t\tattr = item->getCustomAttribute(getString(L, 2));\n\t} else {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tif (attr) {\n\t\tattr->pushToLua(L);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemSetCustomAttribute(lua_State* L) {\n\t// item:setCustomAttribute(key, value)\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (!item) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tstd::string key;\n\tif (isNumber(L, 2)) {\n\t\tkey = boost::lexical_cast<std::string>(getNumber<int64_t>(L, 2));\n\t} else if (isString(L, 2)) {\n\t\tkey = getString(L, 2);\n\t} else {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tItemAttributes::CustomAttribute val;\n\tif (isNumber(L, 3)) {\n\t\tdouble tmp = getNumber<double>(L, 3);\n\t\tif (std::floor(tmp) < tmp) {\n\t\t\tval.set<double>(tmp);\n\t\t} else {\n\t\t\tval.set<int64_t>(tmp);\n\t\t}\n\t} else if (isString(L, 3)) {\n\t\tval.set<std::string>(getString(L, 3));\n\t} else if (isBoolean(L, 3)) {\n\t\tval.set<bool>(getBoolean(L, 3));\n\t} else {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\titem->setCustomAttribute(key, val);\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemRemoveCustomAttribute(lua_State* L) {\n\t// item:removeCustomAttribute(key)\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (!item) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tif (isNumber(L, 2)) {\n\t\tpushBoolean(L, item->removeCustomAttribute(getNumber<int64_t>(L, 2)));\n\t} else if (isString(L, 2)) {\n\t\tpushBoolean(L, item->removeCustomAttribute(getString(L, 2)));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemMoveTo(lua_State* L)\n{\n\t// item:moveTo(position or cylinder[, flags])\n\tItem** itemPtr = getRawUserdata<Item>(L, 1);\n\tif (!itemPtr) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tItem* item = *itemPtr;\n\tif (!item || item->isRemoved()) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tCylinder* toCylinder;\n\tif (isUserdata(L, 2)) {\n\t\tconst LuaDataType type = getUserdataType(L, 2);\n\t\tswitch (type) {\n\t\t\tcase LuaData_Container:\n\t\t\t\ttoCylinder = getUserdata<Container>(L, 2);\n\t\t\t\tbreak;\n\t\t\tcase LuaData_Player:\n\t\t\t\ttoCylinder = getUserdata<Player>(L, 2);\n\t\t\t\tbreak;\n\t\t\tcase LuaData_Tile:\n\t\t\t\ttoCylinder = getUserdata<Tile>(L, 2);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\ttoCylinder = nullptr;\n\t\t\t\tbreak;\n\t\t}\n\t} else {\n\t\ttoCylinder = g_game.map.getTile(getPosition(L, 2));\n\t}\n\n\tif (!toCylinder) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tif (item->getParent() == toCylinder) {\n\t\tpushBoolean(L, true);\n\t\treturn 1;\n\t}\n\n\tuint32_t flags = getNumber<uint32_t>(L, 3, FLAG_NOLIMIT | FLAG_IGNOREBLOCKITEM | FLAG_IGNOREBLOCKCREATURE | FLAG_IGNORENOTMOVEABLE);\n\n\tif (item->getParent() == VirtualCylinder::virtualCylinder) {\n\t\tpushBoolean(L, g_game.internalAddItem(toCylinder, item, INDEX_WHEREEVER, flags) == RETURNVALUE_NOERROR);\n\t} else {\n\t\tItem* moveItem = nullptr;\n\t\tReturnValue ret = g_game.internalMoveItem(item->getParent(), toCylinder, INDEX_WHEREEVER, item, item->getItemCount(), &moveItem, flags);\n\t\tif (moveItem) {\n\t\t\t*itemPtr = moveItem;\n\t\t}\n\t\tpushBoolean(L, ret == RETURNVALUE_NOERROR);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTransform(lua_State* L)\n{\n\t// item:transform(itemId[, count/subType = -1])\n\tItem** itemPtr = getRawUserdata<Item>(L, 1);\n\tif (!itemPtr) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tItem*& item = *itemPtr;\n\tif (!item) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tuint16_t itemId;\n\tif (isNumber(L, 2)) {\n\t\titemId = getNumber<uint16_t>(L, 2);\n\t} else {\n\t\titemId = Item::items.getItemIdByName(getString(L, 2));\n\t\tif (itemId == 0) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tint32_t subType = getNumber<int32_t>(L, 3, -1);\n\tif (item->getID() == itemId && (subType == -1 || subType == item->getSubType())) {\n\t\tpushBoolean(L, true);\n\t\treturn 1;\n\t}\n\n\tconst ItemType& it = Item::items[itemId];\n\tif (it.stackable) {\n\t\tsubType = std::min<int32_t>(subType, 100);\n\t}\n\n\tScriptEnvironment* env = getScriptEnv();\n\tuint32_t uid = env->addThing(item);\n\n\tItem* newItem = g_game.transformItem(item, itemId, subType);\n\tif (item->isRemoved()) {\n\t\tenv->removeItemByUID(uid);\n\t}\n\n\tif (newItem && newItem != item) {\n\t\tenv->insertItem(uid, newItem);\n\t}\n\n\titem = newItem;\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemDecay(lua_State* L)\n{\n\t// item:decay(decayId)\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (item) {\n\t\tif (isNumber(L, 2)) {\n\t\t\titem->setDecayTo(getNumber<int32_t>(L, 2));\n\t\t}\n\n\t\tg_game.startDecay(item);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemGetDescription(lua_State* L)\n{\n\t// item:getDescription(distance)\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (item) {\n\t\tint32_t distance = getNumber<int32_t>(L, 2);\n\t\tpushString(L, item->getDescription(distance));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemHasProperty(lua_State* L)\n{\n\t// item:hasProperty(property)\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (item) {\n\t\tITEMPROPERTY property = getNumber<ITEMPROPERTY>(L, 2);\n\t\tpushBoolean(L, item->hasProperty(property));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemIsLoadedFromMap(lua_State* L)\n{\n\t// item:isLoadedFromMap()\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (item) {\n\t\tpushBoolean(L, item->isLoadedFromMap());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemSetStoreItem(lua_State* L)\n{\n\t// item:setStoreItem(storeItem)\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (!item) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\titem->setStoreItem(getBoolean(L, 2, false));\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemIsStoreItem(lua_State* L)\n{\n\t// item:isStoreItem()\n\tItem* item = getUserdata<Item>(L, 1);\n\tif (item) {\n\t\tpushBoolean(L, item->isStoreItem());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\n// Container\nint LuaScriptInterface::luaContainerCreate(lua_State* L)\n{\n\t// Container(uid)\n\tuint32_t id = getNumber<uint32_t>(L, 2);\n\n\tContainer* container = getScriptEnv()->getContainerByUID(id);\n\tif (container) {\n\t\tpushUserdata(L, container);\n\t\tsetMetatable(L, -1, \"Container\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaContainerGetSize(lua_State* L)\n{\n\t// container:getSize()\n\tContainer* container = getUserdata<Container>(L, 1);\n\tif (container) {\n\t\tlua_pushnumber(L, container->size());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaContainerGetCapacity(lua_State* L)\n{\n\t// container:getCapacity()\n\tContainer* container = getUserdata<Container>(L, 1);\n\tif (container) {\n\t\tlua_pushnumber(L, container->capacity());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaContainerGetEmptySlots(lua_State* L)\n{\n\t// container:getEmptySlots([recursive = false])\n\tContainer* container = getUserdata<Container>(L, 1);\n\tif (!container) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tuint32_t slots = container->capacity() - container->size();\n\tbool recursive = getBoolean(L, 2, false);\n\tif (recursive) {\n\t\tfor (ContainerIterator it = container->iterator(); it.hasNext(); it.advance()) {\n\t\t\tif (Container* tmpContainer = (*it)->getContainer()) {\n\t\t\t\tslots += tmpContainer->capacity() - tmpContainer->size();\n\t\t\t}\n\t\t}\n\t}\n\tlua_pushnumber(L, slots);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaContainerGetItemHoldingCount(lua_State* L)\n{\n\t// container:getItemHoldingCount()\n\tContainer* container = getUserdata<Container>(L, 1);\n\tif (container) {\n\t\tlua_pushnumber(L, container->getItemHoldingCount());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaContainerGetItem(lua_State* L)\n{\n\t// container:getItem(index)\n\tContainer* container = getUserdata<Container>(L, 1);\n\tif (!container) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tuint32_t index = getNumber<uint32_t>(L, 2);\n\tItem* item = container->getItemByIndex(index);\n\tif (item) {\n\t\tpushUserdata<Item>(L, item);\n\t\tsetItemMetatable(L, -1, item);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaContainerHasItem(lua_State* L)\n{\n\t// container:hasItem(item)\n\tItem* item = getUserdata<Item>(L, 2);\n\tContainer* container = getUserdata<Container>(L, 1);\n\tif (container) {\n\t\tpushBoolean(L, container->isHoldingItem(item));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaContainerAddItem(lua_State* L)\n{\n\t// container:addItem(itemId[, count/subType = 1[, index = INDEX_WHEREEVER[, flags = 0]]])\n\tContainer* container = getUserdata<Container>(L, 1);\n\tif (!container) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tuint16_t itemId;\n\tif (isNumber(L, 2)) {\n\t\titemId = getNumber<uint16_t>(L, 2);\n\t} else {\n\t\titemId = Item::items.getItemIdByName(getString(L, 2));\n\t\tif (itemId == 0) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tuint32_t count = getNumber<uint32_t>(L, 3, 1);\n\tconst ItemType& it = Item::items[itemId];\n\tif (it.stackable) {\n\t\tcount = std::min<uint16_t>(count, 100);\n\t}\n\n\tItem* item = Item::CreateItem(itemId, count);\n\tif (!item) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tint32_t index = getNumber<int32_t>(L, 4, INDEX_WHEREEVER);\n\tuint32_t flags = getNumber<uint32_t>(L, 5, 0);\n\n\tReturnValue ret = g_game.internalAddItem(container, item, index, flags);\n\tif (ret == RETURNVALUE_NOERROR) {\n\t\tpushUserdata<Item>(L, item);\n\t\tsetItemMetatable(L, -1, item);\n\t} else {\n\t\tdelete item;\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaContainerAddItemEx(lua_State* L)\n{\n\t// container:addItemEx(item[, index = INDEX_WHEREEVER[, flags = 0]])\n\tItem* item = getUserdata<Item>(L, 2);\n\tif (!item) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tContainer* container = getUserdata<Container>(L, 1);\n\tif (!container) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tif (item->getParent() != VirtualCylinder::virtualCylinder) {\n\t\treportErrorFunc(\"Item already has a parent\");\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tint32_t index = getNumber<int32_t>(L, 3, INDEX_WHEREEVER);\n\tuint32_t flags = getNumber<uint32_t>(L, 4, 0);\n\tReturnValue ret = g_game.internalAddItem(container, item, index, flags);\n\tif (ret == RETURNVALUE_NOERROR) {\n\t\tScriptEnvironment::removeTempItem(item);\n\t}\n\tlua_pushnumber(L, ret);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaContainerGetCorpseOwner(lua_State* L)\n{\n\t// container:getCorpseOwner()\n\tContainer* container = getUserdata<Container>(L, 1);\n\tif (container) {\n\t\tlua_pushnumber(L, container->getCorpseOwner());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaContainerGetItemCountById(lua_State* L)\n{\n\t// container:getItemCountById(itemId[, subType = -1])\n\tContainer* container = getUserdata<Container>(L, 1);\n\tif (!container) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tuint16_t itemId;\n\tif (isNumber(L, 2)) {\n\t\titemId = getNumber<uint16_t>(L, 2);\n\t} else {\n\t\titemId = Item::items.getItemIdByName(getString(L, 2));\n\t\tif (itemId == 0) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tint32_t subType = getNumber<int32_t>(L, 3, -1);\n\tlua_pushnumber(L, container->getItemTypeCount(itemId, subType));\n\treturn 1;\n}\n\nint LuaScriptInterface::luaContainerGetContentDescription(lua_State* L)\n{\n\t// container:getContentDescription()\n\tContainer* container = getUserdata<Container>(L, 1);\n\tif (container) {\n\t\tpushString(L, container->getContentDescription());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaContainerGetItems(lua_State* L)\n{\n\t// container:getItems([recursive = false])\n\tContainer* container = getUserdata<Container>(L, 1);\n\tif (!container) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tbool recursive = getBoolean(L, 2, false);\n\tstd::vector<Item*> items = container->getItems(recursive);\n\n\tlua_createtable(L, items.size(), 0);\n\n\tint index = 0;\n\tfor (Item* item : items) {\n\t\tpushUserdata(L, item);\n\t\tsetItemMetatable(L, -1, item);\n\t\tlua_rawseti(L, -2, ++index);\n\t}\n\treturn 1;\n}\n\n// Teleport\nint LuaScriptInterface::luaTeleportCreate(lua_State* L)\n{\n\t// Teleport(uid)\n\tuint32_t id = getNumber<uint32_t>(L, 2);\n\n\tItem* item = getScriptEnv()->getItemByUID(id);\n\tif (item && item->getTeleport()) {\n\t\tpushUserdata(L, item);\n\t\tsetMetatable(L, -1, \"Teleport\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTeleportGetDestination(lua_State* L)\n{\n\t// teleport:getDestination()\n\tTeleport* teleport = getUserdata<Teleport>(L, 1);\n\tif (teleport) {\n\t\tpushPosition(L, teleport->getDestPos());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTeleportSetDestination(lua_State* L)\n{\n\t// teleport:setDestination(position)\n\tTeleport* teleport = getUserdata<Teleport>(L, 1);\n\tif (teleport) {\n\t\tteleport->setDestPos(getPosition(L, 2));\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\n// Creature\nint LuaScriptInterface::luaCreatureCreate(lua_State* L)\n{\n\t// Creature(id or name or userdata)\n\tCreature* creature;\n\tif (isNumber(L, 2)) {\n\t\tcreature = g_game.getCreatureByID(getNumber<uint32_t>(L, 2));\n\t} else if (isString(L, 2)) {\n\t\tcreature = g_game.getCreatureByName(getString(L, 2));\n\t} else if (isUserdata(L, 2)) {\n\t\tLuaDataType type = getUserdataType(L, 2);\n\t\tif (type != LuaData_Player && type != LuaData_Monster && type != LuaData_Npc) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\t\tcreature = getUserdata<Creature>(L, 2);\n\t} else {\n\t\tcreature = nullptr;\n\t}\n\n\tif (creature) {\n\t\tpushUserdata<Creature>(L, creature);\n\t\tsetCreatureMetatable(L, -1, creature);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureGetEvents(lua_State* L)\n{\n\t// creature:getEvents(type)\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (!creature) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tCreatureEventType_t eventType = getNumber<CreatureEventType_t>(L, 2);\n\tconst auto& eventList = creature->getCreatureEvents(eventType);\n\tlua_createtable(L, eventList.size(), 0);\n\n\tint index = 0;\n\tfor (CreatureEvent* event : eventList) {\n\t\tpushString(L, event->getName());\n\t\tlua_rawseti(L, -2, ++index);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureRegisterEvent(lua_State* L)\n{\n\t// creature:registerEvent(name)\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (creature) {\n\t\tconst std::string& name = getString(L, 2);\n\t\tpushBoolean(L, creature->registerCreatureEvent(name));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureUnregisterEvent(lua_State* L)\n{\n\t// creature:unregisterEvent(name)\n\tconst std::string& name = getString(L, 2);\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (creature) {\n\t\tpushBoolean(L, creature->unregisterCreatureEvent(name));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureIsRemoved(lua_State* L)\n{\n\t// creature:isRemoved()\n\tconst Creature* creature = getUserdata<const Creature>(L, 1);\n\tif (creature) {\n\t\tpushBoolean(L, creature->isRemoved());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureIsCreature(lua_State* L)\n{\n\t// creature:isCreature()\n\tpushBoolean(L, getUserdata<const Creature>(L, 1) != nullptr);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureIsInGhostMode(lua_State* L)\n{\n\t// creature:isInGhostMode()\n\tconst Creature* creature = getUserdata<const Creature>(L, 1);\n\tif (creature) {\n\t\tpushBoolean(L, creature->isInGhostMode());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureIsHealthHidden(lua_State* L)\n{\n\t// creature:isHealthHidden()\n\tconst Creature* creature = getUserdata<const Creature>(L, 1);\n\tif (creature) {\n\t\tpushBoolean(L, creature->isHealthHidden());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureCanSee(lua_State* L)\n{\n\t// creature:canSee(position)\n\tconst Creature* creature = getUserdata<const Creature>(L, 1);\n\tif (creature) {\n\t\tconst Position& position = getPosition(L, 2);\n\t\tpushBoolean(L, creature->canSee(position));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureCanSeeCreature(lua_State* L)\n{\n\t// creature:canSeeCreature(creature)\n\tconst Creature* creature = getUserdata<const Creature>(L, 1);\n\tif (creature) {\n\t\tconst Creature* otherCreature = getCreature(L, 2);\n\t\tpushBoolean(L, creature->canSeeCreature(otherCreature));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureGetParent(lua_State* L)\n{\n\t// creature:getParent()\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (!creature) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tCylinder* parent = creature->getParent();\n\tif (!parent) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tpushCylinder(L, parent);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureGetId(lua_State* L)\n{\n\t// creature:getId()\n\tconst Creature* creature = getUserdata<const Creature>(L, 1);\n\tif (creature) {\n\t\tlua_pushnumber(L, creature->getID());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureGetName(lua_State* L)\n{\n\t// creature:getName()\n\tconst Creature* creature = getUserdata<const Creature>(L, 1);\n\tif (creature) {\n\t\tpushString(L, creature->getName());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureGetTarget(lua_State* L)\n{\n\t// creature:getTarget()\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (!creature) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tCreature* target = creature->getAttackedCreature();\n\tif (target) {\n\t\tpushUserdata<Creature>(L, target);\n\t\tsetCreatureMetatable(L, -1, target);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureSetTarget(lua_State* L)\n{\n\t// creature:setTarget(target)\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (creature) {\n\t\tCreature* target = getCreature(L, 2);\n\t\tpushBoolean(L, creature->setAttackedCreature(target));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureGetFollowCreature(lua_State* L)\n{\n\t// creature:getFollowCreature()\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (!creature) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tCreature* followCreature = creature->getFollowCreature();\n\tif (followCreature) {\n\t\tpushUserdata<Creature>(L, followCreature);\n\t\tsetCreatureMetatable(L, -1, followCreature);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureSetFollowCreature(lua_State* L)\n{\n\t// creature:setFollowCreature(followedCreature)\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (creature) {\n\t\tCreature* followCreature = getCreature(L, 2);\n\t\tpushBoolean(L, creature->setFollowCreature(followCreature));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureGetMaster(lua_State* L)\n{\n\t// creature:getMaster()\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (!creature) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tCreature* master = creature->getMaster();\n\tif (!master) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tpushUserdata<Creature>(L, master);\n\tsetCreatureMetatable(L, -1, master);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureSetMaster(lua_State* L)\n{\n\t// creature:setMaster(master)\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (!creature) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tpushBoolean(L, creature->setMaster(getCreature(L, 2)));\n\tg_game.updateCreatureType(creature);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureGetLight(lua_State* L)\n{\n\t// creature:getLight()\n\tconst Creature* creature = getUserdata<const Creature>(L, 1);\n\tif (!creature) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tLightInfo lightInfo = creature->getCreatureLight();\n\tlua_pushnumber(L, lightInfo.level);\n\tlua_pushnumber(L, lightInfo.color);\n\treturn 2;\n}\n\nint LuaScriptInterface::luaCreatureSetLight(lua_State* L)\n{\n\t// creature:setLight(color, level)\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (!creature) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tLightInfo light;\n\tlight.color = getNumber<uint8_t>(L, 2);\n\tlight.level = getNumber<uint8_t>(L, 3);\n\tcreature->setCreatureLight(light);\n\tg_game.changeLight(creature);\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureGetSpeed(lua_State* L)\n{\n\t// creature:getSpeed()\n\tconst Creature* creature = getUserdata<const Creature>(L, 1);\n\tif (creature) {\n\t\tlua_pushnumber(L, creature->getSpeed());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureGetBaseSpeed(lua_State* L)\n{\n\t// creature:getBaseSpeed()\n\tconst Creature* creature = getUserdata<const Creature>(L, 1);\n\tif (creature) {\n\t\tlua_pushnumber(L, creature->getBaseSpeed());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureChangeSpeed(lua_State* L)\n{\n\t// creature:changeSpeed(delta)\n\tCreature* creature = getCreature(L, 1);\n\tif (!creature) {\n\t\treportErrorFunc(getErrorDesc(LUA_ERROR_CREATURE_NOT_FOUND));\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tint32_t delta = getNumber<int32_t>(L, 2);\n\tg_game.changeSpeed(creature, delta);\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureSetDropLoot(lua_State* L)\n{\n\t// creature:setDropLoot(doDrop)\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (creature) {\n\t\tcreature->setDropLoot(getBoolean(L, 2));\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureSetSkillLoss(lua_State* L)\n{\n\t// creature:setSkillLoss(skillLoss)\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (creature) {\n\t\tcreature->setSkillLoss(getBoolean(L, 2));\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureGetPosition(lua_State* L)\n{\n\t// creature:getPosition()\n\tconst Creature* creature = getUserdata<const Creature>(L, 1);\n\tif (creature) {\n\t\tpushPosition(L, creature->getPosition());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureGetTile(lua_State* L)\n{\n\t// creature:getTile()\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (!creature) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tTile* tile = creature->getTile();\n\tif (tile) {\n\t\tpushUserdata<Tile>(L, tile);\n\t\tsetMetatable(L, -1, \"Tile\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureGetDirection(lua_State* L)\n{\n\t// creature:getDirection()\n\tconst Creature* creature = getUserdata<const Creature>(L, 1);\n\tif (creature) {\n\t\tlua_pushnumber(L, creature->getDirection());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureSetDirection(lua_State* L)\n{\n\t// creature:setDirection(direction)\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (creature) {\n\t\tpushBoolean(L, g_game.internalCreatureTurn(creature, getNumber<Direction>(L, 2)));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureGetHealth(lua_State* L)\n{\n\t// creature:getHealth()\n\tconst Creature* creature = getUserdata<const Creature>(L, 1);\n\tif (creature) {\n\t\tlua_pushnumber(L, creature->getHealth());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureSetHealth(lua_State* L)\n{\n\t// creature:setHealth(health)\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (!creature) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tcreature->health = std::min<int32_t>(getNumber<uint32_t>(L, 2), creature->healthMax);\n\tg_game.addCreatureHealth(creature);\n\n\tPlayer* player = creature->getPlayer();\n\tif (player) {\n\t\tplayer->sendStats();\n\t}\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureAddHealth(lua_State* L)\n{\n\t// creature:addHealth(healthChange)\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (!creature) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tCombatDamage damage;\n\tdamage.primary.value = getNumber<int32_t>(L, 2);\n\tif (damage.primary.value >= 0) {\n\t\tdamage.primary.type = COMBAT_HEALING;\n\t} else {\n\t\tdamage.primary.type = COMBAT_UNDEFINEDDAMAGE;\n\t}\n\tpushBoolean(L, g_game.combatChangeHealth(nullptr, creature, damage));\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureGetMaxHealth(lua_State* L)\n{\n\t// creature:getMaxHealth()\n\tconst Creature* creature = getUserdata<const Creature>(L, 1);\n\tif (creature) {\n\t\tlua_pushnumber(L, creature->getMaxHealth());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureSetMaxHealth(lua_State* L)\n{\n\t// creature:setMaxHealth(maxHealth)\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (!creature) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tcreature->healthMax = getNumber<uint32_t>(L, 2);\n\tcreature->health = std::min<int32_t>(creature->health, creature->healthMax);\n\tg_game.addCreatureHealth(creature);\n\n\tPlayer* player = creature->getPlayer();\n\tif (player) {\n\t\tplayer->sendStats();\n\t}\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureSetHiddenHealth(lua_State* L)\n{\n\t// creature:setHiddenHealth(hide)\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (creature) {\n\t\tcreature->setHiddenHealth(getBoolean(L, 2));\n\t\tg_game.addCreatureHealth(creature);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureGetSkull(lua_State* L)\n{\n\t// creature:getSkull()\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (creature) {\n\t\tlua_pushnumber(L, creature->getSkull());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureSetSkull(lua_State* L)\n{\n\t// creature:setSkull(skull)\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (creature) {\n\t\tcreature->setSkull(getNumber<Skulls_t>(L, 2));\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureGetOutfit(lua_State* L)\n{\n\t// creature:getOutfit()\n\tconst Creature* creature = getUserdata<const Creature>(L, 1);\n\tif (creature) {\n\t\tpushOutfit(L, creature->getCurrentOutfit());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureSetOutfit(lua_State* L)\n{\n\t// creature:setOutfit(outfit)\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (creature) {\n\t\tcreature->defaultOutfit = getOutfit(L, 2);\n\t\tg_game.internalCreatureChangeOutfit(creature, creature->defaultOutfit);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureGetCondition(lua_State* L)\n{\n\t// creature:getCondition(conditionType[, conditionId = CONDITIONID_COMBAT[, subId = 0]])\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (!creature) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tConditionType_t conditionType = getNumber<ConditionType_t>(L, 2);\n\tConditionId_t conditionId = getNumber<ConditionId_t>(L, 3, CONDITIONID_COMBAT);\n\tuint32_t subId = getNumber<uint32_t>(L, 4, 0);\n\n\tCondition* condition = creature->getCondition(conditionType, conditionId, subId);\n\tif (condition) {\n\t\tpushUserdata<Condition>(L, condition);\n\t\tsetWeakMetatable(L, -1, \"Condition\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureAddCondition(lua_State* L)\n{\n\t// creature:addCondition(condition[, force = false])\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tCondition* condition = getUserdata<Condition>(L, 2);\n\tif (creature && condition) {\n\t\tbool force = getBoolean(L, 3, false);\n\t\tpushBoolean(L, creature->addCondition(condition->clone(), force));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureRemoveCondition(lua_State* L)\n{\n\t// creature:removeCondition(conditionType[, conditionId = CONDITIONID_COMBAT[, subId = 0[, force = false]]])\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (!creature) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tConditionType_t conditionType = getNumber<ConditionType_t>(L, 2);\n\tConditionId_t conditionId = getNumber<ConditionId_t>(L, 3, CONDITIONID_COMBAT);\n\tuint32_t subId = getNumber<uint32_t>(L, 4, 0);\n\tCondition* condition = creature->getCondition(conditionType, conditionId, subId);\n\tif (condition) {\n\t\tbool force = getBoolean(L, 5, false);\n\t\tcreature->removeCondition(condition, force);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureHasCondition(lua_State* L)\n{\n\t// creature:hasCondition(conditionType[, subId = 0])\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (!creature) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tConditionType_t conditionType = getNumber<ConditionType_t>(L, 2);\n\tuint32_t subId = getNumber<uint32_t>(L, 3, 0);\n\tpushBoolean(L, creature->hasCondition(conditionType, subId));\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureIsImmune(lua_State* L)\n{\n\t// creature:isImmune(condition or conditionType)\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (!creature) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tif (isNumber(L, 2)) {\n\t\tpushBoolean(L, creature->isImmune(getNumber<ConditionType_t>(L, 2)));\n\t} else if (Condition* condition = getUserdata<Condition>(L, 2)) {\n\t\tpushBoolean(L, creature->isImmune(condition->getType()));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureRemove(lua_State* L)\n{\n\t// creature:remove()\n\tCreature** creaturePtr = getRawUserdata<Creature>(L, 1);\n\tif (!creaturePtr) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tCreature* creature = *creaturePtr;\n\tif (!creature) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tPlayer* player = creature->getPlayer();\n\tif (player) {\n\t\tplayer->kickPlayer(true);\n\t} else {\n\t\tg_game.removeCreature(creature);\n\t}\n\n\t*creaturePtr = nullptr;\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureTeleportTo(lua_State* L)\n{\n\t// creature:teleportTo(position[, pushMovement = false])\n\tbool pushMovement = getBoolean(L, 3, false);\n\n\tconst Position& position = getPosition(L, 2);\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (!creature) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tconst Position oldPosition = creature->getPosition();\n\tif (g_game.internalTeleport(creature, position, pushMovement) != RETURNVALUE_NOERROR) {\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tif (pushMovement) {\n\t\tif (oldPosition.x == position.x) {\n\t\t\tif (oldPosition.y < position.y) {\n\t\t\t\tg_game.internalCreatureTurn(creature, DIRECTION_SOUTH);\n\t\t\t} else {\n\t\t\t\tg_game.internalCreatureTurn(creature, DIRECTION_NORTH);\n\t\t\t}\n\t\t} else if (oldPosition.x > position.x) {\n\t\t\tg_game.internalCreatureTurn(creature, DIRECTION_WEST);\n\t\t} else if (oldPosition.x < position.x) {\n\t\t\tg_game.internalCreatureTurn(creature, DIRECTION_EAST);\n\t\t}\n\t}\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureSay(lua_State* L)\n{\n\t// creature:say(text[, type = TALKTYPE_MONSTER_SAY[, ghost = false[, target = nullptr[, position]]]])\n\tint parameters = lua_gettop(L);\n\n\tPosition position;\n\tif (parameters >= 6) {\n\t\tposition = getPosition(L, 6);\n\t\tif (!position.x || !position.y) {\n\t\t\treportErrorFunc(\"Invalid position specified.\");\n\t\t\tpushBoolean(L, false);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tCreature* target = nullptr;\n\tif (parameters >= 5) {\n\t\ttarget = getCreature(L, 5);\n\t}\n\n\tbool ghost = getBoolean(L, 4, false);\n\n\tSpeakClasses type = getNumber<SpeakClasses>(L, 3, TALKTYPE_MONSTER_SAY);\n\tconst std::string& text = getString(L, 2);\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (!creature) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tSpectatorVec spectators;\n\tif (target) {\n\t\tspectators.emplace_back(target);\n\t}\n\n\tif (position.x != 0) {\n\t\tpushBoolean(L, g_game.internalCreatureSay(creature, type, text, ghost, &spectators, &position));\n\t} else {\n\t\tpushBoolean(L, g_game.internalCreatureSay(creature, type, text, ghost, &spectators));\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureGetDamageMap(lua_State* L)\n{\n\t// creature:getDamageMap()\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (!creature) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tlua_createtable(L, creature->damageMap.size(), 0);\n\tfor (auto damageEntry : creature->damageMap) {\n\t\tlua_createtable(L, 0, 2);\n\t\tsetField(L, \"total\", damageEntry.second.total);\n\t\tsetField(L, \"ticks\", damageEntry.second.ticks);\n\t\tlua_rawseti(L, -2, damageEntry.first);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureGetSummons(lua_State* L)\n{\n\t// creature:getSummons()\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (!creature) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tlua_createtable(L, creature->getSummonCount(), 0);\n\n\tint index = 0;\n\tfor (Creature* summon : creature->getSummons()) {\n\t\tpushUserdata<Creature>(L, summon);\n\t\tsetCreatureMetatable(L, -1, summon);\n\t\tlua_rawseti(L, -2, ++index);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureGetDescription(lua_State* L)\n{\n\t// creature:getDescription(distance)\n\tint32_t distance = getNumber<int32_t>(L, 2);\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (creature) {\n\t\tpushString(L, creature->getDescription(distance));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureGetPathTo(lua_State* L)\n{\n\t// creature:getPathTo(pos[, minTargetDist = 0[, maxTargetDist = 1[, fullPathSearch = true[, clearSight = true[, maxSearchDist = 0]]]]])\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (!creature) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tconst Position& position = getPosition(L, 2);\n\n\tFindPathParams fpp;\n\tfpp.minTargetDist = getNumber<int32_t>(L, 3, 0);\n\tfpp.maxTargetDist = getNumber<int32_t>(L, 4, 1);\n\tfpp.fullPathSearch = getBoolean(L, 5, fpp.fullPathSearch);\n\tfpp.clearSight = getBoolean(L, 6, fpp.clearSight);\n\tfpp.maxSearchDist = getNumber<int32_t>(L, 7, fpp.maxSearchDist);\n\n\tstd::forward_list<Direction> dirList;\n\tif (creature->getPathTo(position, dirList, fpp)) {\n\t\tlua_newtable(L);\n\n\t\tint index = 0;\n\t\tfor (Direction dir : dirList) {\n\t\t\tlua_pushnumber(L, dir);\n\t\t\tlua_rawseti(L, -2, ++index);\n\t\t}\n\t} else {\n\t\tpushBoolean(L, false);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureMove(lua_State* L)\n{\n\t// creature:move(direction)\n\t// creature:move(tile[, flags = 0])\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (!creature) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tif (isNumber(L, 2)) {\n\t\tDirection direction = getNumber<Direction>(L, 2);\n\t\tif (direction > DIRECTION_LAST) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\t\tlua_pushnumber(L, g_game.internalMoveCreature(creature, direction, FLAG_NOLIMIT));\n\t} else {\n\t\tTile* tile = getUserdata<Tile>(L, 2);\n\t\tif (!tile) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\t\tlua_pushnumber(L, g_game.internalMoveCreature(*creature, *tile, getNumber<uint32_t>(L, 3)));\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureGetZone(lua_State* L)\n{\n\t// creature:getZone()\n\tCreature* creature = getUserdata<Creature>(L, 1);\n\tif (creature) {\n\t\tlua_pushnumber(L, creature->getZone());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\n// Player\nint LuaScriptInterface::luaPlayerCreate(lua_State* L)\n{\n\t// Player(id or guid or name or userdata)\n\tPlayer* player;\n\tif (isNumber(L, 2)) {\n\t\tuint32_t id = getNumber<uint32_t>(L, 2);\n\t\tif (id >= 0x10000000 && id <= Player::playerAutoID) {\n\t\t\tplayer = g_game.getPlayerByID(id);\n\t\t} else {\n\t\t\tplayer = g_game.getPlayerByGUID(id);\n\t\t}\n\t} else if (isString(L, 2)) {\n\t\tReturnValue ret = g_game.getPlayerByNameWildcard(getString(L, 2), player);\n\t\tif (ret != RETURNVALUE_NOERROR) {\n\t\t\tlua_pushnil(L);\n\t\t\tlua_pushnumber(L, ret);\n\t\t\treturn 2;\n\t\t}\n\t} else if (isUserdata(L, 2)) {\n\t\tif (getUserdataType(L, 2) != LuaData_Player) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\t\tplayer = getUserdata<Player>(L, 2);\n\t} else {\n\t\tplayer = nullptr;\n\t}\n\n\tif (player) {\n\t\tpushUserdata<Player>(L, player);\n\t\tsetMetatable(L, -1, \"Player\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerIsPlayer(lua_State* L)\n{\n\t// player:isPlayer()\n\tpushBoolean(L, getUserdata<const Player>(L, 1) != nullptr);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetGuid(lua_State* L)\n{\n\t// player:getGuid()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tlua_pushnumber(L, player->getGUID());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetIp(lua_State* L)\n{\n\t// player:getIp()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tlua_pushnumber(L, player->getIP());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetAccountId(lua_State* L)\n{\n\t// player:getAccountId()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tlua_pushnumber(L, player->getAccount());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetLastLoginSaved(lua_State* L)\n{\n\t// player:getLastLoginSaved()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tlua_pushnumber(L, player->getLastLoginSaved());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetLastLogout(lua_State* L)\n{\n\t// player:getLastLogout()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tlua_pushnumber(L, player->getLastLogout());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetAccountType(lua_State* L)\n{\n\t// player:getAccountType()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tlua_pushnumber(L, player->getAccountType());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerSetAccountType(lua_State* L)\n{\n\t// player:setAccountType(accountType)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tplayer->accountType = getNumber<AccountType_t>(L, 2);\n\t\tIOLoginData::setAccountType(player->getAccount(), player->accountType);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetCapacity(lua_State* L)\n{\n\t// player:getCapacity()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tlua_pushnumber(L, player->getCapacity());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerSetCapacity(lua_State* L)\n{\n\t// player:setCapacity(capacity)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tplayer->capacity = getNumber<uint32_t>(L, 2);\n\t\tplayer->sendStats();\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetFreeCapacity(lua_State* L)\n{\n\t// player:getFreeCapacity()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tlua_pushnumber(L, player->getFreeCapacity());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetDepotChest(lua_State* L)\n{\n\t// player:getDepotChest(depotId[, autoCreate = false])\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tuint32_t depotId = getNumber<uint32_t>(L, 2);\n\tbool autoCreate = getBoolean(L, 3, false);\n\tDepotChest* depotChest = player->getDepotChest(depotId, autoCreate);\n\tif (depotChest) {\n\t\tplayer->setLastDepotId(depotId); // FIXME: workaround for #2251\n\t\tpushUserdata<Item>(L, depotChest);\n\t\tsetItemMetatable(L, -1, depotChest);\n\t} else {\n\t\tpushBoolean(L, false);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetInbox(lua_State* L)\n{\n\t// player:getInbox()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tInbox* inbox = player->getInbox();\n\tif (inbox) {\n\t\tpushUserdata<Item>(L, inbox);\n\t\tsetItemMetatable(L, -1, inbox);\n\t} else {\n\t\tpushBoolean(L, false);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetSkullTime(lua_State* L)\n{\n\t// player:getSkullTime()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tlua_pushnumber(L, player->getSkullTicks());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerSetSkullTime(lua_State* L)\n{\n\t// player:setSkullTime(skullTime)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tplayer->setSkullTicks(getNumber<int64_t>(L, 2));\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetDeathPenalty(lua_State* L)\n{\n\t// player:getDeathPenalty()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tlua_pushnumber(L, player->getLostPercent() * 100);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetExperience(lua_State* L)\n{\n\t// player:getExperience()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tlua_pushnumber(L, player->getExperience());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerAddExperience(lua_State* L)\n{\n\t// player:addExperience(experience[, sendText = false])\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tint64_t experience = getNumber<int64_t>(L, 2);\n\t\tbool sendText = getBoolean(L, 3, false);\n\t\tplayer->addExperience(nullptr, experience, sendText);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerRemoveExperience(lua_State* L)\n{\n\t// player:removeExperience(experience[, sendText = false])\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tint64_t experience = getNumber<int64_t>(L, 2);\n\t\tbool sendText = getBoolean(L, 3, false);\n\t\tplayer->removeExperience(experience, sendText);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetLevel(lua_State* L)\n{\n\t// player:getLevel()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tlua_pushnumber(L, player->getLevel());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetMagicLevel(lua_State* L)\n{\n\t// player:getMagicLevel()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tlua_pushnumber(L, player->getMagicLevel());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetBaseMagicLevel(lua_State* L)\n{\n\t// player:getBaseMagicLevel()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tlua_pushnumber(L, player->getBaseMagicLevel());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetMana(lua_State* L)\n{\n\t// player:getMana()\n\tconst Player* player = getUserdata<const Player>(L, 1);\n\tif (player) {\n\t\tlua_pushnumber(L, player->getMana());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerAddMana(lua_State* L)\n{\n\t// player:addMana(manaChange[, animationOnLoss = false])\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tint32_t manaChange = getNumber<int32_t>(L, 2);\n\tbool animationOnLoss = getBoolean(L, 3, false);\n\tif (!animationOnLoss && manaChange < 0) {\n\t\tplayer->changeMana(manaChange);\n\t} else {\n\t\tCombatDamage damage;\n\t\tdamage.primary.value = manaChange;\n\t\tdamage.origin = ORIGIN_NONE;\n\t\tg_game.combatChangeMana(nullptr, player, damage);\n\t}\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetMaxMana(lua_State* L)\n{\n\t// player:getMaxMana()\n\tconst Player* player = getUserdata<const Player>(L, 1);\n\tif (player) {\n\t\tlua_pushnumber(L, player->getMaxMana());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerSetMaxMana(lua_State* L)\n{\n\t// player:setMaxMana(maxMana)\n\tPlayer* player = getPlayer(L, 1);\n\tif (player) {\n\t\tplayer->manaMax = getNumber<int32_t>(L, 2);\n\t\tplayer->mana = std::min<int32_t>(player->mana, player->manaMax);\n\t\tplayer->sendStats();\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetManaSpent(lua_State* L)\n{\n\t// player:getManaSpent()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tlua_pushnumber(L, player->getSpentMana());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerAddManaSpent(lua_State* L)\n{\n\t// player:addManaSpent(amount)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tplayer->addManaSpent(getNumber<uint64_t>(L, 2));\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetBaseMaxHealth(lua_State* L)\n{\n\t// player:getBaseMaxHealth()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tlua_pushnumber(L, player->healthMax);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetBaseMaxMana(lua_State* L)\n{\n\t// player:getBaseMaxMana()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tlua_pushnumber(L, player->manaMax);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetSkillLevel(lua_State* L)\n{\n\t// player:getSkillLevel(skillType)\n\tskills_t skillType = getNumber<skills_t>(L, 2);\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player && skillType <= SKILL_LAST) {\n\t\tlua_pushnumber(L, player->skills[skillType].level);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetEffectiveSkillLevel(lua_State* L)\n{\n\t// player:getEffectiveSkillLevel(skillType)\n\tskills_t skillType = getNumber<skills_t>(L, 2);\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player && skillType <= SKILL_LAST) {\n\t\tlua_pushnumber(L, player->getSkillLevel(skillType));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetSkillPercent(lua_State* L)\n{\n\t// player:getSkillPercent(skillType)\n\tskills_t skillType = getNumber<skills_t>(L, 2);\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player && skillType <= SKILL_LAST) {\n\t\tlua_pushnumber(L, player->skills[skillType].percent);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetSkillTries(lua_State* L)\n{\n\t// player:getSkillTries(skillType)\n\tskills_t skillType = getNumber<skills_t>(L, 2);\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player && skillType <= SKILL_LAST) {\n\t\tlua_pushnumber(L, player->skills[skillType].tries);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerAddSkillTries(lua_State* L)\n{\n\t// player:addSkillTries(skillType, tries)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tskills_t skillType = getNumber<skills_t>(L, 2);\n\t\tuint64_t tries = getNumber<uint64_t>(L, 3);\n\t\tplayer->addSkillAdvance(skillType, tries);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetSpecialSkill(lua_State* L)\n{\n\t// player:getSpecialSkill(specialSkillType)\n\tSpecialSkills_t specialSkillType = getNumber<SpecialSkills_t>(L, 2);\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player && specialSkillType <= SPECIALSKILL_LAST) {\n\t\tlua_pushnumber(L, player->getSpecialSkill(specialSkillType));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerAddSpecialSkill(lua_State* L)\n{\n\t// player:addSpecialSkill(specialSkillType, value)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tSpecialSkills_t specialSkillType = getNumber<SpecialSkills_t>(L, 2);\n\tif (specialSkillType > SPECIALSKILL_LAST) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tplayer->setVarSpecialSkill(specialSkillType, getNumber<int32_t>(L, 3));\n\tplayer->sendSkills();\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerAddOfflineTrainingTime(lua_State* L)\n{\n\t// player:addOfflineTrainingTime(time)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tint32_t time = getNumber<int32_t>(L, 2);\n\t\tplayer->addOfflineTrainingTime(time);\n\t\tplayer->sendStats();\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\n\nint LuaScriptInterface::luaPlayerGetOfflineTrainingTime(lua_State* L)\n{\n\t// player:getOfflineTrainingTime()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tlua_pushnumber(L, player->getOfflineTrainingTime());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerRemoveOfflineTrainingTime(lua_State* L)\n{\n\t// player:removeOfflineTrainingTime(time)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tint32_t time = getNumber<int32_t>(L, 2);\n\t\tplayer->removeOfflineTrainingTime(time);\n\t\tplayer->sendStats();\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerAddOfflineTrainingTries(lua_State* L)\n{\n\t// player:addOfflineTrainingTries(skillType, tries)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tskills_t skillType = getNumber<skills_t>(L, 2);\n\t\tuint64_t tries = getNumber<uint64_t>(L, 3);\n\t\tpushBoolean(L, player->addOfflineTrainingTries(skillType, tries));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetOfflineTrainingSkill(lua_State* L)\n{\n\t// player:getOfflineTrainingSkill()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tlua_pushnumber(L, player->getOfflineTrainingSkill());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerSetOfflineTrainingSkill(lua_State* L)\n{\n\t// player:setOfflineTrainingSkill(skillId)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tuint32_t skillId = getNumber<uint32_t>(L, 2);\n\t\tplayer->setOfflineTrainingSkill(skillId);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetItemCount(lua_State* L)\n{\n\t// player:getItemCount(itemId[, subType = -1])\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tuint16_t itemId;\n\tif (isNumber(L, 2)) {\n\t\titemId = getNumber<uint16_t>(L, 2);\n\t} else {\n\t\titemId = Item::items.getItemIdByName(getString(L, 2));\n\t\tif (itemId == 0) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tint32_t subType = getNumber<int32_t>(L, 3, -1);\n\tlua_pushnumber(L, player->getItemTypeCount(itemId, subType));\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetItemById(lua_State* L)\n{\n\t// player:getItemById(itemId, deepSearch[, subType = -1])\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tuint16_t itemId;\n\tif (isNumber(L, 2)) {\n\t\titemId = getNumber<uint16_t>(L, 2);\n\t} else {\n\t\titemId = Item::items.getItemIdByName(getString(L, 2));\n\t\tif (itemId == 0) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\t}\n\tbool deepSearch = getBoolean(L, 3);\n\tint32_t subType = getNumber<int32_t>(L, 4, -1);\n\n\tItem* item = g_game.findItemOfType(player, itemId, deepSearch, subType);\n\tif (item) {\n\t\tpushUserdata<Item>(L, item);\n\t\tsetItemMetatable(L, -1, item);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetVocation(lua_State* L)\n{\n\t// player:getVocation()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tpushUserdata<Vocation>(L, player->getVocation());\n\t\tsetMetatable(L, -1, \"Vocation\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerSetVocation(lua_State* L)\n{\n\t// player:setVocation(id or name or userdata)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tVocation* vocation;\n\tif (isNumber(L, 2)) {\n\t\tvocation = g_vocations.getVocation(getNumber<uint16_t>(L, 2));\n\t} else if (isString(L, 2)) {\n\t\tvocation = g_vocations.getVocation(g_vocations.getVocationId(getString(L, 2)));\n\t} else if (isUserdata(L, 2)) {\n\t\tvocation = getUserdata<Vocation>(L, 2);\n\t} else {\n\t\tvocation = nullptr;\n\t}\n\n\tif (!vocation) {\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tplayer->setVocation(vocation->getId());\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetSex(lua_State* L)\n{\n\t// player:getSex()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tlua_pushnumber(L, player->getSex());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerSetSex(lua_State* L)\n{\n\t// player:setSex(newSex)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tPlayerSex_t newSex = getNumber<PlayerSex_t>(L, 2);\n\t\tplayer->setSex(newSex);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetTown(lua_State* L)\n{\n\t// player:getTown()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tpushUserdata<Town>(L, player->getTown());\n\t\tsetMetatable(L, -1, \"Town\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerSetTown(lua_State* L)\n{\n\t// player:setTown(town)\n\tTown* town = getUserdata<Town>(L, 2);\n\tif (!town) {\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tplayer->setTown(town);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetGuild(lua_State* L)\n{\n\t// player:getGuild()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tGuild* guild = player->getGuild();\n\tif (!guild) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tpushUserdata<Guild>(L, guild);\n\tsetMetatable(L, -1, \"Guild\");\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerSetGuild(lua_State* L)\n{\n\t// player:setGuild(guild)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tplayer->setGuild(getUserdata<Guild>(L, 2));\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetGuildLevel(lua_State* L)\n{\n\t// player:getGuildLevel()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player && player->getGuild()) {\n\t\tlua_pushnumber(L, player->getGuildRank()->level);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerSetGuildLevel(lua_State* L)\n{\n\t// player:setGuildLevel(level)\n\tuint8_t level = getNumber<uint8_t>(L, 2);\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player || !player->getGuild()) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tGuildRank_ptr rank = player->getGuild()->getRankByLevel(level);\n\tif (!rank) {\n\t\tpushBoolean(L, false);\n\t} else {\n\t\tplayer->setGuildRank(rank);\n\t\tpushBoolean(L, true);\n\t}\n\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetGuildNick(lua_State* L)\n{\n\t// player:getGuildNick()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tpushString(L, player->getGuildNick());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerSetGuildNick(lua_State* L)\n{\n\t// player:setGuildNick(nick)\n\tconst std::string& nick = getString(L, 2);\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tplayer->setGuildNick(nick);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetGroup(lua_State* L)\n{\n\t// player:getGroup()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tpushUserdata<Group>(L, player->getGroup());\n\t\tsetMetatable(L, -1, \"Group\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerSetGroup(lua_State* L)\n{\n\t// player:setGroup(group)\n\tGroup* group = getUserdata<Group>(L, 2);\n\tif (!group) {\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tplayer->setGroup(group);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetStamina(lua_State* L)\n{\n\t// player:getStamina()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tlua_pushnumber(L, player->getStaminaMinutes());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerSetStamina(lua_State* L)\n{\n\t// player:setStamina(stamina)\n\tuint16_t stamina = getNumber<uint16_t>(L, 2);\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tplayer->staminaMinutes = std::min<uint16_t>(2520, stamina);\n\t\tplayer->sendStats();\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetSoul(lua_State* L)\n{\n\t// player:getSoul()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tlua_pushnumber(L, player->getSoul());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerAddSoul(lua_State* L)\n{\n\t// player:addSoul(soulChange)\n\tint32_t soulChange = getNumber<int32_t>(L, 2);\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tplayer->changeSoul(soulChange);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetMaxSoul(lua_State* L)\n{\n\t// player:getMaxSoul()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player && player->vocation) {\n\t\tlua_pushnumber(L, player->vocation->getSoulMax());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetBankBalance(lua_State* L)\n{\n\t// player:getBankBalance()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tlua_pushnumber(L, player->getBankBalance());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerSetBankBalance(lua_State* L)\n{\n\t// player:setBankBalance(bankBalance)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tint64_t balance = getNumber<int64_t>(L, 2);\n\tif (balance < 0) {\n\t\treportErrorFunc(\"Invalid bank balance value.\");\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tplayer->setBankBalance(balance);\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetStorageValue(lua_State* L)\n{\n\t// player:getStorageValue(key)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tuint32_t key = getNumber<uint32_t>(L, 2);\n\tint32_t value;\n\tif (player->getStorageValue(key, value)) {\n\t\tlua_pushnumber(L, value);\n\t} else {\n\t\tlua_pushnumber(L, -1);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerSetStorageValue(lua_State* L)\n{\n\t// player:setStorageValue(key, value)\n\tint32_t value = getNumber<int32_t>(L, 3);\n\tuint32_t key = getNumber<uint32_t>(L, 2);\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (IS_IN_KEYRANGE(key, RESERVED_RANGE)) {\n\t\tstd::ostringstream ss;\n\t\tss << \"Accessing reserved range: \" << key;\n\t\treportErrorFunc(ss.str());\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tif (player) {\n\t\tplayer->addStorageValue(key, value);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerAddItem(lua_State* L)\n{\n\t// player:addItem(itemId[, count = 1[, canDropOnMap = true[, subType = 1[, slot = CONST_SLOT_WHEREEVER]]]])\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tuint16_t itemId;\n\tif (isNumber(L, 2)) {\n\t\titemId = getNumber<uint16_t>(L, 2);\n\t} else {\n\t\titemId = Item::items.getItemIdByName(getString(L, 2));\n\t\tif (itemId == 0) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tint32_t count = getNumber<int32_t>(L, 3, 1);\n\tint32_t subType = getNumber<int32_t>(L, 5, 1);\n\n\tconst ItemType& it = Item::items[itemId];\n\n\tint32_t itemCount = 1;\n\tint parameters = lua_gettop(L);\n\tif (parameters >= 4) {\n\t\titemCount = std::max<int32_t>(1, count);\n\t} else if (it.hasSubType()) {\n\t\tif (it.stackable) {\n\t\t\titemCount = std::ceil(count / 100.f);\n\t\t}\n\n\t\tsubType = count;\n\t} else {\n\t\titemCount = std::max<int32_t>(1, count);\n\t}\n\n\tbool hasTable = itemCount > 1;\n\tif (hasTable) {\n\t\tlua_newtable(L);\n\t} else if (itemCount == 0) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tbool canDropOnMap = getBoolean(L, 4, true);\n\tslots_t slot = getNumber<slots_t>(L, 6, CONST_SLOT_WHEREEVER);\n\tfor (int32_t i = 1; i <= itemCount; ++i) {\n\t\tint32_t stackCount = subType;\n\t\tif (it.stackable) {\n\t\t\tstackCount = std::min<int32_t>(stackCount, 100);\n\t\t\tsubType -= stackCount;\n\t\t}\n\n\t\tItem* item = Item::CreateItem(itemId, stackCount);\n\t\tif (!item) {\n\t\t\tif (!hasTable) {\n\t\t\t\tlua_pushnil(L);\n\t\t\t}\n\t\t\treturn 1;\n\t\t}\n\n\t\tReturnValue ret = g_game.internalPlayerAddItem(player, item, canDropOnMap, slot);\n\t\tif (ret != RETURNVALUE_NOERROR) {\n\t\t\tdelete item;\n\t\t\tif (!hasTable) {\n\t\t\t\tlua_pushnil(L);\n\t\t\t}\n\t\t\treturn 1;\n\t\t}\n\n\t\tif (hasTable) {\n\t\t\tlua_pushnumber(L, i);\n\t\t\tpushUserdata<Item>(L, item);\n\t\t\tsetItemMetatable(L, -1, item);\n\t\t\tlua_settable(L, -3);\n\t\t} else {\n\t\t\tpushUserdata<Item>(L, item);\n\t\t\tsetItemMetatable(L, -1, item);\n\t\t}\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerAddItemEx(lua_State* L)\n{\n\t// player:addItemEx(item[, canDropOnMap = false[, index = INDEX_WHEREEVER[, flags = 0]]])\n\t// player:addItemEx(item[, canDropOnMap = true[, slot = CONST_SLOT_WHEREEVER]])\n\tItem* item = getUserdata<Item>(L, 2);\n\tif (!item) {\n\t\treportErrorFunc(getErrorDesc(LUA_ERROR_ITEM_NOT_FOUND));\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tif (item->getParent() != VirtualCylinder::virtualCylinder) {\n\t\treportErrorFunc(\"Item already has a parent\");\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tbool canDropOnMap = getBoolean(L, 3, false);\n\tReturnValue returnValue;\n\tif (canDropOnMap) {\n\t\tslots_t slot = getNumber<slots_t>(L, 4, CONST_SLOT_WHEREEVER);\n\t\treturnValue = g_game.internalPlayerAddItem(player, item, true, slot);\n\t} else {\n\t\tint32_t index = getNumber<int32_t>(L, 4, INDEX_WHEREEVER);\n\t\tuint32_t flags = getNumber<uint32_t>(L, 5, 0);\n\t\treturnValue = g_game.internalAddItem(player, item, index, flags);\n\t}\n\n\tif (returnValue == RETURNVALUE_NOERROR) {\n\t\tScriptEnvironment::removeTempItem(item);\n\t}\n\tlua_pushnumber(L, returnValue);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerRemoveItem(lua_State* L)\n{\n\t// player:removeItem(itemId, count[, subType = -1[, ignoreEquipped = false]])\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tuint16_t itemId;\n\tif (isNumber(L, 2)) {\n\t\titemId = getNumber<uint16_t>(L, 2);\n\t} else {\n\t\titemId = Item::items.getItemIdByName(getString(L, 2));\n\t\tif (itemId == 0) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tuint32_t count = getNumber<uint32_t>(L, 3);\n\tint32_t subType = getNumber<int32_t>(L, 4, -1);\n\tbool ignoreEquipped = getBoolean(L, 5, false);\n\tpushBoolean(L, player->removeItemOfType(itemId, count, subType, ignoreEquipped));\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetMoney(lua_State* L)\n{\n\t// player:getMoney()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tlua_pushnumber(L, player->getMoney());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerAddMoney(lua_State* L)\n{\n\t// player:addMoney(money)\n\tuint64_t money = getNumber<uint64_t>(L, 2);\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tg_game.addMoney(player, money);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerRemoveMoney(lua_State* L)\n{\n\t// player:removeMoney(money)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tuint64_t money = getNumber<uint64_t>(L, 2);\n\t\tpushBoolean(L, g_game.removeMoney(player, money));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerShowTextDialog(lua_State* L)\n{\n\t// player:showTextDialog(id or name or userdata[, text[, canWrite[, length]]])\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tint32_t length = getNumber<int32_t>(L, 5, -1);\n\tbool canWrite = getBoolean(L, 4, false);\n\tstd::string text;\n\n\tint parameters = lua_gettop(L);\n\tif (parameters >= 3) {\n\t\ttext = getString(L, 3);\n\t}\n\n\tItem* item;\n\tif (isNumber(L, 2)) {\n\t\titem = Item::CreateItem(getNumber<uint16_t>(L, 2));\n\t} else if (isString(L, 2)) {\n\t\titem = Item::CreateItem(Item::items.getItemIdByName(getString(L, 2)));\n\t} else if (isUserdata(L, 2)) {\n\t\tif (getUserdataType(L, 2) != LuaData_Item) {\n\t\t\tpushBoolean(L, false);\n\t\t\treturn 1;\n\t\t}\n\n\t\titem = getUserdata<Item>(L, 2);\n\t} else {\n\t\titem = nullptr;\n\t}\n\n\tif (!item) {\n\t\treportErrorFunc(getErrorDesc(LUA_ERROR_ITEM_NOT_FOUND));\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tif (length < 0) {\n\t\tlength = Item::items[item->getID()].maxTextLen;\n\t}\n\n\tif (!text.empty()) {\n\t\titem->setText(text);\n\t\tlength = std::max<int32_t>(text.size(), length);\n\t}\n\n\titem->setParent(player);\n\tplayer->setWriteItem(item, length);\n\tplayer->sendTextWindow(item, length, canWrite);\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerSendTextMessage(lua_State* L)\n{\n\t// player:sendTextMessage(type, text[, position, primaryValue = 0, primaryColor = TEXTCOLOR_NONE[, secondaryValue = 0, secondaryColor = TEXTCOLOR_NONE]])\n\t// player:sendTextMessage(type, text, channelId)\n\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tint parameters = lua_gettop(L);\n\n\tTextMessage message(getNumber<MessageClasses>(L, 2), getString(L, 3));\n\tif (parameters == 4) {\n\t\tuint16_t channelId = getNumber<uint16_t>(L, 4);\n\t\tChatChannel* channel = g_chat->getChannel(*player, channelId);\n\t\tif (!channel || !channel->hasUser(*player)) {\n\t\t\tpushBoolean(L, false);\n\t\t\treturn 1;\n\t\t}\n\t\tmessage.channelId = channelId;\n\t} else {\n\t\tif (parameters >= 6) {\n\t\t\tmessage.position = getPosition(L, 4);\n\t\t\tmessage.primary.value = getNumber<int32_t>(L, 5);\n\t\t\tmessage.primary.color = getNumber<TextColor_t>(L, 6);\n\t\t}\n\n\t\tif (parameters >= 8) {\n\t\t\tmessage.secondary.value = getNumber<int32_t>(L, 7);\n\t\t\tmessage.secondary.color = getNumber<TextColor_t>(L, 8);\n\t\t}\n\t}\n\n\tplayer->sendTextMessage(message);\n\tpushBoolean(L, true);\n\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerSendChannelMessage(lua_State* L)\n{\n\t// player:sendChannelMessage(author, text, type, channelId)\n\tuint16_t channelId = getNumber<uint16_t>(L, 5);\n\tSpeakClasses type = getNumber<SpeakClasses>(L, 4);\n\tconst std::string& text = getString(L, 3);\n\tconst std::string& author = getString(L, 2);\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tplayer->sendChannelMessage(author, text, type, channelId);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerSendPrivateMessage(lua_State* L)\n{\n\t// player:sendPrivateMessage(speaker, text[, type])\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tconst Player* speaker = getUserdata<const Player>(L, 2);\n\tconst std::string& text = getString(L, 3);\n\tSpeakClasses type = getNumber<SpeakClasses>(L, 4, TALKTYPE_PRIVATE_FROM);\n\tplayer->sendPrivateMessage(speaker, type, text);\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerChannelSay(lua_State* L)\n{\n\t// player:channelSay(speaker, type, text, channelId)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tCreature* speaker = getCreature(L, 2);\n\tSpeakClasses type = getNumber<SpeakClasses>(L, 3);\n\tconst std::string& text = getString(L, 4);\n\tuint16_t channelId = getNumber<uint16_t>(L, 5);\n\tplayer->sendToChannel(speaker, type, text, channelId);\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerOpenChannel(lua_State* L)\n{\n\t// player:openChannel(channelId)\n\tuint16_t channelId = getNumber<uint16_t>(L, 2);\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tg_game.playerOpenChannel(player->getID(), channelId);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetSlotItem(lua_State* L)\n{\n\t// player:getSlotItem(slot)\n\tconst Player* player = getUserdata<const Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tuint32_t slot = getNumber<uint32_t>(L, 2);\n\tThing* thing = player->getThing(slot);\n\tif (!thing) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tItem* item = thing->getItem();\n\tif (item) {\n\t\tpushUserdata<Item>(L, item);\n\t\tsetItemMetatable(L, -1, item);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetParty(lua_State* L)\n{\n\t// player:getParty()\n\tconst Player* player = getUserdata<const Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tParty* party = player->getParty();\n\tif (party) {\n\t\tpushUserdata<Party>(L, party);\n\t\tsetMetatable(L, -1, \"Party\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerAddOutfit(lua_State* L)\n{\n\t// player:addOutfit(lookType)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tplayer->addOutfit(getNumber<uint16_t>(L, 2), 0);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerAddOutfitAddon(lua_State* L)\n{\n\t// player:addOutfitAddon(lookType, addon)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tuint16_t lookType = getNumber<uint16_t>(L, 2);\n\t\tuint8_t addon = getNumber<uint8_t>(L, 3);\n\t\tplayer->addOutfit(lookType, addon);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerRemoveOutfit(lua_State* L)\n{\n\t// player:removeOutfit(lookType)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tuint16_t lookType = getNumber<uint16_t>(L, 2);\n\t\tpushBoolean(L, player->removeOutfit(lookType));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerRemoveOutfitAddon(lua_State* L)\n{\n\t// player:removeOutfitAddon(lookType, addon)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tuint16_t lookType = getNumber<uint16_t>(L, 2);\n\t\tuint8_t addon = getNumber<uint8_t>(L, 3);\n\t\tpushBoolean(L, player->removeOutfitAddon(lookType, addon));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerHasOutfit(lua_State* L)\n{\n\t// player:hasOutfit(lookType[, addon = 0])\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tuint16_t lookType = getNumber<uint16_t>(L, 2);\n\t\tuint8_t addon = getNumber<uint8_t>(L, 3, 0);\n\t\tpushBoolean(L, player->hasOutfit(lookType, addon));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerCanWearOutfit(lua_State* L)\n{\n\t// player:canWearOutfit(lookType[, addon = 0])\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tuint16_t lookType = getNumber<uint16_t>(L, 2);\n\t\tuint8_t addon = getNumber<uint8_t>(L, 3, 0);\n\t\tpushBoolean(L, player->canWear(lookType, addon));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerSendOutfitWindow(lua_State* L)\n{\n\t// player:sendOutfitWindow()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tplayer->sendOutfitWindow();\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerAddMount(lua_State* L) {\n\t// player:addMount(mountId or mountName)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tuint8_t mountId;\n\tif (isNumber(L, 2)) {\n\t\tmountId = getNumber<uint8_t>(L, 2);\n\t} else {\n\t\tMount* mount = g_game.mounts.getMountByName(getString(L, 2));\n\t\tif (!mount) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\t\tmountId = mount->id;\n\t}\n\tpushBoolean(L, player->tameMount(mountId));\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerRemoveMount(lua_State* L) {\n\t// player:removeMount(mountId or mountName)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tuint8_t mountId;\n\tif (isNumber(L, 2)) {\n\t\tmountId = getNumber<uint8_t>(L, 2);\n\t} else {\n\t\tMount* mount = g_game.mounts.getMountByName(getString(L, 2));\n\t\tif (!mount) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\t\tmountId = mount->id;\n\t}\n\tpushBoolean(L, player->untameMount(mountId));\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerHasMount(lua_State* L) {\n\t// player:hasMount(mountId or mountName)\n\tconst Player* player = getUserdata<const Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tMount* mount = nullptr;\n\tif (isNumber(L, 2)) {\n\t\tmount = g_game.mounts.getMountByID(getNumber<uint8_t>(L, 2));\n\t} else {\n\t\tmount = g_game.mounts.getMountByName(getString(L, 2));\n\t}\n\n\tif (mount) {\n\t\tpushBoolean(L, player->hasMount(mount));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetPremiumEndsAt(lua_State* L)\n{\n\t// player:getPremiumEndsAt()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tlua_pushnumber(L, player->premiumEndsAt);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerSetPremiumEndsAt(lua_State* L)\n{\n\t// player:setPremiumEndsAt(timestamp)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\ttime_t timestamp = getNumber<time_t>(L, 2);\n\n\tplayer->setPremiumTime(timestamp);\n\tIOLoginData::updatePremiumTime(player->getAccount(), timestamp);\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerHasBlessing(lua_State* L)\n{\n\t// player:hasBlessing(blessing)\n\tuint8_t blessing = getNumber<uint8_t>(L, 2) - 1;\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tpushBoolean(L, player->hasBlessing(blessing));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerAddBlessing(lua_State* L)\n{\n\t// player:addBlessing(blessing)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tuint8_t blessing = getNumber<uint8_t>(L, 2) - 1;\n\tif (player->hasBlessing(blessing)) {\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tplayer->addBlessing(1 << blessing);\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerRemoveBlessing(lua_State* L)\n{\n\t// player:removeBlessing(blessing)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tuint8_t blessing = getNumber<uint8_t>(L, 2) - 1;\n\tif (!player->hasBlessing(blessing)) {\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tplayer->removeBlessing(1 << blessing);\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerCanLearnSpell(lua_State* L)\n{\n\t// player:canLearnSpell(spellName)\n\tconst Player* player = getUserdata<const Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tconst std::string& spellName = getString(L, 2);\n\tInstantSpell* spell = g_spells->getInstantSpellByName(spellName);\n\tif (!spell) {\n\t\treportErrorFunc(\"Spell \\\"\" + spellName + \"\\\" not found\");\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tif (player->hasFlag(PlayerFlag_IgnoreSpellCheck)) {\n\t\tpushBoolean(L, true);\n\t\treturn 1;\n\t}\n\n\tconst auto& vocMap = spell->getVocMap();\n\tif (vocMap.count(player->getVocationId()) == 0) {\n\t\tpushBoolean(L, false);\n\t} else if (player->getLevel() < spell->getLevel()) {\n\t\tpushBoolean(L, false);\n\t} else if (player->getMagicLevel() < spell->getMagicLevel()) {\n\t\tpushBoolean(L, false);\n\t} else {\n\t\tpushBoolean(L, true);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerLearnSpell(lua_State* L)\n{\n\t// player:learnSpell(spellName)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tconst std::string& spellName = getString(L, 2);\n\t\tplayer->learnInstantSpell(spellName);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerForgetSpell(lua_State* L)\n{\n\t// player:forgetSpell(spellName)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tconst std::string& spellName = getString(L, 2);\n\t\tplayer->forgetInstantSpell(spellName);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerHasLearnedSpell(lua_State* L)\n{\n\t// player:hasLearnedSpell(spellName)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tconst std::string& spellName = getString(L, 2);\n\t\tpushBoolean(L, player->hasLearnedInstantSpell(spellName));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerSendTutorial(lua_State* L)\n{\n\t// player:sendTutorial(tutorialId)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tuint8_t tutorialId = getNumber<uint8_t>(L, 2);\n\t\tplayer->sendTutorial(tutorialId);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerAddMapMark(lua_State* L)\n{\n\t// player:addMapMark(position, type, description)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tconst Position& position = getPosition(L, 2);\n\t\tuint8_t type = getNumber<uint8_t>(L, 3);\n\t\tconst std::string& description = getString(L, 4);\n\t\tplayer->sendAddMarker(position, type, description);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerSave(lua_State* L)\n{\n\t// player:save()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tplayer->loginPosition = player->getPosition();\n\t\tpushBoolean(L, IOLoginData::savePlayer(player));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerPopupFYI(lua_State* L)\n{\n\t// player:popupFYI(message)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tconst std::string& message = getString(L, 2);\n\t\tplayer->sendFYIBox(message);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerIsPzLocked(lua_State* L)\n{\n\t// player:isPzLocked()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tpushBoolean(L, player->isPzLocked());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetClient(lua_State* L)\n{\n\t// player:getClient()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tlua_createtable(L, 0, 2);\n\t\tsetField(L, \"version\", player->getProtocolVersion());\n\t\tsetField(L, \"os\", player->getOperatingSystem());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetHouse(lua_State* L)\n{\n\t// player:getHouse()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tHouse* house = g_game.map.houses.getHouseByPlayerId(player->getGUID());\n\tif (house) {\n\t\tpushUserdata<House>(L, house);\n\t\tsetMetatable(L, -1, \"House\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerSendHouseWindow(lua_State* L)\n{\n\t// player:sendHouseWindow(house, listId)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tHouse* house = getUserdata<House>(L, 2);\n\tif (!house) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tuint32_t listId = getNumber<uint32_t>(L, 3);\n\tplayer->sendHouseWindow(house, listId);\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerSetEditHouse(lua_State* L)\n{\n\t// player:setEditHouse(house, listId)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tHouse* house = getUserdata<House>(L, 2);\n\tif (!house) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tuint32_t listId = getNumber<uint32_t>(L, 3);\n\tplayer->setEditHouse(house, listId);\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerSetGhostMode(lua_State* L)\n{\n\t// player:setGhostMode(enabled[, showEffect=true])\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tbool enabled = getBoolean(L, 2);\n\tif (player->isInGhostMode() == enabled) {\n\t\tpushBoolean(L, true);\n\t\treturn 1;\n\t}\n\n\tbool showEffect = getBoolean(L, 3, true);\n\n\tplayer->switchGhostMode();\n\n\tTile* tile = player->getTile();\n\tconst Position& position = player->getPosition();\n\n\tSpectatorVec spectators;\n\tg_game.map.getSpectators(spectators, position, true, true);\n\tfor (Creature* spectator : spectators) {\n\t\tPlayer* tmpPlayer = spectator->getPlayer();\n\t\tif (tmpPlayer != player && !tmpPlayer->isAccessPlayer()) {\n\t\t\tif (enabled) {\n\t\t\t\ttmpPlayer->sendRemoveTileThing(position, tile->getStackposOfCreature(tmpPlayer, player));\n\t\t\t} else {\n\t\t\t\ttmpPlayer->sendCreatureAppear(player, position, showEffect);\n\t\t\t}\n\t\t} else {\n\t\t\ttmpPlayer->sendCreatureChangeVisible(player, !enabled);\n\t\t}\n\t}\n\n\tif (player->isInGhostMode()) {\n\t\tfor (const auto& it : g_game.getPlayers()) {\n\t\t\tif (!it.second->isAccessPlayer()) {\n\t\t\t\tit.second->notifyStatusChange(player, VIPSTATUS_OFFLINE);\n\t\t\t}\n\t\t}\n\t\tIOLoginData::updateOnlineStatus(player->getGUID(), false);\n\t} else {\n\t\tfor (const auto& it : g_game.getPlayers()) {\n\t\t\tif (!it.second->isAccessPlayer()) {\n\t\t\t\tit.second->notifyStatusChange(player, VIPSTATUS_ONLINE);\n\t\t\t}\n\t\t}\n\t\tIOLoginData::updateOnlineStatus(player->getGUID(), true);\n\t}\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetContainerId(lua_State* L)\n{\n\t// player:getContainerId(container)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tContainer* container = getUserdata<Container>(L, 2);\n\tif (container) {\n\t\tlua_pushnumber(L, player->getContainerID(container));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetContainerById(lua_State* L)\n{\n\t// player:getContainerById(id)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tContainer* container = player->getContainerByID(getNumber<uint8_t>(L, 2));\n\tif (container) {\n\t\tpushUserdata<Container>(L, container);\n\t\tsetMetatable(L, -1, \"Container\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetContainerIndex(lua_State* L)\n{\n\t// player:getContainerIndex(id)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tlua_pushnumber(L, player->getContainerIndex(getNumber<uint8_t>(L, 2)));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetInstantSpells(lua_State* L)\n{\n\t// player:getInstantSpells()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tstd::vector<const InstantSpell*> spells;\n\tfor (auto& spell : g_spells->getInstantSpells()) {\n\t\tif (spell.second.canCast(player)) {\n\t\t\tspells.push_back(&spell.second);\n\t\t}\n\t}\n\n\tlua_createtable(L, spells.size(), 0);\n\n\tint index = 0;\n\tfor (auto spell : spells) {\n\t\tpushInstantSpell(L, *spell);\n\t\tlua_rawseti(L, -2, ++index);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerCanCast(lua_State* L)\n{\n\t// player:canCast(spell)\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tInstantSpell* spell = getUserdata<InstantSpell>(L, 2);\n\tif (player && spell) {\n\t\tpushBoolean(L, spell->canCast(player));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerHasChaseMode(lua_State* L)\n{\n\t// player:hasChaseMode()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tpushBoolean(L, player->chaseMode);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerHasSecureMode(lua_State* L)\n{\n\t// player:hasSecureMode()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tpushBoolean(L, player->secureMode);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetFightMode(lua_State* L)\n{\n\t// player:getFightMode()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (player) {\n\t\tlua_pushnumber(L, player->fightMode);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPlayerGetStoreInbox(lua_State* L)\n{\n\t// player:getStoreInbox()\n\tPlayer* player = getUserdata<Player>(L, 1);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tContainer* storeInbox = player->getStoreInbox();\n\tif (!storeInbox) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tpushUserdata<Container>(L, storeInbox);\n\tsetMetatable(L, -1, \"Container\");\n\treturn 1;\n}\n\n// Monster\nint LuaScriptInterface::luaMonsterCreate(lua_State* L)\n{\n\t// Monster(id or userdata)\n\tMonster* monster;\n\tif (isNumber(L, 2)) {\n\t\tmonster = g_game.getMonsterByID(getNumber<uint32_t>(L, 2));\n\t} else if (isUserdata(L, 2)) {\n\t\tif (getUserdataType(L, 2) != LuaData_Monster) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\t\tmonster = getUserdata<Monster>(L, 2);\n\t} else {\n\t\tmonster = nullptr;\n\t}\n\n\tif (monster) {\n\t\tpushUserdata<Monster>(L, monster);\n\t\tsetMetatable(L, -1, \"Monster\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterIsMonster(lua_State* L)\n{\n\t// monster:isMonster()\n\tpushBoolean(L, getUserdata<const Monster>(L, 1) != nullptr);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterGetType(lua_State* L)\n{\n\t// monster:getType()\n\tconst Monster* monster = getUserdata<const Monster>(L, 1);\n\tif (monster) {\n\t\tpushUserdata<MonsterType>(L, monster->mType);\n\t\tsetMetatable(L, -1, \"MonsterType\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterGetSpawnPosition(lua_State* L)\n{\n\t// monster:getSpawnPosition()\n\tconst Monster* monster = getUserdata<const Monster>(L, 1);\n\tif (monster) {\n\t\tpushPosition(L, monster->getMasterPos());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterIsInSpawnRange(lua_State* L)\n{\n\t// monster:isInSpawnRange([position])\n\tMonster* monster = getUserdata<Monster>(L, 1);\n\tif (monster) {\n\t\tpushBoolean(L, monster->isInSpawnRange(lua_gettop(L) >= 2 ? getPosition(L, 2) : monster->getPosition()));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterIsIdle(lua_State* L)\n{\n\t// monster:isIdle()\n\tMonster* monster = getUserdata<Monster>(L, 1);\n\tif (monster) {\n\t\tpushBoolean(L, monster->getIdleStatus());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterSetIdle(lua_State* L)\n{\n\t// monster:setIdle(idle)\n\tMonster* monster = getUserdata<Monster>(L, 1);\n\tif (!monster) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tmonster->setIdle(getBoolean(L, 2));\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterIsTarget(lua_State* L)\n{\n\t// monster:isTarget(creature)\n\tMonster* monster = getUserdata<Monster>(L, 1);\n\tif (monster) {\n\t\tconst Creature* creature = getCreature(L, 2);\n\t\tpushBoolean(L, monster->isTarget(creature));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterIsOpponent(lua_State* L)\n{\n\t// monster:isOpponent(creature)\n\tMonster* monster = getUserdata<Monster>(L, 1);\n\tif (monster) {\n\t\tconst Creature* creature = getCreature(L, 2);\n\t\tpushBoolean(L, monster->isOpponent(creature));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterIsFriend(lua_State* L)\n{\n\t// monster:isFriend(creature)\n\tMonster* monster = getUserdata<Monster>(L, 1);\n\tif (monster) {\n\t\tconst Creature* creature = getCreature(L, 2);\n\t\tpushBoolean(L, monster->isFriend(creature));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterAddFriend(lua_State* L)\n{\n\t// monster:addFriend(creature)\n\tMonster* monster = getUserdata<Monster>(L, 1);\n\tif (monster) {\n\t\tCreature* creature = getCreature(L, 2);\n\t\tmonster->addFriend(creature);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterRemoveFriend(lua_State* L)\n{\n\t// monster:removeFriend(creature)\n\tMonster* monster = getUserdata<Monster>(L, 1);\n\tif (monster) {\n\t\tCreature* creature = getCreature(L, 2);\n\t\tmonster->removeFriend(creature);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterGetFriendList(lua_State* L)\n{\n\t// monster:getFriendList()\n\tMonster* monster = getUserdata<Monster>(L, 1);\n\tif (!monster) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tconst auto& friendList = monster->getFriendList();\n\tlua_createtable(L, friendList.size(), 0);\n\n\tint index = 0;\n\tfor (Creature* creature : friendList) {\n\t\tpushUserdata<Creature>(L, creature);\n\t\tsetCreatureMetatable(L, -1, creature);\n\t\tlua_rawseti(L, -2, ++index);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterGetFriendCount(lua_State* L)\n{\n\t// monster:getFriendCount()\n\tMonster* monster = getUserdata<Monster>(L, 1);\n\tif (monster) {\n\t\tlua_pushnumber(L, monster->getFriendList().size());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterAddTarget(lua_State* L)\n{\n\t// monster:addTarget(creature[, pushFront = false])\n\tMonster* monster = getUserdata<Monster>(L, 1);\n\tif (!monster) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tCreature* creature = getCreature(L, 2);\n\tbool pushFront = getBoolean(L, 3, false);\n\tmonster->addTarget(creature, pushFront);\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterRemoveTarget(lua_State* L)\n{\n\t// monster:removeTarget(creature)\n\tMonster* monster = getUserdata<Monster>(L, 1);\n\tif (!monster) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tmonster->removeTarget(getCreature(L, 2));\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterGetTargetList(lua_State* L)\n{\n\t// monster:getTargetList()\n\tMonster* monster = getUserdata<Monster>(L, 1);\n\tif (!monster) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tconst auto& targetList = monster->getTargetList();\n\tlua_createtable(L, targetList.size(), 0);\n\n\tint index = 0;\n\tfor (Creature* creature : targetList) {\n\t\tpushUserdata<Creature>(L, creature);\n\t\tsetCreatureMetatable(L, -1, creature);\n\t\tlua_rawseti(L, -2, ++index);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterGetTargetCount(lua_State* L)\n{\n\t// monster:getTargetCount()\n\tMonster* monster = getUserdata<Monster>(L, 1);\n\tif (monster) {\n\t\tlua_pushnumber(L, monster->getTargetList().size());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterSelectTarget(lua_State* L)\n{\n\t// monster:selectTarget(creature)\n\tMonster* monster = getUserdata<Monster>(L, 1);\n\tif (monster) {\n\t\tCreature* creature = getCreature(L, 2);\n\t\tpushBoolean(L, monster->selectTarget(creature));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterSearchTarget(lua_State* L)\n{\n\t// monster:searchTarget([searchType = TARGETSEARCH_DEFAULT])\n\tMonster* monster = getUserdata<Monster>(L, 1);\n\tif (monster) {\n\t\tTargetSearchType_t searchType = getNumber<TargetSearchType_t>(L, 2, TARGETSEARCH_DEFAULT);\n\t\tpushBoolean(L, monster->searchTarget(searchType));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\n// Npc\nint LuaScriptInterface::luaNpcCreate(lua_State* L)\n{\n\t// Npc([id or name or userdata])\n\tNpc* npc;\n\tif (lua_gettop(L) >= 2) {\n\t\tif (isNumber(L, 2)) {\n\t\t\tnpc = g_game.getNpcByID(getNumber<uint32_t>(L, 2));\n\t\t} else if (isString(L, 2)) {\n\t\t\tnpc = g_game.getNpcByName(getString(L, 2));\n\t\t} else if (isUserdata(L, 2)) {\n\t\t\tif (getUserdataType(L, 2) != LuaData_Npc) {\n\t\t\t\tlua_pushnil(L);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\tnpc = getUserdata<Npc>(L, 2);\n\t\t} else {\n\t\t\tnpc = nullptr;\n\t\t}\n\t} else {\n\t\tnpc = getScriptEnv()->getNpc();\n\t}\n\n\tif (npc) {\n\t\tpushUserdata<Npc>(L, npc);\n\t\tsetMetatable(L, -1, \"Npc\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaNpcIsNpc(lua_State* L)\n{\n\t// npc:isNpc()\n\tpushBoolean(L, getUserdata<const Npc>(L, 1) != nullptr);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaNpcSetMasterPos(lua_State* L)\n{\n\t// npc:setMasterPos(pos[, radius])\n\tNpc* npc = getUserdata<Npc>(L, 1);\n\tif (!npc) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tconst Position& pos = getPosition(L, 2);\n\tint32_t radius = getNumber<int32_t>(L, 3, 1);\n\tnpc->setMasterPos(pos, radius);\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaNpcGetSpeechBubble(lua_State* L)\n{\n\t// npc:getSpeechBubble()\n\tNpc* npc = getUserdata<Npc>(L, 1);\n\tif (npc) {\n\t\tlua_pushnumber(L, npc->getSpeechBubble());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaNpcSetSpeechBubble(lua_State* L)\n{\n\t// npc:setSpeechBubble(speechBubble)\n\tNpc* npc = getUserdata<Npc>(L, 1);\n\tif (npc) {\n\t\tnpc->setSpeechBubble(getNumber<uint8_t>(L, 2));\n\t}\n\treturn 0;\n}\n\n// Guild\nint LuaScriptInterface::luaGuildCreate(lua_State* L)\n{\n\t// Guild(id)\n\tuint32_t id = getNumber<uint32_t>(L, 2);\n\n\tGuild* guild = g_game.getGuild(id);\n\tif (guild) {\n\t\tpushUserdata<Guild>(L, guild);\n\t\tsetMetatable(L, -1, \"Guild\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGuildGetId(lua_State* L)\n{\n\t// guild:getId()\n\tGuild* guild = getUserdata<Guild>(L, 1);\n\tif (guild) {\n\t\tlua_pushnumber(L, guild->getId());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGuildGetName(lua_State* L)\n{\n\t// guild:getName()\n\tGuild* guild = getUserdata<Guild>(L, 1);\n\tif (guild) {\n\t\tpushString(L, guild->getName());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGuildGetMembersOnline(lua_State* L)\n{\n\t// guild:getMembersOnline()\n\tconst Guild* guild = getUserdata<const Guild>(L, 1);\n\tif (!guild) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tconst auto& members = guild->getMembersOnline();\n\tlua_createtable(L, members.size(), 0);\n\n\tint index = 0;\n\tfor (Player* player : members) {\n\t\tpushUserdata<Player>(L, player);\n\t\tsetMetatable(L, -1, \"Player\");\n\t\tlua_rawseti(L, -2, ++index);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGuildAddRank(lua_State* L)\n{\n\t// guild:addRank(id, name, level)\n\tGuild* guild = getUserdata<Guild>(L, 1);\n\tif (guild) {\n\t\tuint32_t id = getNumber<uint32_t>(L, 2);\n\t\tconst std::string& name = getString(L, 3);\n\t\tuint8_t level = getNumber<uint8_t>(L, 4);\n\t\tguild->addRank(id, name, level);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGuildGetRankById(lua_State* L)\n{\n\t// guild:getRankById(id)\n\tGuild* guild = getUserdata<Guild>(L, 1);\n\tif (!guild) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tuint32_t id = getNumber<uint32_t>(L, 2);\n\tGuildRank_ptr rank = guild->getRankById(id);\n\tif (rank) {\n\t\tlua_createtable(L, 0, 3);\n\t\tsetField(L, \"id\", rank->id);\n\t\tsetField(L, \"name\", rank->name);\n\t\tsetField(L, \"level\", rank->level);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGuildGetRankByLevel(lua_State* L)\n{\n\t// guild:getRankByLevel(level)\n\tconst Guild* guild = getUserdata<const Guild>(L, 1);\n\tif (!guild) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tuint8_t level = getNumber<uint8_t>(L, 2);\n\tGuildRank_ptr rank = guild->getRankByLevel(level);\n\tif (rank) {\n\t\tlua_createtable(L, 0, 3);\n\t\tsetField(L, \"id\", rank->id);\n\t\tsetField(L, \"name\", rank->name);\n\t\tsetField(L, \"level\", rank->level);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGuildGetMotd(lua_State* L)\n{\n\t// guild:getMotd()\n\tGuild* guild = getUserdata<Guild>(L, 1);\n\tif (guild) {\n\t\tpushString(L, guild->getMotd());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGuildSetMotd(lua_State* L)\n{\n\t// guild:setMotd(motd)\n\tconst std::string& motd = getString(L, 2);\n\tGuild* guild = getUserdata<Guild>(L, 1);\n\tif (guild) {\n\t\tguild->setMotd(motd);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\n// Group\nint LuaScriptInterface::luaGroupCreate(lua_State* L)\n{\n\t// Group(id)\n\tuint32_t id = getNumber<uint32_t>(L, 2);\n\n\tGroup* group = g_game.groups.getGroup(id);\n\tif (group) {\n\t\tpushUserdata<Group>(L, group);\n\t\tsetMetatable(L, -1, \"Group\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGroupGetId(lua_State* L)\n{\n\t// group:getId()\n\tGroup* group = getUserdata<Group>(L, 1);\n\tif (group) {\n\t\tlua_pushnumber(L, group->id);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGroupGetName(lua_State* L)\n{\n\t// group:getName()\n\tGroup* group = getUserdata<Group>(L, 1);\n\tif (group) {\n\t\tpushString(L, group->name);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGroupGetFlags(lua_State* L)\n{\n\t// group:getFlags()\n\tGroup* group = getUserdata<Group>(L, 1);\n\tif (group) {\n\t\tlua_pushnumber(L, group->flags);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGroupGetAccess(lua_State* L)\n{\n\t// group:getAccess()\n\tGroup* group = getUserdata<Group>(L, 1);\n\tif (group) {\n\t\tpushBoolean(L, group->access);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGroupGetMaxDepotItems(lua_State* L)\n{\n\t// group:getMaxDepotItems()\n\tGroup* group = getUserdata<Group>(L, 1);\n\tif (group) {\n\t\tlua_pushnumber(L, group->maxDepotItems);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGroupGetMaxVipEntries(lua_State* L)\n{\n\t// group:getMaxVipEntries()\n\tGroup* group = getUserdata<Group>(L, 1);\n\tif (group) {\n\t\tlua_pushnumber(L, group->maxVipEntries);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGroupHasFlag(lua_State* L)\n{\n\t// group:hasFlag(flag)\n\tGroup* group = getUserdata<Group>(L, 1);\n\tif (group) {\n\t\tPlayerFlags flag = getNumber<PlayerFlags>(L, 2);\n\t\tpushBoolean(L, (group->flags & flag) != 0);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\n// Vocation\nint LuaScriptInterface::luaVocationCreate(lua_State* L)\n{\n\t// Vocation(id or name)\n\tuint32_t id;\n\tif (isNumber(L, 2)) {\n\t\tid = getNumber<uint32_t>(L, 2);\n\t} else {\n\t\tid = g_vocations.getVocationId(getString(L, 2));\n\t}\n\n\tVocation* vocation = g_vocations.getVocation(id);\n\tif (vocation) {\n\t\tpushUserdata<Vocation>(L, vocation);\n\t\tsetMetatable(L, -1, \"Vocation\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaVocationGetId(lua_State* L)\n{\n\t// vocation:getId()\n\tVocation* vocation = getUserdata<Vocation>(L, 1);\n\tif (vocation) {\n\t\tlua_pushnumber(L, vocation->getId());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaVocationGetClientId(lua_State* L)\n{\n\t// vocation:getClientId()\n\tVocation* vocation = getUserdata<Vocation>(L, 1);\n\tif (vocation) {\n\t\tlua_pushnumber(L, vocation->getClientId());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaVocationGetName(lua_State* L)\n{\n\t// vocation:getName()\n\tVocation* vocation = getUserdata<Vocation>(L, 1);\n\tif (vocation) {\n\t\tpushString(L, vocation->getVocName());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaVocationGetDescription(lua_State* L)\n{\n\t// vocation:getDescription()\n\tVocation* vocation = getUserdata<Vocation>(L, 1);\n\tif (vocation) {\n\t\tpushString(L, vocation->getVocDescription());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaVocationGetRequiredSkillTries(lua_State* L)\n{\n\t// vocation:getRequiredSkillTries(skillType, skillLevel)\n\tVocation* vocation = getUserdata<Vocation>(L, 1);\n\tif (vocation) {\n\t\tskills_t skillType = getNumber<skills_t>(L, 2);\n\t\tuint16_t skillLevel = getNumber<uint16_t>(L, 3);\n\t\tlua_pushnumber(L, vocation->getReqSkillTries(skillType, skillLevel));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaVocationGetRequiredManaSpent(lua_State* L)\n{\n\t// vocation:getRequiredManaSpent(magicLevel)\n\tVocation* vocation = getUserdata<Vocation>(L, 1);\n\tif (vocation) {\n\t\tuint32_t magicLevel = getNumber<uint32_t>(L, 2);\n\t\tlua_pushnumber(L, vocation->getReqMana(magicLevel));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaVocationGetCapacityGain(lua_State* L)\n{\n\t// vocation:getCapacityGain()\n\tVocation* vocation = getUserdata<Vocation>(L, 1);\n\tif (vocation) {\n\t\tlua_pushnumber(L, vocation->getCapGain());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaVocationGetHealthGain(lua_State* L)\n{\n\t// vocation:getHealthGain()\n\tVocation* vocation = getUserdata<Vocation>(L, 1);\n\tif (vocation) {\n\t\tlua_pushnumber(L, vocation->getHPGain());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaVocationGetHealthGainTicks(lua_State* L)\n{\n\t// vocation:getHealthGainTicks()\n\tVocation* vocation = getUserdata<Vocation>(L, 1);\n\tif (vocation) {\n\t\tlua_pushnumber(L, vocation->getHealthGainTicks());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaVocationGetHealthGainAmount(lua_State* L)\n{\n\t// vocation:getHealthGainAmount()\n\tVocation* vocation = getUserdata<Vocation>(L, 1);\n\tif (vocation) {\n\t\tlua_pushnumber(L, vocation->getHealthGainAmount());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaVocationGetManaGain(lua_State* L)\n{\n\t// vocation:getManaGain()\n\tVocation* vocation = getUserdata<Vocation>(L, 1);\n\tif (vocation) {\n\t\tlua_pushnumber(L, vocation->getManaGain());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaVocationGetManaGainTicks(lua_State* L)\n{\n\t// vocation:getManaGainTicks()\n\tVocation* vocation = getUserdata<Vocation>(L, 1);\n\tif (vocation) {\n\t\tlua_pushnumber(L, vocation->getManaGainTicks());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaVocationGetManaGainAmount(lua_State* L)\n{\n\t// vocation:getManaGainAmount()\n\tVocation* vocation = getUserdata<Vocation>(L, 1);\n\tif (vocation) {\n\t\tlua_pushnumber(L, vocation->getManaGainAmount());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaVocationGetMaxSoul(lua_State* L)\n{\n\t// vocation:getMaxSoul()\n\tVocation* vocation = getUserdata<Vocation>(L, 1);\n\tif (vocation) {\n\t\tlua_pushnumber(L, vocation->getSoulMax());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaVocationGetSoulGainTicks(lua_State* L)\n{\n\t// vocation:getSoulGainTicks()\n\tVocation* vocation = getUserdata<Vocation>(L, 1);\n\tif (vocation) {\n\t\tlua_pushnumber(L, vocation->getSoulGainTicks());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaVocationGetAttackSpeed(lua_State* L)\n{\n\t// vocation:getAttackSpeed()\n\tVocation* vocation = getUserdata<Vocation>(L, 1);\n\tif (vocation) {\n\t\tlua_pushnumber(L, vocation->getAttackSpeed());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaVocationGetBaseSpeed(lua_State* L)\n{\n\t// vocation:getBaseSpeed()\n\tVocation* vocation = getUserdata<Vocation>(L, 1);\n\tif (vocation) {\n\t\tlua_pushnumber(L, vocation->getBaseSpeed());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaVocationGetDemotion(lua_State* L)\n{\n\t// vocation:getDemotion()\n\tVocation* vocation = getUserdata<Vocation>(L, 1);\n\tif (!vocation) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tuint16_t fromId = vocation->getFromVocation();\n\tif (fromId == VOCATION_NONE) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tVocation* demotedVocation = g_vocations.getVocation(fromId);\n\tif (demotedVocation && demotedVocation != vocation) {\n\t\tpushUserdata<Vocation>(L, demotedVocation);\n\t\tsetMetatable(L, -1, \"Vocation\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaVocationGetPromotion(lua_State* L)\n{\n\t// vocation:getPromotion()\n\tVocation* vocation = getUserdata<Vocation>(L, 1);\n\tif (!vocation) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tuint16_t promotedId = g_vocations.getPromotedVocation(vocation->getId());\n\tif (promotedId == VOCATION_NONE) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tVocation* promotedVocation = g_vocations.getVocation(promotedId);\n\tif (promotedVocation && promotedVocation != vocation) {\n\t\tpushUserdata<Vocation>(L, promotedVocation);\n\t\tsetMetatable(L, -1, \"Vocation\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\n// Town\nint LuaScriptInterface::luaTownCreate(lua_State* L)\n{\n\t// Town(id or name)\n\tTown* town;\n\tif (isNumber(L, 2)) {\n\t\ttown = g_game.map.towns.getTown(getNumber<uint32_t>(L, 2));\n\t} else if (isString(L, 2)) {\n\t\ttown = g_game.map.towns.getTown(getString(L, 2));\n\t} else {\n\t\ttown = nullptr;\n\t}\n\n\tif (town) {\n\t\tpushUserdata<Town>(L, town);\n\t\tsetMetatable(L, -1, \"Town\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTownGetId(lua_State* L)\n{\n\t// town:getId()\n\tTown* town = getUserdata<Town>(L, 1);\n\tif (town) {\n\t\tlua_pushnumber(L, town->getID());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTownGetName(lua_State* L)\n{\n\t// town:getName()\n\tTown* town = getUserdata<Town>(L, 1);\n\tif (town) {\n\t\tpushString(L, town->getName());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTownGetTemplePosition(lua_State* L)\n{\n\t// town:getTemplePosition()\n\tTown* town = getUserdata<Town>(L, 1);\n\tif (town) {\n\t\tpushPosition(L, town->getTemplePosition());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\n// House\nint LuaScriptInterface::luaHouseCreate(lua_State* L)\n{\n\t// House(id)\n\tHouse* house = g_game.map.houses.getHouse(getNumber<uint32_t>(L, 2));\n\tif (house) {\n\t\tpushUserdata<House>(L, house);\n\t\tsetMetatable(L, -1, \"House\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaHouseGetId(lua_State* L)\n{\n\t// house:getId()\n\tHouse* house = getUserdata<House>(L, 1);\n\tif (house) {\n\t\tlua_pushnumber(L, house->getId());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaHouseGetName(lua_State* L)\n{\n\t// house:getName()\n\tHouse* house = getUserdata<House>(L, 1);\n\tif (house) {\n\t\tpushString(L, house->getName());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaHouseGetTown(lua_State* L)\n{\n\t// house:getTown()\n\tHouse* house = getUserdata<House>(L, 1);\n\tif (!house) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tTown* town = g_game.map.towns.getTown(house->getTownId());\n\tif (town) {\n\t\tpushUserdata<Town>(L, town);\n\t\tsetMetatable(L, -1, \"Town\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaHouseGetExitPosition(lua_State* L)\n{\n\t// house:getExitPosition()\n\tHouse* house = getUserdata<House>(L, 1);\n\tif (house) {\n\t\tpushPosition(L, house->getEntryPosition());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaHouseGetRent(lua_State* L)\n{\n\t// house:getRent()\n\tHouse* house = getUserdata<House>(L, 1);\n\tif (house) {\n\t\tlua_pushnumber(L, house->getRent());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaHouseGetOwnerGuid(lua_State* L)\n{\n\t// house:getOwnerGuid()\n\tHouse* house = getUserdata<House>(L, 1);\n\tif (house) {\n\t\tlua_pushnumber(L, house->getOwner());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaHouseSetOwnerGuid(lua_State* L)\n{\n\t// house:setOwnerGuid(guid[, updateDatabase = true])\n\tHouse* house = getUserdata<House>(L, 1);\n\tif (house) {\n\t\tuint32_t guid = getNumber<uint32_t>(L, 2);\n\t\tbool updateDatabase = getBoolean(L, 3, true);\n\t\thouse->setOwner(guid, updateDatabase);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaHouseStartTrade(lua_State* L)\n{\n\t// house:startTrade(player, tradePartner)\n\tHouse* house = getUserdata<House>(L, 1);\n\tPlayer* player = getUserdata<Player>(L, 2);\n\tPlayer* tradePartner = getUserdata<Player>(L, 3);\n\n\tif (!player || !tradePartner || !house) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tif (!Position::areInRange<2, 2, 0>(tradePartner->getPosition(), player->getPosition())) {\n\t\tlua_pushnumber(L, RETURNVALUE_TRADEPLAYERFARAWAY);\n\t\treturn 1;\n\t}\n\n\tif (house->getOwner() != player->getGUID()) {\n\t\tlua_pushnumber(L, RETURNVALUE_YOUDONTOWNTHISHOUSE);\n\t\treturn 1;\n\t}\n\n\tif (g_game.map.houses.getHouseByPlayerId(tradePartner->getGUID())) {\n\t\tlua_pushnumber(L, RETURNVALUE_TRADEPLAYERALREADYOWNSAHOUSE);\n\t\treturn 1;\n\t}\n\n\tif (IOLoginData::hasBiddedOnHouse(tradePartner->getGUID())) {\n\t\tlua_pushnumber(L, RETURNVALUE_TRADEPLAYERHIGHESTBIDDER);\n\t\treturn 1;\n\t}\n\n\tItem* transferItem = house->getTransferItem();\n\tif (!transferItem) {\n\t\tlua_pushnumber(L, RETURNVALUE_YOUCANNOTTRADETHISHOUSE);\n\t\treturn 1;\n\t}\n\n\ttransferItem->getParent()->setParent(player);\n\tif (!g_game.internalStartTrade(player, tradePartner, transferItem)) {\n\t\thouse->resetTransferItem();\n\t}\n\n\tlua_pushnumber(L, RETURNVALUE_NOERROR);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaHouseGetBeds(lua_State* L)\n{\n\t// house:getBeds()\n\tHouse* house = getUserdata<House>(L, 1);\n\tif (!house) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tconst auto& beds = house->getBeds();\n\tlua_createtable(L, beds.size(), 0);\n\n\tint index = 0;\n\tfor (BedItem* bedItem : beds) {\n\t\tpushUserdata<Item>(L, bedItem);\n\t\tsetItemMetatable(L, -1, bedItem);\n\t\tlua_rawseti(L, -2, ++index);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaHouseGetBedCount(lua_State* L)\n{\n\t// house:getBedCount()\n\tHouse* house = getUserdata<House>(L, 1);\n\tif (house) {\n\t\tlua_pushnumber(L, house->getBedCount());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaHouseGetDoors(lua_State* L)\n{\n\t// house:getDoors()\n\tHouse* house = getUserdata<House>(L, 1);\n\tif (!house) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tconst auto& doors = house->getDoors();\n\tlua_createtable(L, doors.size(), 0);\n\n\tint index = 0;\n\tfor (Door* door : doors) {\n\t\tpushUserdata<Item>(L, door);\n\t\tsetItemMetatable(L, -1, door);\n\t\tlua_rawseti(L, -2, ++index);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaHouseGetDoorCount(lua_State* L)\n{\n\t// house:getDoorCount()\n\tHouse* house = getUserdata<House>(L, 1);\n\tif (house) {\n\t\tlua_pushnumber(L, house->getDoors().size());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaHouseGetDoorIdByPosition(lua_State* L)\n{\n\t// house:getDoorIdByPosition(position)\n\tHouse* house = getUserdata<House>(L, 1);\n\tif (!house) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tDoor* door = house->getDoorByPosition(getPosition(L, 2));\n\tif (door) {\n\t\tlua_pushnumber(L, door->getDoorId());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaHouseGetTiles(lua_State* L)\n{\n\t// house:getTiles()\n\tHouse* house = getUserdata<House>(L, 1);\n\tif (!house) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tconst auto& tiles = house->getTiles();\n\tlua_createtable(L, tiles.size(), 0);\n\n\tint index = 0;\n\tfor (Tile* tile : tiles) {\n\t\tpushUserdata<Tile>(L, tile);\n\t\tsetMetatable(L, -1, \"Tile\");\n\t\tlua_rawseti(L, -2, ++index);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaHouseGetItems(lua_State* L)\n{\n\t// house:getItems()\n\tHouse* house = getUserdata<House>(L, 1);\n\tif (!house) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tconst auto& tiles = house->getTiles();\n\tlua_newtable(L);\n\n\tint index = 0;\n\tfor (Tile* tile : tiles) {\n\t\tTileItemVector* itemVector = tile->getItemList();\n\t\tif(itemVector) {\n\t\t\tfor(Item* item : *itemVector) {\n\t\t\t\tpushUserdata<Item>(L, item);\n\t\t\t\tsetItemMetatable(L, -1, item);\n\t\t\t\tlua_rawseti(L, -2, ++index);\n\t\t\t}\n\t\t}\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaHouseGetTileCount(lua_State* L)\n{\n\t// house:getTileCount()\n\tHouse* house = getUserdata<House>(L, 1);\n\tif (house) {\n\t\tlua_pushnumber(L, house->getTiles().size());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaHouseCanEditAccessList(lua_State* L)\n{\n\t// house:canEditAccessList(listId, player)\n\tHouse* house = getUserdata<House>(L, 1);\n\tif (!house) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tuint32_t listId = getNumber<uint32_t>(L, 2);\n\tPlayer* player = getPlayer(L, 3);\n\n\tpushBoolean(L, house->canEditAccessList(listId, player));\n\treturn 1;\n}\n\nint LuaScriptInterface::luaHouseGetAccessList(lua_State* L)\n{\n\t// house:getAccessList(listId)\n\tHouse* house = getUserdata<House>(L, 1);\n\tif (!house) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tstd::string list;\n\tuint32_t listId = getNumber<uint32_t>(L, 2);\n\tif (house->getAccessList(listId, list)) {\n\t\tpushString(L, list);\n\t} else {\n\t\tpushBoolean(L, false);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaHouseSetAccessList(lua_State* L)\n{\n\t// house:setAccessList(listId, list)\n\tHouse* house = getUserdata<House>(L, 1);\n\tif (!house) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tuint32_t listId = getNumber<uint32_t>(L, 2);\n\tconst std::string& list = getString(L, 3);\n\thouse->setAccessList(listId, list);\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaHouseKickPlayer(lua_State* L)\n{\n\t// house:kickPlayer(player, targetPlayer)\n\tHouse* house = getUserdata<House>(L, 1);\n\tif (!house) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tpushBoolean(L, house->kickPlayer(getPlayer(L, 2), getPlayer(L, 3)));\n\treturn 1;\n}\n\n// ItemType\nint LuaScriptInterface::luaItemTypeCreate(lua_State* L)\n{\n\t// ItemType(id or name)\n\tuint32_t id;\n\tif (isNumber(L, 2)) {\n\t\tid = getNumber<uint32_t>(L, 2);\n\t} else if (isString(L, 2)) {\n\t\tid = Item::items.getItemIdByName(getString(L, 2));\n\t} else {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tconst ItemType& itemType = Item::items[id];\n\tpushUserdata<const ItemType>(L, &itemType);\n\tsetMetatable(L, -1, \"ItemType\");\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeIsCorpse(lua_State* L)\n{\n\t// itemType:isCorpse()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tpushBoolean(L, itemType->corpseType != RACE_NONE);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeIsDoor(lua_State* L)\n{\n\t// itemType:isDoor()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tpushBoolean(L, itemType->isDoor());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeIsContainer(lua_State* L)\n{\n\t// itemType:isContainer()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tpushBoolean(L, itemType->isContainer());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeIsFluidContainer(lua_State* L)\n{\n\t// itemType:isFluidContainer()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tpushBoolean(L, itemType->isFluidContainer());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeIsMovable(lua_State* L)\n{\n\t// itemType:isMovable()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tpushBoolean(L, itemType->moveable);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeIsRune(lua_State* L)\n{\n\t// itemType:isRune()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tpushBoolean(L, itemType->isRune());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeIsStackable(lua_State* L)\n{\n\t// itemType:isStackable()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tpushBoolean(L, itemType->stackable);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeIsReadable(lua_State* L)\n{\n\t// itemType:isReadable()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tpushBoolean(L, itemType->canReadText);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeIsWritable(lua_State* L)\n{\n\t// itemType:isWritable()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tpushBoolean(L, itemType->canWriteText);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeIsBlocking(lua_State* L)\n{\n\t// itemType:isBlocking()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tpushBoolean(L, itemType->blockProjectile || itemType->blockSolid);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeIsGroundTile(lua_State* L)\n{\n\t// itemType:isGroundTile()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tpushBoolean(L, itemType->isGroundTile());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeIsMagicField(lua_State* L)\n{\n\t// itemType:isMagicField()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tpushBoolean(L, itemType->isMagicField());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeIsUseable(lua_State* L)\n{\n\t// itemType:isUseable()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tpushBoolean(L, itemType->isUseable());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeIsPickupable(lua_State* L)\n{\n\t// itemType:isPickupable()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tpushBoolean(L, itemType->isPickupable());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeGetType(lua_State* L)\n{\n\t// itemType:getType()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tlua_pushnumber(L, itemType->type);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeGetId(lua_State* L)\n{\n\t// itemType:getId()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tlua_pushnumber(L, itemType->id);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeGetClientId(lua_State* L)\n{\n\t// itemType:getClientId()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tlua_pushnumber(L, itemType->clientId);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeGetName(lua_State* L)\n{\n\t// itemType:getName()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tpushString(L, itemType->name);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeGetPluralName(lua_State* L)\n{\n\t// itemType:getPluralName()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tpushString(L, itemType->getPluralName());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeGetArticle(lua_State* L)\n{\n\t// itemType:getArticle()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tpushString(L, itemType->article);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeGetDescription(lua_State* L)\n{\n\t// itemType:getDescription()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tpushString(L, itemType->description);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeGetSlotPosition(lua_State *L)\n{\n\t// itemType:getSlotPosition()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tlua_pushnumber(L, itemType->slotPosition);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeGetCharges(lua_State* L)\n{\n\t// itemType:getCharges()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tlua_pushnumber(L, itemType->charges);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeGetFluidSource(lua_State* L)\n{\n\t// itemType:getFluidSource()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tlua_pushnumber(L, itemType->fluidSource);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeGetCapacity(lua_State* L)\n{\n\t// itemType:getCapacity()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tlua_pushnumber(L, itemType->maxItems);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeGetWeight(lua_State* L)\n{\n\t// itemType:getWeight([count = 1])\n\tuint16_t count = getNumber<uint16_t>(L, 2, 1);\n\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (!itemType) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tuint64_t weight = static_cast<uint64_t>(itemType->weight) * std::max<int32_t>(1, count);\n\tlua_pushnumber(L, weight);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeGetHitChance(lua_State* L)\n{\n\t// itemType:getHitChance()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tlua_pushnumber(L, itemType->hitChance);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeGetShootRange(lua_State* L)\n{\n\t// itemType:getShootRange()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tlua_pushnumber(L, itemType->shootRange);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeGetAttack(lua_State* L)\n{\n\t// itemType:getAttack()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tlua_pushnumber(L, itemType->attack);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeGetDefense(lua_State* L)\n{\n\t// itemType:getDefense()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tlua_pushnumber(L, itemType->defense);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeGetExtraDefense(lua_State* L)\n{\n\t// itemType:getExtraDefense()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tlua_pushnumber(L, itemType->extraDefense);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeGetArmor(lua_State* L)\n{\n\t// itemType:getArmor()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tlua_pushnumber(L, itemType->armor);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeGetWeaponType(lua_State* L)\n{\n\t// itemType:getWeaponType()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tlua_pushnumber(L, itemType->weaponType);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeGetAmmoType(lua_State* L)\n{\n\t// itemType:getAmmoType()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tlua_pushnumber(L, itemType->ammoType);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeGetCorpseType(lua_State* L)\n{\n\t// itemType:getCorpseType()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tlua_pushnumber(L, itemType->corpseType);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeGetElementType(lua_State* L)\n{\n\t// itemType:getElementType()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (!itemType) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tauto& abilities = itemType->abilities;\n\tif (abilities) {\n\t\tlua_pushnumber(L, abilities->elementType);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeGetElementDamage(lua_State* L)\n{\n\t// itemType:getElementDamage()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (!itemType) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tauto& abilities = itemType->abilities;\n\tif (abilities) {\n\t\tlua_pushnumber(L, abilities->elementDamage);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeGetTransformEquipId(lua_State* L)\n{\n\t// itemType:getTransformEquipId()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tlua_pushnumber(L, itemType->transformEquipTo);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeGetTransformDeEquipId(lua_State* L)\n{\n\t// itemType:getTransformDeEquipId()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tlua_pushnumber(L, itemType->transformDeEquipTo);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeGetDestroyId(lua_State* L)\n{\n\t// itemType:getDestroyId()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tlua_pushnumber(L, itemType->destroyTo);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeGetDecayId(lua_State* L)\n{\n\t// itemType:getDecayId()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tlua_pushnumber(L, itemType->decayTo);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeGetRequiredLevel(lua_State* L)\n{\n\t// itemType:getRequiredLevel()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tlua_pushnumber(L, itemType->minReqLevel);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeHasSubType(lua_State* L)\n{\n\t// itemType:hasSubType()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tpushBoolean(L, itemType->hasSubType());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaItemTypeIsStoreItem(lua_State* L)\n{\n\t// itemType:isStoreItem()\n\tconst ItemType* itemType = getUserdata<const ItemType>(L, 1);\n\tif (itemType) {\n\t\tpushBoolean(L, itemType->storeItem);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\n// Combat\nint LuaScriptInterface::luaCombatCreate(lua_State* L)\n{\n\t// Combat()\n\tpushUserdata<Combat>(L, g_luaEnvironment.createCombatObject(getScriptEnv()->getScriptInterface()));\n\tsetMetatable(L, -1, \"Combat\");\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCombatSetParameter(lua_State* L)\n{\n\t// combat:setParameter(key, value)\n\tCombat* combat = getUserdata<Combat>(L, 1);\n\tif (!combat) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tCombatParam_t key = getNumber<CombatParam_t>(L, 2);\n\tuint32_t value;\n\tif (isBoolean(L, 3)) {\n\t\tvalue = getBoolean(L, 3) ? 1 : 0;\n\t} else {\n\t\tvalue = getNumber<uint32_t>(L, 3);\n\t}\n\tcombat->setParam(key, value);\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCombatSetFormula(lua_State* L)\n{\n\t// combat:setFormula(type, mina, minb, maxa, maxb)\n\tCombat* combat = getUserdata<Combat>(L, 1);\n\tif (!combat) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tformulaType_t type = getNumber<formulaType_t>(L, 2);\n\tdouble mina = getNumber<double>(L, 3);\n\tdouble minb = getNumber<double>(L, 4);\n\tdouble maxa = getNumber<double>(L, 5);\n\tdouble maxb = getNumber<double>(L, 6);\n\tcombat->setPlayerCombatValues(type, mina, minb, maxa, maxb);\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCombatSetArea(lua_State* L)\n{\n\t// combat:setArea(area)\n\tif (getScriptEnv()->getScriptId() != EVENT_ID_LOADING) {\n\t\treportErrorFunc(\"This function can only be used while loading the script.\");\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tconst AreaCombat* area = g_luaEnvironment.getAreaObject(getNumber<uint32_t>(L, 2));\n\tif (!area) {\n\t\treportErrorFunc(getErrorDesc(LUA_ERROR_AREA_NOT_FOUND));\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tCombat* combat = getUserdata<Combat>(L, 1);\n\tif (combat) {\n\t\tcombat->setArea(new AreaCombat(*area));\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCombatAddCondition(lua_State* L)\n{\n\t// combat:addCondition(condition)\n\tCondition* condition = getUserdata<Condition>(L, 2);\n\tCombat* combat = getUserdata<Combat>(L, 1);\n\tif (combat && condition) {\n\t\tcombat->addCondition(condition->clone());\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCombatClearConditions(lua_State* L)\n{\n\t// combat:clearConditions()\n\tCombat* combat = getUserdata<Combat>(L, 1);\n\tif (combat) {\n\t\tcombat->clearConditions();\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCombatSetCallback(lua_State* L)\n{\n\t// combat:setCallback(key, function)\n\tCombat* combat = getUserdata<Combat>(L, 1);\n\tif (!combat) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tCallBackParam_t key = getNumber<CallBackParam_t>(L, 2);\n\tif (!combat->setCallback(key)) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tCallBack* callback = combat->getCallback(key);\n\tif (!callback) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tconst std::string& function = getString(L, 3);\n\tpushBoolean(L, callback->loadCallBack(getScriptEnv()->getScriptInterface(), function));\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCombatSetOrigin(lua_State* L)\n{\n\t// combat:setOrigin(origin)\n\tCombat* combat = getUserdata<Combat>(L, 1);\n\tif (combat) {\n\t\tcombat->setOrigin(getNumber<CombatOrigin>(L, 2));\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCombatExecute(lua_State* L)\n{\n\t// combat:execute(creature, variant)\n\tCombat* combat = getUserdata<Combat>(L, 1);\n\tif (!combat) {\n\t\tpushBoolean(L, false);\n\t\treturn 1;\n\t}\n\n\tif (isUserdata(L, 2)) {\n\t\tLuaDataType type = getUserdataType(L, 2);\n\t\tif (type != LuaData_Player && type != LuaData_Monster && type != LuaData_Npc) {\n\t\t\tpushBoolean(L, false);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tCreature* creature = getCreature(L, 2);\n\n\tconst LuaVariant& variant = getVariant(L, 3);\n\tswitch (variant.type) {\n\t\tcase VARIANT_NUMBER: {\n\t\t\tCreature* target = g_game.getCreatureByID(variant.number);\n\t\t\tif (!target) {\n\t\t\t\tpushBoolean(L, false);\n\t\t\t\treturn 1;\n\t\t\t}\n\n\t\t\tif (combat->hasArea()) {\n\t\t\t\tcombat->doCombat(creature, target->getPosition());\n\t\t\t} else {\n\t\t\t\tcombat->doCombat(creature, target);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\tcase VARIANT_POSITION: {\n\t\t\tcombat->doCombat(creature, variant.pos);\n\t\t\tbreak;\n\t\t}\n\n\t\tcase VARIANT_TARGETPOSITION: {\n\t\t\tif (combat->hasArea()) {\n\t\t\t\tcombat->doCombat(creature, variant.pos);\n\t\t\t} else {\n\t\t\t\tcombat->postCombatEffects(creature, variant.pos);\n\t\t\t\tg_game.addMagicEffect(variant.pos, CONST_ME_POFF);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\tcase VARIANT_STRING: {\n\t\t\tPlayer* target = g_game.getPlayerByName(variant.text);\n\t\t\tif (!target) {\n\t\t\t\tpushBoolean(L, false);\n\t\t\t\treturn 1;\n\t\t\t}\n\n\t\t\tcombat->doCombat(creature, target);\n\t\t\tbreak;\n\t\t}\n\n\t\tcase VARIANT_NONE: {\n\t\t\treportErrorFunc(getErrorDesc(LUA_ERROR_VARIANT_NOT_FOUND));\n\t\t\tpushBoolean(L, false);\n\t\t\treturn 1;\n\t\t}\n\n\t\tdefault: {\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\n// Condition\nint LuaScriptInterface::luaConditionCreate(lua_State* L)\n{\n\t// Condition(conditionType[, conditionId = CONDITIONID_COMBAT])\n\tConditionType_t conditionType = getNumber<ConditionType_t>(L, 2);\n\tConditionId_t conditionId = getNumber<ConditionId_t>(L, 3, CONDITIONID_COMBAT);\n\n\tCondition* condition = Condition::createCondition(conditionId, conditionType, 0, 0);\n\tif (condition) {\n\t\tpushUserdata<Condition>(L, condition);\n\t\tsetMetatable(L, -1, \"Condition\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaConditionDelete(lua_State* L)\n{\n\t// condition:delete()\n\tCondition** conditionPtr = getRawUserdata<Condition>(L, 1);\n\tif (conditionPtr && *conditionPtr) {\n\t\tdelete *conditionPtr;\n\t\t*conditionPtr = nullptr;\n\t}\n\treturn 0;\n}\n\nint LuaScriptInterface::luaConditionGetId(lua_State* L)\n{\n\t// condition:getId()\n\tCondition* condition = getUserdata<Condition>(L, 1);\n\tif (condition) {\n\t\tlua_pushnumber(L, condition->getId());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaConditionGetSubId(lua_State* L)\n{\n\t// condition:getSubId()\n\tCondition* condition = getUserdata<Condition>(L, 1);\n\tif (condition) {\n\t\tlua_pushnumber(L, condition->getSubId());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaConditionGetType(lua_State* L)\n{\n\t// condition:getType()\n\tCondition* condition = getUserdata<Condition>(L, 1);\n\tif (condition) {\n\t\tlua_pushnumber(L, condition->getType());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaConditionGetIcons(lua_State* L)\n{\n\t// condition:getIcons()\n\tCondition* condition = getUserdata<Condition>(L, 1);\n\tif (condition) {\n\t\tlua_pushnumber(L, condition->getIcons());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaConditionGetEndTime(lua_State* L)\n{\n\t// condition:getEndTime()\n\tCondition* condition = getUserdata<Condition>(L, 1);\n\tif (condition) {\n\t\tlua_pushnumber(L, condition->getEndTime());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaConditionClone(lua_State* L)\n{\n\t// condition:clone()\n\tCondition* condition = getUserdata<Condition>(L, 1);\n\tif (condition) {\n\t\tpushUserdata<Condition>(L, condition->clone());\n\t\tsetMetatable(L, -1, \"Condition\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaConditionGetTicks(lua_State* L)\n{\n\t// condition:getTicks()\n\tCondition* condition = getUserdata<Condition>(L, 1);\n\tif (condition) {\n\t\tlua_pushnumber(L, condition->getTicks());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaConditionSetTicks(lua_State* L)\n{\n\t// condition:setTicks(ticks)\n\tint32_t ticks = getNumber<int32_t>(L, 2);\n\tCondition* condition = getUserdata<Condition>(L, 1);\n\tif (condition) {\n\t\tcondition->setTicks(ticks);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaConditionSetParameter(lua_State* L)\n{\n\t// condition:setParameter(key, value)\n\tCondition* condition = getUserdata<Condition>(L, 1);\n\tif (!condition) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tConditionParam_t key = getNumber<ConditionParam_t>(L, 2);\n\tint32_t value;\n\tif (isBoolean(L, 3)) {\n\t\tvalue = getBoolean(L, 3) ? 1 : 0;\n\t} else {\n\t\tvalue = getNumber<int32_t>(L, 3);\n\t}\n\tcondition->setParam(key, value);\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaConditionSetFormula(lua_State* L)\n{\n\t// condition:setFormula(mina, minb, maxa, maxb)\n\tdouble maxb = getNumber<double>(L, 5);\n\tdouble maxa = getNumber<double>(L, 4);\n\tdouble minb = getNumber<double>(L, 3);\n\tdouble mina = getNumber<double>(L, 2);\n\tConditionSpeed* condition = dynamic_cast<ConditionSpeed*>(getUserdata<Condition>(L, 1));\n\tif (condition) {\n\t\tcondition->setFormulaVars(mina, minb, maxa, maxb);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaConditionSetOutfit(lua_State* L)\n{\n\t// condition:setOutfit(outfit)\n\t// condition:setOutfit(lookTypeEx, lookType, lookHead, lookBody, lookLegs, lookFeet[, lookAddons[, lookMount]])\n\tOutfit_t outfit;\n\tif (isTable(L, 2)) {\n\t\toutfit = getOutfit(L, 2);\n\t} else {\n\t\toutfit.lookMount = getNumber<uint16_t>(L, 9, outfit.lookMount);\n\t\toutfit.lookAddons = getNumber<uint8_t>(L, 8, outfit.lookAddons);\n\t\toutfit.lookFeet = getNumber<uint8_t>(L, 7);\n\t\toutfit.lookLegs = getNumber<uint8_t>(L, 6);\n\t\toutfit.lookBody = getNumber<uint8_t>(L, 5);\n\t\toutfit.lookHead = getNumber<uint8_t>(L, 4);\n\t\toutfit.lookType = getNumber<uint16_t>(L, 3);\n\t\toutfit.lookTypeEx = getNumber<uint16_t>(L, 2);\n\t}\n\n\tConditionOutfit* condition = dynamic_cast<ConditionOutfit*>(getUserdata<Condition>(L, 1));\n\tif (condition) {\n\t\tcondition->setOutfit(outfit);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaConditionAddDamage(lua_State* L)\n{\n\t// condition:addDamage(rounds, time, value)\n\tint32_t value = getNumber<int32_t>(L, 4);\n\tint32_t time = getNumber<int32_t>(L, 3);\n\tint32_t rounds = getNumber<int32_t>(L, 2);\n\tConditionDamage* condition = dynamic_cast<ConditionDamage*>(getUserdata<Condition>(L, 1));\n\tif (condition) {\n\t\tpushBoolean(L, condition->addDamage(rounds, time, value));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\n// Outfit\nint LuaScriptInterface::luaOutfitCreate(lua_State* L)\n{\n\t// Outfit(looktype)\n\tconst Outfit* outfit = Outfits::getInstance().getOutfitByLookType(getNumber<uint16_t>(L, 2));\n\tif (outfit) {\n\t\tpushOutfit(L, outfit);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaOutfitCompare(lua_State* L)\n{\n\t// outfit == outfitEx\n\tOutfit outfitEx = getOutfitClass(L, 2);\n\tOutfit outfit = getOutfitClass(L, 1);\n\tpushBoolean(L, outfit == outfitEx);\n\treturn 1;\n}\n\n// MonsterType\nint LuaScriptInterface::luaMonsterTypeCreate(lua_State* L)\n{\n\t// MonsterType(name)\n\tMonsterType* monsterType = g_monsters.getMonsterType(getString(L, 2));\n\tif (monsterType) {\n\t\tpushUserdata<MonsterType>(L, monsterType);\n\t\tsetMetatable(L, -1, \"MonsterType\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeIsAttackable(lua_State* L)\n{\n\t// get: monsterType:isAttackable() set: monsterType:isAttackable(bool)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushBoolean(L, monsterType->info.isAttackable);\n\t\t} else {\n\t\t\tmonsterType->info.isAttackable = getBoolean(L, 2);\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeIsConvinceable(lua_State* L)\n{\n\t// get: monsterType:isConvinceable() set: monsterType:isConvinceable(bool)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushBoolean(L, monsterType->info.isConvinceable);\n\t\t} else {\n\t\t\tmonsterType->info.isConvinceable = getBoolean(L, 2);\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeIsSummonable(lua_State* L)\n{\n\t// get: monsterType:isSummonable() set: monsterType:isSummonable(bool)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushBoolean(L, monsterType->info.isSummonable);\n\t\t} else {\n\t\t\tmonsterType->info.isSummonable = getBoolean(L, 2);\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeIsIllusionable(lua_State* L)\n{\n\t// get: monsterType:isIllusionable() set: monsterType:isIllusionable(bool)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushBoolean(L, monsterType->info.isIllusionable);\n\t\t} else {\n\t\t\tmonsterType->info.isIllusionable = getBoolean(L, 2);\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeIsHostile(lua_State* L)\n{\n\t// get: monsterType:isHostile() set: monsterType:isHostile(bool)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushBoolean(L, monsterType->info.isHostile);\n\t\t} else {\n\t\t\tmonsterType->info.isHostile = getBoolean(L, 2);\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeIsPushable(lua_State* L)\n{\n\t// get: monsterType:isPushable() set: monsterType:isPushable(bool)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushBoolean(L, monsterType->info.pushable);\n\t\t} else {\n\t\t\tmonsterType->info.pushable = getBoolean(L, 2);\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeIsHealthHidden(lua_State* L)\n{\n\t// get: monsterType:isHealthHidden() set: monsterType:isHealthHidden(bool)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushBoolean(L, monsterType->info.hiddenHealth);\n\t\t} else {\n\t\t\tmonsterType->info.hiddenHealth = getBoolean(L, 2);\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeIsBoss(lua_State* L)\n{\n\t// get: monsterType:isBoss() set: monsterType:isBoss(bool)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushBoolean(L, monsterType->info.isBoss);\n\t\t} else {\n\t\t\tmonsterType->info.isBoss = getBoolean(L, 2);\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeCanPushItems(lua_State* L)\n{\n\t// get: monsterType:canPushItems() set: monsterType:canPushItems(bool)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushBoolean(L, monsterType->info.canPushItems);\n\t\t} else {\n\t\t\tmonsterType->info.canPushItems = getBoolean(L, 2);\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeCanPushCreatures(lua_State* L)\n{\n\t// get: monsterType:canPushCreatures() set: monsterType:canPushCreatures(bool)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushBoolean(L, monsterType->info.canPushCreatures);\n\t\t} else {\n\t\t\tmonsterType->info.canPushCreatures = getBoolean(L, 2);\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint32_t LuaScriptInterface::luaMonsterTypeName(lua_State* L)\n{\n\t// get: monsterType:name() set: monsterType:name(name)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushString(L, monsterType->name);\n\t\t} else {\n\t\t\tmonsterType->name = getString(L, 2);\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeNameDescription(lua_State* L)\n{\n\t// get: monsterType:nameDescription() set: monsterType:nameDescription(desc)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushString(L, monsterType->nameDescription);\n\t\t} else {\n\t\t\tmonsterType->nameDescription = getString(L, 2);\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeHealth(lua_State* L)\n{\n\t// get: monsterType:health() set: monsterType:health(health)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, monsterType->info.health);\n\t\t} else {\n\t\t\tmonsterType->info.health = getNumber<int32_t>(L, 2);\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeMaxHealth(lua_State* L)\n{\n\t// get: monsterType:maxHealth() set: monsterType:maxHealth(health)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, monsterType->info.healthMax);\n\t\t} else {\n\t\t\tmonsterType->info.healthMax = getNumber<int32_t>(L, 2);\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeRunHealth(lua_State* L)\n{\n\t// get: monsterType:runHealth() set: monsterType:runHealth(health)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, monsterType->info.runAwayHealth);\n\t\t} else {\n\t\t\tmonsterType->info.runAwayHealth = getNumber<int32_t>(L, 2);\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeExperience(lua_State* L)\n{\n\t// get: monsterType:experience() set: monsterType:experience(exp)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, monsterType->info.experience);\n\t\t} else {\n\t\t\tmonsterType->info.experience = getNumber<uint64_t>(L, 2);\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeSkull(lua_State* L)\n{\n\t// get: monsterType:skull() set: monsterType:skull(str/constant)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, monsterType->info.skull);\n\t\t} else {\n\t\t\tif (isNumber(L, 2)) {\n\t\t\t\tmonsterType->info.skull = getNumber<Skulls_t>(L, 2);\n\t\t\t} else {\n\t\t\t\tmonsterType->info.skull = getSkullType(getString(L, 2));\n\t\t\t}\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeCombatImmunities(lua_State* L)\n{\n\t// get: monsterType:combatImmunities() set: monsterType:combatImmunities(immunity)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, monsterType->info.damageImmunities);\n\t\t} else {\n\t\t\tstd::string immunity = getString(L, 2);\n\t\t\tif (immunity == \"physical\") {\n\t\t\t\tmonsterType->info.damageImmunities |= COMBAT_PHYSICALDAMAGE;\n\t\t\t\tpushBoolean(L, true);\n\t\t\t} else if (immunity == \"energy\") {\n\t\t\t\tmonsterType->info.damageImmunities |= COMBAT_ENERGYDAMAGE;\n\t\t\t\tpushBoolean(L, true);\n\t\t\t} else if (immunity == \"fire\") {\n\t\t\t\tmonsterType->info.damageImmunities |= COMBAT_FIREDAMAGE;\n\t\t\t\tpushBoolean(L, true);\n\t\t\t} else if (immunity == \"poison\" || immunity == \"earth\") {\n\t\t\t\tmonsterType->info.damageImmunities |= COMBAT_EARTHDAMAGE;\n\t\t\t\tpushBoolean(L, true);\n\t\t\t} else if (immunity == \"drown\") {\n\t\t\t\tmonsterType->info.damageImmunities |= COMBAT_DROWNDAMAGE;\n\t\t\t\tpushBoolean(L, true);\n\t\t\t} else if (immunity == \"ice\") {\n\t\t\t\tmonsterType->info.damageImmunities |= COMBAT_ICEDAMAGE;\n\t\t\t\tpushBoolean(L, true);\n\t\t\t} else if (immunity == \"holy\") {\n\t\t\t\tmonsterType->info.damageImmunities |= COMBAT_HOLYDAMAGE;\n\t\t\t\tpushBoolean(L, true);\n\t\t\t} else if (immunity == \"death\") {\n\t\t\t\tmonsterType->info.damageImmunities |= COMBAT_DEATHDAMAGE;\n\t\t\t\tpushBoolean(L, true);\n\t\t\t} else if (immunity == \"lifedrain\") {\n\t\t\t\tmonsterType->info.damageImmunities |= COMBAT_LIFEDRAIN;\n\t\t\t\tpushBoolean(L, true);\n\t\t\t} else if (immunity == \"manadrain\") {\n\t\t\t\tmonsterType->info.damageImmunities |= COMBAT_MANADRAIN;\n\t\t\t\tpushBoolean(L, true);\n\t\t\t} else {\n\t\t\t\tstd::cout << \"[Warning - Monsters::loadMonster] Unknown immunity name \" << immunity << \" for monster: \" << monsterType->name << std::endl;\n\t\t\t\tlua_pushnil(L);\n\t\t\t}\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeConditionImmunities(lua_State* L)\n{\n\t// get: monsterType:conditionImmunities() set: monsterType:conditionImmunities(immunity)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, monsterType->info.conditionImmunities);\n\t\t} else {\n\t\t\tstd::string immunity = getString(L, 2);\n\t\t\tif (immunity == \"physical\") {\n\t\t\t\tmonsterType->info.conditionImmunities |= CONDITION_BLEEDING;\n\t\t\t\tpushBoolean(L, true);\n\t\t\t} else if (immunity == \"energy\") {\n\t\t\t\tmonsterType->info.conditionImmunities |= CONDITION_ENERGY;\n\t\t\t\tpushBoolean(L, true);\n\t\t\t} else if (immunity == \"fire\") {\n\t\t\t\tmonsterType->info.conditionImmunities |= CONDITION_FIRE;\n\t\t\t\tpushBoolean(L, true);\n\t\t\t} else if (immunity == \"poison\" || immunity == \"earth\") {\n\t\t\t\tmonsterType->info.conditionImmunities |= CONDITION_POISON;\n\t\t\t\tpushBoolean(L, true);\n\t\t\t} else if (immunity == \"drown\") {\n\t\t\t\tmonsterType->info.conditionImmunities |= CONDITION_DROWN;\n\t\t\t\tpushBoolean(L, true);\n\t\t\t} else if (immunity == \"ice\") {\n\t\t\t\tmonsterType->info.conditionImmunities |= CONDITION_FREEZING;\n\t\t\t\tpushBoolean(L, true);\n\t\t\t} else if (immunity == \"holy\") {\n\t\t\t\tmonsterType->info.conditionImmunities |= CONDITION_DAZZLED;\n\t\t\t\tpushBoolean(L, true);\n\t\t\t} else if (immunity == \"death\") {\n\t\t\t\tmonsterType->info.conditionImmunities |= CONDITION_CURSED;\n\t\t\t\tpushBoolean(L, true);\n\t\t\t} else if (immunity == \"paralyze\") {\n\t\t\t\tmonsterType->info.conditionImmunities |= CONDITION_PARALYZE;\n\t\t\t\tpushBoolean(L, true);\n\t\t\t} else if (immunity == \"outfit\") {\n\t\t\t\tmonsterType->info.conditionImmunities |= CONDITION_OUTFIT;\n\t\t\t\tpushBoolean(L, true);\n\t\t\t} else if (immunity == \"drunk\") {\n\t\t\t\tmonsterType->info.conditionImmunities |= CONDITION_DRUNK;\n\t\t\t\tpushBoolean(L, true);\n\t\t\t} else if (immunity == \"invisible\" || immunity == \"invisibility\") {\n\t\t\t\tmonsterType->info.conditionImmunities |= CONDITION_INVISIBLE;\n\t\t\t\tpushBoolean(L, true);\n\t\t\t} else if (immunity == \"bleed\") {\n\t\t\t\tmonsterType->info.conditionImmunities |= CONDITION_BLEEDING;\n\t\t\t\tpushBoolean(L, true);\n\t\t\t} else {\n\t\t\t\tstd::cout << \"[Warning - Monsters::loadMonster] Unknown immunity name \" << immunity << \" for monster: \" << monsterType->name << std::endl;\n\t\t\t\tlua_pushnil(L);\n\t\t\t}\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeGetAttackList(lua_State* L)\n{\n\t// monsterType:getAttackList()\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (!monsterType) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tlua_createtable(L, monsterType->info.attackSpells.size(), 0);\n\n\tint index = 0;\n\tfor (const auto& spellBlock : monsterType->info.attackSpells) {\n\t\tlua_createtable(L, 0, 8);\n\n\t\tsetField(L, \"chance\", spellBlock.chance);\n\t\tsetField(L, \"isCombatSpell\", spellBlock.combatSpell ? 1 : 0);\n\t\tsetField(L, \"isMelee\", spellBlock.isMelee ? 1 : 0);\n\t\tsetField(L, \"minCombatValue\", spellBlock.minCombatValue);\n\t\tsetField(L, \"maxCombatValue\", spellBlock.maxCombatValue);\n\t\tsetField(L, \"range\", spellBlock.range);\n\t\tsetField(L, \"speed\", spellBlock.speed);\n\t\tpushUserdata<CombatSpell>(L, static_cast<CombatSpell*>(spellBlock.spell));\n\t\tlua_setfield(L, -2, \"spell\");\n\n\t\tlua_rawseti(L, -2, ++index);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeAddAttack(lua_State* L)\n{\n\t// monsterType:addAttack(monsterspell)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tMonsterSpell* spell = getUserdata<MonsterSpell>(L, 2);\n\t\tif (spell) {\n\t\t\tspellBlock_t sb;\n\t\t\tif (g_monsters.deserializeSpell(spell, sb, monsterType->name)) {\n\t\t\t\tmonsterType->info.attackSpells.push_back(std::move(sb));\n\t\t\t} else {\n\t\t\t\tstd::cout << monsterType->name << std::endl;\n\t\t\t\tstd::cout << \"[Warning - Monsters::loadMonster] Cant load spell. \" << spell->name << std::endl;\n\t\t\t}\n\t\t} else {\n\t\t\tlua_pushnil(L);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeGetDefenseList(lua_State* L)\n{\n\t// monsterType:getDefenseList()\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (!monsterType) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tlua_createtable(L, monsterType->info.defenseSpells.size(), 0);\n\n\n\tint index = 0;\n\tfor (const auto& spellBlock : monsterType->info.defenseSpells) {\n\t\tlua_createtable(L, 0, 8);\n\n\t\tsetField(L, \"chance\", spellBlock.chance);\n\t\tsetField(L, \"isCombatSpell\", spellBlock.combatSpell ? 1 : 0);\n\t\tsetField(L, \"isMelee\", spellBlock.isMelee ? 1 : 0);\n\t\tsetField(L, \"minCombatValue\", spellBlock.minCombatValue);\n\t\tsetField(L, \"maxCombatValue\", spellBlock.maxCombatValue);\n\t\tsetField(L, \"range\", spellBlock.range);\n\t\tsetField(L, \"speed\", spellBlock.speed);\n\t\tpushUserdata<CombatSpell>(L, static_cast<CombatSpell*>(spellBlock.spell));\n\t\tlua_setfield(L, -2, \"spell\");\n\n\t\tlua_rawseti(L, -2, ++index);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeAddDefense(lua_State* L)\n{\n\t// monsterType:addDefense(monsterspell)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tMonsterSpell* spell = getUserdata<MonsterSpell>(L, 2);\n\t\tif (spell) {\n\t\t\tspellBlock_t sb;\n\t\t\tif (g_monsters.deserializeSpell(spell, sb, monsterType->name)) {\n\t\t\t\tmonsterType->info.defenseSpells.push_back(std::move(sb));\n\t\t\t} else {\n\t\t\t\tstd::cout << monsterType->name << std::endl;\n\t\t\t\tstd::cout << \"[Warning - Monsters::loadMonster] Cant load spell. \" << spell->name << std::endl;\n\t\t\t}\n\t\t} else {\n\t\t\tlua_pushnil(L);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeGetElementList(lua_State* L)\n{\n\t// monsterType:getElementList()\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (!monsterType) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tlua_createtable(L, monsterType->info.elementMap.size(), 0);\n\tfor (const auto& elementEntry : monsterType->info.elementMap) {\n\t\tlua_pushnumber(L, elementEntry.second);\n\t\tlua_rawseti(L, -2, elementEntry.first);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeAddElement(lua_State* L)\n{\n\t// monsterType:addElement(type, percent)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tCombatType_t element = getNumber<CombatType_t>(L, 2);\n\t\tmonsterType->info.elementMap[element] = getNumber<int32_t>(L, 3);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeGetVoices(lua_State* L)\n{\n\t// monsterType:getVoices()\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (!monsterType) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tint index = 0;\n\tlua_createtable(L, monsterType->info.voiceVector.size(), 0);\n\tfor (const auto& voiceBlock : monsterType->info.voiceVector) {\n\t\tlua_createtable(L, 0, 2);\n\t\tsetField(L, \"text\", voiceBlock.text);\n\t\tsetField(L, \"yellText\", voiceBlock.yellText);\n\t\tlua_rawseti(L, -2, ++index);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeAddVoice(lua_State* L)\n{\n\t// monsterType:addVoice(sentence, interval, chance, yell)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tvoiceBlock_t voice;\n\t\tvoice.text = getString(L, 2);\n\t\tmonsterType->info.yellSpeedTicks = getNumber<uint32_t>(L, 3);\n\t\tmonsterType->info.yellChance = getNumber<uint32_t>(L, 4);\n\t\tvoice.yellText = getBoolean(L, 5);\n\t\tmonsterType->info.voiceVector.push_back(voice);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeGetLoot(lua_State* L)\n{\n\t// monsterType:getLoot()\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (!monsterType) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tpushLoot(L, monsterType->info.lootItems);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeAddLoot(lua_State* L)\n{\n\t// monsterType:addLoot(loot)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tLoot* loot = getUserdata<Loot>(L, 2);\n\t\tif (loot) {\n\t\t\tmonsterType->loadLoot(monsterType, loot->lootBlock);\n\t\t\tpushBoolean(L, true);\n\t\t} else {\n\t\t\tlua_pushnil(L);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeGetCreatureEvents(lua_State* L)\n{\n\t// monsterType:getCreatureEvents()\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (!monsterType) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tint index = 0;\n\tlua_createtable(L, monsterType->info.scripts.size(), 0);\n\tfor (const std::string& creatureEvent : monsterType->info.scripts) {\n\t\tpushString(L, creatureEvent);\n\t\tlua_rawseti(L, -2, ++index);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeRegisterEvent(lua_State* L)\n{\n\t// monsterType:registerEvent(name)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tmonsterType->info.scripts.push_back(getString(L, 2));\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeEventOnCallback(lua_State* L)\n{\n\t// monsterType:onThink(callback)\n\t// monsterType:onAppear(callback)\n\t// monsterType:onDisappear(callback)\n\t// monsterType:onMove(callback)\n\t// monsterType:onSay(callback)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (monsterType->loadCallback(&g_scripts->getScriptInterface())) {\n\t\t\tpushBoolean(L, true);\n\t\t\treturn 1;\n\t\t}\n\t\tpushBoolean(L, false);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeEventType(lua_State* L)\n{\n\t// monstertype:eventType(event)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tmonsterType->info.eventType = getNumber<MonstersEvent_t>(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeGetSummonList(lua_State* L)\n{\n\t// monsterType:getSummonList()\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (!monsterType) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tint index = 0;\n\tlua_createtable(L, monsterType->info.summons.size(), 0);\n\tfor (const auto& summonBlock : monsterType->info.summons) {\n\t\tlua_createtable(L, 0, 3);\n\t\tsetField(L, \"name\", summonBlock.name);\n\t\tsetField(L, \"speed\", summonBlock.speed);\n\t\tsetField(L, \"chance\", summonBlock.chance);\n\t\tlua_rawseti(L, -2, ++index);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeAddSummon(lua_State* L)\n{\n\t// monsterType:addSummon(name, interval, chance)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tsummonBlock_t summon;\n\t\tsummon.name = getString(L, 2);\n\t\tsummon.chance = getNumber<int32_t>(L, 3);\n\t\tsummon.speed = getNumber<int32_t>(L, 4);\n\t\tmonsterType->info.summons.push_back(summon);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeMaxSummons(lua_State* L)\n{\n\t// get: monsterType:maxSummons() set: monsterType:maxSummons(ammount)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, monsterType->info.maxSummons);\n\t\t} else {\n\t\t\tmonsterType->info.maxSummons = getNumber<uint32_t>(L, 2);\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeArmor(lua_State* L)\n{\n\t// get: monsterType:armor() set: monsterType:armor(armor)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, monsterType->info.armor);\n\t\t} else {\n\t\t\tmonsterType->info.armor = getNumber<int32_t>(L, 2);\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeDefense(lua_State* L)\n{\n\t// get: monsterType:defense() set: monsterType:defense(defense)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, monsterType->info.defense);\n\t\t} else {\n\t\t\tmonsterType->info.defense = getNumber<int32_t>(L, 2);\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeOutfit(lua_State* L)\n{\n\t// get: monsterType:outfit() set: monsterType:outfit(outfit)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushOutfit(L, monsterType->info.outfit);\n\t\t} else {\n\t\t\tmonsterType->info.outfit = getOutfit(L, 2);\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeRace(lua_State* L)\n{\n\t// get: monsterType:race() set: monsterType:race(race)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tstd::string race = getString(L, 2);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, monsterType->info.race);\n\t\t} else {\n\t\t\tif (race == \"venom\") {\n\t\t\t\tmonsterType->info.race = RACE_VENOM;\n\t\t\t} else if (race == \"blood\") {\n\t\t\t\tmonsterType->info.race = RACE_BLOOD;\n\t\t\t} else if (race == \"undead\") {\n\t\t\t\tmonsterType->info.race = RACE_UNDEAD;\n\t\t\t} else if (race == \"fire\") {\n\t\t\t\tmonsterType->info.race = RACE_FIRE;\n\t\t\t} else if (race == \"energy\") {\n\t\t\t\tmonsterType->info.race = RACE_ENERGY;\n\t\t\t} else {\n\t\t\t\tstd::cout << \"[Warning - Monsters::loadMonster] Unknown race type \" << race << \".\" << std::endl;\n\t\t\t\tlua_pushnil(L);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeCorpseId(lua_State* L)\n{\n\t// get: monsterType:corpseId() set: monsterType:corpseId(id)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, monsterType->info.lookcorpse);\n\t\t} else {\n\t\t\tmonsterType->info.lookcorpse = getNumber<uint16_t>(L, 2);\n\t\t\tlua_pushboolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeManaCost(lua_State* L)\n{\n\t// get: monsterType:manaCost() set: monsterType:manaCost(mana)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, monsterType->info.manaCost);\n\t\t} else {\n\t\t\tmonsterType->info.manaCost = getNumber<uint32_t>(L, 2);\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeBaseSpeed(lua_State* L)\n{\n\t// get: monsterType:baseSpeed() set: monsterType:baseSpeed(speed)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, monsterType->info.baseSpeed);\n\t\t} else {\n\t\t\tmonsterType->info.baseSpeed = getNumber<uint32_t>(L, 2);\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeLight(lua_State* L)\n{\n\t// get: monsterType:light() set: monsterType:light(color, level)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (!monsterType) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\tif (lua_gettop(L) == 1) {\n\t\tlua_pushnumber(L, monsterType->info.light.level);\n\t\tlua_pushnumber(L, monsterType->info.light.color);\n\t\treturn 2;\n\t} else {\n\t\tmonsterType->info.light.color = getNumber<uint8_t>(L, 2);\n\t\tmonsterType->info.light.level = getNumber<uint8_t>(L, 3);\n\t\tpushBoolean(L, true);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeStaticAttackChance(lua_State* L)\n{\n\t// get: monsterType:staticAttackChance() set: monsterType:staticAttackChance(chance)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, monsterType->info.staticAttackChance);\n\t\t} else {\n\t\t\tmonsterType->info.staticAttackChance = getNumber<uint32_t>(L, 2);\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeTargetDistance(lua_State* L)\n{\n\t// get: monsterType:targetDistance() set: monsterType:targetDistance(distance)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, monsterType->info.targetDistance);\n\t\t} else {\n\t\t\tmonsterType->info.targetDistance = getNumber<int32_t>(L, 2);\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeYellChance(lua_State* L)\n{\n\t// get: monsterType:yellChance() set: monsterType:yellChance(chance)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, monsterType->info.yellChance);\n\t\t} else {\n\t\t\tmonsterType->info.yellChance = getNumber<uint32_t>(L, 2);\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeYellSpeedTicks(lua_State* L)\n{\n\t// get: monsterType:yellSpeedTicks() set: monsterType:yellSpeedTicks(rate)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, monsterType->info.yellSpeedTicks);\n\t\t} else {\n\t\t\tmonsterType->info.yellSpeedTicks = getNumber<uint32_t>(L, 2);\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeChangeTargetChance(lua_State* L)\n{\n\t// get: monsterType:changeTargetChance() set: monsterType:changeTargetChance(chance)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, monsterType->info.changeTargetChance);\n\t\t} else {\n\t\t\tmonsterType->info.changeTargetChance = getNumber<int32_t>(L, 2);\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterTypeChangeTargetSpeed(lua_State* L)\n{\n\t// get: monsterType:changeTargetSpeed() set: monsterType:changeTargetSpeed(speed)\n\tMonsterType* monsterType = getUserdata<MonsterType>(L, 1);\n\tif (monsterType) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, monsterType->info.changeTargetSpeed);\n\t\t} else {\n\t\t\tmonsterType->info.changeTargetSpeed = getNumber<uint32_t>(L, 2);\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\n// Loot\nint LuaScriptInterface::luaCreateLoot(lua_State* L)\n{\n\t// Loot() will create a new loot item\n\tLoot* loot = new Loot();\n\tif (loot) {\n\t\tpushUserdata<Loot>(L, loot);\n\t\tsetMetatable(L, -1, \"Loot\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaDeleteLoot(lua_State* L)\n{\n\t// loot:delete() loot:__gc()\n\tLoot** lootPtr = getRawUserdata<Loot>(L, 1);\n\tif (lootPtr && *lootPtr) {\n\t\tdelete *lootPtr;\n\t\t*lootPtr = nullptr;\n\t}\n\treturn 0;\n}\n\nint LuaScriptInterface::luaLootSetId(lua_State* L)\n{\n\t// loot:setId(id or name)\n\tLoot* loot = getUserdata<Loot>(L, 1);\n\tif (loot) {\n\t\tif (isNumber(L, 2)) {\n\t\t\tloot->lootBlock.id = getNumber<uint16_t>(L, 2);\n\t\t} else {\n\t\t\tauto name = getString(L, 2);\n\t\t\tauto ids = Item::items.nameToItems.equal_range(asLowerCaseString(name));\n\n\t\t\tif (ids.first == Item::items.nameToItems.cend()) {\n\t\t\t\tstd::cout << \"[Warning - Loot:setId] Unknown loot item \\\"\" << name << \"\\\". \" << std::endl;\n\t\t\t\tpushBoolean(L, false);\n\t\t\t\treturn 1;\n\t\t\t}\n\n\t\t\tif (std::next(ids.first) != ids.second) {\n\t\t\t\tstd::cout << \"[Warning - Loot:setId] Non-unique loot item \\\"\" << name << \"\\\". \" << std::endl;\n\t\t\t\tpushBoolean(L, false);\n\t\t\t\treturn 1;\n\t\t\t}\n\n\t\t\tloot->lootBlock.id = ids.first->second;\n\t\t}\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaLootSetSubType(lua_State* L)\n{\n\t// loot:setSubType(type)\n\tLoot* loot = getUserdata<Loot>(L, 1);\n\tif (loot) {\n\t\tloot->lootBlock.subType = getNumber<uint16_t>(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaLootSetChance(lua_State* L)\n{\n\t// loot:setChance(chance)\n\tLoot* loot = getUserdata<Loot>(L, 1);\n\tif (loot) {\n\t\tloot->lootBlock.chance = getNumber<uint32_t>(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaLootSetMaxCount(lua_State* L)\n{\n\t// loot:setMaxCount(max)\n\tLoot* loot = getUserdata<Loot>(L, 1);\n\tif (loot) {\n\t\tloot->lootBlock.countmax = getNumber<uint32_t>(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaLootSetActionId(lua_State* L)\n{\n\t// loot:setActionId(actionid)\n\tLoot* loot = getUserdata<Loot>(L, 1);\n\tif (loot) {\n\t\tloot->lootBlock.actionId = getNumber<uint32_t>(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaLootSetDescription(lua_State* L)\n{\n\t// loot:setDescription(desc)\n\tLoot* loot = getUserdata<Loot>(L, 1);\n\tif (loot) {\n\t\tloot->lootBlock.text = getString(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaLootAddChildLoot(lua_State* L)\n{\n\t// loot:addChildLoot(loot)\n\tLoot* loot = getUserdata<Loot>(L, 1);\n\tif (loot) {\n\t\tloot->lootBlock.childLoot.push_back(getUserdata<Loot>(L, 2)->lootBlock);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\n// MonsterSpell\nint LuaScriptInterface::luaCreateMonsterSpell(lua_State* L)\n{\n\t// MonsterSpell() will create a new Monster Spell\n\tMonsterSpell* spell = new MonsterSpell();\n\tif (spell) {\n\t\tpushUserdata<MonsterSpell>(L, spell);\n\t\tsetMetatable(L, -1, \"MonsterSpell\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaDeleteMonsterSpell(lua_State* L)\n{\n\t// monsterSpell:delete() monsterSpell:__gc()\n\tMonsterSpell** monsterSpellPtr = getRawUserdata<MonsterSpell>(L, 1);\n\tif (monsterSpellPtr && *monsterSpellPtr) {\n\t\tdelete *monsterSpellPtr;\n\t\t*monsterSpellPtr = nullptr;\n\t}\n\treturn 0;\n}\n\nint LuaScriptInterface::luaMonsterSpellSetType(lua_State* L)\n{\n\t// monsterSpell:setType(type)\n\tMonsterSpell* spell = getUserdata<MonsterSpell>(L, 1);\n\tif (spell) {\n\t\tspell->name = getString(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterSpellSetScriptName(lua_State* L)\n{\n\t// monsterSpell:setScriptName(name)\n\tMonsterSpell* spell = getUserdata<MonsterSpell>(L, 1);\n\tif (spell) {\n\t\tspell->scriptName = getString(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterSpellSetChance(lua_State* L)\n{\n\t// monsterSpell:setChance(chance)\n\tMonsterSpell* spell = getUserdata<MonsterSpell>(L, 1);\n\tif (spell) {\n\t\tspell->chance = getNumber<uint8_t>(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterSpellSetInterval(lua_State* L)\n{\n\t// monsterSpell:setInterval(interval)\n\tMonsterSpell* spell = getUserdata<MonsterSpell>(L, 1);\n\tif (spell) {\n\t\tspell->interval = getNumber<uint16_t>(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterSpellSetRange(lua_State* L)\n{\n\t// monsterSpell:setRange(range)\n\tMonsterSpell* spell = getUserdata<MonsterSpell>(L, 1);\n\tif (spell) {\n\t\tspell->range = getNumber<uint8_t>(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterSpellSetCombatValue(lua_State* L)\n{\n\t// monsterSpell:setCombatValue(min, max)\n\tMonsterSpell* spell = getUserdata<MonsterSpell>(L, 1);\n\tif (spell) {\n\t\tspell->minCombatValue = getNumber<int32_t>(L, 2);\n\t\tspell->maxCombatValue = getNumber<int32_t>(L, 3);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterSpellSetCombatType(lua_State* L)\n{\n\t// monsterSpell:setCombatType(combatType_t)\n\tMonsterSpell* spell = getUserdata<MonsterSpell>(L, 1);\n\tif (spell) {\n\t\tspell->combatType = getNumber<CombatType_t>(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterSpellSetAttackValue(lua_State* L)\n{\n\t// monsterSpell:setAttackValue(attack, skill)\n\tMonsterSpell* spell = getUserdata<MonsterSpell>(L, 1);\n\tif (spell) {\n\t\tspell->attack = getNumber<int32_t>(L, 2);\n\t\tspell->skill = getNumber<int32_t>(L, 3);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterSpellSetNeedTarget(lua_State* L)\n{\n\t// monsterSpell:setNeedTarget(bool)\n\tMonsterSpell* spell = getUserdata<MonsterSpell>(L, 1);\n\tif (spell) {\n\t\tspell->needTarget = getBoolean(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterSpellSetCombatLength(lua_State* L)\n{\n\t// monsterSpell:setCombatLength(length)\n\tMonsterSpell* spell = getUserdata<MonsterSpell>(L, 1);\n\tif (spell) {\n\t\tspell->length = getNumber<int32_t>(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterSpellSetCombatSpread(lua_State* L)\n{\n\t// monsterSpell:setCombatSpread(spread)\n\tMonsterSpell* spell = getUserdata<MonsterSpell>(L, 1);\n\tif (spell) {\n\t\tspell->spread = getNumber<int32_t>(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterSpellSetCombatRadius(lua_State* L)\n{\n\t// monsterSpell:setCombatRadius(radius)\n\tMonsterSpell* spell = getUserdata<MonsterSpell>(L, 1);\n\tif (spell) {\n\t\tspell->radius = getNumber<int32_t>(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterSpellSetConditionType(lua_State* L)\n{\n\t// monsterSpell:setConditionType(type)\n\tMonsterSpell* spell = getUserdata<MonsterSpell>(L, 1);\n\tif (spell) {\n\t\tspell->conditionType = getNumber<ConditionType_t>(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterSpellSetConditionDamage(lua_State* L)\n{\n\t// monsterSpell:setConditionDamage(min, max, start)\n\tMonsterSpell* spell = getUserdata<MonsterSpell>(L, 1);\n\tif (spell) {\n\t\tspell->conditionMinDamage = getNumber<int32_t>(L, 2);\n\t\tspell->conditionMaxDamage = getNumber<int32_t>(L, 3);\n\t\tspell->conditionStartDamage = getNumber<int32_t>(L, 4);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterSpellSetConditionSpeedChange(lua_State* L)\n{\n\t// monsterSpell:setConditionSpeedChange(minSpeed[, maxSpeed])\n\tMonsterSpell* spell = getUserdata<MonsterSpell>(L, 1);\n\tif (spell) {\n\t\tspell->minSpeedChange = getNumber<int32_t>(L, 2);\n\t\tspell->maxSpeedChange = getNumber<int32_t>(L, 3, 0);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterSpellSetConditionDuration(lua_State* L)\n{\n\t// monsterSpell:setConditionDuration(duration)\n\tMonsterSpell* spell = getUserdata<MonsterSpell>(L, 1);\n\tif (spell) {\n\t\tspell->duration = getNumber<int32_t>(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterSpellSetConditionTickInterval(lua_State* L)\n{\n\t// monsterSpell:setConditionTickInterval(interval)\n\tMonsterSpell* spell = getUserdata<MonsterSpell>(L, 1);\n\tif (spell) {\n\t\tspell->tickInterval = getNumber<int32_t>(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterSpellSetCombatShootEffect(lua_State* L)\n{\n\t// monsterSpell:setCombatShootEffect(effect)\n\tMonsterSpell* spell = getUserdata<MonsterSpell>(L, 1);\n\tif (spell) {\n\t\tspell->shoot = getNumber<ShootType_t>(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMonsterSpellSetCombatEffect(lua_State* L)\n{\n\t// monsterSpell:setCombatEffect(effect)\n\tMonsterSpell* spell = getUserdata<MonsterSpell>(L, 1);\n\tif (spell) {\n\t\tspell->effect = getNumber<MagicEffectClasses>(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\n// Party\nint32_t LuaScriptInterface::luaPartyCreate(lua_State* L)\n{\n\t// Party(userdata)\n\tPlayer* player = getUserdata<Player>(L, 2);\n\tif (!player) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tParty* party = player->getParty();\n\tif (!party) {\n\t\tparty = new Party(player);\n\t\tg_game.updatePlayerShield(player);\n\t\tplayer->sendCreatureSkull(player);\n\t\tpushUserdata<Party>(L, party);\n\t\tsetMetatable(L, -1, \"Party\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPartyDisband(lua_State* L)\n{\n\t// party:disband()\n\tParty** partyPtr = getRawUserdata<Party>(L, 1);\n\tif (partyPtr && *partyPtr) {\n\t\tParty*& party = *partyPtr;\n\t\tparty->disband();\n\t\tparty = nullptr;\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPartyGetLeader(lua_State* L)\n{\n\t// party:getLeader()\n\tParty* party = getUserdata<Party>(L, 1);\n\tif (!party) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tPlayer* leader = party->getLeader();\n\tif (leader) {\n\t\tpushUserdata<Player>(L, leader);\n\t\tsetMetatable(L, -1, \"Player\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPartySetLeader(lua_State* L)\n{\n\t// party:setLeader(player)\n\tPlayer* player = getPlayer(L, 2);\n\tParty* party = getUserdata<Party>(L, 1);\n\tif (party && player) {\n\t\tpushBoolean(L, party->passPartyLeadership(player));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPartyGetMembers(lua_State* L)\n{\n\t// party:getMembers()\n\tParty* party = getUserdata<Party>(L, 1);\n\tif (!party) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tint index = 0;\n\tlua_createtable(L, party->getMemberCount(), 0);\n\tfor (Player* player : party->getMembers()) {\n\t\tpushUserdata<Player>(L, player);\n\t\tsetMetatable(L, -1, \"Player\");\n\t\tlua_rawseti(L, -2, ++index);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPartyGetMemberCount(lua_State* L)\n{\n\t// party:getMemberCount()\n\tParty* party = getUserdata<Party>(L, 1);\n\tif (party) {\n\t\tlua_pushnumber(L, party->getMemberCount());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPartyGetInvitees(lua_State* L)\n{\n\t// party:getInvitees()\n\tParty* party = getUserdata<Party>(L, 1);\n\tif (party) {\n\t\tlua_createtable(L, party->getInvitationCount(), 0);\n\n\t\tint index = 0;\n\t\tfor (Player* player : party->getInvitees()) {\n\t\t\tpushUserdata<Player>(L, player);\n\t\t\tsetMetatable(L, -1, \"Player\");\n\t\t\tlua_rawseti(L, -2, ++index);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPartyGetInviteeCount(lua_State* L)\n{\n\t// party:getInviteeCount()\n\tParty* party = getUserdata<Party>(L, 1);\n\tif (party) {\n\t\tlua_pushnumber(L, party->getInvitationCount());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPartyAddInvite(lua_State* L)\n{\n\t// party:addInvite(player)\n\tPlayer* player = getPlayer(L, 2);\n\tParty* party = getUserdata<Party>(L, 1);\n\tif (party && player) {\n\t\tpushBoolean(L, party->invitePlayer(*player));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPartyRemoveInvite(lua_State* L)\n{\n\t// party:removeInvite(player)\n\tPlayer* player = getPlayer(L, 2);\n\tParty* party = getUserdata<Party>(L, 1);\n\tif (party && player) {\n\t\tpushBoolean(L, party->removeInvite(*player));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPartyAddMember(lua_State* L)\n{\n\t// party:addMember(player)\n\tPlayer* player = getPlayer(L, 2);\n\tParty* party = getUserdata<Party>(L, 1);\n\tif (party && player) {\n\t\tpushBoolean(L, party->joinParty(*player));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPartyRemoveMember(lua_State* L)\n{\n\t// party:removeMember(player)\n\tPlayer* player = getPlayer(L, 2);\n\tParty* party = getUserdata<Party>(L, 1);\n\tif (party && player) {\n\t\tpushBoolean(L, party->leaveParty(player));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPartyIsSharedExperienceActive(lua_State* L)\n{\n\t// party:isSharedExperienceActive()\n\tParty* party = getUserdata<Party>(L, 1);\n\tif (party) {\n\t\tpushBoolean(L, party->isSharedExperienceActive());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPartyIsSharedExperienceEnabled(lua_State* L)\n{\n\t// party:isSharedExperienceEnabled()\n\tParty* party = getUserdata<Party>(L, 1);\n\tif (party) {\n\t\tpushBoolean(L, party->isSharedExperienceEnabled());\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPartyShareExperience(lua_State* L)\n{\n\t// party:shareExperience(experience)\n\tuint64_t experience = getNumber<uint64_t>(L, 2);\n\tParty* party = getUserdata<Party>(L, 1);\n\tif (party) {\n\t\tparty->shareExperience(experience);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaPartySetSharedExperience(lua_State* L)\n{\n\t// party:setSharedExperience(active)\n\tbool active = getBoolean(L, 2);\n\tParty* party = getUserdata<Party>(L, 1);\n\tif (party) {\n\t\tpushBoolean(L, party->setSharedExperience(party->getLeader(), active));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\n// Spells\nint LuaScriptInterface::luaSpellCreate(lua_State* L)\n{\n\t// Spell(words, name or id) to get an existing spell\n\t// Spell(type) ex: Spell(SPELL_INSTANT) or Spell(SPELL_RUNE) to create a new spell\n\tif (lua_gettop(L) == 1) {\n\t\tstd::cout << \"[Error - Spell::luaSpellCreate] There is no parameter set!\" << std::endl;\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tSpellType_t spellType = SPELL_UNDEFINED;\n\n\tif (isNumber(L, 2)) {\n\t\tint32_t id = getNumber<int32_t>(L, 2);\n\t\tRuneSpell* rune = g_spells->getRuneSpell(id);\n\n\t\tif (rune) {\n\t\t\tpushUserdata<Spell>(L, rune);\n\t\t\tsetMetatable(L, -1, \"Spell\");\n\t\t\treturn 1;\n\t\t}\n\n\t\tspellType = static_cast<SpellType_t>(id);\n\t} else if (isString(L, 2)) {\n\t\tstd::string arg = getString(L, 2);\n\t\tInstantSpell* instant = g_spells->getInstantSpellByName(arg);\n\t\tif (instant) {\n\t\t\tpushUserdata<Spell>(L, instant);\n\t\t\tsetMetatable(L, -1, \"Spell\");\n\t\t\treturn 1;\n\t\t}\n\t\tinstant = g_spells->getInstantSpell(arg);\n\t\tif (instant) {\n\t\t\tpushUserdata<Spell>(L, instant);\n\t\t\tsetMetatable(L, -1, \"Spell\");\n\t\t\treturn 1;\n\t\t}\n\t\tRuneSpell* rune = g_spells->getRuneSpellByName(arg);\n\t\tif (rune) {\n\t\t\tpushUserdata<Spell>(L, rune);\n\t\t\tsetMetatable(L, -1, \"Spell\");\n\t\t\treturn 1;\n\t\t}\n\n\t\tstd::string tmp = asLowerCaseString(arg);\n\t\tif (tmp == \"instant\") {\n\t\t\tspellType = SPELL_INSTANT;\n\t\t} else if (tmp == \"rune\") {\n\t\t\tspellType = SPELL_RUNE;\n\t\t}\n\t}\n\n\tif (spellType == SPELL_INSTANT) {\n\t\tInstantSpell* spell = new InstantSpell(getScriptEnv()->getScriptInterface());\n\t\tspell->fromLua = true;\n\t\tpushUserdata<Spell>(L, spell);\n\t\tsetMetatable(L, -1, \"Spell\");\n\t\tspell->spellType = SPELL_INSTANT;\n\t\treturn 1;\n\t} else if (spellType == SPELL_RUNE) {\n\t\tRuneSpell* spell = new RuneSpell(getScriptEnv()->getScriptInterface());\n\t\tspell->fromLua = true;\n\t\tpushUserdata<Spell>(L, spell);\n\t\tsetMetatable(L, -1, \"Spell\");\n\t\tspell->spellType = SPELL_RUNE;\n\t\treturn 1;\n\t}\n\n\tlua_pushnil(L);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaSpellOnCastSpell(lua_State* L)\n{\n\t// spell:onCastSpell(callback)\n\tSpell* spell = getUserdata<Spell>(L, 1);\n\tif (spell) {\n\t\tif (spell->spellType == SPELL_INSTANT) {\n\t\t\tInstantSpell* instant = dynamic_cast<InstantSpell*>(getUserdata<Spell>(L, 1));\n\t\t\tif (!instant->loadCallback()) {\n\t\t\t\tpushBoolean(L, false);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\tinstant->scripted = true;\n\t\t\tpushBoolean(L, true);\n\t\t} else if (spell->spellType == SPELL_RUNE) {\n\t\t\tRuneSpell* rune = dynamic_cast<RuneSpell*>(getUserdata<Spell>(L, 1));\n\t\t\tif (!rune->loadCallback()) {\n\t\t\t\tpushBoolean(L, false);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\trune->scripted = true;\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaSpellRegister(lua_State* L)\n{\n\t// spell:register()\n\tSpell* spell = getUserdata<Spell>(L, 1);\n\tif (spell) {\n\t\tif (spell->spellType == SPELL_INSTANT) {\n\t\t\tInstantSpell* instant = dynamic_cast<InstantSpell*>(getUserdata<Spell>(L, 1));\n\t\t\tif (!instant->isScripted()) {\n\t\t\t\tpushBoolean(L, false);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\tpushBoolean(L, g_spells->registerInstantLuaEvent(instant));\n\t\t} else if (spell->spellType == SPELL_RUNE) {\n\t\t\tRuneSpell* rune = dynamic_cast<RuneSpell*>(getUserdata<Spell>(L, 1));\n\t\t\tif (rune->getMagicLevel() != 0 || rune->getLevel() != 0) {\n\t\t\t\t//Change information in the ItemType to get accurate description\n\t\t\t\tItemType& iType = Item::items.getItemType(rune->getRuneItemId());\n\t\t\t\tiType.name = rune->getName();\n\t\t\t\tiType.runeMagLevel = rune->getMagicLevel();\n\t\t\t\tiType.runeLevel = rune->getLevel();\n\t\t\t\tiType.charges = rune->getCharges();\n\t\t\t}\n\t\t\tif (!rune->isScripted()) {\n\t\t\t\tpushBoolean(L, false);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\tpushBoolean(L, g_spells->registerRuneLuaEvent(rune));\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaSpellName(lua_State* L)\n{\n\t// spell:name(name)\n\tSpell* spell = getUserdata<Spell>(L, 1);\n\tif (spell) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushString(L, spell->getName());\n\t\t} else {\n\t\t\tspell->setName(getString(L, 2));\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaSpellId(lua_State* L)\n{\n\t// spell:id(id)\n\tSpell* spell = getUserdata<Spell>(L, 1);\n\tif (spell) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, spell->getId());\n\t\t} else {\n\t\t\tspell->setId(getNumber<uint8_t>(L, 2));\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaSpellGroup(lua_State* L)\n{\n\t// spell:group(primaryGroup[, secondaryGroup])\n\tSpell* spell = getUserdata<Spell>(L, 1);\n\tif (spell) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, spell->getGroup());\n\t\t\tlua_pushnumber(L, spell->getSecondaryGroup());\n\t\t\treturn 2;\n\t\t} else if (lua_gettop(L) == 2) {\n\t\t\tSpellGroup_t group = getNumber<SpellGroup_t>(L, 2);\n\t\t\tif (group) {\n\t\t\t\tspell->setGroup(group);\n\t\t\t\tpushBoolean(L, true);\n\t\t\t} else if (isString(L, 2)) {\n\t\t\t\tgroup = stringToSpellGroup(getString(L, 2));\n\t\t\t\tif (group != SPELLGROUP_NONE) {\n\t\t\t\t\tspell->setGroup(group);\n\t\t\t\t} else {\n\t\t\t\t\tstd::cout << \"[Warning - Spell::group] Unknown group: \" << getString(L, 2) << std::endl;\n\t\t\t\t\tpushBoolean(L, false);\n\t\t\t\t\treturn 1;\n\t\t\t\t}\n\t\t\t\tpushBoolean(L, true);\n\t\t\t} else {\n\t\t\t\tstd::cout << \"[Warning - Spell::group] Unknown group: \" << getString(L, 2) << std::endl;\n\t\t\t\tpushBoolean(L, false);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t} else {\n\t\t\tSpellGroup_t primaryGroup = getNumber<SpellGroup_t>(L, 2);\n\t\t\tSpellGroup_t secondaryGroup = getNumber<SpellGroup_t>(L, 2);\n\t\t\tif (primaryGroup && secondaryGroup) {\n\t\t\t\tspell->setGroup(primaryGroup);\n\t\t\t\tspell->setSecondaryGroup(secondaryGroup);\n\t\t\t\tpushBoolean(L, true);\n\t\t\t} else if (isString(L, 2) && isString(L, 3)) {\n\t\t\t\tprimaryGroup = stringToSpellGroup(getString(L, 2));\n\t\t\t\tif (primaryGroup != SPELLGROUP_NONE) {\n\t\t\t\t\tspell->setGroup(primaryGroup);\n\t\t\t\t} else {\n\t\t\t\t\tstd::cout << \"[Warning - Spell::group] Unknown primaryGroup: \" << getString(L, 2) << std::endl;\n\t\t\t\t\tpushBoolean(L, false);\n\t\t\t\t\treturn 1;\n\t\t\t\t}\n\t\t\t\tsecondaryGroup = stringToSpellGroup(getString(L, 3));\n\t\t\t\tif (secondaryGroup != SPELLGROUP_NONE) {\n\t\t\t\t\tspell->setSecondaryGroup(secondaryGroup);\n\t\t\t\t} else {\n\t\t\t\t\tstd::cout << \"[Warning - Spell::group] Unknown secondaryGroup: \" << getString(L, 3) << std::endl;\n\t\t\t\t\tpushBoolean(L, false);\n\t\t\t\t\treturn 1;\n\t\t\t\t}\n\t\t\t\tpushBoolean(L, true);\n\t\t\t} else {\n\t\t\t\tstd::cout << \"[Warning - Spell::group] Unknown primaryGroup: \" << getString(L, 2) << \" or secondaryGroup: \" << getString(L, 3) << std::endl;\n\t\t\t\tpushBoolean(L, false);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaSpellCooldown(lua_State* L)\n{\n\t// spell:cooldown(cooldown)\n\tSpell* spell = getUserdata<Spell>(L, 1);\n\tif (spell) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, spell->getCooldown());\n\t\t} else {\n\t\t\tspell->setCooldown(getNumber<uint32_t>(L, 2));\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaSpellGroupCooldown(lua_State* L)\n{\n\t// spell:groupCooldown(primaryGroupCd[, secondaryGroupCd])\n\tSpell* spell = getUserdata<Spell>(L, 1);\n\tif (spell) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, spell->getGroupCooldown());\n\t\t\tlua_pushnumber(L, spell->getSecondaryCooldown());\n\t\t\treturn 2;\n\t\t} else if (lua_gettop(L) == 2) {\n\t\t\tspell->setGroupCooldown(getNumber<uint32_t>(L, 2));\n\t\t\tpushBoolean(L, true);\n\t\t} else {\n\t\t\tspell->setGroupCooldown(getNumber<uint32_t>(L, 2));\n\t\t\tspell->setSecondaryCooldown(getNumber<uint32_t>(L, 3));\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaSpellLevel(lua_State* L)\n{\n\t// spell:level(lvl)\n\tSpell* spell = getUserdata<Spell>(L, 1);\n\tif (spell) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, spell->getLevel());\n\t\t} else {\n\t\t\tspell->setLevel(getNumber<uint32_t>(L, 2));\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaSpellMagicLevel(lua_State* L)\n{\n\t// spell:magicLevel(lvl)\n\tSpell* spell = getUserdata<Spell>(L, 1);\n\tif (spell) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, spell->getMagicLevel());\n\t\t} else {\n\t\t\tspell->setMagicLevel(getNumber<uint32_t>(L, 2));\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaSpellMana(lua_State* L)\n{\n\t// spell:mana(mana)\n\tSpell* spell = getUserdata<Spell>(L, 1);\n\tif (spell) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, spell->getMana());\n\t\t} else {\n\t\t\tspell->setMana(getNumber<uint32_t>(L, 2));\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaSpellManaPercent(lua_State* L)\n{\n\t// spell:manaPercent(percent)\n\tSpell* spell = getUserdata<Spell>(L, 1);\n\tif (spell) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, spell->getManaPercent());\n\t\t} else {\n\t\t\tspell->setManaPercent(getNumber<uint32_t>(L, 2));\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaSpellSoul(lua_State* L)\n{\n\t// spell:soul(soul)\n\tSpell* spell = getUserdata<Spell>(L, 1);\n\tif (spell) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, spell->getSoulCost());\n\t\t} else {\n\t\t\tspell->setSoulCost(getNumber<uint32_t>(L, 2));\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaSpellRange(lua_State* L)\n{\n\t// spell:range(range)\n\tSpell* spell = getUserdata<Spell>(L, 1);\n\tif (spell) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, spell->getRange());\n\t\t} else {\n\t\t\tspell->setRange(getNumber<int32_t>(L, 2));\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaSpellPremium(lua_State* L)\n{\n\t// spell:isPremium(bool)\n\tSpell* spell = getUserdata<Spell>(L, 1);\n\tif (spell) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushBoolean(L, spell->isPremium());\n\t\t} else {\n\t\t\tspell->setPremium(getBoolean(L, 2));\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaSpellEnabled(lua_State* L)\n{\n\t// spell:isEnabled(bool)\n\tSpell* spell = getUserdata<Spell>(L, 1);\n\tif (spell) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushBoolean(L, spell->isEnabled());\n\t\t} else {\n\t\t\tspell->setEnabled(getBoolean(L, 2));\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaSpellNeedTarget(lua_State* L)\n{\n\t// spell:needTarget(bool)\n\tSpell* spell = getUserdata<Spell>(L, 1);\n\tif (spell) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushBoolean(L, spell->getNeedTarget());\n\t\t} else {\n\t\t\tspell->setNeedTarget(getBoolean(L, 2));\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaSpellNeedWeapon(lua_State* L)\n{\n\t// spell:needWeapon(bool)\n\tSpell* spell = getUserdata<Spell>(L, 1);\n\tif (spell) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushBoolean(L, spell->getNeedWeapon());\n\t\t} else {\n\t\t\tspell->setNeedWeapon(getBoolean(L, 2));\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaSpellNeedLearn(lua_State* L)\n{\n\t// spell:needLearn(bool)\n\tSpell* spell = getUserdata<Spell>(L, 1);\n\tif (spell) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushBoolean(L, spell->getNeedLearn());\n\t\t} else {\n\t\t\tspell->setNeedLearn(getBoolean(L, 2));\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaSpellSelfTarget(lua_State* L)\n{\n\t// spell:isSelfTarget(bool)\n\tSpell* spell = getUserdata<Spell>(L, 1);\n\tif (spell) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushBoolean(L, spell->getSelfTarget());\n\t\t} else {\n\t\t\tspell->setSelfTarget(getBoolean(L, 2));\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaSpellBlocking(lua_State* L)\n{\n\t// spell:isBlocking(blockingSolid, blockingCreature)\n\tSpell* spell = getUserdata<Spell>(L, 1);\n\tif (spell) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushBoolean(L, spell->getBlockingSolid());\n\t\t\tpushBoolean(L, spell->getBlockingCreature());\n\t\t\treturn 2;\n\t\t} else {\n\t\t\tspell->setBlockingSolid(getBoolean(L, 2));\n\t\t\tspell->setBlockingCreature(getBoolean(L, 3));\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaSpellAggressive(lua_State* L)\n{\n\t// spell:isAggressive(bool)\n\tSpell* spell = getUserdata<Spell>(L, 1);\n\tif (spell) {\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushBoolean(L, spell->getAggressive());\n\t\t} else {\n\t\t\tspell->setAggressive(getBoolean(L, 2));\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaSpellVocation(lua_State* L)\n{\n\t// spell:vocation(vocation)\n\tSpell* spell = getUserdata<Spell>(L, 1);\n\tif (!spell) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tif (lua_gettop(L) == 1) {\n\t\tlua_createtable(L, 0, 0);\n\t\tint i = 0;\n\t\tfor (auto& voc : spell->getVocMap()) {\n\t\t\tstd::string name = g_vocations.getVocation(voc.first)->getVocName();\n\t\t\tpushString(L, name);\n\t\t\tlua_rawseti(L, -2, ++i);\n\t\t}\n\t\tsetMetatable(L, -1, \"Spell\");\n\t} else {\n\t\tint parameters = lua_gettop(L) - 1; // - 1 because self is a parameter aswell, which we want to skip ofc\n\t\tfor (int i = 0; i < parameters; ++i) {\n\t\t\tstd::vector<std::string> vocList = explodeString(getString(L, 2 + i), \";\");\n\t\t\tspell->addVocMap(g_vocations.getVocationId(vocList[0]), vocList.size() > 1 ? booleanString(vocList[1]) : false);\n\t\t}\n\t\tpushBoolean(L, true);\n\t}\n\treturn 1;\n}\n\n// only for InstantSpells\nint LuaScriptInterface::luaSpellWords(lua_State* L)\n{\n\t// spell:words(words[, separator = \"\"])\n\tInstantSpell* spell = dynamic_cast<InstantSpell*>(getUserdata<Spell>(L, 1));\n\tif (spell) {\n\t\t// if spell != SPELL_INSTANT, it means that this actually is no InstantSpell, so we return nil\n\t\tif (spell->spellType != SPELL_INSTANT) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushString(L, spell->getWords().front());\n\t\t\tpushString(L, spell->getSeparator());\n\t\t\treturn 2;\n\t\t} else {\n\t\t\tstd::string sep = \"\";\n\t\t\tif (lua_gettop(L) == 3) {\n\t\t\t\tsep = getString(L, 3);\n\t\t\t}\n\t\t\tspell->setWords(getString(L, 2));\n\t\t\tspell->setSeparator(sep);\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\n// only for InstantSpells\nint LuaScriptInterface::luaSpellNeedDirection(lua_State* L)\n{\n\t// spell:needDirection(bool)\n\tInstantSpell* spell = dynamic_cast<InstantSpell*>(getUserdata<Spell>(L, 1));\n\tif (spell) {\n\t\t// if spell != SPELL_INSTANT, it means that this actually is no InstantSpell, so we return nil\n\t\tif (spell->spellType != SPELL_INSTANT) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushBoolean(L, spell->getNeedDirection());\n\t\t} else {\n\t\t\tspell->setNeedDirection(getBoolean(L, 2));\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\n// only for InstantSpells\nint LuaScriptInterface::luaSpellHasParams(lua_State* L)\n{\n\t// spell:hasParams(bool)\n\tInstantSpell* spell = dynamic_cast<InstantSpell*>(getUserdata<Spell>(L, 1));\n\tif (spell) {\n\t\t// if spell != SPELL_INSTANT, it means that this actually is no InstantSpell, so we return nil\n\t\tif (spell->spellType != SPELL_INSTANT) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushBoolean(L, spell->getHasParam());\n\t\t} else {\n\t\t\tspell->setHasParam(getBoolean(L, 2));\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\n// only for InstantSpells\nint LuaScriptInterface::luaSpellHasPlayerNameParam(lua_State* L)\n{\n\t// spell:hasPlayerNameParam(bool)\n\tInstantSpell* spell = dynamic_cast<InstantSpell*>(getUserdata<Spell>(L, 1));\n\tif (spell) {\n\t\t// if spell != SPELL_INSTANT, it means that this actually is no InstantSpell, so we return nil\n\t\tif (spell->spellType != SPELL_INSTANT) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushBoolean(L, spell->getHasPlayerNameParam());\n\t\t} else {\n\t\t\tspell->setHasPlayerNameParam(getBoolean(L, 2));\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\n// only for InstantSpells\nint LuaScriptInterface::luaSpellNeedCasterTargetOrDirection(lua_State* L)\n{\n\t// spell:needCasterTargetOrDirection(bool)\n\tInstantSpell* spell = dynamic_cast<InstantSpell*>(getUserdata<Spell>(L, 1));\n\tif (spell) {\n\t\t// if spell != SPELL_INSTANT, it means that this actually is no InstantSpell, so we return nil\n\t\tif (spell->spellType != SPELL_INSTANT) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushBoolean(L, spell->getNeedCasterTargetOrDirection());\n\t\t} else {\n\t\t\tspell->setNeedCasterTargetOrDirection(getBoolean(L, 2));\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\n// only for InstantSpells\nint LuaScriptInterface::luaSpellIsBlockingWalls(lua_State* L)\n{\n\t// spell:blockWalls(bool)\n\tInstantSpell* spell = dynamic_cast<InstantSpell*>(getUserdata<Spell>(L, 1));\n\tif (spell) {\n\t\t// if spell != SPELL_INSTANT, it means that this actually is no InstantSpell, so we return nil\n\t\tif (spell->spellType != SPELL_INSTANT) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushBoolean(L, spell->getBlockWalls());\n\t\t} else {\n\t\t\tspell->setBlockWalls(getBoolean(L, 2));\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\n// only for RuneSpells\nint LuaScriptInterface::luaSpellRuneId(lua_State* L)\n{\n\t// spell:runeId(id)\n\tRuneSpell* spell = dynamic_cast<RuneSpell*>(getUserdata<Spell>(L, 1));\n\tif (spell) {\n\t\t// if spell != SPELL_RUNE, it means that this actually is no RuneSpell, so we return nil\n\t\tif (spell->spellType != SPELL_RUNE) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, spell->getRuneItemId());\n\t\t} else {\n\t\t\tspell->setRuneItemId(getNumber<uint16_t>(L, 2));\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\n// only for RuneSpells\nint LuaScriptInterface::luaSpellCharges(lua_State* L)\n{\n\t// spell:charges(charges)\n\tRuneSpell* spell = dynamic_cast<RuneSpell*>(getUserdata<Spell>(L, 1));\n\tif (spell) {\n\t\t// if spell != SPELL_RUNE, it means that this actually is no RuneSpell, so we return nil\n\t\tif (spell->spellType != SPELL_RUNE) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tlua_pushnumber(L, spell->getCharges());\n\t\t} else {\n\t\t\tspell->setCharges(getNumber<uint32_t>(L, 2));\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\n// only for RuneSpells\nint LuaScriptInterface::luaSpellAllowFarUse(lua_State* L)\n{\n\t// spell:allowFarUse(bool)\n\tRuneSpell* spell = dynamic_cast<RuneSpell*>(getUserdata<Spell>(L, 1));\n\tif (spell) {\n\t\t// if spell != SPELL_RUNE, it means that this actually is no RuneSpell, so we return nil\n\t\tif (spell->spellType != SPELL_RUNE) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushBoolean(L, spell->getAllowFarUse());\n\t\t} else {\n\t\t\tspell->setAllowFarUse(getBoolean(L, 2));\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\n// only for RuneSpells\nint LuaScriptInterface::luaSpellBlockWalls(lua_State* L)\n{\n\t// spell:blockWalls(bool)\n\tRuneSpell* spell = dynamic_cast<RuneSpell*>(getUserdata<Spell>(L, 1));\n\tif (spell) {\n\t\t// if spell != SPELL_RUNE, it means that this actually is no RuneSpell, so we return nil\n\t\tif (spell->spellType != SPELL_RUNE) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushBoolean(L, spell->getCheckLineOfSight());\n\t\t} else {\n\t\t\tspell->setCheckLineOfSight(getBoolean(L, 2));\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\n// only for RuneSpells\nint LuaScriptInterface::luaSpellCheckFloor(lua_State* L)\n{\n\t// spell:checkFloor(bool)\n\tRuneSpell* spell = dynamic_cast<RuneSpell*>(getUserdata<Spell>(L, 1));\n\tif (spell) {\n\t\t// if spell != SPELL_RUNE, it means that this actually is no RuneSpell, so we return nil\n\t\tif (spell->spellType != SPELL_RUNE) {\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\n\t\tif (lua_gettop(L) == 1) {\n\t\t\tpushBoolean(L, spell->getCheckFloor());\n\t\t} else {\n\t\t\tspell->setCheckFloor(getBoolean(L, 2));\n\t\t\tpushBoolean(L, true);\n\t\t}\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreateAction(lua_State* L)\n{\n\t// Action()\n\tif (getScriptEnv()->getScriptInterface() != &g_scripts->getScriptInterface()) {\n\t\treportErrorFunc(\"Actions can only be registered in the Scripts interface.\");\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tAction* action = new Action(getScriptEnv()->getScriptInterface());\n\tif (action) {\n\t\taction->fromLua = true;\n\t\tpushUserdata<Action>(L, action);\n\t\tsetMetatable(L, -1, \"Action\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaActionOnUse(lua_State* L)\n{\n\t// action:onUse(callback)\n\tAction* action = getUserdata<Action>(L, 1);\n\tif (action) {\n\t\tif (!action->loadCallback()) {\n\t\t\tpushBoolean(L, false);\n\t\t\treturn 1;\n\t\t}\n\t\taction->scripted = true;\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaActionRegister(lua_State* L)\n{\n\t// action:register()\n\tAction* action = getUserdata<Action>(L, 1);\n\tif (action) {\n\t\tif (!action->isScripted()) {\n\t\t\tpushBoolean(L, false);\n\t\t\treturn 1;\n\t\t}\n\t\tpushBoolean(L, g_actions->registerLuaEvent(action));\n\t\taction->getActionIdRange().clear();\n\t\taction->getItemIdRange().clear();\n\t\taction->getUniqueIdRange().clear();\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaActionItemId(lua_State* L)\n{\n\t// action:id(ids)\n\tAction* action = getUserdata<Action>(L, 1);\n\tif (action) {\n\t\tint parameters = lua_gettop(L) - 1; // - 1 because self is a parameter aswell, which we want to skip ofc\n\t\tif (parameters > 1) {\n\t\t\tfor (int i = 0; i < parameters; ++i) {\n\t\t\t\taction->addItemId(getNumber<uint32_t>(L, 2 + i));\n\t\t\t}\n\t\t} else {\n\t\t\taction->addItemId(getNumber<uint32_t>(L, 2));\n\t\t}\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaActionActionId(lua_State* L)\n{\n\t// action:aid(aids)\n\tAction* action = getUserdata<Action>(L, 1);\n\tif (action) {\n\t\tint parameters = lua_gettop(L) - 1; // - 1 because self is a parameter aswell, which we want to skip ofc\n\t\tif (parameters > 1) {\n\t\t\tfor (int i = 0; i < parameters; ++i) {\n\t\t\t\taction->addActionId(getNumber<uint32_t>(L, 2 + i));\n\t\t\t}\n\t\t} else {\n\t\t\taction->addActionId(getNumber<uint32_t>(L, 2));\n\t\t}\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaActionUniqueId(lua_State* L)\n{\n\t// action:uid(uids)\n\tAction* action = getUserdata<Action>(L, 1);\n\tif (action) {\n\t\tint parameters = lua_gettop(L) - 1; // - 1 because self is a parameter aswell, which we want to skip ofc\n\t\tif (parameters > 1) {\n\t\t\tfor (int i = 0; i < parameters; ++i) {\n\t\t\t\taction->addUniqueId(getNumber<uint32_t>(L, 2 + i));\n\t\t\t}\n\t\t} else {\n\t\t\taction->addUniqueId(getNumber<uint32_t>(L, 2));\n\t\t}\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaActionAllowFarUse(lua_State* L)\n{\n\t// action:allowFarUse(bool)\n\tAction* action = getUserdata<Action>(L, 1);\n\tif (action) {\n\t\taction->setAllowFarUse(getBoolean(L, 2));\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaActionBlockWalls(lua_State* L)\n{\n\t// action:blockWalls(bool)\n\tAction* action = getUserdata<Action>(L, 1);\n\tif (action) {\n\t\taction->setCheckLineOfSight(getBoolean(L, 2));\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaActionCheckFloor(lua_State* L)\n{\n\t// action:checkFloor(bool)\n\tAction* action = getUserdata<Action>(L, 1);\n\tif (action) {\n\t\taction->setCheckFloor(getBoolean(L, 2));\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreateTalkaction(lua_State* L)\n{\n\t// TalkAction(words)\n\tif (getScriptEnv()->getScriptInterface() != &g_scripts->getScriptInterface()) {\n\t\treportErrorFunc(\"TalkActions can only be registered in the Scripts interface.\");\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tTalkAction* talk = new TalkAction(getScriptEnv()->getScriptInterface());\n\tif (talk) {\n\t\tfor (int i = 2; i <= lua_gettop(L); i++) {\n\t\t\ttalk->setWords(getString(L, i));\n\t\t}\n\t\ttalk->fromLua = true;\n\t\tpushUserdata<TalkAction>(L, talk);\n\t\tsetMetatable(L, -1, \"TalkAction\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTalkactionOnSay(lua_State* L)\n{\n\t// talkAction:onSay(callback)\n\tTalkAction* talk = getUserdata<TalkAction>(L, 1);\n\tif (talk) {\n\t\tif (!talk->loadCallback()) {\n\t\t\tpushBoolean(L, false);\n\t\t\treturn 1;\n\t\t}\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTalkactionRegister(lua_State* L)\n{\n\t// talkAction:register()\n\tTalkAction* talk = getUserdata<TalkAction>(L, 1);\n\tif (talk) {\n\t\tif (!talk->isScripted()) {\n\t\t\tpushBoolean(L, false);\n\t\t\treturn 1;\n\t\t}\n\t\tpushBoolean(L, g_talkActions->registerLuaEvent(talk));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaTalkactionSeparator(lua_State* L)\n{\n\t// talkAction:separator(sep)\n\tTalkAction* talk = getUserdata<TalkAction>(L, 1);\n\tif (talk) {\n\t\ttalk->setSeparator(getString(L, 2).c_str());\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreateCreatureEvent(lua_State* L)\n{\n\t// CreatureEvent(eventName)\n\tif (getScriptEnv()->getScriptInterface() != &g_scripts->getScriptInterface()) {\n\t\treportErrorFunc(\"CreatureEvents can only be registered in the Scripts interface.\");\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tCreatureEvent* creature = new CreatureEvent(getScriptEnv()->getScriptInterface());\n\tif (creature) {\n\t\tcreature->setName(getString(L, 2));\n\t\tcreature->fromLua = true;\n\t\tpushUserdata<CreatureEvent>(L, creature);\n\t\tsetMetatable(L, -1, \"CreatureEvent\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureEventType(lua_State* L)\n{\n\t// creatureevent:type(callback)\n\tCreatureEvent* creature = getUserdata<CreatureEvent>(L, 1);\n\tif (creature) {\n\t\tstd::string typeName = getString(L, 2);\n\t\tstd::string tmpStr = asLowerCaseString(typeName);\n\t\tif (tmpStr == \"login\") {\n\t\t\tcreature->setEventType(CREATURE_EVENT_LOGIN);\n\t\t} else if (tmpStr == \"logout\") {\n\t\t\tcreature->setEventType(CREATURE_EVENT_LOGOUT);\n\t\t} else if (tmpStr == \"think\") {\n\t\t\tcreature->setEventType(CREATURE_EVENT_THINK);\n\t\t} else if (tmpStr == \"preparedeath\") {\n\t\t\tcreature->setEventType(CREATURE_EVENT_PREPAREDEATH);\n\t\t} else if (tmpStr == \"death\") {\n\t\t\tcreature->setEventType(CREATURE_EVENT_DEATH);\n\t\t} else if (tmpStr == \"kill\") {\n\t\t\tcreature->setEventType(CREATURE_EVENT_KILL);\n\t\t} else if (tmpStr == \"advance\") {\n\t\t\tcreature->setEventType(CREATURE_EVENT_ADVANCE);\n\t\t} else if (tmpStr == \"modalwindow\") {\n\t\t\tcreature->setEventType(CREATURE_EVENT_MODALWINDOW);\n\t\t} else if (tmpStr == \"textedit\") {\n\t\t\tcreature->setEventType(CREATURE_EVENT_TEXTEDIT);\n\t\t} else if (tmpStr == \"healthchange\") {\n\t\t\tcreature->setEventType(CREATURE_EVENT_HEALTHCHANGE);\n\t\t} else if (tmpStr == \"manachange\") {\n\t\t\tcreature->setEventType(CREATURE_EVENT_MANACHANGE);\n\t\t} else if (tmpStr == \"extendedopcode\") {\n\t\t\tcreature->setEventType(CREATURE_EVENT_EXTENDED_OPCODE);\n\t\t} else {\n\t\t\tstd::cout << \"[Error - CreatureEvent::configureLuaEvent] Invalid type for creature event: \" << typeName << std::endl;\n\t\t\tpushBoolean(L, false);\n\t\t}\n\t\tcreature->setLoaded(true);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureEventRegister(lua_State* L)\n{\n\t// creatureevent:register()\n\tCreatureEvent* creature = getUserdata<CreatureEvent>(L, 1);\n\tif (creature) {\n\t\tif (!creature->isScripted()) {\n\t\t\tpushBoolean(L, false);\n\t\t\treturn 1;\n\t\t}\n\t\tpushBoolean(L, g_creatureEvents->registerLuaEvent(creature));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreatureEventOnCallback(lua_State* L)\n{\n\t// creatureevent:onLogin / logout / etc. (callback)\n\tCreatureEvent* creature = getUserdata<CreatureEvent>(L, 1);\n\tif (creature) {\n\t\tif (!creature->loadCallback()) {\n\t\t\tpushBoolean(L, false);\n\t\t\treturn 1;\n\t\t}\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreateMoveEvent(lua_State* L)\n{\n\t// MoveEvent()\n\tif (getScriptEnv()->getScriptInterface() != &g_scripts->getScriptInterface()) {\n\t\treportErrorFunc(\"MoveEvents can only be registered in the Scripts interface.\");\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tMoveEvent* moveevent = new MoveEvent(getScriptEnv()->getScriptInterface());\n\tif (moveevent) {\n\t\tmoveevent->fromLua = true;\n\t\tpushUserdata<MoveEvent>(L, moveevent);\n\t\tsetMetatable(L, -1, \"MoveEvent\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMoveEventType(lua_State* L)\n{\n\t// moveevent:type(callback)\n\tMoveEvent* moveevent = getUserdata<MoveEvent>(L, 1);\n\tif (moveevent) {\n\t\tstd::string typeName = getString(L, 2);\n\t\tstd::string tmpStr = asLowerCaseString(typeName);\n\t\tif (tmpStr == \"stepin\") {\n\t\t\tmoveevent->setEventType(MOVE_EVENT_STEP_IN);\n\t\t\tmoveevent->stepFunction = moveevent->StepInField;\n\t\t} else if (tmpStr == \"stepout\") {\n\t\t\tmoveevent->setEventType(MOVE_EVENT_STEP_OUT);\n\t\t\tmoveevent->stepFunction = moveevent->StepOutField;\n\t\t} else if (tmpStr == \"equip\") {\n\t\t\tmoveevent->setEventType(MOVE_EVENT_EQUIP);\n\t\t\tmoveevent->equipFunction = moveevent->EquipItem;\n\t\t} else if (tmpStr == \"deequip\") {\n\t\t\tmoveevent->setEventType(MOVE_EVENT_DEEQUIP);\n\t\t\tmoveevent->equipFunction = moveevent->DeEquipItem;\n\t\t} else if (tmpStr == \"additem\") {\n\t\t\tmoveevent->setEventType(MOVE_EVENT_ADD_ITEM_ITEMTILE);\n\t\t\tmoveevent->moveFunction = moveevent->AddItemField;\n\t\t} else if (tmpStr == \"removeitem\") {\n\t\t\tmoveevent->setEventType(MOVE_EVENT_REMOVE_ITEM_ITEMTILE);\n\t\t\tmoveevent->moveFunction = moveevent->RemoveItemField;\n\t\t} else {\n\t\t\tstd::cout << \"Error: [MoveEvent::configureMoveEvent] No valid event name \" << typeName << std::endl;\n\t\t\tpushBoolean(L, false);\n\t\t}\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMoveEventRegister(lua_State* L)\n{\n\t// moveevent:register()\n\tMoveEvent* moveevent = getUserdata<MoveEvent>(L, 1);\n\tif (moveevent) {\n\t\tif ((moveevent->getEventType() == MOVE_EVENT_EQUIP || moveevent->getEventType() == MOVE_EVENT_DEEQUIP) && moveevent->getSlot() == SLOTP_WHEREEVER) {\n\t\t\tuint32_t id = moveevent->getItemIdRange().at(0);\n\t\t\tItemType& it = Item::items.getItemType(id);\n\t\t\tmoveevent->setSlot(it.slotPosition);\n\t\t}\n\t\tif (!moveevent->isScripted()) {\n\t\t\tpushBoolean(L, g_moveEvents->registerLuaFunction(moveevent));\n\t\t\treturn 1;\n\t\t}\n\t\tpushBoolean(L, g_moveEvents->registerLuaEvent(moveevent));\n\t\tmoveevent->getItemIdRange().clear();\n\t\tmoveevent->getActionIdRange().clear();\n\t\tmoveevent->getUniqueIdRange().clear();\n\t\tmoveevent->getPosList().clear();\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMoveEventOnCallback(lua_State* L)\n{\n\t// moveevent:onEquip / deEquip / etc. (callback)\n\tMoveEvent* moveevent = getUserdata<MoveEvent>(L, 1);\n\tif (moveevent) {\n\t\tif (!moveevent->loadCallback()) {\n\t\t\tpushBoolean(L, false);\n\t\t\treturn 1;\n\t\t}\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMoveEventSlot(lua_State* L)\n{\n\t// moveevent:slot(slot)\n\tMoveEvent* moveevent = getUserdata<MoveEvent>(L, 1);\n\tif (!moveevent) {\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tif (moveevent->getEventType() == MOVE_EVENT_EQUIP || moveevent->getEventType() == MOVE_EVENT_DEEQUIP) {\n\t\tstd::string slotName = asLowerCaseString(getString(L, 2));\n\t\tif (slotName == \"head\") {\n\t\t\tmoveevent->setSlot(SLOTP_HEAD);\n\t\t} else if (slotName == \"necklace\") {\n\t\t\tmoveevent->setSlot(SLOTP_NECKLACE);\n\t\t} else if (slotName == \"backpack\") {\n\t\t\tmoveevent->setSlot(SLOTP_BACKPACK);\n\t\t} else if (slotName == \"armor\" || slotName == \"body\") {\n\t\t\tmoveevent->setSlot(SLOTP_ARMOR);\n\t\t} else if (slotName == \"right-hand\") {\n\t\t\tmoveevent->setSlot(SLOTP_RIGHT);\n\t\t} else if (slotName == \"left-hand\") {\n\t\t\tmoveevent->setSlot(SLOTP_LEFT);\n\t\t} else if (slotName == \"hand\" || slotName == \"shield\") {\n\t\t\tmoveevent->setSlot(SLOTP_RIGHT | SLOTP_LEFT);\n\t\t} else if (slotName == \"legs\") {\n\t\t\tmoveevent->setSlot(SLOTP_LEGS);\n\t\t} else if (slotName == \"feet\") {\n\t\t\tmoveevent->setSlot(SLOTP_FEET);\n\t\t} else if (slotName == \"ring\") {\n\t\t\tmoveevent->setSlot(SLOTP_RING);\n\t\t} else if (slotName == \"ammo\") {\n\t\t\tmoveevent->setSlot(SLOTP_AMMO);\n\t\t} else {\n\t\t\tstd::cout << \"[Warning - MoveEvent::configureMoveEvent] Unknown slot type: \" << slotName << std::endl;\n\t\t\tpushBoolean(L, false);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tpushBoolean(L, true);\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMoveEventLevel(lua_State* L)\n{\n\t// moveevent:level(lvl)\n\tMoveEvent* moveevent = getUserdata<MoveEvent>(L, 1);\n\tif (moveevent) {\n\t\tmoveevent->setRequiredLevel(getNumber<uint32_t>(L, 2));\n\t\tmoveevent->setWieldInfo(WIELDINFO_LEVEL);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMoveEventMagLevel(lua_State* L)\n{\n\t// moveevent:magicLevel(lvl)\n\tMoveEvent* moveevent = getUserdata<MoveEvent>(L, 1);\n\tif (moveevent) {\n\t\tmoveevent->setRequiredMagLevel(getNumber<uint32_t>(L, 2));\n\t\tmoveevent->setWieldInfo(WIELDINFO_MAGLV);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMoveEventPremium(lua_State* L)\n{\n\t// moveevent:premium(bool)\n\tMoveEvent* moveevent = getUserdata<MoveEvent>(L, 1);\n\tif (moveevent) {\n\t\tmoveevent->setNeedPremium(getBoolean(L, 2));\n\t\tmoveevent->setWieldInfo(WIELDINFO_PREMIUM);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMoveEventVocation(lua_State* L)\n{\n\t// moveevent:vocation(vocName[, showInDescription = false, lastVoc = false])\n\tMoveEvent* moveevent = getUserdata<MoveEvent>(L, 1);\n\tif (moveevent) {\n\t\tmoveevent->addVocEquipMap(getString(L, 2));\n\t\tmoveevent->setWieldInfo(WIELDINFO_VOCREQ);\n\t\tstd::string tmp;\n\t\tbool showInDescription = false;\n\t\tbool lastVoc = false;\n\t\tif (getBoolean(L, 3)) {\n\t\t\tshowInDescription = getBoolean(L, 3);\n\t\t}\n\t\tif (getBoolean(L, 4)) {\n\t\t\tlastVoc = getBoolean(L, 4);\n\t\t}\n\t\tif (showInDescription) {\n\t\t\tif (moveevent->getVocationString().empty()) {\n\t\t\t\ttmp = asLowerCaseString(getString(L, 2));\n\t\t\t\ttmp += \"s\";\n\t\t\t\tmoveevent->setVocationString(tmp);\n\t\t\t} else {\n\t\t\t\ttmp = moveevent->getVocationString();\n\t\t\t\tif (lastVoc) {\n\t\t\t\t\ttmp += \" and \";\n\t\t\t\t} else {\n\t\t\t\t\ttmp += \", \";\n\t\t\t\t}\n\t\t\t\ttmp += asLowerCaseString(getString(L, 2));\n\t\t\t\ttmp += \"s\";\n\t\t\t\tmoveevent->setVocationString(tmp);\n\t\t\t}\n\t\t}\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMoveEventItemId(lua_State* L)\n{\n\t// moveevent:id(ids)\n\tMoveEvent* moveevent = getUserdata<MoveEvent>(L, 1);\n\tif (moveevent) {\n\t\tint parameters = lua_gettop(L) - 1; // - 1 because self is a parameter aswell, which we want to skip ofc\n\t\tif (parameters > 1) {\n\t\t\tfor (int i = 0; i < parameters; ++i) {\n\t\t\t\tmoveevent->addItemId(getNumber<uint32_t>(L, 2 + i));\n\t\t\t}\n\t\t} else {\n\t\t\tmoveevent->addItemId(getNumber<uint32_t>(L, 2));\n\t\t}\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMoveEventActionId(lua_State* L)\n{\n\t// moveevent:aid(ids)\n\tMoveEvent* moveevent = getUserdata<MoveEvent>(L, 1);\n\tif (moveevent) {\n\t\tint parameters = lua_gettop(L) - 1; // - 1 because self is a parameter aswell, which we want to skip ofc\n\t\tif (parameters > 1) {\n\t\t\tfor (int i = 0; i < parameters; ++i) {\n\t\t\t\tmoveevent->addActionId(getNumber<uint32_t>(L, 2 + i));\n\t\t\t}\n\t\t} else {\n\t\t\tmoveevent->addActionId(getNumber<uint32_t>(L, 2));\n\t\t}\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMoveEventUniqueId(lua_State* L)\n{\n\t// moveevent:uid(ids)\n\tMoveEvent* moveevent = getUserdata<MoveEvent>(L, 1);\n\tif (moveevent) {\n\t\tint parameters = lua_gettop(L) - 1; // - 1 because self is a parameter aswell, which we want to skip ofc\n\t\tif (parameters > 1) {\n\t\t\tfor (int i = 0; i < parameters; ++i) {\n\t\t\t\tmoveevent->addUniqueId(getNumber<uint32_t>(L, 2 + i));\n\t\t\t}\n\t\t} else {\n\t\t\tmoveevent->addUniqueId(getNumber<uint32_t>(L, 2));\n\t\t}\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaMoveEventPosition(lua_State* L)\n{\n\t// moveevent:position(positions)\n\tMoveEvent* moveevent = getUserdata<MoveEvent>(L, 1);\n\tif (moveevent) {\n\t\tint parameters = lua_gettop(L) - 1; // - 1 because self is a parameter aswell, which we want to skip ofc\n\t\tif (parameters > 1) {\n\t\t\tfor (int i = 0; i < parameters; ++i) {\n\t\t\t\tmoveevent->addPosList(getPosition(L, 2 + i));\n\t\t\t}\n\t\t} else {\n\t\t\tmoveevent->addPosList(getPosition(L, 2));\n\t\t}\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaCreateGlobalEvent(lua_State* L)\n{\n\t// GlobalEvent(eventName)\n\tif (getScriptEnv()->getScriptInterface() != &g_scripts->getScriptInterface()) {\n\t\treportErrorFunc(\"GlobalEvents can only be registered in the Scripts interface.\");\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tGlobalEvent* global = new GlobalEvent(getScriptEnv()->getScriptInterface());\n\tif (global) {\n\t\tglobal->setName(getString(L, 2));\n\t\tglobal->setEventType(GLOBALEVENT_NONE);\n\t\tglobal->fromLua = true;\n\t\tpushUserdata<GlobalEvent>(L, global);\n\t\tsetMetatable(L, -1, \"GlobalEvent\");\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGlobalEventType(lua_State* L)\n{\n\t// globalevent:type(callback)\n\tGlobalEvent* global = getUserdata<GlobalEvent>(L, 1);\n\tif (global) {\n\t\tstd::string typeName = getString(L, 2);\n\t\tstd::string tmpStr = asLowerCaseString(typeName);\n\t\tif (tmpStr == \"startup\") {\n\t\t\tglobal->setEventType(GLOBALEVENT_STARTUP);\n\t\t} else if (tmpStr == \"shutdown\") {\n\t\t\tglobal->setEventType(GLOBALEVENT_SHUTDOWN);\n\t\t} else if (tmpStr == \"record\") {\n\t\t\tglobal->setEventType(GLOBALEVENT_RECORD);\n\t\t} else {\n\t\t\tstd::cout << \"[Error - CreatureEvent::configureLuaEvent] Invalid type for global event: \" << typeName << std::endl;\n\t\t\tpushBoolean(L, false);\n\t\t}\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGlobalEventRegister(lua_State* L)\n{\n\t// globalevent:register()\n\tGlobalEvent* globalevent = getUserdata<GlobalEvent>(L, 1);\n\tif (globalevent) {\n\t\tif (!globalevent->isScripted()) {\n\t\t\tpushBoolean(L, false);\n\t\t\treturn 1;\n\t\t}\n\t\tpushBoolean(L, g_globalEvents->registerLuaEvent(globalevent));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGlobalEventOnCallback(lua_State* L)\n{\n\t// globalevent:onThink / record / etc. (callback)\n\tGlobalEvent* globalevent = getUserdata<GlobalEvent>(L, 1);\n\tif (globalevent) {\n\t\tif (!globalevent->loadCallback()) {\n\t\t\tpushBoolean(L, false);\n\t\t\treturn 1;\n\t\t}\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGlobalEventTime(lua_State* L)\n{\n\t// globalevent:time(time)\n\tGlobalEvent* globalevent = getUserdata<GlobalEvent>(L, 1);\n\tif (globalevent) {\n\t\tstd::string timer = getString(L, 2);\n\t\tstd::vector<int32_t> params = vectorAtoi(explodeString(timer, \":\"));\n\n\t\tint32_t hour = params.front();\n\t\tif (hour < 0 || hour > 23) {\n\t\t\tstd::cout << \"[Error - GlobalEvent::configureEvent] Invalid hour \\\"\" << timer << \"\\\" for globalevent with name: \" << globalevent->getName() << std::endl;\n\t\t\tpushBoolean(L, false);\n\t\t\treturn 1;\n\t\t}\n\n\t\tglobalevent->setInterval(hour << 16);\n\n\t\tint32_t min = 0;\n\t\tint32_t sec = 0;\n\t\tif (params.size() > 1) {\n\t\t\tmin = params[1];\n\t\t\tif (min < 0 || min > 59) {\n\t\t\t\tstd::cout << \"[Error - GlobalEvent::configureEvent] Invalid minute \\\"\" << timer << \"\\\" for globalevent with name: \" << globalevent->getName() << std::endl;\n\t\t\t\tpushBoolean(L, false);\n\t\t\t\treturn 1;\n\t\t\t}\n\n\t\t\tif (params.size() > 2) {\n\t\t\t\tsec = params[2];\n\t\t\t\tif (sec < 0 || sec > 59) {\n\t\t\t\t\tstd::cout << \"[Error - GlobalEvent::configureEvent] Invalid second \\\"\" << timer << \"\\\" for globalevent with name: \" << globalevent->getName() << std::endl;\n\t\t\t\t\tpushBoolean(L, false);\n\t\t\t\t\treturn 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\ttime_t current_time = time(nullptr);\n\t\ttm* timeinfo = localtime(&current_time);\n\t\ttimeinfo->tm_hour = hour;\n\t\ttimeinfo->tm_min = min;\n\t\ttimeinfo->tm_sec = sec;\n\n\t\ttime_t difference = static_cast<time_t>(difftime(mktime(timeinfo), current_time));\n\t\tif (difference < 0) {\n\t\t\tdifference += 86400;\n\t\t}\n\n\t\tglobalevent->setNextExecution(current_time + difference);\n\t\tglobalevent->setEventType(GLOBALEVENT_TIMER);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaGlobalEventInterval(lua_State* L)\n{\n\t// globalevent:interval(interval)\n\tGlobalEvent* globalevent = getUserdata<GlobalEvent>(L, 1);\n\tif (globalevent) {\n\t\tglobalevent->setInterval(getNumber<uint32_t>(L, 2));\n\t\tglobalevent->setNextExecution(OTSYS_TIME() + getNumber<uint32_t>(L, 2));\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\n// Weapon\nint LuaScriptInterface::luaCreateWeapon(lua_State* L)\n{\n\t// Weapon(type)\n\tif (getScriptEnv()->getScriptInterface() != &g_scripts->getScriptInterface()) {\n\t\treportErrorFunc(\"Weapons can only be registered in the Scripts interface.\");\n\t\tlua_pushnil(L);\n\t\treturn 1;\n\t}\n\n\tWeaponType_t type = getNumber<WeaponType_t>(L, 2);\n\tswitch (type) {\n\t\tcase WEAPON_SWORD:\n\t\tcase WEAPON_AXE:\n\t\tcase WEAPON_CLUB: {\n\t\t\tWeaponMelee* weapon = new WeaponMelee(getScriptEnv()->getScriptInterface());\n\t\t\tif (weapon) {\n\t\t\t\tpushUserdata<WeaponMelee>(L, weapon);\n\t\t\t\tsetMetatable(L, -1, \"Weapon\");\n\t\t\t\tweapon->weaponType = type;\n\t\t\t\tweapon->fromLua = true;\n\t\t\t} else {\n\t\t\t\tlua_pushnil(L);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tcase WEAPON_DISTANCE:\n\t\tcase WEAPON_AMMO: {\n\t\t\tWeaponDistance* weapon = new WeaponDistance(getScriptEnv()->getScriptInterface());\n\t\t\tif (weapon) {\n\t\t\t\tpushUserdata<WeaponDistance>(L, weapon);\n\t\t\t\tsetMetatable(L, -1, \"Weapon\");\n\t\t\t\tweapon->weaponType = type;\n\t\t\t\tweapon->fromLua = true;\n\t\t\t} else {\n\t\t\t\tlua_pushnil(L);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tcase WEAPON_WAND: {\n\t\t\tWeaponWand* weapon = new WeaponWand(getScriptEnv()->getScriptInterface());\n\t\t\tif (weapon) {\n\t\t\t\tpushUserdata<WeaponWand>(L, weapon);\n\t\t\t\tsetMetatable(L, -1, \"Weapon\");\n\t\t\t\tweapon->weaponType = type;\n\t\t\t\tweapon->fromLua = true;\n\t\t\t} else {\n\t\t\t\tlua_pushnil(L);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tdefault: {\n\t\t\tlua_pushnil(L);\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponAction(lua_State* L)\n{\n\t// weapon:action(callback)\n\tWeapon* weapon = getUserdata<Weapon>(L, 1);\n\tif (weapon) {\n\t\tstd::string typeName = getString(L, 2);\n\t\tstd::string tmpStr = asLowerCaseString(typeName);\n\t\tif (tmpStr == \"removecount\") {\n\t\t\tweapon->action = WEAPONACTION_REMOVECOUNT;\n\t\t} else if (tmpStr == \"removecharge\") {\n\t\t\tweapon->action = WEAPONACTION_REMOVECHARGE;\n\t\t} else if (tmpStr == \"move\") {\n\t\t\tweapon->action = WEAPONACTION_MOVE;\n\t\t} else {\n\t\t\tstd::cout << \"Error: [Weapon::action] No valid action \" << typeName << std::endl;\n\t\t\tpushBoolean(L, false);\n\t\t}\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponRegister(lua_State* L)\n{\n\t// weapon:register()\n\tWeapon* weapon = getUserdata<Weapon>(L, 1);\n\tif (weapon) {\n\t\tif (weapon->weaponType == WEAPON_DISTANCE || weapon->weaponType == WEAPON_AMMO) {\n\t\t\tweapon = getUserdata<WeaponDistance>(L, 1);\n\t\t} else if (weapon->weaponType == WEAPON_WAND) {\n\t\t\tweapon = getUserdata<WeaponWand>(L, 1);\n\t\t} else {\n\t\t\tweapon = getUserdata<WeaponMelee>(L, 1);\n\t\t}\n\n\t\tuint16_t id = weapon->getID();\n\t\tItemType& it = Item::items.getItemType(id);\n\t\tit.weaponType = weapon->weaponType;\n\n\t\tif (weapon->getWieldInfo() != 0) {\n\t\t\tit.wieldInfo = weapon->getWieldInfo();\n\t\t\tit.vocationString = weapon->getVocationString();\n\t\t\tit.minReqLevel = weapon->getReqLevel();\n\t\t\tit.minReqMagicLevel = weapon->getReqMagLv();\n\t\t}\n\n\t\tweapon->configureWeapon(it);\n\t\tpushBoolean(L, g_weapons->registerLuaEvent(weapon));\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponOnUseWeapon(lua_State* L)\n{\n\t// weapon:onUseWeapon(callback)\n\tWeapon* weapon = getUserdata<Weapon>(L, 1);\n\tif (weapon) {\n\t\tif (!weapon->loadCallback()) {\n\t\t\tpushBoolean(L, false);\n\t\t\treturn 1;\n\t\t}\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponUnproperly(lua_State* L)\n{\n\t// weapon:wieldedUnproperly(bool)\n\tWeapon* weapon = getUserdata<Weapon>(L, 1);\n\tif (weapon) {\n\t\tweapon->setWieldUnproperly(getBoolean(L, 2));\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponLevel(lua_State* L)\n{\n\t// weapon:level(lvl)\n\tWeapon* weapon = getUserdata<Weapon>(L, 1);\n\tif (weapon) {\n\t\tweapon->setRequiredLevel(getNumber<uint32_t>(L, 2));\n\t\tweapon->setWieldInfo(WIELDINFO_LEVEL);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponMagicLevel(lua_State* L)\n{\n\t// weapon:magicLevel(lvl)\n\tWeapon* weapon = getUserdata<Weapon>(L, 1);\n\tif (weapon) {\n\t\tweapon->setRequiredMagLevel(getNumber<uint32_t>(L, 2));\n\t\tweapon->setWieldInfo(WIELDINFO_MAGLV);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponMana(lua_State* L)\n{\n\t// weapon:mana(mana)\n\tWeapon* weapon = getUserdata<Weapon>(L, 1);\n\tif (weapon) {\n\t\tweapon->setMana(getNumber<uint32_t>(L, 2));\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponManaPercent(lua_State* L)\n{\n\t// weapon:manaPercent(percent)\n\tWeapon* weapon = getUserdata<Weapon>(L, 1);\n\tif (weapon) {\n\t\tweapon->setManaPercent(getNumber<uint32_t>(L, 2));\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponHealth(lua_State* L)\n{\n\t// weapon:health(health)\n\tWeapon* weapon = getUserdata<Weapon>(L, 1);\n\tif (weapon) {\n\t\tweapon->setHealth(getNumber<int32_t>(L, 2));\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponHealthPercent(lua_State* L)\n{\n\t// weapon:healthPercent(percent)\n\tWeapon* weapon = getUserdata<Weapon>(L, 1);\n\tif (weapon) {\n\t\tweapon->setHealthPercent(getNumber<uint32_t>(L, 2));\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponSoul(lua_State* L)\n{\n\t// weapon:soul(soul)\n\tWeapon* weapon = getUserdata<Weapon>(L, 1);\n\tif (weapon) {\n\t\tweapon->setSoul(getNumber<uint32_t>(L, 2));\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponBreakChance(lua_State* L)\n{\n\t// weapon:breakChance(percent)\n\tWeapon* weapon = getUserdata<Weapon>(L, 1);\n\tif (weapon) {\n\t\tweapon->setBreakChance(getNumber<uint32_t>(L, 2));\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponWandDamage(lua_State* L)\n{\n\t// weapon:damage(damage[min, max]) only use this if the weapon is a wand!\n\tWeaponWand* weapon = getUserdata<WeaponWand>(L, 1);\n\tif (weapon) {\n\t\tweapon->setMinChange(getNumber<uint32_t>(L, 2));\n\t\tif (lua_gettop(L) > 2) {\n\t\t\tweapon->setMaxChange(getNumber<uint32_t>(L, 3));\n\t\t} else {\n\t\t\tweapon->setMaxChange(getNumber<uint32_t>(L, 2));\n\t\t}\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponElement(lua_State* L)\n{\n\t// weapon:element(combatType)\n\tWeapon* weapon = getUserdata<Weapon>(L, 1);\n\tif (weapon) {\n\t\tif (!getNumber<CombatType_t>(L, 2)) {\n\t\t\tstd::string element = getString(L, 2);\n\t\t\tstd::string tmpStrValue = asLowerCaseString(element);\n\t\t\tif (tmpStrValue == \"earth\") {\n\t\t\t\tweapon->params.combatType = COMBAT_EARTHDAMAGE;\n\t\t\t} else if (tmpStrValue == \"ice\") {\n\t\t\t\tweapon->params.combatType = COMBAT_ICEDAMAGE;\n\t\t\t} else if (tmpStrValue == \"energy\") {\n\t\t\t\tweapon->params.combatType = COMBAT_ENERGYDAMAGE;\n\t\t\t} else if (tmpStrValue == \"fire\") {\n\t\t\t\tweapon->params.combatType = COMBAT_FIREDAMAGE;\n\t\t\t} else if (tmpStrValue == \"death\") {\n\t\t\t\tweapon->params.combatType = COMBAT_DEATHDAMAGE;\n\t\t\t} else if (tmpStrValue == \"holy\") {\n\t\t\t\tweapon->params.combatType = COMBAT_HOLYDAMAGE;\n\t\t\t} else {\n\t\t\t\tstd::cout << \"[Warning - weapon:element] Type \\\"\" << element << \"\\\" does not exist.\" << std::endl;\n\t\t\t}\n\t\t} else {\n\t\t\tweapon->params.combatType = getNumber<CombatType_t>(L, 2);\n\t\t}\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponPremium(lua_State* L)\n{\n\t// weapon:premium(bool)\n\tWeapon* weapon = getUserdata<Weapon>(L, 1);\n\tif (weapon) {\n\t\tweapon->setNeedPremium(getBoolean(L, 2));\n\t\tweapon->setWieldInfo(WIELDINFO_PREMIUM);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponVocation(lua_State* L)\n{\n\t// weapon:vocation(vocName[, showInDescription = false, lastVoc = false])\n\tWeapon* weapon = getUserdata<Weapon>(L, 1);\n\tif (weapon) {\n\t\tweapon->addVocWeaponMap(getString(L, 2));\n\t\tweapon->setWieldInfo(WIELDINFO_VOCREQ);\n\t\tstd::string tmp;\n\t\tbool showInDescription = getBoolean(L, 3, false);\n\t\tbool lastVoc = getBoolean(L, 4, false);\n\n\t\tif (showInDescription) {\n\t\t\tif (weapon->getVocationString().empty()) {\n\t\t\t\ttmp = asLowerCaseString(getString(L, 2));\n\t\t\t\ttmp += \"s\";\n\t\t\t\tweapon->setVocationString(tmp);\n\t\t\t} else {\n\t\t\t\ttmp = weapon->getVocationString();\n\t\t\t\tif (lastVoc) {\n\t\t\t\t\ttmp += \" and \";\n\t\t\t\t} else {\n\t\t\t\t\ttmp += \", \";\n\t\t\t\t}\n\t\t\t\ttmp += asLowerCaseString(getString(L, 2));\n\t\t\t\ttmp += \"s\";\n\t\t\t\tweapon->setVocationString(tmp);\n\t\t\t}\n\t\t}\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponId(lua_State* L)\n{\n\t// weapon:id(id)\n\tWeapon* weapon = getUserdata<Weapon>(L, 1);\n\tif (weapon) {\n\t\tweapon->setID(getNumber<uint32_t>(L, 2));\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponAttack(lua_State* L)\n{\n\t// weapon:attack(atk)\n\tWeapon* weapon = getUserdata<Weapon>(L, 1);\n\tif (weapon) {\n\t\tuint16_t id = weapon->getID();\n\t\tItemType& it = Item::items.getItemType(id);\n\t\tit.attack = getNumber<int32_t>(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponDefense(lua_State* L)\n{\n\t// weapon:defense(defense[, extraDefense])\n\tWeapon* weapon = getUserdata<Weapon>(L, 1);\n\tif (weapon) {\n\t\tuint16_t id = weapon->getID();\n\t\tItemType& it = Item::items.getItemType(id);\n\t\tit.defense = getNumber<int32_t>(L, 2);\n\t\tif (lua_gettop(L) > 2) {\n\t\t\tit.extraDefense = getNumber<int32_t>(L, 3);\n\t\t}\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponRange(lua_State* L)\n{\n\t// weapon:range(range)\n\tWeapon* weapon = getUserdata<Weapon>(L, 1);\n\tif (weapon) {\n\t\tuint16_t id = weapon->getID();\n\t\tItemType& it = Item::items.getItemType(id);\n\t\tit.shootRange = getNumber<uint8_t>(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponCharges(lua_State* L)\n{\n\t// weapon:charges(charges[, showCharges = true])\n\tWeapon* weapon = getUserdata<Weapon>(L, 1);\n\tif (weapon) {\n\t\tbool showCharges = getBoolean(L, 3, true);\n\t\tuint16_t id = weapon->getID();\n\t\tItemType& it = Item::items.getItemType(id);\n\n\t\tit.charges = getNumber<uint8_t>(L, 2);\n\t\tit.showCharges = showCharges;\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponDuration(lua_State* L)\n{\n\t// weapon:duration(duration[, showDuration = true])\n\tWeapon* weapon = getUserdata<Weapon>(L, 1);\n\tif (weapon) {\n\t\tbool showDuration = getBoolean(L, 3, true);\n\t\tuint16_t id = weapon->getID();\n\t\tItemType& it = Item::items.getItemType(id);\n\n\t\tit.decayTime = getNumber<uint32_t>(L, 2);\n\t\tit.showDuration = showDuration;\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponDecayTo(lua_State* L)\n{\n\t// weapon:decayTo([itemid = 0]\n\tWeapon* weapon = getUserdata<Weapon>(L, 1);\n\tif (weapon) {\n\t\tuint16_t itemid = getNumber<uint16_t>(L, 2, 0);\n\t\tuint16_t id = weapon->getID();\n\t\tItemType& it = Item::items.getItemType(id);\n\n\t\tit.decayTo = itemid;\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponTransformEquipTo(lua_State* L)\n{\n\t// weapon:transformEquipTo(itemid)\n\tWeapon* weapon = getUserdata<Weapon>(L, 1);\n\tif (weapon) {\n\t\tuint16_t id = weapon->getID();\n\t\tItemType& it = Item::items.getItemType(id);\n\t\tit.transformEquipTo = getNumber<uint16_t>(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponTransformDeEquipTo(lua_State* L)\n{\n\t// weapon:transformDeEquipTo(itemid)\n\tWeapon* weapon = getUserdata<Weapon>(L, 1);\n\tif (weapon) {\n\t\tuint16_t id = weapon->getID();\n\t\tItemType& it = Item::items.getItemType(id);\n\t\tit.transformDeEquipTo = getNumber<uint16_t>(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponShootType(lua_State* L)\n{\n\t// weapon:shootType(type)\n\tWeapon* weapon = getUserdata<Weapon>(L, 1);\n\tif (weapon) {\n\t\tuint16_t id = weapon->getID();\n\t\tItemType& it = Item::items.getItemType(id);\n\t\tit.shootType = getNumber<ShootType_t>(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponSlotType(lua_State* L)\n{\n\t// weapon:slotType(slot)\n\tWeapon* weapon = getUserdata<Weapon>(L, 1);\n\tif (weapon) {\n\t\tuint16_t id = weapon->getID();\n\t\tItemType& it = Item::items.getItemType(id);\n\t\tstd::string slot = getString(L, 2);\n\n\t\tif (slot == \"two-handed\") {\n\t\t\tit.slotPosition |= SLOTP_TWO_HAND;\n\t\t} else {\n\t\t\tit.slotPosition |= SLOTP_HAND;\n\t\t}\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponAmmoType(lua_State* L)\n{\n\t// weapon:ammoType(type)\n\tWeaponDistance* weapon = getUserdata<WeaponDistance>(L, 1);\n\tif (weapon) {\n\t\tuint16_t id = weapon->getID();\n\t\tItemType& it = Item::items.getItemType(id);\n\t\tstd::string type = getString(L, 2);\n\n\t\tif (type == \"arrow\") {\n\t\t\tit.ammoType = AMMO_ARROW;\n\t\t} else if (type == \"bolt\"){\n\t\t\tit.ammoType = AMMO_BOLT;\n\t\t} else {\n\t\t\tstd::cout << \"[Warning - weapon:ammoType] Type \\\"\" << type << \"\\\" does not exist.\" << std::endl;\n\t\t\tlua_pushnil(L);\n\t\t\treturn 1;\n\t\t}\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponHitChance(lua_State* L)\n{\n\t// weapon:hitChance(chance)\n\tWeapon* weapon = getUserdata<Weapon>(L, 1);\n\tif (weapon) {\n\t\tuint16_t id = weapon->getID();\n\t\tItemType& it = Item::items.getItemType(id);\n\t\tit.hitChance = getNumber<int8_t>(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponMaxHitChance(lua_State* L)\n{\n\t// weapon:maxHitChance(max)\n\tWeapon* weapon = getUserdata<Weapon>(L, 1);\n\tif (weapon) {\n\t\tuint16_t id = weapon->getID();\n\t\tItemType& it = Item::items.getItemType(id);\n\t\tit.maxHitChance = getNumber<int32_t>(L, 2);\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\nint LuaScriptInterface::luaWeaponExtraElement(lua_State* L)\n{\n\t// weapon:extraElement(atk, combatType)\n\tWeapon* weapon = getUserdata<Weapon>(L, 1);\n\tif (weapon) {\n\t\tuint16_t id = weapon->getID();\n\t\tItemType& it = Item::items.getItemType(id);\n\t\tit.abilities.get()->elementDamage = getNumber<uint16_t>(L, 2);\n\n\t\tif (!getNumber<CombatType_t>(L, 3)) {\n\t\t\tstd::string element = getString(L, 3);\n\t\t\tstd::string tmpStrValue = asLowerCaseString(element);\n\t\t\tif (tmpStrValue == \"earth\") {\n\t\t\t\tit.abilities.get()->elementType = COMBAT_EARTHDAMAGE;\n\t\t\t} else if (tmpStrValue == \"ice\") {\n\t\t\t\tit.abilities.get()->elementType = COMBAT_ICEDAMAGE;\n\t\t\t} else if (tmpStrValue == \"energy\") {\n\t\t\t\tit.abilities.get()->elementType = COMBAT_ENERGYDAMAGE;\n\t\t\t} else if (tmpStrValue == \"fire\") {\n\t\t\t\tit.abilities.get()->elementType = COMBAT_FIREDAMAGE;\n\t\t\t} else if (tmpStrValue == \"death\") {\n\t\t\t\tit.abilities.get()->elementType = COMBAT_DEATHDAMAGE;\n\t\t\t} else if (tmpStrValue == \"holy\") {\n\t\t\t\tit.abilities.get()->elementType = COMBAT_HOLYDAMAGE;\n\t\t\t} else {\n\t\t\t\tstd::cout << \"[Warning - weapon:extraElement] Type \\\"\" << element << \"\\\" does not exist.\" << std::endl;\n\t\t\t}\n\t\t} else {\n\t\t\tit.abilities.get()->elementType = getNumber<CombatType_t>(L, 3);\n\t\t}\n\t\tpushBoolean(L, true);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\treturn 1;\n}\n\n//\nLuaEnvironment::LuaEnvironment() : LuaScriptInterface(\"Main Interface\") {}\n\nLuaEnvironment::~LuaEnvironment()\n{\n\tdelete testInterface;\n\tcloseState();\n}\n\nbool LuaEnvironment::initState()\n{\n\tluaState = luaL_newstate();\n\tif (!luaState) {\n\t\treturn false;\n\t}\n\n\tluaL_openlibs(luaState);\n\tregisterFunctions();\n\n\trunningEventId = EVENT_ID_USER;\n\treturn true;\n}\n\nbool LuaEnvironment::reInitState()\n{\n\t// TODO: get children, reload children\n\tcloseState();\n\treturn initState();\n}\n\nbool LuaEnvironment::closeState()\n{\n\tif (!luaState) {\n\t\treturn false;\n\t}\n\n\tfor (const auto& combatEntry : combatIdMap) {\n\t\tclearCombatObjects(combatEntry.first);\n\t}\n\n\tfor (const auto& areaEntry : areaIdMap) {\n\t\tclearAreaObjects(areaEntry.first);\n\t}\n\n\tfor (auto& timerEntry : timerEvents) {\n\t\tLuaTimerEventDesc timerEventDesc = std::move(timerEntry.second);\n\t\tfor (int32_t parameter : timerEventDesc.parameters) {\n\t\t\tluaL_unref(luaState, LUA_REGISTRYINDEX, parameter);\n\t\t}\n\t\tluaL_unref(luaState, LUA_REGISTRYINDEX, timerEventDesc.function);\n\t}\n\n\tcombatIdMap.clear();\n\tareaIdMap.clear();\n\ttimerEvents.clear();\n\tcacheFiles.clear();\n\n\tlua_close(luaState);\n\tluaState = nullptr;\n\treturn true;\n}\n\nLuaScriptInterface* LuaEnvironment::getTestInterface()\n{\n\tif (!testInterface) {\n\t\ttestInterface = new LuaScriptInterface(\"Test Interface\");\n\t\ttestInterface->initState();\n\t}\n\treturn testInterface;\n}\n\nCombat* LuaEnvironment::getCombatObject(uint32_t id) const\n{\n\tauto it = combatMap.find(id);\n\tif (it == combatMap.end()) {\n\t\treturn nullptr;\n\t}\n\treturn it->second;\n}\n\nCombat* LuaEnvironment::createCombatObject(LuaScriptInterface* interface)\n{\n\tCombat* combat = new Combat;\n\tcombatMap[++lastCombatId] = combat;\n\tcombatIdMap[interface].push_back(lastCombatId);\n\treturn combat;\n}\n\nvoid LuaEnvironment::clearCombatObjects(LuaScriptInterface* interface)\n{\n\tauto it = combatIdMap.find(interface);\n\tif (it == combatIdMap.end()) {\n\t\treturn;\n\t}\n\n\tfor (uint32_t id : it->second) {\n\t\tauto itt = combatMap.find(id);\n\t\tif (itt != combatMap.end()) {\n\t\t\tdelete itt->second;\n\t\t\tcombatMap.erase(itt);\n\t\t}\n\t}\n\tit->second.clear();\n}\n\nAreaCombat* LuaEnvironment::getAreaObject(uint32_t id) const\n{\n\tauto it = areaMap.find(id);\n\tif (it == areaMap.end()) {\n\t\treturn nullptr;\n\t}\n\treturn it->second;\n}\n\nuint32_t LuaEnvironment::createAreaObject(LuaScriptInterface* interface)\n{\n\tareaMap[++lastAreaId] = new AreaCombat;\n\tareaIdMap[interface].push_back(lastAreaId);\n\treturn lastAreaId;\n}\n\nvoid LuaEnvironment::clearAreaObjects(LuaScriptInterface* interface)\n{\n\tauto it = areaIdMap.find(interface);\n\tif (it == areaIdMap.end()) {\n\t\treturn;\n\t}\n\n\tfor (uint32_t id : it->second) {\n\t\tauto itt = areaMap.find(id);\n\t\tif (itt != areaMap.end()) {\n\t\t\tdelete itt->second;\n\t\t\tareaMap.erase(itt);\n\t\t}\n\t}\n\tit->second.clear();\n}\n\nvoid LuaEnvironment::executeTimerEvent(uint32_t eventIndex)\n{\n\tauto it = timerEvents.find(eventIndex);\n\tif (it == timerEvents.end()) {\n\t\treturn;\n\t}\n\n\tLuaTimerEventDesc timerEventDesc = std::move(it->second);\n\ttimerEvents.erase(it);\n\n\t//push function\n\tlua_rawgeti(luaState, LUA_REGISTRYINDEX, timerEventDesc.function);\n\n\t//push parameters\n\tfor (auto parameter : boost::adaptors::reverse(timerEventDesc.parameters)) {\n\t\tlua_rawgeti(luaState, LUA_REGISTRYINDEX, parameter);\n\t}\n\n\t//call the function\n\tif (reserveScriptEnv()) {\n\t\tScriptEnvironment* env = getScriptEnv();\n\t\tenv->setTimerEvent();\n\t\tenv->setScriptId(timerEventDesc.scriptId, this);\n\t\tcallFunction(timerEventDesc.parameters.size());\n\t} else {\n\t\tstd::cout << \"[Error - LuaScriptInterface::executeTimerEvent] Call stack overflow\" << std::endl;\n\t}\n\n\t//free resources\n\tluaL_unref(luaState, LUA_REGISTRYINDEX, timerEventDesc.function);\n\tfor (auto parameter : timerEventDesc.parameters) {\n\t\tluaL_unref(luaState, LUA_REGISTRYINDEX, parameter);\n\t}\n}\n", "idx": 68, "id": 18738, "msg": "", "proj": "otland-forgottenserver", "lang": "cpp"}
{"patch": "@@ -463,6 +463,7 @@ func (m *executionManagerImpl) SerializeWorkflowSnapshot(\n \t\tTransferTasks:    input.TransferTasks,\n \t\tReplicationTasks: input.ReplicationTasks,\n \t\tTimerTasks:       input.TimerTasks,\n+\t\tVisibilityTasks:  input.VisibilityTasks,\n \n \t\tCondition: input.Condition,\n \t\tChecksum:  input.Checksum,", "y": 1, "oldf": "// The MIT License\n//\n// Copyright (c) 2020 Temporal Technologies Inc.  All rights reserved.\n//\n// Copyright (c) 2020 Uber Technologies, Inc.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n// THE SOFTWARE.\n\npackage persistence\n\nimport (\n\tcommonpb \"go.temporal.io/api/common/v1\"\n\tenumspb \"go.temporal.io/api/enums/v1\"\n\thistorypb \"go.temporal.io/api/history/v1\"\n\tworkflowpb \"go.temporal.io/api/workflow/v1\"\n\n\thistoryspb \"go.temporal.io/server/api/history/v1\"\n\tpersistencespb \"go.temporal.io/server/api/persistence/v1\"\n\t\"go.temporal.io/server/common\"\n\t\"go.temporal.io/server/common/log\"\n\t\"go.temporal.io/server/common/persistence/versionhistory\"\n)\n\ntype (\n\t// executionManagerImpl implements ExecutionManager based on ExecutionStore, statsComputer and PayloadSerializer\n\texecutionManagerImpl struct {\n\t\tserializer    PayloadSerializer\n\t\tpersistence   ExecutionStore\n\t\tstatsComputer statsComputer\n\t\tlogger        log.Logger\n\t}\n)\n\nvar _ ExecutionManager = (*executionManagerImpl)(nil)\n\n// NewExecutionManagerImpl returns new ExecutionManager\nfunc NewExecutionManagerImpl(\n\tpersistence ExecutionStore,\n\tlogger log.Logger,\n) ExecutionManager {\n\n\treturn &executionManagerImpl{\n\t\tserializer:    NewPayloadSerializer(),\n\t\tpersistence:   persistence,\n\t\tstatsComputer: statsComputer{},\n\t\tlogger:        logger,\n\t}\n}\n\nfunc (m *executionManagerImpl) GetName() string {\n\treturn m.persistence.GetName()\n}\n\nfunc (m *executionManagerImpl) GetShardID() int32 {\n\treturn m.persistence.GetShardID()\n}\n\n// The below three APIs are related to serialization/deserialization\nfunc (m *executionManagerImpl) GetWorkflowExecution(\n\trequest *GetWorkflowExecutionRequest,\n) (*GetWorkflowExecutionResponse, error) {\n\n\tresponse, err := m.persistence.GetWorkflowExecution(request)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tnewResponse := &GetWorkflowExecutionResponse{\n\t\tState: &persistencespb.WorkflowMutableState{\n\t\t\tActivityInfos:       response.State.ActivityInfos,\n\t\t\tTimerInfos:          response.State.TimerInfos,\n\t\t\tRequestCancelInfos:  response.State.RequestCancelInfos,\n\t\t\tSignalInfos:         response.State.SignalInfos,\n\t\t\tSignalRequestedIds:  response.State.SignalRequestedIDs,\n\t\t\tChecksum:            response.State.Checksum,\n\t\t\tChildExecutionInfos: response.State.ChildExecutionInfos,\n\t\t\tExecutionState:      response.State.ExecutionState,\n\t\t\tNextEventId:         response.State.NextEventID,\n\t\t},\n\t}\n\n\tnewResponse.State.BufferedEvents, err = m.DeserializeBufferedEvents(response.State.BufferedEvents)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tnewResponse.State.ExecutionInfo, err = m.DeserializeExecutionInfo(response.State.ExecutionInfo)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tnewResponse.MutableStateStats = m.statsComputer.computeMutableStateStats(response)\n\n\treturn newResponse, nil\n}\n\nfunc (m *executionManagerImpl) DeserializeExecutionInfo(\n\t// TODO: info should be a blob\n\tinfo *persistencespb.WorkflowExecutionInfo,\n) (*persistencespb.WorkflowExecutionInfo, error) {\n\tnewInfo := &persistencespb.WorkflowExecutionInfo{\n\t\tCompletionEvent:                   info.CompletionEvent,\n\t\tNamespaceId:                       info.NamespaceId,\n\t\tWorkflowId:                        info.WorkflowId,\n\t\tFirstExecutionRunId:               info.FirstExecutionRunId,\n\t\tParentNamespaceId:                 info.ParentNamespaceId,\n\t\tParentWorkflowId:                  info.ParentWorkflowId,\n\t\tParentRunId:                       info.ParentRunId,\n\t\tInitiatedId:                       info.InitiatedId,\n\t\tCompletionEventBatchId:            info.CompletionEventBatchId,\n\t\tTaskQueue:                         info.TaskQueue,\n\t\tWorkflowTypeName:                  info.WorkflowTypeName,\n\t\tWorkflowRunTimeout:                info.WorkflowRunTimeout,\n\t\tWorkflowExecutionTimeout:          info.WorkflowExecutionTimeout,\n\t\tDefaultWorkflowTaskTimeout:        info.DefaultWorkflowTaskTimeout,\n\t\tLastFirstEventId:                  info.LastFirstEventId,\n\t\tLastEventTaskId:                   info.LastEventTaskId,\n\t\tLastProcessedEvent:                info.LastProcessedEvent,\n\t\tStartTime:                         info.StartTime,\n\t\tLastUpdateTime:                    info.LastUpdateTime,\n\t\tSignalCount:                       info.SignalCount,\n\t\tWorkflowTaskVersion:               info.WorkflowTaskVersion,\n\t\tWorkflowTaskScheduleId:            info.WorkflowTaskScheduleId,\n\t\tWorkflowTaskStartedId:             info.WorkflowTaskStartedId,\n\t\tWorkflowTaskRequestId:             info.WorkflowTaskRequestId,\n\t\tWorkflowTaskTimeout:               info.WorkflowTaskTimeout,\n\t\tWorkflowTaskAttempt:               info.WorkflowTaskAttempt,\n\t\tWorkflowTaskStartedTime:           info.WorkflowTaskStartedTime,\n\t\tWorkflowTaskScheduledTime:         info.WorkflowTaskScheduledTime,\n\t\tWorkflowTaskOriginalScheduledTime: info.WorkflowTaskOriginalScheduledTime,\n\t\tCancelRequested:                   info.CancelRequested,\n\t\tStickyTaskQueue:                   info.StickyTaskQueue,\n\t\tStickyScheduleToStartTimeout:      info.StickyScheduleToStartTimeout,\n\t\tAttempt:                           info.Attempt,\n\t\tHasRetryPolicy:                    info.HasRetryPolicy,\n\t\tRetryInitialInterval:              info.RetryInitialInterval,\n\t\tRetryBackoffCoefficient:           info.RetryBackoffCoefficient,\n\t\tRetryMaximumInterval:              info.RetryMaximumInterval,\n\t\tRetryMaximumAttempts:              info.RetryMaximumAttempts,\n\t\tRetryNonRetryableErrorTypes:       info.RetryNonRetryableErrorTypes,\n\t\tEventBranchToken:                  info.EventBranchToken,\n\t\tCronSchedule:                      info.CronSchedule,\n\t\tAutoResetPoints:                   info.AutoResetPoints,\n\t\tSearchAttributes:                  info.SearchAttributes,\n\t\tMemo:                              info.Memo,\n\t\tExecutionStats:                    info.ExecutionStats,\n\t\tStartVersion:                      info.StartVersion,\n\t\tHistorySize:                       info.HistorySize,\n\t\tCancelRequestId:                   info.CancelRequestId,\n\t\tVersionHistories:                  info.VersionHistories,\n\t\tWorkflowRunExpirationTime:         info.WorkflowRunExpirationTime,\n\t\tWorkflowExecutionExpirationTime:   info.WorkflowExecutionExpirationTime,\n\t}\n\n\tif newInfo.AutoResetPoints == nil {\n\t\tnewInfo.AutoResetPoints = &workflowpb.ResetPoints{}\n\t}\n\n\treturn newInfo, nil\n}\n\nfunc (m *executionManagerImpl) DeserializeBufferedEvents(\n\tblobs []*commonpb.DataBlob,\n) ([]*historypb.HistoryEvent, error) {\n\n\tevents := make([]*historypb.HistoryEvent, 0)\n\tfor _, b := range blobs {\n\t\tif b == nil {\n\t\t\t// Should not happen, log and discard to prevent callers from consuming\n\t\t\tm.logger.Warn(\"discarding nil buffered event\")\n\t\t\tcontinue\n\t\t}\n\n\t\thistory, err := m.serializer.DeserializeEvents(b)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tevents = append(events, history...)\n\t}\n\treturn events, nil\n}\n\nfunc (m *executionManagerImpl) UpdateWorkflowExecution(\n\trequest *UpdateWorkflowExecutionRequest,\n) (*UpdateWorkflowExecutionResponse, error) {\n\n\tserializedWorkflowMutation, err := m.SerializeWorkflowMutation(&request.UpdateWorkflowMutation)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvar serializedNewWorkflowSnapshot *InternalWorkflowSnapshot\n\tif request.NewWorkflowSnapshot != nil {\n\t\tserializedNewWorkflowSnapshot, err = m.SerializeWorkflowSnapshot(request.NewWorkflowSnapshot)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tnewRequest := &InternalUpdateWorkflowExecutionRequest{\n\t\tRangeID: request.RangeID,\n\n\t\tMode: request.Mode,\n\n\t\tUpdateWorkflowMutation: *serializedWorkflowMutation,\n\t\tNewWorkflowSnapshot:    serializedNewWorkflowSnapshot,\n\t}\n\n\tmsuss := m.statsComputer.computeMutableStateUpdateStats(newRequest)\n\terr1 := m.persistence.UpdateWorkflowExecution(newRequest)\n\treturn &UpdateWorkflowExecutionResponse{MutableStateUpdateSessionStats: msuss}, err1\n}\n\nfunc (m *executionManagerImpl) SerializeExecutionInfo(\n\tinfo *persistencespb.WorkflowExecutionInfo,\n\t// TODO: return blob here\n) (*persistencespb.WorkflowExecutionInfo, error) {\n\n\tif info == nil {\n\t\treturn &persistencespb.WorkflowExecutionInfo{}, nil\n\t}\n\n\treturn &persistencespb.WorkflowExecutionInfo{\n\t\tNamespaceId:                       info.NamespaceId,\n\t\tWorkflowId:                        info.WorkflowId,\n\t\tFirstExecutionRunId:               info.FirstExecutionRunId,\n\t\tParentNamespaceId:                 info.ParentNamespaceId,\n\t\tParentWorkflowId:                  info.ParentWorkflowId,\n\t\tParentRunId:                       info.ParentRunId,\n\t\tInitiatedId:                       info.InitiatedId,\n\t\tCompletionEventBatchId:            info.CompletionEventBatchId,\n\t\tCompletionEvent:                   info.CompletionEvent,\n\t\tTaskQueue:                         info.TaskQueue,\n\t\tWorkflowTypeName:                  info.WorkflowTypeName,\n\t\tWorkflowRunTimeout:                info.WorkflowRunTimeout,\n\t\tWorkflowExecutionTimeout:          info.WorkflowExecutionTimeout,\n\t\tDefaultWorkflowTaskTimeout:        info.DefaultWorkflowTaskTimeout,\n\t\tLastFirstEventId:                  info.LastFirstEventId,\n\t\tLastEventTaskId:                   info.LastEventTaskId,\n\t\tLastProcessedEvent:                info.LastProcessedEvent,\n\t\tStartTime:                         info.StartTime,\n\t\tLastUpdateTime:                    info.LastUpdateTime,\n\t\tSignalCount:                       info.SignalCount,\n\t\tWorkflowTaskVersion:               info.WorkflowTaskVersion,\n\t\tWorkflowTaskScheduleId:            info.WorkflowTaskScheduleId,\n\t\tWorkflowTaskStartedId:             info.WorkflowTaskStartedId,\n\t\tWorkflowTaskRequestId:             info.WorkflowTaskRequestId,\n\t\tWorkflowTaskTimeout:               info.WorkflowTaskTimeout,\n\t\tWorkflowTaskAttempt:               info.WorkflowTaskAttempt,\n\t\tWorkflowTaskStartedTime:           info.WorkflowTaskStartedTime,\n\t\tWorkflowTaskScheduledTime:         info.WorkflowTaskScheduledTime,\n\t\tWorkflowTaskOriginalScheduledTime: info.WorkflowTaskOriginalScheduledTime,\n\t\tCancelRequested:                   info.CancelRequested,\n\t\tStickyTaskQueue:                   info.StickyTaskQueue,\n\t\tStickyScheduleToStartTimeout:      info.StickyScheduleToStartTimeout,\n\t\tAutoResetPoints:                   info.AutoResetPoints,\n\t\tAttempt:                           info.Attempt,\n\t\tHasRetryPolicy:                    info.HasRetryPolicy,\n\t\tRetryInitialInterval:              info.RetryInitialInterval,\n\t\tRetryBackoffCoefficient:           info.RetryBackoffCoefficient,\n\t\tRetryMaximumInterval:              info.RetryMaximumInterval,\n\t\tRetryMaximumAttempts:              info.RetryMaximumAttempts,\n\t\tRetryNonRetryableErrorTypes:       info.RetryNonRetryableErrorTypes,\n\t\tEventBranchToken:                  info.EventBranchToken,\n\t\tCronSchedule:                      info.CronSchedule,\n\t\tMemo:                              info.Memo,\n\t\tSearchAttributes:                  info.SearchAttributes,\n\t\tWorkflowRunExpirationTime:         info.WorkflowRunExpirationTime,\n\t\tWorkflowExecutionExpirationTime:   info.WorkflowExecutionExpirationTime,\n\n\t\tExecutionStats:   info.ExecutionStats,\n\t\tVersionHistories: info.VersionHistories,\n\t\tCancelRequestId:  info.CancelRequestId,\n\t\tHistorySize:      info.HistorySize,\n\t\tStartVersion:     info.StartVersion,\n\t}, nil\n}\n\nfunc (m *executionManagerImpl) ConflictResolveWorkflowExecution(\n\trequest *ConflictResolveWorkflowExecutionRequest,\n) error {\n\n\tserializedResetWorkflowSnapshot, err := m.SerializeWorkflowSnapshot(&request.ResetWorkflowSnapshot)\n\tif err != nil {\n\t\treturn err\n\t}\n\tvar serializedCurrentWorkflowMutation *InternalWorkflowMutation\n\tif request.CurrentWorkflowMutation != nil {\n\t\tserializedCurrentWorkflowMutation, err = m.SerializeWorkflowMutation(request.CurrentWorkflowMutation)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tvar serializedNewWorkflowMutation *InternalWorkflowSnapshot\n\tif request.NewWorkflowSnapshot != nil {\n\t\tserializedNewWorkflowMutation, err = m.SerializeWorkflowSnapshot(request.NewWorkflowSnapshot)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tnewRequest := &InternalConflictResolveWorkflowExecutionRequest{\n\t\tRangeID: request.RangeID,\n\n\t\tMode: request.Mode,\n\n\t\tResetWorkflowSnapshot: *serializedResetWorkflowSnapshot,\n\n\t\tNewWorkflowSnapshot: serializedNewWorkflowMutation,\n\n\t\tCurrentWorkflowMutation: serializedCurrentWorkflowMutation,\n\t}\n\treturn m.persistence.ConflictResolveWorkflowExecution(newRequest)\n}\n\nfunc (m *executionManagerImpl) ResetWorkflowExecution(\n\trequest *ResetWorkflowExecutionRequest,\n) error {\n\n\tserializedNewWorkflowSnapshot, err := m.SerializeWorkflowSnapshot(&request.NewWorkflowSnapshot)\n\tif err != nil {\n\t\treturn err\n\t}\n\tvar serializedUpdateWorkflowSnapshot *InternalWorkflowMutation\n\tif request.CurrentWorkflowMutation != nil {\n\t\tserializedUpdateWorkflowSnapshot, err = m.SerializeWorkflowMutation(request.CurrentWorkflowMutation)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tnewRequest := &InternalResetWorkflowExecutionRequest{\n\t\tRangeID: request.RangeID,\n\n\t\tBaseRunID:          request.BaseRunID,\n\t\tBaseRunNextEventID: request.BaseRunNextEventID,\n\n\t\tCurrentRunID:          request.CurrentRunID,\n\t\tCurrentRunNextEventID: request.CurrentRunNextEventID,\n\n\t\tCurrentWorkflowMutation: serializedUpdateWorkflowSnapshot,\n\n\t\tNewWorkflowSnapshot: *serializedNewWorkflowSnapshot,\n\t}\n\treturn m.persistence.ResetWorkflowExecution(newRequest)\n}\n\nfunc (m *executionManagerImpl) CreateWorkflowExecution(\n\trequest *CreateWorkflowExecutionRequest,\n) (*CreateWorkflowExecutionResponse, error) {\n\n\tserializedNewWorkflowSnapshot, err := m.SerializeWorkflowSnapshot(&request.NewWorkflowSnapshot)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tnewRequest := &InternalCreateWorkflowExecutionRequest{\n\t\tRangeID: request.RangeID,\n\n\t\tMode: request.Mode,\n\n\t\tPreviousRunID:            request.PreviousRunID,\n\t\tPreviousLastWriteVersion: request.PreviousLastWriteVersion,\n\n\t\tNewWorkflowSnapshot: *serializedNewWorkflowSnapshot,\n\t}\n\n\treturn m.persistence.CreateWorkflowExecution(newRequest)\n}\n\nfunc (m *executionManagerImpl) SerializeWorkflowMutation(\n\tinput *WorkflowMutation,\n) (*InternalWorkflowMutation, error) {\n\n\tserializedExecutionInfo, err := m.SerializeExecutionInfo(input.ExecutionInfo)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar serializedNewBufferedEvents *commonpb.DataBlob\n\tif len(input.NewBufferedEvents) > 0 {\n\t\tserializedNewBufferedEvents, err = m.serializer.SerializeEvents(input.NewBufferedEvents, enumspb.ENCODING_TYPE_PROTO3)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tlastWriteVersion, err := getLastWriteVersion(input.ExecutionInfo.VersionHistories)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &InternalWorkflowMutation{\n\t\tExecutionInfo:    serializedExecutionInfo,\n\t\tExecutionState:   input.ExecutionState,\n\t\tNextEventID:      input.NextEventID,\n\t\tLastWriteVersion: lastWriteVersion,\n\n\t\tUpsertActivityInfos:       input.UpsertActivityInfos,\n\t\tDeleteActivityInfos:       input.DeleteActivityInfos,\n\t\tUpsertTimerInfos:          input.UpsertTimerInfos,\n\t\tDeleteTimerInfos:          input.DeleteTimerInfos,\n\t\tUpsertChildExecutionInfos: input.UpsertChildExecutionInfos,\n\t\tDeleteChildExecutionInfos: input.DeleteChildExecutionInfos,\n\t\tUpsertRequestCancelInfos:  input.UpsertRequestCancelInfos,\n\t\tDeleteRequestCancelInfos:  input.DeleteRequestCancelInfos,\n\t\tUpsertSignalInfos:         input.UpsertSignalInfos,\n\t\tDeleteSignalInfos:         input.DeleteSignalInfos,\n\t\tUpsertSignalRequestedIDs:  input.UpsertSignalRequestedIDs,\n\t\tDeleteSignalRequestedIDs:  input.DeleteSignalRequestedIDs,\n\t\tNewBufferedEvents:         serializedNewBufferedEvents,\n\t\tClearBufferedEvents:       input.ClearBufferedEvents,\n\n\t\tTransferTasks:    input.TransferTasks,\n\t\tReplicationTasks: input.ReplicationTasks,\n\t\tTimerTasks:       input.TimerTasks,\n\n\t\tCondition: input.Condition,\n\t\tChecksum:  input.Checksum,\n\t}, nil\n}\n\nfunc (m *executionManagerImpl) SerializeWorkflowSnapshot(\n\tinput *WorkflowSnapshot,\n) (*InternalWorkflowSnapshot, error) {\n\n\tserializedExecutionInfo, err := m.SerializeExecutionInfo(input.ExecutionInfo)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tlastWriteVersion, err := getLastWriteVersion(input.ExecutionInfo.VersionHistories)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &InternalWorkflowSnapshot{\n\t\tExecutionInfo:    serializedExecutionInfo,\n\t\tExecutionState:   input.ExecutionState,\n\t\tNextEventID:      input.NextEventID,\n\t\tLastWriteVersion: lastWriteVersion,\n\n\t\tActivityInfos:       input.ActivityInfos,\n\t\tTimerInfos:          input.TimerInfos,\n\t\tChildExecutionInfos: input.ChildExecutionInfos,\n\t\tRequestCancelInfos:  input.RequestCancelInfos,\n\t\tSignalInfos:         input.SignalInfos,\n\t\tSignalRequestedIDs:  input.SignalRequestedIDs,\n\n\t\tTransferTasks:    input.TransferTasks,\n\t\tReplicationTasks: input.ReplicationTasks,\n\t\tTimerTasks:       input.TimerTasks,\n\n\t\tCondition: input.Condition,\n\t\tChecksum:  input.Checksum,\n\t}, nil\n}\n\nfunc (m *executionManagerImpl) DeleteWorkflowExecution(\n\trequest *DeleteWorkflowExecutionRequest,\n) error {\n\treturn m.persistence.DeleteWorkflowExecution(request)\n}\n\nfunc (m *executionManagerImpl) DeleteCurrentWorkflowExecution(\n\trequest *DeleteCurrentWorkflowExecutionRequest,\n) error {\n\treturn m.persistence.DeleteCurrentWorkflowExecution(request)\n}\n\nfunc (m *executionManagerImpl) GetCurrentExecution(\n\trequest *GetCurrentExecutionRequest,\n) (*GetCurrentExecutionResponse, error) {\n\treturn m.persistence.GetCurrentExecution(request)\n}\n\nfunc (m *executionManagerImpl) ListConcreteExecutions(\n\trequest *ListConcreteExecutionsRequest,\n) (*ListConcreteExecutionsResponse, error) {\n\tresponse, err := m.persistence.ListConcreteExecutions(request)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tnewResponse := &ListConcreteExecutionsResponse{\n\t\tStates:    make([]*persistencespb.WorkflowMutableState, len(response.States)),\n\t\tPageToken: response.NextPageToken,\n\t}\n\tfor i, s := range response.States {\n\t\tstate := &persistencespb.WorkflowMutableState{\n\t\t\tActivityInfos:       s.ActivityInfos,\n\t\t\tTimerInfos:          s.TimerInfos,\n\t\t\tRequestCancelInfos:  s.RequestCancelInfos,\n\t\t\tSignalInfos:         s.SignalInfos,\n\t\t\tSignalRequestedIds:  s.SignalRequestedIDs,\n\t\t\tChecksum:            s.Checksum,\n\t\t\tChildExecutionInfos: s.ChildExecutionInfos,\n\t\t\tExecutionState:      s.ExecutionState,\n\t\t\tNextEventId:         s.NextEventID,\n\t\t}\n\n\t\tstate.BufferedEvents, err = m.DeserializeBufferedEvents(s.BufferedEvents)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tstate.ExecutionInfo, err = m.DeserializeExecutionInfo(s.ExecutionInfo)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tnewResponse.States[i] = state\n\t}\n\treturn newResponse, nil\n}\n\n// Transfer task related methods\nfunc (m *executionManagerImpl) GetTransferTask(\n\trequest *GetTransferTaskRequest,\n) (*GetTransferTaskResponse, error) {\n\treturn m.persistence.GetTransferTask(request)\n}\n\nfunc (m *executionManagerImpl) GetTransferTasks(\n\trequest *GetTransferTasksRequest,\n) (*GetTransferTasksResponse, error) {\n\treturn m.persistence.GetTransferTasks(request)\n}\n\nfunc (m *executionManagerImpl) CompleteTransferTask(\n\trequest *CompleteTransferTaskRequest,\n) error {\n\treturn m.persistence.CompleteTransferTask(request)\n}\n\nfunc (m *executionManagerImpl) RangeCompleteTransferTask(\n\trequest *RangeCompleteTransferTaskRequest,\n) error {\n\treturn m.persistence.RangeCompleteTransferTask(request)\n}\n\n// Replication task related methods\nfunc (m *executionManagerImpl) GetReplicationTask(\n\trequest *GetReplicationTaskRequest,\n) (*GetReplicationTaskResponse, error) {\n\treturn m.persistence.GetReplicationTask(request)\n}\n\nfunc (m *executionManagerImpl) GetReplicationTasks(\n\trequest *GetReplicationTasksRequest,\n) (*GetReplicationTasksResponse, error) {\n\treturn m.persistence.GetReplicationTasks(request)\n}\n\nfunc (m *executionManagerImpl) CompleteReplicationTask(\n\trequest *CompleteReplicationTaskRequest,\n) error {\n\treturn m.persistence.CompleteReplicationTask(request)\n}\n\nfunc (m *executionManagerImpl) RangeCompleteReplicationTask(\n\trequest *RangeCompleteReplicationTaskRequest,\n) error {\n\treturn m.persistence.RangeCompleteReplicationTask(request)\n}\n\nfunc (m *executionManagerImpl) PutReplicationTaskToDLQ(\n\trequest *PutReplicationTaskToDLQRequest,\n) error {\n\treturn m.persistence.PutReplicationTaskToDLQ(request)\n}\n\nfunc (m *executionManagerImpl) GetReplicationTasksFromDLQ(\n\trequest *GetReplicationTasksFromDLQRequest,\n) (*GetReplicationTasksFromDLQResponse, error) {\n\treturn m.persistence.GetReplicationTasksFromDLQ(request)\n}\n\nfunc (m *executionManagerImpl) DeleteReplicationTaskFromDLQ(\n\trequest *DeleteReplicationTaskFromDLQRequest,\n) error {\n\treturn m.persistence.DeleteReplicationTaskFromDLQ(request)\n}\n\nfunc (m *executionManagerImpl) RangeDeleteReplicationTaskFromDLQ(\n\trequest *RangeDeleteReplicationTaskFromDLQRequest,\n) error {\n\treturn m.persistence.RangeDeleteReplicationTaskFromDLQ(request)\n}\n\n// Timer related methods.\nfunc (m *executionManagerImpl) GetTimerTask(\n\trequest *GetTimerTaskRequest,\n) (*GetTimerTaskResponse, error) {\n\treturn m.persistence.GetTimerTask(request)\n}\n\nfunc (m *executionManagerImpl) GetTimerIndexTasks(\n\trequest *GetTimerIndexTasksRequest,\n) (*GetTimerIndexTasksResponse, error) {\n\treturn m.persistence.GetTimerIndexTasks(request)\n}\n\nfunc (m *executionManagerImpl) CompleteTimerTask(\n\trequest *CompleteTimerTaskRequest,\n) error {\n\treturn m.persistence.CompleteTimerTask(request)\n}\n\nfunc (m *executionManagerImpl) RangeCompleteTimerTask(\n\trequest *RangeCompleteTimerTaskRequest,\n) error {\n\treturn m.persistence.RangeCompleteTimerTask(request)\n}\n\nfunc (m *executionManagerImpl) Close() {\n\tm.persistence.Close()\n}\n\nfunc getLastWriteVersion(\n\tversionHistories *historyspb.VersionHistories,\n) (int64, error) {\n\n\tif versionHistories == nil {\n\t\treturn common.EmptyVersion, nil\n\t}\n\n\tversionHistory, err := versionhistory.GetCurrentVersionHistory(versionHistories)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\tversionHistoryItem, err := versionhistory.GetLastVersionHistoryItem(versionHistory)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\treturn versionHistoryItem.GetVersion(), nil\n}\n", "idx": 1, "id": 10835, "msg": "missing this logic on / after line 427", "proj": "temporalio-temporal", "lang": "go"}
{"patch": "@@ -850,13 +850,13 @@ define(['connectionManager', 'cardBuilder', 'registrationServices', 'appSettings\n \n                     }) + '\" class=\"more button-flat button-flat-mini sectionTitleTextButton\">';\n                     html += '<h2 class=\"sectionTitle sectionTitle-cards\">';\n-                    html += globalize.translate('sharedcomponents#HeaderOnNow');\n+                    html += globalize.translate('HeaderOnNow');\n                     html += '</h2>';\n                     html += '<i class=\"md-icon\">&#xE5CC;</i>';\n                     html += '</a>';\n \n                 } else {\n-                    html += '<h2 class=\"sectionTitle sectionTitle-cards\">' + globalize.translate('sharedcomponents#HeaderOnNow') + '</h2>';\n+                    html += '<h2 class=\"sectionTitle sectionTitle-cards\">' + globalize.translate('HeaderOnNow') + '</h2>';\n                 }\n                 html += '</div>';\n ", "y": 0, "oldf": "define(['connectionManager', 'cardBuilder', 'registrationServices', 'appSettings', 'dom', 'apphost', 'layoutManager', 'imageLoader', 'globalize', 'itemShortcuts', 'itemHelper', 'appRouter', 'emby-button', 'paper-icon-button-light', 'emby-itemscontainer', 'emby-scroller', 'emby-linkbutton', 'css!./homesections'], function (connectionManager, cardBuilder, registrationServices, appSettings, dom, appHost, layoutManager, imageLoader, globalize, itemShortcuts, itemHelper, appRouter) {\n    'use strict';\n\n    function getDefaultSection(index) {\n\n        switch (index) {\n\n            case 0:\n                return 'smalllibrarytiles';\n            case 1:\n                return 'resume';\n            case 2:\n                return 'resumeaudio';\n            case 3:\n                return 'livetv';\n            case 4:\n                return 'nextup';\n            case 5:\n                return 'latestmedia';\n            case 6:\n                return 'none';\n            default:\n                return '';\n        }\n    }\n\n    function getAllSectionsToShow(userSettings, sectionCount) {\n\n        var sections = [];\n\n        for (var i = 0, length = sectionCount; i < length; i++) {\n\n            var section = userSettings.get('homesection' + i) || getDefaultSection(i);\n\n            if (section === 'folders') {\n                section = getDefaultSection(0);\n            }\n\n            sections.push(section);\n        }\n\n        return sections;\n    }\n\n    function loadSections(elem, apiClient, user, userSettings) {\n\n        return getUserViews(apiClient, user.Id).then(function (userViews) {\n\n            var i, length;\n            var sectionCount = 7;\n\n            var html = '';\n            for (i = 0, length = sectionCount; i < length; i++) {\n\n                html += '<div class=\"verticalSection section' + i + '\"></div>';\n            }\n\n            elem.innerHTML = html;\n            elem.classList.add('homeSectionsContainer');\n\n            var promises = [];\n            var sections = getAllSectionsToShow(userSettings, sectionCount);\n\n            for (i = 0, length = sections.length; i < length; i++) {\n\n                promises.push(loadSection(elem, apiClient, user, userSettings, userViews, sections, i));\n            }\n\n            return Promise.all(promises).then(function () {\n\n                html = '';\n\n                var style = 'margin-top:4em;';\n\n                if (layoutManager.tv) {\n                    style += 'padding: 0 7.5%;';\n                }\n\n                html += '<div class=\"verticalSection padded-left padded-right customizeSection hide\" style=\"' + style + '\">';\n                html += '<a href=\"' + appRouter.getRouteUrl('settings') + '\" is=\"emby-linkbutton\" class=\"raised block\"><span>' + globalize.translate('sharedcomponents#HeaderCustomizeHomeScreen') + '</span></a>';\n                html += '</div>';\n\n                elem.insertAdjacentHTML('beforeend', html);\n\n                return resume(elem, {\n                    refresh: true,\n                    returnPromise: false\n                });\n            });\n        });\n    }\n\n    function destroySections(elem) {\n\n        var elems = elem.querySelectorAll('.itemsContainer');\n        var i, length;\n\n        for (i = 0, length = elems.length; i < length; i++) {\n\n            elems[i].fetchData = null;\n            elems[i].parentContainer = null;\n            elems[i].getItemsHtml = null;\n        }\n\n        elem.innerHTML = '';\n    }\n\n    function pause(elem) {\n\n        var elems = elem.querySelectorAll('.itemsContainer');\n        var i, length;\n        for (i = 0, length = elems.length; i < length; i++) {\n\n            elems[i].pause();\n        }\n    }\n\n    function resume(elem, options) {\n\n        var elems = elem.querySelectorAll('.itemsContainer');\n        var i, length;\n        var promises = [];\n\n        for (i = 0, length = elems.length; i < length; i++) {\n            promises.push(elems[i].resume(options));\n        }\n\n        var promise = Promise.all(promises).then(function () {\n            elem.querySelector('.customizeSection').classList.remove('hide');\n        });\n\n        if (!options || options.returnPromise !== false) {\n            return promise;\n        }\n    }\n\n    function loadSection(page, apiClient, user, userSettings, userViews, allSections, index) {\n\n        var section = allSections[index];\n        var userId = user.Id;\n\n        var elem = page.querySelector('.section' + index);\n\n        if (section === 'latestmedia') {\n            loadRecentlyAdded(elem, apiClient, user, userViews);\n        }\n        else if (section === 'librarytiles' || section === 'smalllibrarytiles' || section === 'smalllibrarytiles-automobile' || section === 'librarytiles-automobile') {\n            loadLibraryTiles(elem, apiClient, user, userSettings, 'smallBackdrop', userViews, allSections);\n        }\n        else if (section === 'librarybuttons') {\n            loadlibraryButtons(elem, apiClient, user, userSettings, userViews, allSections);\n        }\n        else if (section === 'resume') {\n            loadResumeVideo(elem, apiClient, userId);\n        }\n        else if (section === 'resumeaudio') {\n            loadResumeAudio(elem, apiClient, userId);\n        }\n        else if (section === 'activerecordings') {\n            loadLatestLiveTvRecordings(elem, true, apiClient, userId);\n        }\n        else if (section === 'nextup') {\n            loadNextUp(elem, apiClient, userId);\n        }\n        else if (section === 'onnow' || section === 'livetv') {\n            return loadOnNow(elem, apiClient, user);\n        }\n        else {\n\n            elem.innerHTML = '';\n\n            return Promise.resolve();\n        }\n        return Promise.resolve();\n    }\n\n    function getUserViews(apiClient, userId) {\n\n        return apiClient.getUserViews({}, userId || apiClient.getCurrentUserId()).then(function (result) {\n\n            return result.Items;\n        });\n    }\n\n    function enableScrollX() {\n        return true;\n    }\n\n    function getSquareShape() {\n        return enableScrollX() ? 'overflowSquare' : 'square';\n    }\n\n    function getThumbShape() {\n        return enableScrollX() ? 'overflowBackdrop' : 'backdrop';\n    }\n\n    function getPortraitShape() {\n        return enableScrollX() ? 'autooverflow' : 'auto';\n    }\n\n    function getLibraryButtonsHtml(items) {\n\n        var html = \"\";\n\n        html += '<div class=\"verticalSection verticalSection-extrabottompadding\">';\n        html += '<div class=\"sectionTitleContainer sectionTitleContainer-cards\">';\n        html += '<h2 class=\"sectionTitle sectionTitle-cards padded-left\">' + globalize.translate('sharedcomponents#HeaderMyMedia') + '</h2>';\n\n        if (!layoutManager.tv) {\n            html += '<button type=\"button\" is=\"paper-icon-button-light\" class=\"sectionTitleIconButton btnHomeScreenSettings\"><i class=\"md-icon\">&#xE5D3;</i></button>';\n        }\n\n        html += '</div>';\n\n        html += '<div is=\"emby-itemscontainer\" class=\"itemsContainer padded-left padded-right vertical-wrap focuscontainer-x\" data-multiselect=\"false\">';\n\n        // \"My Library\" backgrounds\n        for (var i = 0, length = items.length; i < length; i++) {\n\n            var item = items[i];\n\n            var icon;\n\n            switch (item.CollectionType) {\n                case \"movies\":\n                    icon = \"local_movies\";\n                    break;\n                case \"music\":\n                    icon = \"library_music\";\n                    break;\n                case \"photos\":\n                    icon = \"photo\";\n                    break;\n                case \"livetv\":\n                    icon = \"live_tv\";\n                    break;\n                case \"tvshows\":\n                    icon = \"live_tv\";\n                    break;\n                case \"trailers\":\n                    icon = \"local_movies\";\n                    break;\n                case \"homevideos\":\n                    icon = \"video_library\";\n                    break;\n                case \"musicvideos\":\n                    icon = \"video_library\";\n                    break;\n                case \"books\":\n                    icon = \"folder\";\n                    break;\n                case \"channels\":\n                    icon = \"folder\";\n                    break;\n                case \"playlists\":\n                    icon = \"folder\";\n                    break;\n                default:\n                    icon = \"folder\";\n                    break;\n            }\n\n            html += '<a is=\"emby-linkbutton\" href=\"' + appRouter.getRouteUrl(item) + '\" class=\"raised homeLibraryButton\"><i class=\"md-icon\">' + icon + '</i><span>' + item.Name + '</span></a>';\n        }\n\n        html += '</div>';\n        html += '</div>';\n\n        return html;\n    }\n\n    function loadlibraryButtons(elem, apiClient, user, userSettings, userViews) {\n        elem.classList.remove('verticalSection');\n        var html = getLibraryButtonsHtml(userViews);\n\n        elem.innerHTML = html;\n        bindHomeScreenSettingsIcon(elem, apiClient, user.Id, userSettings);\n        imageLoader.lazyChildren(elem);\n    }\n\n    /**\n     * Returns a random integer between min (inclusive) and max (inclusive)\n     * Using Math.round() will give you a non-uniform distribution!\n     */\n    function getRandomInt(min, max) {\n        return Math.floor(Math.random() * (max - min + 1)) + min;\n    }\n\n    function getFetchLatestItemsFn(serverId, parentId, collectionType) {\n\n        return function () {\n\n            var apiClient = connectionManager.getApiClient(serverId);\n\n            var limit = 16;\n\n            if (enableScrollX()) {\n\n                if (collectionType === 'music') {\n                    limit = 30;\n                }\n            }\n            else {\n\n                if (collectionType === 'tvshows') {\n                    limit = 5;\n                } else if (collectionType === 'music') {\n                    limit = 9;\n                } else {\n                    limit = 8;\n                }\n            }\n\n            var options = {\n\n                Limit: limit,\n                Fields: \"PrimaryImageAspectRatio,BasicSyncInfo\",\n                ImageTypeLimit: 1,\n                EnableImageTypes: \"Primary,Backdrop,Thumb\",\n                ParentId: parentId\n            };\n\n            return apiClient.getLatestItems(options);\n        };\n    }\n\n    function getLatestItemsHtmlFn(itemType, viewType) {\n\n        return function (items) {\n\n            var shape = itemType === 'Channel' || viewType === 'movies' ?\n                getPortraitShape() :\n                viewType === 'music' ?\n                    getSquareShape() :\n                    getThumbShape();\n\n            var cardLayout = false;\n\n            return cardBuilder.getCardsHtml({\n                items: items,\n                shape: shape,\n                preferThumb: viewType !== 'movies' && itemType !== 'Channel' && viewType !== 'music' ? 'auto' : null,\n                showUnplayedIndicator: false,\n                showChildCountIndicator: true,\n                context: 'home',\n                overlayText: false,\n                centerText: !cardLayout,\n                overlayPlayButton: viewType !== 'photos',\n                allowBottomPadding: !enableScrollX() && !cardLayout,\n                cardLayout: cardLayout,\n                showTitle: viewType !== 'photos',\n                showYear: viewType === 'movies' || viewType === 'tvshows' || !viewType,\n                showParentTitle: viewType === 'music' || viewType === 'tvshows' || !viewType || (cardLayout && (viewType === 'tvshows')),\n                lines: 2\n            });\n        };\n    }\n\n    function renderLatestSection(elem, apiClient, user, parent) {\n\n        var html = '';\n        html += '<div class=\"sectionTitleContainer sectionTitleContainer-cards padded-left\">';\n        if (!layoutManager.tv) {\n\n            html += '<a is=\"emby-linkbutton\" href=\"' + appRouter.getRouteUrl(parent, {\n\n                section: 'latest'\n\n            }) + '\" class=\"more button-flat button-flat-mini sectionTitleTextButton\">';\n            html += '<h2 class=\"sectionTitle sectionTitle-cards\">';\n            html += globalize.translate('sharedcomponents#LatestFromLibrary', parent.Name);\n            html += '</h2>';\n            html += '<i class=\"md-icon\">&#xE5CC;</i>';\n            html += '</a>';\n\n        } else {\n            html += '<h2 class=\"sectionTitle sectionTitle-cards\">' + globalize.translate('sharedcomponents#LatestFromLibrary', parent.Name) + '</h2>';\n        }\n        html += '</div>';\n\n        if (enableScrollX()) {\n            html += '<div is=\"emby-scroller\" data-mousewheel=\"false\" data-centerfocus=\"true\" class=\"padded-top-focusscale padded-bottom-focusscale\"><div is=\"emby-itemscontainer\" class=\"itemsContainer scrollSlider focuscontainer-x padded-left padded-right\">';\n        } else {\n            html += '<div is=\"emby-itemscontainer\" class=\"itemsContainer padded-left padded-right vertical-wrap focuscontainer-x\">';\n        }\n\n        if (enableScrollX()) {\n            html += '</div>';\n        }\n        html += '</div>';\n\n        elem.innerHTML = html;\n\n        var itemsContainer = elem.querySelector('.itemsContainer');\n        itemsContainer.fetchData = getFetchLatestItemsFn(apiClient.serverId(), parent.Id, parent.CollectionType);\n        itemsContainer.getItemsHtml = getLatestItemsHtmlFn(parent.Type, parent.CollectionType);\n        itemsContainer.parentContainer = elem;\n\n    }\n\n    function loadRecentlyAdded(elem, apiClient, user, userViews) {\n\n        elem.classList.remove('verticalSection');\n\n        var excludeViewTypes = ['playlists', 'livetv', 'boxsets', 'channels'];\n\n        for (var i = 0, length = userViews.length; i < length; i++) {\n\n            var item = userViews[i];\n\n            if (user.Configuration.LatestItemsExcludes.indexOf(item.Id) !== -1) {\n                continue;\n            }\n\n            if (excludeViewTypes.indexOf(item.CollectionType || []) !== -1) {\n                continue;\n            }\n\n            var frag = document.createElement('div');\n            frag.classList.add('verticalSection');\n            frag.classList.add('hide');\n            elem.appendChild(frag);\n\n            renderLatestSection(frag, apiClient, user, item);\n        }\n    }\n\n    function getRequirePromise(deps) {\n\n        return new Promise(function (resolve, reject) {\n\n            require(deps, resolve);\n        });\n    }\n\n    function showHomeScreenSettings(elem, options) {\n        return getRequirePromise(['homescreenSettingsDialog']).then(function (homescreenSettingsDialog) {\n\n            return homescreenSettingsDialog.show(options).then(function () {\n\n                dom.parentWithClass(elem, 'homeSectionsContainer').dispatchEvent(new CustomEvent('settingschange', {\n                    cancelable: false\n                }));\n            });\n        });\n    }\n\n    function bindHomeScreenSettingsIcon(elem, apiClient, userId, userSettings) {\n\n        var btnHomeScreenSettings = elem.querySelector('.btnHomeScreenSettings');\n        if (!btnHomeScreenSettings) {\n            return;\n        }\n\n        btnHomeScreenSettings.addEventListener('click', function () {\n            showHomeScreenSettings(elem, {\n                serverId: apiClient.serverId(),\n                userId: userId,\n                userSettings: userSettings\n\n            });\n        });\n    }\n\n    function loadLibraryTiles(elem, apiClient, user, userSettings, shape, userViews, allSections) {\n\n        elem.classList.remove('verticalSection');\n\n        var html = '';\n\n        var scrollX = !layoutManager.desktop;\n\n        if (userViews.length) {\n\n            html += '<div class=\"verticalSection\">';\n\n            html += '<div class=\"sectionTitleContainer sectionTitleContainer-cards\">';\n            html += '<h2 class=\"sectionTitle sectionTitle-cards padded-left\">' + globalize.translate('sharedcomponents#HeaderMyMedia') + '</h2>';\n\n            if (!layoutManager.tv) {\n                html += '<button type=\"button\" is=\"paper-icon-button-light\" class=\"sectionTitleIconButton btnHomeScreenSettings\"><i class=\"md-icon\">&#xE5D3;</i></button>';\n            }\n\n            html += '</div>';\n\n            if (scrollX) {\n                html += '<div is=\"emby-scroller\" class=\"padded-top-focusscale padded-bottom-focusscale\" data-mousewheel=\"false\" data-centerfocus=\"true\"><div is=\"emby-itemscontainer\" class=\"scrollSlider focuscontainer-x padded-left padded-right\">';\n            } else {\n                html += '<div is=\"emby-itemscontainer\" class=\"itemsContainer padded-left padded-right vertical-wrap focuscontainer-x\">';\n            }\n\n            html += cardBuilder.getCardsHtml({\n                items: userViews,\n                shape: scrollX ? 'overflowSmallBackdrop' : shape,\n                showTitle: true,\n                centerText: true,\n                overlayText: false,\n                lazy: true,\n                transition: false,\n                allowBottomPadding: !scrollX\n            });\n\n            if (scrollX) {\n                html += '</div>';\n            }\n            html += '</div>';\n            html += '</div>';\n        }\n\n        elem.innerHTML = html;\n        bindHomeScreenSettingsIcon(elem, apiClient, user.Id, userSettings);\n        imageLoader.lazyChildren(elem);\n    }\n\n    function getContinueWatchingFetchFn(serverId) {\n\n        return function () {\n\n            var apiClient = connectionManager.getApiClient(serverId);\n\n            var screenWidth = dom.getWindowSize().innerWidth;\n\n            var limit;\n\n            if (enableScrollX()) {\n\n                limit = 12;\n\n            } else {\n\n                limit = screenWidth >= 1920 ? 8 : (screenWidth >= 1600 ? 8 : (screenWidth >= 1200 ? 9 : 6));\n                limit = Math.min(limit, 5);\n            }\n\n            var options = {\n\n                Limit: limit,\n                Recursive: true,\n                Fields: \"PrimaryImageAspectRatio,BasicSyncInfo\",\n                ImageTypeLimit: 1,\n                EnableImageTypes: \"Primary,Backdrop,Thumb\",\n                EnableTotalRecordCount: false,\n                MediaTypes: 'Video'\n            };\n\n            return apiClient.getResumableItems(apiClient.getCurrentUserId(), options);\n        };\n    }\n\n    function getContinueWatchingItemsHtml(items) {\n\n        var cardLayout = false;\n\n        return cardBuilder.getCardsHtml({\n            items: items,\n            preferThumb: true,\n            shape: getThumbShape(),\n            overlayText: false,\n            showTitle: true,\n            showParentTitle: true,\n            lazy: true,\n            showDetailsMenu: true,\n            overlayPlayButton: true,\n            context: 'home',\n            centerText: !cardLayout,\n            allowBottomPadding: false,\n            cardLayout: cardLayout,\n            showYear: true,\n            lines: 2\n        });\n    }\n\n    function loadResumeVideo(elem, apiClient, userId) {\n\n        var html = '';\n        html += '<h2 class=\"sectionTitle sectionTitle-cards padded-left\">' + globalize.translate('sharedcomponents#HeaderContinueWatching') + '</h2>';\n\n        if (enableScrollX()) {\n            html += '<div is=\"emby-scroller\" data-mousewheel=\"false\" data-centerfocus=\"true\" class=\"padded-top-focusscale padded-bottom-focusscale\"><div is=\"emby-itemscontainer\" class=\"itemsContainer scrollSlider focuscontainer-x padded-left padded-right\" data-monitor=\"videoplayback,markplayed\">';\n        } else {\n            html += '<div is=\"emby-itemscontainer\" class=\"itemsContainer padded-left padded-right vertical-wrap focuscontainer-x\" data-monitor=\"videoplayback,markplayed\">';\n        }\n\n        if (enableScrollX()) {\n            html += '</div>';\n        }\n        html += '</div>';\n\n        elem.classList.add('hide');\n        elem.innerHTML = html;\n\n        var itemsContainer = elem.querySelector('.itemsContainer');\n        itemsContainer.fetchData = getContinueWatchingFetchFn(apiClient.serverId());\n        itemsContainer.getItemsHtml = getContinueWatchingItemsHtml;\n        itemsContainer.parentContainer = elem;\n    }\n\n    function getContinueListeningFetchFn(serverId) {\n\n        return function () {\n\n            var apiClient = connectionManager.getApiClient(serverId);\n\n            var screenWidth = dom.getWindowSize().innerWidth;\n\n            var limit;\n\n            if (enableScrollX()) {\n\n                limit = 12;\n\n            } else {\n\n                limit = screenWidth >= 1920 ? 8 : (screenWidth >= 1600 ? 8 : (screenWidth >= 1200 ? 9 : 6));\n                limit = Math.min(limit, 5);\n            }\n\n            var options = {\n\n                Limit: limit,\n                Recursive: true,\n                Fields: \"PrimaryImageAspectRatio,BasicSyncInfo\",\n                ImageTypeLimit: 1,\n                EnableImageTypes: \"Primary,Backdrop,Thumb\",\n                EnableTotalRecordCount: false,\n                MediaTypes: 'Audio'\n            };\n\n            return apiClient.getResumableItems(apiClient.getCurrentUserId(), options);\n        };\n    }\n\n    function getContinueListeningItemsHtml(items) {\n\n        var cardLayout = false;\n\n        return cardBuilder.getCardsHtml({\n            items: items,\n            preferThumb: true,\n            shape: getThumbShape(),\n            overlayText: false,\n            showTitle: true,\n            showParentTitle: true,\n            lazy: true,\n            showDetailsMenu: true,\n            overlayPlayButton: true,\n            context: 'home',\n            centerText: !cardLayout,\n            allowBottomPadding: false,\n            cardLayout: cardLayout,\n            showYear: true,\n            lines: 2\n        });\n    }\n\n    function loadResumeAudio(elem, apiClient, userId) {\n\n        var html = '';\n        html += '<h2 class=\"sectionTitle sectionTitle-cards padded-left\">' + globalize.translate('sharedcomponents#HeaderContinueWatching') + '</h2>';\n\n        if (enableScrollX()) {\n            html += '<div is=\"emby-scroller\" data-mousewheel=\"false\" data-centerfocus=\"true\" class=\"padded-top-focusscale padded-bottom-focusscale\"><div is=\"emby-itemscontainer\" class=\"itemsContainer scrollSlider focuscontainer-x padded-left padded-right\" data-monitor=\"audioplayback,markplayed\">';\n        } else {\n            html += '<div is=\"emby-itemscontainer\" class=\"itemsContainer padded-left padded-right vertical-wrap focuscontainer-x\" data-monitor=\"audioplayback,markplayed\">';\n        }\n\n        if (enableScrollX()) {\n            html += '</div>';\n        }\n        html += '</div>';\n\n        elem.classList.add('hide');\n        elem.innerHTML = html;\n\n        var itemsContainer = elem.querySelector('.itemsContainer');\n        itemsContainer.fetchData = getContinueListeningFetchFn(apiClient.serverId());\n        itemsContainer.getItemsHtml = getContinueListeningItemsHtml;\n        itemsContainer.parentContainer = elem;\n    }\n\n    function bindUnlockClick(elem) {\n\n        var btnUnlock = elem.querySelector('.btnUnlock');\n        if (btnUnlock) {\n            btnUnlock.addEventListener('click', function (e) {\n\n                registrationServices.validateFeature('livetv', {\n\n                    viewOnly: true\n\n                }).then(function () {\n\n                    dom.parentWithClass(elem, 'homeSectionsContainer').dispatchEvent(new CustomEvent('settingschange', {\n                        cancelable: false\n                    }));\n                });\n            });\n        }\n    }\n\n    function getOnNowFetchFn(serverId) {\n\n        return function () {\n\n            var apiClient = connectionManager.getApiClient(serverId);\n\n            return apiClient.getLiveTvRecommendedPrograms({\n\n                userId: apiClient.getCurrentUserId(),\n                IsAiring: true,\n                limit: 24,\n                ImageTypeLimit: 1,\n                EnableImageTypes: \"Primary,Thumb,Backdrop\",\n                EnableTotalRecordCount: false,\n                Fields: \"ChannelInfo,PrimaryImageAspectRatio\"\n\n            });\n        };\n    }\n\n    function getOnNowItemsHtml(items) {\n\n        var cardLayout = false;\n\n        return cardBuilder.getCardsHtml({\n            items: items,\n            preferThumb: 'auto',\n            inheritThumb: false,\n            shape: (enableScrollX() ? 'autooverflow' : 'auto'),\n            showParentTitleOrTitle: true,\n            showTitle: true,\n            centerText: true,\n            coverImage: true,\n            overlayText: false,\n            allowBottomPadding: !enableScrollX(),\n            showAirTime: true,\n            showChannelName: false,\n            showAirDateTime: false,\n            showAirEndTime: true,\n            defaultShape: getThumbShape(),\n            lines: 3,\n            overlayPlayButton: true\n        });\n    }\n\n    function loadOnNow(elem, apiClient, user) {\n\n        if (!user.Policy.EnableLiveTvAccess) {\n            return Promise.resolve();\n        }\n\n        var promises = [];\n\n        promises.push(registrationServices.validateFeature('livetv',\n            {\n                viewOnly: true,\n                showDialog: false\n            }).then(function () {\n                return true;\n            }, function () {\n                return false;\n            }));\n\n        var userId = user.Id;\n\n        promises.push(apiClient.getLiveTvRecommendedPrograms({\n\n            userId: apiClient.getCurrentUserId(),\n            IsAiring: true,\n            limit: 1,\n            ImageTypeLimit: 1,\n            EnableImageTypes: \"Primary,Thumb,Backdrop\",\n            EnableTotalRecordCount: false,\n            Fields: \"ChannelInfo,PrimaryImageAspectRatio\"\n\n        }));\n\n        return Promise.all(promises).then(function (responses) {\n\n            var registered = responses[0];\n            var result = responses[1];\n            var html = '';\n\n            if (result.Items.length && registered) {\n\n                elem.classList.remove('padded-left');\n                elem.classList.remove('padded-right');\n                elem.classList.remove('padded-bottom');\n                elem.classList.remove('verticalSection');\n\n                html += '<div class=\"verticalSection\">';\n                html += '<div class=\"sectionTitleContainer sectionTitleContainer-cards padded-left\">';\n\n                html += '<h2 class=\"sectionTitle sectionTitle-cards\">' + globalize.translate('sharedcomponents#LiveTV') + '</h2>';\n\n                html += '</div>';\n\n                if (enableScrollX()) {\n                    html += '<div is=\"emby-scroller\" class=\"padded-top-focusscale padded-bottom-focusscale\" data-mousewheel=\"false\" data-centerfocus=\"true\" data-scrollbuttons=\"false\">';\n                    html += '<div class=\"scrollSlider padded-left padded-right padded-top padded-bottom focuscontainer-x\">';\n                }\n                else {\n                    html += '<div class=\"padded-left padded-right padded-top focuscontainer-x\">';\n                }\n\n                html += '<a style=\"margin-left:.8em;margin-right:0;\" is=\"emby-linkbutton\" href=\"' + appRouter.getRouteUrl('livetv', {\n\n                    serverId: apiClient.serverId()\n\n                }) + '\" class=\"raised\"><span>' + globalize.translate('sharedcomponents#Programs') + '</span></a>';\n\n                html += '<a style=\"margin-left:.5em;margin-right:0;\" is=\"emby-linkbutton\" href=\"' + appRouter.getRouteUrl('livetv', {\n\n                    serverId: apiClient.serverId(),\n                    section: 'guide'\n\n                }) + '\" class=\"raised\"><span>' + globalize.translate('sharedcomponents#Guide') + '</span></a>';\n\n                html += '<a style=\"margin-left:.5em;margin-right:0;\" is=\"emby-linkbutton\" href=\"' + appRouter.getRouteUrl('recordedtv', {\n\n                    serverId: apiClient.serverId()\n\n                }) + '\" class=\"raised\"><span>' + globalize.translate('sharedcomponents#Recordings') + '</span></a>';\n\n                html += '<a style=\"margin-left:.5em;margin-right:0;\" is=\"emby-linkbutton\" href=\"' + appRouter.getRouteUrl('livetv', {\n\n                    serverId: apiClient.serverId(),\n                    section: 'dvrschedule'\n\n                }) + '\" class=\"raised\"><span>' + globalize.translate('sharedcomponents#Schedule') + '</span></a>';\n\n                html += '</div>';\n\n                if (enableScrollX()) {\n                    html += '</div>';\n                }\n\n                html += '</div>';\n                html += '</div>';\n\n                html += '<div class=\"verticalSection\">';\n                html += '<div class=\"sectionTitleContainer sectionTitleContainer-cards padded-left\">';\n\n                if (!layoutManager.tv) {\n\n                    html += '<a is=\"emby-linkbutton\" href=\"' + appRouter.getRouteUrl('livetv', {\n\n                        serverId: apiClient.serverId(),\n                        section: 'onnow'\n\n                    }) + '\" class=\"more button-flat button-flat-mini sectionTitleTextButton\">';\n                    html += '<h2 class=\"sectionTitle sectionTitle-cards\">';\n                    html += globalize.translate('sharedcomponents#HeaderOnNow');\n                    html += '</h2>';\n                    html += '<i class=\"md-icon\">&#xE5CC;</i>';\n                    html += '</a>';\n\n                } else {\n                    html += '<h2 class=\"sectionTitle sectionTitle-cards\">' + globalize.translate('sharedcomponents#HeaderOnNow') + '</h2>';\n                }\n                html += '</div>';\n\n                if (enableScrollX()) {\n                    html += '<div is=\"emby-scroller\" data-mousewheel=\"false\" data-centerfocus=\"true\" class=\"padded-top-focusscale padded-bottom-focusscale\"><div is=\"emby-itemscontainer\" class=\"itemsContainer scrollSlider focuscontainer-x padded-left padded-right\" data-refreshinterval=\"300000\">';\n                } else {\n                    html += '<div is=\"emby-itemscontainer\" class=\"itemsContainer padded-left padded-right vertical-wrap focuscontainer-x\" data-refreshinterval=\"300000\">';\n                }\n\n                if (enableScrollX()) {\n                    html += '</div>';\n                }\n\n                html += '</div>';\n                html += '</div>';\n\n                elem.innerHTML = html;\n\n                var itemsContainer = elem.querySelector('.itemsContainer');\n                itemsContainer.parentContainer = elem;\n                itemsContainer.fetchData = getOnNowFetchFn(apiClient.serverId());\n                itemsContainer.getItemsHtml = getOnNowItemsHtml;\n\n            } else if (result.Items.length && !registered) {\n\n                elem.classList.add('padded-left');\n                elem.classList.add('padded-right');\n                elem.classList.add('padded-bottom');\n\n                html += '<h2 class=\"sectionTitle\">' + globalize.translate('sharedcomponents#LiveTvRequiresUnlock') + '</h2>';\n                html += '<button is=\"emby-button\" type=\"button\" class=\"raised button-submit block btnUnlock\">';\n                html += '<span>' + globalize.translate('sharedcomponents#HeaderBecomeProjectSupporter') + '</span>';\n                html += '</button>';\n\n                elem.innerHTML = html;\n            }\n\n            bindUnlockClick(elem);\n        });\n    }\n\n    function getNextUpFetchFn(serverId) {\n\n        return function () {\n\n            var apiClient = connectionManager.getApiClient(serverId);\n\n            return apiClient.getNextUpEpisodes({\n\n                Limit: enableScrollX() ? 24 : 15,\n                Fields: \"PrimaryImageAspectRatio,SeriesInfo,DateCreated,BasicSyncInfo\",\n                UserId: apiClient.getCurrentUserId(),\n                ImageTypeLimit: 1,\n                EnableImageTypes: \"Primary,Backdrop,Banner,Thumb\",\n                EnableTotalRecordCount: false\n            });\n        };\n    }\n\n    function getNextUpItemsHtml(items) {\n\n        var cardLayout = false;\n\n        return cardBuilder.getCardsHtml({\n            items: items,\n            preferThumb: true,\n            shape: getThumbShape(),\n            overlayText: false,\n            showTitle: true,\n            showParentTitle: true,\n            lazy: true,\n            overlayPlayButton: true,\n            context: 'home',\n            centerText: !cardLayout,\n            allowBottomPadding: !enableScrollX(),\n            cardLayout: cardLayout\n        });\n    }\n\n    function loadNextUp(elem, apiClient, userId) {\n\n        var html = '';\n        html += '<div class=\"sectionTitleContainer sectionTitleContainer-cards padded-left\">';\n        if (!layoutManager.tv) {\n\n            html += '<a is=\"emby-linkbutton\" href=\"' + appRouter.getRouteUrl('nextup', {\n\n                serverId: apiClient.serverId()\n\n            }) + '\" class=\"button-flat button-flat-mini sectionTitleTextButton\">';\n            html += '<h2 class=\"sectionTitle sectionTitle-cards\">';\n            html += globalize.translate('sharedcomponents#HeaderNextUp');\n            html += '</h2>';\n            html += '<i class=\"md-icon\">&#xE5CC;</i>';\n            html += '</a>';\n\n        } else {\n            html += '<h2 class=\"sectionTitle sectionTitle-cards\">' + globalize.translate('sharedcomponents#HeaderNextUp') + '</h2>';\n        }\n        html += '</div>';\n\n        if (enableScrollX()) {\n            html += '<div is=\"emby-scroller\" data-mousewheel=\"false\" data-centerfocus=\"true\" class=\"padded-top-focusscale padded-bottom-focusscale\"><div is=\"emby-itemscontainer\" class=\"itemsContainer scrollSlider focuscontainer-x padded-left padded-right\" data-monitor=\"videoplayback,markplayed\">';\n        } else {\n            html += '<div is=\"emby-itemscontainer\" class=\"itemsContainer padded-left padded-right vertical-wrap focuscontainer-x\" data-monitor=\"videoplayback,markplayed\">';\n        }\n\n        if (enableScrollX()) {\n            html += '</div>';\n        }\n\n        html += '</div>';\n\n        elem.classList.add('hide');\n        elem.innerHTML = html;\n\n        var itemsContainer = elem.querySelector('.itemsContainer');\n        itemsContainer.fetchData = getNextUpFetchFn(apiClient.serverId());\n        itemsContainer.getItemsHtml = getNextUpItemsHtml;\n        itemsContainer.parentContainer = elem;\n    }\n\n    function getLatestRecordingsFetchFn(serverId, activeRecordingsOnly) {\n\n        return function () {\n\n            var apiClient = connectionManager.getApiClient(serverId);\n\n            return apiClient.getLiveTvRecordings({\n\n                userId: apiClient.getCurrentUserId(),\n                Limit: enableScrollX() ? 12 : 5,\n                Fields: \"PrimaryImageAspectRatio,BasicSyncInfo\",\n                EnableTotalRecordCount: false,\n                IsLibraryItem: activeRecordingsOnly ? null : false,\n                IsInProgress: activeRecordingsOnly ? true : null\n\n            });\n        };\n    }\n\n    function getLatestRecordingItemsHtml(activeRecordingsOnly) {\n\n        return function (items) {\n            var cardLayout = false;\n\n            return cardBuilder.getCardsHtml({\n                items: items,\n                shape: enableScrollX() ? 'autooverflow' : 'auto',\n                showTitle: true,\n                showParentTitle: true,\n                coverImage: true,\n                lazy: true,\n                showDetailsMenu: true,\n                centerText: true,\n                overlayText: false,\n                showYear: true,\n                lines: 2,\n                overlayPlayButton: !activeRecordingsOnly,\n                allowBottomPadding: !enableScrollX(),\n                preferThumb: true,\n                cardLayout: false,\n                overlayMoreButton: activeRecordingsOnly,\n                action: activeRecordingsOnly ? 'none' : null,\n                centerPlayButton: activeRecordingsOnly\n            });\n        };\n    }\n\n    function loadLatestLiveTvRecordings(elem, activeRecordingsOnly, apiClient, userId) {\n\n        var title = activeRecordingsOnly ?\n            globalize.translate('sharedcomponents#HeaderActiveRecordings') :\n            globalize.translate('sharedcomponents#HeaderLatestRecordings');\n\n        var html = '';\n\n        html += '<div class=\"sectionTitleContainer sectionTitleContainer-cards\">';\n        html += '<h2 class=\"sectionTitle sectionTitle-cards padded-left\">' + title + '</h2>';\n        if (!layoutManager.tv) {\n            //html += '<a href=\"livetv.html?tab=3\" class=\"clearLink\" style=\"margin-left:2em;\"><button is=\"emby-button\" type=\"button\" class=\"raised more mini\"><span>' + globalize.translate('sharedcomponents#More') + '</span></button></a>';\n            //html += '<button data-href=\"\" type=\"button\" is=\"emby-button\" class=\"raised raised-mini sectionTitleButton btnMore\">';\n            //html += '<span>' + globalize.translate('sharedcomponents#More') + '</span>';\n            //html += '</button>';\n        }\n        html += '</div>';\n\n        if (enableScrollX()) {\n            html += '<div is=\"emby-scroller\" data-mousewheel=\"false\" data-centerfocus=\"true\" class=\"padded-top-focusscale padded-bottom-focusscale\"><div is=\"emby-itemscontainer\" class=\"itemsContainer scrollSlider focuscontainer-x padded-left padded-right\">';\n        } else {\n            html += '<div is=\"emby-itemscontainer\" class=\"itemsContainer padded-left padded-right vertical-wrap focuscontainer-x\">';\n        }\n\n        if (enableScrollX()) {\n            html += '</div>';\n        }\n\n        html += '</div>';\n\n        elem.classList.add('hide');\n        elem.innerHTML = html;\n\n        var itemsContainer = elem.querySelector('.itemsContainer');\n        itemsContainer.fetchData = getLatestRecordingsFetchFn(apiClient.serverId(), activeRecordingsOnly);\n        itemsContainer.getItemsHtml = getLatestRecordingItemsHtml(activeRecordingsOnly);\n        itemsContainer.parentContainer = elem;\n    }\n\n    return {\n        loadLibraryTiles: loadLibraryTiles,\n        getDefaultSection: getDefaultSection,\n        loadSections: loadSections,\n        destroySections: destroySections,\n        pause: pause,\n        resume: resume\n    };\n});\n", "idx": 9, "id": 10616, "msg": "", "proj": "jellyfin-jellyfin-web", "lang": "js"}
{"patch": "@@ -50,6 +50,11 @@ public class MediaAdapter extends RecyclerView.Adapter<MediaAdapter.ViewHolder>\n         placeholder = (BitmapDrawable) drawable;\n     }\n \n+    public ArrayList<Media> getList()\n+    {\n+        return medias;\n+    }\n+\n     @Override\n     public ViewHolder onCreateViewHolder(ViewGroup parent, int viewType) {\n         View v = LayoutInflater.from(parent.getContext()).inflate(R.layout.card_photo, parent, false);", "y": 1, "oldf": "package org.fossasia.phimpme.gallery.adapters;\n\nimport android.content.Context;\nimport android.graphics.PorterDuff;\nimport android.graphics.drawable.BitmapDrawable;\nimport android.graphics.drawable.Drawable;\nimport android.support.v4.content.ContextCompat;\nimport android.support.v7.widget.RecyclerView;\nimport android.view.LayoutInflater;\nimport android.view.View;\nimport android.view.ViewGroup;\nimport android.widget.ImageView;\nimport android.widget.TextView;\n\nimport com.bumptech.glide.Glide;\nimport com.bumptech.glide.load.engine.DiskCacheStrategy;\nimport com.mikepenz.community_material_typeface_library.CommunityMaterial;\nimport com.mikepenz.iconics.view.IconicsImageView;\n\nimport org.fossasia.phimpme.R;\nimport org.fossasia.phimpme.gallery.data.Media;\n\nimport java.util.ArrayList;\n\nimport butterknife.BindView;\nimport butterknife.ButterKnife;\n\n/**\n * Created by dnld on 1/7/16.\n */\n\npublic class MediaAdapter extends RecyclerView.Adapter<MediaAdapter.ViewHolder> {\n\n    private ArrayList<Media> medias;\n    private boolean fav = false;\n\n    private BitmapDrawable placeholder;\n    private View.OnClickListener mOnClickListener;\n    private View.OnLongClickListener mOnLongClickListener;\n    Context context;\n\n    public MediaAdapter(ArrayList<Media> ph, Context context) {\n        medias = ph;\n        this.context = context;\n        updatePlaceholder(context);\n    }\n\n    public void updatePlaceholder(Context context) {\n        Drawable drawable = ContextCompat.getDrawable(context, R.drawable.placeholder);\n        placeholder = (BitmapDrawable) drawable;\n    }\n\n    @Override\n    public ViewHolder onCreateViewHolder(ViewGroup parent, int viewType) {\n        View v = LayoutInflater.from(parent.getContext()).inflate(R.layout.card_photo, parent, false);\n        v.setOnClickListener(mOnClickListener);\n        v.setOnLongClickListener(mOnLongClickListener);\n        return new ViewHolder(v);\n    }\n\n\n    @Override\n    public void onBindViewHolder(final MediaAdapter.ViewHolder holder, int position) {\n\n        Media f = medias.get(position);\n\n        holder.path.setTag(f);\n\n        holder.icon.setVisibility(View.GONE);\n\n\n        Glide.with(holder.imageView.getContext())\n                .load(f.getUri())\n                .asBitmap()\n                .signature(f.getSignature())\n                .centerCrop()\n                .diskCacheStrategy(DiskCacheStrategy.RESULT)\n                .thumbnail(0.5f)\n                .placeholder(placeholder)\n                .animate(R.anim.fade_in)\n                .into(holder.imageView);\n        holder.icon.setVisibility(View.GONE);\n        holder.path.setVisibility(View.GONE);\n\n        if (f.isSelected()) {\n            holder.icon.setIcon(CommunityMaterial.Icon.cmd_check);\n            holder.icon.setVisibility(View.VISIBLE);\n            holder.imageView.setColorFilter(0x88000000, PorterDuff.Mode.SRC_ATOP);\n            holder.layout.setPadding(15, 15, 15, 15);\n        } else {\n            holder.imageView.clearColorFilter();\n            holder.layout.setPadding(0, 0, 0, 0);\n        }\n    }\n\n    @Override\n    public int getItemCount() {\n        return medias.size();\n    }\n\n    public void setOnClickListener(View.OnClickListener lis) {\n        mOnClickListener = lis;\n    }\n\n    public void setOnLongClickListener(View.OnLongClickListener lis) {\n        mOnLongClickListener = lis;\n    }\n\n    public void swapDataSet(ArrayList<Media> asd, boolean fav) {\n        medias = asd;\n        this.fav = fav;\n        notifyDataSetChanged();\n    }\n\n    static class ViewHolder extends RecyclerView.ViewHolder {\n        @BindView(R.id.photo_preview)\n        protected ImageView imageView;\n        @BindView(R.id.media_card_layout)\n        protected View layout;\n        @BindView(R.id.photo_path)\n        protected TextView path;\n        @BindView(R.id.icon)\n        protected IconicsImageView icon;\n\n        ViewHolder(View itemView) {\n            super(itemView);\n            ButterKnife.bind(this, itemView);\n        }\n    }\n}\n\n\n\n", "idx": 1, "id": 12795, "msg": "@angmas1 move the opening bracket of the method next to the method declaration as it is in all other methods.", "proj": "fossasia-phimpme-android", "lang": "java"}
{"patch": "@@ -16,25 +16,28 @@\n # You should have received a copy of the GNU General Public License\n # along with this program. If not, see <http://www.gnu.org/licenses/>.\n \n-import sys\n-import os\n-import hashlib\n import ast\n-import threading\n+import binascii\n+import cmdtr\n+import hashlib\n+import math\n+import os\n import random\n+from struct import pack\n+import sys\n+import threading\n import time\n-import math\n+from trezorlib.client import types\n \n-from util import print_msg, print_error\n-\n-from bitcoin import *\n from account import *\n-from version import *\n-\n-from transaction import Transaction\n-from plugins import run_hook\n+from bitcoin import *\n import bitcoin\n+from plugins import run_hook\n from synchronizer import WalletSynchronizer\n+from transaction import Transaction\n+from util import print_msg, print_error\n+from version import *\n+\n \n COINBASE_MATURITY = 100\n DUST_THRESHOLD = 5430", "y": 1, "oldf": "#!/usr/bin/env python\n#\n# Electrum - lightweight Bitcoin client\n# Copyright (C) 2011 thomasv@gitorious\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program. If not, see <http://www.gnu.org/licenses/>.\n\nimport sys\nimport os\nimport hashlib\nimport ast\nimport threading\nimport random\nimport time\nimport math\n\nfrom util import print_msg, print_error\n\nfrom bitcoin import *\nfrom account import *\nfrom version import *\n\nfrom transaction import Transaction\nfrom plugins import run_hook\nimport bitcoin\nfrom synchronizer import WalletSynchronizer\n\nCOINBASE_MATURITY = 100\nDUST_THRESHOLD = 5430\n\n# internal ID for imported account\nIMPORTED_ACCOUNT = '/x'\n\n\n\nclass WalletStorage:\n\n    def __init__(self, config):\n        self.lock = threading.Lock()\n        self.config = config\n        self.data = {}\n        self.file_exists = False\n        self.path = self.init_path(config)\n        print_error( \"wallet path\", self.path )\n        if self.path:\n            self.read(self.path)\n\n\n    def init_path(self, config):\n        \"\"\"Set the path of the wallet.\"\"\"\n\n        # command line -w option\n        path = config.get('wallet_path')\n        if path:\n            return path\n\n        # path in config file\n        path = config.get('default_wallet_path')\n        if path:\n            return path\n\n        # default path\n        dirpath = os.path.join(config.path, \"wallets\")\n        if not os.path.exists(dirpath):\n            os.mkdir(dirpath)\n\n        new_path = os.path.join(config.path, \"wallets\", \"default_wallet\")\n\n        # default path in pre 1.9 versions\n        old_path = os.path.join(config.path, \"electrum.dat\")\n        if os.path.exists(old_path) and not os.path.exists(new_path):\n            os.rename(old_path, new_path)\n\n        return new_path\n\n\n    def read(self, path):\n        \"\"\"Read the contents of the wallet file.\"\"\"\n        try:\n            with open(self.path, \"r\") as f:\n                data = f.read()\n        except IOError:\n            return\n        try:\n            d = ast.literal_eval( data )  #parse raw data from reading wallet file\n        except Exception:\n            raise IOError(\"Cannot read wallet file.\")\n\n        self.data = d\n        self.file_exists = True\n\n\n    def get(self, key, default=None):\n        v = self.data.get(key)\n        if v is None:\n            v = default\n        return v\n\n    def put(self, key, value, save = True):\n\n        with self.lock:\n            if value is not None:\n                self.data[key] = value\n            elif key in self.data:\n                self.data.pop(key)\n            if save:\n                self.write()\n\n    def write(self):\n        s = repr(self.data)\n        f = open(self.path,\"w\")\n        f.write( s )\n        f.close()\n        if 'ANDROID_DATA' not in os.environ:\n            import stat\n            os.chmod(self.path,stat.S_IREAD | stat.S_IWRITE)\n\n\nclass Abstract_Wallet:\n    \"\"\"\n    Wallet classes are created to handle various address generation methods.\n    Completion states (watching-only, single account, no seed, etc) are handled inside classes.\n    \"\"\"\n\n    def __init__(self, storage):\n        self.storage = storage\n        self.electrum_version = ELECTRUM_VERSION\n        self.gap_limit_for_change = 3 # constant\n        # saved fields\n        self.seed_version          = storage.get('seed_version', NEW_SEED_VERSION)\n        self.gap_limit             = storage.get('gap_limit', 5)\n        self.use_change            = storage.get('use_change',True)\n        self.use_encryption        = storage.get('use_encryption', False)\n        self.seed                  = storage.get('seed', '')               # encrypted\n        self.labels                = storage.get('labels', {})\n        self.frozen_addresses      = storage.get('frozen_addresses',[])\n        self.addressbook           = storage.get('contacts', [])\n\n        self.history               = storage.get('addr_history',{})        # address -> list(txid, height)\n\n        self.fee                   = int(storage.get('fee_per_kb', 10000))\n\n        self.master_public_keys = storage.get('master_public_keys',{})\n        self.master_private_keys = storage.get('master_private_keys', {})\n\n        self.next_addresses = storage.get('next_addresses',{})\n\n\n        # This attribute is set when wallet.start_threads is called.\n        self.synchronizer = None\n\n        self.load_accounts()\n\n        self.transactions = {}\n        tx_list = self.storage.get('transactions',{})\n        for k,v in tx_list.items():\n            try:\n                tx = Transaction(v)\n            except Exception:\n                print_msg(\"Warning: Cannot deserialize transactions. skipping\")\n                continue\n\n            self.add_extra_addresses(tx)\n            self.transactions[k] = tx\n\n        for h,tx in self.transactions.items():\n            if not self.check_new_tx(h, tx):\n                print_error(\"removing unreferenced tx\", h)\n                self.transactions.pop(h)\n\n\n        # not saved\n        self.prevout_values = {}     # my own transaction outputs\n        self.spent_outputs = []\n\n        # spv\n        self.verifier = None\n\n        # there is a difference between wallet.up_to_date and interface.is_up_to_date()\n        # interface.is_up_to_date() returns true when all requests have been answered and processed\n        # wallet.up_to_date is true when the wallet is synchronized (stronger requirement)\n\n        self.up_to_date = False\n        self.lock = threading.Lock()\n        self.transaction_lock = threading.Lock()\n        self.tx_event = threading.Event()\n        for tx_hash, tx in self.transactions.items():\n            self.update_tx_outputs(tx_hash)\n\n    def add_extra_addresses(self, tx):\n        h = tx.hash()\n        # find the address corresponding to pay-to-pubkey inputs\n        tx.add_extra_addresses(self.transactions)\n        for o in tx.d.get('outputs'):\n            if o.get('is_pubkey'):\n                for tx2 in self.transactions.values():\n                    tx2.add_extra_addresses({h:tx})\n\n    def get_action(self):\n        pass\n\n    def convert_imported_keys(self, password):\n        for k, v in self.imported_keys.items():\n            sec = pw_decode(v, password)\n            pubkey = public_key_from_private_key(sec)\n            address = public_key_to_bc_address(pubkey.decode('hex'))\n            assert address == k\n            self.import_key(sec, password)\n            self.imported_keys.pop(k)\n        self.storage.put('imported_keys', self.imported_keys)\n\n    def load_accounts(self):\n        self.accounts = {}\n        self.imported_keys = self.storage.get('imported_keys',{})\n\n        d = self.storage.get('accounts', {})\n        for k, v in d.items():\n            if k == 0:\n                v['mpk'] = self.storage.get('master_public_key')\n                self.accounts[k] = OldAccount(v)\n            elif v.get('imported'):\n                self.accounts[k] = ImportedAccount(v)\n            elif v.get('xpub3'):\n                self.accounts[k] = BIP32_Account_2of3(v)\n            elif v.get('xpub2'):\n                self.accounts[k] = BIP32_Account_2of2(v)\n            elif v.get('xpub'):\n                self.accounts[k] = BIP32_Account(v)\n            elif v.get('pending'):\n                self.accounts[k] = PendingAccount(v)\n            else:\n                print_error(\"cannot load account\", v)\n\n    def synchronize(self):\n        pass\n\n    def can_create_accounts(self):\n        return False\n\n    def set_up_to_date(self,b):\n        with self.lock: self.up_to_date = b\n\n    def is_up_to_date(self):\n        with self.lock: return self.up_to_date\n\n    def update(self):\n        self.up_to_date = False\n        while not self.is_up_to_date():\n            time.sleep(0.1)\n\n    def is_imported(self, addr):\n        account = self.accounts.get(IMPORTED_ACCOUNT)\n        if account:\n            return addr in account.get_addresses(0)\n        else:\n            return False\n\n    def has_imported_keys(self):\n        account = self.accounts.get(IMPORTED_ACCOUNT)\n        return account is not None\n\n    def import_key(self, sec, password):\n        try:\n            pubkey = public_key_from_private_key(sec)\n            address = public_key_to_bc_address(pubkey.decode('hex'))\n        except Exception:\n            raise Exception('Invalid private key')\n\n        if self.is_mine(address):\n            raise Exception('Address already in wallet')\n\n        if self.accounts.get(IMPORTED_ACCOUNT) is None:\n            self.accounts[IMPORTED_ACCOUNT] = ImportedAccount({'imported':{}})\n        self.accounts[IMPORTED_ACCOUNT].add(address, pubkey, sec, password)\n        self.save_accounts()\n\n        if self.synchronizer:\n            self.synchronizer.subscribe_to_addresses([address])\n        return address\n\n    def delete_imported_key(self, addr):\n        account = self.accounts[IMPORTED_ACCOUNT]\n        account.remove(addr)\n        if not account.get_addresses(0):\n            self.accounts.pop(IMPORTED_ACCOUNT)\n        self.save_accounts()\n\n    def set_label(self, name, text = None):\n        changed = False\n        old_text = self.labels.get(name)\n        if text:\n            if old_text != text:\n                self.labels[name] = text\n                changed = True\n        else:\n            if old_text:\n                self.labels.pop(name)\n                changed = True\n\n        if changed:\n            self.storage.put('labels', self.labels, True)\n\n        run_hook('set_label', name, text, changed)\n        return changed\n\n    def addresses(self, include_change = True, _next=True):\n        o = []\n        for a in self.accounts.keys():\n            o += self.get_account_addresses(a, include_change)\n\n        if _next:\n            for addr in self.next_addresses.values():\n                if addr not in o:\n                    o += [addr]\n        return o\n\n    def is_mine(self, address):\n        return address in self.addresses(True)\n\n    def is_change(self, address):\n        if not self.is_mine(address): return False\n        acct, s = self.get_address_index(address)\n        if s is None: return False\n        return s[0] == 1\n\n    def get_address_index(self, address):\n\n        for account in self.accounts.keys():\n            for for_change in [0,1]:\n                addresses = self.accounts[account].get_addresses(for_change)\n                for addr in addresses:\n                    if address == addr:\n                        return account, (for_change, addresses.index(addr))\n\n        for k,v in self.next_addresses.items():\n            if v == address:\n                return k, (0,0)\n\n        raise Exception(\"Address not found\", address)\n\n    def getpubkeys(self, addr):\n        assert is_address(addr) and self.is_mine(addr)\n        account, sequence = self.get_address_index(addr)\n        a = self.accounts[account]\n        return a.get_pubkeys( sequence )\n\n    def get_private_key(self, address, password):\n        if self.is_watching_only():\n            return []\n        account_id, sequence = self.get_address_index(address)\n        return self.accounts[account_id].get_private_key(sequence, self, password)\n\n    def get_public_keys(self, address):\n        account_id, sequence = self.get_address_index(address)\n        return self.accounts[account_id].get_pubkeys(sequence)\n\n    def can_sign(self, tx):\n\n        if self.is_watching_only():\n            return False\n\n        if tx.is_complete():\n            return False\n\n        addr_list, xpub_list = tx.inputs_to_sign()\n        for addr in addr_list:\n            if self.is_mine(addr):\n                return True\n\n        mpk = [ self.master_public_keys[k] for k in self.master_private_keys.keys() ]\n        for xpub, sequence in xpub_list:\n            if xpub in mpk:\n                return True\n\n        return False\n\n    def add_keypairs(self, tx, keypairs, password):\n        # first check the provided password. This will raise if invalid.\n        self.check_password(password)\n\n        addr_list, xpub_list = tx.inputs_to_sign()\n        for addr in addr_list:\n            if self.is_mine(addr):\n                private_keys = self.get_private_key(addr, password)\n                for sec in private_keys:\n                    pubkey = public_key_from_private_key(sec)\n                    keypairs[ pubkey ] = sec\n\n        for xpub, sequence in xpub_list:\n            # look for account that can sign\n            for k, account in self.accounts.items():\n                if xpub in account.get_master_pubkeys():\n                    break\n            else:\n                continue\n\n            addr = account.get_address(*sequence)\n            pk = self.get_private_key(addr, password)\n            for sec in pk:\n                pubkey = public_key_from_private_key(sec)\n                keypairs[pubkey] = sec\n\n    def signrawtransaction(self, tx, private_keys, password):\n        # check that the password is correct. This will raise if it's not.\n        self.get_seed(password)\n\n        # build a list of public/private keys\n        keypairs = {}\n\n        # add private keys from parameter\n        for sec in private_keys:\n            pubkey = public_key_from_private_key(sec)\n            keypairs[ pubkey ] = sec\n\n        # add private_keys\n        self.add_keypairs(tx, keypairs, password)\n\n        # sign the transaction\n        self.sign_transaction(tx, keypairs, password)\n\n    def sign_message(self, address, message, password):\n        keys = self.get_private_key(address, password)\n        assert len(keys) == 1\n        sec = keys[0]\n        key = regenerate_key(sec)\n        compressed = is_compressed(sec)\n        return key.sign_message(message, compressed, address)\n\n    def decrypt_message(self, pubkey, message, password):\n        address = public_key_to_bc_address(pubkey.decode('hex'))\n        keys = self.get_private_key(address, password)\n        secret = keys[0]\n        ec = regenerate_key(secret)\n        decrypted = ec.decrypt_message(message)\n        return decrypted\n\n    def is_found(self):\n        return self.history.values() != [[]] * len(self.history)\n\n    def add_contact(self, address, label=None):\n        self.addressbook.append(address)\n        self.storage.put('contacts', self.addressbook, True)\n        if label:\n            self.set_label(address, label)\n\n    def delete_contact(self, addr):\n        if addr in self.addressbook:\n            self.addressbook.remove(addr)\n            self.storage.put('addressbook', self.addressbook, True)\n\n    def fill_addressbook(self):\n        for tx_hash, tx in self.transactions.items():\n            is_relevant, is_send, _, _ = self.get_tx_value(tx)\n            if is_send:\n                for addr, v in tx.outputs:\n                    if not self.is_mine(addr) and addr not in self.addressbook:\n                        self.addressbook.append(addr)\n        # redo labels\n        # self.update_tx_labels()\n\n    def get_num_tx(self, address):\n        n = 0\n        for tx in self.transactions.values():\n            if address in map(lambda x:x[0], tx.outputs): n += 1\n        return n\n\n    def get_address_flags(self, addr):\n        flags = \"C\" if self.is_change(addr) else \"I\" if addr in self.imported_keys.keys() else \"-\"\n        flags += \"F\" if addr in self.frozen_addresses else \"-\"\n        return flags\n\n    def get_tx_value(self, tx, account=None):\n        domain = self.get_account_addresses(account)\n        return tx.get_value(domain, self.prevout_values)\n\n    def update_tx_outputs(self, tx_hash):\n        tx = self.transactions.get(tx_hash)\n\n        for i, (addr, value) in enumerate(tx.outputs):\n            key = tx_hash+ ':%d'%i\n            self.prevout_values[key] = value\n\n        for item in tx.inputs:\n            if self.is_mine(item.get('address')):\n                key = item['prevout_hash'] + ':%d'%item['prevout_n']\n                self.spent_outputs.append(key)\n\n    def get_addr_balance(self, address):\n        #assert self.is_mine(address)\n        h = self.history.get(address,[])\n        if h == ['*']: return 0,0\n        c = u = 0\n        received_coins = []   # list of coins received at address\n\n        for tx_hash, tx_height in h:\n            tx = self.transactions.get(tx_hash)\n            if not tx: continue\n\n            for i, (addr, value) in enumerate(tx.outputs):\n                if addr == address:\n                    key = tx_hash + ':%d'%i\n                    received_coins.append(key)\n\n        for tx_hash, tx_height in h:\n            tx = self.transactions.get(tx_hash)\n            if not tx: continue\n            v = 0\n\n            for item in tx.inputs:\n                addr = item.get('address')\n                if addr == address:\n                    key = item['prevout_hash']  + ':%d'%item['prevout_n']\n                    value = self.prevout_values.get( key )\n                    if key in received_coins:\n                        v -= value\n\n            for i, (addr, value) in enumerate(tx.outputs):\n                key = tx_hash + ':%d'%i\n                if addr == address:\n                    v += value\n\n            if tx_height:\n                c += v\n            else:\n                u += v\n        return c, u\n\n    def get_account_name(self, k):\n        return self.labels.get(k, self.accounts[k].get_name(k))\n\n    def get_account_names(self):\n        account_names = {}\n        for k in self.accounts.keys():\n            account_names[k] = self.get_account_name(k)\n        return account_names\n\n    def get_account_addresses(self, a, include_change=True):\n        if a is None:\n            o = self.addresses(include_change)\n        elif a in self.accounts:\n            ac = self.accounts[a]\n            o = ac.get_addresses(0)\n            if include_change: o += ac.get_addresses(1)\n        return o\n\n    def get_account_balance(self, account):\n        return self.get_balance(self.get_account_addresses(account))\n\n    def get_frozen_balance(self):\n        return self.get_balance(self.frozen_addresses)\n\n    def get_balance(self, domain=None):\n        if domain is None: domain = self.addresses(True)\n        cc = uu = 0\n        for addr in domain:\n            c, u = self.get_addr_balance(addr)\n            cc += c\n            uu += u\n        return cc, uu\n\n    def get_unspent_coins(self, domain=None):\n        coins = []\n        if domain is None: domain = self.addresses(True)\n        for addr in domain:\n            h = self.history.get(addr, [])\n            if h == ['*']: continue\n            for tx_hash, tx_height in h:\n                tx = self.transactions.get(tx_hash)\n                if tx is None: raise Exception(\"Wallet not synchronized\")\n                is_coinbase = tx.inputs[0].get('prevout_hash') == '0'*64\n                for o in tx.d.get('outputs'):\n                    output = o.copy()\n                    if output.get('address') != addr: continue\n                    key = tx_hash + \":%d\" % output.get('prevout_n')\n                    if key in self.spent_outputs: continue\n                    output['prevout_hash'] = tx_hash\n                    output['height'] = tx_height\n                    output['coinbase'] = is_coinbase\n                    coins.append((tx_height, output))\n\n        # sort by age\n        if coins:\n            coins = sorted(coins)\n            if coins[-1][0] != 0:\n                while coins[0][0] == 0:\n                    coins = coins[1:] + [ coins[0] ]\n        return [x[1] for x in coins]\n\n    def choose_tx_inputs( self, amount, fixed_fee, num_outputs, domain = None, coins = None ):\n        \"\"\" todo: minimize tx size \"\"\"\n        total = 0\n        fee = self.fee if fixed_fee is None else fixed_fee\n\n        if not coins:\n            if domain is None:\n                domain = self.addresses(True)\n            for i in self.frozen_addresses:\n                if i in domain: domain.remove(i)\n            coins = self.get_unspent_coins(domain)\n\n        inputs = []\n\n        for item in coins:\n            if item.get('coinbase') and item.get('height') + COINBASE_MATURITY > self.network.get_local_height():\n                continue\n            v = item.get('value')\n            total += v\n            inputs.append(item)\n            fee = self.estimated_fee(inputs, num_outputs) if fixed_fee is None else fixed_fee\n            if total >= amount + fee: break\n        else:\n            inputs = []\n\n        return inputs, total, fee\n\n    def set_fee(self, fee):\n        if self.fee != fee:\n            self.fee = fee\n            self.storage.put('fee_per_kb', self.fee, True)\n\n    def estimated_fee(self, inputs, num_outputs):\n        estimated_size =  len(inputs) * 180 + num_outputs * 34    # this assumes non-compressed keys\n        fee = self.fee * int(math.ceil(estimated_size/1000.))\n        return fee\n\n    def add_tx_change( self, inputs, outputs, amount, fee, total, change_addr=None):\n        \"add change to a transaction\"\n        change_amount = total - ( amount + fee )\n        if change_amount > DUST_THRESHOLD:\n            if not change_addr:\n\n                # send change to one of the accounts involved in the tx\n                address = inputs[0].get('address')\n                account, _ = self.get_address_index(address)\n\n                if not self.use_change or account == IMPORTED_ACCOUNT:\n                    change_addr = inputs[-1]['address']\n                else:\n                    change_addr = self.accounts[account].get_addresses(1)[-self.gap_limit_for_change]\n\n            # Insert the change output at a random position in the outputs\n            posn = random.randint(0, len(outputs))\n            outputs[posn:posn] = [( change_addr,  change_amount)]\n        return outputs\n\n    def get_history(self, address):\n        with self.lock:\n            return self.history.get(address)\n\n    def get_status(self, h):\n        if not h: return None\n        if h == ['*']: return '*'\n        status = ''\n        for tx_hash, height in h:\n            status += tx_hash + ':%d:' % height\n        return hashlib.sha256( status ).digest().encode('hex')\n\n    def receive_tx_callback(self, tx_hash, tx, tx_height):\n\n        with self.transaction_lock:\n            self.add_extra_addresses(tx)\n            if not self.check_new_tx(tx_hash, tx):\n                # may happen due to pruning\n                print_error(\"received transaction that is no longer referenced in history\", tx_hash)\n                return\n            self.transactions[tx_hash] = tx\n            self.network.pending_transactions_for_notifications.append(tx)\n            self.save_transactions()\n            if self.verifier and tx_height>0:\n                self.verifier.add(tx_hash, tx_height)\n            self.update_tx_outputs(tx_hash)\n\n    def save_transactions(self):\n        tx = {}\n        for k,v in self.transactions.items():\n            tx[k] = str(v)\n        self.storage.put('transactions', tx, True)\n\n    def receive_history_callback(self, addr, hist):\n\n        if not self.check_new_history(addr, hist):\n            raise Exception(\"error: received history for %s is not consistent with known transactions\"%addr)\n\n        with self.lock:\n            self.history[addr] = hist\n            self.storage.put('addr_history', self.history, True)\n\n        if hist != ['*']:\n            for tx_hash, tx_height in hist:\n                if tx_height>0:\n                    # add it in case it was previously unconfirmed\n                    if self.verifier: self.verifier.add(tx_hash, tx_height)\n\n    def get_tx_history(self, account=None):\n        if not self.verifier:\n            return []\n\n        with self.transaction_lock:\n            history = self.transactions.items()\n            history.sort(key = lambda x: self.verifier.get_txpos(x[0]))\n            result = []\n\n            balance = 0\n            for tx_hash, tx in history:\n                is_relevant, is_mine, v, fee = self.get_tx_value(tx, account)\n                if v is not None: balance += v\n\n            c, u = self.get_account_balance(account)\n\n            if balance != c+u:\n                result.append( ('', 1000, 0, c+u-balance, None, c+u-balance, None ) )\n\n            balance = c + u - balance\n            for tx_hash, tx in history:\n                is_relevant, is_mine, value, fee = self.get_tx_value(tx, account)\n                if not is_relevant:\n                    continue\n                if value is not None:\n                    balance += value\n\n                conf, timestamp = self.verifier.get_confirmations(tx_hash) if self.verifier else (None, None)\n                result.append( (tx_hash, conf, is_mine, value, fee, balance, timestamp) )\n\n        return result\n\n    def get_label(self, tx_hash):\n        label = self.labels.get(tx_hash)\n        is_default = (label == '') or (label is None)\n        if is_default: label = self.get_default_label(tx_hash)\n        return label, is_default\n\n    def get_default_label(self, tx_hash):\n        tx = self.transactions.get(tx_hash)\n        default_label = ''\n        if tx:\n            is_relevant, is_mine, _, _ = self.get_tx_value(tx)\n            if is_mine:\n                for o in tx.outputs:\n                    o_addr, _ = o\n                    if not self.is_mine(o_addr):\n                        try:\n                            default_label = self.labels[o_addr]\n                        except KeyError:\n                            default_label = '>' + o_addr\n                        break\n                else:\n                    default_label = '(internal)'\n            else:\n                for o in tx.outputs:\n                    o_addr, _ = o\n                    if self.is_mine(o_addr) and not self.is_change(o_addr):\n                        break\n                else:\n                    for o in tx.outputs:\n                        o_addr, _ = o\n                        if self.is_mine(o_addr):\n                            break\n                    else:\n                        o_addr = None\n\n                if o_addr:\n                    try:\n                        default_label = self.labels[o_addr]\n                    except KeyError:\n                        default_label = '<' + o_addr\n\n        return default_label\n\n    def make_unsigned_transaction(self, outputs, fee=None, change_addr=None, domain=None, coins=None ):\n        for address, x in outputs:\n            if address.startswith('OP_RETURN:'):\n                continue\n            assert is_address(address), \"Address \" + address + \" is invalid!\"\n        amount = sum( map(lambda x:x[1], outputs) )\n        inputs, total, fee = self.choose_tx_inputs( amount, fee, len(outputs), domain, coins )\n        if not inputs:\n            raise ValueError(\"Not enough funds\")\n        for txin in inputs:\n            self.add_input_info(txin)\n        outputs = self.add_tx_change(inputs, outputs, amount, fee, total, change_addr)\n        return Transaction.from_io(inputs, outputs)\n\n    def mktx(self, outputs, password, fee=None, change_addr=None, domain= None, coins = None ):\n        tx = self.make_unsigned_transaction(outputs, fee, change_addr, domain, coins)\n        keypairs = {}\n        self.add_keypairs(tx, keypairs, password)\n        if keypairs:\n            self.sign_transaction(tx, keypairs, password)\n        return tx\n\n    def add_input_info(self, txin):\n        address = txin['address']\n        account_id, sequence = self.get_address_index(address)\n        account = self.accounts[account_id]\n        redeemScript = account.redeem_script(sequence)\n        txin['x_pubkeys'] = account.get_xpubkeys(sequence)\n        txin['pubkeys'] = pubkeys = account.get_pubkeys(sequence)\n        txin['signatures'] = [None] * len(pubkeys)\n\n        if redeemScript:\n            txin['redeemScript'] = redeemScript\n            txin['num_sig'] = 2\n        else:\n            txin['redeemPubkey'] = account.get_pubkey(*sequence)\n            txin['num_sig'] = 1\n\n    def sign_transaction(self, tx, keypairs, password):\n        tx.sign(keypairs)\n        run_hook('sign_transaction', tx, password)\n\n    def sendtx(self, tx):\n        # synchronous\n        h = self.send_tx(tx)\n        self.tx_event.wait()\n        return self.receive_tx(h, tx)\n\n    def send_tx(self, tx):\n        # asynchronous\n        self.tx_event.clear()\n        self.network.send([('blockchain.transaction.broadcast', [str(tx)])], self.on_broadcast)\n        return tx.hash()\n\n    def on_broadcast(self, i, r):\n        self.tx_result = r.get('result')\n        self.tx_event.set()\n\n    def receive_tx(self, tx_hash, tx):\n        out = self.tx_result\n        if out != tx_hash:\n            return False, \"error: \" + out\n        run_hook('receive_tx', tx, self)\n        return True, out\n\n    def update_password(self, old_password, new_password):\n        if new_password == '':\n            new_password = None\n\n        if self.has_seed():\n            decoded = self.get_seed(old_password)\n            self.seed = pw_encode( decoded, new_password)\n            self.storage.put('seed', self.seed, True)\n\n        imported_account = self.accounts.get(IMPORTED_ACCOUNT)\n        if imported_account:\n            imported_account.update_password(old_password, new_password)\n            self.save_accounts()\n\n        for k, v in self.master_private_keys.items():\n            b = pw_decode(v, old_password)\n            c = pw_encode(b, new_password)\n            self.master_private_keys[k] = c\n        self.storage.put('master_private_keys', self.master_private_keys, True)\n\n        self.use_encryption = (new_password != None)\n        self.storage.put('use_encryption', self.use_encryption,True)\n\n    def freeze(self,addr):\n        if self.is_mine(addr) and addr not in self.frozen_addresses:\n            self.frozen_addresses.append(addr)\n            self.storage.put('frozen_addresses', self.frozen_addresses, True)\n            return True\n        else:\n            return False\n\n    def unfreeze(self,addr):\n        if self.is_mine(addr) and addr in self.frozen_addresses:\n            self.frozen_addresses.remove(addr)\n            self.storage.put('frozen_addresses', self.frozen_addresses, True)\n            return True\n        else:\n            return False\n\n    def set_verifier(self, verifier):\n        self.verifier = verifier\n\n        # review transactions that are in the history\n        for addr, hist in self.history.items():\n            if hist == ['*']: continue\n            for tx_hash, tx_height in hist:\n                if tx_height>0:\n                    # add it in case it was previously unconfirmed\n                    self.verifier.add(tx_hash, tx_height)\n\n        # if we are on a pruning server, remove unverified transactions\n        vr = self.verifier.transactions.keys() + self.verifier.verified_tx.keys()\n        for tx_hash in self.transactions.keys():\n            if tx_hash not in vr:\n                self.transactions.pop(tx_hash)\n\n    def check_new_history(self, addr, hist):\n        # check that all tx in hist are relevant\n        if hist != ['*']:\n            for tx_hash, height in hist:\n                tx = self.transactions.get(tx_hash)\n                if not tx: continue\n                if not tx.has_address(addr):\n                    return False\n\n        # check that we are not \"orphaning\" a transaction\n        old_hist = self.history.get(addr,[])\n        if old_hist == ['*']: return True\n\n        for tx_hash, height in old_hist:\n            if tx_hash in map(lambda x:x[0], hist): continue\n            found = False\n            for _addr, _hist in self.history.items():\n                if _addr == addr: continue\n                if _hist == ['*']: continue\n                _tx_hist = map(lambda x:x[0], _hist)\n                if tx_hash in _tx_hist:\n                    found = True\n                    break\n\n            if not found:\n                tx = self.transactions.get(tx_hash)\n                # tx might not be there\n                if not tx: continue\n\n                # already verified?\n                if self.verifier.get_height(tx_hash):\n                    continue\n                # unconfirmed tx\n                print_error(\"new history is orphaning transaction:\", tx_hash)\n                # check that all outputs are not mine, request histories\n                ext_requests = []\n                for _addr, _v in tx.outputs:\n                    # assert not self.is_mine(_addr)\n                    ext_requests.append( ('blockchain.address.get_history', [_addr]) )\n\n                ext_h = self.network.synchronous_get(ext_requests)\n                print_error(\"sync:\", ext_requests, ext_h)\n                height = None\n                for h in ext_h:\n                    if h == ['*']: continue\n                    for item in h:\n                        if item.get('tx_hash') == tx_hash:\n                            height = item.get('height')\n                if height:\n                    print_error(\"found height for\", tx_hash, height)\n                    self.verifier.add(tx_hash, height)\n                else:\n                    print_error(\"removing orphaned tx from history\", tx_hash)\n                    self.transactions.pop(tx_hash)\n\n        return True\n\n    def check_new_tx(self, tx_hash, tx):\n        # 1 check that tx is referenced in addr_history.\n        addresses = []\n        for addr, hist in self.history.items():\n            if hist == ['*']:continue\n            for txh, height in hist:\n                if txh == tx_hash:\n                    addresses.append(addr)\n\n        if not addresses:\n            return False\n\n        # 2 check that referencing addresses are in the tx\n        for addr in addresses:\n            if not tx.has_address(addr):\n                return False\n\n        return True\n\n    def start_threads(self, network):\n        from verifier import TxVerifier\n        self.network = network\n        if self.network is not None:\n            self.verifier = TxVerifier(self.network, self.storage)\n            self.verifier.start()\n            self.set_verifier(self.verifier)\n            self.synchronizer = WalletSynchronizer(self, network)\n            self.synchronizer.start()\n        else:\n            self.verifier = None\n            self.synchronizer =None\n\n    def stop_threads(self):\n        if self.network:\n            self.verifier.stop()\n            self.synchronizer.stop()\n\n    def restore(self, cb):\n        pass\n\n    def get_accounts(self):\n        return self.accounts\n\n    def save_accounts(self):\n        d = {}\n        for k, v in self.accounts.items():\n            d[k] = v.dump()\n        self.storage.put('accounts', d, True)\n\n    def can_import(self):\n        return not self.is_watching_only()\n\n    def is_used(self, address):\n        h = self.history.get(address,[])\n        c, u = self.get_addr_balance(address)\n        return len(h), len(h) > 0 and c == -u\n\n    def address_is_old(self, address, age_limit=2):\n        age = -1\n        h = self.history.get(address, [])\n        if h == ['*']:\n            return True\n        for tx_hash, tx_height in h:\n            if tx_height == 0:\n                tx_age = 0\n            else:\n                tx_age = self.network.get_local_height() - tx_height + 1\n            if tx_age > age:\n                age = tx_age\n        return age > age_limit\n\n\nclass Imported_Wallet(Abstract_Wallet):\n\n    def __init__(self, storage):\n        Abstract_Wallet.__init__(self, storage)\n        a = self.accounts.get(IMPORTED_ACCOUNT)\n        if not a:\n            self.accounts[IMPORTED_ACCOUNT] = ImportedAccount({'imported':{}})\n        self.storage.put('wallet_type', 'imported', True)\n\n    def is_watching_only(self):\n        acc = self.accounts[IMPORTED_ACCOUNT]\n        n = acc.keypairs.values()\n        return n == [(None, None)] * len(n)\n\n    def has_seed(self):\n        return False\n\n    def is_deterministic(self):\n        return False\n\n    def check_password(self, password):\n        self.accounts[IMPORTED_ACCOUNT].get_private_key((0,0), self, password)\n\n    def is_used(self, address):\n        h = self.history.get(address,[])\n        return len(h), False\n\n    def get_master_public_keys(self):\n        return {}\n\n    def is_beyond_limit(self, address, account, is_change):\n        return False\n\nclass Deterministic_Wallet(Abstract_Wallet):\n\n    def __init__(self, storage):\n        Abstract_Wallet.__init__(self, storage)\n\n    def has_seed(self):\n        return self.seed != ''\n\n    def is_deterministic(self):\n        return True\n\n    def is_watching_only(self):\n        return not self.has_seed()\n\n    def add_seed(self, seed, password):\n        if self.seed:\n            raise Exception(\"a seed exists\")\n\n        self.seed_version, self.seed = self.prepare_seed(seed)\n        if password:\n            self.seed = pw_encode( self.seed, password)\n            self.use_encryption = True\n        else:\n            self.use_encryption = False\n\n        self.storage.put('seed', self.seed, True)\n        self.storage.put('seed_version', self.seed_version, True)\n        self.storage.put('use_encryption', self.use_encryption,True)\n        self.create_master_keys(password)\n\n    def get_seed(self, password):\n        return pw_decode(self.seed, password)\n\n    def get_mnemonic(self, password):\n        return self.get_seed(password)\n\n    def change_gap_limit(self, value):\n        if value >= self.gap_limit:\n            self.gap_limit = value\n            self.storage.put('gap_limit', self.gap_limit, True)\n            #self.interface.poke('synchronizer')\n            return True\n\n        elif value >= self.min_acceptable_gap():\n            for key, account in self.accounts.items():\n                addresses = account[0]\n                k = self.num_unused_trailing_addresses(addresses)\n                n = len(addresses) - k + value\n                addresses = addresses[0:n]\n                self.accounts[key][0] = addresses\n\n            self.gap_limit = value\n            self.storage.put('gap_limit', self.gap_limit, True)\n            self.save_accounts()\n            return True\n        else:\n            return False\n\n    def num_unused_trailing_addresses(self, addresses):\n        k = 0\n        for a in addresses[::-1]:\n            if self.history.get(a):break\n            k = k + 1\n        return k\n\n    def min_acceptable_gap(self):\n        # fixme: this assumes wallet is synchronized\n        n = 0\n        nmax = 0\n\n        for account in self.accounts.values():\n            addresses = account.get_addresses(0)\n            k = self.num_unused_trailing_addresses(addresses)\n            for a in addresses[0:-k]:\n                if self.history.get(a):\n                    n = 0\n                else:\n                    n += 1\n                    if n > nmax: nmax = n\n        return nmax + 1\n\n    def create_new_address(self, account=None, for_change=0):\n        if account is None:\n            account = self.default_account()\n        address = account.create_new_address(for_change)\n        self.history[address] = []\n        self.synchronizer.add(address)\n        self.save_accounts()\n        return address\n\n    def synchronize_sequence(self, account, for_change):\n        limit = self.gap_limit_for_change if for_change else self.gap_limit\n        while True:\n            addresses = account.get_addresses(for_change)\n            if len(addresses) < limit:\n                self.create_new_address(account, for_change)\n                continue\n            if map( lambda a: self.address_is_old(a), addresses[-limit:] ) == limit*[False]:\n                break\n            else:\n                self.create_new_address(account, for_change)\n\n    def check_pending_accounts(self):\n        for account_id, addr in self.next_addresses.items():\n            if self.address_is_old(addr):\n                print_error( \"creating account\", account_id )\n                xpub = self.master_public_keys[account_id]\n                account = BIP32_Account({'xpub':xpub})\n                self.add_account(account_id, account)\n                self.next_addresses.pop(account_id)\n\n    def synchronize_account(self, account):\n        self.synchronize_sequence(account, 0)\n        self.synchronize_sequence(account, 1)\n\n    def synchronize(self):\n        self.check_pending_accounts()\n        for account in self.accounts.values():\n            if type(account) in [ImportedAccount, PendingAccount]:\n                continue\n            self.synchronize_account(account)\n\n    def restore(self, callback):\n        from i18n import _\n        def wait_for_wallet():\n            self.set_up_to_date(False)\n            while not self.is_up_to_date():\n                msg = \"%s\\n%s %d\\n%s %.1f\"%(\n                    _(\"Please wait...\"),\n                    _(\"Addresses generated:\"),\n                    len(self.addresses(True)),\n                    _(\"Kilobytes received:\"),\n                    self.network.interface.bytes_received/1024.)\n\n                apply(callback, (msg,))\n                time.sleep(0.1)\n\n        def wait_for_network():\n            while not self.network.is_connected():\n                msg = \"%s \\n\" % (_(\"Connecting...\"))\n                apply(callback, (msg,))\n                time.sleep(0.1)\n\n        # wait until we are connected, because the user might have selected another server\n        if self.network:\n            wait_for_network()\n            wait_for_wallet()\n        else:\n            self.synchronize()\n        self.fill_addressbook()\n\n    def create_account(self, name, password):\n        i = self.num_accounts()\n        account_id = self.account_id(i)\n        account = self.make_account(account_id, password)\n        self.add_account(account_id, account)\n        if name:\n            self.set_label(account_id, name)\n\n        # add address of the next account\n        _, _ = self.next_account_address(password)\n\n\n    def add_account(self, account_id, account):\n        self.accounts[account_id] = account\n        self.save_accounts()\n\n    def account_is_pending(self, k):\n        return type(self.accounts.get(k)) == PendingAccount\n\n    def delete_pending_account(self, k):\n        assert self.account_is_pending(k)\n        self.accounts.pop(k)\n        self.save_accounts()\n\n    def create_pending_account(self, name, password):\n        account_id, addr = self.next_account_address(password)\n        self.set_label(account_id, name)\n        self.accounts[account_id] = PendingAccount({'pending':addr})\n        self.save_accounts()\n\n    def is_beyond_limit(self, address, account, is_change):\n        if type(account) == ImportedAccount:\n            return False\n        addr_list = account.get_addresses(is_change)\n        i = addr_list.index(address)\n        prev_addresses = addr_list[:max(0, i)]\n        limit = self.gap_limit_for_change if is_change else self.gap_limit\n        if len(prev_addresses) < limit:\n            return False\n        prev_addresses = prev_addresses[max(0, i - limit):]\n        for addr in prev_addresses:\n            if self.address_is_old(addr):\n                return False\n        return True\n\n\nclass NewWallet(Deterministic_Wallet):\n\n    def __init__(self, storage):\n        Deterministic_Wallet.__init__(self, storage)\n\n    def default_account(self):\n        return self.accounts[\"m/0'\"]\n\n    def is_watching_only(self):\n        return self.master_private_keys is {}\n\n    def can_create_accounts(self):\n        return 'm/' in self.master_private_keys.keys()\n\n    def get_master_public_key(self):\n        return self.master_public_keys[\"m/\"]\n\n    def get_master_public_keys(self):\n        out = {}\n        for k, account in self.accounts.items():\n            name = self.get_account_name(k)\n            mpk_text = '\\n\\n'.join( account.get_master_pubkeys() )\n            out[name] = mpk_text\n        return out\n\n    def get_master_private_key(self, account, password):\n        k = self.master_private_keys.get(account)\n        if not k: return\n        xpriv = pw_decode( k, password)\n        return xpriv\n\n    def check_password(self, password):\n        xpriv = self.get_master_private_key( \"m/\", password )\n        xpub = self.master_public_keys[\"m/\"]\n        assert deserialize_xkey(xpriv)[3] == deserialize_xkey(xpub)[3]\n\n    def create_xprv_wallet(self, xprv, password):\n        xpub = bitcoin.xpub_from_xprv(xprv)\n        account = BIP32_Account({'xpub':xpub})\n        account_id = 'm/' + bitcoin.get_xkey_name(xpub)\n        self.storage.put('seed_version', self.seed_version, True)\n        self.add_master_private_key(account_id, xprv, password)\n        self.add_master_public_key(account_id, xpub)\n        self.add_account(account_id, account)\n\n    def create_watching_only_wallet(self, xpub):\n        account = BIP32_Account({'xpub':xpub})\n        account_id = 'm/' + bitcoin.get_xkey_name(xpub)\n        self.storage.put('seed_version', self.seed_version, True)\n        self.add_master_public_key(account_id, xpub)\n        self.add_account(account_id, account)\n\n    def create_accounts(self, password):\n        # First check the password is valid (this raises if it isn't).\n        self.check_password(password)\n        self.create_account('Main account', password)\n\n    def add_master_public_key(self, name, xpub):\n        self.master_public_keys[name] = xpub\n        self.storage.put('master_public_keys', self.master_public_keys, True)\n\n    def add_master_private_key(self, name, xpriv, password):\n        self.master_private_keys[name] = pw_encode(xpriv, password)\n        self.storage.put('master_private_keys', self.master_private_keys, True)\n\n    def add_master_keys(self, root, account_id, password):\n        x = self.master_private_keys.get(root)\n        if x:\n            master_xpriv = pw_decode(x, password )\n            xpriv, xpub = bip32_private_derivation(master_xpriv, root, account_id)\n            self.add_master_public_key(account_id, xpub)\n            self.add_master_private_key(account_id, xpriv, password)\n        else:\n            master_xpub = self.master_public_keys[root]\n            xpub = bip32_public_derivation(master_xpub, root, account_id)\n            self.add_master_public_key(account_id, xpub)\n        return xpub\n\n    def create_master_keys(self, password):\n        xpriv, xpub = bip32_root(mnemonic_to_seed(self.get_seed(password),'').encode('hex'))\n        self.add_master_public_key(\"m/\", xpub)\n        self.add_master_private_key(\"m/\", xpriv, password)\n\n    def find_root_by_master_key(self, xpub):\n        for key, xpub2 in self.master_public_keys.items():\n            if key == \"m/\":continue\n            if xpub == xpub2:\n                return key\n\n    def num_accounts(self):\n        keys = []\n        for k, v in self.accounts.items():\n            if type(v) != BIP32_Account:\n                continue\n            keys.append(k)\n\n        i = 0\n        while True:\n            account_id = self.account_id(i)\n            if account_id not in keys: break\n            i += 1\n        return i\n\n    def next_account_address(self, password):\n        i = self.num_accounts()\n        account_id = self.account_id(i)\n\n        addr = self.next_addresses.get(account_id)\n        if not addr:\n            account = self.make_account(account_id, password)\n            addr = account.first_address()\n            self.next_addresses[account_id] = addr\n            self.storage.put('next_addresses', self.next_addresses)\n\n        return account_id, addr\n\n    def account_id(self, i):\n        return \"m/%d'\"%i\n\n    def make_account(self, account_id, password):\n        \"\"\"Creates and saves the master keys, but does not save the account\"\"\"\n        xpub = self.add_master_keys(\"m/\", account_id, password)\n        account = BIP32_Account({'xpub':xpub})\n        return account\n\n    def make_seed(self):\n        import mnemonic, ecdsa\n        entropy = ecdsa.util.randrange( pow(2,160) )\n        nonce = 0\n        while True:\n            ss = \"%040x\"%(entropy+nonce)\n            s = hashlib.sha256(ss.decode('hex')).digest().encode('hex')\n            # we keep only 13 words, that's approximately 139 bits of entropy\n            words = mnemonic.mn_encode(s)[0:13]\n            seed = ' '.join(words)\n            if is_new_seed(seed):\n                break  # this will remove 8 bits of entropy\n            nonce += 1\n        return seed\n\n    def prepare_seed(self, seed):\n        import unicodedata\n        return NEW_SEED_VERSION, unicodedata.normalize('NFC', unicode(seed.strip()))\n\n\nclass Wallet_2of2(NewWallet):\n    \"\"\" This class is used for multisignature addresses\"\"\"\n\n    def __init__(self, storage):\n        NewWallet.__init__(self, storage)\n        self.storage.put('wallet_type', '2of2', True)\n\n    def default_account(self):\n        return self.accounts['m/']\n\n    def can_create_accounts(self):\n        return False\n\n    def can_import(self):\n        return False\n\n    def create_account(self):\n        xpub1 = self.master_public_keys.get(\"m/\")\n        xpub2 = self.master_public_keys.get(\"cold/\")\n        account = BIP32_Account_2of2({'xpub':xpub1, 'xpub2':xpub2})\n        self.add_account('m/', account)\n\n    def get_master_public_keys(self):\n        xpub1 = self.master_public_keys.get(\"m/\")\n        xpub2 = self.master_public_keys.get(\"cold/\")\n        return {'hot':xpub1, 'cold':xpub2}\n\n    def get_action(self):\n        xpub1 = self.master_public_keys.get(\"m/\")\n        xpub2 = self.master_public_keys.get(\"cold/\")\n        if xpub1 is None:\n            return 'create_2of2_1'\n        if xpub2 is None:\n            return 'create_2of2_2'\n\n\nclass Wallet_2of3(Wallet_2of2):\n    \"\"\" This class is used for multisignature addresses\"\"\"\n\n    def __init__(self, storage):\n        Wallet_2of2.__init__(self, storage)\n        self.storage.put('wallet_type', '2of3', True)\n\n    def create_account(self):\n        xpub1 = self.master_public_keys.get(\"m/\")\n        xpub2 = self.master_public_keys.get(\"cold/\")\n        xpub3 = self.master_public_keys.get(\"remote/\")\n        account = BIP32_Account_2of3({'xpub':xpub1, 'xpub2':xpub2, 'xpub3':xpub3})\n        self.add_account('m/', account)\n\n    def get_master_public_keys(self):\n        xpub1 = self.master_public_keys.get(\"m/\")\n        xpub2 = self.master_public_keys.get(\"cold/\")\n        xpub3 = self.master_public_keys.get(\"remote/\")\n        return {'hot':xpub1, 'cold':xpub2, 'remote':xpub3}\n\n    def get_action(self):\n        xpub1 = self.master_public_keys.get(\"m/\")\n        xpub2 = self.master_public_keys.get(\"cold/\")\n        xpub3 = self.master_public_keys.get(\"remote/\")\n        # fixme: we use order of creation\n        if xpub2 and xpub1 is None:\n            return 'create_2fa_2'\n        if xpub1 is None:\n            return 'create_2of3_1'\n        if xpub2 is None or xpub3 is None:\n            return 'create_2of3_2'\n\n\nclass OldWallet(Deterministic_Wallet):\n\n    def default_account(self):\n        return self.accounts[0]\n\n    def make_seed(self):\n        import mnemonic\n        seed = random_seed(128)\n        return ' '.join(mnemonic.mn_encode(seed))\n\n    def prepare_seed(self, seed):\n        import mnemonic\n        # see if seed was entered as hex\n        seed = seed.strip()\n        try:\n            assert seed\n            seed.decode('hex')\n            return OLD_SEED_VERSION, str(seed)\n        except Exception:\n            pass\n\n        words = seed.split()\n        seed = mnemonic.mn_decode(words)\n        if not seed:\n            raise Exception(\"Invalid seed\")\n\n        return OLD_SEED_VERSION, seed\n\n    def create_master_keys(self, password):\n        seed = self.get_seed(password)\n        mpk = OldAccount.mpk_from_seed(seed)\n        self.storage.put('master_public_key', mpk, True)\n\n    def get_master_public_key(self):\n        return self.storage.get(\"master_public_key\")\n\n    def get_master_public_keys(self):\n        return {'Main Account':self.get_master_public_key()}\n\n    def create_accounts(self, password):\n        mpk = self.storage.get(\"master_public_key\")\n        self.create_account(mpk)\n\n    def create_account(self, mpk):\n        self.accounts[0] = OldAccount({'mpk':mpk, 0:[], 1:[]})\n        self.save_accounts()\n\n    def create_watching_only_wallet(self, mpk):\n        self.seed_version = OLD_SEED_VERSION\n        self.storage.put('seed_version', self.seed_version, True)\n        self.storage.put('master_public_key', mpk, True)\n        self.create_account(mpk)\n\n    def get_seed(self, password):\n        seed = pw_decode(self.seed, password).encode('utf8')\n        return seed\n\n    def check_password(self, password):\n        seed = self.get_seed(password)\n        self.accounts[0].check_seed(seed)\n\n    def get_mnemonic(self, password):\n        import mnemonic\n        s = self.get_seed(password)\n        return ' '.join(mnemonic.mn_encode(s))\n\n    def check_pending_accounts(self):\n        pass\n\n\n# former WalletFactory\nclass Wallet(object):\n    \"\"\"The main wallet \"entry point\".\n    This class is actually a factory that will return a wallet of the correct\n    type when passed a WalletStorage instance.\"\"\"\n\n    def __new__(self, storage):\n        config = storage.config\n        if config.get('bitkey', False):\n            # if user requested support for Bitkey device,\n            # import Bitkey driver\n            from wallet_bitkey import WalletBitkey\n            return WalletBitkey(config)\n\n        if storage.get('wallet_type') == '2of2':\n            return Wallet_2of2(storage)\n\n        if storage.get('wallet_type') == '2of3':\n            return Wallet_2of3(storage)\n\n        if storage.get('wallet_type') == 'imported':\n            return Imported_Wallet(storage)\n\n        if not storage.file_exists:\n            seed_version = NEW_SEED_VERSION if config.get('bip32') is True else OLD_SEED_VERSION\n        else:\n            seed_version = storage.get('seed_version')\n            if not seed_version:\n                seed_version = OLD_SEED_VERSION if len(storage.get('master_public_key')) == 128 else NEW_SEED_VERSION\n\n        if seed_version == OLD_SEED_VERSION:\n            return OldWallet(storage)\n        elif seed_version == NEW_SEED_VERSION:\n            return NewWallet(storage)\n        else:\n            msg = \"This wallet seed is not supported.\"\n            if seed_version in [5]:\n                msg += \"\\nTo open this wallet, try 'git checkout seed_v%d'\"%seed_version\n            print msg\n            sys.exit(1)\n\n    @classmethod\n    def is_seed(self, seed):\n        if not seed:\n            return False\n        elif is_old_seed(seed):\n            return True\n        elif is_new_seed(seed):\n            return True\n        else:\n            return False\n\n    @classmethod\n    def is_old_mpk(self, mpk):\n        try:\n            int(mpk, 16)\n            assert len(mpk) == 128\n            return True\n        except:\n            return False\n\n    @classmethod\n    def is_xpub(self, text):\n        try:\n            assert text[0:4] == 'xpub'\n            deserialize_xkey(text)\n            return True\n        except:\n            return False\n\n    @classmethod\n    def is_xprv(self, text):\n        try:\n            assert text[0:4] == 'xprv'\n            deserialize_xkey(text)\n            return True\n        except:\n            return False\n\n    @classmethod\n    def is_address(self, text):\n        if not text:\n            return False\n        for x in text.split():\n            if not bitcoin.is_address(x):\n                return False\n        return True\n\n    @classmethod\n    def is_private_key(self, text):\n        if not text:\n            return False\n        for x in text.split():\n            if not bitcoin.is_private_key(x):\n                return False\n        return True\n\n    @classmethod\n    def from_seed(self, seed, storage):\n        if is_old_seed(seed):\n            klass = OldWallet\n        elif is_new_seed(seed):\n            klass = NewWallet\n        w = klass(storage)\n        return w\n\n    @classmethod\n    def from_address(self, text, storage):\n        w = Imported_Wallet(storage)\n        for x in text.split():\n            w.accounts[IMPORTED_ACCOUNT].add(x, None, None, None)\n        w.save_accounts()\n        return w\n\n    @classmethod\n    def from_private_key(self, text, storage):\n        w = Imported_Wallet(storage)\n        for x in text.split():\n            w.import_key(x, None)\n        return w\n\n    @classmethod\n    def from_old_mpk(self, mpk, storage):\n        w = OldWallet(storage)\n        w.seed = ''\n        w.create_watching_only_wallet(mpk)\n        return w\n\n    @classmethod\n    def from_xpub(self, xpub, storage):\n        w = NewWallet(storage)\n        w.create_watching_only_wallet(xpub)\n        return w\n\n    @classmethod\n    def from_xprv(self, xprv, password, storage):\n        w = NewWallet(storage)\n        w.create_xprv_wallet(xprv, password)\n        return w\n", "idx": 1, "id": 10942, "msg": "move to try/except - this shouldn't be required for people that don't have a trezor", "proj": "spesmilo-electrum", "lang": "py"}
{"patch": "@@ -780,10 +780,18 @@ class CommandDispatcher:\n                 text=\"Are you sure you want to close pinned tabs?\")\n \n     @cmdutils.register(instance='command-dispatcher', scope='window')\n-    def undo(self):\n-        \"\"\"Re-open the last closed tab or tabs.\"\"\"\n+    def undo(self, window: bool = False):\n+        \"\"\"Re-open the last closed tab(s) or window.\n+\n+        Args:\n+            window: Re-open the last closed window (and its tabs).\n+        \"\"\"\n         try:\n-            self._tabbed_browser.undo()\n+            if window:\n+                app = QApplication.instance()\n+                app.undo_last_window_close()\n+            else:\n+                self._tabbed_browser.undo()\n         except IndexError:\n             raise cmdutils.CommandError(\"Nothing to undo!\")\n ", "y": 1, "oldf": "# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:\n\n# Copyright 2014-2020 Florian Bruhin (The Compiler) <mail@qutebrowser.org>\n#\n# This file is part of qutebrowser.\n#\n# qutebrowser is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# qutebrowser is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with qutebrowser.  If not, see <http://www.gnu.org/licenses/>.\n\n\"\"\"Command dispatcher for TabbedBrowser.\"\"\"\n\nimport os.path\nimport shlex\nimport functools\nimport typing\n\nfrom PyQt5.QtWidgets import QApplication, QTabBar\nfrom PyQt5.QtCore import pyqtSlot, Qt, QUrl, QEvent, QUrlQuery\n\nfrom qutebrowser.commands import userscripts, runners\nfrom qutebrowser.api import cmdutils\nfrom qutebrowser.config import config, configdata\nfrom qutebrowser.browser import (urlmarks, browsertab, navigate, webelem,\n                                 downloads)\nfrom qutebrowser.keyinput import modeman, keyutils\nfrom qutebrowser.utils import (message, usertypes, log, qtutils, urlutils,\n                               objreg, utils, standarddir, debug)\nfrom qutebrowser.utils.usertypes import KeyMode\nfrom qutebrowser.misc import editor, guiprocess, objects\nfrom qutebrowser.completion.models import urlmodel, miscmodels\nfrom qutebrowser.mainwindow import mainwindow\n\n\nclass CommandDispatcher:\n\n    \"\"\"Command dispatcher for TabbedBrowser.\n\n    Contains all commands which are related to the current tab.\n\n    We can't simply add these commands to BrowserTab directly and use\n    currentWidget() for TabbedBrowser.cmd because at the time\n    cmdutils.register() decorators are run, currentWidget() will return None.\n\n    Attributes:\n        _win_id: The window ID the CommandDispatcher is associated with.\n        _tabbed_browser: The TabbedBrowser used.\n    \"\"\"\n\n    def __init__(self, win_id, tabbed_browser):\n        self._win_id = win_id\n        self._tabbed_browser = tabbed_browser\n\n    def __repr__(self):\n        return utils.get_repr(self)\n\n    def _new_tabbed_browser(self, private):\n        \"\"\"Get a tabbed-browser from a new window.\"\"\"\n        args = QApplication.instance().arguments()\n        if private and '--single-process' in args:\n            raise cmdutils.CommandError(\"Private windows are unavailable with \"\n                                        \"the single-process process model.\")\n\n        new_window = mainwindow.MainWindow(private=private)\n        new_window.show()\n        return new_window.tabbed_browser\n\n    def _count(self) -> int:\n        \"\"\"Convenience method to get the widget count.\"\"\"\n        return self._tabbed_browser.widget.count()\n\n    def _set_current_index(self, idx):\n        \"\"\"Convenience method to set the current widget index.\"\"\"\n        cmdutils.check_overflow(idx, 'int')\n        self._tabbed_browser.widget.setCurrentIndex(idx)\n\n    def _current_index(self):\n        \"\"\"Convenience method to get the current widget index.\"\"\"\n        return self._tabbed_browser.widget.currentIndex()\n\n    def _current_url(self):\n        \"\"\"Convenience method to get the current url.\"\"\"\n        try:\n            return self._tabbed_browser.current_url()\n        except qtutils.QtValueError as e:\n            msg = \"Current URL is invalid\"\n            if e.reason:\n                msg += \" ({})\".format(e.reason)\n            msg += \"!\"\n            raise cmdutils.CommandError(msg)\n\n    def _current_title(self):\n        \"\"\"Convenience method to get the current title.\"\"\"\n        return self._current_widget().title()\n\n    def _current_widget(self):\n        \"\"\"Get the currently active widget from a command.\"\"\"\n        widget = self._tabbed_browser.widget.currentWidget()\n        if widget is None:\n            raise cmdutils.CommandError(\"No WebView available yet!\")\n        return widget\n\n    def _open(self, url, tab=False, background=False, window=False,\n              related=False, private=None):\n        \"\"\"Helper function to open a page.\n\n        Args:\n            url: The URL to open as QUrl.\n            tab: Whether to open in a new tab.\n            background: Whether to open in the background.\n            window: Whether to open in a new window\n            private: If opening a new window, open it in private browsing mode.\n                     If not given, inherit the current window's mode.\n        \"\"\"\n        urlutils.raise_cmdexc_if_invalid(url)\n        tabbed_browser = self._tabbed_browser\n        cmdutils.check_exclusive((tab, background, window, private), 'tbwp')\n        if window and private is None:\n            private = self._tabbed_browser.is_private\n\n        if window or private:\n            tabbed_browser = self._new_tabbed_browser(private)\n            tabbed_browser.tabopen(url)\n        elif tab:\n            tabbed_browser.tabopen(url, background=False, related=related)\n        elif background:\n            tabbed_browser.tabopen(url, background=True, related=related)\n        else:\n            widget = self._current_widget()\n            widget.load_url(url)\n\n    def _cntwidget(self, count=None):\n        \"\"\"Return a widget based on a count/idx.\n\n        Args:\n            count: The tab index, or None.\n\n        Return:\n            The current widget if count is None.\n            The widget with the given tab ID if count is given.\n            None if no widget was found.\n        \"\"\"\n        if count is None:\n            return self._tabbed_browser.widget.currentWidget()\n        elif 1 <= count <= self._count():\n            cmdutils.check_overflow(count + 1, 'int')\n            return self._tabbed_browser.widget.widget(count - 1)\n        else:\n            return None\n\n    def _tab_focus_stack(self, mode: str, *, show_error: bool = True) -> None:\n        \"\"\"Select the tab which was last focused.\"\"\"\n        tab_deque = self._tabbed_browser.tab_deque\n        cur_tab = self._cntwidget()\n\n        try:\n            if mode == \"last\":\n                tab = tab_deque.last(cur_tab)\n            elif mode == \"stack-prev\":\n                tab = tab_deque.prev(cur_tab)\n            elif mode == \"stack-next\":\n                tab = tab_deque.next(cur_tab)\n            else:\n                raise NotImplementedError(\n                    \"Missing implementation for stack mode!\")\n        except IndexError:\n            if not show_error:\n                return\n            raise cmdutils.CommandError(\"Could not find requested tab!\")\n\n        idx = self._tabbed_browser.widget.indexOf(tab)\n        if idx == -1:\n            raise cmdutils.CommandError(\"Requested tab vanished!\")\n        self._set_current_index(idx)\n\n    def _get_selection_override(self, prev, next_, opposite):\n        \"\"\"Helper function for tab_close to get the tab to select.\n\n        Args:\n            prev: Force selecting the tab before the current tab.\n            next_: Force selecting the tab after the current tab.\n            opposite: Force selecting the tab in the opposite direction of\n                      what's configured in 'tabs.select_on_remove'.\n\n        Return:\n            QTabBar.SelectLeftTab, QTabBar.SelectRightTab, or None if no change\n            should be made.\n        \"\"\"\n        cmdutils.check_exclusive((prev, next_, opposite), 'pno')\n        if prev:\n            return QTabBar.SelectLeftTab\n        elif next_:\n            return QTabBar.SelectRightTab\n        elif opposite:\n            conf_selection = config.val.tabs.select_on_remove\n            if conf_selection == QTabBar.SelectLeftTab:\n                return QTabBar.SelectRightTab\n            elif conf_selection == QTabBar.SelectRightTab:\n                return QTabBar.SelectLeftTab\n            elif conf_selection == QTabBar.SelectPreviousTab:\n                raise cmdutils.CommandError(\n                    \"-o is not supported with 'tabs.select_on_remove' set to \"\n                    \"'last-used'!\")\n            else:  # pragma: no cover\n                raise ValueError(\"Invalid select_on_remove value \"\n                                 \"{!r}!\".format(conf_selection))\n        return None\n\n    def _tab_close(self, tab, prev=False, next_=False, opposite=False):\n        \"\"\"Helper function for tab_close be able to handle message.async.\n\n        Args:\n            tab: Tab object to select be closed.\n            prev: Force selecting the tab before the current tab.\n            next_: Force selecting the tab after the current tab.\n            opposite: Force selecting the tab in the opposite direction of\n                      what's configured in 'tabs.select_on_remove'.\n            count: The tab index to close, or None\n        \"\"\"\n        tabbar = self._tabbed_browser.widget.tabBar()\n        selection_override = self._get_selection_override(prev, next_,\n                                                          opposite)\n\n        if selection_override is None:\n            self._tabbed_browser.close_tab(tab)\n        else:\n            old_selection_behavior = tabbar.selectionBehaviorOnRemove()\n            tabbar.setSelectionBehaviorOnRemove(selection_override)\n            self._tabbed_browser.close_tab(tab)\n            tabbar.setSelectionBehaviorOnRemove(old_selection_behavior)\n\n    @cmdutils.register(instance='command-dispatcher', scope='window')\n    @cmdutils.argument('count', value=cmdutils.Value.count)\n    def tab_close(self, prev=False, next_=False, opposite=False,\n                  force=False, count=None):\n        \"\"\"Close the current/[count]th tab.\n\n        Args:\n            prev: Force selecting the tab before the current tab.\n            next_: Force selecting the tab after the current tab.\n            opposite: Force selecting the tab in the opposite direction of\n                      what's configured in 'tabs.select_on_remove'.\n            force: Avoid confirmation for pinned tabs.\n            count: The tab index to close, or None\n        \"\"\"\n        tab = self._cntwidget(count)\n        if tab is None:\n            return\n        close = functools.partial(self._tab_close, tab, prev,\n                                  next_, opposite)\n\n        self._tabbed_browser.tab_close_prompt_if_pinned(tab, force, close)\n\n    @cmdutils.register(instance='command-dispatcher', scope='window',\n                       name='tab-pin')\n    @cmdutils.argument('count', value=cmdutils.Value.count)\n    def tab_pin(self, count=None):\n        \"\"\"Pin/Unpin the current/[count]th tab.\n\n        Pinning a tab shrinks it to the size of its title text.\n        Attempting to close a pinned tab will cause a confirmation,\n        unless --force is passed.\n\n        Args:\n            count: The tab index to pin or unpin, or None\n        \"\"\"\n        tab = self._cntwidget(count)\n        if tab is None:\n            return\n\n        to_pin = not tab.data.pinned\n        self._tabbed_browser.widget.set_tab_pinned(tab, to_pin)\n\n    @cmdutils.register(instance='command-dispatcher', name='open',\n                       maxsplit=0, scope='window')\n    @cmdutils.argument('url', completion=urlmodel.url)\n    @cmdutils.argument('count', value=cmdutils.Value.count)\n    def openurl(self, url=None, related=False,\n                bg=False, tab=False, window=False, count=None, secure=False,\n                private=False):\n        \"\"\"Open a URL in the current/[count]th tab.\n\n        If the URL contains newlines, each line gets opened in its own tab.\n\n        Args:\n            url: The URL to open.\n            bg: Open in a new background tab.\n            tab: Open in a new tab.\n            window: Open in a new window.\n            related: If opening a new tab, position the tab as related to the\n                     current one (like clicking on a link).\n            count: The tab index to open the URL in, or None.\n            secure: Force HTTPS.\n            private: Open a new window in private browsing mode.\n        \"\"\"\n        if url is None:\n            urls = [config.val.url.default_page]\n        else:\n            urls = self._parse_url_input(url)\n\n        for i, cur_url in enumerate(urls):\n            if secure and cur_url.scheme() == 'http':\n                cur_url.setScheme('https')\n\n            if not window and i > 0:\n                tab = False\n                bg = True\n\n            if tab or bg or window or private:\n                self._open(cur_url, tab, bg, window, related=related,\n                           private=private)\n            else:\n                curtab = self._cntwidget(count)\n                if curtab is None:\n                    if count is None:\n                        # We want to open a URL in the current tab, but none\n                        # exists yet.\n                        self._tabbed_browser.tabopen(cur_url)\n                    else:\n                        # Explicit count with a tab that doesn't exist.\n                        return\n                elif curtab.navigation_blocked():\n                    message.info(\"Tab is pinned!\")\n                else:\n                    curtab.load_url(cur_url)\n\n    def _parse_url(self, url, *, force_search=False):\n        \"\"\"Parse a URL or quickmark or search query.\n\n        Args:\n            url: The URL to parse.\n            force_search: Whether to force a search even if the content can be\n                          interpreted as a URL or a path.\n\n        Return:\n            A URL that can be opened.\n        \"\"\"\n        try:\n            return objreg.get('quickmark-manager').get(url)\n        except urlmarks.Error:\n            try:\n                return urlutils.fuzzy_url(url, force_search=force_search)\n            except urlutils.InvalidUrlError as e:\n                # We don't use cmdutils.CommandError here as this can be\n                # called async from edit_url\n                message.error(str(e))\n                return None\n\n    def _parse_url_input(self, url):\n        \"\"\"Parse a URL or newline-separated list of URLs.\n\n        Args:\n            url: The URL or list to parse.\n\n        Return:\n            A list of URLs that can be opened.\n        \"\"\"\n        if isinstance(url, QUrl):\n            yield url\n            return\n\n        force_search = False\n        urllist = [u for u in url.split('\\n') if u.strip()]\n        if (len(urllist) > 1 and not urlutils.is_url(urllist[0]) and\n                urlutils.get_path_if_valid(urllist[0], check_exists=True)\n                is None):\n            urllist = [url]\n            force_search = True\n        for cur_url in urllist:\n            parsed = self._parse_url(cur_url, force_search=force_search)\n            if parsed is not None:\n                yield parsed\n\n    @cmdutils.register(instance='command-dispatcher', scope='window')\n    def tab_clone(self, bg=False, window=False):\n        \"\"\"Duplicate the current tab.\n\n        Args:\n            bg: Open in a background tab.\n            window: Open in a new window.\n\n        Return:\n            The new QWebView.\n        \"\"\"\n        cmdutils.check_exclusive((bg, window), 'bw')\n        curtab = self._current_widget()\n        cur_title = self._tabbed_browser.widget.page_title(\n            self._current_index())\n        try:\n            history = curtab.history.private_api.serialize()\n        except browsertab.WebTabError as e:\n            raise cmdutils.CommandError(e)\n\n        # The new tab could be in a new tabbed_browser (e.g. because of\n        # tabs.tabs_are_windows being set)\n        if window:\n            new_tabbed_browser = self._new_tabbed_browser(\n                private=self._tabbed_browser.is_private)\n        else:\n            new_tabbed_browser = self._tabbed_browser\n        newtab = new_tabbed_browser.tabopen(background=bg)\n        new_tabbed_browser = objreg.get('tabbed-browser', scope='window',\n                                        window=newtab.win_id)\n        idx = new_tabbed_browser.widget.indexOf(newtab)\n\n        new_tabbed_browser.widget.set_page_title(idx, cur_title)\n        if curtab.data.should_show_icon():\n            new_tabbed_browser.widget.setTabIcon(idx, curtab.icon())\n            if config.val.tabs.tabs_are_windows:\n                new_tabbed_browser.widget.window().setWindowIcon(curtab.icon())\n\n        newtab.data.keep_icon = True\n        newtab.history.private_api.deserialize(history)\n        newtab.zoom.set_factor(curtab.zoom.factor())\n        new_tabbed_browser.widget.set_tab_pinned(newtab, curtab.data.pinned)\n        return newtab\n\n    @cmdutils.register(instance='command-dispatcher', scope='window',\n                       maxsplit=0)\n    @cmdutils.argument('index', completion=miscmodels.other_buffer)\n    def tab_take(self, index, keep=False):\n        \"\"\"Take a tab from another window.\n\n        Args:\n            index: The [win_id/]index of the tab to take. Or a substring\n                   in which case the closest match will be taken.\n            keep: If given, keep the old tab around.\n        \"\"\"\n        if config.val.tabs.tabs_are_windows:\n            raise cmdutils.CommandError(\"Can't take tabs when using \"\n                                        \"windows as tabs\")\n\n        tabbed_browser, tab = self._resolve_buffer_index(index)\n\n        if tabbed_browser is self._tabbed_browser:\n            raise cmdutils.CommandError(\"Can't take a tab from the same \"\n                                        \"window\")\n\n        self._open(tab.url(), tab=True)\n        if not keep:\n            tabbed_browser.close_tab(tab, add_undo=False)\n\n    @cmdutils.register(instance='command-dispatcher', scope='window')\n    @cmdutils.argument('win_id', completion=miscmodels.window)\n    @cmdutils.argument('count', value=cmdutils.Value.count)\n    def tab_give(self, win_id: int = None, keep: bool = False,\n                 count: int = None, private: bool = False) -> None:\n        \"\"\"Give the current tab to a new or existing window if win_id given.\n\n        If no win_id is given, the tab will get detached into a new window.\n\n        Args:\n            win_id: The window ID of the window to give the current tab to.\n            keep: If given, keep the old tab around.\n            count: Overrides win_id (index starts at 1 for win_id=0).\n            private: If the tab should be detached into a private instance.\n        \"\"\"\n        if config.val.tabs.tabs_are_windows:\n            raise cmdutils.CommandError(\"Can't give tabs when using \"\n                                        \"windows as tabs\")\n\n        if count is not None:\n            win_id = count - 1\n\n        if win_id == self._win_id:\n            raise cmdutils.CommandError(\"Can't give a tab to the same window\")\n\n        if win_id is None:\n            if self._count() < 2 and not keep:\n                raise cmdutils.CommandError(\"Cannot detach from a window with \"\n                                            \"only one tab\")\n\n            tabbed_browser = self._new_tabbed_browser(\n                private=private or self._tabbed_browser.is_private)\n        else:\n            if win_id not in objreg.window_registry:\n                raise cmdutils.CommandError(\n                    \"There's no window with id {}!\".format(win_id))\n\n            tabbed_browser = objreg.get('tabbed-browser', scope='window',\n                                        window=win_id)\n\n            if private and not tabbed_browser.is_private:\n                raise cmdutils.CommandError(\n                    \"The window with id {} is not private\".format(win_id))\n\n        tabbed_browser.tabopen(self._current_url())\n        if not keep:\n            self._tabbed_browser.close_tab(self._current_widget(),\n                                           add_undo=False)\n\n    def _back_forward(self, tab, bg, window, count, forward):\n        \"\"\"Helper function for :back/:forward.\"\"\"\n        history = self._current_widget().history\n        # Catch common cases before e.g. cloning tab\n        if not forward and not history.can_go_back():\n            raise cmdutils.CommandError(\"At beginning of history.\")\n        if forward and not history.can_go_forward():\n            raise cmdutils.CommandError(\"At end of history.\")\n\n        if tab or bg or window:\n            widget = self.tab_clone(bg, window)\n        else:\n            widget = self._current_widget()\n\n        try:\n            if forward:\n                widget.history.forward(count)\n            else:\n                widget.history.back(count)\n        except browsertab.WebTabError as e:\n            raise cmdutils.CommandError(e)\n\n    @cmdutils.register(instance='command-dispatcher', scope='window')\n    @cmdutils.argument('count', value=cmdutils.Value.count)\n    def back(self, tab=False, bg=False, window=False, count=1):\n        \"\"\"Go back in the history of the current tab.\n\n        Args:\n            tab: Go back in a new tab.\n            bg: Go back in a background tab.\n            window: Go back in a new window.\n            count: How many pages to go back.\n        \"\"\"\n        self._back_forward(tab, bg, window, count, forward=False)\n\n    @cmdutils.register(instance='command-dispatcher', scope='window')\n    @cmdutils.argument('count', value=cmdutils.Value.count)\n    def forward(self, tab=False, bg=False, window=False, count=1):\n        \"\"\"Go forward in the history of the current tab.\n\n        Args:\n            tab: Go forward in a new tab.\n            bg: Go forward in a background tab.\n            window: Go forward in a new window.\n            count: How many pages to go forward.\n        \"\"\"\n        self._back_forward(tab, bg, window, count, forward=True)\n\n    @cmdutils.register(instance='command-dispatcher', scope='window')\n    @cmdutils.argument('where', choices=['prev', 'next', 'up', 'increment',\n                                         'decrement'])\n    @cmdutils.argument('count', value=cmdutils.Value.count)\n    def navigate(self, where: str, tab: bool = False, bg: bool = False,\n                 window: bool = False, count: int = 1) -> None:\n        \"\"\"Open typical prev/next links or navigate using the URL path.\n\n        This tries to automatically click on typical _Previous Page_ or\n        _Next Page_ links using some heuristics.\n\n        Alternatively it can navigate by changing the current URL.\n\n        Args:\n            where: What to open.\n\n                - `prev`: Open a _previous_ link.\n                - `next`: Open a _next_ link.\n                - `up`: Go up a level in the current URL.\n                - `increment`: Increment the last number in the URL.\n                  Uses the\n                  link:settings{outsuffix}#url.incdec_segments[url.incdec_segments]\n                  config option.\n                - `decrement`: Decrement the last number in the URL.\n                  Uses the\n                  link:settings{outsuffix}#url.incdec_segments[url.incdec_segments]\n                  config option.\n\n            tab: Open in a new tab.\n            bg: Open in a background tab.\n            window: Open in a new window.\n            count: For `increment` and `decrement`, the number to change the\n                   URL by. For `up`, the number of levels to go up in the URL.\n        \"\"\"\n        cmdutils.check_exclusive((tab, bg, window), 'tbw')\n        widget = self._current_widget()\n        url = self._current_url()\n\n        handlers = {\n            'prev': functools.partial(navigate.prevnext, prev=True),\n            'next': functools.partial(navigate.prevnext, prev=False),\n            'up': navigate.path_up,\n            'decrement': functools.partial(navigate.incdec,\n                                           inc_or_dec='decrement'),\n            'increment': functools.partial(navigate.incdec,\n                                           inc_or_dec='increment'),\n        }  # type: typing.Dict[str, typing.Callable]\n\n        try:\n            if where in ['prev', 'next']:\n                handler = handlers[where]\n                handler(browsertab=widget, win_id=self._win_id, baseurl=url,\n                        tab=tab, background=bg, window=window)\n            elif where in ['up', 'increment', 'decrement']:\n                if where == 'up':\n                    url = url.adjusted(QUrl.RemoveFragment | QUrl.RemoveQuery)\n                new_url = handlers[where](url, count)\n                self._open(new_url, tab, bg, window, related=True)\n            else:  # pragma: no cover\n                raise ValueError(\"Got called with invalid value {} for \"\n                                 \"`where'.\".format(where))\n        except navigate.Error as e:\n            raise cmdutils.CommandError(e)\n\n    @cmdutils.register(instance='command-dispatcher', scope='window')\n    @cmdutils.argument('count', value=cmdutils.Value.count)\n    @cmdutils.argument('top_navigate', metavar='ACTION',\n                       choices=('prev', 'decrement'))\n    @cmdutils.argument('bottom_navigate', metavar='ACTION',\n                       choices=('next', 'increment'))\n    def scroll_page(self, x: float, y: float, *,\n                    top_navigate: str = None, bottom_navigate: str = None,\n                    count: int = 1) -> None:\n        \"\"\"Scroll the frame page-wise.\n\n        Args:\n            x: How many pages to scroll to the right.\n            y: How many pages to scroll down.\n            bottom_navigate: :navigate action (next, increment) to run when\n                             scrolling down at the bottom of the page.\n            top_navigate: :navigate action (prev, decrement) to run when\n                          scrolling up at the top of the page.\n            count: multiplier\n        \"\"\"\n        tab = self._current_widget()\n        if not tab.url().isValid():\n            # See https://github.com/qutebrowser/qutebrowser/issues/701\n            return\n\n        if bottom_navigate is not None and tab.scroller.at_bottom():\n            self.navigate(bottom_navigate)\n            return\n        elif top_navigate is not None and tab.scroller.at_top():\n            self.navigate(top_navigate)\n            return\n\n        try:\n            tab.scroller.delta_page(count * x, count * y)\n        except OverflowError:\n            raise cmdutils.CommandError(\n                \"Numeric argument is too large for internal int \"\n                \"representation.\")\n\n    def _yank_url(self, what):\n        \"\"\"Helper method for yank() to get the URL to copy.\"\"\"\n        assert what in ['url', 'pretty-url'], what\n\n        if what == 'pretty-url':\n            flags = QUrl.RemovePassword | QUrl.DecodeReserved\n        else:\n            flags = QUrl.RemovePassword | QUrl.FullyEncoded\n\n        url = QUrl(self._current_url())\n        url_query = QUrlQuery()\n        url_query_str = urlutils.query_string(url)\n        if '&' not in url_query_str and ';' in url_query_str:\n            url_query.setQueryDelimiters('=', ';')\n        url_query.setQuery(url_query_str)\n        for key in dict(url_query.queryItems()):\n            if key in config.val.url.yank_ignored_parameters:\n                url_query.removeQueryItem(key)\n        url.setQuery(url_query)\n        return url.toString(flags)  # type: ignore[arg-type]\n\n    @cmdutils.register(instance='command-dispatcher', scope='window')\n    @cmdutils.argument('what', choices=['selection', 'url', 'pretty-url',\n                                        'title', 'domain', 'inline'])\n    def yank(self, what='url', inline=None,\n             sel=False, keep=False, quiet=False):\n        \"\"\"Yank (copy) something to the clipboard or primary selection.\n\n        Args:\n            what: What to yank.\n\n                - `url`: The current URL.\n                - `pretty-url`: The URL in pretty decoded form.\n                - `title`: The current page's title.\n                - `domain`: The current scheme, domain, and port number.\n                - `selection`: The selection under the cursor.\n                - `inline`: Yank the text contained in the 'inline' argument.\n\n            sel: Use the primary selection instead of the clipboard.\n            keep: Stay in visual mode after yanking the selection.\n            quiet: Don't show an information message.\n            inline: A block of text, to be yanked if 'what'\n                is inline and ignored otherwise.\n        \"\"\"\n        if what == 'inline':\n            s = inline\n            what = 'inline block'\n        elif what == 'title':\n            s = self._tabbed_browser.widget.page_title(self._current_index())\n        elif what == 'domain':\n            port = self._current_url().port()\n            s = '{}://{}{}'.format(self._current_url().scheme(),\n                                   self._current_url().host(),\n                                   ':' + str(port) if port > -1 else '')\n        elif what in ['url', 'pretty-url']:\n            s = self._yank_url(what)\n            what = 'URL'  # For printing\n        elif what == 'selection':\n            def _selection_callback(s):\n                if not s and not quiet:\n                    message.info(\"Nothing to yank\")\n                    return\n                self._yank_to_target(s, sel, what, keep, quiet)\n\n            caret = self._current_widget().caret\n            caret.selection(callback=_selection_callback)\n            return\n        else:  # pragma: no cover\n            raise ValueError(\"Invalid value {!r} for `what'.\".format(what))\n\n        self._yank_to_target(s, sel, what, keep, quiet)\n\n    def _yank_to_target(self, s, sel, what, keep, quiet):\n        if sel and utils.supports_selection():\n            target = \"primary selection\"\n        else:\n            sel = False\n            target = \"clipboard\"\n\n        utils.set_clipboard(s, selection=sel)\n        if what != 'selection':\n            if not quiet:\n                message.info(\"Yanked {} to {}: {}\".format(what, target, s))\n        else:\n            if not quiet:\n                message.info(\"{} {} yanked to {}\".format(\n                    len(s), \"char\" if len(s) == 1 else \"chars\", target))\n            if not keep:\n                modeman.leave(self._win_id, KeyMode.caret, \"yank selected\",\n                              maybe=True)\n\n    @cmdutils.register(instance='command-dispatcher', scope='window')\n    def tab_only(self, prev=False, next_=False, force=False):\n        \"\"\"Close all tabs except for the current one.\n\n        Args:\n            prev: Keep tabs before the current.\n            next_: Keep tabs after the current.\n            force: Avoid confirmation for pinned tabs.\n        \"\"\"\n        cmdutils.check_exclusive((prev, next_), 'pn')\n        cur_idx = self._tabbed_browser.widget.currentIndex()\n        assert cur_idx != -1\n\n        def _to_close(i):\n            \"\"\"Helper method to check if a tab should be closed or not.\"\"\"\n            return not (i == cur_idx or\n                        (prev and i < cur_idx) or\n                        (next_ and i > cur_idx))\n\n        # close as many tabs as we can\n        first_tab = True\n        pinned_tabs_cleanup = False\n        for i, tab in enumerate(self._tabbed_browser.widgets()):\n            if _to_close(i):\n                if force or not tab.data.pinned:\n                    self._tabbed_browser.close_tab(tab, new_undo=first_tab)\n                    first_tab = False\n                else:\n                    pinned_tabs_cleanup = tab\n\n        # Check to see if we would like to close any pinned tabs\n        if pinned_tabs_cleanup:\n            self._tabbed_browser.tab_close_prompt_if_pinned(\n                pinned_tabs_cleanup,\n                force,\n                lambda: self.tab_only(\n                    prev=prev, next_=next_, force=True),\n                text=\"Are you sure you want to close pinned tabs?\")\n\n    @cmdutils.register(instance='command-dispatcher', scope='window')\n    def undo(self):\n        \"\"\"Re-open the last closed tab or tabs.\"\"\"\n        try:\n            self._tabbed_browser.undo()\n        except IndexError:\n            raise cmdutils.CommandError(\"Nothing to undo!\")\n\n    @cmdutils.register(instance='command-dispatcher', scope='window')\n    @cmdutils.argument('count', value=cmdutils.Value.count)\n    def tab_prev(self, count=1):\n        \"\"\"Switch to the previous tab, or switch [count] tabs back.\n\n        Args:\n            count: How many tabs to switch back.\n        \"\"\"\n        if self._count() == 0:\n            # Running :tab-prev after last tab was closed\n            # See https://github.com/qutebrowser/qutebrowser/issues/1448\n            return\n        newidx = self._current_index() - count\n        if newidx >= 0:\n            self._set_current_index(newidx)\n        elif config.val.tabs.wrap:\n            self._set_current_index(newidx % self._count())\n        else:\n            log.webview.debug(\"First tab\")\n\n    @cmdutils.register(instance='command-dispatcher', scope='window')\n    @cmdutils.argument('count', value=cmdutils.Value.count)\n    def tab_next(self, count=1):\n        \"\"\"Switch to the next tab, or switch [count] tabs forward.\n\n        Args:\n            count: How many tabs to switch forward.\n        \"\"\"\n        if self._count() == 0:\n            # Running :tab-next after last tab was closed\n            # See https://github.com/qutebrowser/qutebrowser/issues/1448\n            return\n        newidx = self._current_index() + count\n        if newidx < self._count():\n            self._set_current_index(newidx)\n        elif config.val.tabs.wrap:\n            self._set_current_index(newidx % self._count())\n        else:\n            log.webview.debug(\"Last tab\")\n\n    def _resolve_buffer_index(self, index):\n        \"\"\"Resolve a buffer index to the tabbedbrowser and tab.\n\n        Args:\n            index: The [win_id/]index of the tab to be selected. Or a substring\n                   in which case the closest match will be focused.\n        \"\"\"\n        index_parts = index.split('/', 1)\n\n        try:\n            for part in index_parts:\n                int(part)\n        except ValueError:\n            model = miscmodels.buffer()\n            model.set_pattern(index)\n            if model.count() > 0:\n                index = model.data(model.first_item())\n                index_parts = index.split('/', 1)\n            else:\n                raise cmdutils.CommandError(\n                    \"No matching tab for: {}\".format(index))\n\n        if len(index_parts) == 2:\n            win_id = int(index_parts[0])\n            idx = int(index_parts[1])\n        elif len(index_parts) == 1:\n            idx = int(index_parts[0])\n            active_win = QApplication.activeWindow()\n            if active_win is None:\n                # Not sure how you enter a command without an active window...\n                raise cmdutils.CommandError(\n                    \"No window specified and couldn't find active window!\")\n            win_id = active_win.win_id\n\n        if win_id not in objreg.window_registry:\n            raise cmdutils.CommandError(\n                \"There's no window with id {}!\".format(win_id))\n\n        tabbed_browser = objreg.get('tabbed-browser', scope='window',\n                                    window=win_id)\n        if not 0 < idx <= tabbed_browser.widget.count():\n            raise cmdutils.CommandError(\n                \"There's no tab with index {}!\".format(idx))\n\n        return (tabbed_browser, tabbed_browser.widget.widget(idx-1))\n\n    @cmdutils.register(instance='command-dispatcher', scope='window',\n                       maxsplit=0)\n    @cmdutils.argument('index', completion=miscmodels.buffer)\n    @cmdutils.argument('count', value=cmdutils.Value.count)\n    def buffer(self, index=None, count=None):\n        \"\"\"Select tab by index or url/title best match.\n\n        Focuses window if necessary when index is given. If both index and\n        count are given, use count.\n\n        With neither index nor count given, open the qute://tabs page.\n\n        Args:\n            index: The [win_id/]index of the tab to focus. Or a substring\n                   in which case the closest match will be focused.\n            count: The tab index to focus, starting with 1.\n        \"\"\"\n        if count is None and index is None:\n            self.openurl('qute://tabs/', tab=True)\n            return\n\n        if count is not None:\n            index = str(count)\n\n        tabbed_browser, tab = self._resolve_buffer_index(index)\n\n        window = tabbed_browser.widget.window()\n        window.activateWindow()\n        window.raise_()\n        tabbed_browser.widget.setCurrentWidget(tab)\n\n    @cmdutils.register(instance='command-dispatcher', scope='window')\n    @cmdutils.argument('index', choices=['last', 'stack-next', 'stack-prev'],\n                       completion=miscmodels.tab_focus)\n    @cmdutils.argument('count', value=cmdutils.Value.count)\n    def tab_focus(self, index: typing.Union[str, int] = None,\n                  count: int = None, no_last: bool = False) -> None:\n        \"\"\"Select the tab given as argument/[count].\n\n        If neither count nor index are given, it behaves like tab-next.\n        If both are given, use count.\n\n        Args:\n            index: The tab index to focus, starting with 1. The special value\n                   `last` focuses the last focused tab (regardless of count),\n                   and `stack-prev`/`stack-next` traverse a stack of visited\n                   tabs. Negative indices count from the end, such that -1 is\n                   the last tab.\n            count: The tab index to focus, starting with 1.\n            no_last: Whether to avoid focusing last tab if already focused.\n        \"\"\"\n        index = count if count is not None else index\n\n        if index in {'last', 'stack-next', 'stack-prev'}:\n            assert isinstance(index, str)\n            self._tab_focus_stack(index)\n            return\n        elif index is None:\n            self.tab_next()\n            return\n\n        assert isinstance(index, int)\n\n        if index < 0:\n            index = self._count() + index + 1\n\n        if not no_last and index == self._current_index() + 1:\n            self._tab_focus_stack('last', show_error=False)\n            return\n\n        if 1 <= index <= self._count():\n            self._set_current_index(index - 1)\n        else:\n            raise cmdutils.CommandError(\"There's no tab with index {}!\".format(\n                index))\n\n    @cmdutils.register(instance='command-dispatcher', scope='window')\n    @cmdutils.argument('index', choices=['+', '-'])\n    @cmdutils.argument('count', value=cmdutils.Value.count)\n    def tab_move(self, index: typing.Union[str, int] = None,\n                 count: int = None) -> None:\n        \"\"\"Move the current tab according to the argument and [count].\n\n        If neither is given, move it to the first position.\n\n        Args:\n            index: `+` or `-` to move relative to the current tab by\n                   count, or a default of 1 space.\n                   A tab index to move to that index.\n            count: If moving relatively: Offset.\n                   If moving absolutely: New position (default: 0). This\n                   overrides the index argument, if given.\n        \"\"\"\n        if index in ['+', '-']:\n            # relative moving\n            new_idx = self._current_index()\n            delta = 1 if count is None else count\n            if index == '-':\n                new_idx -= delta\n            elif index == '+':  # pragma: no branch\n                new_idx += delta\n\n            if config.val.tabs.wrap:\n                new_idx %= self._count()\n        else:\n            # absolute moving\n            if count is not None:\n                new_idx = count - 1\n            elif index is not None:\n                assert isinstance(index, int)\n                new_idx = index - 1 if index >= 0 else index + self._count()\n            else:\n                new_idx = 0\n\n        if not 0 <= new_idx < self._count():\n            raise cmdutils.CommandError(\"Can't move tab to position {}!\"\n                                        .format(new_idx + 1))\n\n        cur_idx = self._current_index()\n        cmdutils.check_overflow(cur_idx, 'int')\n        cmdutils.check_overflow(new_idx, 'int')\n        self._tabbed_browser.widget.tabBar().moveTab(cur_idx, new_idx)\n\n    @cmdutils.register(instance='command-dispatcher', scope='window',\n                       maxsplit=0, no_replace_variables=True)\n    @cmdutils.argument('count', value=cmdutils.Value.count)\n    @cmdutils.argument('output_messages', flag='m')\n    def spawn(self, cmdline, userscript=False, verbose=False,\n              output=False, output_messages=False, detach=False, count=None):\n        \"\"\"Spawn an external command.\n\n        Note that the command is *not* run in a shell, so things like `$VAR` or\n        `> output` won't have the desired effect.\n\n        Args:\n            userscript: Run the command as a userscript. You can use an\n                        absolute path, or store the userscript in one of those\n                        locations:\n                            - `~/.local/share/qutebrowser/userscripts`\n                              (or `$XDG_DATA_HOME`)\n                            - `/usr/share/qutebrowser/userscripts`\n            verbose: Show notifications when the command started/exited.\n            output: Show the output in a new tab.\n            output_messages: Show the output as messages.\n            detach: Whether the command should be detached from qutebrowser.\n            cmdline: The commandline to execute.\n            count: Given to userscripts as $QUTE_COUNT.\n        \"\"\"\n        cmdutils.check_exclusive((userscript, detach), 'ud')\n        try:\n            cmd, *args = shlex.split(cmdline)\n        except ValueError as e:\n            raise cmdutils.CommandError(\"Error while splitting command: \"\n                                        \"{}\".format(e))\n\n        args = runners.replace_variables(self._win_id, args)\n\n        log.procs.debug(\"Executing {} with args {}, userscript={}\".format(\n            cmd, args, userscript))\n\n        @pyqtSlot()\n        def _on_proc_finished():\n            if output:\n                tb = objreg.get('tabbed-browser', scope='window',\n                                window='last-focused')\n                tb.load_url(QUrl('qute://spawn-output'), newtab=True)\n\n        if userscript:\n            def _selection_callback(s):\n                try:\n                    runner = self._run_userscript(\n                        s, cmd, args, verbose, output_messages, count)\n                    runner.finished.connect(_on_proc_finished)\n                except cmdutils.CommandError as e:\n                    message.error(str(e))\n\n            # ~ expansion is handled by the userscript module.\n            # dirty hack for async call because of:\n            # https://bugreports.qt.io/browse/QTBUG-53134\n            # until it fixed or blocked async call implemented:\n            # https://github.com/qutebrowser/qutebrowser/issues/3327\n            caret = self._current_widget().caret\n            caret.selection(callback=_selection_callback)\n        else:\n            cmd = os.path.expanduser(cmd)\n            proc = guiprocess.GUIProcess(what='command', verbose=verbose,\n                                         output_messages=output_messages,\n                                         parent=self._tabbed_browser)\n            if detach:\n                ok = proc.start_detached(cmd, args)\n                if not ok:\n                    message.info(\"Hint: Try without --detach for a more \"\n                                 \"detailed error\")\n            else:\n                proc.start(cmd, args)\n            proc.finished.connect(_on_proc_finished)\n\n    def _run_userscript(self, selection, cmd, args, verbose, output_messages,\n                        count):\n        \"\"\"Run a userscript given as argument.\n\n        Args:\n            cmd: The userscript to run.\n            args: Arguments to pass to the userscript.\n            verbose: Show notifications when the command started/exited.\n            output_messages: Show the output as messages.\n            count: Exposed to the userscript.\n        \"\"\"\n        env = {\n            'QUTE_MODE': 'command',\n            'QUTE_SELECTED_TEXT': selection,\n        }\n\n        if count is not None:\n            env['QUTE_COUNT'] = str(count)\n\n        idx = self._current_index()\n        if idx != -1:\n            env['QUTE_TITLE'] = self._tabbed_browser.widget.page_title(idx)\n\n        # FIXME:qtwebengine: If tab is None, run_async will fail!\n        tab = self._tabbed_browser.widget.currentWidget()\n\n        try:\n            url = self._tabbed_browser.current_url()\n        except qtutils.QtValueError:\n            pass\n        else:\n            env['QUTE_URL'] = url.toString(QUrl.FullyEncoded)\n\n        try:\n            runner = userscripts.run_async(\n                tab, cmd, *args, win_id=self._win_id, env=env, verbose=verbose,\n                output_messages=output_messages)\n        except userscripts.Error as e:\n            raise cmdutils.CommandError(e)\n        return runner\n\n    @cmdutils.register(instance='command-dispatcher', scope='window')\n    def quickmark_save(self):\n        \"\"\"Save the current page as a quickmark.\"\"\"\n        quickmark_manager = objreg.get('quickmark-manager')\n        quickmark_manager.prompt_save(self._current_url())\n\n    @cmdutils.register(instance='command-dispatcher', scope='window',\n                       maxsplit=0)\n    @cmdutils.argument('name', completion=miscmodels.quickmark)\n    def quickmark_load(self, name, tab=False, bg=False, window=False):\n        \"\"\"Load a quickmark.\n\n        Args:\n            name: The name of the quickmark to load.\n            tab: Load the quickmark in a new tab.\n            bg: Load the quickmark in a new background tab.\n            window: Load the quickmark in a new window.\n        \"\"\"\n        try:\n            url = objreg.get('quickmark-manager').get(name)\n        except urlmarks.Error as e:\n            raise cmdutils.CommandError(str(e))\n        self._open(url, tab, bg, window)\n\n    @cmdutils.register(instance='command-dispatcher', scope='window',\n                       maxsplit=0)\n    @cmdutils.argument('name', completion=miscmodels.quickmark)\n    def quickmark_del(self, name=None):\n        \"\"\"Delete a quickmark.\n\n        Args:\n            name: The name of the quickmark to delete. If not given, delete the\n                  quickmark for the current page (choosing one arbitrarily\n                  if there are more than one).\n        \"\"\"\n        quickmark_manager = objreg.get('quickmark-manager')\n        if name is None:\n            url = self._current_url()\n            try:\n                name = quickmark_manager.get_by_qurl(url)\n            except urlmarks.DoesNotExistError as e:\n                raise cmdutils.CommandError(str(e))\n        try:\n            quickmark_manager.delete(name)\n        except KeyError:\n            raise cmdutils.CommandError(\"Quickmark '{}' not found!\"\n                                        .format(name))\n\n    @cmdutils.register(instance='command-dispatcher', scope='window')\n    def bookmark_add(self, url=None, title=None, toggle=False):\n        \"\"\"Save the current page as a bookmark, or a specific url.\n\n        If no url and title are provided, then save the current page as a\n        bookmark.\n        If a url and title have been provided, then save the given url as\n        a bookmark with the provided title.\n\n        You can view all saved bookmarks on the\n        link:qute://bookmarks[bookmarks page].\n\n        Args:\n            url: url to save as a bookmark. If not given, use url of current\n                 page.\n            title: title of the new bookmark.\n            toggle: remove the bookmark instead of raising an error if it\n                    already exists.\n        \"\"\"\n        if url and not title:\n            raise cmdutils.CommandError('Title must be provided if url has '\n                                        'been provided')\n        bookmark_manager = objreg.get('bookmark-manager')\n        if not url:\n            url = self._current_url()\n        else:\n            try:\n                url = urlutils.fuzzy_url(url)\n            except urlutils.InvalidUrlError as e:\n                raise cmdutils.CommandError(e)\n        if not title:\n            title = self._current_title()\n        try:\n            was_added = bookmark_manager.add(url, title, toggle=toggle)\n        except urlmarks.Error as e:\n            raise cmdutils.CommandError(str(e))\n        else:\n            msg = \"Bookmarked {}\" if was_added else \"Removed bookmark {}\"\n            message.info(msg.format(url.toDisplayString()))\n\n    @cmdutils.register(instance='command-dispatcher', scope='window',\n                       maxsplit=0)\n    @cmdutils.argument('url', completion=miscmodels.bookmark)\n    def bookmark_load(self, url, tab=False, bg=False, window=False,\n                      delete=False):\n        \"\"\"Load a bookmark.\n\n        Args:\n            url: The url of the bookmark to load.\n            tab: Load the bookmark in a new tab.\n            bg: Load the bookmark in a new background tab.\n            window: Load the bookmark in a new window.\n            delete: Whether to delete the bookmark afterwards.\n        \"\"\"\n        try:\n            qurl = urlutils.fuzzy_url(url)\n        except urlutils.InvalidUrlError as e:\n            raise cmdutils.CommandError(e)\n        self._open(qurl, tab, bg, window)\n        if delete:\n            self.bookmark_del(url)\n\n    @cmdutils.register(instance='command-dispatcher', scope='window',\n                       maxsplit=0)\n    @cmdutils.argument('url', completion=miscmodels.bookmark)\n    def bookmark_del(self, url=None):\n        \"\"\"Delete a bookmark.\n\n        Args:\n            url: The url of the bookmark to delete. If not given, use the\n                 current page's url.\n        \"\"\"\n        if url is None:\n            url = self._current_url().toString(QUrl.RemovePassword |\n                                               QUrl.FullyEncoded)\n        try:\n            objreg.get('bookmark-manager').delete(url)\n        except KeyError:\n            raise cmdutils.CommandError(\"Bookmark '{}' not found!\".format(url))\n        message.info(\"Removed bookmark {}\".format(url))\n\n    @cmdutils.register(instance='command-dispatcher', scope='window')\n    def download(self, url=None, *, mhtml_=False, dest=None):\n        \"\"\"Download a given URL, or current page if no URL given.\n\n        Args:\n            url: The URL to download. If not given, download the current page.\n            dest: The file path to write the download to, or None to ask.\n            mhtml_: Download the current page and all assets as mhtml file.\n        \"\"\"\n        # FIXME:qtwebengine do this with the QtWebEngine download manager?\n        download_manager = objreg.get('qtnetwork-download-manager')\n        target = None\n        if dest is not None:\n            dest = downloads.transform_path(dest)\n            if dest is None:\n                raise cmdutils.CommandError(\"Invalid target filename\")\n            target = downloads.FileDownloadTarget(dest)\n\n        tab = self._current_widget()\n\n        if url:\n            if mhtml_:\n                raise cmdutils.CommandError(\"Can only download the current \"\n                                            \"page as mhtml.\")\n            url = urlutils.qurl_from_user_input(url)\n            urlutils.raise_cmdexc_if_invalid(url)\n            download_manager.get(url, target=target)\n        elif mhtml_:\n            tab = self._current_widget()\n            if tab.backend == usertypes.Backend.QtWebEngine:\n                webengine_download_manager = objreg.get(\n                    'webengine-download-manager')\n                try:\n                    webengine_download_manager.get_mhtml(tab, target)\n                except browsertab.UnsupportedOperationError as e:\n                    raise cmdutils.CommandError(e)\n            else:\n                download_manager.get_mhtml(tab, target)\n        else:\n            qnam = tab.private_api.networkaccessmanager()\n\n            suggested_fn = downloads.suggested_fn_from_title(\n                self._current_url().path(), tab.title()\n            )\n\n            download_manager.get(\n                self._current_url(),\n                qnam=qnam,\n                target=target,\n                suggested_fn=suggested_fn\n            )\n\n    @cmdutils.register(instance='command-dispatcher', scope='window')\n    def view_source(self, edit=False, pygments=False):\n        \"\"\"Show the source of the current page in a new tab.\n\n        Args:\n            edit: Edit the source in the editor instead of opening a tab.\n            pygments: Use pygments to generate the view. This is always\n                      the case for QtWebKit. For QtWebEngine it may display\n                      slightly different source.\n                      Some JavaScript processing may be applied.\n        \"\"\"\n        tab = self._current_widget()\n        try:\n            current_url = self._current_url()\n        except cmdutils.CommandError as e:\n            message.error(str(e))\n            return\n\n        if current_url.scheme() == 'view-source' or tab.data.viewing_source:\n            raise cmdutils.CommandError(\"Already viewing source!\")\n\n        if edit:\n            ed = editor.ExternalEditor(self._tabbed_browser)\n            tab.dump_async(ed.edit)\n        else:\n            tab.action.show_source(pygments)\n\n    @cmdutils.register(instance='command-dispatcher', scope='window')\n    def history(self, tab=True, bg=False, window=False):\n        \"\"\"Show browsing history.\n\n        Args:\n            tab: Open in a new tab.\n            bg: Open in a background tab.\n            window: Open in a new window.\n        \"\"\"\n        url = QUrl('qute://history/')\n        self._open(url, tab, bg, window)\n\n    @cmdutils.register(instance='command-dispatcher', name='help',\n                       scope='window')\n    @cmdutils.argument('topic', completion=miscmodels.helptopic)\n    def show_help(self, tab=False, bg=False, window=False, topic=None):\n        r\"\"\"Show help about a command or setting.\n\n        Args:\n            tab: Open in a new tab.\n            bg: Open in a background tab.\n            window: Open in a new window.\n            topic: The topic to show help for.\n\n                   - :__command__ for commands.\n                   - __section__.__option__ for settings.\n        \"\"\"\n        if topic is None:\n            path = 'index.html'\n        elif topic.startswith(':'):\n            command = topic[1:]\n            if command not in objects.commands:\n                raise cmdutils.CommandError(\"Invalid command {}!\".format(\n                    command))\n\n            deprecated = objects.commands[command].deprecated\n            if deprecated:\n                raise cmdutils.CommandError(\n                    \"{} is deprecated - {}\".format(command, deprecated))\n\n            path = 'commands.html#{}'.format(command)\n        elif topic in configdata.DATA:\n            path = 'settings.html#{}'.format(topic)\n        else:\n            raise cmdutils.CommandError(\"Invalid help topic {}!\".format(topic))\n        url = QUrl('qute://help/{}'.format(path))\n        self._open(url, tab, bg, window)\n\n    @cmdutils.register(instance='command-dispatcher', scope='window')\n    @cmdutils.argument('logfilter', flag='f')\n    def messages(self, level='info', *, plain=False, tab=False, bg=False,\n                 window=False, logfilter=None):\n        \"\"\"Show a log of past messages.\n\n        Args:\n            level: Include messages with `level` or higher severity.\n                   Valid values: vdebug, debug, info, warning, error, critical.\n            plain: Whether to show plaintext (as opposed to html).\n            logfilter: A comma-separated filter string of logging categories.\n                       If the filter string starts with an exclamation mark, it\n                       is negated.\n            tab: Open in a new tab.\n            bg: Open in a background tab.\n            window: Open in a new window.\n        \"\"\"\n        if level.upper() not in log.LOG_LEVELS:\n            raise cmdutils.CommandError(\"Invalid log level {}!\".format(level))\n\n        query = QUrlQuery()\n        query.addQueryItem('level', level)\n        if plain:\n            query.addQueryItem('plain', typing.cast(str, None))\n\n        if logfilter:\n            try:\n                log.LogFilter.parse(logfilter)\n            except log.InvalidLogFilterError as e:\n                raise cmdutils.CommandError(e)\n            query.addQueryItem('logfilter', logfilter)\n\n        url = QUrl('qute://log')\n        url.setQuery(query)\n\n        self._open(url, tab, bg, window)\n\n    def _open_editor_cb(self, elem):\n        \"\"\"Open editor after the focus elem was found in open_editor.\"\"\"\n        if elem is None:\n            message.error(\"No element focused!\")\n            return\n        if not elem.is_editable(strict=True):\n            message.error(\"Focused element is not editable!\")\n            return\n\n        text = elem.value()\n        if text is None:\n            message.error(\"Could not get text from the focused element.\")\n            return\n        assert isinstance(text, str), text\n\n        caret_position = elem.caret_position()\n\n        ed = editor.ExternalEditor(watch=True, parent=self._tabbed_browser)\n        ed.file_updated.connect(functools.partial(\n            self.on_file_updated, ed, elem))\n        ed.editing_finished.connect(lambda: mainwindow.raise_window(\n            objreg.last_focused_window(), alert=False))\n        ed.edit(text, caret_position)\n\n    @cmdutils.register(instance='command-dispatcher', scope='window')\n    def open_editor(self):\n        \"\"\"Open an external editor with the currently selected form field.\n\n        The editor which should be launched can be configured via the\n        `editor.command` config option.\n        \"\"\"\n        tab = self._current_widget()\n        tab.elements.find_focused(self._open_editor_cb)\n\n    def on_file_updated(self, ed, elem, text):\n        \"\"\"Write the editor text into the form field and clean up tempfile.\n\n        Callback for GUIProcess when the edited text was updated.\n\n        Args:\n            elem: The WebElementWrapper which was modified.\n            text: The new text to insert.\n        \"\"\"\n        try:\n            elem.set_value(text)\n            # Kick off js handlers to trick them into thinking there was input.\n            elem.dispatch_event(\"input\", bubbles=True)\n        except webelem.OrphanedError:\n            message.error('Edited element vanished')\n            ed.backup()\n        except webelem.Error as e:\n            message.error(str(e))\n            ed.backup()\n\n    def _search_cb(self, found, *, tab, old_scroll_pos, options, text, prev):\n        \"\"\"Callback called from search/search_next/search_prev.\n\n        Args:\n            found: Whether the text was found.\n            tab: The AbstractTab in which the search was made.\n            old_scroll_pos: The scroll position (QPoint) before the search.\n            options: The options (dict) the search was made with.\n            text: The text searched for.\n            prev: Whether we're searching backwards (i.e. :search-prev)\n        \"\"\"\n        # :search/:search-next without reverse -> down\n        # :search/:search-next    with reverse -> up\n        # :search-prev         without reverse -> up\n        # :search-prev            with reverse -> down\n        going_up = options['reverse'] ^ prev\n\n        if found:\n            # Check if the scroll position got smaller and show info.\n            if not going_up and tab.scroller.pos_px().y() < old_scroll_pos.y():\n                message.info(\"Search hit BOTTOM, continuing at TOP\")\n            elif going_up and tab.scroller.pos_px().y() > old_scroll_pos.y():\n                message.info(\"Search hit TOP, continuing at BOTTOM\")\n        else:\n            message.warning(\"Text '{}' not found on page!\".format(text),\n                            replace=True)\n\n    @cmdutils.register(instance='command-dispatcher', scope='window',\n                       maxsplit=0)\n    def search(self, text=\"\", reverse=False):\n        \"\"\"Search for a text on the current page. With no text, clear results.\n\n        Args:\n            text: The text to search for.\n            reverse: Reverse search direction.\n        \"\"\"\n        tab = self._current_widget()\n\n        if not text:\n            if tab.search.search_displayed:\n                tab.search.clear()\n            return\n\n        options = {\n            'ignore_case': config.val.search.ignore_case,\n            'reverse': reverse,\n            'wrap': config.val.search.wrap,\n        }\n\n        self._tabbed_browser.search_text = text\n        self._tabbed_browser.search_options = dict(options)\n\n        cb = functools.partial(self._search_cb, tab=tab,\n                               old_scroll_pos=tab.scroller.pos_px(),\n                               options=options, text=text, prev=False)\n        options['result_cb'] = cb\n\n        tab.scroller.before_jump_requested.emit()\n        tab.search.search(text, **options)\n\n    @cmdutils.register(instance='command-dispatcher', scope='window')\n    @cmdutils.argument('count', value=cmdutils.Value.count)\n    def search_next(self, count=1):\n        \"\"\"Continue the search to the ([count]th) next term.\n\n        Args:\n            count: How many elements to ignore.\n        \"\"\"\n        tab = self._current_widget()\n        window_text = self._tabbed_browser.search_text\n        window_options = self._tabbed_browser.search_options\n\n        if window_text is None:\n            raise cmdutils.CommandError(\"No search done yet.\")\n\n        tab.scroller.before_jump_requested.emit()\n\n        if window_text is not None and window_text != tab.search.text:\n            tab.search.clear()\n            tab.search.search(window_text, **window_options)\n            count -= 1\n\n        if count == 0:\n            return\n\n        cb = functools.partial(self._search_cb, tab=tab,\n                               old_scroll_pos=tab.scroller.pos_px(),\n                               options=window_options, text=window_text,\n                               prev=False)\n\n        for _ in range(count - 1):\n            tab.search.next_result()\n        tab.search.next_result(result_cb=cb)\n\n    @cmdutils.register(instance='command-dispatcher', scope='window')\n    @cmdutils.argument('count', value=cmdutils.Value.count)\n    def search_prev(self, count=1):\n        \"\"\"Continue the search to the ([count]th) previous term.\n\n        Args:\n            count: How many elements to ignore.\n        \"\"\"\n        tab = self._current_widget()\n        window_text = self._tabbed_browser.search_text\n        window_options = self._tabbed_browser.search_options\n\n        if window_text is None:\n            raise cmdutils.CommandError(\"No search done yet.\")\n\n        tab.scroller.before_jump_requested.emit()\n\n        if window_text is not None and window_text != tab.search.text:\n            tab.search.clear()\n            tab.search.search(window_text, **window_options)\n            count -= 1\n\n        if count == 0:\n            return\n\n        cb = functools.partial(self._search_cb, tab=tab,\n                               old_scroll_pos=tab.scroller.pos_px(),\n                               options=window_options, text=window_text,\n                               prev=True)\n\n        for _ in range(count - 1):\n            tab.search.prev_result()\n        tab.search.prev_result(result_cb=cb)\n\n    @cmdutils.register(instance='command-dispatcher', scope='window',\n                       maxsplit=0, no_cmd_split=True)\n    def jseval(self, js_code: str, file: bool = False, quiet: bool = False, *,\n               world: typing.Union[usertypes.JsWorld, int] = None) -> None:\n        \"\"\"Evaluate a JavaScript string.\n\n        Args:\n            js_code: The string/file to evaluate.\n            file: Interpret js-code as a path to a file.\n                  If the path is relative, the file is searched in a js/ subdir\n                  in qutebrowser's data dir, e.g.\n                  `~/.local/share/qutebrowser/js`.\n            quiet: Don't show resulting JS object.\n            world: Ignored on QtWebKit. On QtWebEngine, a world ID or name to\n                   run the snippet in.\n        \"\"\"\n        if world is None:\n            world = usertypes.JsWorld.jseval\n\n        if quiet:\n            jseval_cb = None\n        else:\n            def jseval_cb(out):\n                \"\"\"Show the data returned from JS.\"\"\"\n                if out is None:\n                    # Getting the actual error (if any) seems to be difficult.\n                    # The error does end up in\n                    # BrowserPage.javaScriptConsoleMessage(), but\n                    # distinguishing between :jseval errors and errors from the\n                    # webpage is not trivial...\n                    message.info('No output or error')\n                else:\n                    # The output can be a string, number, dict, array, etc. But\n                    # *don't* output too much data, as this will make\n                    # qutebrowser hang\n                    out = str(out)\n                    if len(out) > 5000:\n                        out = out[:5000] + ' [...trimmed...]'\n                    message.info(out)\n\n        if file:\n            path = os.path.expanduser(js_code)\n            if not os.path.isabs(path):\n                path = os.path.join(standarddir.data(), 'js', path)\n\n            try:\n                with open(path, 'r', encoding='utf-8') as f:\n                    js_code = f.read()\n            except OSError as e:\n                raise cmdutils.CommandError(str(e))\n\n        widget = self._current_widget()\n        try:\n            widget.run_js_async(js_code, callback=jseval_cb, world=world)\n        except browsertab.WebTabError as e:\n            raise cmdutils.CommandError(str(e))\n\n    @cmdutils.register(instance='command-dispatcher', scope='window')\n    def fake_key(self, keystring, global_=False):\n        \"\"\"Send a fake keypress or key string to the website or qutebrowser.\n\n        :fake-key xy - sends the keychain 'xy'\n        :fake-key <Ctrl-x> - sends Ctrl-x\n        :fake-key <Escape> - sends the escape key\n\n        Args:\n            keystring: The keystring to send.\n            global_: If given, the keys are sent to the qutebrowser UI.\n        \"\"\"\n        try:\n            sequence = keyutils.KeySequence.parse(keystring)\n        except keyutils.KeyParseError as e:\n            raise cmdutils.CommandError(str(e))\n\n        for keyinfo in sequence:\n            press_event = keyinfo.to_event(QEvent.KeyPress)\n            release_event = keyinfo.to_event(QEvent.KeyRelease)\n\n            if global_:\n                window = QApplication.focusWindow()\n                if window is None:\n                    raise cmdutils.CommandError(\"No focused window!\")\n                QApplication.postEvent(window, press_event)\n                QApplication.postEvent(window, release_event)\n            else:\n                tab = self._current_widget()\n                tab.send_event(press_event)\n                tab.send_event(release_event)\n\n    @cmdutils.register(instance='command-dispatcher', scope='window',\n                       debug=True, backend=usertypes.Backend.QtWebKit)\n    def debug_clear_ssl_errors(self):\n        \"\"\"Clear remembered SSL error answers.\"\"\"\n        self._current_widget().private_api.clear_ssl_errors()\n\n    @cmdutils.register(instance='command-dispatcher', scope='window')\n    def edit_url(self, url=None, bg=False, tab=False, window=False,\n                 private=False, related=False):\n        \"\"\"Navigate to a url formed in an external editor.\n\n        The editor which should be launched can be configured via the\n        `editor.command` config option.\n\n        Args:\n            url: URL to edit; defaults to the current page url.\n            bg: Open in a new background tab.\n            tab: Open in a new tab.\n            window: Open in a new window.\n            private: Open a new window in private browsing mode.\n            related: If opening a new tab, position the tab as related to the\n                     current one (like clicking on a link).\n        \"\"\"\n        cmdutils.check_exclusive((tab, bg, window), 'tbw')\n\n        old_url = self._current_url().toString()\n\n        ed = editor.ExternalEditor(self._tabbed_browser)\n\n        # Passthrough for openurl args (e.g. -t, -b, -w)\n        ed.file_updated.connect(functools.partial(\n            self._open_if_changed, old_url=old_url, bg=bg, tab=tab,\n            window=window, private=private, related=related))\n\n        ed.edit(url or old_url)\n\n    @cmdutils.register(instance='command-dispatcher', scope='window')\n    def set_mark(self, key):\n        \"\"\"Set a mark at the current scroll position in the current tab.\n\n        Args:\n            key: mark identifier; capital indicates a global mark\n        \"\"\"\n        self._tabbed_browser.set_mark(key)\n\n    @cmdutils.register(instance='command-dispatcher', scope='window')\n    def jump_mark(self, key):\n        \"\"\"Jump to the mark named by `key`.\n\n        Args:\n            key: mark identifier; capital indicates a global mark\n        \"\"\"\n        self._tabbed_browser.jump_mark(key)\n\n    def _open_if_changed(self, url=None, old_url=None, bg=False, tab=False,\n                         window=False, private=False, related=False):\n        \"\"\"Open a URL unless it's already open in the tab.\n\n        Args:\n            old_url: The original URL to compare against.\n            url: The URL to open.\n            bg: Open in a new background tab.\n            tab: Open in a new tab.\n            window: Open in a new window.\n            private: Open a new window in private browsing mode.\n            related: If opening a new tab, position the tab as related to the\n                     current one (like clicking on a link).\n        \"\"\"\n        if bg or tab or window or private or related or url != old_url:\n            self.openurl(url=url, bg=bg, tab=tab, window=window,\n                         private=private, related=related)\n\n    @cmdutils.register(instance='command-dispatcher', scope='window')\n    def fullscreen(self, leave=False, enter=False):\n        \"\"\"Toggle fullscreen mode.\n\n        Args:\n            leave: Only leave fullscreen if it was entered by the page.\n            enter: Activate fullscreen and do not toggle if it is already\n                   active.\n        \"\"\"\n        if leave:\n            tab = self._current_widget()\n            try:\n                tab.action.exit_fullscreen()\n            except browsertab.UnsupportedOperationError:\n                pass\n            return\n\n        window = self._tabbed_browser.widget.window()\n\n        if not window.isFullScreen():\n            window.state_before_fullscreen = window.windowState()\n        if enter:\n            window.setWindowState(window.windowState() | Qt.WindowFullScreen)\n        else:\n            window.setWindowState(window.windowState() ^ Qt.WindowFullScreen)\n\n        log.misc.debug('state before fullscreen: {}'.format(\n            debug.qflags_key(Qt, window.state_before_fullscreen)))\n", "idx": 1, "id": 23640, "msg": "I think it'd be a nice default behavior (and make things much more discoverable) to reopen a window if that's what was closed last, and reopen a tab otherwise. Not sure how much effort that'd be code-wise though.", "proj": "qutebrowser-qutebrowser", "lang": "py"}
{"patch": "@@ -42,6 +42,14 @@ RETRY_INTERVAL = 600 # 10 min\n #: The download block size in bytes.\n DOWNLOAD_BLOCK_SIZE = 8192 # 8 kb\n \n+#: directory to store pending update files\n+storeUpdatesDir=os.path.join(globalVars.appArgs.configPath, 'updates')\n+try:\n+\tos.makedirs(storeUpdatesDir)\n+except OSError:\n+\tif not os.path.isdir(storeUpdatesDir):\n+\t\tlog.debugWarning(\"Default download path for updates %s could not be created.\"%storeUpdatesDir)\n+\t\t\n #: Persistent state information.\n #: @type: dict\n state = None", "y": 0, "oldf": "#updateCheck.py\r\n#A part of NonVisual Desktop Access (NVDA)\r\n#This file is covered by the GNU General Public License.\r\n#See the file COPYING for more details.\r\n#Copyright (C) 2012-2015 NV Access Limited\r\n\r\n\"\"\"Update checking functionality.\r\n@note: This module may raise C{RuntimeError} on import if update checking for this build is not supported.\r\n\"\"\"\r\n\r\nimport globalVars\r\nif globalVars.appArgs.secure:\r\n\traise RuntimeError(\"updates disabled in secure mode\")\r\nimport versionInfo\r\nif not versionInfo.updateVersionType:\r\n\traise RuntimeError(\"No update version type, update checking not supported\")\r\n\r\nimport winVersion\r\nimport os\r\nimport threading\r\nimport time\r\nimport cPickle\r\nimport urllib\r\nimport tempfile\r\nimport hashlib\r\nimport ctypes.wintypes\r\nimport ssl\r\nimport wx\r\nimport languageHandler\r\nimport gui\r\nfrom logHandler import log\r\nimport config\r\nimport shellapi\r\nimport winUser\r\n\r\n#: The URL to use for update checks.\r\nCHECK_URL = \"https://www.nvaccess.org/nvdaUpdateCheck\"\r\n#: The time to wait between checks.\r\nCHECK_INTERVAL = 86400 # 1 day\r\n#: The time to wait before retrying a failed check.\r\nRETRY_INTERVAL = 600 # 10 min\r\n#: The download block size in bytes.\r\nDOWNLOAD_BLOCK_SIZE = 8192 # 8 kb\r\n\r\n#: Persistent state information.\r\n#: @type: dict\r\nstate = None\r\n_stateFileName = None\r\n#: The single instance of L{AutoUpdateChecker} if automatic update checking is enabled,\r\n#: C{None} if it is disabled.\r\nautoChecker = None\r\n\r\ndef checkForUpdate(auto=False):\r\n\t\"\"\"Check for an updated version of NVDA.\r\n\tThis will block, so it generally shouldn't be called from the main thread.\r\n\t@param auto: Whether this is an automatic check for updates.\r\n\t@type auto: bool\r\n\t@return: Information about the update or C{None} if there is no update.\r\n\t@rtype: dict\r\n\t@raise RuntimeError: If there is an error checking for an update.\r\n\t\"\"\"\r\n\tparams = {\r\n\t\t\"autoCheck\": auto,\r\n\t\t\"version\": versionInfo.version,\r\n\t\t\"versionType\": versionInfo.updateVersionType,\r\n\t\t\"osVersion\": winVersion.winVersionText,\r\n\t\t\"x64\": os.environ.get(\"PROCESSOR_ARCHITEW6432\") == \"AMD64\",\r\n\t\t\"language\": languageHandler.getLanguage(),\r\n\t\t\"installed\": config.isInstalledCopy(),\r\n\t}\r\n\turl = \"%s?%s\" % (CHECK_URL, urllib.urlencode(params))\r\n\ttry:\r\n\t\tres = urllib.urlopen(url)\r\n\texcept IOError as e:\r\n\t\tif isinstance(e.strerror, ssl.SSLError) and e.strerror.reason == \"CERTIFICATE_VERIFY_FAILED\":\r\n\t\t\t# #4803: Windows fetches trusted root certificates on demand.\r\n\t\t\t# Python doesn't trigger this fetch (PythonIssue:20916), so try it ourselves\r\n\t\t\t_updateWindowsRootCertificates()\r\n\t\t\t# and then retry the update check.\r\n\t\t\tres = urllib.urlopen(url)\r\n\t\telse:\r\n\t\t\traise\r\n\tif res.code != 200:\r\n\t\traise RuntimeError(\"Checking for update failed with code %d\" % res.code)\r\n\tinfo = {}\r\n\tfor line in res:\r\n\t\tline = line.rstrip()\r\n\t\ttry:\r\n\t\t\tkey, val = line.split(\": \", 1)\r\n\t\texcept ValueError:\r\n\t\t\traise RuntimeError(\"Error in update check output\")\r\n\t\tinfo[key] = val\r\n\tif not info:\r\n\t\treturn None\r\n\treturn info\r\n\r\nclass UpdateChecker(object):\r\n\t\"\"\"Check for an updated version of NVDA, presenting appropriate user interface.\r\n\tThe check is performed in the background.\r\n\tThis class is for manual update checks.\r\n\tTo use, call L{check} on an instance.\r\n\t\"\"\"\r\n\tAUTO = False\r\n\r\n\tdef check(self):\r\n\t\t\"\"\"Check for an update.\r\n\t\t\"\"\"\r\n\t\tt = threading.Thread(target=self._bg)\r\n\t\tt.daemon = True\r\n\t\tself._started()\r\n\t\tt.start()\r\n\r\n\tdef _bg(self):\r\n\t\ttry:\r\n\t\t\tinfo = checkForUpdate(self.AUTO)\r\n\t\texcept:\r\n\t\t\tlog.debugWarning(\"Error checking for update\", exc_info=True)\r\n\t\t\tself._error()\r\n\t\t\treturn\r\n\t\tself._result(info)\r\n\t\tif info:\r\n\t\t\tstate[\"dontRemindVersion\"] = info[\"version\"]\r\n\t\tstate[\"lastCheck\"] = time.time()\r\n\t\tsaveState()\r\n\t\tif autoChecker:\r\n\t\t\tautoChecker.setNextCheck()\r\n\r\n\tdef _started(self):\r\n\t\tself._progressDialog = gui.IndeterminateProgressDialog(gui.mainFrame,\r\n\t\t\t# Translators: The title of the dialog displayed while manually checking for an NVDA update.\r\n\t\t\t_(\"Checking for Update\"),\r\n\t\t\t# Translators: The progress message displayed while manually checking for an NVDA update.\r\n\t\t\t_(\"Checking for update\"))\r\n\r\n\tdef _error(self):\r\n\t\twx.CallAfter(self._progressDialog.done)\r\n\t\tself._progressDialog = None\r\n\t\twx.CallAfter(gui.messageBox,\r\n\t\t\t# Translators: A message indicating that an error occurred while checking for an update to NVDA.\r\n\t\t\t_(\"Error checking for update.\"),\r\n\t\t\t# Translators: The title of an error message dialog.\r\n\t\t\t_(\"Error\"),\r\n\t\t\twx.OK | wx.ICON_ERROR)\r\n\r\n\tdef _result(self, info):\r\n\t\twx.CallAfter(self._progressDialog.done)\r\n\t\tself._progressDialog = None\r\n\t\twx.CallAfter(UpdateResultDialog, gui.mainFrame, info, False)\r\n\r\nclass AutoUpdateChecker(UpdateChecker):\r\n\t\"\"\"Automatically check for an updated version of NVDA.\r\n\tTo use, create a single instance and maintain a reference to it.\r\n\tChecks will then be performed automatically.\r\n\t\"\"\"\r\n\tAUTO = True\r\n\r\n\tdef __init__(self):\r\n\t\tself._checkTimer = wx.PyTimer(self.check)\r\n\t\t# Set the initial check based on the last check time.\r\n\t\t# #3260: If the system time is earlier than the last check,\r\n\t\t# treat the last check as being right now (so the next will be tomorrow).\r\n\t\tsecsSinceLast = max(time.time() - state[\"lastCheck\"], 0)\r\n\t\t# The maximum time till the next check is CHECK_INTERVAL.\r\n\t\tsecsTillNext = CHECK_INTERVAL - int(min(secsSinceLast, CHECK_INTERVAL))\r\n\t\tself._checkTimer.Start(secsTillNext * 1000, True)\r\n\r\n\tdef terminate(self):\r\n\t\tself._checkTimer.Stop()\r\n\t\tself._checkTimer = None\r\n\r\n\tdef setNextCheck(self, isRetry=False):\r\n\t\tself._checkTimer.Stop()\r\n\t\tself._checkTimer.Start((RETRY_INTERVAL if isRetry else CHECK_INTERVAL) * 1000, True)\r\n\r\n\tdef _started(self):\r\n\t\tlog.info(\"Performing automatic update check\")\r\n\r\n\tdef _error(self):\r\n\t\tself.setNextCheck(isRetry=True)\r\n\r\n\tdef _result(self, info):\r\n\t\tif not info:\r\n\t\t\treturn\r\n\t\tif info[\"version\"] == state[\"dontRemindVersion\"]:\r\n\t\t\treturn\r\n\t\twx.CallAfter(UpdateResultDialog, gui.mainFrame, info, True)\r\n\r\nclass UpdateResultDialog(wx.Dialog):\r\n\r\n\tdef __init__(self, parent, updateInfo, auto):\r\n\t\t# Translators: The title of the dialog informing the user about an NVDA update.\r\n\t\tsuper(UpdateResultDialog, self).__init__(parent, title=_(\"NVDA Update\"))\r\n\t\tself.updateInfo = updateInfo\r\n\t\tmainSizer = wx.BoxSizer(wx.VERTICAL)\r\n\r\n\t\tif updateInfo:\r\n\t\t\tself.isInstalled = config.isInstalledCopy()\r\n\t\t\tself.urls = updateInfo[\"launcherUrl\"].split(\" \")\r\n\t\t\tself.fileHash = updateInfo.get(\"launcherHash\")\r\n\t\t\t# Translators: A message indicating that an updated version of NVDA is available.\r\n\t\t\t# {version} will be replaced with the version; e.g. 2011.3.\r\n\t\t\tmessage = _(\"NVDA version {version} is available.\").format(**updateInfo)\r\n\t\telse:\r\n\t\t\t# Translators: A message indicating that no update to NVDA is available.\r\n\t\t\tmessage = _(\"No update available.\")\r\n\t\tmainSizer.Add(wx.StaticText(self, label=message))\r\n\r\n\t\tif updateInfo:\r\n\t\t\tif self.isInstalled:\r\n\t\t\t\t# Translators: The label of a button to download and install an NVDA update.\r\n\t\t\t\tlabel = _(\"Download and &install update\")\r\n\t\t\telse:\r\n\t\t\t\t# Translators: The label of a button to download an NVDA update.\r\n\t\t\t\tlabel = _(\"&Download update\")\r\n\t\t\titem = wx.Button(self, label=label)\r\n\t\t\titem.Bind(wx.EVT_BUTTON, self.onDownloadButton)\r\n\r\n\t\t\tmainSizer.Add(item)\r\n\r\n\t\t\tif auto:\r\n\t\t\t\t# Translators: The label of a button to remind the user later about performing some action.\r\n\t\t\t\titem = wx.Button(self, label=_(\"Remind me &later\"))\r\n\t\t\t\titem.Bind(wx.EVT_BUTTON, self.onLaterButton)\r\n\t\t\t\tmainSizer.Add(item)\r\n\t\t\t\titem.SetFocus()\r\n\r\n\t\t# Translators: The label of a button to close a dialog.\r\n\t\titem = wx.Button(self, wx.ID_CLOSE, label=_(\"&Close\"))\r\n\t\titem.Bind(wx.EVT_BUTTON, lambda evt: self.Close())\r\n\t\tmainSizer.Add(item)\r\n\t\tself.Bind(wx.EVT_CLOSE, lambda evt: self.Destroy())\r\n\t\tself.EscapeId = wx.ID_CLOSE\r\n\r\n\t\tself.Sizer = mainSizer\r\n\t\tmainSizer.Fit(self)\r\n\t\tself.Center(wx.BOTH | wx.CENTER_ON_SCREEN)\r\n\t\tself.Show()\r\n\r\n\tdef onDownloadButton(self, evt):\r\n\t\tself.Hide()\r\n\t\tDonateRequestDialog(gui.mainFrame, self._download)\r\n\r\n\tdef _download(self):\r\n\t\tif self.isInstalled:\r\n\t\t\tUpdateDownloader(self.urls, fileHash=self.fileHash).start()\r\n\t\telse:\r\n\t\t\tos.startfile(self.urls[0])\r\n\t\tself.Destroy()\r\n\r\n\tdef onLaterButton(self, evt):\r\n\t\tstate[\"dontRemindVersion\"] = None\r\n\t\tsaveState()\r\n\t\tself.Close()\r\n\r\nclass UpdateDownloader(object):\r\n\t\"\"\"Download and start installation of an updated version of NVDA, presenting appropriate user interface.\r\n\tTo use, call L{start} on an instance.\r\n\t\"\"\"\r\n\r\n\tdef __init__(self, urls, fileHash=None):\r\n\t\t\"\"\"Constructor.\r\n\t\t@param urls: URLs to try for the update file.\r\n\t\t@type urls: list of str\r\n\t\t@param fileHash: The SHA-1 hash of the file as a hex string.\r\n\t\t@type fileHash: basestring\r\n\t\t\"\"\"\r\n\t\tself.urls = urls\r\n\t\tself.destPath = tempfile.mktemp(prefix=\"nvda_update_\", suffix=\".exe\")\r\n\t\tself.fileHash = fileHash\r\n\r\n\tdef start(self):\r\n\t\t\"\"\"Start the download.\r\n\t\t\"\"\"\r\n\t\tself._shouldCancel = False\r\n\t\t# Use a timer because timers aren't re-entrant.\r\n\t\tself._guiExecTimer = wx.PyTimer(self._guiExecNotify)\r\n\t\tgui.mainFrame.prePopup()\r\n\t\t# Translators: The title of the dialog displayed while downloading an NVDA update.\r\n\t\tself._progressDialog = wx.ProgressDialog(_(\"Downloading Update\"),\r\n\t\t\t# Translators: The progress message indicating that a connection is being established.\r\n\t\t\t_(\"Connecting\"),\r\n\t\t\t# PD_AUTO_HIDE is required because ProgressDialog.Update blocks at 100%\r\n\t\t\t# and waits for the user to press the Close button.\r\n\t\t\tstyle=wx.PD_CAN_ABORT | wx.PD_ELAPSED_TIME | wx.PD_REMAINING_TIME | wx.PD_AUTO_HIDE,\r\n\t\t\tparent=gui.mainFrame)\r\n\t\tself._progressDialog.Raise()\r\n\t\tt = threading.Thread(target=self._bg)\r\n\t\tt.daemon = True\r\n\t\tt.start()\r\n\r\n\tdef _guiExec(self, func, *args):\r\n\t\tself._guiExecFunc = func\r\n\t\tself._guiExecArgs = args\r\n\t\tif not self._guiExecTimer.IsRunning():\r\n\t\t\tself._guiExecTimer.Start(50, True)\r\n\r\n\tdef _guiExecNotify(self):\r\n\t\tself._guiExecFunc(*self._guiExecArgs)\r\n\r\n\tdef _bg(self):\r\n\t\tsuccess=False\r\n\t\tfor url in self.urls:\r\n\t\t\ttry:\r\n\t\t\t\tself._download(url)\r\n\t\t\texcept:\r\n\t\t\t\tlog.debugWarning(\"Error downloading %s\" % url, exc_info=True)\r\n\t\t\telse: #Successfully downloaded or canceled\r\n\t\t\t\tif not self._shouldCancel:\r\n\t\t\t\t\tsuccess=True\r\n\t\t\t\tbreak\r\n\t\telse:\r\n\t\t\t# None of the URLs succeeded.\r\n\t\t\tself._guiExec(self._error)\r\n\t\t\treturn\r\n\t\tif not success:\r\n\t\t\ttry:\r\n\t\t\t\tos.remove(self.destPath)\r\n\t\t\texcept OSError:\r\n\t\t\t\tpass\r\n\t\t\treturn\r\n\t\tself._guiExec(self._downloadSuccess)\r\n\r\n\tdef _download(self, url):\r\n\t\tremote = urllib.urlopen(url)\r\n\t\tif remote.code != 200:\r\n\t\t\traise RuntimeError(\"Download failed with code %d\" % remote.code)\r\n\t\t# #2352: Some security scanners such as Eset NOD32 HTTP Scanner\r\n\t\t# cause huge read delays while downloading.\r\n\t\t# Therefore, set a higher timeout.\r\n\t\tremote.fp._sock.settimeout(120)\r\n\t\tsize = int(remote.headers[\"content-length\"])\r\n\t\tlocal = file(self.destPath, \"wb\")\r\n\t\tif self.fileHash:\r\n\t\t\thasher = hashlib.sha1()\r\n\t\tself._guiExec(self._downloadReport, 0, size)\r\n\t\tread = 0\r\n\t\tchunk=DOWNLOAD_BLOCK_SIZE\r\n\t\twhile True:\r\n\t\t\tif self._shouldCancel:\r\n\t\t\t\treturn\r\n\t\t\tif size -read <chunk:\r\n\t\t\t\tchunk =size -read\r\n\t\t\tblock = remote.read(chunk)\r\n\t\t\tif not block:\r\n\t\t\t\tbreak\r\n\t\t\tread += len(block)\r\n\t\t\tif self._shouldCancel:\r\n\t\t\t\treturn\r\n\t\t\tlocal.write(block)\r\n\t\t\tif self.fileHash:\r\n\t\t\t\thasher.update(block)\r\n\t\t\tself._guiExec(self._downloadReport, read, size)\r\n\t\tif read < size:\r\n\t\t\traise RuntimeError(\"Content too short\")\r\n\t\tif self.fileHash and hasher.hexdigest() != self.fileHash:\r\n\t\t\traise RuntimeError(\"Content has incorrect file hash\")\r\n\t\tself._guiExec(self._downloadReport, read, size)\r\n\r\n\tdef _downloadReport(self, read, size):\r\n\t\tif self._shouldCancel:\r\n\t\t\treturn\r\n\t\tpercent = int(float(read) / size * 100)\r\n\t\t# Translators: The progress message indicating that a download is in progress.\r\n\t\tcont, skip = self._progressDialog.Update(percent, _(\"Downloading\"))\r\n\t\tif not cont:\r\n\t\t\tself._shouldCancel = True\r\n\t\t\tself._stopped()\r\n\r\n\tdef _stopped(self):\r\n\t\tself._guiExecTimer = None\r\n\t\tself._guiExecFunc = None\r\n\t\tself._guiExecArgs = None\r\n\t\tself._progressDialog.Hide()\r\n\t\tself._progressDialog.Destroy()\r\n\t\tself._progressDialog = None\r\n\t\t# Not sure why, but this doesn't work if we call it directly here.\r\n\t\twx.CallLater(50, gui.mainFrame.postPopup)\r\n\r\n\tdef _error(self):\r\n\t\tself._stopped()\r\n\t\tgui.messageBox(\r\n\t\t\t# Translators: A message indicating that an error occurred while downloading an update to NVDA.\r\n\t\t\t_(\"Error downloading update.\"),\r\n\t\t\t_(\"Error\"),\r\n\t\t\twx.OK | wx.ICON_ERROR)\r\n\r\n\tdef _downloadSuccess(self):\r\n\t\tself._stopped()\r\n\t\t# Translators: The message presented when the update has been successfully downloaded\r\n\t\t# and is about to be installed.\r\n\t\tgui.messageBox(_(\"Update downloaded. It will now be installed.\"),\r\n\t\t\t# Translators: The title of the dialog displayed when the update is about to be installed.\r\n\t\t\t_(\"Install Update\"))\r\n\t\tstate[\"removeFile\"] = self.destPath\r\n\t\tsaveState()\r\n\t\t# #4475: ensure that the new process shows its first window, by providing SW_SHOWNORMAL\r\n\t\tshellapi.ShellExecute(None, None,\r\n\t\t\tself.destPath.decode(\"mbcs\"),\r\n\t\t\tu\"--install -m\",\r\n\t\t\tNone, winUser.SW_SHOWNORMAL)\r\n\r\nclass DonateRequestDialog(wx.Dialog):\r\n\t# Translators: The message requesting donations from users.\r\n\tMESSAGE = _(\r\n\t\t\"We need your help in order to continue to improve NVDA.\\n\"\r\n\t\t\"This project relies primarily on donations and grants. By donating, you are helping to fund full time development.\\n\"\r\n\t\t\"If even $10 is donated for every download, we will be able to cover all of the ongoing costs of the project.\\n\"\r\n\t\t\"All donations are received by NV Access, the non-profit organisation which develops NVDA.\\n\"\r\n\t\t\"Thank you for your support.\"\r\n\t)\r\n\r\n\tdef __init__(self, parent, continueFunc):\r\n\t\t# Translators: The title of the dialog requesting donations from users.\r\n\t\tsuper(DonateRequestDialog, self).__init__(parent, title=_(\"Please Donate\"))\r\n\t\tself._continue = continueFunc\r\n\r\n\t\tmainSizer=wx.BoxSizer(wx.VERTICAL)\r\n\t\titem = wx.StaticText(self, label=self.MESSAGE)\r\n\t\tmainSizer.Add(item, border=20, flag=wx.LEFT | wx.RIGHT | wx.TOP)\r\n\t\tsizer = wx.BoxSizer(wx.HORIZONTAL)\r\n\t\t# Translators: The label of the button to donate\r\n\t\t# in the \"Please Donate\" dialog.\r\n\t\titem = self.donateButton = wx.Button(self, label=_(\"&Donate\"))\r\n\t\titem.Bind(wx.EVT_BUTTON, self.onDonate)\r\n\t\tsizer.Add(item)\r\n\t\t# Translators: The label of the button to decline donation\r\n\t\t# in the \"Please Donate\" dialog.\r\n\t\titem = wx.Button(self, wx.ID_CLOSE, label=_(\"&Not now\"))\r\n\t\titem.Bind(wx.EVT_BUTTON, lambda evt: self.Close())\r\n\t\tsizer.Add(item)\r\n\t\tself.Bind(wx.EVT_CLOSE, self.onClose)\r\n\t\tself.EscapeId = wx.ID_CLOSE\r\n\t\tmainSizer.Add(sizer, flag=wx.TOP | wx.BOTTOM | wx.ALIGN_CENTER_HORIZONTAL, border=20)\r\n\r\n\t\tself.Sizer = mainSizer\r\n\t\tmainSizer.Fit(self)\r\n\t\tself.Center(wx.BOTH | wx.CENTER_ON_SCREEN)\r\n\t\tself.Show()\r\n\r\n\tdef onDonate(self, evt):\r\n\t\tos.startfile(gui.DONATE_URL)\r\n\t\t# Translators: The label of a button to indicate that the user is finished donating\r\n\t\t# in the \"Please Donate\" dialog.\r\n\t\tself.donateButton.Label = _(\"&Done\")\r\n\t\tself.donateButton.Bind(wx.EVT_BUTTON, lambda evt: self.Close())\r\n\r\n\tdef onClose(self, evt):\r\n\t\tself.Hide()\r\n\t\tself._continue()\r\n\t\tself.Destroy()\r\n\r\ndef saveState():\r\n\ttry:\r\n\t\tcPickle.dump(state, file(_stateFilename, \"wb\"))\r\n\texcept:\r\n\t\tlog.debugWarning(\"Error saving state\", exc_info=True)\r\n\r\ndef initialize():\r\n\tglobal state, _stateFilename, autoChecker\r\n\t_stateFilename = os.path.join(globalVars.appArgs.configPath, \"updateCheckState.pickle\")\r\n\ttry:\r\n\t\tstate = cPickle.load(file(_stateFilename, \"r\"))\r\n\texcept:\r\n\t\t# Defaults.\r\n\t\tstate = {\r\n\t\t\t\"lastCheck\": 0,\r\n\t\t\t\"dontRemindVersion\": None,\r\n\t\t}\r\n\r\n\t# If we just updated, remove the updater file.\r\n\ttry:\r\n\t\tos.remove(state.pop(\"removeFile\"))\r\n\t\tsaveState()\r\n\texcept (KeyError, OSError):\r\n\t\tpass\r\n\r\n\tif config.conf[\"update\"][\"autoCheck\"] and not globalVars.appArgs.launcher:\r\n\t\tautoChecker = AutoUpdateChecker()\r\n\r\ndef terminate():\r\n\tglobal state, autoChecker\r\n\tstate = None\r\n\tif autoChecker:\r\n\t\tautoChecker.terminate()\r\n\t\tautoChecker = None\r\n\r\n# These structs are only complete enough to achieve what we need.\r\nclass CERT_USAGE_MATCH(ctypes.Structure):\r\n\t_fields_ = (\r\n\t\t(\"dwType\", ctypes.wintypes.DWORD),\r\n\t\t# CERT_ENHKEY_USAGE struct\r\n\t\t(\"cUsageIdentifier\", ctypes.wintypes.DWORD),\r\n\t\t(\"rgpszUsageIdentifier\", ctypes.c_void_p), # LPSTR *\r\n\t)\r\n\r\nclass CERT_CHAIN_PARA(ctypes.Structure):\r\n\t_fields_ = (\r\n\t\t(\"cbSize\", ctypes.wintypes.DWORD),\r\n\t\t(\"RequestedUsage\", CERT_USAGE_MATCH),\r\n\t\t(\"RequestedIssuancePolicy\", CERT_USAGE_MATCH),\r\n\t\t(\"dwUrlRetrievalTimeout\", ctypes.wintypes.DWORD),\r\n\t\t(\"fCheckRevocationFreshnessTime\", ctypes.wintypes.BOOL),\r\n\t\t(\"dwRevocationFreshnessTime\", ctypes.wintypes.DWORD),\r\n\t\t(\"pftCacheResync\", ctypes.c_void_p), # LPFILETIME\r\n\t\t(\"pStrongSignPara\", ctypes.c_void_p), # PCCERT_STRONG_SIGN_PARA\r\n\t\t(\"dwStrongSignFlags\", ctypes.wintypes.DWORD),\r\n\t)\r\n\r\ndef _updateWindowsRootCertificates():\r\n\tcrypt = ctypes.windll.crypt32\r\n\t# Get the server certificate.\r\n\tsslCont = ssl._create_unverified_context()\r\n\tu = urllib.urlopen(\"https://www.nvaccess.org/nvdaUpdateCheck\", context=sslCont)\r\n\tcert = u.fp._sock.getpeercert(True)\r\n\tu.close()\r\n\t# Convert to a form usable by Windows.\r\n\tcertCont = crypt.CertCreateCertificateContext(\r\n\t\t0x00000001, # X509_ASN_ENCODING\r\n\t\tcert,\r\n\t\tlen(cert))\r\n\t# Ask Windows to build a certificate chain, thus triggering a root certificate update.\r\n\tchainCont = ctypes.c_void_p()\r\n\tcrypt.CertGetCertificateChain(None, certCont, None, None,\r\n\t\tctypes.byref(CERT_CHAIN_PARA(cbSize=ctypes.sizeof(CERT_CHAIN_PARA),\r\n\t\t\tRequestedUsage=CERT_USAGE_MATCH())),\r\n\t\t0, None,\r\n\t\tctypes.byref(chainCont))\r\n\tcrypt.CertFreeCertificateChain(chainCont)\r\n\tcrypt.CertFreeCertificateContext(certCont)\r\n", "idx": 3, "id": 18603, "msg": "", "proj": "nvaccess-nvda", "lang": "py"}
{"patch": "@@ -895,16 +895,21 @@ class Enum_metaclass(type):\n \n \n def export_object(obj):\n-    print(bytes_base64(gzip.zlib.compress(six.moves.cPickle.dumps(obj, 2), 9)))\n+    # type: (Any) -> None\n+    import zlib\n+    print(bytes_base64(zlib.compress(six.moves.cPickle.dumps(obj, 2), 9)))\n \n \n def import_object(obj=None):\n+    # type: (Optional[str]) -> Any\n+    import zlib\n     if obj is None:\n         obj = sys.stdin.read()\n-    return six.moves.cPickle.loads(gzip.zlib.decompress(base64_bytes(obj.strip())))  # noqa: E501\n+    return six.moves.cPickle.loads(zlib.decompress(base64_bytes(obj.strip())))  # noqa: E501\n \n \n def save_object(fname, obj):\n+    # type: (str, Any) -> None\n     \"\"\"Pickle a Python object\"\"\"\n \n     fd = gzip.open(fname, \"wb\")", "y": 0, "oldf": "# This file is part of Scapy\n# See http://www.secdev.org/projects/scapy for more information\n# Copyright (C) Philippe Biondi <phil@secdev.org>\n# This program is published under a GPLv2 license\n\n\"\"\"\nGeneral utility functions.\n\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom decimal import Decimal\n\nimport difflib\nimport os\nimport sys\nimport socket\nimport collections\nimport random\nimport time\nimport gzip\nimport re\nimport struct\nimport array\nimport subprocess\nimport tempfile\nimport threading\nimport warnings\n\nimport scapy.modules.six as six\nfrom scapy.modules.six.moves import range, input, zip_longest\n\nfrom scapy.config import conf\nfrom scapy.consts import DARWIN, WINDOWS, WINDOWS_XP, OPENBSD\nfrom scapy.data import MTU, DLT_EN10MB\nfrom scapy.compat import orb, raw, plain_str, chb, bytes_base64,\\\n    base64_bytes, hex_bytes, lambda_tuple_converter, bytes_encode\nfrom scapy.error import log_runtime, Scapy_Exception, warning\nfrom scapy.pton_ntop import inet_pton\n\nfrom scapy.compat import (\n    Any,\n)\n\n###########\n#  Tools  #\n###########\n\n\ndef issubtype(x, t):\n    \"\"\"issubtype(C, B) -> bool\n\n    Return whether C is a class and if it is a subclass of class B.\n    When using a tuple as the second argument issubtype(X, (A, B, ...)),\n    is a shortcut for issubtype(X, A) or issubtype(X, B) or ... (etc.).\n    \"\"\"\n    if isinstance(t, str):\n        return t in (z.__name__ for z in x.__bases__)\n    if isinstance(x, type) and issubclass(x, t):\n        return True\n    return False\n\n\nclass EDecimal(Decimal):\n    \"\"\"Extended Decimal\n\n    This implements arithmetic and comparison with float for\n    backward compatibility\n    \"\"\"\n\n    def __add__(self, other, **kwargs):\n        return EDecimal(Decimal.__add__(self, Decimal(other), **kwargs))\n\n    def __radd__(self, other, **kwargs):\n        return EDecimal(Decimal.__add__(self, Decimal(other), **kwargs))\n\n    def __sub__(self, other, **kwargs):\n        return EDecimal(Decimal.__sub__(self, Decimal(other), **kwargs))\n\n    def __rsub__(self, other, **kwargs):\n        return EDecimal(Decimal.__rsub__(self, Decimal(other), **kwargs))\n\n    def __mul__(self, other, **kwargs):\n        return EDecimal(Decimal.__mul__(self, Decimal(other), **kwargs))\n\n    def __rmul__(self, other, **kwargs):\n        return EDecimal(Decimal.__mul__(self, Decimal(other), **kwargs))\n\n    def __truediv__(self, other, **kwargs):\n        return EDecimal(Decimal.__truediv__(self, Decimal(other), **kwargs))\n\n    def __floordiv__(self, other, **kwargs):\n        return EDecimal(Decimal.__floordiv__(self, Decimal(other), **kwargs))\n\n    def __div__(self, other, **kwargs):\n        return EDecimal(Decimal.__div__(self, Decimal(other), **kwargs))\n\n    def __rdiv__(self, other, **kwargs):\n        return EDecimal(Decimal.__rdiv__(self, Decimal(other), **kwargs))\n\n    def __mod__(self, other, **kwargs):\n        return EDecimal(Decimal.__mod__(self, Decimal(other), **kwargs))\n\n    def __rmod__(self, other, **kwargs):\n        return EDecimal(Decimal.__rmod__(self, Decimal(other), **kwargs))\n\n    def __divmod__(self, other, **kwargs):\n        return EDecimal(Decimal.__divmod__(self, Decimal(other), **kwargs))\n\n    def __rdivmod__(self, other, **kwargs):\n        return EDecimal(Decimal.__rdivmod__(self, Decimal(other), **kwargs))\n\n    def __pow__(self, other, **kwargs):\n        return EDecimal(Decimal.__pow__(self, Decimal(other), **kwargs))\n\n    def __rpow__(self, other, **kwargs):\n        return EDecimal(Decimal.__rpow__(self, Decimal(other), **kwargs))\n\n    def __eq__(self, other, **kwargs):\n        return super(EDecimal, self).__eq__(other) or float(self) == other\n\n\ndef get_temp_file(keep=False, autoext=\"\", fd=False):\n    \"\"\"Creates a temporary file.\n\n    :param keep: If False, automatically delete the file when Scapy exits.\n    :param autoext: Suffix to add to the generated file name.\n    :param fd: If True, this returns a file-like object with the temporary\n               file opened. If False (default), this returns a file path.\n    \"\"\"\n    f = tempfile.NamedTemporaryFile(prefix=\"scapy\", suffix=autoext,\n                                    delete=False)\n    if not keep:\n        conf.temp_files.append(f.name)\n\n    if fd:\n        return f\n    else:\n        # Close the file so something else can take it.\n        f.close()\n        return f.name\n\n\ndef get_temp_dir(keep=False):\n    \"\"\"Creates a temporary file, and returns its name.\n\n    :param keep: If False (default), the directory will be recursively\n                 deleted when Scapy exits.\n    :return: A full path to a temporary directory.\n    \"\"\"\n\n    dname = tempfile.mkdtemp(prefix=\"scapy\")\n\n    if not keep:\n        conf.temp_files.append(dname)\n\n    return dname\n\n\ndef sane_color(x):\n    r = \"\"\n    for i in x:\n        j = orb(i)\n        if (j < 32) or (j >= 127):\n            r += conf.color_theme.not_printable(\".\")\n        else:\n            r += chr(j)\n    return r\n\n\ndef sane(x):\n    r = \"\"\n    for i in x:\n        j = orb(i)\n        if (j < 32) or (j >= 127):\n            r += \".\"\n        else:\n            r += chr(j)\n    return r\n\n\n@conf.commands.register\ndef restart():\n    \"\"\"Restarts scapy\"\"\"\n    if not conf.interactive or not os.path.isfile(sys.argv[0]):\n        raise OSError(\"Scapy was not started from console\")\n    if WINDOWS:\n        try:\n            res_code = subprocess.call([sys.executable] + sys.argv)\n        except KeyboardInterrupt:\n            res_code = 1\n        finally:\n            os._exit(res_code)\n    os.execv(sys.executable, [sys.executable] + sys.argv)\n\n\ndef lhex(x):\n    # type: (Any) -> str\n    from scapy.volatile import VolatileValue\n    if isinstance(x, VolatileValue):\n        return repr(x)\n    if type(x) in six.integer_types:\n        return hex(x)\n    elif isinstance(x, tuple):\n        return \"(%s)\" % \", \".join(map(lhex, x))\n    elif isinstance(x, list):\n        return \"[%s]\" % \", \".join(map(lhex, x))\n    else:\n        return str(x)\n\n\n@conf.commands.register\ndef hexdump(x, dump=False):\n    \"\"\"Build a tcpdump like hexadecimal view\n\n    :param x: a Packet\n    :param dump: define if the result must be printed or returned in a variable\n    :return: a String only when dump=True\n    \"\"\"\n    s = \"\"\n    x = bytes_encode(x)\n    x_len = len(x)\n    i = 0\n    while i < x_len:\n        s += \"%04x  \" % i\n        for j in range(16):\n            if i + j < x_len:\n                s += \"%02X \" % orb(x[i + j])\n            else:\n                s += \"   \"\n        s += \" %s\\n\" % sane_color(x[i:i + 16])\n        i += 16\n    # remove trailing \\n\n    s = s[:-1] if s.endswith(\"\\n\") else s\n    if dump:\n        return s\n    else:\n        print(s)\n\n\n@conf.commands.register\ndef linehexdump(x, onlyasc=0, onlyhex=0, dump=False):\n    \"\"\"Build an equivalent view of hexdump() on a single line\n\n    Note that setting both onlyasc and onlyhex to 1 results in a empty output\n\n    :param x: a Packet\n    :param onlyasc: 1 to display only the ascii view\n    :param onlyhex: 1 to display only the hexadecimal view\n    :param dump: print the view if False\n    :return: a String only when dump=True\n    \"\"\"\n    s = \"\"\n    s = hexstr(x, onlyasc=onlyasc, onlyhex=onlyhex, color=not dump)\n    if dump:\n        return s\n    else:\n        print(s)\n\n\n@conf.commands.register\ndef chexdump(x, dump=False):\n    \"\"\"Build a per byte hexadecimal representation\n\n    Example:\n        >>> chexdump(IP())\n        0x45, 0x00, 0x00, 0x14, 0x00, 0x01, 0x00, 0x00, 0x40, 0x00, 0x7c, 0xe7, 0x7f, 0x00, 0x00, 0x01, 0x7f, 0x00, 0x00, 0x01  # noqa: E501\n\n    :param x: a Packet\n    :param dump: print the view if False\n    :return: a String only if dump=True\n    \"\"\"\n    x = bytes_encode(x)\n    s = \", \".join(\"%#04x\" % orb(x) for x in x)\n    if dump:\n        return s\n    else:\n        print(s)\n\n\n@conf.commands.register\ndef hexstr(x, onlyasc=0, onlyhex=0, color=False):\n    \"\"\"Build a fancy tcpdump like hex from bytes.\"\"\"\n    x = bytes_encode(x)\n    _sane_func = sane_color if color else sane\n    s = []\n    if not onlyasc:\n        s.append(\" \".join(\"%02X\" % orb(b) for b in x))\n    if not onlyhex:\n        s.append(_sane_func(x))\n    return \"  \".join(s)\n\n\ndef repr_hex(s):\n    \"\"\" Convert provided bitstring to a simple string of hex digits \"\"\"\n    return \"\".join(\"%02x\" % orb(x) for x in s)\n\n\n@conf.commands.register\ndef hexdiff(x, y, autojunk=False):\n    \"\"\"\n    Show differences between 2 binary strings, Packets...\n\n    For the autojunk parameter, see\n    https://docs.python.org/3.8/library/difflib.html#difflib.SequenceMatcher\n\n    :param x:\n    :param y: The binary strings, packets... to compare\n    :param autojunk: Setting it to True will likely increase the comparison\n        speed a lot on big byte strings, but will reduce accuracy (will tend\n        to miss insertion and see replacements instead for instance).\n    \"\"\"\n\n    # Compare the strings using difflib\n\n    x = bytes_encode(x)\n    y = bytes_encode(y)\n\n    sm = difflib.SequenceMatcher(a=x, b=y, autojunk=autojunk)\n    x = [x[i:i + 1] for i in range(len(x))]\n    y = [y[i:i + 1] for i in range(len(y))]\n\n    backtrackx = []\n    backtracky = []\n    for opcode in sm.get_opcodes():\n        typ, x0, x1, y0, y1 = opcode\n        if typ == 'delete':\n            backtrackx += x[x0:x1]\n            backtracky += [''] * (x1 - x0)\n        elif typ == 'insert':\n            backtrackx += [''] * (y1 - y0)\n            backtracky += y[y0:y1]\n        elif typ in ['equal', 'replace']:\n            backtrackx += x[x0:x1]\n            backtracky += y[y0:y1]\n\n    if autojunk:\n        # Some lines may have been considered as junk. Check the sizes\n        lbx = len(backtrackx)\n        lby = len(backtracky)\n        backtrackx += [''] * (max(lbx, lby) - lbx)\n        backtracky += [''] * (max(lbx, lby) - lby)\n\n    # Print the diff\n\n    x = y = i = 0\n    colorize = {0: lambda x: x,\n                -1: conf.color_theme.left,\n                1: conf.color_theme.right}\n\n    dox = 1\n    doy = 0\n    btx_len = len(backtrackx)\n    while i < btx_len:\n        linex = backtrackx[i:i + 16]\n        liney = backtracky[i:i + 16]\n        xx = sum(len(k) for k in linex)\n        yy = sum(len(k) for k in liney)\n        if dox and not xx:\n            dox = 0\n            doy = 1\n        if dox and linex == liney:\n            doy = 1\n\n        if dox:\n            xd = y\n            j = 0\n            while not linex[j]:\n                j += 1\n                xd -= 1\n            print(colorize[doy - dox](\"%04x\" % xd), end=' ')\n            x += xx\n            line = linex\n        else:\n            print(\"    \", end=' ')\n        if doy:\n            yd = y\n            j = 0\n            while not liney[j]:\n                j += 1\n                yd -= 1\n            print(colorize[doy - dox](\"%04x\" % yd), end=' ')\n            y += yy\n            line = liney\n        else:\n            print(\"    \", end=' ')\n\n        print(\" \", end=' ')\n\n        cl = \"\"\n        for j in range(16):\n            if i + j < btx_len:\n                if line[j]:\n                    col = colorize[(linex[j] != liney[j]) * (doy - dox)]\n                    print(col(\"%02X\" % orb(line[j])), end=' ')\n                    if linex[j] == liney[j]:\n                        cl += sane_color(line[j])\n                    else:\n                        cl += col(sane(line[j]))\n                else:\n                    print(\"  \", end=' ')\n                    cl += \" \"\n            else:\n                print(\"  \", end=' ')\n            if j == 7:\n                print(\"\", end=' ')\n\n        print(\" \", cl)\n\n        if doy or not yy:\n            doy = 0\n            dox = 1\n            i += 16\n        else:\n            if yy:\n                dox = 0\n                doy = 1\n            else:\n                i += 16\n\n\nif struct.pack(\"H\", 1) == b\"\\x00\\x01\":  # big endian\n    checksum_endian_transform = lambda chk: chk\nelse:\n    checksum_endian_transform = lambda chk: ((chk >> 8) & 0xff) | chk << 8\n\n\ndef checksum(pkt):\n    if len(pkt) % 2 == 1:\n        pkt += b\"\\0\"\n    s = sum(array.array(\"H\", pkt))\n    s = (s >> 16) + (s & 0xffff)\n    s += s >> 16\n    s = ~s\n    return checksum_endian_transform(s) & 0xffff\n\n\ndef _fletcher16(charbuf):\n    # This is based on the GPLed C implementation in Zebra <http://www.zebra.org/>  # noqa: E501\n    c0 = c1 = 0\n    for char in charbuf:\n        c0 += orb(char)\n        c1 += c0\n\n    c0 %= 255\n    c1 %= 255\n    return (c0, c1)\n\n\n@conf.commands.register\ndef fletcher16_checksum(binbuf):\n    \"\"\"Calculates Fletcher-16 checksum of the given buffer.\n\n       Note:\n       If the buffer contains the two checkbytes derived from the Fletcher-16 checksum  # noqa: E501\n       the result of this function has to be 0. Otherwise the buffer has been corrupted.  # noqa: E501\n    \"\"\"\n    (c0, c1) = _fletcher16(binbuf)\n    return (c1 << 8) | c0\n\n\n@conf.commands.register\ndef fletcher16_checkbytes(binbuf, offset):\n    \"\"\"Calculates the Fletcher-16 checkbytes returned as 2 byte binary-string.\n\n       Including the bytes into the buffer (at the position marked by offset) the  # noqa: E501\n       global Fletcher-16 checksum of the buffer will be 0. Thus it is easy to verify  # noqa: E501\n       the integrity of the buffer on the receiver side.\n\n       For details on the algorithm, see RFC 2328 chapter 12.1.7 and RFC 905 Annex B.  # noqa: E501\n    \"\"\"\n\n    # This is based on the GPLed C implementation in Zebra <http://www.zebra.org/>  # noqa: E501\n    if len(binbuf) < offset:\n        raise Exception(\"Packet too short for checkbytes %d\" % len(binbuf))\n\n    binbuf = binbuf[:offset] + b\"\\x00\\x00\" + binbuf[offset + 2:]\n    (c0, c1) = _fletcher16(binbuf)\n\n    x = ((len(binbuf) - offset - 1) * c0 - c1) % 255\n\n    if (x <= 0):\n        x += 255\n\n    y = 510 - c0 - x\n\n    if (y > 255):\n        y -= 255\n    return chb(x) + chb(y)\n\n\ndef mac2str(mac):\n    return b\"\".join(chb(int(x, 16)) for x in plain_str(mac).split(':'))\n\n\ndef valid_mac(mac):\n    try:\n        return len(mac2str(mac)) == 6\n    except ValueError:\n        pass\n    return False\n\n\ndef str2mac(s):\n    if isinstance(s, str):\n        return (\"%02x:\" * 6)[:-1] % tuple(map(ord, s))\n    return (\"%02x:\" * 6)[:-1] % tuple(s)\n\n\ndef randstring(length):\n    \"\"\"\n    Returns a random string of length (length >= 0)\n    \"\"\"\n    return b\"\".join(struct.pack('B', random.randint(0, 255))\n                    for _ in range(length))\n\n\ndef zerofree_randstring(length):\n    \"\"\"\n    Returns a random string of length (length >= 0) without zero in it.\n    \"\"\"\n    return b\"\".join(struct.pack('B', random.randint(1, 255))\n                    for _ in range(length))\n\n\ndef strxor(s1, s2):\n    \"\"\"\n    Returns the binary XOR of the 2 provided strings s1 and s2. s1 and s2\n    must be of same length.\n    \"\"\"\n    return b\"\".join(map(lambda x, y: chb(orb(x) ^ orb(y)), s1, s2))\n\n\ndef strand(s1, s2):\n    \"\"\"\n    Returns the binary AND of the 2 provided strings s1 and s2. s1 and s2\n    must be of same length.\n    \"\"\"\n    return b\"\".join(map(lambda x, y: chb(orb(x) & orb(y)), s1, s2))\n\n\n# Workaround bug 643005 : https://sourceforge.net/tracker/?func=detail&atid=105470&aid=643005&group_id=5470  # noqa: E501\ntry:\n    socket.inet_aton(\"255.255.255.255\")\nexcept socket.error:\n    def inet_aton(x):\n        if x == \"255.255.255.255\":\n            return b\"\\xff\" * 4\n        else:\n            return socket.inet_aton(x)\nelse:\n    inet_aton = socket.inet_aton\n\ninet_ntoa = socket.inet_ntoa\n\n\ndef atol(x):\n    try:\n        ip = inet_aton(x)\n    except socket.error:\n        ip = inet_aton(socket.gethostbyname(x))\n    return struct.unpack(\"!I\", ip)[0]\n\n\ndef valid_ip(addr):\n    try:\n        addr = plain_str(addr)\n    except UnicodeDecodeError:\n        return False\n    try:\n        atol(addr)\n    except (OSError, ValueError, socket.error):\n        return False\n    return True\n\n\ndef valid_net(addr):\n    try:\n        addr = plain_str(addr)\n    except UnicodeDecodeError:\n        return False\n    if '/' in addr:\n        ip, mask = addr.split('/', 1)\n        return valid_ip(ip) and mask.isdigit() and 0 <= int(mask) <= 32\n    return valid_ip(addr)\n\n\ndef valid_ip6(addr):\n    try:\n        addr = plain_str(addr)\n    except UnicodeDecodeError:\n        return False\n    try:\n        inet_pton(socket.AF_INET6, addr)\n    except socket.error:\n        try:\n            socket.getaddrinfo(addr, None, socket.AF_INET6)[0][4][0]\n        except socket.error:\n            return False\n    return True\n\n\ndef valid_net6(addr):\n    try:\n        addr = plain_str(addr)\n    except UnicodeDecodeError:\n        return False\n    if '/' in addr:\n        ip, mask = addr.split('/', 1)\n        return valid_ip6(ip) and mask.isdigit() and 0 <= int(mask) <= 128\n    return valid_ip6(addr)\n\n\nif WINDOWS_XP:\n    # That is a hell of compatibility :(\n    def ltoa(x):\n        return inet_ntoa(struct.pack(\"<I\", x & 0xffffffff))\nelse:\n    def ltoa(x):\n        return inet_ntoa(struct.pack(\"!I\", x & 0xffffffff))\n\n\ndef itom(x):\n    return (0xffffffff00000000 >> x) & 0xffffffff\n\n\nclass ContextManagerSubprocess(object):\n    \"\"\"\n    Context manager that eases checking for unknown command, without\n    crashing.\n\n    Example:\n    >>> with ContextManagerSubprocess(\"tcpdump\"):\n    >>>     subprocess.Popen([\"tcpdump\", \"--version\"])\n    ERROR: Could not execute tcpdump, is it installed?\n\n    \"\"\"\n\n    def __init__(self, prog, suppress=True):\n        self.prog = prog\n        self.suppress = suppress\n\n    def __enter__(self):\n        pass\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        if exc_value is None:\n            return\n        # Errored\n        if isinstance(exc_value, EnvironmentError):\n            msg = \"Could not execute %s, is it installed?\" % self.prog\n        else:\n            msg = \"%s: execution failed (%s)\" % (\n                self.prog,\n                exc_type.__class__.__name__\n            )\n        if not self.suppress:\n            raise exc_type(msg)\n        log_runtime.error(msg, exc_info=True)\n        return True  # Suppress the exception\n\n\nclass ContextManagerCaptureOutput(object):\n    \"\"\"\n    Context manager that intercept the console's output.\n\n    Example:\n    >>> with ContextManagerCaptureOutput() as cmco:\n    ...     print(\"hey\")\n    ...     assert cmco.get_output() == \"hey\"\n    \"\"\"\n\n    def __init__(self):\n        self.result_export_object = \"\"\n        try:\n            import mock  # noqa: F401\n        except Exception:\n            raise ImportError(\"The mock module needs to be installed !\")\n\n    def __enter__(self):\n        import mock\n\n        def write(s, decorator=self):\n            decorator.result_export_object += s\n        mock_stdout = mock.Mock()\n        mock_stdout.write = write\n        self.bck_stdout = sys.stdout\n        sys.stdout = mock_stdout\n        return self\n\n    def __exit__(self, *exc):\n        sys.stdout = self.bck_stdout\n        return False\n\n    def get_output(self, eval_bytes=False):\n        if self.result_export_object.startswith(\"b'\") and eval_bytes:\n            return plain_str(eval(self.result_export_object))\n        return self.result_export_object\n\n\ndef do_graph(graph, prog=None, format=None, target=None, type=None,\n             string=None, options=None):\n    \"\"\"Processes graph description using an external software.\n    This method is used to convert a graphviz format to an image.\n\n    :param graph: GraphViz graph description\n    :param prog: which graphviz program to use\n    :param format: output type (svg, ps, gif, jpg, etc.), passed to dot's \"-T\"\n        option\n    :param string: if not None, simply return the graph string\n    :param target: filename or redirect. Defaults pipe to Imagemagick's\n        display program\n    :param options: options to be passed to prog\n    \"\"\"\n\n    if format is None:\n        format = \"svg\"\n    if string:\n        return graph\n    if type is not None:\n        warnings.warn(\n            \"type is deprecated, and was renamed format\",\n            DeprecationWarning\n        )\n        format = type\n    if prog is None:\n        prog = conf.prog.dot\n    start_viewer = False\n    if target is None:\n        if WINDOWS:\n            target = get_temp_file(autoext=\".\" + format)\n            start_viewer = True\n        else:\n            with ContextManagerSubprocess(conf.prog.display):\n                target = subprocess.Popen([conf.prog.display],\n                                          stdin=subprocess.PIPE).stdin\n    if format is not None:\n        format = \"-T%s\" % format\n    if isinstance(target, str):\n        if target.startswith('|'):\n            target = subprocess.Popen(target[1:].lstrip(), shell=True,\n                                      stdin=subprocess.PIPE).stdin\n        elif target.startswith('>'):\n            target = open(target[1:].lstrip(), \"wb\")\n        else:\n            target = open(os.path.abspath(target), \"wb\")\n    proc = subprocess.Popen(\n        \"\\\"%s\\\" %s %s\" % (prog, options or \"\", format or \"\"),\n        shell=True, stdin=subprocess.PIPE, stdout=target,\n        stderr=subprocess.PIPE\n    )\n    _, stderr = proc.communicate(bytes_encode(graph))\n    if proc.returncode != 0:\n        raise OSError(\n            \"GraphViz call failed (is it installed?):\\n\" +\n            plain_str(stderr)\n        )\n    try:\n        target.close()\n    except Exception:\n        pass\n    if start_viewer:\n        # Workaround for file not found error: We wait until tempfile is written.  # noqa: E501\n        waiting_start = time.time()\n        while not os.path.exists(target.name):\n            time.sleep(0.1)\n            if time.time() - waiting_start > 3:\n                warning(\"Temporary file '%s' could not be written. Graphic will not be displayed.\", tempfile)  # noqa: E501\n                break\n        else:\n            if conf.prog.display == conf.prog._default:\n                os.startfile(target.name)\n            else:\n                with ContextManagerSubprocess(conf.prog.display):\n                    subprocess.Popen([conf.prog.display, target.name])\n\n\n_TEX_TR = {\n    \"{\": \"{\\\\tt\\\\char123}\",\n    \"}\": \"{\\\\tt\\\\char125}\",\n    \"\\\\\": \"{\\\\tt\\\\char92}\",\n    \"^\": \"\\\\^{}\",\n    \"$\": \"\\\\$\",\n    \"#\": \"\\\\#\",\n    \"_\": \"\\\\_\",\n    \"&\": \"\\\\&\",\n    \"%\": \"\\\\%\",\n    \"|\": \"{\\\\tt\\\\char124}\",\n    \"~\": \"{\\\\tt\\\\char126}\",\n    \"<\": \"{\\\\tt\\\\char60}\",\n    \">\": \"{\\\\tt\\\\char62}\",\n}\n\n\ndef tex_escape(x):\n    s = \"\"\n    for c in x:\n        s += _TEX_TR.get(c, c)\n    return s\n\n\ndef colgen(*lstcol, **kargs):\n    \"\"\"Returns a generator that mixes provided quantities forever\n    trans: a function to convert the three arguments into a color. lambda x,y,z:(x,y,z) by default\"\"\"  # noqa: E501\n    if len(lstcol) < 2:\n        lstcol *= 2\n    trans = kargs.get(\"trans\", lambda x, y, z: (x, y, z))\n    while True:\n        for i in range(len(lstcol)):\n            for j in range(len(lstcol)):\n                for k in range(len(lstcol)):\n                    if i != j or j != k or k != i:\n                        yield trans(lstcol[(i + j) % len(lstcol)], lstcol[(j + k) % len(lstcol)], lstcol[(k + i) % len(lstcol)])  # noqa: E501\n\n\ndef incremental_label(label=\"tag%05i\", start=0):\n    while True:\n        yield label % start\n        start += 1\n\n\ndef binrepr(val):\n    return bin(val)[2:]\n\n\ndef long_converter(s):\n    return int(s.replace('\\n', '').replace(' ', ''), 16)\n\n#########################\n#    Enum management    #\n#########################\n\n\nclass EnumElement:\n    _value = None\n\n    def __init__(self, key, value):\n        self._key = key\n        self._value = value\n\n    def __repr__(self):\n        return \"<%s %s[%r]>\" % (self.__dict__.get(\"_name\", self.__class__.__name__), self._key, self._value)  # noqa: E501\n\n    def __getattr__(self, attr):\n        return getattr(self._value, attr)\n\n    def __str__(self):\n        return self._key\n\n    def __bytes__(self):\n        return bytes_encode(self.__str__())\n\n    def __hash__(self):\n        return self._value\n\n    def __int__(self):\n        return int(self._value)\n\n    def __eq__(self, other):\n        return self._value == int(other)\n\n    def __neq__(self, other):\n        return not self.__eq__(other)\n\n\nclass Enum_metaclass(type):\n    element_class = EnumElement\n\n    def __new__(cls, name, bases, dct):\n        rdict = {}\n        for k, v in six.iteritems(dct):\n            if isinstance(v, int):\n                v = cls.element_class(k, v)\n                dct[k] = v\n                rdict[v] = k\n        dct[\"__rdict__\"] = rdict\n        return super(Enum_metaclass, cls).__new__(cls, name, bases, dct)\n\n    def __getitem__(self, attr):\n        return self.__rdict__[attr]\n\n    def __contains__(self, val):\n        return val in self.__rdict__\n\n    def get(self, attr, val=None):\n        return self.__rdict__.get(attr, val)\n\n    def __repr__(self):\n        return \"<%s>\" % self.__dict__.get(\"name\", self.__name__)\n\n\n###################\n#  Object saving  #\n###################\n\n\ndef export_object(obj):\n    print(bytes_base64(gzip.zlib.compress(six.moves.cPickle.dumps(obj, 2), 9)))\n\n\ndef import_object(obj=None):\n    if obj is None:\n        obj = sys.stdin.read()\n    return six.moves.cPickle.loads(gzip.zlib.decompress(base64_bytes(obj.strip())))  # noqa: E501\n\n\ndef save_object(fname, obj):\n    \"\"\"Pickle a Python object\"\"\"\n\n    fd = gzip.open(fname, \"wb\")\n    six.moves.cPickle.dump(obj, fd)\n    fd.close()\n\n\ndef load_object(fname):\n    \"\"\"unpickle a Python object\"\"\"\n    return six.moves.cPickle.load(gzip.open(fname, \"rb\"))\n\n\n@conf.commands.register\ndef corrupt_bytes(s, p=0.01, n=None):\n    \"\"\"\n    Corrupt a given percentage (at least one byte) or number of bytes\n    from a string\n    \"\"\"\n    s = array.array(\"B\", bytes_encode(s))\n    s_len = len(s)\n    if n is None:\n        n = max(1, int(s_len * p))\n    for i in random.sample(range(s_len), n):\n        s[i] = (s[i] + random.randint(1, 255)) % 256\n    return s.tostring() if six.PY2 else s.tobytes()\n\n\n@conf.commands.register\ndef corrupt_bits(s, p=0.01, n=None):\n    \"\"\"\n    Flip a given percentage (at least one bit) or number of bits\n    from a string\n    \"\"\"\n    s = array.array(\"B\", bytes_encode(s))\n    s_len = len(s) * 8\n    if n is None:\n        n = max(1, int(s_len * p))\n    for i in random.sample(range(s_len), n):\n        s[i // 8] ^= 1 << (i % 8)\n    return s.tostring() if six.PY2 else s.tobytes()\n\n\n#############################\n#  pcap capture file stuff  #\n#############################\n\n@conf.commands.register\ndef wrpcap(filename, pkt, *args, **kargs):\n    \"\"\"Write a list of packets to a pcap file\n\n    :param filename: the name of the file to write packets to, or an open,\n        writable file-like object. The file descriptor will be\n        closed at the end of the call, so do not use an object you\n        do not want to close (e.g., running wrpcap(sys.stdout, [])\n        in interactive mode will crash Scapy).\n    :param gz: set to 1 to save a gzipped capture\n    :param linktype: force linktype value\n    :param endianness: \"<\" or \">\", force endianness\n    :param sync: do not bufferize writes to the capture file\n    \"\"\"\n    with PcapWriter(filename, *args, **kargs) as fdesc:\n        fdesc.write(pkt)\n\n\n@conf.commands.register\ndef rdpcap(filename, count=-1):\n    \"\"\"Read a pcap or pcapng file and return a packet list\n\n    :param count: read only <count> packets\n    \"\"\"\n    with PcapReader(filename) as fdesc:\n        return fdesc.read_all(count=count)\n\n\nclass PcapReader_metaclass(type):\n    \"\"\"Metaclass for (Raw)Pcap(Ng)Readers\"\"\"\n\n    def __new__(cls, name, bases, dct):\n        \"\"\"The `alternative` class attribute is declared in the PcapNg\n        variant, and set here to the Pcap variant.\n\n        \"\"\"\n        newcls = super(PcapReader_metaclass, cls).__new__(cls, name, bases, dct)  # noqa: E501\n        if 'alternative' in dct:\n            dct['alternative'].alternative = newcls\n        return newcls\n\n    def __call__(cls, filename):\n        \"\"\"Creates a cls instance, use the `alternative` if that\n        fails.\n\n        \"\"\"\n        i = cls.__new__(cls, cls.__name__, cls.__bases__, cls.__dict__)\n        filename, fdesc, magic = cls.open(filename)\n        if not magic:\n            raise Scapy_Exception(\n                \"No data could be read!\"\n            )\n        try:\n            i.__init__(filename, fdesc, magic)\n        except Scapy_Exception:\n            if \"alternative\" in cls.__dict__:\n                cls = cls.__dict__[\"alternative\"]\n                i = cls.__new__(cls, cls.__name__, cls.__bases__, cls.__dict__)\n                try:\n                    i.__init__(filename, fdesc, magic)\n                except Scapy_Exception:\n                    try:\n                        i.f.seek(-4, 1)\n                    except Exception:\n                        pass\n                    raise Scapy_Exception(\"Not a supported capture file\")\n\n        return i\n\n    @staticmethod\n    def open(filename):\n        \"\"\"Open (if necessary) filename, and read the magic.\"\"\"\n        if isinstance(filename, six.string_types):\n            try:\n                fdesc = gzip.open(filename, \"rb\")\n                magic = fdesc.read(4)\n            except IOError:\n                fdesc = open(filename, \"rb\")\n                magic = fdesc.read(4)\n        else:\n            fdesc = filename\n            filename = getattr(fdesc, \"name\", \"No name\")\n            magic = fdesc.read(4)\n        return filename, fdesc, magic\n\n\nclass RawPcapReader(six.with_metaclass(PcapReader_metaclass)):\n    \"\"\"A stateful pcap reader. Each packet is returned as a string\"\"\"\n\n    nonblocking_socket = True\n    PacketMetadata = collections.namedtuple(\"PacketMetadata\",\n                                            [\"sec\", \"usec\", \"wirelen\", \"caplen\"])  # noqa: E501\n\n    def __init__(self, filename, fdesc, magic):\n        self.filename = filename\n        self.f = fdesc\n        if magic == b\"\\xa1\\xb2\\xc3\\xd4\":  # big endian\n            self.endian = \">\"\n            self.nano = False\n        elif magic == b\"\\xd4\\xc3\\xb2\\xa1\":  # little endian\n            self.endian = \"<\"\n            self.nano = False\n        elif magic == b\"\\xa1\\xb2\\x3c\\x4d\":  # big endian, nanosecond-precision\n            self.endian = \">\"\n            self.nano = True\n        elif magic == b\"\\x4d\\x3c\\xb2\\xa1\":  # little endian, nanosecond-precision  # noqa: E501\n            self.endian = \"<\"\n            self.nano = True\n        else:\n            raise Scapy_Exception(\n                \"Not a pcap capture file (bad magic: %r)\" % magic\n            )\n        hdr = self.f.read(20)\n        if len(hdr) < 20:\n            raise Scapy_Exception(\"Invalid pcap file (too short)\")\n        vermaj, vermin, tz, sig, snaplen, linktype = struct.unpack(\n            self.endian + \"HHIIII\", hdr\n        )\n        self.linktype = linktype\n        self.snaplen = snaplen\n\n    def __iter__(self):\n        return self\n\n    def next(self):\n        \"\"\"implement the iterator protocol on a set of packets in a pcap file\n        pkt is a tuple (pkt_data, pkt_metadata) as defined in\n        RawPcapReader.read_packet()\n\n        \"\"\"\n        try:\n            return self.read_packet()\n        except EOFError:\n            raise StopIteration\n    __next__ = next\n\n    def read_packet(self, size=MTU):\n        \"\"\"return a single packet read from the file as a tuple containing\n        (pkt_data, pkt_metadata)\n\n        raise EOFError when no more packets are available\n        \"\"\"\n        hdr = self.f.read(16)\n        if len(hdr) < 16:\n            raise EOFError\n        sec, usec, caplen, wirelen = struct.unpack(self.endian + \"IIII\", hdr)\n        return (self.f.read(caplen)[:size],\n                RawPcapReader.PacketMetadata(sec=sec, usec=usec,\n                                             wirelen=wirelen, caplen=caplen))\n\n    def dispatch(self, callback):\n        \"\"\"call the specified callback routine for each packet read\n\n        This is just a convenience function for the main loop\n        that allows for easy launching of packet processing in a\n        thread.\n        \"\"\"\n        for p in self:\n            callback(p)\n\n    def read_all(self, count=-1):\n        \"\"\"return a list of all packets in the pcap file\n        \"\"\"\n        res = []\n        while count != 0:\n            count -= 1\n            try:\n                p = self.read_packet()\n            except EOFError:\n                break\n            res.append(p)\n        return res\n\n    def recv(self, size=MTU):\n        \"\"\" Emulate a socket\n        \"\"\"\n        return self.read_packet(size=size)[0]\n\n    def fileno(self):\n        return self.f.fileno()\n\n    def close(self):\n        return self.f.close()\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_value, tracback):\n        self.close()\n\n    # emulate SuperSocket\n    @staticmethod\n    def select(sockets, remain=None):\n        return sockets, None\n\n\nclass PcapReader(RawPcapReader):\n    def __init__(self, filename, fdesc, magic):\n        RawPcapReader.__init__(self, filename, fdesc, magic)\n        try:\n            self.LLcls = conf.l2types[self.linktype]\n        except KeyError:\n            warning(\"PcapReader: unknown LL type [%i]/[%#x]. Using Raw packets\" % (self.linktype, self.linktype))  # noqa: E501\n            if conf.raw_layer is None:\n                # conf.raw_layer is set on import\n                import scapy.packet  # noqa: F401\n            self.LLcls = conf.raw_layer\n\n    def read_packet(self, size=MTU):\n        rp = super(PcapReader, self).read_packet(size=size)\n        if rp is None:\n            raise EOFError\n        s, pkt_info = rp\n\n        try:\n            p = self.LLcls(s)\n        except KeyboardInterrupt:\n            raise\n        except Exception:\n            if conf.debug_dissector:\n                from scapy.sendrecv import debug\n                debug.crashed_on = (self.LLcls, s)\n                raise\n            if conf.raw_layer is None:\n                # conf.raw_layer is set on import\n                import scapy.packet  # noqa: F401\n            p = conf.raw_layer(s)\n        power = Decimal(10) ** Decimal(-9 if self.nano else -6)\n        p.time = EDecimal(pkt_info.sec + power * pkt_info.usec)\n        p.wirelen = pkt_info.wirelen\n        return p\n\n    def read_all(self, count=-1):\n        res = RawPcapReader.read_all(self, count)\n        from scapy import plist\n        return plist.PacketList(res, name=os.path.basename(self.filename))\n\n    def recv(self, size=MTU):\n        return self.read_packet(size=size)\n\n\nclass RawPcapNgReader(RawPcapReader):\n    \"\"\"A stateful pcapng reader. Each packet is returned as\n    bytes.\n\n    \"\"\"\n\n    alternative = RawPcapReader\n\n    PacketMetadata = collections.namedtuple(\"PacketMetadata\",\n                                            [\"linktype\", \"tsresol\",\n                                             \"tshigh\", \"tslow\", \"wirelen\"])\n\n    def __init__(self, filename, fdesc, magic):\n        self.filename = filename\n        self.f = fdesc\n        # A list of (linktype, snaplen, tsresol); will be populated by IDBs.\n        self.interfaces = []\n        self.default_options = {\n            \"tsresol\": 1000000\n        }\n        self.blocktypes = {\n            1: self.read_block_idb,\n            2: self.read_block_pkt,\n            3: self.read_block_spb,\n            6: self.read_block_epb,\n        }\n        if magic != b\"\\x0a\\x0d\\x0d\\x0a\":  # PcapNg:\n            raise Scapy_Exception(\n                \"Not a pcapng capture file (bad magic: %r)\" % magic\n            )\n        # see https://github.com/pcapng/pcapng\n        blocklen, magic = self.f.read(4), self.f.read(4)  # noqa: F841\n        if magic == b\"\\x1a\\x2b\\x3c\\x4d\":\n            self.endian = \">\"\n        elif magic == b\"\\x4d\\x3c\\x2b\\x1a\":\n            self.endian = \"<\"\n        else:\n            raise Scapy_Exception(\"Not a pcapng capture file (bad magic)\")\n        self.f.read(12)\n        blocklen = struct.unpack(\"!I\", blocklen)[0]\n        # Read default options\n        self.default_options = self.read_options(\n            self.f.read(blocklen - 24)\n        )\n        try:\n            self.f.seek(0)\n        except Exception:\n            pass\n\n    def read_packet(self, size=MTU):\n        \"\"\"Read blocks until it reaches either EOF or a packet, and\n        returns None or (packet, (linktype, sec, usec, wirelen)),\n        where packet is a string.\n\n        \"\"\"\n        while True:\n            try:\n                blocktype, blocklen = struct.unpack(self.endian + \"2I\",\n                                                    self.f.read(8))\n            except struct.error:\n                raise EOFError\n            block = self.f.read(blocklen - 12)\n            if blocklen % 4:\n                pad = self.f.read(4 - (blocklen % 4))\n                warning(\"PcapNg: bad blocklen %d (MUST be a multiple of 4. \"\n                        \"Ignored padding %r\" % (blocklen, pad))\n            try:\n                if (blocklen,) != struct.unpack(self.endian + 'I',\n                                                self.f.read(4)):\n                    warning(\"PcapNg: Invalid pcapng block (bad blocklen)\")\n                    raise EOFError\n            except struct.error:\n                raise EOFError\n            res = self.blocktypes.get(blocktype,\n                                      lambda block, size: None)(block, size)\n            if res is not None:\n                return res\n\n    def read_options(self, options):\n        \"\"\"Section Header Block\"\"\"\n        opts = self.default_options.copy()\n        while len(options) >= 4:\n            code, length = struct.unpack(self.endian + \"HH\", options[:4])\n            # PCAP Next Generation (pcapng) Capture File Format\n            # 4.2. - Interface Description Block\n            # http://xml2rfc.tools.ietf.org/cgi-bin/xml2rfc.cgi?url=https://raw.githubusercontent.com/pcapng/pcapng/master/draft-tuexen-opsawg-pcapng.xml&modeAsFormat=html/ascii&type=ascii#rfc.section.4.2\n            if code == 9 and length == 1 and len(options) >= 5:\n                tsresol = orb(options[4])\n                opts[\"tsresol\"] = (2 if tsresol & 128 else 10) ** (\n                    tsresol & 127\n                )\n            if code == 0:\n                if length != 0:\n                    warning(\"PcapNg: invalid option length %d for end-of-option\" % length)  # noqa: E501\n                break\n            if length % 4:\n                length += (4 - (length % 4))\n            options = options[4 + length:]\n        return opts\n\n    def read_block_idb(self, block, _):\n        \"\"\"Interface Description Block\"\"\"\n        options = self.read_options(block[16:])\n        self.interfaces.append(struct.unpack(self.endian + \"HxxI\", block[:8]) +\n                               (options[\"tsresol\"],))\n\n    def read_block_epb(self, block, size):\n        \"\"\"Enhanced Packet Block\"\"\"\n        intid, tshigh, tslow, caplen, wirelen = struct.unpack(\n            self.endian + \"5I\",\n            block[:20],\n        )\n        return (block[20:20 + caplen][:size],\n                RawPcapNgReader.PacketMetadata(linktype=self.interfaces[intid][0],  # noqa: E501\n                                               tsresol=self.interfaces[intid][2],  # noqa: E501\n                                               tshigh=tshigh,\n                                               tslow=tslow,\n                                               wirelen=wirelen))\n\n    def read_block_spb(self, block, size):\n        \"\"\"Simple Packet Block\"\"\"\n        # \"it MUST be assumed that all the Simple Packet Blocks have\n        # been captured on the interface previously specified in the\n        # first Interface Description Block.\"\n        intid = 0\n        wirelen, = struct.unpack(self.endian + \"I\", block[:4])\n        caplen = min(wirelen, self.interfaces[intid][1])\n        return (block[4:4 + caplen][:size],\n                RawPcapNgReader.PacketMetadata(linktype=self.interfaces[intid][0],  # noqa: E501\n                                               tsresol=self.interfaces[intid][2],  # noqa: E501\n                                               tshigh=None,\n                                               tslow=None,\n                                               wirelen=wirelen))\n\n    def read_block_pkt(self, block, size):\n        \"\"\"(Obsolete) Packet Block\"\"\"\n        intid, drops, tshigh, tslow, caplen, wirelen = struct.unpack(\n            self.endian + \"HH4I\",\n            block[:20],\n        )\n        return (block[20:20 + caplen][:size],\n                RawPcapNgReader.PacketMetadata(linktype=self.interfaces[intid][0],  # noqa: E501\n                                               tsresol=self.interfaces[intid][2],  # noqa: E501\n                                               tshigh=tshigh,\n                                               tslow=tslow,\n                                               wirelen=wirelen))\n\n\nclass PcapNgReader(RawPcapNgReader):\n\n    alternative = PcapReader\n\n    def __init__(self, filename, fdesc, magic):\n        RawPcapNgReader.__init__(self, filename, fdesc, magic)\n\n    def read_packet(self, size=MTU):\n        rp = super(PcapNgReader, self).read_packet(size=size)\n        if rp is None:\n            raise EOFError\n        s, (linktype, tsresol, tshigh, tslow, wirelen) = rp\n        try:\n            p = conf.l2types[linktype](s)\n        except KeyboardInterrupt:\n            raise\n        except Exception:\n            if conf.debug_dissector:\n                raise\n            if conf.raw_layer is None:\n                # conf.raw_layer is set on import\n                import scapy.packet  # noqa: F401\n            p = conf.raw_layer(s)\n        if tshigh is not None:\n            p.time = EDecimal((tshigh << 32) + tslow) / tsresol\n        p.wirelen = wirelen\n        return p\n\n    def read_all(self, count=-1):\n        res = RawPcapNgReader.read_all(self, count)\n        from scapy import plist\n        return plist.PacketList(res, name=os.path.basename(self.filename))\n\n    def recv(self, size=MTU):\n        return self.read_packet()\n\n\nclass RawPcapWriter:\n    \"\"\"A stream PCAP writer with more control than wrpcap()\"\"\"\n\n    def __init__(self, filename, linktype=None, gz=False, endianness=\"\",\n                 append=False, sync=False, nano=False, snaplen=MTU):\n        \"\"\"\n        :param filename: the name of the file to write packets to, or an open,\n            writable file-like object.\n        :param linktype: force linktype to a given value. If None, linktype is\n            taken from the first writer packet\n        :param gz: compress the capture on the fly\n        :param endianness: force an endianness (little:\"<\", big:\">\").\n            Default is native\n        :param append: append packets to the capture file instead of\n            truncating it\n        :param sync: do not bufferize writes to the capture file\n        :param nano: use nanosecond-precision (requires libpcap >= 1.5.0)\n\n        \"\"\"\n\n        self.linktype = linktype\n        self.snaplen = snaplen\n        self.header_present = 0\n        self.append = append\n        self.gz = gz\n        self.endian = endianness\n        self.sync = sync\n        self.nano = nano\n        bufsz = 4096\n        if sync:\n            bufsz = 0\n\n        if isinstance(filename, six.string_types):\n            self.filename = filename\n            self.f = [open, gzip.open][gz](filename, append and \"ab\" or \"wb\", gz and 9 or bufsz)  # noqa: E501\n        else:\n            self.f = filename\n            self.filename = getattr(filename, \"name\", \"No name\")\n\n    def fileno(self):\n        return self.f.fileno()\n\n    def _write_header(self, pkt):\n        self.header_present = 1\n\n        if self.append:\n            # Even if prone to race conditions, this seems to be\n            # safest way to tell whether the header is already present\n            # because we have to handle compressed streams that\n            # are not as flexible as basic files\n            g = [open, gzip.open][self.gz](self.filename, \"rb\")\n            if g.read(16):\n                return\n\n        self.f.write(struct.pack(self.endian + \"IHHIIII\", 0xa1b23c4d if self.nano else 0xa1b2c3d4,  # noqa: E501\n                                 2, 4, 0, 0, self.snaplen, self.linktype))\n        self.f.flush()\n\n    def write(self, pkt):\n        \"\"\"\n        Writes a Packet, a SndRcvList object, or bytes to a pcap file.\n\n        :param pkt: Packet(s) to write (one record for each Packet), or raw\n                    bytes to write (as one record).\n        :type pkt: iterable[scapy.packet.Packet], scapy.packet.Packet or bytes\n        \"\"\"\n        if isinstance(pkt, bytes):\n            if not self.header_present:\n                self._write_header(pkt)\n            self._write_packet(pkt)\n        else:\n            # Import here to avoid a circular dependency\n            from scapy.plist import SndRcvList\n            if isinstance(pkt, SndRcvList):\n                def _iter(pkt=pkt):\n                    for s, r in pkt:\n                        if s.sent_time:\n                            s.time = s.sent_time\n                        yield s\n                        yield r\n                pkt = _iter()\n            else:\n                pkt = pkt.__iter__()\n            for p in pkt:\n\n                if not self.header_present:\n                    self._write_header(p)\n\n                if self.linktype != conf.l2types.get(type(p), None):\n                    warning(\"Inconsistent linktypes detected!\"\n                            \" The resulting PCAP file might contain\"\n                            \" invalid packets.\"\n                            )\n\n                self._write_packet(p)\n\n    def _write_packet(self, packet, sec=None, usec=None, caplen=None,\n                      wirelen=None):\n        \"\"\"\n        Writes a single packet to the pcap file.\n\n        :param packet: bytes for a single packet\n        :type packet: bytes\n        :param sec: time the packet was captured, in seconds since epoch. If\n                    not supplied, defaults to now.\n        :type sec: int or long\n        :param usec: If ``nano=True``, then number of nanoseconds after the\n                     second that the packet was captured. If ``nano=False``,\n                     then the number of microseconds after the second the\n                     packet was captured\n        :type usec: int or long\n        :param caplen: The length of the packet in the capture file. If not\n                       specified, uses ``len(packet)``.\n        :type caplen: int\n        :param wirelen: The length of the packet on the wire. If not\n                        specified, uses ``caplen``.\n        :type wirelen: int\n        :return: None\n        :rtype: None\n        \"\"\"\n        if caplen is None:\n            caplen = len(packet)\n        if wirelen is None:\n            wirelen = caplen\n        if sec is None or usec is None:\n            t = time.time()\n            it = int(t)\n            if sec is None:\n                sec = it\n                usec = int(round((t - it) *\n                                 (1000000000 if self.nano else 1000000)))\n            elif usec is None:\n                usec = 0\n\n        self.f.write(struct.pack(self.endian + \"IIII\",\n                                 sec, usec, caplen, wirelen))\n        self.f.write(packet)\n        if self.sync:\n            self.f.flush()\n\n    def flush(self):\n        return self.f.flush()\n\n    def close(self):\n        if not self.header_present:\n            self._write_header(None)\n        return self.f.close()\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_value, tracback):\n        self.flush()\n        self.close()\n\n\nclass PcapWriter(RawPcapWriter):\n    \"\"\"A stream PCAP writer with more control than wrpcap()\"\"\"\n\n    def _write_header(self, pkt):\n        if self.linktype is None:\n            try:\n                self.linktype = conf.l2types[pkt.__class__]\n                # Import here to prevent import loops\n                from scapy.layers.inet import IP\n                from scapy.layers.inet6 import IPv6\n                if OPENBSD and isinstance(pkt, (IP, IPv6)):\n                    self.linktype = 14  # DLT_RAW\n            except KeyError:\n                warning(\"PcapWriter: unknown LL type for %s. Using type 1 (Ethernet)\", pkt.__class__.__name__)  # noqa: E501\n                self.linktype = DLT_EN10MB\n        RawPcapWriter._write_header(self, pkt)\n\n    def _write_packet(self, packet, sec=None, usec=None, caplen=None,\n                      wirelen=None):\n        \"\"\"\n        Writes a single packet to the pcap file.\n\n        :param packet: Packet, or bytes for a single packet\n        :type packet: scapy.packet.Packet or bytes\n        :param sec: time the packet was captured, in seconds since epoch. If\n                    not supplied, defaults to now.\n        :type sec: int or long\n        :param usec: If ``nano=True``, then number of nanoseconds after the\n                     second that the packet was captured. If ``nano=False``,\n                     then the number of microseconds after the second the\n                     packet was captured. If ``sec`` is not specified,\n                     this value is ignored.\n        :type usec: int or long\n        :param caplen: The length of the packet in the capture file. If not\n                       specified, uses ``len(raw(packet))``.\n        :type caplen: int\n        :param wirelen: The length of the packet on the wire. If not\n                        specified, tries ``packet.wirelen``, otherwise uses\n                        ``caplen``.\n        :type wirelen: int\n        :return: None\n        :rtype: None\n        \"\"\"\n        if hasattr(packet, \"time\"):\n            if sec is None:\n                sec = int(packet.time)\n                usec = int(round((packet.time - sec) *\n                                 (1000000000 if self.nano else 1000000)))\n        if usec is None:\n            usec = 0\n\n        rawpkt = raw(packet)\n        caplen = len(rawpkt) if caplen is None else caplen\n\n        if wirelen is None:\n            if hasattr(packet, \"wirelen\"):\n                wirelen = packet.wirelen\n        if wirelen is None:\n            wirelen = caplen\n\n        RawPcapWriter._write_packet(\n            self, rawpkt, sec=sec, usec=usec, caplen=caplen, wirelen=wirelen)\n\n\n@conf.commands.register\ndef import_hexcap(input_string=None):\n    \"\"\"Imports a tcpdump like hexadecimal view\n\n    e.g: exported via hexdump() or tcpdump or wireshark's \"export as hex\"\n\n    :param input_string: String containing the hexdump input to parse. If None,\n        read from standard input.\n    \"\"\"\n    re_extract_hexcap = re.compile(r\"^((0x)?[0-9a-fA-F]{2,}[ :\\t]{,3}|) *(([0-9a-fA-F]{2} {,2}){,16})\")  # noqa: E501\n    p = \"\"\n    try:\n        if input_string:\n            input_function = six.StringIO(input_string).readline\n        else:\n            input_function = input\n        while True:\n            line = input_function().strip()\n            if not line:\n                break\n            try:\n                p += re_extract_hexcap.match(line).groups()[2]\n            except Exception:\n                warning(\"Parsing error during hexcap\")\n                continue\n    except EOFError:\n        pass\n\n    p = p.replace(\" \", \"\")\n    return hex_bytes(p)\n\n\n@conf.commands.register\ndef wireshark(pktlist, wait=False, **kwargs):\n    \"\"\"\n    Runs Wireshark on a list of packets.\n\n    See :func:`tcpdump` for more parameter description.\n\n    Note: this defaults to wait=False, to run Wireshark in the background.\n    \"\"\"\n    return tcpdump(pktlist, prog=conf.prog.wireshark, wait=wait, **kwargs)\n\n\n@conf.commands.register\ndef tdecode(pktlist, args=None, **kwargs):\n    \"\"\"\n    Run tshark on a list of packets.\n\n    :param args: If not specified, defaults to ``tshark -V``.\n\n    See :func:`tcpdump` for more parameters.\n    \"\"\"\n    if args is None:\n        args = [\"-V\"]\n    return tcpdump(pktlist, prog=conf.prog.tshark, args=args, **kwargs)\n\n\ndef _guess_linktype_name(value):\n    \"\"\"Guess the DLT name from its value.\"\"\"\n    import scapy.data\n    return next(\n        k[4:] for k, v in six.iteritems(scapy.data.__dict__)\n        if k.startswith(\"DLT\") and v == value\n    )\n\n\ndef _guess_linktype_value(name):\n    \"\"\"Guess the value of a DLT name.\"\"\"\n    import scapy.data\n    if not name.startswith(\"DLT_\"):\n        name = \"DLT_\" + name\n    return scapy.data.__dict__[name]\n\n\n@conf.commands.register\ndef tcpdump(pktlist=None, dump=False, getfd=False, args=None, flt=None,\n            prog=None, getproc=False, quiet=False, use_tempfile=None,\n            read_stdin_opts=None, linktype=None, wait=True,\n            _suppress=False):\n    \"\"\"Run tcpdump or tshark on a list of packets.\n\n    When using ``tcpdump`` on OSX (``prog == conf.prog.tcpdump``), this uses a\n    temporary file to store the packets. This works around a bug in Apple's\n    version of ``tcpdump``: http://apple.stackexchange.com/questions/152682/\n\n    Otherwise, the packets are passed in stdin.\n\n    This function can be explicitly enabled or disabled with the\n    ``use_tempfile`` parameter.\n\n    When using ``wireshark``, it will be called with ``-ki -`` to start\n    immediately capturing packets from stdin.\n\n    Otherwise, the command will be run with ``-r -`` (which is correct for\n    ``tcpdump`` and ``tshark``).\n\n    This can be overridden with ``read_stdin_opts``. This has no effect when\n    ``use_tempfile=True``, or otherwise reading packets from a regular file.\n\n    :param pktlist: a Packet instance, a PacketList instance or a list of\n        Packet instances. Can also be a filename (as a string), an open\n        file-like object that must be a file format readable by\n        tshark (Pcap, PcapNg, etc.) or None (to sniff)\n    :param flt: a filter to use with tcpdump\n    :param dump:    when set to True, returns a string instead of displaying it.\n    :param getfd:   when set to True, returns a file-like object to read data\n        from tcpdump or tshark from.\n    :param getproc: when set to True, the subprocess.Popen object is returned\n    :param args:    arguments (as a list) to pass to tshark (example for tshark:\n        args=[\"-T\", \"json\"]).\n    :param prog:    program to use (defaults to tcpdump, will work with tshark)\n    :param quiet:   when set to True, the process stderr is discarded\n    :param use_tempfile: When set to True, always use a temporary file to store\n        packets.\n        When set to False, pipe packets through stdin.\n        When set to None (default), only use a temporary file with\n        ``tcpdump`` on OSX.\n    :param read_stdin_opts: When set, a list of arguments needed to capture\n        from stdin. Otherwise, attempts to guess.\n    :param linktype: A custom DLT value or name, to overwrite the default\n        values.\n    :param wait: If True (default), waits for the process to terminate before\n        returning to Scapy. If False, the process will be detached to the\n        background. If dump, getproc or getfd is True, these have the same\n        effect as ``wait=False``.\n\n    Examples::\n\n        >>> tcpdump([IP()/TCP(), IP()/UDP()])\n        reading from file -, link-type RAW (Raw IP)\n        16:46:00.474515 IP 127.0.0.1.20 > 127.0.0.1.80: Flags [S], seq 0, win 8192, length 0  # noqa: E501\n        16:46:00.475019 IP 127.0.0.1.53 > 127.0.0.1.53: [|domain]\n\n        >>> tcpdump([IP()/TCP(), IP()/UDP()], prog=conf.prog.tshark)\n          1   0.000000    127.0.0.1 -> 127.0.0.1    TCP 40 20->80 [SYN] Seq=0 Win=8192 Len=0  # noqa: E501\n          2   0.000459    127.0.0.1 -> 127.0.0.1    UDP 28 53->53 Len=0\n\n    To get a JSON representation of a tshark-parsed PacketList(), one can::\n\n        >>> import json, pprint\n        >>> json_data = json.load(tcpdump(IP(src=\"217.25.178.5\",\n        ...                                  dst=\"45.33.32.156\"),\n        ...                               prog=conf.prog.tshark,\n        ...                               args=[\"-T\", \"json\"],\n        ...                               getfd=True))\n        >>> pprint.pprint(json_data)\n        [{u'_index': u'packets-2016-12-23',\n          u'_score': None,\n          u'_source': {u'layers': {u'frame': {u'frame.cap_len': u'20',\n                                              u'frame.encap_type': u'7',\n        [...]\n                                              },\n                                   u'ip': {u'ip.addr': u'45.33.32.156',\n                                           u'ip.checksum': u'0x0000a20d',\n        [...]\n                                           u'ip.ttl': u'64',\n                                           u'ip.version': u'4'},\n                                   u'raw': u'Raw packet data'}},\n          u'_type': u'pcap_file'}]\n        >>> json_data[0]['_source']['layers']['ip']['ip.ttl']\n        u'64'\n    \"\"\"\n    getfd = getfd or getproc\n    if prog is None:\n        if not conf.prog.tcpdump:\n            raise Scapy_Exception(\n                \"tcpdump is not available\"\n            )\n        prog = [conf.prog.tcpdump]\n    elif isinstance(prog, six.string_types):\n        prog = [prog]\n    else:\n        raise ValueError(\"prog must be a string\")\n\n    if linktype is not None:\n        # Tcpdump does not support integers in -y (yet)\n        # https://github.com/the-tcpdump-group/tcpdump/issues/758\n        if isinstance(linktype, int):\n            # Guess name from value\n            try:\n                linktype_name = _guess_linktype_name(linktype)\n            except StopIteration:\n                linktype = -1\n        else:\n            # Guess value from name\n            if linktype.startswith(\"DLT_\"):\n                linktype = linktype[4:]\n            linktype_name = linktype\n            try:\n                linktype = _guess_linktype_value(linktype)\n            except KeyError:\n                linktype = -1\n        if linktype == -1:\n            raise ValueError(\n                \"Unknown linktype. Try passing its datalink name instead\"\n            )\n        prog += [\"-y\", linktype_name]\n\n    # Build Popen arguments\n    if args is None:\n        args = []\n    else:\n        # Make a copy of args\n        args = list(args)\n\n    if flt is not None:\n        # Check the validity of the filter\n        from scapy.arch.common import compile_filter\n        compile_filter(flt)\n        args.append(flt)\n\n    stdout = subprocess.PIPE if dump or getfd else None\n    stderr = open(os.devnull) if quiet else None\n    proc = None\n\n    if use_tempfile is None:\n        # Apple's tcpdump cannot read from stdin, see:\n        # http://apple.stackexchange.com/questions/152682/\n        use_tempfile = DARWIN and prog[0] == conf.prog.tcpdump\n\n    if read_stdin_opts is None:\n        if prog[0] == conf.prog.wireshark:\n            # Start capturing immediately (-k) from stdin (-i -)\n            read_stdin_opts = [\"-ki\", \"-\"]\n        elif prog[0] == conf.prog.tcpdump:\n            # Capture in packet-buffered mode (-U) from stdin (-r -)\n            read_stdin_opts = [\"-U\", \"-r\", \"-\"]\n        else:\n            read_stdin_opts = [\"-r\", \"-\"]\n    else:\n        # Make a copy of read_stdin_opts\n        read_stdin_opts = list(read_stdin_opts)\n\n    if pktlist is None:\n        # sniff\n        with ContextManagerSubprocess(prog[0], suppress=_suppress):\n            proc = subprocess.Popen(\n                prog + args,\n                stdout=stdout,\n                stderr=stderr,\n            )\n    elif isinstance(pktlist, six.string_types):\n        # file\n        with ContextManagerSubprocess(prog[0], suppress=_suppress):\n            proc = subprocess.Popen(\n                prog + [\"-r\", pktlist] + args,\n                stdout=stdout,\n                stderr=stderr,\n            )\n    elif use_tempfile:\n        tmpfile = get_temp_file(autoext=\".pcap\", fd=True)\n        try:\n            tmpfile.writelines(iter(lambda: pktlist.read(1048576), b\"\"))\n        except AttributeError:\n            wrpcap(tmpfile, pktlist, linktype=linktype)\n        else:\n            tmpfile.close()\n        with ContextManagerSubprocess(prog[0], suppress=_suppress):\n            proc = subprocess.Popen(\n                prog + [\"-r\", tmpfile.name] + args,\n                stdout=stdout,\n                stderr=stderr,\n            )\n    else:\n        try:\n            pktlist.fileno()\n            # pass the packet stream\n            with ContextManagerSubprocess(prog[0], suppress=_suppress):\n                proc = subprocess.Popen(\n                    prog + read_stdin_opts + args,\n                    stdin=pktlist,\n                    stdout=stdout,\n                    stderr=stderr,\n                )\n        except (AttributeError, ValueError):\n            # write the packet stream to stdin\n            with ContextManagerSubprocess(prog[0], suppress=_suppress):\n                proc = subprocess.Popen(\n                    prog + read_stdin_opts + args,\n                    stdin=subprocess.PIPE,\n                    stdout=stdout,\n                    stderr=stderr,\n                )\n            if proc is None:\n                # An error has occurred\n                return\n            try:\n                proc.stdin.writelines(iter(lambda: pktlist.read(1048576), b\"\"))\n            except AttributeError:\n                wrpcap(proc.stdin, pktlist, linktype=linktype)\n            except UnboundLocalError:\n                # The error was handled by ContextManagerSubprocess\n                pass\n            else:\n                proc.stdin.close()\n    if proc is None:\n        # An error has occurred\n        return\n    if dump:\n        return b\"\".join(iter(lambda: proc.stdout.read(1048576), b\"\"))\n    if getproc:\n        return proc\n    if getfd:\n        return proc.stdout\n    if wait:\n        proc.wait()\n\n\n@conf.commands.register\ndef hexedit(pktlist):\n    \"\"\"Run hexedit on a list of packets, then return the edited packets.\"\"\"\n    f = get_temp_file()\n    wrpcap(f, pktlist)\n    with ContextManagerSubprocess(conf.prog.hexedit):\n        subprocess.call([conf.prog.hexedit, f])\n    pktlist = rdpcap(f)\n    os.unlink(f)\n    return pktlist\n\n\ndef get_terminal_width():\n    \"\"\"Get terminal width (number of characters) if in a window.\n\n    Notice: this will try several methods in order to\n    support as many terminals and OS as possible.\n    \"\"\"\n    # Let's first try using the official API\n    # (Python 3.3+)\n    if not six.PY2:\n        import shutil\n        sizex = shutil.get_terminal_size(fallback=(0, 0))[0]\n        if sizex != 0:\n            return sizex\n    # Backups / Python 2.7\n    if WINDOWS:\n        from ctypes import windll, create_string_buffer\n        # http://code.activestate.com/recipes/440694-determine-size-of-console-window-on-windows/\n        h = windll.kernel32.GetStdHandle(-12)\n        csbi = create_string_buffer(22)\n        res = windll.kernel32.GetConsoleScreenBufferInfo(h, csbi)\n        if res:\n            (bufx, bufy, curx, cury, wattr,\n             left, top, right, bottom, maxx, maxy) = struct.unpack(\"hhhhHhhhhhh\", csbi.raw)  # noqa: E501\n            sizex = right - left + 1\n            # sizey = bottom - top + 1\n            return sizex\n        return None\n    else:\n        # We have various methods\n        sizex = None\n        # COLUMNS is set on some terminals\n        try:\n            sizex = int(os.environ['COLUMNS'])\n        except Exception:\n            pass\n        if sizex:\n            return sizex\n        # We can query TIOCGWINSZ\n        try:\n            import fcntl\n            import termios\n            s = struct.pack('HHHH', 0, 0, 0, 0)\n            x = fcntl.ioctl(1, termios.TIOCGWINSZ, s)\n            sizex = struct.unpack('HHHH', x)[1]\n        except IOError:\n            pass\n        return sizex\n\n\ndef pretty_list(rtlst, header, sortBy=0, borders=False):\n    \"\"\"\n    Pretty list to fit the terminal, and add header.\n\n    :param rtlst: a list of tuples. each tuple contains a value which can\n        be either a string or a list of string.\n    :param sortBy: the column id (starting with 0) which whill be used for\n        ordering\n    :param borders: whether to put borders on the table or not\n    \"\"\"\n    if borders:\n        _space = \"|\"\n    else:\n        _space = \"  \"\n    cols = len(header[0])\n    # Windows has a fat terminal border\n    _spacelen = len(_space) * (cols - 1) + int(WINDOWS)\n    _croped = False\n    # Sort correctly\n    rtlst.sort(key=lambda x: x[sortBy])\n    # Resolve multi-values\n    for i, line in enumerate(rtlst):\n        ids = []\n        values = []\n        for j, val in enumerate(line):\n            if isinstance(val, list):\n                ids.append(j)\n                values.append(val or \" \")\n        if values:\n            del rtlst[i]\n            k = 0\n            for ex_vals in zip_longest(*values, fillvalue=\" \"):\n                extra_line = ([\" \"] * cols) if k else list(line)\n                for j, h in enumerate(ids):\n                    extra_line[h] = ex_vals[j]\n                rtlst.insert(i + k, tuple(extra_line))\n                k += 1\n    # Append tag\n    rtlst = header + rtlst\n    # Detect column's width\n    colwidth = [max(len(y) for y in x) for x in zip(*rtlst)]\n    # Make text fit in box (if required)\n    width = get_terminal_width()\n    if conf.auto_crop_tables and width:\n        width = width - _spacelen\n        while sum(colwidth) > width:\n            _croped = True\n            # Needs to be cropped\n            # Get the longest row\n            i = colwidth.index(max(colwidth))\n            # Get all elements of this row\n            row = [len(x[i]) for x in rtlst]\n            # Get biggest element of this row: biggest of the array\n            j = row.index(max(row))\n            # Re-build column tuple with the edited element\n            t = list(rtlst[j])\n            t[i] = t[i][:-2] + \"_\"\n            rtlst[j] = tuple(t)\n            # Update max size\n            row[j] = len(t[i])\n            colwidth[i] = max(row)\n    if _croped:\n        log_runtime.info(\"Table cropped to fit the terminal (conf.auto_crop_tables==True)\")  # noqa: E501\n    # Generate padding scheme\n    fmt = _space.join([\"%%-%ds\" % x for x in colwidth])\n    # Append separation line if needed\n    if borders:\n        rtlst.insert(1, tuple(\"-\" * x for x in colwidth))\n    # Compile\n    return \"\\n\".join(fmt % x for x in rtlst)\n\n\ndef __make_table(yfmtfunc, fmtfunc, endline, data, fxyz, sortx=None, sorty=None, seplinefunc=None, dump=False):  # noqa: E501\n    \"\"\"Core function of the make_table suite, which generates the table\"\"\"\n    vx = {}\n    vy = {}\n    vz = {}\n    vxf = {}\n\n    # Python 2 backward compatibility\n    fxyz = lambda_tuple_converter(fxyz)\n\n    tmp_len = 0\n    for e in data:\n        xx, yy, zz = [str(s) for s in fxyz(*e)]\n        tmp_len = max(len(yy), tmp_len)\n        vx[xx] = max(vx.get(xx, 0), len(xx), len(zz))\n        vy[yy] = None\n        vz[(xx, yy)] = zz\n\n    vxk = list(vx)\n    vyk = list(vy)\n    if sortx:\n        vxk.sort(key=sortx)\n    else:\n        try:\n            vxk.sort(key=int)\n        except Exception:\n            try:\n                vxk.sort(key=atol)\n            except Exception:\n                vxk.sort()\n    if sorty:\n        vyk.sort(key=sorty)\n    else:\n        try:\n            vyk.sort(key=int)\n        except Exception:\n            try:\n                vyk.sort(key=atol)\n            except Exception:\n                vyk.sort()\n\n    s = \"\"\n    if seplinefunc:\n        sepline = seplinefunc(tmp_len, [vx[x] for x in vxk])\n        s += sepline + \"\\n\"\n\n    fmt = yfmtfunc(tmp_len)\n    s += fmt % \"\"\n    s += ' '\n    for x in vxk:\n        vxf[x] = fmtfunc(vx[x])\n        s += vxf[x] % x\n        s += ' '\n    s += endline + \"\\n\"\n    if seplinefunc:\n        s += sepline + \"\\n\"\n    for y in vyk:\n        s += fmt % y\n        s += ' '\n        for x in vxk:\n            s += vxf[x] % vz.get((x, y), \"-\")\n            s += ' '\n        s += endline + \"\\n\"\n    if seplinefunc:\n        s += sepline + \"\\n\"\n\n    if dump:\n        return s\n    else:\n        print(s, end=\"\")\n\n\ndef make_table(*args, **kargs):\n    return __make_table(lambda l: \"%%-%is\" % l, lambda l: \"%%-%is\" % l, \"\", *args, **kargs)  # noqa: E501\n\n\ndef make_lined_table(*args, **kargs):\n    return __make_table(lambda l: \"%%-%is |\" % l, lambda l: \"%%-%is |\" % l, \"\",\n                        seplinefunc=lambda a, x: \"+\".join('-' * (y + 2) for y in [a - 1] + x + [-2]),  # noqa: E501\n                        *args, **kargs)\n\n\ndef make_tex_table(*args, **kargs):\n    return __make_table(lambda l: \"%s\", lambda l: \"& %s\", \"\\\\\\\\\", seplinefunc=lambda a, x: \"\\\\hline\", *args, **kargs)  # noqa: E501\n\n####################\n#   WHOIS CLIENT   #\n####################\n\n\ndef whois(ip_address):\n    \"\"\"Whois client for Python\"\"\"\n    whois_ip = str(ip_address)\n    try:\n        query = socket.gethostbyname(whois_ip)\n    except Exception:\n        query = whois_ip\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    s.connect((\"whois.ripe.net\", 43))\n    s.send(query.encode(\"utf8\") + b\"\\r\\n\")\n    answer = b\"\"\n    while True:\n        d = s.recv(4096)\n        answer += d\n        if not d:\n            break\n    s.close()\n    ignore_tag = b\"remarks:\"\n    # ignore all lines starting with the ignore_tag\n    lines = [line for line in answer.split(b\"\\n\") if not line or (line and not line.startswith(ignore_tag))]  # noqa: E501\n    # remove empty lines at the bottom\n    for i in range(1, len(lines)):\n        if not lines[-i].strip():\n            del lines[-i]\n        else:\n            break\n    return b\"\\n\".join(lines[3:])\n\n#######################\n#   PERIODIC SENDER   #\n#######################\n\n\nclass PeriodicSenderThread(threading.Thread):\n    def __init__(self, sock, pkt, interval=0.5):\n        \"\"\" Thread to send packets periodically\n\n        Args:\n            sock: socket where packet is sent periodically\n            pkt: packet to send\n            interval: interval between two packets\n        \"\"\"\n        self._pkt = pkt\n        self._socket = sock\n        self._stopped = threading.Event()\n        self._interval = interval\n        threading.Thread.__init__(self)\n\n    def run(self):\n        while not self._stopped.is_set():\n            self._socket.send(self._pkt)\n            time.sleep(self._interval)\n\n    def stop(self):\n        self._stopped.set()\n\n\nclass SingleConversationSocket(object):\n    def __init__(self, o):\n        self._inner = o\n        self._tx_mutex = threading.RLock()\n\n    @property\n    def __dict__(self):\n        return self._inner.__dict__\n\n    def __getattr__(self, name):\n        return getattr(self._inner, name)\n\n    def sr1(self, *args, **kargs):\n        with self._tx_mutex:\n            return self._inner.sr1(*args, **kargs)\n\n    def sr(self, *args, **kargs):\n        with self._tx_mutex:\n            return self._inner.sr(*args, **kargs)\n\n    def send(self, x):\n        with self._tx_mutex:\n            return self._inner.send(x)\n", "idx": 39, "id": 18379, "msg": "", "proj": "secdev-scapy", "lang": "py"}
{"patch": "@@ -0,0 +1,38 @@\n+import { assert } from 'chai';\n+import * as R from 'ramda';\n+\n+import * as RA from '../src';\n+\n+describe('isPositiveZero', function() {\n+  context('given a positive zero (+0)', function() {\n+    specify('should return true', function() {\n+      assert.isTrue(RA.isPositiveZero(+0));\n+    });\n+  });\n+\n+  context('given a value different from positive zero (+0)', function() {\n+    specify('should return false', function() {\n+      assert.isFalse(RA.isPositiveZero(-0));\n+      assert.isFalse(RA.isPositiveZero(null));\n+      assert.isFalse(RA.isPositiveZero(true));\n+      assert.isFalse(RA.isPositiveZero(NaN));\n+      assert.isFalse(RA.isPositiveZero({}));\n+      assert.isFalse(RA.isPositiveZero([]));\n+      assert.isFalse(RA.isPositiveZero(() => {}));\n+      assert.isFalse(RA.isPositiveZero('string'));\n+      assert.isFalse(RA.isPositiveZero(1));\n+      assert.isFalse(RA.isPositiveZero(0.1));\n+      assert.isFalse(RA.isPositiveZero(Object(0.1)));\n+      assert.isFalse(RA.isPositiveZero(NaN));\n+      assert.isFalse(RA.isPositiveZero(Infinity));\n+      assert.isFalse(RA.isPositiveZero(Number.MAX_VALUE));\n+      assert.isFalse(RA.isPositiveZero(Number.MIN_VALUE));\n+    });\n+  });\n+\n+  it('should support placeholder to specify \"gaps\"', function() {\n+    const isPositiveZero = RA.isPositiveZero(R.__);\n+\n+    assert.isTrue(isPositiveZero(+0));\n+  });\n+});", "y": 1, "oldf": "", "idx": 1, "id": 6194, "msg": "Last thing: we are missing test for implicit positive zero assert.isTrue(RA.isPositiveZero(0));", "proj": "char0n-ramda-adjunct", "lang": "js"}
{"patch": "@@ -38,8 +38,6 @@ namespace OpenTelemetry.Trace\n         /// <returns>Disposable object to control span to current context association.</returns>\n         public abstract IDisposable WithSpan(TelemetrySpan span, bool endSpanOnDispose);\n \n-        // TODO: add sampling hints\n-\n         /// <summary>\n         /// Starts root span.\n         /// </summary>", "y": 1, "oldf": "\ufeff// <copyright file=\"Tracer.cs\" company=\"OpenTelemetry Authors\">\n// Copyright 2018, OpenTelemetry Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n// </copyright>\n\nusing System;\nusing System.Collections.Generic;\nusing System.Diagnostics;\n\nnamespace OpenTelemetry.Trace\n{\n    /// <summary>\n    /// Tracer to record distributed tracing information.\n    /// </summary>\n    public abstract class Tracer\n    {\n        /// <summary>\n        /// Gets the current span from the context.\n        /// </summary>\n        public abstract TelemetrySpan CurrentSpan { get; }\n\n        /// <summary>\n        /// Activates the span on the current context.\n        /// </summary>\n        /// <param name=\"span\">Span to associate with the current context.</param>\n        /// <param name=\"endSpanOnDispose\">Flag indicating if span should end when scope is disposed.</param>\n        /// <returns>Disposable object to control span to current context association.</returns>\n        public abstract IDisposable WithSpan(TelemetrySpan span, bool endSpanOnDispose);\n\n        // TODO: add sampling hints\n\n        /// <summary>\n        /// Starts root span.\n        /// </summary>\n        /// <param name=\"operationName\">Span name.</param>\n        /// <param name=\"kind\">Kind.</param>\n        /// <param name=\"options\">Advanced span creation options.</param>\n        /// <returns>Span instance.</returns>\n        public abstract TelemetrySpan StartRootSpan(string operationName, SpanKind kind, SpanCreationOptions options);\n\n        /// <summary>\n        /// Starts span.\n        /// </summary>\n        /// <param name=\"operationName\">Span name.</param>\n        /// <param name=\"parent\">Parent for new span.</param>\n        /// <param name=\"kind\">Kind.</param>\n        /// <param name=\"options\">Advanced span creation options.</param>\n        /// <returns>Span instance.</returns>\n        public abstract TelemetrySpan StartSpan(string operationName, TelemetrySpan parent, SpanKind kind, SpanCreationOptions options);\n\n        /// <summary>\n        /// Starts span.\n        /// </summary>\n        /// <param name=\"operationName\">Span name.</param>\n        /// <param name=\"parent\">Parent for new span.</param>\n        /// <param name=\"kind\">Kind.</param>\n        /// <param name=\"options\">Advanced span creation options.</param>\n        /// <returns>Span instance.</returns>\n        public abstract TelemetrySpan StartSpan(string operationName, in SpanContext parent, SpanKind kind, SpanCreationOptions options);\n\n        /// <summary>\n        /// Starts span from auto-collected <see cref=\"Activity\"/>.\n        /// </summary>\n        /// <param name=\"operationName\">Span name.</param>\n        /// <param name=\"activity\">Activity instance to create span from.</param>\n        /// <param name=\"kind\">Kind.</param>\n        /// <param name=\"links\">Links collection.</param>\n        /// <returns>Span scope instance.</returns>\n        public abstract TelemetrySpan StartSpanFromActivity(string operationName, Activity activity, SpanKind kind, IEnumerable<Link> links);\n    }\n}\n", "idx": 1, "id": 13635, "msg": "sampling hints are removed from Spec, so no longer applicable here.", "proj": "open-telemetry-opentelemetry-dotnet", "lang": ".cs"}
{"patch": "@@ -628,19 +628,26 @@ func lookUpContainerInPod(containerID string, status corev1.PodStatus) (*corev1.\n \treturn nil, containerNotInPod\n }\n \n-func getPodImages(containerStatusArray []corev1.ContainerStatus) map[string]bool {\n-\tpodImages := make(map[string]bool)\n-\n-\t// collect container images\n+func getPodImageIdentifiers(containerStatusArray []corev1.ContainerStatus) []string {\n+\tvar podImages []string\n+\t// Note that for each pod image we generate *2* matching selectors.\n+\t// This is to support matching against ImageID, which has a SHA\n+\t// docker.io/envoyproxy/envoy-alpine@sha256:bf862e5f5eca0a73e7e538224578c5cf867ce2be91b5eaed22afc153c00363eb\n+\t// as well as\n+\t// docker.io/envoyproxy/envoy-alpine:v1.16.0, which does not,\n+\t// while also maintaining backwards compatibility and allowing for dynamic attestation\n+\t// when the SHA is not yet known (e.g. before the image pull is initiated)\n+\t// More info here: https://github.com/spiffe/spire/issues/2026\n \tfor _, status := range containerStatusArray {\n-\t\tpodImages[status.ImageID] = true\n+\t\tpodImages = append(podImages, status.ImageID, status.Image)\n \t}\n \treturn podImages\n }\n \n func getSelectorsFromPodInfo(pod *corev1.Pod, status *corev1.ContainerStatus) []*common.Selector {\n-\tpodImages := getPodImages(pod.Status.ContainerStatuses)\n-\tpodInitImages := getPodImages(pod.Status.InitContainerStatuses)\n+\tpodImageIdentifiers := getPodImageIdentifiers(pod.Status.ContainerStatuses)\n+\tpodInitImageIdentifiers := getPodImageIdentifiers(pod.Status.InitContainerStatuses)\n+\tcontainerImageIdentifiers := getPodImageIdentifiers([]corev1.ContainerStatus{*status})\n \n \tselectors := []*common.Selector{\n \t\tmakeSelector(\"sa:%s\", pod.Spec.ServiceAccountName),", "y": 1, "oldf": "package k8s\n\nimport (\n\t\"context\"\n\t\"crypto/tls\"\n\t\"crypto/x509\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"log\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"os\"\n\t\"regexp\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/andres-erbsen/clock\"\n\t\"github.com/hashicorp/go-hclog\"\n\t\"github.com/hashicorp/hcl\"\n\t\"github.com/spiffe/spire/pkg/agent/common/cgroups\"\n\t\"github.com/spiffe/spire/pkg/agent/plugin/workloadattestor\"\n\t\"github.com/spiffe/spire/pkg/common/catalog\"\n\t\"github.com/spiffe/spire/pkg/common/pemutil\"\n\t\"github.com/spiffe/spire/pkg/common/telemetry\"\n\t\"github.com/spiffe/spire/proto/spire/common\"\n\tspi \"github.com/spiffe/spire/proto/spire/common/plugin\"\n\t\"github.com/zeebo/errs\"\n\tcorev1 \"k8s.io/api/core/v1\"\n)\n\nconst (\n\tpluginName               = \"k8s\"\n\tdefaultMaxPollAttempts   = 60\n\tdefaultPollRetryInterval = time.Millisecond * 500\n\tdefaultSecureKubeletPort = 10250\n\tdefaultKubeletCAPath     = \"/run/secrets/kubernetes.io/serviceaccount/ca.crt\"\n\tdefaultTokenPath         = \"/run/secrets/kubernetes.io/serviceaccount/token\" //nolint: gosec // false positive\n\tdefaultNodeNameEnv       = \"MY_NODE_NAME\"\n\tdefaultReloadInterval    = time.Minute\n)\n\ntype containerLookup int\n\nconst (\n\tcontainerInPod = iota\n\tcontainerNotInPod\n)\n\nvar k8sErr = errs.Class(\"k8s\")\n\nfunc BuiltIn() catalog.Plugin {\n\treturn builtin(New())\n}\n\nfunc builtin(p *Plugin) catalog.Plugin {\n\treturn catalog.MakePlugin(pluginName, workloadattestor.PluginServer(p))\n}\n\n// HCLConfig holds the configuration parsed from HCL\ntype HCLConfig struct {\n\t// KubeletReadOnlyPort defines the read only port for the kubelet\n\t// (typically 10255). This option is mutally exclusive with\n\t// KubeletSecurePort.\n\tKubeletReadOnlyPort int `hcl:\"kubelet_read_only_port\"`\n\n\t// KubeletSecurePort defines the secure port for the kubelet (typically\n\t// 10250). This option is mutually exclusive with KubeletReadOnlyPort.\n\tKubeletSecurePort int `hcl:\"kubelet_secure_port\"`\n\n\t// MaxPollAttempts is the maximum number of polling attempts for the\n\t// container hosting the workload process.\n\tMaxPollAttempts int `hcl:\"max_poll_attempts\"`\n\n\t// PollRetryInterval is the time in between polling attempts.\n\tPollRetryInterval string `hcl:\"poll_retry_interval\"`\n\n\t// KubeletCAPath is the path to the CA certificate for authenticating the\n\t// kubelet over the secure port. Required when using the secure port unless\n\t// SkipKubeletVerification is set. Defaults to the cluster trust bundle.\n\tKubeletCAPath string `hcl:\"kubelet_ca_path\"`\n\n\t// SkipKubeletVerification controls whether or not the plugin will\n\t// verify the certificate presented by the kubelet.\n\tSkipKubeletVerification bool `hcl:\"skip_kubelet_verification\"`\n\n\t// TokenPath is the path to the bearer token used to authenticate to the\n\t// secure port. Defaults to the default service account token path unless\n\t// PrivateKeyPath and CertificatePath are specified.\n\tTokenPath string `hcl:\"token_path\"`\n\n\t// CertificatePath is the path to a certificate key used for client\n\t// authentication with the kubelet. Must be used with PrivateKeyPath.\n\tCertificatePath string `hcl:\"certificate_path\"`\n\n\t// PrivateKeyPath is the path to a private key used for client\n\t// authentication with the kubelet. Must be used with CertificatePath.\n\tPrivateKeyPath string `hcl:\"private_key_path\"`\n\n\t// NodeNameEnv is the environment variable used to determine the node name\n\t// for contacting the kubelet. It defaults to \"MY_NODE_NAME\". If the\n\t// environment variable is not set, and NodeName is not specified, the\n\t// plugin will default to localhost (which requires host networking).\n\tNodeNameEnv string `hcl:\"node_name_env\"`\n\n\t// NodeName is the node name used when contacting the kubelet. If set, it\n\t// takes precedence over NodeNameEnv.\n\tNodeName string `hcl:\"node_name\"`\n\n\t// ReloadInterval controls how often TLS and token configuration is loaded\n\t// from the disk.\n\tReloadInterval string `hcl:\"reload_interval\"`\n}\n\n// k8sConfig holds the configuration distilled from HCL\ntype k8sConfig struct {\n\tSecure                  bool\n\tPort                    int\n\tMaxPollAttempts         int\n\tPollRetryInterval       time.Duration\n\tSkipKubeletVerification bool\n\tTokenPath               string\n\tCertificatePath         string\n\tPrivateKeyPath          string\n\tKubeletCAPath           string\n\tNodeName                string\n\tReloadInterval          time.Duration\n\n\tClient     *kubeletClient\n\tLastReload time.Time\n}\n\ntype Plugin struct {\n\tworkloadattestor.UnsafeWorkloadAttestorServer\n\n\tlog    hclog.Logger\n\tfs     cgroups.FileSystem\n\tclock  clock.Clock\n\tgetenv func(string) string\n\n\tmu     sync.RWMutex\n\tconfig *k8sConfig\n}\n\nfunc New() *Plugin {\n\treturn &Plugin{\n\t\tfs:     cgroups.OSFileSystem{},\n\t\tclock:  clock.New(),\n\t\tgetenv: os.Getenv,\n\t}\n}\n\nfunc (p *Plugin) SetLogger(log hclog.Logger) {\n\tp.log = log\n}\n\nfunc (p *Plugin) Attest(ctx context.Context, req *workloadattestor.AttestRequest) (*workloadattestor.AttestResponse, error) {\n\tconfig, err := p.getConfig()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tcontainerID, err := p.getContainerIDFromCGroups(req.Pid)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Not a Kubernetes pod\n\tif containerID == \"\" {\n\t\treturn &workloadattestor.AttestResponse{}, nil\n\t}\n\n\tlog := p.log.With(telemetry.ContainerID, containerID)\n\n\t// Poll pod information and search for the pod with the container. If\n\t// the pod is not found then delay for a little bit and try again.\n\tfor attempt := 1; ; attempt++ {\n\t\tlog = log.With(telemetry.Attempt, attempt)\n\n\t\tlist, err := config.Client.GetPodList()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tfor _, item := range list.Items {\n\t\t\titem := item\n\t\t\tstatus, lookup := lookUpContainerInPod(containerID, item.Status)\n\t\t\tswitch lookup {\n\t\t\tcase containerInPod:\n\t\t\t\treturn &workloadattestor.AttestResponse{\n\t\t\t\t\tSelectors: getSelectorsFromPodInfo(&item, status),\n\t\t\t\t}, nil\n\t\t\tcase containerNotInPod:\n\t\t\t}\n\t\t}\n\n\t\t// if the container was not located after the maximum number of attempts then the search is over.\n\t\tif attempt >= config.MaxPollAttempts {\n\t\t\tlog.Warn(\"Container id not found; giving up\")\n\t\t\treturn nil, k8sErr.New(\"no selectors found\")\n\t\t}\n\n\t\t// wait a bit for containers to initialize before trying again.\n\t\tlog.Warn(\"Container id not found\", telemetry.RetryInterval, config.PollRetryInterval)\n\n\t\tselect {\n\t\tcase <-p.clock.After(config.PollRetryInterval):\n\t\tcase <-ctx.Done():\n\t\t\treturn nil, k8sErr.New(\"no selectors found: %v\", ctx.Err())\n\t\t}\n\t}\n}\n\nfunc (p *Plugin) Configure(ctx context.Context, req *spi.ConfigureRequest) (resp *spi.ConfigureResponse, err error) {\n\t// Parse HCL config payload into config struct\n\tconfig := new(HCLConfig)\n\tif err := hcl.Decode(config, req.Configuration); err != nil {\n\t\treturn nil, k8sErr.New(\"unable to decode configuration: %v\", err)\n\t}\n\n\t// Determine max poll attempts with default\n\tmaxPollAttempts := config.MaxPollAttempts\n\tif maxPollAttempts <= 0 {\n\t\tmaxPollAttempts = defaultMaxPollAttempts\n\t}\n\n\t// Determine poll retry interval with default\n\tvar pollRetryInterval time.Duration\n\tif config.PollRetryInterval != \"\" {\n\t\tpollRetryInterval, err = time.ParseDuration(config.PollRetryInterval)\n\t\tif err != nil {\n\t\t\treturn nil, k8sErr.New(\"unable to parse poll retry interval: %v\", err)\n\t\t}\n\t}\n\tif pollRetryInterval <= 0 {\n\t\tpollRetryInterval = defaultPollRetryInterval\n\t}\n\n\t// Determine reload interval\n\tvar reloadInterval time.Duration\n\tif config.ReloadInterval != \"\" {\n\t\treloadInterval, err = time.ParseDuration(config.ReloadInterval)\n\t\tif err != nil {\n\t\t\treturn nil, k8sErr.New(\"unable to parse reload interval: %v\", err)\n\t\t}\n\t}\n\tif reloadInterval <= 0 {\n\t\treloadInterval = defaultReloadInterval\n\t}\n\n\t// Determine which kubelet port to hit. Default to the secure port if none\n\t// is specified (this is backwards compatible because the read-only-port\n\t// config value has always been required, so it should already be set in\n\t// existing configurations that rely on it).\n\tif config.KubeletSecurePort > 0 && config.KubeletReadOnlyPort > 0 {\n\t\treturn nil, k8sErr.New(\"cannot use both the read-only and secure port\")\n\t}\n\tport := config.KubeletReadOnlyPort\n\tsecure := false\n\tif port <= 0 {\n\t\tport = config.KubeletSecurePort\n\t\tsecure = true\n\t}\n\tif port <= 0 {\n\t\tport = defaultSecureKubeletPort\n\t\tsecure = true\n\t}\n\n\t// Determine the node name\n\tnodeName := p.getNodeName(config.NodeName, config.NodeNameEnv)\n\n\t// Configure the kubelet client\n\tc := &k8sConfig{\n\t\tSecure:                  secure,\n\t\tPort:                    port,\n\t\tMaxPollAttempts:         maxPollAttempts,\n\t\tPollRetryInterval:       pollRetryInterval,\n\t\tSkipKubeletVerification: config.SkipKubeletVerification,\n\t\tTokenPath:               config.TokenPath,\n\t\tCertificatePath:         config.CertificatePath,\n\t\tPrivateKeyPath:          config.PrivateKeyPath,\n\t\tKubeletCAPath:           config.KubeletCAPath,\n\t\tNodeName:                nodeName,\n\t\tReloadInterval:          reloadInterval,\n\t}\n\tif err := p.reloadKubeletClient(c); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Set the config\n\tp.setConfig(c)\n\treturn &spi.ConfigureResponse{}, nil\n}\n\nfunc (*Plugin) GetPluginInfo(context.Context, *spi.GetPluginInfoRequest) (*spi.GetPluginInfoResponse, error) {\n\treturn &spi.GetPluginInfoResponse{}, nil\n}\n\nfunc (p *Plugin) setConfig(config *k8sConfig) {\n\tp.mu.Lock()\n\tdefer p.mu.Unlock()\n\tp.config = config\n}\n\nfunc (p *Plugin) getConfig() (*k8sConfig, error) {\n\tp.mu.RLock()\n\tdefer p.mu.RUnlock()\n\n\tif p.config == nil {\n\t\treturn nil, k8sErr.New(\"not configured\")\n\t}\n\tif err := p.reloadKubeletClient(p.config); err != nil {\n\t\tp.log.Warn(\"Unable to load kubelet client\", \"err\", err)\n\t}\n\treturn p.config, nil\n}\n\nfunc (p *Plugin) getContainerIDFromCGroups(pid int32) (string, error) {\n\tcgroups, err := cgroups.GetCgroups(pid, p.fs)\n\tif err != nil {\n\t\treturn \"\", k8sErr.Wrap(err)\n\t}\n\n\treturn getContainerIDFromCGroups(cgroups)\n}\n\nfunc (p *Plugin) reloadKubeletClient(config *k8sConfig) (err error) {\n\t// The insecure client only needs to be loaded once.\n\tif !config.Secure {\n\t\tif config.Client == nil {\n\t\t\tconfig.Client = &kubeletClient{\n\t\t\t\tURL: url.URL{\n\t\t\t\t\tScheme: \"http\",\n\t\t\t\t\tHost:   fmt.Sprintf(\"127.0.0.1:%d\", config.Port),\n\t\t\t\t},\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n\n\t// Is the client still fresh?\n\tif config.Client != nil && p.clock.Now().Sub(config.LastReload) < config.ReloadInterval {\n\t\treturn nil\n\t}\n\n\ttlsConfig := &tls.Config{\n\t\tInsecureSkipVerify: config.SkipKubeletVerification, //nolint: gosec // intentionally configurable\n\t}\n\n\tvar rootCAs *x509.CertPool\n\tif !config.SkipKubeletVerification {\n\t\trootCAs, err = p.loadKubeletCA(config.KubeletCAPath)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tswitch {\n\tcase config.SkipKubeletVerification:\n\n\t// When contacting the kubelet over localhost, skip the hostname validation.\n\t// Unfortunately Go does not make this straightforward. We disable\n\t// verification but supply a VerifyPeerCertificate that will be called\n\t// with the raw kubelet certs that we can verify directly.\n\tcase config.NodeName == \"\":\n\t\ttlsConfig.InsecureSkipVerify = true\n\t\ttlsConfig.VerifyPeerCertificate = func(rawCerts [][]byte, _ [][]*x509.Certificate) error {\n\t\t\tvar certs []*x509.Certificate\n\t\t\tfor _, rawCert := range rawCerts {\n\t\t\t\tcert, err := x509.ParseCertificate(rawCert)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tcerts = append(certs, cert)\n\t\t\t}\n\n\t\t\t// this is improbable.\n\t\t\tif len(certs) == 0 {\n\t\t\t\treturn errors.New(\"no certs presented by kubelet\")\n\t\t\t}\n\n\t\t\t_, err := certs[0].Verify(x509.VerifyOptions{\n\t\t\t\tRoots:         rootCAs,\n\t\t\t\tIntermediates: newCertPool(certs[1:]),\n\t\t\t})\n\t\t\treturn err\n\t\t}\n\tdefault:\n\t\ttlsConfig.RootCAs = rootCAs\n\t}\n\n\tvar token string\n\tswitch {\n\tcase config.CertificatePath != \"\" && config.PrivateKeyPath != \"\":\n\t\tkp, err := p.loadX509KeyPair(config.CertificatePath, config.PrivateKeyPath)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\ttlsConfig.Certificates = append(tlsConfig.Certificates, *kp)\n\tcase config.CertificatePath != \"\" && config.PrivateKeyPath == \"\":\n\t\treturn k8sErr.New(\"the private key path is required with the certificate path\")\n\tcase config.CertificatePath == \"\" && config.PrivateKeyPath != \"\":\n\t\treturn k8sErr.New(\"the certificate path is required with the private key path\")\n\tcase config.CertificatePath == \"\" && config.PrivateKeyPath == \"\":\n\t\ttoken, err = p.loadToken(config.TokenPath)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\thost := config.NodeName\n\tif host == \"\" {\n\t\thost = \"127.0.0.1\"\n\t}\n\n\tconfig.Client = &kubeletClient{\n\t\tTransport: &http.Transport{\n\t\t\tTLSClientConfig: tlsConfig,\n\t\t},\n\t\tURL: url.URL{\n\t\t\tScheme: \"https\",\n\t\t\tHost:   fmt.Sprintf(\"%s:%d\", host, config.Port),\n\t\t},\n\t\tToken: token,\n\t}\n\tconfig.LastReload = p.clock.Now()\n\treturn nil\n}\n\nfunc (p *Plugin) loadKubeletCA(path string) (*x509.CertPool, error) {\n\tif path == \"\" {\n\t\tpath = defaultKubeletCAPath\n\t}\n\tcaPEM, err := p.readFile(path)\n\tif err != nil {\n\t\treturn nil, k8sErr.New(\"unable to load kubelet CA: %v\", err)\n\t}\n\tcerts, err := pemutil.ParseCertificates(caPEM)\n\tif err != nil {\n\t\treturn nil, k8sErr.New(\"unable to parse kubelet CA: %v\", err)\n\t}\n\n\treturn newCertPool(certs), nil\n}\n\nfunc (p *Plugin) loadX509KeyPair(cert, key string) (*tls.Certificate, error) {\n\tcertPEM, err := p.readFile(cert)\n\tif err != nil {\n\t\treturn nil, k8sErr.New(\"unable to load certificate: %v\", err)\n\t}\n\tkeyPEM, err := p.readFile(key)\n\tif err != nil {\n\t\treturn nil, k8sErr.New(\"unable to load private key: %v\", err)\n\t}\n\tkp, err := tls.X509KeyPair(certPEM, keyPEM)\n\tif err != nil {\n\t\treturn nil, k8sErr.New(\"unable to load keypair: %v\", err)\n\t}\n\treturn &kp, nil\n}\n\nfunc (p *Plugin) loadToken(path string) (string, error) {\n\tif path == \"\" {\n\t\tpath = defaultTokenPath\n\t}\n\ttoken, err := p.readFile(path)\n\tif err != nil {\n\t\treturn \"\", k8sErr.New(\"unable to load token: %v\", err)\n\t}\n\treturn strings.TrimSpace(string(token)), nil\n}\n\n// readFile reads the contents of a file through the filesystem interface\nfunc (p *Plugin) readFile(path string) ([]byte, error) {\n\tf, err := p.fs.Open(path)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer f.Close()\n\treturn ioutil.ReadAll(f)\n}\n\nfunc (p *Plugin) getNodeName(name string, env string) string {\n\tswitch {\n\tcase name != \"\":\n\t\treturn name\n\tcase env != \"\":\n\t\treturn p.getenv(env)\n\tdefault:\n\t\treturn p.getenv(defaultNodeNameEnv)\n\t}\n}\n\ntype kubeletClient struct {\n\tTransport *http.Transport\n\tURL       url.URL\n\tToken     string\n}\n\nfunc (c *kubeletClient) GetPodList() (*corev1.PodList, error) {\n\turl := c.URL\n\turl.Path = \"/pods\"\n\treq, err := http.NewRequest(\"GET\", url.String(), nil)\n\tif err != nil {\n\t\treturn nil, k8sErr.New(\"unable to create request: %v\", err)\n\t}\n\tif c.Token != \"\" {\n\t\treq.Header.Set(\"Authorization\", \"Bearer \"+c.Token)\n\t}\n\n\tclient := &http.Client{}\n\tif c.Transport != nil {\n\t\tclient.Transport = c.Transport\n\t}\n\tresp, err := client.Do(req)\n\tif err != nil {\n\t\treturn nil, k8sErr.New(\"unable to perform request: %v\", err)\n\t}\n\tdefer resp.Body.Close()\n\n\tif resp.StatusCode != http.StatusOK {\n\t\treturn nil, k8sErr.New(\"unexpected status code on pods response: %d %s\", resp.StatusCode, tryRead(resp.Body))\n\t}\n\n\tout := new(corev1.PodList)\n\tif err := json.NewDecoder(resp.Body).Decode(out); err != nil {\n\t\treturn nil, k8sErr.New(\"unable to decode kubelet response: %v\", err)\n\t}\n\n\treturn out, nil\n}\n\nfunc getContainerIDFromCGroups(cgroups []cgroups.Cgroup) (string, error) {\n\tvar containerID string\n\tfor _, cgroup := range cgroups {\n\t\tcandidate, ok := getContainerIDFromCGroupPath(cgroup.GroupPath)\n\t\tswitch {\n\t\tcase !ok:\n\t\t\t// Cgroup did not contain a container ID.\n\t\t\tcontinue\n\t\tcase containerID == \"\":\n\t\t\t// This is the first container ID found so far.\n\t\t\tcontainerID = candidate\n\t\tcase containerID != candidate:\n\t\t\t// More than one container ID found in the cgroups.\n\t\t\treturn \"\", k8sErr.New(\"multiple container IDs found in cgroups (%s, %s)\",\n\t\t\t\tcontainerID, candidate)\n\t\t}\n\t}\n\n\treturn containerID, nil\n}\n\n// containerIDRe is the regex used to parse out the container ID from a cgroup\n// name. It assumes that any \".scope\" suffix has been trimmed off beforehand.\nvar containerIDRe = regexp.MustCompile(`` +\n\t// \"kubepods\" surrounded by punctuation\n\t`[[:punct:]]kubepods[[:punct:]]` +\n\t// zero or more punctuation separated \"segments\" (e.g. \"burstable-\")\n\t`(?:[[:^punct:]]+[[:punct:]])*` +\n\t// \"pod\"-prefixed Pod UUID (with punctuation separated groups) followed by punctuation\n\t`pod[[:xdigit:]]{8}[[:punct:]][[:xdigit:]]{4}[[:punct:]][[:xdigit:]]{4}[[:punct:]][[:xdigit:]]{4}[[:punct:]][[:xdigit:]]{12}[[:punct:]]` +\n\t// zero or more punctuation separated \"segments\" (e.g. \"docker-\")\n\t`(?:[[:^punct:]]+[[:punct:]])*` +\n\t// non-punctuation end of string, i.e., the container ID\n\t`([[:^punct:]]+)$`)\n\nfunc getContainerIDFromCGroupPath(cgroupPath string) (string, bool) {\n\t// We are only interested in kube pods entries, for example:\n\t// - /kubepods/burstable/pod2c48913c-b29f-11e7-9350-020968147796/9bca8d63d5fa610783847915bcff0ecac1273e5b4bed3f6fa1b07350e0135961\n\t// - /docker/8d461fa5765781bcf5f7eb192f101bc3103d4b932e26236f43feecfa20664f96/kubepods/besteffort/poddaa5c7ee-3484-4533-af39-3591564fd03e/aff34703e5e1f89443e9a1bffcc80f43f74d4808a2dd22c8f88c08547b323934\n\t// - /kubepods.slice/kubepods-burstable.slice/kubepods-burstable-pod2c48913c-b29f-11e7-9350-020968147796.slice/docker-9bca8d63d5fa610783847915bcff0ecac1273e5b4bed3f6fa1b07350e0135961.scope\n\t// - /kubepods-besteffort-pod72f7f152_440c_66ac_9084_e0fc1d8a910c.slice:cri-containerd:b2a102854b4969b2ce98dc329c86b4fb2b06e4ad2cc8da9d8a7578c9cd2004a2\"\n\n\t// First trim off any .scope suffix. This allows for a cleaner regex since\n\t// we don't have to muck with greediness. TrimSuffix is no-copy so this\n\t// is cheap.\n\tcgroupPath = strings.TrimSuffix(cgroupPath, \".scope\")\n\n\tmatches := containerIDRe.FindStringSubmatch(cgroupPath)\n\tif matches != nil {\n\t\treturn matches[1], true\n\t}\n\treturn \"\", false\n}\n\nfunc lookUpContainerInPod(containerID string, status corev1.PodStatus) (*corev1.ContainerStatus, containerLookup) {\n\tfor _, status := range status.ContainerStatuses {\n\t\t// TODO: should we be keying off of the status or is the lack of a\n\t\t// container id sufficient to know the container is not ready?\n\t\tif status.ContainerID == \"\" {\n\t\t\tcontinue\n\t\t}\n\n\t\tcontainerURL, err := url.Parse(status.ContainerID)\n\t\tif err != nil {\n\t\t\tlog.Printf(\"Malformed container id %q: %v\", status.ContainerID, err)\n\t\t\tcontinue\n\t\t}\n\n\t\tif containerID == containerURL.Host {\n\t\t\treturn &status, containerInPod\n\t\t}\n\t}\n\n\tfor _, status := range status.InitContainerStatuses {\n\t\t// TODO: should we be keying off of the status or is the lack of a\n\t\t// container id sufficient to know the container is not ready?\n\t\tif status.ContainerID == \"\" {\n\t\t\tcontinue\n\t\t}\n\n\t\tcontainerURL, err := url.Parse(status.ContainerID)\n\t\tif err != nil {\n\t\t\tlog.Printf(\"Malformed container id %q: %v\", status.ContainerID, err)\n\t\t\tcontinue\n\t\t}\n\n\t\tif containerID == containerURL.Host {\n\t\t\treturn &status, containerInPod\n\t\t}\n\t}\n\n\treturn nil, containerNotInPod\n}\n\nfunc getPodImages(containerStatusArray []corev1.ContainerStatus) map[string]bool {\n\tpodImages := make(map[string]bool)\n\n\t// collect container images\n\tfor _, status := range containerStatusArray {\n\t\tpodImages[status.ImageID] = true\n\t}\n\treturn podImages\n}\n\nfunc getSelectorsFromPodInfo(pod *corev1.Pod, status *corev1.ContainerStatus) []*common.Selector {\n\tpodImages := getPodImages(pod.Status.ContainerStatuses)\n\tpodInitImages := getPodImages(pod.Status.InitContainerStatuses)\n\n\tselectors := []*common.Selector{\n\t\tmakeSelector(\"sa:%s\", pod.Spec.ServiceAccountName),\n\t\tmakeSelector(\"ns:%s\", pod.Namespace),\n\t\tmakeSelector(\"node-name:%s\", pod.Spec.NodeName),\n\t\tmakeSelector(\"pod-uid:%s\", pod.UID),\n\t\tmakeSelector(\"pod-name:%s\", pod.Name),\n\t\tmakeSelector(\"container-name:%s\", status.Name),\n\t\tmakeSelector(\"container-image:%s\", status.Image),\n\t\tmakeSelector(\"pod-image-count:%s\", strconv.Itoa(len(podImages))),\n\t\tmakeSelector(\"pod-init-image-count:%s\", strconv.Itoa(len(podInitImages))),\n\t}\n\tfor podImage := range podImages {\n\t\tselectors = append(selectors, makeSelector(\"pod-image:%s\", podImage))\n\t}\n\tfor podInitImage := range podInitImages {\n\t\tselectors = append(selectors, makeSelector(\"pod-init-image:%s\", podInitImage))\n\t}\n\n\tfor k, v := range pod.Labels {\n\t\tselectors = append(selectors, makeSelector(\"pod-label:%s:%s\", k, v))\n\t}\n\tfor _, ownerReference := range pod.OwnerReferences {\n\t\tselectors = append(selectors, makeSelector(\"pod-owner:%s:%s\", ownerReference.Kind, ownerReference.Name))\n\t\tselectors = append(selectors, makeSelector(\"pod-owner-uid:%s:%s\", ownerReference.Kind, ownerReference.UID))\n\t}\n\n\treturn selectors\n}\n\nfunc makeSelector(format string, args ...interface{}) *common.Selector {\n\treturn &common.Selector{\n\t\tType:  pluginName,\n\t\tValue: fmt.Sprintf(format, args...),\n\t}\n}\n\nfunc tryRead(r io.Reader) string {\n\tbuf := make([]byte, 1024)\n\tn, _ := r.Read(buf)\n\treturn string(buf[:n])\n}\n\nfunc newCertPool(certs []*x509.Certificate) *x509.CertPool {\n\tcertPool := x509.NewCertPool()\n\tfor _, cert := range certs {\n\t\tcertPool.AddCert(cert)\n\t}\n\treturn certPool\n}\n", "idx": 1, "id": 15991, "msg": "I think this was `map[string]bool` before to avoid duplicate selectors when the same image appears multiple times Multiple images could have the same `status.Image` or `status.ImageID`, and in the case that an image is scheduled using the sha256, it is even possible that `status.ImageID == status.Image`", "proj": "spiffe-spire", "lang": "go"}
{"patch": "@@ -1153,8 +1153,8 @@ bool GoExecutor::processFinalResult(RpcResponse &rpcResp, Callback cb) const {\n                     };\n \n                     // Evaluate filter\n-                    if (filter_ != nullptr) {\n-                        auto value = filter_->eval();\n+                    if (whereWrapper_->filter_ != nullptr) {\n+                        auto value = whereWrapper_->filter_->eval(getters);\n                         if (!value.ok()) {\n                             doError(std::move(value).status(),\n                                     ectx()->getGraphStats()->getGoStats());", "y": 0, "oldf": "/* Copyright (c) 2018 vesoft inc. All rights reserved.\n *\n * This source code is licensed under Apache 2.0 License,\n * attached with Common Clause Condition 1.0, found in the LICENSES directory.\n */\n\n#include \"base/Base.h\"\n#include \"graph/GoExecutor.h\"\n#include \"graph/SchemaHelper.h\"\n#include \"dataman/RowReader.h\"\n#include \"dataman/RowSetReader.h\"\n#include \"dataman/ResultSchemaProvider.h\"\n\n\nnamespace nebula {\nnamespace graph {\n\nusing SchemaProps = std::unordered_map<std::string, std::vector<std::string>>;\nusing nebula::cpp2::SupportedType;\n\nGoExecutor::GoExecutor(Sentence *sentence, ExecutionContext *ectx) : TraverseExecutor(ectx) {\n    // The RTTI is guaranteed by Sentence::Kind,\n    // so we use `static_cast' instead of `dynamic_cast' for the sake of efficiency.\n    sentence_ = static_cast<GoSentence*>(sentence);\n}\n\n\nStatus GoExecutor::prepare() {\n    return Status::OK();\n}\n\n\nStatus GoExecutor::prepareClauses() {\n    DCHECK(sentence_ != nullptr);\n    Status status;\n    expCtx_ = std::make_unique<ExpressionContext>();\n    expCtx_->setStorageClient(ectx()->getStorageClient());\n\n    do {\n        status = checkIfGraphSpaceChosen();\n        if (!status.ok()) {\n            break;\n        }\n        status = prepareStep();\n        if (!status.ok()) {\n            break;\n        }\n        status = prepareFrom();\n        if (!status.ok()) {\n            break;\n        }\n        status = prepareOver();\n        if (!status.ok()) {\n            break;\n        }\n        status = prepareWhere();\n        if (!status.ok()) {\n            break;\n        }\n        status = prepareYield();\n        if (!status.ok()) {\n            break;\n        }\n        status = prepareNeededProps();\n        if (!status.ok()) {\n            break;\n        }\n        status = prepareDistinct();\n        if (!status.ok()) {\n            break;\n        }\n    } while (false);\n\n    if (!status.ok()) {\n        LOG(ERROR) << \"Preparing failed: \" << status;\n        return status;\n    }\n\n    return status;\n}\n\n\nvoid GoExecutor::execute() {\n    FLOG_INFO(\"Executing Go: %s\", sentence_->toString().c_str());\n    auto status = prepareClauses();\n    if (!status.ok()) {\n        doError(std::move(status), ectx()->getGraphStats()->getGoStats());\n        return;\n    }\n\n    status = setupStarts();\n    if (!status.ok()) {\n        doError(std::move(status), ectx()->getGraphStats()->getGoStats());\n        return;\n    }\n    if (starts_.empty()) {\n        onEmptyInputs();\n        return;\n    }\n    if (distinct_) {\n        std::unordered_set<VertexID> uniqID;\n        for (auto id : starts_) {\n            uniqID.emplace(id);\n        }\n        starts_ = std::vector<VertexID>(uniqID.begin(), uniqID.end());\n    }\n    stepOut();\n}\n\n\nvoid GoExecutor::feedResult(std::unique_ptr<InterimResult> result) {\n    inputs_ = std::move(result);\n}\n\n\nStatus GoExecutor::prepareStep() {\n    auto *clause = sentence_->stepClause();\n    if (clause != nullptr) {\n        steps_ = clause->steps();\n        upto_ = clause->isUpto();\n    }\n\n    if (isUpto()) {\n        return Status::Error(\"`UPTO' not supported yet\");\n    }\n\n    if (steps_ != 1) {\n        backTracker_ = std::make_unique<VertexBackTracker>();\n    }\n\n    return Status::OK();\n}\n\n\nStatus GoExecutor::prepareFrom() {\n    Status status = Status::OK();\n    auto *clause = sentence_->fromClause();\n    do {\n        if (clause == nullptr) {\n            LOG(FATAL) << \"From clause shall never be null\";\n        }\n\n        if (clause->isRef()) {\n            auto *expr = clause->ref();\n            if (expr->isInputExpression()) {\n                fromType_ = kPipe;\n                auto *iexpr = static_cast<InputPropertyExpression*>(expr);\n                colname_ = iexpr->prop();\n            } else if (expr->isVariableExpression()) {\n                fromType_ = kVariable;\n                auto *vexpr = static_cast<VariablePropertyExpression*>(expr);\n                varname_ = vexpr->alias();\n                colname_ = vexpr->prop();\n            } else {\n                // No way to happen except memory corruption\n                LOG(FATAL) << \"Unknown kind of expression\";\n            }\n\n            if (colname_ != nullptr && *colname_ == \"*\") {\n                status = Status::Error(\"Can not use `*' to reference a vertex id column.\");\n                break;\n            }\n            break;\n        }\n\n        auto space = ectx()->rctx()->session()->space();\n        expCtx_->setSpace(space);\n        auto vidList = clause->vidList();\n        for (auto *expr : vidList) {\n            expr->setContext(expCtx_.get());\n\n            status = expr->prepare();\n            if (!status.ok()) {\n                break;\n            }\n            auto value = expr->eval();\n            if (!value.ok()) {\n                status = Status::Error();\n                break;\n            }\n            if (expr->isFunCallExpression()) {\n                auto *funcExpr = static_cast<FunctionCallExpression*>(expr);\n                if (*(funcExpr->name()) == \"near\") {\n                    auto v = Expression::asString(value.value());\n                    std::vector<VertexID> result;\n                    folly::split(\",\", v, result, true);\n                    starts_.insert(starts_.end(),\n                                   std::make_move_iterator(result.begin()),\n                                   std::make_move_iterator(result.end()));\n                    continue;\n                }\n            }\n            auto v = value.value();\n            if (!Expression::isInt(v)) {\n                status = Status::Error(\"Vertex ID should be of type integer\");\n                break;\n            }\n            starts_.push_back(Expression::asInt(v));\n        }\n        fromType_ = kInstantExpr;\n        if (!status.ok()) {\n            break;\n        }\n    } while (false);\n    return status;\n}\n\nStatus GoExecutor::prepareOverAll() {\n    auto spaceId = ectx()->rctx()->session()->space();\n    auto edgeAllStatus = ectx()->schemaManager()->getAllEdge(spaceId);\n\n    if (!edgeAllStatus.ok()) {\n        return edgeAllStatus.status();\n    }\n\n    auto allEdge = edgeAllStatus.value();\n    for (auto &e : allEdge) {\n        auto edgeStatus = ectx()->schemaManager()->toEdgeType(spaceId, e);\n        if (!edgeStatus.ok()) {\n            return edgeStatus.status();\n        }\n\n        auto v = edgeStatus.value();\n        if (isReversely()) {\n            v = -v;\n        }\n\n        edgeTypes_.push_back(v);\n\n        if (!expCtx_->addEdge(e, v)) {\n            return Status::Error(folly::sformat(\"edge alias({}) was dup\", e));\n        }\n    }\n\n    return Status::OK();\n}\n\nStatus GoExecutor::prepareOver() {\n    Status status = Status::OK();\n    auto *clause = sentence_->overClause();\n    if (clause == nullptr) {\n        LOG(FATAL) << \"Over clause shall never be null\";\n    }\n\n    isReversely_ = clause->isReversely();\n\n    if (isReversely()) {\n        edgeHolder_ = std::make_unique<EdgeHolder>();\n    }\n\n    auto edges = clause->edges();\n    for (auto e : edges) {\n        if (e->isOverAll()) {\n            expCtx_->setOverAllEdge();\n            return prepareOverAll();\n        }\n\n        auto spaceId = ectx()->rctx()->session()->space();\n        auto edgeStatus = ectx()->schemaManager()->toEdgeType(spaceId, *e->edge());\n        if (!edgeStatus.ok()) {\n            return edgeStatus.status();\n        }\n\n        auto v = edgeStatus.value();\n        if (isReversely()) {\n            v = -v;\n        }\n        edgeTypes_.push_back(v);\n\n        if (e->alias() != nullptr) {\n            if (!expCtx_->addEdge(*e->alias(), v)) {\n                return Status::Error(folly::sformat(\"edge alias({}) was dup\", *e->alias()));\n            }\n        } else {\n            if (!expCtx_->addEdge(*e->edge(), v)) {\n                return Status::Error(folly::sformat(\"edge alias({}) was dup\", *e->edge()));\n            }\n        }\n    }\n\n    return status;\n}\n\n\nStatus GoExecutor::prepareWhere() {\n    auto *clause = sentence_->whereClause();\n    if (clause != nullptr) {\n        filter_ = clause->filter();\n    }\n    return Status::OK();\n}\n\n\nStatus GoExecutor::prepareYield() {\n    auto *clause = sentence_->yieldClause();\n    // this preparation depends on interim result,\n    // it can only be called after getting results of the previous executor,\n    // but if we can do the semantic analysis before execution,\n    // then we can do the preparation before execution\n    // TODO: make it possible that this preparation not depends on interim result\n    if (clause != nullptr) {\n        yieldClauseWrapper_ = std::make_unique<YieldClauseWrapper>(clause);\n        auto *varHolder = ectx()->variableHolder();\n        auto status = yieldClauseWrapper_->prepare(inputs_.get(), varHolder, yields_);\n        if (!status.ok()) {\n            return status;\n        }\n        for (auto *col : yields_) {\n            if (!col->getFunName().empty()) {\n                return Status::SyntaxError(\"Do not support in aggregated query without group by\");\n            }\n        }\n    }\n    return Status::OK();\n}\n\n\nStatus GoExecutor::prepareNeededProps() {\n    auto status = Status::OK();\n    do {\n        if (filter_ != nullptr) {\n            filter_->setContext(expCtx_.get());\n            status = filter_->prepare();\n            if (!status.ok()) {\n                break;\n            }\n        }\n\n        for (auto *col : yields_) {\n            col->expr()->setContext(expCtx_.get());\n            status = col->expr()->prepare();\n            if (!status.ok()) {\n                break;\n            }\n        }\n        if (!status.ok()) {\n            break;\n        }\n\n        if (expCtx_->hasVariableProp()) {\n            if (fromType_ != kVariable) {\n                status = Status::Error(\"A variable must be referred in FROM \"\n                                       \"before used in WHERE or YIELD\");\n                break;\n            }\n            auto &variables = expCtx_->variables();\n            if (variables.size() > 1) {\n                status = Status::Error(\"Only one variable allowed to use\");\n                break;\n            }\n            auto &var = *variables.begin();\n            if (var != *varname_) {\n                status = Status::Error(\"Variable name not match: `%s' vs. `%s'\",\n                                       var.c_str(), varname_->c_str());\n                break;\n            }\n        }\n\n        if (expCtx_->hasInputProp()) {\n            if (fromType_ != kPipe) {\n                status = Status::Error(\"`$-' must be referred in FROM \"\n                                       \"before used in WHERE or YIELD\");\n                break;\n            }\n        }\n\n        auto &tagMap = expCtx_->getTagMap();\n        auto spaceId = ectx()->rctx()->session()->space();\n        for (auto &entry : tagMap) {\n            auto tagId = ectx()->schemaManager()->toTagID(spaceId, entry.first);\n            if (!tagId.ok()) {\n                status == Status::Error(\"Tag `%s' not found.\", entry.first.c_str());\n                break;\n            }\n            entry.second = tagId.value();\n        }\n    } while (false);\n\n    return status;\n}\n\n\nStatus GoExecutor::prepareDistinct() {\n    auto *clause = sentence_->yieldClause();\n    if (clause != nullptr) {\n        distinct_ = clause->isDistinct();\n        // TODO Consider distinct pushdown later, depends on filter and some other clause pushdown.\n        distinctPushDown_ =\n            !((expCtx_->hasSrcTagProp() || expCtx_->hasEdgeProp()) && expCtx_->hasDstTagProp());\n    }\n    return Status::OK();\n}\n\n\nStatus GoExecutor::setupStarts() {\n    // Literal vertex ids\n    if (!starts_.empty()) {\n        return Status::OK();\n    }\n    const auto *inputs = inputs_.get();\n    // Take one column from a variable\n    if (varname_ != nullptr) {\n        bool existing = false;\n        auto *varInputs = ectx()->variableHolder()->get(*varname_, &existing);\n        if (varInputs == nullptr && !existing) {\n            return Status::Error(\"Variable `%s' not defined\", varname_->c_str());\n        }\n        DCHECK(inputs == nullptr);\n        inputs = varInputs;\n    }\n    // No error happened, but we are having empty inputs\n    if (inputs == nullptr || !inputs->hasData()) {\n        return Status::OK();\n    }\n\n    auto result = inputs->getVIDs(*colname_);\n    if (!result.ok()) {\n        LOG(ERROR) << \"Get vid fail: \" << *colname_;\n        return std::move(result).status();\n    }\n    starts_ = std::move(result).value();\n\n    auto indexResult = inputs->buildIndex(*colname_);\n    if (!indexResult.ok()) {\n        return std::move(indexResult).status();\n    }\n    index_ = std::move(indexResult).value();\n    return Status::OK();\n}\n\n\nvoid GoExecutor::setupResponse(cpp2::ExecutionResponse &resp) {\n    if (resp_ == nullptr) {\n        resp_ = std::make_unique<cpp2::ExecutionResponse>();\n    }\n    resp = std::move(*resp_);\n}\n\n\nvoid GoExecutor::stepOut() {\n    auto spaceId = ectx()->rctx()->session()->space();\n    auto status = getStepOutProps();\n    if (!status.ok()) {\n        doError(Status::Error(\"Get step out props failed\"),\n                ectx()->getGraphStats()->getGoStats());\n        return;\n    }\n    auto returns = status.value();\n    auto future  = ectx()->getStorageClient()->getNeighbors(spaceId,\n                                                            starts_,\n                                                            edgeTypes_,\n                                                            \"\",\n                                                            std::move(returns));\n    auto *runner = ectx()->rctx()->runner();\n    auto cb = [this] (auto &&result) {\n        auto completeness = result.completeness();\n        if (completeness == 0) {\n            doError(Status::Error(\"Get neighbors failed\"), ectx()->getGraphStats()->getGoStats());\n            return;\n        } else if (completeness != 100) {\n            // TODO(dutor) We ought to let the user know that the execution was partially\n            // performed, even in the case that this happened in the intermediate process.\n            // Or, make this case configurable at runtime.\n            // For now, we just do some logging and keep going.\n            LOG(INFO) << \"Get neighbors partially failed: \"  << completeness << \"%\";\n            for (auto &error : result.failedParts()) {\n                LOG(ERROR) << \"part: \" << error.first\n                           << \"error code: \" << static_cast<int>(error.second);\n            }\n        }\n        onStepOutResponse(std::move(result));\n    };\n    auto error = [this] (auto &&e) {\n        LOG(ERROR) << \"Exception caught: \" << e.what();\n        doError(Status::Error(\"Exeception when handle out-bounds/in-bounds.\"),\n                ectx()->getGraphStats()->getGoStats());\n    };\n    std::move(future).via(runner).thenValue(cb).thenError(error);\n}\n\n\nvoid GoExecutor::onStepOutResponse(RpcResponse &&rpcResp) {\n    if (isFinalStep()) {\n        maybeFinishExecution(std::move(rpcResp));\n        return;\n    } else {\n        starts_ = getDstIdsFromResp(rpcResp);\n        if (starts_.empty()) {\n            onEmptyInputs();\n            return;\n        }\n        curStep_++;\n        stepOut();\n    }\n}\n\n\nvoid GoExecutor::maybeFinishExecution(RpcResponse &&rpcResp) {\n    auto requireDstProps = expCtx_->hasDstTagProp();\n    auto requireEdgeProps = !expCtx_->aliasProps().empty();\n\n    // Non-reversely traversal, no properties required on destination nodes\n    // Or, Reversely traversal but no properties on edge and destination nodes required.\n    // Note that the `dest` which used in reversely traversal means the `src` in foword edge.\n    if ((!requireDstProps && !isReversely()) ||\n        (isReversely() && !requireDstProps && !requireEdgeProps &&\n         !(expCtx_->isOverAllEdge() && yields_.empty()))) {\n        finishExecution(std::move(rpcResp));\n        return;\n    }\n\n    auto dstids = getDstIdsFromResp(rpcResp);\n\n    // Reaching the dead end\n    if (dstids.empty()) {\n        onEmptyInputs();\n        return;\n    }\n\n    // Only properties on destination nodes required\n    if (!isReversely() || (requireDstProps && !requireEdgeProps)) {\n        fetchVertexProps(std::move(dstids), std::move(rpcResp));\n        return;\n    }\n\n    // Reversely traversal\n    DCHECK(isReversely());\n\n    std::unordered_map<EdgeType, std::vector<storage::cpp2::EdgeKey>> edgeKeysMapping;\n    std::unordered_map<EdgeType, std::vector<storage::cpp2::PropDef>> edgePropsMapping;\n\n    // TODO: There would be no need to fetch edges' props here,\n    // if we implemnet the feature that keep all the props in the reverse edge.\n    for (auto &resp : rpcResp.responses()) {\n        auto *vertices = resp.get_vertices();\n        if (vertices == nullptr) {\n            continue;\n        }\n        auto *eschema = resp.get_edge_schema();\n        if (eschema == nullptr) {\n            continue;\n        }\n        std::unordered_map<EdgeType, std::shared_ptr<ResultSchemaProvider>> schemas;\n        std::transform(eschema->cbegin(), eschema->cend(), std::inserter(schemas, schemas.begin()),\n                [] (auto &s) {\n            return std::make_pair(s.first, std::make_shared<ResultSchemaProvider>(s.second));\n        });\n\n        for (auto &vdata : *vertices) {\n            for (auto &edge : vdata.edge_data) {\n                RowSetReader rsReader(schemas[edge.type], edge.data);\n                auto iter = rsReader.begin();\n                while (iter) {\n                    VertexID dst;\n                    EdgeRanking rank;\n                    auto rc = iter->getVid(_DST, dst);\n                    if (rc != ResultType::SUCCEEDED) {\n                        doError(Status::Error(\"Get dst error when go reversely.\"),\n                                ectx()->getGraphStats()->getGoStats());\n                        return;\n                    }\n                    rc = iter->getVid(_RANK, rank);\n                    if (rc != ResultType::SUCCEEDED) {\n                        doError(Status::Error(\"Get rank error when go reversely.\"),\n                                ectx()->getGraphStats()->getGoStats());\n                        return;\n                    }\n                    auto type = std::abs(edge.type);\n                    auto &edgeKeys = edgeKeysMapping[type];\n                    edgeKeys.emplace_back();\n                    edgeKeys.back().set_src(dst);\n                    edgeKeys.back().set_dst(vdata.get_vertex_id());\n                    edgeKeys.back().set_ranking(rank);\n                    edgeKeys.back().set_edge_type(type);\n                    ++iter;\n                }\n            }\n        }\n    }\n\n    for (auto &prop : expCtx_->aliasProps()) {\n        EdgeType edgeType;\n        if (!expCtx_->getEdgeType(prop.first, edgeType)) {\n            doError(Status::Error(\"No schema found for `%s'\", prop.first.c_str()),\n                    ectx()->getGraphStats()->getGoStats());\n            return;\n        }\n\n        edgeType = std::abs(edgeType);\n        auto &edgeProps = edgePropsMapping[edgeType];\n        edgeProps.emplace_back();\n        edgeProps.back().owner = storage::cpp2::PropOwner::EDGE;\n        edgeProps.back().name = prop.second;\n        edgeProps.back().id.set_edge_type(edgeType);\n    }\n\n    using EdgePropResponse = storage::StorageRpcResponse<storage::cpp2::EdgePropResponse>;\n    std::vector<folly::SemiFuture<EdgePropResponse>> futures;\n\n    auto spaceId = ectx()->rctx()->session()->space();\n    auto *runner = ectx()->rctx()->runner();\n\n    for (auto &pair : edgeKeysMapping) {\n        auto *storage = ectx()->getStorageClient();\n        auto future = storage->getEdgeProps(spaceId,\n                                            pair.second,\n                                            edgePropsMapping[pair.first]);\n        futures.emplace_back(std::move(future));\n    }\n\n    auto cb = [this, stepResp = std::move(rpcResp),\n               dstids = std::move(dstids)] (auto &&result) mutable {\n        for (auto &t : result) {\n            if (t.hasException()) {\n                LOG(ERROR) << \"Exception caught: \" << t.exception().what();\n                doError(Status::Error(\"Exeception when get edge props in reversely traversal.\"),\n                        ectx()->getGraphStats()->getGoStats());\n                return;\n            }\n            auto resp = std::move(t).value();\n            for (auto &edgePropResp : resp.responses()) {\n                auto status = edgeHolder_->add(edgePropResp);\n                if (!status.ok()) {\n                    LOG(ERROR) << \"Error when handle edges: \" << status;\n                    doError(std::move(status), ectx()->getGraphStats()->getGoStats());\n                    return;\n                }\n            }\n        }\n\n        if (expCtx_->hasDstTagProp()) {\n            fetchVertexProps(std::move(dstids), std::move(stepResp));\n            return;\n        }\n\n        finishExecution(std::move(stepResp));\n    };\n\n    auto error = [this] (auto &&e) {\n        LOG(ERROR) << \"Exception caught: \" << e.what();\n        doError(Status::Error(\"Exception when handle edges.\"),\n                ectx()->getGraphStats()->getGoStats());\n    };\n\n    folly::collectAll(std::move(futures)).via(runner).thenValue(cb).thenError(error);\n}\n\nvoid GoExecutor::onVertexProps(RpcResponse &&rpcResp) {\n    UNUSED(rpcResp);\n}\n\nstd::vector<std::string> GoExecutor::getEdgeNamesFromResp(RpcResponse &rpcResp) const {\n    std::vector<std::string> names;\n    auto spaceId = ectx()->rctx()->session()->space();\n    auto &resp = rpcResp.responses();\n    auto *edgeSchema = resp[0].get_edge_schema();\n    if (edgeSchema == nullptr) {\n        return names;\n    }\n\n    for (auto &schema : *edgeSchema) {\n        auto edgeType = schema.first;\n        auto status = ectx()->schemaManager()->toEdgeName(spaceId, std::abs(edgeType));\n        DCHECK(status.ok());\n        auto edgeName = status.value();\n        names.emplace_back(std::move(edgeName));\n    }\n\n    return names;\n}\n\nstd::vector<VertexID> GoExecutor::getDstIdsFromResp(RpcResponse &rpcResp) const {\n    std::unordered_set<VertexID> set;\n    for (auto &resp : rpcResp.responses()) {\n        auto *vertices = resp.get_vertices();\n        if (vertices == nullptr) {\n            continue;\n        }\n\n        auto *eschema = resp.get_edge_schema();\n        if (eschema == nullptr) {\n            continue;\n        }\n        std::unordered_map<EdgeType, std::shared_ptr<ResultSchemaProvider>> schema;\n\n        std::transform(eschema->cbegin(), eschema->cend(), std::inserter(schema, schema.begin()),\n                       [](auto &s) {\n                           return std::make_pair(\n                               s.first, std::make_shared<ResultSchemaProvider>(s.second));\n                       });\n\n        for (auto &vdata : *vertices) {\n            for (auto &edata : vdata.edge_data) {\n                auto it = schema.find(edata.type);\n                DCHECK(it != schema.end());\n                RowSetReader rsReader(it->second, edata.data);\n                auto iter = rsReader.begin();\n                while (iter) {\n                    VertexID dst;\n                    auto rc = iter->getVid(_DST, dst);\n                    CHECK(rc == ResultType::SUCCEEDED);\n                    if (!isFinalStep() && backTracker_ != nullptr) {\n                        backTracker_->add(vdata.get_vertex_id(), dst);\n                    }\n                    set.emplace(dst);\n                    ++iter;\n                }\n            }\n        }\n    }\n    return std::vector<VertexID>(set.begin(), set.end());\n}\n\nvoid GoExecutor::finishExecution(RpcResponse &&rpcResp) {\n    // MayBe we can do better.\n    std::vector<std::unique_ptr<YieldColumn>> yc;\n    if (expCtx_->isOverAllEdge() && yields_.empty()) {\n        auto edgeNames = getEdgeNamesFromResp(rpcResp);\n        if (edgeNames.empty()) {\n            doError(Status::Error(\"get edge name failed\"), ectx()->getGraphStats()->getGoStats());\n            return;\n        }\n        for (const auto &name : edgeNames) {\n            auto dummy = new std::string(name);\n            auto dummy_exp = new EdgeDstIdExpression(dummy);\n            auto ptr = std::make_unique<YieldColumn>(dummy_exp);\n            dummy_exp->setContext(expCtx_.get());\n            yields_.emplace_back(ptr.get());\n            yc.emplace_back(std::move(ptr));\n        }\n    }\n\n    std::unique_ptr<InterimResult> outputs;\n    if (!setupInterimResult(std::move(rpcResp), outputs)) {\n        return;\n    }\n\n    if (onResult_) {\n        onResult_(std::move(outputs));\n    } else {\n        resp_ = std::make_unique<cpp2::ExecutionResponse>();\n        resp_->set_column_names(getResultColumnNames());\n        if (outputs != nullptr && outputs->hasData()) {\n            auto ret = outputs->getRows();\n            if (!ret.ok()) {\n                LOG(ERROR) << \"Get rows failed: \" << ret.status();\n                doError(std::move(ret).status(), ectx()->getGraphStats()->getGoStats());\n                return;\n            }\n            resp_->set_rows(std::move(ret).value());\n        }\n    }\n    doFinish(Executor::ProcessControl::kNext, ectx()->getGraphStats()->getGoStats());\n}\n\nStatusOr<std::vector<storage::cpp2::PropDef>> GoExecutor::getStepOutProps() {\n    std::vector<storage::cpp2::PropDef> props;\n    for (auto &e : edgeTypes_) {\n        storage::cpp2::PropDef pd;\n        pd.owner = storage::cpp2::PropOwner::EDGE;\n        pd.name = _DST;\n        pd.id.set_edge_type(e);\n        props.emplace_back(std::move(pd));\n        // We need ranking when go reverly in final step,\n        // because we have to fetch the coresponding edges.\n        if (isReversely() && isFinalStep()) {\n            storage::cpp2::PropDef rankPd;\n            rankPd.owner = storage::cpp2::PropOwner::EDGE;\n            rankPd.name = _RANK;\n            rankPd.id.set_edge_type(e);\n            props.emplace_back(std::move(rankPd));\n        }\n    }\n\n    if (!isFinalStep()) {\n        return props;\n    }\n\n    auto spaceId = ectx()->rctx()->session()->space();\n    for (auto &tagProp : expCtx_->srcTagProps()) {\n        storage::cpp2::PropDef pd;\n        pd.owner = storage::cpp2::PropOwner::SOURCE;\n        pd.name = tagProp.second;\n        auto status = ectx()->schemaManager()->toTagID(spaceId, tagProp.first);\n        if (!status.ok()) {\n            return Status::Error(\"No schema found for '%s'\", tagProp.first.c_str());\n        }\n        auto tagId = status.value();\n        pd.id.set_tag_id(tagId);\n        props.emplace_back(std::move(pd));\n    }\n\n    if (isReversely()) {\n        return props;\n    }\n\n    for (auto &prop : expCtx_->aliasProps()) {\n        storage::cpp2::PropDef pd;\n        pd.owner = storage::cpp2::PropOwner::EDGE;\n        pd.name  = prop.second;\n\n        EdgeType edgeType;\n\n        if (!expCtx_->getEdgeType(prop.first, edgeType)) {\n            return Status::Error(\"the edge was not found '%s'\", prop.first.c_str());\n        }\n        pd.id.set_edge_type(edgeType);\n        props.emplace_back(std::move(pd));\n    }\n\n    return props;\n}\n\n\nStatusOr<std::vector<storage::cpp2::PropDef>> GoExecutor::getDstProps() {\n    std::vector<storage::cpp2::PropDef> props;\n    auto spaceId = ectx()->rctx()->session()->space();\n    for (auto &tagProp : expCtx_->dstTagProps()) {\n        storage::cpp2::PropDef pd;\n        pd.owner = storage::cpp2::PropOwner::DEST;\n        pd.name = tagProp.second;\n        auto status = ectx()->schemaManager()->toTagID(spaceId, tagProp.first);\n        if (!status.ok()) {\n            return Status::Error(\"No schema found for '%s'\", tagProp.first.c_str());\n        }\n        auto tagId = status.value();\n        pd.id.set_tag_id(tagId);\n        props.emplace_back(std::move(pd));\n    }\n    return props;\n}\n\n\nvoid GoExecutor::fetchVertexProps(std::vector<VertexID> ids, RpcResponse &&rpcResp) {\n    auto spaceId = ectx()->rctx()->session()->space();\n    auto status = getDstProps();\n    if (!status.ok()) {\n        doError(Status::Error(\"Get dest props failed\"), ectx()->getGraphStats()->getGoStats());\n        return;\n    }\n    auto returns = status.value();\n    auto future = ectx()->getStorageClient()->getVertexProps(spaceId, ids, returns);\n    auto *runner = ectx()->rctx()->runner();\n    auto cb = [this, stepOutResp = std::move(rpcResp)] (auto &&result) mutable {\n        auto completeness = result.completeness();\n        if (completeness == 0) {\n            doError(Status::Error(\"Get dest props failed\"), ectx()->getGraphStats()->getGoStats());\n            return;\n        } else if (completeness != 100) {\n            LOG(INFO) << \"Get neighbors partially failed: \"  << completeness << \"%\";\n            for (auto &error : result.failedParts()) {\n                LOG(ERROR) << \"part: \" << error.first\n                           << \"error code: \" << static_cast<int>(error.second);\n            }\n        }\n        if (vertexHolder_ == nullptr) {\n            vertexHolder_ = std::make_unique<VertexHolder>();\n        }\n        for (auto &resp : result.responses()) {\n            vertexHolder_->add(resp);\n        }\n        finishExecution(std::move(stepOutResp));\n        return;\n    };\n    auto error = [this] (auto &&e) {\n        LOG(ERROR) << \"Exception caught: \" << e.what();\n        doError(Status::Error(\"Exception when handle vertex props.\"),\n                ectx()->getGraphStats()->getGoStats());\n    };\n    std::move(future).via(runner).thenValue(cb).thenError(error);\n}\n\n\nstd::vector<std::string> GoExecutor::getResultColumnNames() const {\n    std::vector<std::string> result;\n    result.reserve(yields_.size());\n    for (auto *col : yields_) {\n        if (col->alias() == nullptr) {\n            result.emplace_back(col->expr()->toString());\n        } else {\n            result.emplace_back(*col->alias());\n        }\n    }\n    return result;\n}\n\n\nbool GoExecutor::setupInterimResult(RpcResponse &&rpcResp, std::unique_ptr<InterimResult> &result) {\n    // Generic results\n    result = std::make_unique<InterimResult>(getResultColumnNames());\n    std::shared_ptr<SchemaWriter> schema;\n    std::unique_ptr<RowSetWriter> rsWriter;\n    auto uniqResult = std::make_unique<std::unordered_set<std::string>>();\n    auto cb = [&] (std::vector<VariantType> record,\n                       std::vector<nebula::cpp2::SupportedType> colTypes) {\n        if (schema == nullptr) {\n            schema = std::make_shared<SchemaWriter>();\n            auto colnames = getResultColumnNames();\n            if (record.size() != colTypes.size()) {\n                LOG(FATAL) << \"data nums: \" << record.size()\n                           << \" != type nums: \" << colTypes.size();\n            }\n            for (auto i = 0u; i < record.size(); i++) {\n                SupportedType type;\n                if (colTypes[i] == SupportedType::UNKNOWN) {\n                    switch (record[i].which()) {\n                        case VAR_INT64:\n                            // all integers in InterimResult are regarded as type of INT\n                            type = SupportedType::INT;\n                            break;\n                        case VAR_DOUBLE:\n                            type = SupportedType::DOUBLE;\n                            break;\n                        case VAR_BOOL:\n                            type = SupportedType::BOOL;\n                            break;\n                        case VAR_STR:\n                            type = SupportedType::STRING;\n                            break;\n                        default:\n                            LOG(FATAL) << \"Unknown VariantType: \" << record[i].which();\n                    }\n                } else {\n                    type = colTypes[i];\n                }\n                schema->appendCol(colnames[i], type);\n            }  // for\n            rsWriter = std::make_unique<RowSetWriter>(schema);\n        }  // if\n\n        RowWriter writer(schema);\n        for (auto &column : record) {\n            switch (column.which()) {\n                case VAR_INT64:\n                    writer << boost::get<int64_t>(column);\n                    break;\n                case VAR_DOUBLE:\n                    writer << boost::get<double>(column);\n                    break;\n                case VAR_BOOL:\n                    writer << boost::get<bool>(column);\n                    break;\n                case VAR_STR:\n                    writer << boost::get<std::string>(column);\n                    break;\n                default:\n                    LOG(FATAL) << \"Unknown VariantType: \" << column.which();\n            }\n        }\n        // TODO Consider float/double, and need to reduce mem copy.\n        std::string encode = writer.encode();\n        if (distinct_) {\n            auto ret = uniqResult->emplace(encode);\n            if (ret.second) {\n                rsWriter->addRow(std::move(encode));\n            }\n        } else {\n            rsWriter->addRow(std::move(encode));\n        }\n    };  // cb\n    if (!processFinalResult(rpcResp, cb)) {\n        return false;\n    }\n\n    if (rsWriter != nullptr) {\n        result->setInterim(std::move(rsWriter));\n    }\n    return true;\n}\n\n\nvoid GoExecutor::onEmptyInputs() {\n    auto resultColNames = getResultColumnNames();\n    auto outputs = std::make_unique<InterimResult>(std::move(resultColNames));\n    if (onResult_) {\n        onResult_(std::move(outputs));\n    } else if (resp_ == nullptr) {\n        resp_ = std::make_unique<cpp2::ExecutionResponse>();\n    }\n    doFinish(Executor::ProcessControl::kNext, ectx()->getGraphStats()->getGoStats());\n}\n\n\nbool GoExecutor::processFinalResult(RpcResponse &rpcResp, Callback cb) const {\n    auto all = rpcResp.responses();\n    auto spaceId = ectx()->rctx()->session()->space();\n    for (auto &resp : all) {\n        if (resp.get_vertices() == nullptr) {\n            continue;\n        }\n\n        std::unordered_map<TagID, std::shared_ptr<ResultSchemaProvider>> tagSchema;\n        auto *vschema = resp.get_vertex_schema();\n        if (vschema != nullptr) {\n            std::transform(vschema->cbegin(), vschema->cend(),\n                           std::inserter(tagSchema, tagSchema.begin()), [](auto &schema) {\n                               return std::make_pair(\n                                   schema.first,\n                                   std::make_shared<ResultSchemaProvider>(schema.second));\n                           });\n        }\n\n        std::unordered_map<EdgeType, std::shared_ptr<ResultSchemaProvider>> edgeSchema;\n        auto *eschema = resp.get_edge_schema();\n        if (eschema != nullptr) {\n            std::transform(eschema->cbegin(), eschema->cend(),\n                           std::inserter(edgeSchema, edgeSchema.begin()), [](auto &schema) {\n                               return std::make_pair(\n                                   schema.first,\n                                   std::make_shared<ResultSchemaProvider>(schema.second));\n                           });\n        }\n\n        if (tagSchema.empty() && edgeSchema.empty()) {\n            continue;\n        }\n\n        for (auto &vdata : resp.vertices) {\n            DCHECK(vdata.__isset.edge_data);\n            auto tagData = vdata.get_tag_data();\n            for (auto &edata : vdata.edge_data) {\n                auto it = edgeSchema.find(edata.type);\n                DCHECK(it != edgeSchema.end());\n                RowSetReader rsReader(it->second, edata.data);\n                auto iter = rsReader.begin();\n                auto edgeType = edata.type;\n                while (iter) {\n                    std::vector<SupportedType> colTypes;\n                    bool saveTypeFlag = false;\n                    auto &getters = expCtx_->getters();\n                    getters.getAliasProp = [&iter,\n                                            &spaceId,\n                                            &edgeType,\n                                            &saveTypeFlag,\n                                            &colTypes,\n                                            &edgeSchema,\n                                            srcid = vdata.get_vertex_id(),\n                                            this](const std::string &edgeName,\n                                                  const std::string &prop) -> OptVariantType {\n                        EdgeType type;\n                        auto found = expCtx_->getEdgeType(edgeName, type);\n                        if (!found) {\n                            return Status::Error(\n                                    \"Get edge type for `%s' failed in getters.\", edgeName.c_str());\n                        }\n\n                        if (isReversely()) {\n                            auto dst = RowReader::getPropByName(&*iter, _DST);\n                            if (saveTypeFlag) {\n                                colTypes.back() = edgeHolder_->getType(\n                                                    boost::get<VertexID>(value(dst)),\n                                                    srcid,\n                                                    std::abs(edgeType), prop);\n                            }\n                            if (std::abs(edgeType) != std::abs(type)) {\n                                return edgeHolder_->getDefaultProp(std::abs(type), prop);\n                            }\n\n                            return edgeHolder_->get(boost::get<VertexID>(value(dst)),\n                                                    srcid,\n                                                    std::abs(edgeType), prop);\n                        } else {\n                            if (saveTypeFlag) {\n                                colTypes.back() = iter->getSchema()->getFieldType(prop).type;\n                            }\n                            if (std::abs(edgeType) != std::abs(type)) {\n                                auto sit = edgeSchema.find(type);\n                                if (sit == edgeSchema.end()) {\n                                    return Status::Error(\"get schema failed\");\n                                }\n                                return RowReader::getDefaultProp(sit->second.get(), prop);\n                            }\n                            auto res = RowReader::getPropByName(&*iter, prop);\n                            if (!ok(res)) {\n                                return Status::Error(\n                                        folly::sformat(\"get prop({}.{}) failed\", edgeName, prop));\n                            }\n\n                            return value(std::move(res));\n                        }\n                    };\n                    getters.getSrcTagProp =\n                        [&iter, &spaceId, &tagData, &tagSchema, &saveTypeFlag, &colTypes, this](\n                            const std::string &tag, const std::string &prop) -> OptVariantType {\n                        TagID tagId;\n                        auto found = expCtx_->getTagId(tag, tagId);\n                        if (!found) {\n                            return Status::Error(\n                                    \"Get tag id for `%s' failed in getters.\", tag.c_str());\n                        }\n\n                        auto it2 =\n                            std::find_if(tagData.cbegin(), tagData.cend(), [&tagId](auto &td) {\n                                if (td.tag_id == tagId) {\n                                    return true;\n                                }\n\n                                return false;\n                            });\n\n                        if (it2 == tagData.cend()) {\n                            return RowReader::getDefaultProp(iter->getSchema().get(), prop);\n                        }\n\n                        if (saveTypeFlag) {\n                            colTypes.back() = tagSchema[tagId]->getFieldType(prop).type;\n                        }\n                        DCHECK(it2->__isset.data);\n                        auto vreader = RowReader::getRowReader(it2->data, tagSchema[tagId]);\n                        auto res = RowReader::getPropByName(vreader.get(), prop);\n                        if (!ok(res)) {\n                            return Status::Error(\n                                folly::sformat(\"get prop({}.{}) failed\", tag, prop));\n                        }\n                        return value(res);\n                    };\n                    getters.getDstTagProp = [&iter, &spaceId, &saveTypeFlag, &colTypes, this](\n                                                const std::string &tag,\n                                                const std::string &prop) -> OptVariantType {\n                        auto dst = RowReader::getPropByName(&*iter, \"_dst\");\n                        if (!ok(dst)) {\n                            return Status::Error(\n                                folly::sformat(\"get prop({}.{}) failed\", tag, prop));\n                        }\n                        auto vid = boost::get<int64_t>(value(std::move(dst)));\n\n                        TagID tagId;\n                        auto found = expCtx_->getTagId(tag, tagId);\n                        if (!found) {\n                            return Status::Error(\n                                    \"Get tag id for `%s' failed in getters.\", tag.c_str());\n                        }\n\n                        if (saveTypeFlag) {\n                            SupportedType type = vertexHolder_->getType(vid, tagId, prop);\n                            colTypes.back() = type;\n                        }\n                        return vertexHolder_->get(vid, tagId, prop);\n                    };\n                    getters.getVariableProp = [&saveTypeFlag, &colTypes, &vdata,\n                                               this](const std::string &prop) {\n                        if (saveTypeFlag) {\n                            colTypes.back() = getPropTypeFromInterim(prop);\n                        }\n                        return getPropFromInterim(vdata.get_vertex_id(), prop);\n                    };\n                    getters.getInputProp = [&saveTypeFlag, &colTypes, &vdata,\n                                            this](const std::string &prop) {\n                        if (saveTypeFlag) {\n                            colTypes.back() = getPropTypeFromInterim(prop);\n                        }\n                        return getPropFromInterim(vdata.get_vertex_id(), prop);\n                    };\n\n                    // Evaluate filter\n                    if (filter_ != nullptr) {\n                        auto value = filter_->eval();\n                        if (!value.ok()) {\n                            doError(std::move(value).status(),\n                                    ectx()->getGraphStats()->getGoStats());\n                            return false;\n                        }\n                        if (!Expression::asBool(value.value())) {\n                            ++iter;\n                            continue;\n                        }\n                    }\n                    std::vector<VariantType> record;\n                    record.reserve(yields_.size());\n                    saveTypeFlag = true;\n                    for (auto *column : yields_) {\n                        colTypes.emplace_back(SupportedType::UNKNOWN);\n                        auto *expr = column->expr();\n                        auto value = expr->eval();\n                        if (!value.ok()) {\n                            doError(std::move(value).status(),\n                                    ectx()->getGraphStats()->getGoStats());\n                            return false;\n                        }\n                        if (column->expr()->isTypeCastingExpression()) {\n                            auto exprPtr = static_cast<TypeCastingExpression *>(column->expr());\n                            colTypes.back() = SchemaHelper::columnTypeToSupportedType(\n                                                    exprPtr->getType());\n                        }\n                        record.emplace_back(std::move(value.value()));\n                    }\n                    cb(std::move(record), std::move(colTypes));\n                    ++iter;\n                }  // while `iter'\n            }\n        }   // for `vdata'\n    }   // for `resp'\n    return true;\n}\n\nOptVariantType GoExecutor::VertexHolder::getDefaultProp(TagID tid, const std::string &prop) const {\n    for (auto it = data_.cbegin(); it != data_.cend(); ++it) {\n        auto it2 = it->second.find(tid);\n        if (it2 != it->second.cend()) {\n            return RowReader::getDefaultProp(std::get<0>(it2->second).get(), prop);\n        }\n    }\n\n    return Status::Error(\"Unknown Vertex\");\n}\n\nSupportedType GoExecutor::VertexHolder::getDefaultPropType(TagID tid,\n                                                           const std::string &prop) const {\n    for (auto it = data_.cbegin(); it != data_.cend(); ++it) {\n        auto it2 = it->second.find(tid);\n        if (it2 != it->second.cend()) {\n            return std::get<0>(it2->second)->getFieldType(prop).type;\n        }\n    }\n\n    return nebula::cpp2::SupportedType::UNKNOWN;\n}\n\nOptVariantType GoExecutor::VertexHolder::get(VertexID id, TagID tid,\n                                             const std::string &prop) const {\n    auto iter = data_.find(id);\n    if (iter == data_.end()) {\n        return getDefaultProp(tid, prop);\n    }\n\n    auto iter2 = iter->second.find(tid);\n    if (iter2 == iter->second.end()) {\n        return getDefaultProp(tid, prop);\n    }\n\n    auto reader = RowReader::getRowReader(std::get<1>(iter2->second), std::get<0>(iter2->second));\n\n    auto res = RowReader::getPropByName(reader.get(), prop);\n    if (!ok(res)) {\n        return Status::Error(folly::sformat(\"get prop({}) failed\", prop));\n    }\n    return value(std::move(res));\n}\n\nSupportedType GoExecutor::VertexHolder::getType(VertexID id, TagID tid, const std::string &prop) {\n    auto iter = data_.find(id);\n    if (iter == data_.end()) {\n        return getDefaultPropType(tid, prop);\n    }\n\n    auto iter2 = iter->second.find(tid);\n    if (iter2 == iter->second.end()) {\n        return getDefaultPropType(tid, prop);\n    }\n\n    return std::get<0>(iter2->second)->getFieldType(prop).type;\n}\n\nvoid GoExecutor::VertexHolder::add(const storage::cpp2::QueryResponse &resp) {\n    auto *vertices = resp.get_vertices();\n    if (vertices == nullptr) {\n        return;\n    }\n\n    auto *vertexSchema = resp.get_vertex_schema();\n    if (vertexSchema == nullptr) {\n        return;\n    }\n    for (auto &vdata : *vertices) {\n        std::unordered_map<TagID, VData> m;\n        for (auto &td : vdata.tag_data) {\n            DCHECK(td.__isset.data);\n            auto it = vertexSchema->find(td.tag_id);\n            DCHECK(it != vertexSchema->end());\n            m[td.tag_id] = {std::make_shared<ResultSchemaProvider>(it->second), td.data};\n        }\n        data_[vdata.vertex_id] = std::move(m);\n    }\n}\n\n\nStatus GoExecutor::EdgeHolder::add(const storage::cpp2::EdgePropResponse &resp) {\n    if (resp.get_schema() == nullptr ||\n            resp.get_data() == nullptr ||\n            resp.get_data()->empty()) {\n        return Status::OK();\n    }\n\n    auto eschema = std::make_shared<ResultSchemaProvider>(*resp.get_schema());\n    RowSetReader rsReader(eschema, *resp.get_data());\n    auto collector = std::make_unique<Collector>();\n    auto iter = rsReader.begin();\n    while (iter) {\n        auto src = collector->getProp(eschema.get(), _SRC, &*iter);\n        auto dst = collector->getProp(eschema.get(), _DST, &*iter);\n        auto type = collector->getProp(eschema.get(), _TYPE, &*iter);\n        if (!src.ok() || !dst.ok() || !type.ok()) {\n            ++iter;\n            continue;\n        }\n        auto key = std::make_tuple(boost::get<int64_t>(src.value()),\n                                   boost::get<int64_t>(dst.value()),\n                                   boost::get<int64_t>(type.value()));\n        RowWriter rWriter(eschema);\n        auto fields = iter->numFields();\n        for (auto i = 0; i < fields; i++) {\n            auto result = RowReader::getPropByIndex(&*iter, i);\n            if (!ok(result)) {\n                return Status::Error(\"Get prop failed when add edge.\");\n            }\n            collector->collect(value(result), &rWriter);\n        }\n\n        VLOG(2) << \"EdgeHolder added edge, type: \" << type.value() << \" src: \" << src.value()\n                << \" dst: \" << dst.value();\n        edges_.emplace(std::move(key), std::make_pair(eschema, rWriter.encode()));\n\n        schemas_.emplace(boost::get<int64_t>(type.value()), eschema);\n        ++iter;\n    }\n\n    return Status::OK();\n}\n\n\nOptVariantType GoExecutor::EdgeHolder::get(VertexID src,\n                                           VertexID dst,\n                                           EdgeType type,\n                                           const std::string &prop) const {\n    auto iter = edges_.find(std::make_tuple(src, dst, type));\n    CHECK(iter != edges_.end());\n    auto reader = RowReader::getRowReader(iter->second.second, iter->second.first);\n    auto result = RowReader::getPropByName(reader.get(), prop);\n    if (!ok(result)) {\n        return Status::Error(\"Prop not found: `%s'\", prop.c_str());\n    }\n    return value(result);\n}\n\n\nSupportedType GoExecutor::EdgeHolder::getType(VertexID src,\n                                              VertexID dst,\n                                              EdgeType type,\n                                              const std::string &prop) const {\n    auto iter = edges_.find(std::make_tuple(src, dst, type));\n    CHECK(iter != edges_.end());\n    return iter->second.first->getFieldType(prop).type;\n}\n\n\nOptVariantType GoExecutor::EdgeHolder::getDefaultProp(EdgeType type,\n                                                      const std::string &prop) {\n    auto sit = schemas_.find(type);\n    if (sit == schemas_.end()) {\n        // This means that the reversely edge does not exist\n        if (prop == _DST || prop == _SRC || prop == _RANK) {\n            return static_cast<int64_t>(0);\n        } else {\n            return Status::Error(\"Get default prop failed in reversely traversal.\");\n        }\n    }\n\n    return RowReader::getDefaultProp(sit->second.get(), prop);\n}\n\n\nOptVariantType GoExecutor::getPropFromInterim(VertexID id, const std::string &prop) const {\n    auto rootId = id;\n    if (backTracker_ != nullptr) {\n        DCHECK_NE(steps_ , 1u);\n        rootId = backTracker_->get(id);\n    }\n    DCHECK(index_ != nullptr);\n    return index_->getColumnWithVID(rootId, prop);\n}\n\n\nSupportedType GoExecutor::getPropTypeFromInterim(const std::string &prop) const {\n    DCHECK(index_ != nullptr);\n    return index_->getColumnType(prop);\n}\n\n}   // namespace graph\n}   // namespace nebula\n", "idx": 8, "id": 22562, "msg": "", "proj": "vesoft-inc-nebula", "lang": "cpp"}
{"patch": "@@ -55,15 +55,23 @@ using namespace LxQt;\n ************************************************/\n LxQtTaskBar::LxQtTaskBar(ILxQtPanelPlugin *plugin, QWidget *parent) :\n     QFrame(parent),\n-    mButtonStyle(Qt::ToolButtonTextBesideIcon),\n-    mCheckedBtn(NULL),\n-    mCloseOnMiddleClick(true),\n-    mShowOnlyCurrentDesktopTasks(false),\n-    mAutoRotate(true),\n     mPlugin(plugin),\n     mPlaceHolder(new QWidget(this)),\n     mStyle(new ElidedButtonStyle())\n {\n+\n+    mMasterPopup = NULL;\n+    mSettings.autoRotate = true;\n+    mSettings.buttonWidth = 400;\n+    mSettings.closeOnMiddleClick = true;\n+    mSettings.enabledGrouping = true;\n+    mSettings.showOnlyCurrentDesktopTasks = false;\n+    mSettings.toolButtonStyle = Qt::ToolButtonTextBesideIcon;\n+    mSettings.eyeCandy = true;\n+    mSettings.showGroupWhenHover = false;\n+    //mSettings.showGroupWhenHoverOneWindow = false;\n+    mSettings.switchGroupWhenHover = true;\n+\n     mLayout = new LxQt::GridLayout(this);\n     setLayout(mLayout);\n     mLayout->setMargin(0);", "y": 0, "oldf": "/* BEGIN_COMMON_COPYRIGHT_HEADER\n * (c)LGPL2+\n *\n * LXDE-Qt - a lightweight, Qt based, desktop toolset\n * http://razor-qt.org\n * http://lxqt.org\n *\n * Copyright: 2011 Razor team\n *            2014 LXQt team\n * Authors:\n *   Alexander Sokoloff <sokoloff.a@gmail.com>\n *   Maciej P\u0142aza <plaza.maciej@gmail.com>\n *   Kuzma Shapran <kuzma.shapran@gmail.com>\n *\n * This program or library is free software; you can redistribute it\n * and/or modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * This library is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n\n * You should have received a copy of the GNU Lesser General\n * Public License along with this library; if not, write to the\n * Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,\n * Boston, MA 02110-1301 USA\n *\n * END_COMMON_COPYRIGHT_HEADER */\n\n#include <QApplication>\n#include <QDebug>\n#include <QToolButton>\n#include <QSettings>\n\n#include <LXQt/GridLayout>\n#include <XdgIcon>\n#include <QList>\n#include <QMimeData>\n#include <QDesktopWidget>\n#include <QWheelEvent>\n#include <QFlag>\n#include <QX11Info>\n#include <QDebug>\n\n#include \"lxqttaskbar.h\"\n#include \"lxqttaskbutton.h\"\n#include \"../panel/ilxqtpanelplugin.h\"\n\nusing namespace LxQt;\n\n/************************************************\n\n************************************************/\nLxQtTaskBar::LxQtTaskBar(ILxQtPanelPlugin *plugin, QWidget *parent) :\n    QFrame(parent),\n    mButtonStyle(Qt::ToolButtonTextBesideIcon),\n    mCheckedBtn(NULL),\n    mCloseOnMiddleClick(true),\n    mShowOnlyCurrentDesktopTasks(false),\n    mAutoRotate(true),\n    mPlugin(plugin),\n    mPlaceHolder(new QWidget(this)),\n    mStyle(new ElidedButtonStyle())\n{\n    mLayout = new LxQt::GridLayout(this);\n    setLayout(mLayout);\n    mLayout->setMargin(0);\n    realign();\n\n    mPlaceHolder->setStyle(mStyle);\n    mPlaceHolder->setMinimumSize(1, 1);\n    mPlaceHolder->setMaximumSize(QWIDGETSIZE_MAX, QWIDGETSIZE_MAX);\n    mPlaceHolder->setSizePolicy(QSizePolicy(QSizePolicy::Expanding, QSizePolicy::Expanding));\n    mLayout->addWidget(mPlaceHolder);\n\n    settingsChanged();\n    setAcceptDrops(true);\n\n    connect(KWindowSystem::self(), SIGNAL(stackingOrderChanged()), SLOT(refreshTaskList()));\n    connect(KWindowSystem::self(), SIGNAL(currentDesktopChanged(int)), SLOT(refreshTaskList()));\n    connect(KWindowSystem::self(), SIGNAL(activeWindowChanged(WId)), SLOT(activeWindowChanged(WId)));\n    connect(KWindowSystem::self(), SIGNAL(windowChanged(WId, NET::Properties, NET::Properties2)),\n            SLOT(windowChanged(WId, NET::Properties, NET::Properties2)));\n}\n\n/************************************************\n\n ************************************************/\nLxQtTaskBar::~LxQtTaskBar()\n{\n    delete mStyle;\n}\n\n/************************************************\n\n ************************************************/\nLxQtTaskButton* LxQtTaskBar::buttonByWindow(WId window) const\n{\n    if (mButtonsHash.contains(window))\n        return mButtonsHash.value(window);\n    return 0;\n}\n\n/************************************************\n\n ************************************************/\nbool LxQtTaskBar::windowOnActiveDesktop(WId window) const\n{\n    if (!mShowOnlyCurrentDesktopTasks)\n        return true;\n\n    int desktop = KWindowInfo(window, NET::WMDesktop).desktop();\n    if (desktop == NET::OnAllDesktops)\n        return true;\n\n    return desktop == KWindowSystem::currentDesktop();\n}\n\n/************************************************\n\n ************************************************/\nbool LxQtTaskBar::acceptWindow(WId window) const\n{\n    QFlags<NET::WindowTypeMask> ignoreList;\n    ignoreList |= NET::DesktopMask;\n    ignoreList |= NET::DockMask;\n    ignoreList |= NET::SplashMask;\n    ignoreList |= NET::ToolbarMask;\n    ignoreList |= NET::MenuMask;\n    ignoreList |= NET::PopupMenuMask;\n    ignoreList |= NET::NotificationMask;\n\n    KWindowInfo info(window, NET::WMWindowType | NET::WMState, NET::WM2TransientFor);\n    if (!info.valid())\n        return false;\n\n    if (NET::typeMatchesMask(info.windowType(NET::AllTypesMask), ignoreList))\n        return false;\n\n    if (info.state() & NET::SkipTaskbar)\n        return false;\n\n    // WM_TRANSIENT_FOR hint not set - normal window\n    WId transFor = info.transientFor();\n    if (transFor == 0 || transFor == window || transFor == (WId) QX11Info::appRootWindow())\n        return true;\n\n    info = KWindowInfo(transFor, NET::WMWindowType);\n\n    QFlags<NET::WindowTypeMask> normalFlag;\n    normalFlag |= NET::NormalMask;\n    normalFlag |= NET::DialogMask;\n    normalFlag |= NET::UtilityMask;\n\n    return !NET::typeMatchesMask(info.windowType(NET::AllTypesMask), normalFlag);\n}\n\n/************************************************\n\n ************************************************/\nvoid LxQtTaskBar::dragEnterEvent(QDragEnterEvent* event)\n{\n    if (event->mimeData()->hasFormat(\"lxqt/lxqttaskbutton\"))\n        event->acceptProposedAction();\n    else\n        event->ignore();\n    QWidget::dragEnterEvent(event);\n}\n\n/************************************************\n\n ************************************************/\nvoid LxQtTaskBar::dropEvent(QDropEvent* event)\n{\n    if (!event->mimeData()->hasFormat(\"lxqt/lxqttaskbutton\"))\n        return;\n\n    QDataStream stream(event->mimeData()->data(\"lxqt/lxqttaskbutton\"));\n    // window id for dropped button\n    qlonglong temp;\n    stream >> temp;\n    WId droppedWid = (WId) temp;\n    qDebug() << QString(\"Dropped window: %1\").arg(droppedWid);\n\n    int droppedIndex = mLayout->indexOf(mButtonsHash[droppedWid]);\n    int newPos = -1;\n    const int size = mLayout->count();\n    for (int i = 0; i < droppedIndex && newPos == -1; i++)\n        if (mLayout->itemAt(i)->widget()->x() + mLayout->itemAt(i)->widget()->width() / 2 > event->pos().x())\n            newPos = i;\n\n    for (int i = size - 1; i > droppedIndex && newPos == -1; i--)\n        if (mLayout->itemAt(i)->widget()->x() + mLayout->itemAt(i)->widget()->width() / 2 < event->pos().x())\n            newPos = i;\n\n    if (newPos == -1 || droppedIndex == newPos)\n        return;\n\n    qDebug() << QString(\"Dropped button shoud go to position %1\").arg(newPos);\n\n    mLayout->moveItem(droppedIndex, newPos);\n    mLayout->invalidate();\n\n    QWidget::dropEvent(event);\n}\n\n/************************************************\n\n ************************************************/\nvoid LxQtTaskBar::refreshTaskList()\n{\n    QList<WId> tmp = KWindowSystem::stackingOrder();\n\n    QMutableHashIterator<WId, LxQtTaskButton*> i(mButtonsHash);\n    while (i.hasNext())\n    {\n        i.next();\n        int n = tmp.removeAll(i.key());\n\n        if (!n)\n        {\n            // if the button we're removing is the currently selected app\n            if(i.value() == mCheckedBtn)\n                mCheckedBtn = NULL;\n            delete i.value();\n            i.remove();\n        }\n    }\n\n    foreach (WId wnd, tmp)\n    {\n        if (acceptWindow(wnd))\n        {\n            LxQtTaskButton* btn = new LxQtTaskButton(wnd, this);\n            btn->setStyle(mStyle);\n            btn->setToolButtonStyle(mButtonStyle);\n\n            mButtonsHash.insert(wnd, btn);\n            mLayout->addWidget(btn);\n        }\n    }\n    refreshButtonVisibility();\n    mLayout->invalidate();\n    activeWindowChanged();\n    realign();\n}\n\n/************************************************\n\n ************************************************/\nvoid LxQtTaskBar::refreshButtonRotation()\n{\n    bool autoRotate = mAutoRotate && (mButtonStyle != Qt::ToolButtonIconOnly);\n\n    ILxQtPanel::Position panelPosition = mPlugin->panel()->position();\n\n    QHashIterator<WId, LxQtTaskButton*> i(mButtonsHash);\n    while (i.hasNext())\n    {\n        i.next();\n        i.value()->setAutoRotation(autoRotate, panelPosition);\n    }\n}\n/************************************************\n\n ************************************************/\n\nvoid LxQtTaskBar::refreshButtonVisibility()\n{\n    bool haveVisibleWindow = false;\n    QHashIterator<WId, LxQtTaskButton*> i(mButtonsHash);\n    while (i.hasNext())\n    {\n        i.next();\n        bool isVisible = windowOnActiveDesktop(i.key());\n        haveVisibleWindow |= isVisible;\n        i.value()->setVisible(isVisible);\n    }\n    mPlaceHolder->setVisible(!haveVisibleWindow);\n    if (haveVisibleWindow)\n        mPlaceHolder->setFixedSize(0, 0);\n    else\n    {\n        mPlaceHolder->setMinimumSize(1, 1);\n        mPlaceHolder->setMaximumSize(QWIDGETSIZE_MAX, QWIDGETSIZE_MAX);\n    }\n\n}\n\n/************************************************\n\n ************************************************/\nvoid LxQtTaskBar::refreshIconGeometry()\n{\n    // FIXME: sometimes we get wrong globalPos here, especially\n    // after changing the pos or size of the panel.\n    // this might be caused by bugs in lxqtpanel.cpp.\n    QHashIterator<WId, LxQtTaskButton*> i(mButtonsHash);\n    while (i.hasNext())\n    {\n        i.next();\n        LxQtTaskButton* button = i.value();\n        QRect rect = button->geometry();\n        QPoint globalPos = mapToGlobal(button->pos());\n        rect.moveTo(globalPos);\n\n        NETWinInfo info(QX11Info::connection(), button->windowId(),\n                        (WId) QX11Info::appRootWindow(), NET::WMIconGeometry, 0);\n        NETRect nrect;\n        nrect.pos.x = rect.x();\n        nrect.pos.y = rect.y();\n        nrect.size.height = rect.height();\n        nrect.size.width = rect.width();\n        info.setIconGeometry(nrect);\n    }\n}\n\n/************************************************\n\n ************************************************/\nvoid LxQtTaskBar::activeWindowChanged(WId window)\n{\n    if (!window)\n        window = KWindowSystem::activeWindow();\n\n    LxQtTaskButton* btn = buttonByWindow(window);\n\n    if (mCheckedBtn != btn)\n    {\n        if (mCheckedBtn)\n            mCheckedBtn->setChecked(false);\n        if (btn)\n        {\n            btn->setChecked(true);\n            if (btn->hasUrgencyHint())\n                btn->setUrgencyHint(false);\n        }\n        mCheckedBtn = btn;\n    }\n}\n\n/************************************************\n\n ************************************************/\nvoid LxQtTaskBar::windowChanged(WId window, NET::Properties prop, NET::Properties2 prop2)\n{\n    LxQtTaskButton* button = buttonByWindow(window);\n    if (!button)\n        return;\n\n    // window changed virtual desktop\n    if (prop.testFlag(NET::WMDesktop))\n    {\n        if (mShowOnlyCurrentDesktopTasks)\n        {\n            int desktop = button->desktopNum();\n            button->setHidden(desktop != NET::OnAllDesktops && desktop != KWindowSystem::currentDesktop());\n        }\n    }\n\n    if (prop.testFlag(NET::WMVisibleName) || prop.testFlag(NET::WMName))\n        button->updateText();\n\n    // FIXME: NET::WMIconGeometry is causing high CPU and memory usage\n    if (prop.testFlag(NET::WMIcon) /*|| prop.testFlag(NET::WMIconGeometry)*/)\n        button->updateIcon();\n\n    if (prop.testFlag(NET::WMState))\n        button->setUrgencyHint(KWindowInfo(window, NET::WMState).hasState(NET::DemandsAttention));\n}\n\n/************************************************\n\n ************************************************/\nvoid LxQtTaskBar::setButtonStyle(Qt::ToolButtonStyle buttonStyle)\n{\n    mButtonStyle = buttonStyle;\n\n    QHashIterator<WId, LxQtTaskButton*> i(mButtonsHash);\n    while (i.hasNext())\n    {\n        i.next();\n        i.value()->setToolButtonStyle(mButtonStyle);\n    }\n}\n\n/************************************************\n\n ************************************************/\nvoid LxQtTaskBar::settingsChanged()\n{\n    mButtonWidth = mPlugin->settings()->value(\"buttonWidth\", 400).toInt();\n    QString s = mPlugin->settings()->value(\"buttonStyle\").toString().toUpper();\n\n    if (s == \"ICON\")\n        setButtonStyle(Qt::ToolButtonIconOnly);\n    else if (s == \"TEXT\")\n        setButtonStyle(Qt::ToolButtonTextOnly);\n    else\n        setButtonStyle(Qt::ToolButtonTextBesideIcon);\n\n    mShowOnlyCurrentDesktopTasks = mPlugin->settings()->value(\"showOnlyCurrentDesktopTasks\", mShowOnlyCurrentDesktopTasks).toBool();\n    mAutoRotate = mPlugin->settings()->value(\"autoRotate\", true).toBool();\n    mCloseOnMiddleClick = mPlugin->settings()->value(\"closeOnMiddleClick\", true).toBool();\n\n    refreshTaskList();\n}\n\n/************************************************\n\n ************************************************/\nvoid LxQtTaskBar::realign()\n{\n    mLayout->setEnabled(false);\n\n    refreshButtonRotation();\n\n    ILxQtPanel *panel = mPlugin->panel();\n    QSize maxSize = QSize(QWIDGETSIZE_MAX, QWIDGETSIZE_MAX);\n    QSize minSize = QSize(0, 0);\n\n    bool rotated = false;\n    if (panel->isHorizontal())\n    {\n        if (mButtonStyle == Qt::ToolButtonIconOnly)\n        {\n            // Horizontal + Icons **************\n            mLayout->setRowCount(panel->lineCount());\n            mLayout->setColumnCount(0);\n            mLayout->setStretch(LxQt::GridLayout::StretchVertical);\n\n            minSize.rheight() = 0;\n            minSize.rwidth()  = 0;\n\n            maxSize.rheight() = QWIDGETSIZE_MAX;\n            maxSize.rwidth()  = mButtonWidth;\n        }\n        else\n        {\n            // Horizontal + Text ***************\n            mLayout->setRowCount(panel->lineCount());\n            mLayout->setColumnCount(0);\n            mLayout->setStretch(LxQt::GridLayout::StretchHorizontal | LxQt::GridLayout::StretchVertical);\n\n            minSize.rheight() = 0;\n            minSize.rwidth()  = 0;\n\n            maxSize.rheight() = QWIDGETSIZE_MAX;\n            maxSize.rwidth()  = mButtonWidth;\n        }\n    }\n    else\n    {\n        if (mButtonStyle == Qt::ToolButtonIconOnly)\n        {\n            // Vertical + Icons ****************\n            mLayout->setRowCount(0);\n            mLayout->setColumnCount(panel->lineCount());\n            mLayout->setStretch(LxQt::GridLayout::StretchHorizontal);\n\n            minSize.rheight() = 0;\n            minSize.rwidth()  = 0;\n\n            maxSize.rheight() = QWIDGETSIZE_MAX;\n            maxSize.rwidth()  = QWIDGETSIZE_MAX;\n\n        }\n        else\n        {\n            if (mAutoRotate)\n            {\n                switch (panel->position())\n                {\n                case ILxQtPanel::PositionLeft:\n                case ILxQtPanel::PositionRight:\n                    rotated = true;\n                    break;\n\n                default:;\n                }\n            }\n\n            // Vertical + Text *****************\n            if (rotated)\n            {\n                mLayout->setColumnCount(panel->lineCount());\n                mLayout->setRowCount(0);\n                mLayout->setStretch(LxQt::GridLayout::StretchHorizontal | LxQt::GridLayout::StretchVertical);\n\n                minSize.rheight() = 0;\n                minSize.rwidth()  = 0;\n\n                maxSize.rheight() = mButtonWidth;\n                maxSize.rwidth()  = QWIDGETSIZE_MAX;\n            }\n            else\n            {\n                mLayout->setColumnCount(1);\n                mLayout->setRowCount(0);\n                mLayout->setStretch(LxQt::GridLayout::StretchHorizontal);\n\n                minSize.rheight() = 0;\n                minSize.rwidth()  = mButtonWidth;\n\n                maxSize.rheight() = QWIDGETSIZE_MAX;\n                maxSize.rwidth()  = QWIDGETSIZE_MAX;\n            }\n        }\n    }\n\n    mLayout->setCellMinimumSize(minSize);\n    mLayout->setCellMaximumSize(maxSize);\n\n    mLayout->setDirection(rotated ? LxQt::GridLayout::TopToBottom : LxQt::GridLayout::LeftToRight);\n    mLayout->setEnabled(true);\n    refreshIconGeometry();\n}\n\n/************************************************\n\n ************************************************/\n\nvoid LxQtTaskBar::mousePressEvent(QMouseEvent *event)\n{\n    // close the app on mouse middle click\n    if (mCloseOnMiddleClick && event->button() == Qt::MidButton)\n    {\n        // find the button at current cursor pos\n        QHashIterator<WId, LxQtTaskButton*> i(mButtonsHash);\n        while (i.hasNext())\n        {\n            i.next();\n            LxQtTaskButton* btn = i.value();\n            if (btn->geometry().contains(event->pos()) &&\n                (!mShowOnlyCurrentDesktopTasks || KWindowSystem::currentDesktop() == KWindowInfo(i.key(), NET::WMDesktop).desktop()))\n            {\n                btn->closeApplication();\n                break;\n            }\n        }\n    }\n    QFrame::mousePressEvent(event);\n}\n\n/************************************************\n\n ************************************************/\nvoid LxQtTaskBar::wheelEvent(QWheelEvent* event)\n{\n    if (!mCheckedBtn)\n        return;\n\n    int current = mLayout->indexOf(mCheckedBtn);\n    if (current == -1)\n        return;\n\n    int delta = event->delta() < 0 ? 1 : -1;\n    for (int ix = current + delta; 0 <= ix && ix < mLayout->count(); ix += delta)\n    {\n        QLayoutItem *item = mLayout->itemAt(ix);\n        if (!item)\n            continue;\n\n        WId window = ((LxQtTaskButton *) item->widget())->windowId();\n        if (acceptWindow(window) && windowOnActiveDesktop(window))\n        {\n            KWindowSystem::activateWindow(window);\n            break;\n        }\n    }\n}\n\n/************************************************\n\n ************************************************/\nvoid LxQtTaskBar::resizeEvent(QResizeEvent* event)\n{\n    refreshIconGeometry();\n    return QWidget::resizeEvent(event);\n}\n\n/************************************************\n\n ************************************************/\nvoid LxQtTaskBar::changeEvent(QEvent* event)\n{\n    // if current style is changed, reset the base style of the proxy style\n    // so we can apply the new style correctly to task buttons.\n    if(event->type() == QEvent::StyleChange)\n        mStyle->setBaseStyle(NULL);\n\n    QFrame::changeEvent(event);\n}\n", "idx": 2, "id": 4672, "msg": "", "proj": "lxqt-lxqt-panel", "lang": "cpp"}
{"patch": "@@ -218,7 +218,6 @@ analyze_callee_save_reg(dcontext_t *dcontext, callee_info_t *ci)\n     instrlist_t *ilist = ci->ilist;\n     instr_t *top, *bot, *instr;\n     reg_id_t reg1, reg2;\n-    bool not_found;\n     /* pointers to instructions of interest */\n     instr_t *enter = NULL, *leave = NULL;\n ", "y": 0, "oldf": "/* **********************************************************\n * Copyright (c) 2016-2017 ARM Limited. All rights reserved.\n * **********************************************************/\n\n/*\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n * * Redistributions of source code must retain the above copyright notice,\n *   this list of conditions and the following disclaimer.\n *\n * * Redistributions in binary form must reproduce the above copyright notice,\n *   this list of conditions and the following disclaimer in the documentation\n *   and/or other materials provided with the distribution.\n *\n * * Neither the name of ARM Limited nor the names of its contributors may be\n *   used to endorse or promote products derived from this software without\n *   specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED. IN NO EVENT SHALL ARM LIMITED OR CONTRIBUTORS BE LIABLE\n * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\n * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH\n * DAMAGE.\n */\n\n/* file \"clean_call_opt.c\" */\n\n#include \"../globals.h\"\n#include \"arch.h\"\n#include \"../clean_call_opt.h\"\n\n#ifdef CLIENT_INTERFACE\n\n/* For fast recognition we do not check the instructions operand by operand.\n * Instead we test the encoding directly.\n */\n\n/* remove variable bits in the encoding */\n# define STP_LDP_ENC_MASK 0x7fc07fff\n# define STR_LDR_ENC_MASK 0xbfc003ff\n# define MOV_STK_ENC_MASK 0x7f0003ff\n# define STP_LDP_REG_MASK 0xffff83e0\n# define STR_LDR_REG_MASK 0xffffffe0\n\n/* stp x29, x30, [sp, #frame_size]! */\n# define PUSH_FP_LR_ENC 0x29807bfd\n/* ldp x29, x30, [sp], #frame_size */\n# define POP_FP_LR_ENC 0x28c07bfd\n/* add sp, sp, #frame_size */\n# define ADD_SP_ENC 0x110003ff\n/* sub sp, sp, #frame_size */\n# define SUB_SP_ENC 0x510003ff\n/* mov x29, sp */\n# define MOV_X29_SP_ENC 0x910003fd\n/* stp xx, xx, [sp, #offset] */\n# define STP_SP_ENC 0x290003e0\n/* ldp xx, xx, [sp, #offset] */\n# define LDP_SP_ENC 0x294003e0\n/* str xx, [sp, #offset] */\n# define STR_SP_ENC 0xb90003e0\n/* ldr xx, [sp, #offset] */\n# define LDR_SP_ENC 0xb94003e0\n\nstatic inline bool\ninstr_is_push_fp_and_lr(instr_t *instr)\n{\n    uint enc = *(uint *)instr->bytes;\n    return (enc & STP_LDP_ENC_MASK) == PUSH_FP_LR_ENC;\n}\n\nstatic inline bool\ninstr_is_pop_fp_and_lr(instr_t *instr)\n{\n    uint enc = *(uint *)instr->bytes;\n    return (enc & STP_LDP_ENC_MASK) == POP_FP_LR_ENC;\n}\n\nstatic inline bool\ninstr_is_move_frame_ptr(instr_t *instr)\n{\n    uint enc = *(uint *)instr->bytes;\n    return enc == MOV_X29_SP_ENC;\n}\n\nstatic inline bool\ninstr_is_add_stk_ptr(instr_t *instr)\n{\n    uint enc = *(uint *)instr->bytes;\n    return (enc & MOV_STK_ENC_MASK) == ADD_SP_ENC;\n}\n\nstatic inline bool\ninstr_is_sub_stk_ptr(instr_t *instr)\n{\n    uint enc = *(uint *)instr->bytes;\n    return (enc & MOV_STK_ENC_MASK) == SUB_SP_ENC;\n}\n\nstatic inline bool\ninstr_is_push_reg_pair(instr_t *instr, reg_id_t *reg1, reg_id_t *reg2)\n{\n    uint enc = *(uint *)instr->bytes;\n    enc = enc & STP_LDP_ENC_MASK;\n    if ((enc & STP_LDP_REG_MASK) != STP_SP_ENC)\n        return false;\n    *reg1 = (reg_id_t)(enc & 31) + DR_REG_START_GPR;\n    *reg2 = (reg_id_t)(enc >> 10 & 31) + DR_REG_START_GPR;\n    return true;\n}\n\nstatic inline bool\ninstr_is_pop_reg_pair(instr_t *instr, reg_id_t *reg1, reg_id_t *reg2)\n{\n    uint enc = *(uint *)instr->bytes;\n    enc = enc & STP_LDP_ENC_MASK;\n    if ((enc & STP_LDP_REG_MASK) != LDP_SP_ENC)\n        return false;\n    *reg1 = (reg_id_t)(enc & 31) + DR_REG_START_GPR;\n    *reg2 = (reg_id_t)(enc >> 10 & 31) + DR_REG_START_GPR;\n    return true;\n}\n\nstatic inline bool\ninstr_is_push_reg(instr_t *instr, reg_id_t *reg)\n{\n    uint enc = *(uint *)instr->bytes;\n    enc = enc & STR_LDR_ENC_MASK;\n    if ((enc & STR_LDR_REG_MASK) != STR_SP_ENC)\n        return false;\n    *reg = (reg_id_t)(enc & 31) + DR_REG_START_GPR;\n    return true;\n}\n\nstatic inline bool\ninstr_is_pop_reg(instr_t *instr, reg_id_t *reg)\n{\n    uint enc = *(uint *)instr->bytes;\n    enc = enc & STR_LDR_ENC_MASK;\n    if ((enc & STR_LDR_REG_MASK) != LDR_SP_ENC)\n        return false;\n    *reg = (reg_id_t)(enc & 31) + DR_REG_START_GPR;\n    return true;\n}\n\nvoid\nanalyze_callee_regs_usage(dcontext_t *dcontext, callee_info_t *ci)\n{\n    instrlist_t *ilist = ci->ilist;\n    instr_t *instr;\n    uint i, num_regparm;\n\n    /* XXX implement bitset for optimisation */\n    memset(ci->reg_used, 0, sizeof(bool) * NUM_GP_REGS);\n    ci->num_simd_used = 0;\n    memset(ci->simd_used, 0, sizeof(bool) * NUM_SIMD_REGS);\n\n    for (instr  = instrlist_first(ilist);\n         instr != NULL;\n         instr  = instr_get_next(instr)) {\n\n        /* General purpose registers */\n        for (i = 0; i < NUM_GP_REGS; i++) {\n            reg_id_t reg = DR_REG_START_GPR + (reg_id_t)i;\n            if (!ci->reg_used[i] &&\n                instr_uses_reg(instr, reg)) {\n                LOG(THREAD, LOG_CLEANCALL, 2,\n                    \"CLEANCALL: callee \"PFX\" uses REG %s at \"PFX\"\\n\",\n                    ci->start, reg_names[reg],\n                    instr_get_app_pc(instr));\n                ci->reg_used[i] = true;\n                callee_info_reserve_slot(ci, SLOT_REG, reg);\n            }\n        }\n\n        /* SIMD register usage */\n        for (i=0; i<NUM_SIMD_REGS; i++) {\n            if (!ci->simd_used[i] &&\n                instr_uses_reg(instr, (DR_REG_Q0 + (reg_id_t)i))) {\n                LOG(THREAD, LOG_CLEANCALL, 2,\n                    \"CLEANCALL: callee \"PFX\" uses VREG%d at \"PFX\"\\n\",\n                    ci->start, i, instr_get_app_pc(instr));\n                ci->simd_used[i] = true;\n                ci->num_simd_used++;\n            }\n        }\n    }\n\n    num_regparm = MIN(ci->num_args, NUM_REGPARM);\n    for (i = 0; i < num_regparm; i++) {\n        reg_id_t reg = regparms[i];\n        if (!ci->reg_used[reg - DR_REG_START_GPR]) {\n            LOG(THREAD, LOG_CLEANCALL, 2,\n                \"CLEANCALL: callee \"PFX\" uses REG %s for arg passing\\n\",\n                ci->start, reg_names[reg]);\n            ci->reg_used[reg - DR_REG_START_GPR] = true;\n            callee_info_reserve_slot(ci, SLOT_REG, reg);\n        }\n    }\n    /* FIXME i#1621: the following checks are still missing:\n     *    - analysis of eflags (depends on i#2263)\n     */\n}\n\n/* We use stp/ldp/str/ldr [sp, #imm] pattern to detect callee saved registers,\n * and assume that the code later won't change those saved value\n * on the stack.\n */\nvoid\nanalyze_callee_save_reg(dcontext_t *dcontext, callee_info_t *ci)\n{\n    instrlist_t *ilist = ci->ilist;\n    instr_t *top, *bot, *instr;\n    reg_id_t reg1, reg2;\n    bool not_found;\n    /* pointers to instructions of interest */\n    instr_t *enter = NULL, *leave = NULL;\n\n    ci->num_callee_save_regs = 0;\n    top = instrlist_first(ilist);\n    bot = instrlist_last(ilist);\n\n    /* zero or one instruction only, no callee save */\n    if (top == bot)\n        return;\n\n    /* Stack frame analysis\n     * A typical function (fewer than 8 arguments) has the following form:\n     * (a) stp x29, x30, [sp, #-frame_size]!\n     * (b) mov x29, sp\n     * (c) stp x19, x20, [sp, #callee_save_offset]\n     * (c) str x21, [sp, #callee_save_offset+8]\n     * ...\n     * (c) ldp x19, x20, [sp, #callee_save_offset]\n     * (c) ldr x21, [sp, #callee_save_offset+8]\n     * (a) ldp x29, x30, [sp], #frame_size\n     *     ret\n     * Pair (a) appears when the callee calls another function.\n     * If the callee is a leaf function, pair (a) typically has the following form:\n     * (a) sub, sp, sp, #frame_size\n     * (a) add, sp, sp, #frame_size\n     * If (b) is found, x29 is used as the frame pointer.\n     * Pair (c) may have two forms, using stp/ldp for register pairs\n     * or str/ldr for a single callee-saved register.\n     */\n     /* Check for pair (a) */\n    for (instr = top; instr != bot; instr = instr_get_next(instr)) {\n        if (instr->bytes == NULL)\n            continue;\n        if (instr_is_push_fp_and_lr(instr) ||\n            instr_is_sub_stk_ptr(instr)) {\n            enter = instr;\n            break;\n        }\n    }\n    if (enter != NULL) {\n        for (instr = bot; instr != enter; instr = instr_get_prev(instr)) {\n            if (!instr->bytes)\n                continue;\n            if (instr_is_pop_fp_and_lr(instr) ||\n                instr_is_add_stk_ptr(instr)) {\n                leave = instr;\n                break;\n            }\n        }\n    }\n    /* Check for (b) */\n    ci->standard_fp = false;\n    if (enter != NULL && leave != NULL &&\n        (ci->bwd_tgt == NULL || instr_get_app_pc(enter) <  ci->bwd_tgt) &&\n        (ci->fwd_tgt == NULL || instr_get_app_pc(leave) >= ci->fwd_tgt)) {\n        for (instr = instr_get_next(enter);\n             instr != leave;\n             instr = instr_get_next(instr)) {\n            if (instr_is_move_frame_ptr(instr)) {\n                ci->standard_fp = true;\n                /* Remove this instruction. */\n                instrlist_remove(ilist, instr);\n                instr_destroy(GLOBAL_DCONTEXT, instr);\n                break;\n            }\n        }\n        if (ci->standard_fp) {\n            LOG(THREAD, LOG_CLEANCALL, 2,\n                \"CLEANCALL: callee \"PFX\" use X29 as frame pointer\\n\", ci->start);\n        }\n        /* remove pair (a) */\n        instrlist_remove(ilist, enter);\n        instrlist_remove(ilist, leave);\n        instr_destroy(GLOBAL_DCONTEXT, enter);\n        instr_destroy(GLOBAL_DCONTEXT, leave);\n        top = instrlist_first(ilist);\n        bot = instrlist_last(ilist);\n    }\n    /* Check for (c): callee-saved registers */\n    while (top != NULL && bot != NULL) {\n        /* if not in the first/last bb, break */\n        if ((ci->bwd_tgt != NULL && instr_get_app_pc(top) >= ci->bwd_tgt) ||\n            (ci->fwd_tgt != NULL && instr_get_app_pc(bot) <  ci->fwd_tgt) ||\n            instr_is_cti(top) || instr_is_cti(bot))\n            break;\n        if (instr_is_push_reg_pair(top, &reg1, &reg2)) {\n            not_found = true;\n            /* If a save reg pair is found and the register,\n             * search from the bottom for restore.\n             */\n            for (instr = bot; !instr_is_cti(instr); instr = instr_get_prev(instr)) {\n                reg_id_t reg1_c, reg2_c;\n                if (instr_is_pop_reg_pair(instr, &reg1_c, &reg2_c) &&\n                    reg1 == reg1_c &&\n                    reg2 == reg2_c) {\n                    /* found a save/restore pair */\n                    ci->callee_save_regs[reg1] = true;\n                    ci->callee_save_regs[reg2] = true;\n                    ci->num_callee_save_regs += 2;\n                    /* remove & destroy the pairs */\n                    instrlist_remove(ilist, top);\n                    instr_destroy(GLOBAL_DCONTEXT, top);\n                    instrlist_remove(ilist, instr);\n                    instr_destroy(GLOBAL_DCONTEXT, instr);\n                    /* get next pair */\n                    top = instrlist_first(ilist);\n                    bot = instrlist_last(ilist);\n                    not_found = false;\n                }\n            }\n            if (not_found)\n                break;\n        } else if (instr_is_push_reg(top, &reg1)) {\n            not_found = true;\n            /* If a save reg is found, search from the bottom for restore. */\n            for (instr = bot; instr != top; instr = instr_get_prev(instr)) {\n                reg_id_t reg1_c;\n                if (instr_is_pop_reg(instr, &reg1_c) &&\n                    reg1 == reg1_c) {\n                    /* found a save/restore pair */\n                    ci->callee_save_regs[reg1] = true;\n                    ci->num_callee_save_regs += 1;\n                    /* remove & destroy the pairs */\n                    instrlist_remove(ilist, top);\n                    instr_destroy(GLOBAL_DCONTEXT, top);\n                    instrlist_remove(ilist, instr);\n                    instr_destroy(GLOBAL_DCONTEXT, instr);\n                    /* get next pair */\n                    top = instrlist_first(ilist);\n                    bot = instrlist_last(ilist);\n                    break;\n                }\n            }\n            if (not_found)\n                break;\n        } else\n            break;\n    }\n}\n\nvoid\nanalyze_callee_tls(dcontext_t *dcontext, callee_info_t *ci)\n{\n    /* FIXME i#1621: NYI on AArch64\n     * Non-essential for cleancall_opt=1 optimizations.\n     */\n}\n\napp_pc\ncheck_callee_instr_level2(dcontext_t *dcontext, callee_info_t *ci, app_pc next_pc,\n                          app_pc cur_pc, app_pc tgt_pc)\n{\n    /* FIXME i#1569: For opt level greater than 1, we abort. */\n    return NULL;\n}\n\nbool\ncheck_callee_ilist_inline(dcontext_t *dcontext, callee_info_t *ci)\n{\n    ASSERT_NOT_IMPLEMENTED(false); /* FIXME i#1569: NYI on AArch64 */\n    return false;\n}\n\nvoid\nanalyze_clean_call_aflags(dcontext_t *dcontext,\n                          clean_call_info_t *cci, instr_t *where)\n{\n    /* FIXME i#1621: NYI on AArch64\n     * Non-essential for cleancall_opt=1 optimizations.\n     */\n}\n\nvoid\ninsert_inline_reg_save(dcontext_t *dcontext, clean_call_info_t *cci,\n                       instrlist_t *ilist, instr_t *where, opnd_t *args)\n{\n    ASSERT_NOT_IMPLEMENTED(false); /* FIXME i#1569: NYI on AArch64 */\n}\n\nvoid\ninsert_inline_reg_restore(dcontext_t *dcontext, clean_call_info_t *cci,\n                          instrlist_t *ilist, instr_t *where)\n{\n    ASSERT_NOT_IMPLEMENTED(false); /* FIXME i#1569: NYI on AArch64 */\n}\n\nvoid\ninsert_inline_arg_setup(dcontext_t *dcontext, clean_call_info_t *cci,\n                        instrlist_t *ilist, instr_t *where, opnd_t *args)\n{\n    ASSERT_NOT_IMPLEMENTED(false); /* FIXME i#1569: NYI on AArch64 */\n}\n\n#endif /* CLIENT_INTERFACE */\n", "idx": 4, "id": 11915, "msg": "", "proj": "DynamoRIO-dynamorio", "lang": "c"}
{"patch": "@@ -36,6 +36,16 @@ class CommandOperation extends OperationBase {\n   constructor(db, command, options, collection) {\n     super(options);\n \n+    if (!this.hasAspect(Aspect.WRITE_OPERATION)) {\n+      if (collection != null) {\n+        this.options.readPreference = resolveReadPreference(collection, options);\n+      } else {\n+        this.options.readPreference = resolveReadPreference(db, options);\n+      }\n+    } else {\n+      this.options.readPreference = ReadPreference.primary;\n+    }\n+\n     this.db = db;\n     this.command = command;\n ", "y": 1, "oldf": "'use strict';\n\nconst Aspect = require('./operation').Aspect;\nconst OperationBase = require('./operation').OperationBase;\nconst applyWriteConcern = require('../utils').applyWriteConcern;\nconst debugOptions = require('../utils').debugOptions;\nconst handleCallback = require('../utils').handleCallback;\nconst MongoError = require('../core').MongoError;\nconst ReadPreference = require('../core').ReadPreference;\nconst resolveReadPreference = require('../utils').resolveReadPreference;\nconst MongoDBNamespace = require('../utils').MongoDBNamespace;\n\nconst debugFields = [\n  'authSource',\n  'w',\n  'wtimeout',\n  'j',\n  'native_parser',\n  'forceServerObjectId',\n  'serializeFunctions',\n  'raw',\n  'promoteLongs',\n  'promoteValues',\n  'promoteBuffers',\n  'bufferMaxEntries',\n  'numberOfRetries',\n  'retryMiliSeconds',\n  'readPreference',\n  'pkFactory',\n  'parentDb',\n  'promiseLibrary',\n  'noListener'\n];\n\nclass CommandOperation extends OperationBase {\n  constructor(db, command, options, collection) {\n    super(options);\n\n    this.db = db;\n    this.command = command;\n\n    if (collection) {\n      this.collection = collection;\n    }\n  }\n\n  execute(callback) {\n    const db = this.db;\n    const command = this.command;\n    const options = this.options;\n    const collection = this.collection || undefined;\n\n    // Did the user destroy the topology\n    if (db.serverConfig && db.serverConfig.isDestroyed())\n      return callback(new MongoError('topology was destroyed'));\n    // Get the db name we are executing against\n    const dbName = options.dbName || options.authdb || db.databaseName;\n\n    // Convert the readPreference if its not a write\n    if (!this.hasAspect(Aspect.WRITE_OPERATION)) {\n      if (collection != null) {\n        options.readPreference = resolveReadPreference(collection, options);\n      } else {\n        options.readPreference = resolveReadPreference(db, options);\n      }\n    } else {\n      options.readPreference = ReadPreference.primary;\n      applyWriteConcern(command, { db }, options);\n    }\n\n    // Debug information\n    if (db.s.logger.isDebug())\n      db.s.logger.debug(\n        `executing command ${JSON.stringify(\n          command\n        )} against ${dbName}.$cmd with options [${JSON.stringify(\n          debugOptions(debugFields, options)\n        )}]`\n      );\n\n    const namespace = new MongoDBNamespace(dbName, '$cmd');\n\n    // Execute command\n    db.s.topology.command(namespace, command, options, (err, result) => {\n      if (err) return handleCallback(callback, err);\n      if (options.full) return handleCallback(callback, null, result);\n      handleCallback(callback, null, result.result);\n    });\n  }\n}\n\nmodule.exports = CommandOperation;\n", "idx": 1, "id": 15513, "msg": "We should, either in `OperationBase` or here, be resolving `WriteConcern`, `ReadConcern`, and `retryWrites`", "proj": "mongodb-node-mongodb-native", "lang": "js"}
{"patch": "@@ -1,12 +1,15 @@\n # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n # SPDX - License - Identifier: Apache - 2.0\n \n+# Purpose\n+# This code example demonstrates how to get the contents of an object in an Amazon Simple Storage Solution (Amazon S3) bucket.\n+# The object's content must have already been encrypted with an RSA public key.\n+\n+# snippet-start:[s3.s3_get_cspk_decrypt_item.rb]\n+\n require 'aws-sdk-s3'\n require 'openssl'\n \n-# Gets the contents of an object in an Amazon S3 bucket. The\n-#   object's content must have already been encrypted with an RSA public key.\n-#\n # Prerequisites:\n #\n # - An Amazon S3 bucket.", "y": 1, "oldf": "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\r\n# SPDX - License - Identifier: Apache - 2.0\r\n\r\nrequire 'aws-sdk-s3'\r\nrequire 'openssl'\r\n\r\n# Gets the contents of an object in an Amazon S3 bucket. The\r\n#   object's content must have already been encrypted with an RSA public key.\r\n#\r\n# Prerequisites:\r\n#\r\n# - An Amazon S3 bucket.\r\n# - An object in the bucket. This object contains the encrypted content.\r\n# - The RSA private key corresponding to the RSA public key that was\r\n#     originally used to encrypt the object's content.\r\n#\r\n# @param s3_client [Aws::S3::Client] An initialized Amazon S3 client.\r\n# @param bucket_name [String] The name of the bucket.\r\n# @param object_key [String] The name of the object to get.\r\n# @param private_key_file [String] The name of the private key file.\r\n# @return [String] If successful, the object's decrypted content; otherwise,\r\n#   diagnostic information about the unsuccessful attempt.\r\n# @example\r\n#   s3_client = Aws::S3::Client.new(region: 'us-east-1')\r\n#   puts get_decrypted_object_content(\r\n#     s3_client,\r\n#     'doc-example-bucket',\r\n#     'my-file.txt',\r\n#     'my-private-key.pem'\r\n#   )\r\ndef get_decrypted_object_content(\r\n  s3_client,\r\n  bucket_name,\r\n  object_key,\r\n  private_key_file\r\n)\r\n  response = s3_client.get_object(\r\n    bucket: bucket_name,\r\n    key: object_key)\r\n  if defined?(response.body)\r\n    encrypted_content = response.body.read\r\n    private_key = OpenSSL::PKey::RSA.new(File.read(private_key_file))\r\n    private_key.private_decrypt(Base64.decode64(encrypted_content))\r\n  else\r\n    return 'Error: Object content empty or unavailable.'\r\n  end\r\nrescue StandardError => e\r\n  return \"Error getting object content: #{e.message}\"\r\nend\r\n\r\n# Full example call:\r\ndef run_me\r\n  bucket_name = 'doc-example-bucket'\r\n  object_key = 'my-file.txt'\r\n  region = 'us-east-1'\r\n  s3_client = Aws::S3::Client.new(region: region)\r\n  private_key_file = 'my-private-key.pem'\r\n\r\n  puts get_decrypted_object_content(\r\n    s3_client,\r\n    bucket_name,\r\n    object_key,\r\n    private_key_file\r\n  )\r\nend\r\n\r\nrun_me if $PROGRAM_NAME == __FILE__\r\n", "idx": 1, "id": 20546, "msg": "Simple Storage **Service**", "proj": "awsdocs-aws-doc-sdk-examples", "lang": "rb"}
{"patch": "@@ -184,7 +184,6 @@ def FingerprintsFromDetails(details, reportFreq=10):\n     smiCol = 1\n   elif details.inFileName and details.useSD:\n     conn = None\n-    dataset = None\n     if not details.idName:\n       details.idName = 'ID'\n     dataSet = []", "y": 0, "oldf": "#\n#  Copyright (c) 2003-2006 Rational Discovery LLC\n#\n#   @@ All Rights Reserved @@\n#  This file is part of the RDKit.\n#  The contents are covered by the terms of the BSD license\n#  which is included in the file license.txt, found at the root\n#  of the RDKit source tree.\n#\n\"\"\" utility functionality for fingerprinting sets of molecules\n includes a command line app for working with fingerprints\n and databases\n\n\nSample Usage:\n\n  python FingerprintMols.py  -d data.gdb \\\n        -t 'raw_dop_data' --smilesName=\"Structure\" --idName=\"Mol_ID\"  \\\n        --outTable=\"daylight_sig\"\n\n\n\"\"\"\n\n\n\nimport getopt\nimport sys\n\nfrom rdkit import Chem\nfrom rdkit import DataStructs\nfrom rdkit.Chem import MACCSkeys\nfrom rdkit.ML.Cluster import Murtagh\nimport pickle\n\n\ndef error(msg):\n  sys.stderr.write(msg)\n\n\ndef message(msg):\n  sys.stderr.write(msg)\n\n\ndef GetRDKFingerprint(mol):\n  \"\"\" uses default parameters \"\"\"\n  details = FingerprinterDetails()\n  return FingerprintMol(mol, **details.__dict__)\n\n\ndef FoldFingerprintToTargetDensity(fp, **fpArgs):\n  nOn = fp.GetNumOnBits()\n  nTot = fp.GetNumBits()\n  while (float(nOn) / nTot < fpArgs['tgtDensity']):\n    if nTot / 2 > fpArgs['minSize']:\n      fp = DataStructs.FoldFingerprint(fp, 2)\n      nOn = fp.GetNumOnBits()\n      nTot = fp.GetNumBits()\n    else:\n      break\n  return fp\n\n\ndef FingerprintMol(mol, fingerprinter=Chem.RDKFingerprint, **fpArgs):\n  if not fpArgs:\n    details = FingerprinterDetails()\n    fpArgs = details.__dict__\n\n  if fingerprinter != Chem.RDKFingerprint:\n    fp = fingerprinter(mol, **fpArgs)\n    fp = FoldFingerprintToTargetDensity(fp, **fpArgs)\n  else:\n    fp = fingerprinter(mol, fpArgs['minPath'], fpArgs['maxPath'], fpArgs['fpSize'],\n                       fpArgs['bitsPerHash'], fpArgs['useHs'], fpArgs['tgtDensity'],\n                       fpArgs['minSize'])\n  return fp\n\n\ndef FingerprintsFromSmiles(dataSource, idCol, smiCol, fingerprinter=Chem.RDKFingerprint,\n                           reportFreq=10, maxMols=-1, **fpArgs):\n  \"\"\" fpArgs are passed as keyword arguments to the fingerprinter\n\n  Returns a list of 2-tuples: (ID,fp)\n\n  \"\"\"\n  res = []\n  nDone = 0\n  for entry in dataSource:\n    ID, smi = str(entry[idCol]), str(entry[smiCol])\n    mol = Chem.MolFromSmiles(smi)\n    if mol is not None:\n      fp = FingerprintMol(mol, fingerprinter, **fpArgs)\n      res.append((ID, fp))\n      nDone += 1\n      if reportFreq > 0 and not nDone % reportFreq:\n        message('Done %d molecules\\n' % (nDone))\n      if maxMols > 0 and nDone >= maxMols:\n        break\n    else:\n      error('Problems parsing SMILES: %s\\n' % smi)\n  return res\n\n\ndef FingerprintsFromMols(mols, fingerprinter=Chem.RDKFingerprint, reportFreq=10, maxMols=-1,\n                         **fpArgs):\n  \"\"\" fpArgs are passed as keyword arguments to the fingerprinter\n\n  Returns a list of 2-tuples: (ID,fp)\n\n  \"\"\"\n  res = []\n  nDone = 0\n  for ID, mol in mols:\n    if mol:\n      fp = FingerprintMol(mol, fingerprinter, **fpArgs)\n      res.append((ID, fp))\n      nDone += 1\n      if reportFreq > 0 and not nDone % reportFreq:\n        message('Done %d molecules\\n' % (nDone))\n      if maxMols > 0 and nDone >= maxMols:\n        break\n    else:\n      error('Problems parsing SMILES: %s\\n' % smi)\n  return res\n\n\ndef FingerprintsFromPickles(dataSource, idCol, pklCol, fingerprinter=Chem.RDKFingerprint,\n                            reportFreq=10, maxMols=-1, **fpArgs):\n  \"\"\" fpArgs are passed as keyword arguments to the fingerprinter\n\n  Returns a list of 2-tuples: (ID,fp)\n\n  \"\"\"\n  res = []\n  nDone = 0\n  for entry in dataSource:\n    ID, pkl = str(entry[idCol]), str(entry[pklCol])\n    mol = Chem.Mol(pkl)\n    if mol is not None:\n      fp = FingerprintMol(mol, fingerprinter, **fpArgs)\n      res.append((ID, fp))\n      nDone += 1\n      if reportFreq > 0 and not nDone % reportFreq:\n        message('Done %d molecules\\n' % (nDone))\n      if maxMols > 0 and nDone >= maxMols:\n        break\n    else:\n      error('Problems parsing pickle for ID: %s\\n' % ID)\n  return res\n\n\ndef FingerprintsFromDetails(details, reportFreq=10):\n  data = None\n  if details.dbName and details.tableName:\n    from rdkit.Dbase.DbConnection import DbConnect\n    from rdkit.Dbase import DbInfo\n    from rdkit.ML.Data import DataUtils\n    try:\n      conn = DbConnect(details.dbName, details.tableName)\n    except Exception:\n      import traceback\n      error('Problems establishing connection to database: %s|%s\\n' % (details.dbName,\n                                                                       details.tableName))\n      traceback.print_exc()\n    if not details.idName:\n      details.idName = DbInfo.GetColumnNames(details.dbName, details.tableName)[0]\n    dataSet = DataUtils.DBToData(details.dbName, details.tableName,\n                                 what='%s,%s' % (details.idName, details.smilesName))\n    idCol = 0\n    smiCol = 1\n  elif details.inFileName and details.useSmiles:\n    from rdkit.ML.Data import DataUtils\n    conn = None\n    if not details.idName:\n      details.idName = 'ID'\n    try:\n      dataSet = DataUtils.TextFileToData(details.inFileName,\n                                         onlyCols=[details.idName, details.smilesName])\n    except IOError:\n      import traceback\n      error('Problems reading from file %s\\n' % (details.inFileName))\n      traceback.print_exc()\n\n    idCol = 0\n    smiCol = 1\n  elif details.inFileName and details.useSD:\n    conn = None\n    dataset = None\n    if not details.idName:\n      details.idName = 'ID'\n    dataSet = []\n    try:\n      s = Chem.SDMolSupplier(details.inFileName)\n    except Exception:\n      import traceback\n      error('Problems reading from file %s\\n' % (details.inFileName))\n      traceback.print_exc()\n    else:\n      while 1:\n        try:\n          m = s.next()\n        except StopIteration:\n          break\n        if m:\n          dataSet.append(m)\n          if reportFreq > 0 and not len(dataSet) % reportFreq:\n            message('Read %d molecules\\n' % (len(dataSet)))\n            if details.maxMols > 0 and len(dataSet) >= details.maxMols:\n              break\n\n    for i, mol in enumerate(dataSet):\n      if mol.HasProp(details.idName):\n        nm = mol.GetProp(details.idName)\n      else:\n        nm = mol.GetProp('_Name')\n      dataSet[i] = (nm, mol)\n  else:\n    dataSet = None\n\n  fps = None\n  if dataSet and not details.useSD:\n    data = dataSet.GetNamedData()\n    if not details.molPklName:\n      fps = FingerprintsFromSmiles(data, idCol, smiCol, **details.__dict__)\n    else:\n      fps = FingerprintsFromPickles(data, idCol, smiCol, **details.__dict__)\n  elif dataSet and details.useSD:\n    fps = FingerprintsFromMols(dataSet, **details.__dict__)\n\n  if fps:\n    if details.outFileName:\n      outF = open(details.outFileName, 'wb+')\n      for i in range(len(fps)):\n        pickle.dump(fps[i], outF)\n      outF.close()\n    dbName = details.outDbName or details.dbName\n    if details.outTableName and dbName:\n      from rdkit.Dbase.DbConnection import DbConnect\n      from rdkit.Dbase import DbUtils, DbModule\n      conn = DbConnect(dbName)\n      #\n      #  We don't have a db open already, so we'll need to figure out\n      #    the types of our columns...\n      #\n      colTypes = DbUtils.TypeFinder(data, len(data), len(data[0]))\n      typeStrs = DbUtils.GetTypeStrings([details.idName, details.smilesName], colTypes,\n                                        keyCol=details.idName)\n      cols = '%s, %s %s' % (typeStrs[0], details.fpColName, DbModule.binaryTypeName)\n\n      # FIX: we should really check to see if the table\n      #  is already there and, if so, add the appropriate\n      #  column.\n\n      #\n      # create the new table\n      #\n      if details.replaceTable or \\\n         details.outTableName.upper() not in [x.upper() for x in conn.GetTableNames()]:\n        conn.AddTable(details.outTableName, cols)\n\n      #\n      # And add the data\n      #\n      for ID, fp in fps:\n        tpl = ID, DbModule.binaryHolder(fp.ToBinary())\n        conn.InsertData(details.outTableName, tpl)\n      conn.Commit()\n  return fps\n# ------------------------------------------------\n#\n#  Command line parsing stuff\n#\n# ------------------------------------------------\n\n\nclass FingerprinterDetails(object):\n  \"\"\" class for storing the details of a fingerprinting run,\n     generates sensible defaults on construction\n\n  \"\"\"\n\n  def __init__(self):\n    self._fingerprinterInit()\n    self._screenerInit()\n    self._clusterInit()\n\n  def _fingerprinterInit(self):\n    self.fingerprinter = Chem.RDKFingerprint\n    self.fpColName = \"AutoFragmentFP\"\n    self.idName = ''\n    self.dbName = ''\n    self.outDbName = ''\n    self.tableName = ''\n    self.minSize = 64\n    self.fpSize = 2048\n    self.tgtDensity = 0.3\n    self.minPath = 1\n    self.maxPath = 7\n    self.discrimHash = 0\n    self.useHs = 0\n    self.useValence = 0\n    self.bitsPerHash = 2\n    self.smilesName = 'SMILES'\n    self.maxMols = -1\n    self.outFileName = ''\n    self.outTableName = ''\n    self.inFileName = ''\n    self.replaceTable = True\n    self.molPklName = ''\n    self.useSmiles = True\n    self.useSD = False\n\n  def _screenerInit(self):\n    self.metric = DataStructs.TanimotoSimilarity\n    self.doScreen = ''\n    self.topN = 10\n    self.screenThresh = 0.75\n    self.doThreshold = 0\n    self.smilesTableName = ''\n    self.probeSmiles = ''\n    self.probeMol = None\n    self.noPickle = 0\n\n  def _clusterInit(self):\n    self.clusterAlgo = Murtagh.WARDS\n    self.actTableName = ''\n    self.actName = ''\n\n  def GetMetricName(self):\n    if self.metric == DataStructs.TanimotoSimilarity:\n      return 'Tanimoto'\n    elif self.metric == DataStructs.DiceSimilarity:\n      return 'Dice'\n    elif self.metric == DataStructs.CosineSimilarity:\n      return 'Cosine'\n    elif self.metric:\n      return self.metric\n    else:\n      return 'Unknown'\n\n  def SetMetricFromName(self, name):\n    name = name.upper()\n    if name == \"TANIMOTO\":\n      self.metric = DataStructs.TanimotoSimilarity\n    elif name == \"DICE\":\n      self.metric = DataStructs.DiceSimilarity\n    elif name == \"COSINE\":\n      self.metric = DataStructs.CosineSimilarity\n\n\ndef Usage():\n  \"\"\"  prints a usage string and exits\n\n  \"\"\"\n  print(_usageDoc)\n  sys.exit(-1)\n\n\n_usageDoc = \"\"\"\nUsage: FingerprintMols.py [args] <fName>\n\n  If <fName> is provided and no tableName is specified (see below),\n  data will be read from the text file <fName>.  Text files delimited\n  with either commas (extension .csv) or tabs (extension .txt) are\n  supported.\n\n  Command line arguments are:\n    - -d _dbName_: set the name of the database from which\n      to pull input molecule information.  If output is\n      going to a database, this will also be used for that\n      unless the --outDbName option is used.\n\n    - -t _tableName_: set the name of the database table\n      from which to pull input molecule information\n\n    - --smilesName=val: sets the name of the SMILES column\n      in the input database.  Default is *SMILES*.\n\n    - --useSD:  Assume that the input file is an SD file, not a SMILES\n       table.\n\n    - --idName=val: sets the name of the id column in the input\n      database.  Defaults to be the name of the first db column\n      (or *ID* for text files).\n\n    - -o _outFileName_:  name of the output file (output will\n      be a pickle file with one label,fingerprint entry for each\n      molecule).\n\n    - --outTable=val: name of the output db table used to store\n      fingerprints.  If this table already exists, it will be\n      replaced.\n\n    - --outDbName: name of output database, if it's being used.\n      Defaults to be the same as the input db.\n\n    - --fpColName=val: name to use for the column which stores\n      fingerprints (in pickled format) in the output db table.\n      Default is *AutoFragmentFP*\n\n    - --maxSize=val:  base size of the fingerprints to be generated\n      Default is *2048*\n\n    - --minSize=val: minimum size of the fingerprints to be generated\n      (limits the amount of folding that happens).  Default is *64*\n\n    - --density=val: target bit density in the fingerprint.  The\n      fingerprint will be folded until this density is\n      reached. Default is *0.3*\n\n    - --minPath=val:  minimum path length to be included in\n      fragment-based fingerprints. Default is *1*.\n\n    - --maxPath=val:  maximum path length to be included in\n      fragment-based fingerprints. Default is *7*.\n\n    - --nBitsPerHash: number of bits to be set in the output\n      fingerprint for each fragment. Default is *2*.\n\n    - --discrim: use of path-based discriminators to hash bits.\n      Default is *false*.\n\n    - -V: include valence information in the fingerprints\n      Default is *false*.\n\n    - -H: include Hs in the fingerprint\n      Default is *false*.\n\n    - --maxMols=val: sets the maximum number of molecules to be\n      fingerprinted.\n\n    - --useMACCS: use the public MACCS keys to do the fingerprinting\n      (instead of a daylight-type fingerprint)\n\n\"\"\"\n\n\ndef ParseArgs(details=None):\n  \"\"\" parses the command line arguments and returns a\n   _FingerprinterDetails_ instance with the results.\n\n   **Note**:\n\n     - If you make modifications here, please update the global\n       _usageDoc string so the Usage message is up to date.\n\n     - This routine is used by both the fingerprinter, the clusterer and the\n       screener; not all arguments make sense for all applications.\n\n  \"\"\"\n  args = sys.argv[1:]\n  try:\n    args, extras = getopt.getopt(args,\n                                 'HVs:d:t:o:h',\n                                 [\n                                   'minSize=',\n                                   'maxSize=',\n                                   'density=',\n                                   'minPath=',\n                                   'maxPath=',\n                                   'bitsPerHash=',\n                                   'smilesName=',\n                                   'molPkl=',\n                                   'useSD',\n                                   'idName=',\n                                   'discrim',\n                                   'outTable=',\n                                   'outDbName=',\n                                   'fpColName=',\n                                   'maxMols=',\n                                   'useMACCS',\n                                   'keepTable',\n                                   # SCREENING:\n                                   'smilesTable=',\n                                   'doScreen=',\n                                   'topN=',\n                                   'thresh=',\n                                   'smiles=',\n                                   'dice',\n                                   'cosine',\n                                   # CLUSTERING:\n                                   'actTable=',\n                                   'actName=',\n                                   'SLINK',\n                                   'CLINK',\n                                   'UPGMA',\n                                 ])\n  except Exception:\n    import traceback\n    traceback.print_exc()\n    Usage()\n\n  if details is None:\n    details = FingerprinterDetails()\n  if len(extras):\n    details.inFileName = extras[0]\n\n  for arg, val in args:\n    if arg == '-H':\n      details.useHs = 1\n    elif arg == '-V':\n      details.useValence = 1\n    elif arg == '-d':\n      details.dbName = val\n    elif arg == '-t':\n      details.tableName = val\n    elif arg == '-o':\n      details.outFileName = val\n    elif arg == '--minSize':\n      details.minSize = int(val)\n    elif arg == '--maxSize':\n      details.fpSize = int(val)\n    elif arg == '--density':\n      details.tgtDensity = float(val)\n    elif arg == '--outTable':\n      details.outTableName = val\n    elif arg == '--outDbName':\n      details.outDbName = val\n    elif arg == '--fpColName':\n      details.fpColName = val\n    elif arg == '--minPath':\n      details.minPath = int(val)\n    elif arg == '--maxPath':\n      details.maxPath = int(val)\n    elif arg == '--nBitsPerHash':\n      details.bitsPerHash = int(val)\n    elif arg == '--discrim':\n      details.discrimHash = 1\n    elif arg == '--smilesName':\n      details.smilesName = val\n    elif arg == '--molPkl':\n      details.molPklName = val\n    elif arg == '--useSD':\n      details.useSmiles = False\n      details.useSD = True\n    elif arg == '--idName':\n      details.idName = val\n    elif arg == '--maxMols':\n      details.maxMols = int(val)\n    elif arg == '--useMACCS':\n      details.fingerprinter = MACCSkeys.GenMACCSKeys\n    elif arg == '--keepTable':\n      details.replaceTable = False\n\n    # SCREENER:\n    elif arg == '--smilesTable':\n      details.smilesTableName = val\n    elif arg == '--topN':\n      details.doThreshold = 0\n      details.topN = int(val)\n    elif arg == '--thresh':\n      details.doThreshold = 1\n      details.screenThresh = float(val)\n    elif arg == '--smiles':\n      details.probeSmiles = val\n    elif arg == '--dice':\n      details.metric = DataStructs.DiceSimilarity\n    elif arg == '--cosine':\n      details.metric = DataStructs.CosineSimilarity\n\n    # CLUSTERS:\n    elif arg == '--SLINK':\n      details.clusterAlgo = Murtagh.SLINK\n    elif arg == '--CLINK':\n      details.clusterAlgo = Murtagh.CLINK\n    elif arg == '--UPGMA':\n      details.clusterAlgo = Murtagh.UPGMA\n    elif arg == '--actTable':\n      details.actTableName = val\n    elif arg == '--actName':\n      details.actName = val\n    elif arg == '-h':\n      Usage()\n  return details\n\n\nif __name__ == '__main__':\n  message(\"This is FingerprintMols\\n\\n\")\n  details = ParseArgs()\n  FingerprintsFromDetails(details)\n", "idx": 7, "id": 24081, "msg": "", "proj": "rdkit-rdkit", "lang": "cpp"}
{"patch": "@@ -77,8 +77,8 @@ class WebDriver(RemoteWebDriver):\n             executable_path,\n             port=self.port,\n             host=self.host,\n-            log_level=self.log_level,\n-            log_file=self.log_file)\n+            log_level=log_level,\n+            log_file=service_log_path)\n \n         self.iedriver.start()\n ", "y": 0, "oldf": "# Licensed to the Software Freedom Conservancy (SFC) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The SFC licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\nimport warnings\n\nfrom selenium.webdriver.common import utils\nfrom selenium.webdriver.remote.webdriver import WebDriver as RemoteWebDriver\nfrom .service import Service\nfrom .options import Options\n\nDEFAULT_TIMEOUT = 30\nDEFAULT_PORT = 0\nDEFAULT_HOST = None\nDEFAULT_LOG_LEVEL = None\nDEFAULT_LOG_FILE = None\n\n\nclass WebDriver(RemoteWebDriver):\n    \"\"\" Controls the IEServerDriver and allows you to drive Internet Explorer \"\"\"\n\n    def __init__(self, executable_path='IEDriverServer.exe', capabilities=None,\n                 port=DEFAULT_PORT, timeout=DEFAULT_TIMEOUT, host=DEFAULT_HOST,\n                 log_level=DEFAULT_LOG_LEVEL, log_file=DEFAULT_LOG_FILE, options=None,\n                 ie_options=None, desired_capabilities=None):\n        \"\"\"\n        Creates a new instance of the chrome driver.\n\n        Starts the service and then creates new instance of chrome driver.\n\n        :Args:\n         - executable_path - path to the executable. If the default is used it assumes the executable is in the $PATH\n         - capabilities: capabilities Dictionary object\n         - port - port you would like the service to run, if left as 0, a free port will be found.\n         - log_level - log level you would like the service to run.\n         - log_file - log file you would like the service to log to.\n         - options: IE Options instance, providing additional IE options\n         - desired_capabilities: alias of capabilities; this will make the signature consistent with RemoteWebDriver.\n        \"\"\"\n        if ie_options:\n            warnings.warn('use options instead of ie_options', DeprecationWarning)\n            options = ie_options\n        self.port = port\n        if self.port == 0:\n            self.port = utils.free_port()\n        self.host = host\n        self.log_level = log_level\n        self.log_file = log_file\n\n        # If both capabilities and desired capabilities are set, ignore desired capabilities.\n        if capabilities is None and desired_capabilities:\n            capabilities = desired_capabilities\n\n        if options is None:\n            if capabilities is None:\n                capabilities = self.create_options().to_capabilities()\n        else:\n            if capabilities is None:\n                capabilities = options.to_capabilities()\n            else:\n                # desired_capabilities stays as passed in\n                capabilities.update(options.to_capabilities())\n\n        self.iedriver = Service(\n            executable_path,\n            port=self.port,\n            host=self.host,\n            log_level=self.log_level,\n            log_file=self.log_file)\n\n        self.iedriver.start()\n\n        RemoteWebDriver.__init__(\n            self,\n            command_executor='http://localhost:%d' % self.port,\n            desired_capabilities=capabilities)\n        self._is_remote = False\n\n    def quit(self):\n        RemoteWebDriver.quit(self)\n        self.iedriver.stop()\n\n    def create_options(self):\n        return Options()\n", "idx": 5, "id": 15502, "msg": "", "proj": "SeleniumHQ-selenium", "lang": "rb"}
{"patch": "@@ -19,6 +19,8 @@ package fv_test\n import (\n \t. \"github.com/onsi/ginkgo\"\n \t. \"github.com/onsi/gomega\"\n+\tlog \"github.com/sirupsen/logrus\"\n+\n \t\"github.com/projectcalico/felix/fv/containers\"\n \t\"github.com/projectcalico/felix/fv/metrics\"\n \t\"github.com/projectcalico/felix/fv/utils\"", "y": 0, "oldf": "// +build fvtests\n\n// Copyright (c) 2017 Tigera, Inc. All rights reserved.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage fv_test\n\nimport (\n\t. \"github.com/onsi/ginkgo\"\n\t. \"github.com/onsi/gomega\"\n\t\"github.com/projectcalico/felix/fv/containers\"\n\t\"github.com/projectcalico/felix/fv/metrics\"\n\t\"github.com/projectcalico/felix/fv/utils\"\n\t\"github.com/projectcalico/felix/fv/workload\"\n\t\"github.com/projectcalico/libcalico-go/lib/api\"\n\t\"github.com/projectcalico/libcalico-go/lib/client\"\n\t\"github.com/projectcalico/libcalico-go/lib/numorstring\"\n\tlog \"github.com/sirupsen/logrus\"\n)\n\nfunc RunEtcd() *containers.Container {\n\treturn containers.Run(\"etcd-fv\",\n\t\t\"quay.io/coreos/etcd\",\n\t\t\"etcd\",\n\t\t\"--advertise-client-urls\", \"http://127.0.0.1:2379\",\n\t\t\"--listen-client-urls\", \"http://0.0.0.0:2379\")\n}\n\nfunc RunFelix(etcdIP string) *containers.Container {\n\treturn containers.Run(\"felix-fv\",\n\t\t\"--privileged\",\n\t\t\"-e\", \"CALICO_DATASTORE_TYPE=etcdv2\",\n\t\t\"-e\", \"FELIX_DATASTORETYPE=etcdv2\",\n\t\t\"-e\", \"FELIX_ETCDENDPOINTS=http://\"+etcdIP+\":2379\",\n\t\t\"-e\", \"FELIX_PROMETHEUSMETRICSENABLED=true\",\n\t\t\"-e\", \"FELIX_USAGEREPORTINGENABLED=false\",\n\t\t\"-e\", \"FELIX_IPV6SUPPORT=false\",\n\t\t\"calico/felix:latest\")\n}\n\nfunc GetEtcdClient(etcdIP string) *client.Client {\n\tclient, err := client.New(api.CalicoAPIConfig{\n\t\tSpec: api.CalicoAPIConfigSpec{\n\t\t\tDatastoreType: api.EtcdV2,\n\t\t\tEtcdConfig: api.EtcdConfig{\n\t\t\t\tEtcdEndpoints: \"http://\" + etcdIP + \":2379\",\n\t\t\t},\n\t\t},\n\t})\n\tExpect(err).NotTo(HaveOccurred())\n\treturn client\n}\n\nfunc MetricsPortReachable(felixName, felixIP string) bool {\n\t// Delete existing conntrack state for the metrics port.\n\tutils.Run(\"docker\", \"exec\", felixName,\n\t\t\"conntrack\", \"-L\")\n\tutils.Run(\"docker\", \"exec\", felixName,\n\t\t\"conntrack\", \"-L\", \"-p\", \"tcp\", \"--dport\", metrics.PortString())\n\tutils.RunMayFail(\"docker\", \"exec\", felixName,\n\t\t\"conntrack\", \"-D\", \"-p\", \"tcp\", \"--orig-port-dst\", metrics.PortString())\n\n\t// Now try to get a metric.\n\tm, err := metrics.GetFelixMetric(felixIP, \"felix_active_local_endpoints\")\n\tif err != nil {\n\t\tlog.WithError(err).Info(\"Metrics port not reachable\")\n\t\treturn false\n\t}\n\tlog.WithField(\"felix_active_local_endpoints\", m).Info(\"Metrics port reachable\")\n\treturn true\n}\n\n// Here we test reachability to a port number running on a Calico host itself, specifically Felix's\n// metrics port 9091, and how that is affected by policy, host endpoint and workload endpoint\n// configuration.\n//\n// - When there is no policy or endpoint configuration, the port should be reachable.\n//\n// - When there is a local workload endpoint, the port should be reachable.  (Existence of workload\n//   endpoints should make no difference to reachability to ports on the host itself.)\n//\n// - When a host endpoint is configured for the host's interface (eth0), but not yet any policy, the\n//   port should be unreachable.\n//\n//   - When pre-DNAT policy is then configured, to allow ingress to that port, it should be\n//     reachable again.\n\nvar _ = Context(\"with initialized Felix and etcd datastore\", func() {\n\n\tvar (\n\t\tetcd                 *containers.Container\n\t\tfelix                *containers.Container\n\t\tclient               *client.Client\n\t\tmetricsPortReachable func() bool\n\t)\n\n\tBeforeEach(func() {\n\n\t\tetcd = RunEtcd()\n\n\t\tclient = GetEtcdClient(etcd.IP)\n\t\tEventually(client.EnsureInitialized, \"10s\", \"1s\").ShouldNot(HaveOccurred())\n\n\t\tfelix = RunFelix(etcd.IP)\n\n\t\tfelixNode := api.NewNode()\n\t\tfelixNode.Metadata.Name = felix.Hostname\n\t\t_, err := client.Nodes().Create(felixNode)\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\tmetricsPortReachable = func() bool {\n\t\t\treturn MetricsPortReachable(felix.Name, felix.IP)\n\t\t}\n\t})\n\n\tAfterEach(func() {\n\n\t\tif CurrentGinkgoTestDescription().Failed {\n\t\t\tutils.Run(\"docker\", \"logs\", felix.Name)\n\t\t\tutils.Run(\"docker\", \"exec\", felix.Name, \"iptables-save\", \"-c\")\n\t\t}\n\t\tfelix.Stop()\n\n\t\tif CurrentGinkgoTestDescription().Failed {\n\t\t\tutils.Run(\"docker\", \"exec\", etcd.Name, \"etcdctl\", \"ls\", \"--recursive\", \"/\")\n\t\t}\n\t\tetcd.Stop()\n\t})\n\n\tIt(\"with no endpoints or policy, port should be reachable\", func() {\n\t\tEventually(metricsPortReachable, \"10s\", \"1s\").Should(BeTrue())\n\t})\n\n\tIt(\"with a local workload, port should be reachable\", func() {\n\t\tw := workload.Run(felix, \"cali12345\", \"10.65.0.2\", \"8055\")\n\t\tw.Configure(client)\n\t\tEventually(metricsPortReachable, \"10s\", \"1s\").Should(BeTrue())\n\t\tw.Stop()\n\t\tEventually(metricsPortReachable, \"10s\", \"1s\").Should(BeTrue())\n\t})\n\n\tContext(\"with host endpoint defined\", func() {\n\n\t\tBeforeEach(func() {\n\t\t\thostEp := api.NewHostEndpoint()\n\t\t\thostEp.Metadata.Name = \"host-endpoint-1\"\n\t\t\thostEp.Metadata.Node = felix.Hostname\n\t\t\thostEp.Metadata.Labels = map[string]string{\"host-endpoint\": \"true\"}\n\t\t\thostEp.Spec.InterfaceName = \"eth0\"\n\t\t\t_, err := client.HostEndpoints().Create(hostEp)\n\t\t\tExpect(err).NotTo(HaveOccurred())\n\t\t})\n\n\t\tIt(\"port should not be reachable\", func() {\n\t\t\tEventually(metricsPortReachable, \"10s\", \"1s\").Should(BeFalse())\n\t\t})\n\n\t\tContext(\"with pre-DNAT policy defined\", func() {\n\n\t\t\tBeforeEach(func() {\n\t\t\t\tpolicy := api.NewPolicy()\n\t\t\t\tpolicy.Metadata.Name = \"pre-dnat-policy-1\"\n\t\t\t\tpolicy.Spec.PreDNAT = true\n\t\t\t\tprotocol := numorstring.ProtocolFromString(\"tcp\")\n\t\t\t\tallowMetricsPortRule := api.Rule{\n\t\t\t\t\tAction:   \"allow\",\n\t\t\t\t\tProtocol: &protocol,\n\t\t\t\t\tDestination: api.EntityRule{\n\t\t\t\t\t\tPorts: []numorstring.Port{numorstring.SinglePort(uint16(metrics.Port))},\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t\tpolicy.Spec.IngressRules = []api.Rule{allowMetricsPortRule}\n\t\t\t\tpolicy.Spec.Selector = \"host-endpoint=='true'\"\n\t\t\t\t_, err := client.Policies().Create(policy)\n\t\t\t\tExpect(err).NotTo(HaveOccurred())\n\t\t\t})\n\n\t\t\tIt(\"port should be reachable\", func() {\n\t\t\t\tEventually(metricsPortReachable, \"10s\", \"1s\").Should(BeTrue())\n\t\t\t})\n\t\t})\n\t})\n})\n", "idx": 1, "id": 15746, "msg": "", "proj": "projectcalico-felix", "lang": "c"}
{"patch": "@@ -270,11 +270,11 @@ describe( 'modules/adsense settings', () => {\n \t\t\t\texpect( registry.select( STORE_NAME ).canSubmitChanges() ).toBe( true );\n \n \t\t\t\tregistry.dispatch( STORE_NAME ).setClientID( '0' );\n-\t\t\t\texpect( () => registry.select( STORE_NAME ).__dangerousCanSubmitChanges() )\n+\t\t\t\texpect( () => registry.select( STORE_NAME ).validateSubmitChanges() )\n \t\t\t\t\t.toThrow( INVARIANT_INVALID_CLIENT_ID );\n \n \t\t\t\tregistry.dispatch( STORE_NAME ).setClientID( null );\n-\t\t\t\texpect( () => registry.select( STORE_NAME ).__dangerousCanSubmitChanges() )\n+\t\t\t\texpect( () => registry.select( STORE_NAME ).validateSubmitChanges() )\n \t\t\t\t\t.toThrow( INVARIANT_INVALID_CLIENT_ID );\n \n \t\t\t\t// An empty string is accepted (for when no client can be determined).", "y": 0, "oldf": "/**\n * `modules/adsense` data store: settings tests.\n *\n * Site Kit by Google, Copyright 2020 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Internal dependencies\n */\nimport API from 'googlesitekit-api';\nimport { STORE_NAME } from './constants';\nimport {\n\tACCOUNT_STATUS_APPROVED,\n\tSITE_STATUS_ADDED,\n} from '../util/status';\nimport {\n\tcreateTestRegistry,\n\tsubscribeUntil,\n\tunsubscribeFromAll,\n} from '../../../../../tests/js/utils';\nimport { getItem, setItem } from '../../../googlesitekit/api/cache';\nimport { createCacheKey } from '../../../googlesitekit/api';\nimport { INVARIANT_INVALID_ACCOUNT_ID, INVARIANT_INVALID_CLIENT_ID } from './settings';\n\ndescribe( 'modules/adsense settings', () => {\n\tlet registry;\n\n\tconst validSettings = {\n\t\taccountID: 'pub-12345678',\n\t\tclientID: 'ca-pub-12345678',\n\t\tuseSnippet: true,\n\t\taccountStatus: ACCOUNT_STATUS_APPROVED,\n\t\tsiteStatus: SITE_STATUS_ADDED,\n\t};\n\tconst wpError = {\n\t\tcode: 'internal_error',\n\t\tmessage: 'Something wrong happened.',\n\t\tdata: { status: 500 },\n\t};\n\n\tbeforeAll( () => {\n\t\tAPI.setUsingCache( false );\n\t} );\n\n\tbeforeEach( () => {\n\t\tregistry = createTestRegistry();\n\t} );\n\n\tafterAll( () => {\n\t\tAPI.setUsingCache( true );\n\t} );\n\n\tafterEach( () => {\n\t\tunsubscribeFromAll( registry );\n\t} );\n\n\tdescribe( 'actions', () => {\n\t\tdescribe( 'saveUseSnippet', () => {\n\t\t\tit( 'does not require any params', () => {\n\t\t\t\texpect( async () => {\n\t\t\t\t\tfetchMock.postOnce(\n\t\t\t\t\t\t/^\\/google-site-kit\\/v1\\/modules\\/adsense\\/data\\/use-snippet/,\n\t\t\t\t\t\t{ body: JSON.stringify( true ), status: 200 }\n\t\t\t\t\t);\n\t\t\t\t\t// Ensure initial settings from server are present.\n\t\t\t\t\tregistry.dispatch( STORE_NAME ).receiveGetSettings( { useSnippet: false } );\n\n\t\t\t\t\tregistry.dispatch( STORE_NAME ).setUseSnippet( true );\n\t\t\t\t\tawait registry.dispatch( STORE_NAME ).saveUseSnippet();\n\t\t\t\t} ).not.toThrow();\n\t\t\t} );\n\n\t\t\tit( 'updates useSnippet setting from server', async () => {\n\t\t\t\tfetchMock.post(\n\t\t\t\t\t/^\\/google-site-kit\\/v1\\/modules\\/adsense\\/data\\/use-snippet/,\n\t\t\t\t\t{ body: JSON.stringify( true ), status: 200 }\n\t\t\t\t);\n\n\t\t\t\t// Update setting and ensure this flags a settings change.\n\t\t\t\tregistry.dispatch( STORE_NAME ).setUseSnippet( true );\n\t\t\t\texpect( registry.select( STORE_NAME ).haveSettingsChanged() ).toBe( true );\n\n\t\t\t\tawait registry.dispatch( STORE_NAME ).saveUseSnippet();\n\n\t\t\t\texpect( fetchMock ).toHaveFetchedTimes( 1 );\n\n\t\t\t\t// Ensure settings now no longer need to be updated because\n\t\t\t\t// server-side and client-side settings now match.\n\t\t\t\texpect( registry.select( STORE_NAME ).haveSettingsChanged() ).toBe( false );\n\t\t\t} );\n\t\t} );\n\n\t\tdescribe( 'fetchSaveUseSnippet', () => {\n\t\t\tit( 'requires the useSnippet param', () => {\n\t\t\t\texpect( () => {\n\t\t\t\t\tregistry.dispatch( STORE_NAME ).fetchSaveUseSnippet();\n\t\t\t\t} ).toThrow( 'useSnippet is required.' );\n\t\t\t} );\n\n\t\t\tit( 'sets isDoingSaveUseSnippet', () => {\n\t\t\t\tfetchMock.postOnce(\n\t\t\t\t\t/^\\/google-site-kit\\/v1\\/modules\\/adsense\\/data\\/use-snippet/,\n\t\t\t\t\t{ body: JSON.stringify( true ), status: 200 }\n\t\t\t\t);\n\n\t\t\t\tregistry.dispatch( STORE_NAME ).fetchSaveUseSnippet( true );\n\t\t\t\texpect( registry.select( STORE_NAME ).isDoingSaveUseSnippet() ).toEqual( true );\n\t\t\t} );\n\t\t} );\n\n\t\tdescribe( 'receiveSaveUseSnippet', () => {\n\t\t\tit( 'requires the response param', () => {\n\t\t\t\texpect( () => {\n\t\t\t\t\tregistry.dispatch( STORE_NAME ).receiveSaveUseSnippet();\n\t\t\t\t} ).toThrow( 'response is required.' );\n\t\t\t} );\n\n\t\t\tit( 'requires the params param', () => {\n\t\t\t\texpect( () => {\n\t\t\t\t\tregistry.dispatch( STORE_NAME ).receiveSaveUseSnippet( true );\n\t\t\t\t} ).toThrow( 'params is required.' );\n\t\t\t} );\n\n\t\t\tit( 'receives useSnippet and integrates into settings store', () => {\n\t\t\t\t// Simulate having loaded settings (useSnippet as false).\n\t\t\t\tregistry.dispatch( STORE_NAME ).receiveGetSettings( {\n\t\t\t\t\tuseSnippet: false,\n\t\t\t\t\taccountStatus: 'test-status',\n\t\t\t\t} );\n\t\t\t\texpect( registry.select( STORE_NAME ).getUseSnippet() ).toBe( false );\n\n\t\t\t\t// Simulate having saved useSnippet as true.\n\t\t\t\tregistry.dispatch( STORE_NAME ).receiveSaveUseSnippet( true, { useSnippet: true } );\n\n\t\t\t\t// getUseSnippet comes from settings store. Account status should be unmodified.\n\t\t\t\texpect( registry.select( STORE_NAME ).getUseSnippet() ).toBe( true );\n\t\t\t\texpect( registry.select( STORE_NAME ).getAccountStatus() ).toEqual( 'test-status' );\n\t\t\t} );\n\n\t\t\tit( 'receives and sets useSnippet from parameter', () => {\n\t\t\t\tregistry.dispatch( STORE_NAME ).setUseSnippet( true );\n\n\t\t\t\t// Fake a request saving the useSnippet as false.\n\t\t\t\tregistry.dispatch( STORE_NAME ).receiveSaveUseSnippet( true, { useSnippet: false } );\n\n\t\t\t\t// Make sure the saved false is now in place.\n\t\t\t\texpect( registry.select( STORE_NAME ).getUseSnippet() ).toBe( false );\n\t\t\t} );\n\t\t} );\n\n\t\tdescribe( 'submitChanges', () => {\n\t\t\tit( 'dispatches saveSettings', async () => {\n\t\t\t\tregistry.dispatch( STORE_NAME ).setSettings( validSettings );\n\t\t\t\tfetchMock.postOnce(\n\t\t\t\t\t/^\\/google-site-kit\\/v1\\/modules\\/adsense\\/data\\/settings/,\n\t\t\t\t\t{ body: validSettings, status: 200 }\n\t\t\t\t);\n\n\t\t\t\tawait registry.dispatch( STORE_NAME ).submitChanges();\n\n\t\t\t\texpect( fetchMock ).toHaveFetchedTimes( 1 );\n\t\t\t\texpect( fetchMock ).toHaveFetched(\n\t\t\t\t\t/^\\/google-site-kit\\/v1\\/modules\\/adsense\\/data\\/settings/,\n\t\t\t\t\t{\n\t\t\t\t\t\tbody: {\n\t\t\t\t\t\t\tdata: validSettings,\n\t\t\t\t\t\t},\n\t\t\t\t\t}\n\t\t\t\t);\n\t\t\t\texpect( registry.select( STORE_NAME ).haveSettingsChanged() ).toBe( false );\n\t\t\t} );\n\n\t\t\tit( 'handles an error if set while saving settings', async () => {\n\t\t\t\tregistry.dispatch( STORE_NAME ).setSettings( validSettings );\n\n\t\t\t\tfetchMock.postOnce(\n\t\t\t\t\t/^\\/google-site-kit\\/v1\\/modules\\/adsense\\/data\\/settings/,\n\t\t\t\t\t{ body: wpError, status: 500 }\n\t\t\t\t);\n\t\t\t\tawait registry.dispatch( STORE_NAME ).submitChanges();\n\n\t\t\t\texpect( registry.select( STORE_NAME ).getSettings() ).toEqual( validSettings );\n\t\t\t\texpect( registry.select( STORE_NAME ).getErrorForAction( 'submitChanges' ) ).toEqual( wpError );\n\t\t\t\texpect( console ).toHaveErrored();\n\t\t\t} );\n\n\t\t\tit( 'invalidates AdSense API cache on success', async () => {\n\t\t\t\tregistry.dispatch( STORE_NAME ).setSettings( validSettings );\n\n\t\t\t\tfetchMock.postOnce(\n\t\t\t\t\t/^\\/google-site-kit\\/v1\\/modules\\/adsense\\/data\\/settings/,\n\t\t\t\t\t{ body: validSettings, status: 200 }\n\t\t\t\t);\n\n\t\t\t\tconst cacheKey = createCacheKey( 'modules', 'adsense', 'arbitrary-datapoint' );\n\t\t\t\texpect( await setItem( cacheKey, 'test-value' ) ).toBe( true );\n\t\t\t\texpect( ( await getItem( cacheKey ) ).value ).toEqual( 'test-value' );\n\n\t\t\t\tawait registry.dispatch( STORE_NAME ).submitChanges();\n\n\t\t\t\texpect( ( await getItem( cacheKey ) ).value ).toBeFalsy();\n\t\t\t} );\n\t\t} );\n\n\t\tdescribe( 'receiveOriginalAccountStatus', () => {\n\t\t\tit( 'requires the originalAccountStatus param', () => {\n\t\t\t\texpect( () => {\n\t\t\t\t\tregistry.dispatch( STORE_NAME ).receiveOriginalAccountStatus();\n\t\t\t\t} ).toThrow( 'originalAccountStatus is required.' );\n\t\t\t} );\n\n\t\t\tit( 'receives and sets originalAccountStatus from parameter', () => {\n\t\t\t\tregistry.dispatch( STORE_NAME ).receiveOriginalAccountStatus( 'something' );\n\t\t\t\texpect( registry.select( STORE_NAME ).getOriginalAccountStatus() ).toEqual( 'something' );\n\t\t\t} );\n\t\t} );\n\t} );\n\n\tdescribe( 'selectors', () => {\n\t\tdescribe( 'isDoingSubmitChanges', () => {\n\t\t\tit( 'sets internal state while submitting changes', () => {\n\t\t\t\texpect( registry.select( STORE_NAME ).isDoingSubmitChanges() ).toBe( false );\n\n\t\t\t\tregistry.dispatch( STORE_NAME ).submitChanges();\n\t\t\t\texpect( registry.select( STORE_NAME ).isDoingSubmitChanges() ).toBe( true );\n\t\t\t} );\n\n\t\t\tit( 'toggles the internal state again once submission is completed', async () => {\n\t\t\t\tconst submitPromise = registry.dispatch( STORE_NAME ).submitChanges();\n\t\t\t\texpect( registry.select( STORE_NAME ).isDoingSubmitChanges() ).toBe( true );\n\n\t\t\t\tawait submitPromise;\n\n\t\t\t\texpect( registry.select( STORE_NAME ).isDoingSubmitChanges() ).toBe( false );\n\t\t\t} );\n\t\t} );\n\n\t\tdescribe( 'canSubmitChanges', () => {\n\t\t\tit( 'requires a valid accountID or empty string', () => {\n\t\t\t\tregistry.dispatch( STORE_NAME ).setSettings( validSettings );\n\t\t\t\texpect( registry.select( STORE_NAME ).canSubmitChanges() ).toBe( true );\n\n\t\t\t\tregistry.dispatch( STORE_NAME ).setAccountID( '0' );\n\t\t\t\texpect( () => registry.select( STORE_NAME ).__dangerousCanSubmitChanges() )\n\t\t\t\t\t.toThrow( INVARIANT_INVALID_ACCOUNT_ID );\n\n\t\t\t\tregistry.dispatch( STORE_NAME ).setAccountID( null );\n\t\t\t\texpect( () => registry.select( STORE_NAME ).__dangerousCanSubmitChanges() )\n\t\t\t\t\t.toThrow( INVARIANT_INVALID_ACCOUNT_ID );\n\n\t\t\t\t// An empty string is accepted (for when no account can be determined).\n\t\t\t\tregistry.dispatch( STORE_NAME ).setAccountID( '' );\n\t\t\t\texpect( registry.select( STORE_NAME ).canSubmitChanges() ).toBe( true );\n\t\t\t} );\n\n\t\t\tit( 'requires a valid clientID or empty string', () => {\n\t\t\t\tregistry.dispatch( STORE_NAME ).setSettings( validSettings );\n\t\t\t\texpect( registry.select( STORE_NAME ).canSubmitChanges() ).toBe( true );\n\n\t\t\t\tregistry.dispatch( STORE_NAME ).setClientID( '0' );\n\t\t\t\texpect( () => registry.select( STORE_NAME ).__dangerousCanSubmitChanges() )\n\t\t\t\t\t.toThrow( INVARIANT_INVALID_CLIENT_ID );\n\n\t\t\t\tregistry.dispatch( STORE_NAME ).setClientID( null );\n\t\t\t\texpect( () => registry.select( STORE_NAME ).__dangerousCanSubmitChanges() )\n\t\t\t\t\t.toThrow( INVARIANT_INVALID_CLIENT_ID );\n\n\t\t\t\t// An empty string is accepted (for when no client can be determined).\n\t\t\t\tregistry.dispatch( STORE_NAME ).setClientID( '' );\n\t\t\t\texpect( registry.select( STORE_NAME ).canSubmitChanges() ).toBe( true );\n\t\t\t} );\n\t\t} );\n\n\t\tdescribe( 'getOriginalAccountStatus', () => {\n\t\t\tit( 'uses a resolver to make a network request via getSettings', async () => {\n\t\t\t\tconst response = { accountStatus: 'some-status' };\n\t\t\t\tfetchMock.getOnce(\n\t\t\t\t\t/^\\/google-site-kit\\/v1\\/modules\\/adsense\\/data\\/settings/,\n\t\t\t\t\t{ body: response, status: 200 }\n\t\t\t\t);\n\n\t\t\t\tconst initialOriginalAccountStatus = registry.select( STORE_NAME ).getOriginalAccountStatus();\n\t\t\t\t// Settings will be their initial value while being fetched.\n\t\t\t\texpect( initialOriginalAccountStatus ).toEqual( undefined );\n\n\t\t\t\tawait subscribeUntil( registry, () => registry.select( STORE_NAME ).hasFinishedResolution( 'getOriginalAccountStatus' ) && registry.select( STORE_NAME ).hasFinishedResolution( 'getSettings' ) );\n\n\t\t\t\tconst originalAccountStatus = registry.select( STORE_NAME ).getOriginalAccountStatus();\n\n\t\t\t\texpect( fetchMock ).toHaveFetchedTimes( 1 );\n\t\t\t\texpect( originalAccountStatus ).toEqual( response.accountStatus );\n\t\t\t} );\n\n\t\t\tit( 'does not make a network request if original account status is already set', async () => {\n\t\t\t\tconst value = 'a-status';\n\t\t\t\tregistry.dispatch( STORE_NAME ).receiveOriginalAccountStatus( value );\n\n\t\t\t\texpect( registry.select( STORE_NAME ).getOriginalAccountStatus() ).toEqual( value );\n\n\t\t\t\tawait subscribeUntil( registry, () => registry.select( STORE_NAME ).hasFinishedResolution( 'getOriginalAccountStatus' ) );\n\n\t\t\t\texpect( fetchMock ).not.toHaveFetched();\n\t\t\t} );\n\n\t\t\tit( 'does not override original account status when receiving settings again', async () => {\n\t\t\t\t// Set original value.\n\t\t\t\tconst value = 'a-status';\n\t\t\t\tregistry.dispatch( STORE_NAME ).receiveOriginalAccountStatus( value );\n\n\t\t\t\texpect( registry.select( STORE_NAME ).getOriginalAccountStatus() ).toEqual( value );\n\n\t\t\t\t// Despite receiving settings, the value should not be updated\n\t\t\t\t// as it was already set.\n\t\t\t\tregistry.dispatch( STORE_NAME ).receiveGetSettings( { accountStatus: 'another-status' } );\n\t\t\t\texpect( registry.select( STORE_NAME ).getOriginalAccountStatus() ).toEqual( value );\n\t\t\t} );\n\t\t} );\n\t} );\n} );\n", "idx": 2, "id": 33502, "msg": "", "proj": "google-site-kit-wp", "lang": "js"}
{"patch": "@@ -644,13 +644,13 @@ func TestService_SendVote(t *testing.T) {\n \tchain := mock_blockchain.NewMockBlockchain(ctrl)\n \tmDp := mock_dispatcher.NewMockDispatcher(ctrl)\n \tbroadcastHandlerCount := 0\n-\tsvc := Service{bc: chain, dp: mDp, broadcastHandler: func(_ uint32, _ proto.Message) error {\n+\tsvc := Service{bc: chain, dp: mDp, broadcastHandler: func(_ context.Context, _ uint32, _ proto.Message) error {\n \t\tbroadcastHandlerCount++\n \t\treturn nil\n \t}}\n \n \tchain.EXPECT().ChainID().Return(uint32(1)).Times(2)\n-\tmDp.EXPECT().HandleBroadcast(gomock.Any(), gomock.Any()).Times(1)\n+\tmDp.EXPECT().HandleBroadcast(gomock.Any(), gomock.Any(), gomock.Any()).Times(1)\n \n \tr := explorer.SendVoteRequest{\n \t\tVersion:     0x1,", "y": 0, "oldf": "// Copyright (c) 2018 IoTeX\n// This is an alpha (internal) release and is not suitable for production. This source code is provided 'as is' and no\n// warranties are given as to title or non-infringement, merchantability or fitness for purpose and, to the extent\n// permitted by law, all liability for your use of the code is disclaimed. This source code is governed by Apache\n// License 2.0 that can be found in the LICENSE file.\n\npackage explorer\n\nimport (\n\t\"context\"\n\t\"encoding/hex\"\n\t\"fmt\"\n\t\"math/big\"\n\t\"net\"\n\t\"strings\"\n\t\"testing\"\n\n\t\"github.com/golang/mock/gomock\"\n\t\"github.com/golang/protobuf/jsonpb\"\n\t\"github.com/golang/protobuf/proto\"\n\t\"github.com/pkg/errors\"\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/require\"\n\n\t\"github.com/iotexproject/iotex-core/action\"\n\t\"github.com/iotexproject/iotex-core/action/protocol\"\n\t\"github.com/iotexproject/iotex-core/action/protocol/account\"\n\t\"github.com/iotexproject/iotex-core/action/protocol/execution\"\n\t\"github.com/iotexproject/iotex-core/action/protocol/multichain/mainchain\"\n\t\"github.com/iotexproject/iotex-core/action/protocol/vote\"\n\t\"github.com/iotexproject/iotex-core/actpool\"\n\t\"github.com/iotexproject/iotex-core/blockchain\"\n\t\"github.com/iotexproject/iotex-core/config\"\n\t\"github.com/iotexproject/iotex-core/consensus/scheme\"\n\t\"github.com/iotexproject/iotex-core/explorer/idl/explorer\"\n\t\"github.com/iotexproject/iotex-core/p2p/node\"\n\t\"github.com/iotexproject/iotex-core/pkg/hash\"\n\t\"github.com/iotexproject/iotex-core/pkg/keypair\"\n\t\"github.com/iotexproject/iotex-core/pkg/util/byteutil\"\n\t\"github.com/iotexproject/iotex-core/state\"\n\t\"github.com/iotexproject/iotex-core/state/factory\"\n\t\"github.com/iotexproject/iotex-core/test/mock/mock_blockchain\"\n\t\"github.com/iotexproject/iotex-core/test/mock/mock_consensus\"\n\t\"github.com/iotexproject/iotex-core/test/mock/mock_dispatcher\"\n\t\"github.com/iotexproject/iotex-core/test/mock/mock_factory\"\n\tta \"github.com/iotexproject/iotex-core/test/testaddress\"\n\t\"github.com/iotexproject/iotex-core/testutil\"\n)\n\nconst (\n\ttestTriePath = \"trie.test\"\n\ttestDBPath   = \"db.test\"\n)\n\nfunc addTestingBlocks(bc blockchain.Blockchain) error {\n\taddr0 := ta.Addrinfo[\"producer\"].Bech32()\n\tpriKey0 := ta.Keyinfo[\"producer\"].PriKey\n\taddr1 := ta.Addrinfo[\"alfa\"].Bech32()\n\tpriKey1 := ta.Keyinfo[\"alfa\"].PriKey\n\taddr2 := ta.Addrinfo[\"bravo\"].Bech32()\n\taddr3 := ta.Addrinfo[\"charlie\"].Bech32()\n\tpriKey3 := ta.Keyinfo[\"charlie\"].PriKey\n\taddr4 := ta.Addrinfo[\"delta\"].Bech32()\n\t// Add block 1\n\t// test --> A, B, C, D, E, F\n\ttsf, err := testutil.SignedTransfer(addr0, addr3, priKey0, 1, big.NewInt(10), []byte{}, testutil.TestGasLimit, big.NewInt(testutil.TestGasPrice))\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tactionMap := make(map[string][]action.SealedEnvelope)\n\tactionMap[tsf.SrcAddr()] = []action.SealedEnvelope{tsf}\n\tblk, err := bc.MintNewBlock(actionMap, ta.Keyinfo[\"producer\"].PubKey,\n\t\tta.Keyinfo[\"producer\"].PriKey, ta.Addrinfo[\"producer\"].Bech32(), nil, nil, \"\")\n\tif err != nil {\n\t\treturn err\n\t}\n\tif err := bc.ValidateBlock(blk, true); err != nil {\n\t\treturn err\n\t}\n\tif err := bc.CommitBlock(blk); err != nil {\n\t\treturn err\n\t}\n\n\t// Add block 2\n\t// Charlie --> A, B, D, E, test\n\ttsf1, err := testutil.SignedTransfer(addr3, addr1, priKey3, 1, big.NewInt(1), []byte{}, testutil.TestGasLimit, big.NewInt(testutil.TestGasPrice))\n\tif err != nil {\n\t\treturn err\n\t}\n\ttsf2, err := testutil.SignedTransfer(addr3, addr2, priKey3, 2, big.NewInt(1), []byte{}, testutil.TestGasLimit, big.NewInt(testutil.TestGasPrice))\n\tif err != nil {\n\t\treturn err\n\t}\n\ttsf3, err := testutil.SignedTransfer(addr3, addr4, priKey3, 3, big.NewInt(1), []byte{}, testutil.TestGasLimit, big.NewInt(testutil.TestGasPrice))\n\tif err != nil {\n\t\treturn err\n\t}\n\ttsf4, err := testutil.SignedTransfer(addr3, addr0, priKey3, 4, big.NewInt(1), []byte{}, testutil.TestGasLimit, big.NewInt(testutil.TestGasPrice))\n\tif err != nil {\n\t\treturn err\n\t}\n\tvote1, err := testutil.SignedVote(addr3, addr3, priKey3, 5, testutil.TestGasLimit, big.NewInt(testutil.TestGasPrice))\n\tif err != nil {\n\t\treturn err\n\t}\n\texecution1, err := testutil.SignedExecution(addr3, addr4, priKey3, 6,\n\t\tbig.NewInt(1), testutil.TestGasLimit, big.NewInt(testutil.TestGasPrice), []byte{1})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tactionMap = make(map[string][]action.SealedEnvelope)\n\tactionMap[tsf1.SrcAddr()] = []action.SealedEnvelope{tsf1, tsf2, tsf3, tsf4, vote1, execution1}\n\tif blk, err = bc.MintNewBlock(actionMap,\n\t\tta.Keyinfo[\"producer\"].PubKey, ta.Keyinfo[\"producer\"].PriKey,\n\t\tta.Addrinfo[\"producer\"].Bech32(), nil, nil, \"\"); err != nil {\n\t\treturn err\n\t}\n\tif err := bc.ValidateBlock(blk, true); err != nil {\n\t\treturn err\n\t}\n\tif err := bc.CommitBlock(blk); err != nil {\n\t\treturn err\n\t}\n\n\t// Add block 3\n\tif blk, err = bc.MintNewBlock(nil, ta.Keyinfo[\"producer\"].PubKey,\n\t\tta.Keyinfo[\"producer\"].PriKey, ta.Addrinfo[\"producer\"].Bech32(), nil,\n\t\tnil, \"\"); err != nil {\n\t\treturn err\n\t}\n\tif err := bc.ValidateBlock(blk, true); err != nil {\n\t\treturn err\n\t}\n\tif err := bc.CommitBlock(blk); err != nil {\n\t\treturn err\n\t}\n\n\t// Add block 4\n\tvote1, err = testutil.SignedVote(addr3, addr3, priKey3, 7, testutil.TestGasLimit, big.NewInt(testutil.TestGasPrice))\n\tif err != nil {\n\t\treturn err\n\t}\n\tvote2, err := testutil.SignedVote(addr1, addr1, priKey1, 1, testutil.TestGasLimit, big.NewInt(testutil.TestGasPrice))\n\tif err != nil {\n\t\treturn err\n\t}\n\texecution1, err = testutil.SignedExecution(addr3, addr4, priKey3, 8,\n\t\tbig.NewInt(2), testutil.TestGasLimit, big.NewInt(testutil.TestGasPrice), []byte{1})\n\tif err != nil {\n\t\treturn err\n\t}\n\texecution2, err := testutil.SignedExecution(addr1, addr4, priKey1, 2,\n\t\tbig.NewInt(1), testutil.TestGasLimit, big.NewInt(testutil.TestGasPrice), []byte{1})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tactionMap = make(map[string][]action.SealedEnvelope)\n\tactionMap[vote1.SrcAddr()] = []action.SealedEnvelope{vote1, execution1}\n\tactionMap[vote2.SrcAddr()] = []action.SealedEnvelope{vote2, execution2}\n\tif blk, err = bc.MintNewBlock(actionMap,\n\t\tta.Keyinfo[\"producer\"].PubKey, ta.Keyinfo[\"producer\"].PriKey,\n\t\tta.Addrinfo[\"producer\"].Bech32(), nil, nil, \"\"); err != nil {\n\t\treturn err\n\t}\n\tif err := bc.ValidateBlock(blk, true); err != nil {\n\t\treturn err\n\t}\n\treturn bc.CommitBlock(blk)\n}\n\nfunc addActsToActPool(ap actpool.ActPool) error {\n\ttsf1, err := testutil.SignedTransfer(ta.Addrinfo[\"producer\"].Bech32(), ta.Addrinfo[\"alfa\"].Bech32(), ta.Keyinfo[\"producer\"].PriKey, 2, big.NewInt(20), []byte{}, testutil.TestGasLimit, big.NewInt(testutil.TestGasPrice))\n\tif err != nil {\n\t\treturn err\n\t}\n\tvote1, err := testutil.SignedVote(ta.Addrinfo[\"producer\"].Bech32(), ta.Addrinfo[\"producer\"].Bech32(), ta.Keyinfo[\"alfa\"].PriKey, 3, testutil.TestGasLimit, big.NewInt(testutil.TestGasPrice))\n\tif err != nil {\n\t\treturn err\n\t}\n\ttsf2, err := testutil.SignedTransfer(ta.Addrinfo[\"producer\"].Bech32(), ta.Addrinfo[\"bravo\"].Bech32(), ta.Keyinfo[\"producer\"].PriKey, 4, big.NewInt(20), []byte{}, testutil.TestGasLimit, big.NewInt(testutil.TestGasPrice))\n\tif err != nil {\n\t\treturn err\n\t}\n\texecution1, err := testutil.SignedExecution(ta.Addrinfo[\"producer\"].Bech32(), ta.Addrinfo[\"delta\"].Bech32(), ta.Keyinfo[\"producer\"].PriKey, 5,\n\t\tbig.NewInt(1), testutil.TestGasLimit, big.NewInt(10), []byte{1})\n\tif err != nil {\n\t\treturn err\n\t}\n\tif err := ap.Add(tsf1); err != nil {\n\t\treturn err\n\t}\n\tif err := ap.Add(vote1); err != nil {\n\t\treturn err\n\t}\n\tif err := ap.Add(tsf2); err != nil {\n\t\treturn err\n\t}\n\treturn ap.Add(execution1)\n}\n\nfunc TestExplorerApi(t *testing.T) {\n\trequire := require.New(t)\n\tcfg := config.Default\n\tcfg.Chain.TrieDBPath = testTriePath\n\tcfg.Chain.ChainDBPath = testDBPath\n\tcfg.Chain.WriteIndexInChainDB = true\n\tcfg.Explorer.Enabled = true\n\n\ttestutil.CleanupPath(t, testTriePath)\n\tdefer testutil.CleanupPath(t, testTriePath)\n\ttestutil.CleanupPath(t, testDBPath)\n\tdefer testutil.CleanupPath(t, testDBPath)\n\n\tsf, err := factory.NewFactory(cfg, factory.InMemTrieOption())\n\trequire.Nil(err)\n\trequire.Nil(sf.Start(context.Background()))\n\trequire.NoError(addCreatorToFactory(sf))\n\n\t// create chain\n\tctx := context.Background()\n\tbc := blockchain.NewBlockchain(cfg, blockchain.PrecreatedStateFactoryOption(sf), blockchain.InMemDaoOption())\n\trequire.NotNil(bc)\n\tap, err := actpool.NewActPool(bc, cfg.ActPool)\n\trequire.Nil(err)\n\tsf.AddActionHandlers(account.NewProtocol(), vote.NewProtocol(nil), execution.NewProtocol(bc))\n\tap.AddActionEnvelopeValidators(protocol.NewGenericValidator(bc))\n\tap.AddActionValidators(vote.NewProtocol(bc),\n\t\texecution.NewProtocol(bc))\n\tbc.Validator().AddActionEnvelopeValidators(protocol.NewGenericValidator(bc))\n\tbc.Validator().AddActionValidators(account.NewProtocol(), vote.NewProtocol(bc),\n\t\texecution.NewProtocol(bc))\n\trequire.NoError(bc.Start(ctx))\n\n\theight := bc.TipHeight()\n\tfmt.Printf(\"Open blockchain pass, height = %d\\n\", height)\n\trequire.Nil(addTestingBlocks(bc))\n\terr = bc.Stop(ctx)\n\trequire.NoError(err)\n\texplorerCfg := config.Explorer{TpsWindow: 10, MaxTransferPayloadBytes: 1024}\n\n\tsvc := Service{\n\t\tbc:  bc,\n\t\tap:  ap,\n\t\tcfg: explorerCfg,\n\t\tgs:  GasStation{bc, explorerCfg},\n\t}\n\n\ttransfers, err := svc.GetTransfersByAddress(ta.Addrinfo[\"charlie\"].Bech32(), 0, 10)\n\trequire.Nil(err)\n\trequire.Equal(5, len(transfers))\n\n\tvotes, err := svc.GetVotesByAddress(ta.Addrinfo[\"charlie\"].Bech32(), 0, 10)\n\trequire.Nil(err)\n\trequire.Equal(4, len(votes))\n\n\tvotes, err = svc.GetVotesByAddress(ta.Addrinfo[\"charlie\"].Bech32(), 0, 2)\n\trequire.Nil(err)\n\trequire.Equal(2, len(votes))\n\n\tvotes, err = svc.GetVotesByAddress(ta.Addrinfo[\"alfa\"].Bech32(), 0, 10)\n\trequire.Nil(err)\n\trequire.Equal(2, len(votes))\n\n\tvotes, err = svc.GetVotesByAddress(ta.Addrinfo[\"delta\"].Bech32(), 0, 10)\n\trequire.Nil(err)\n\trequire.Equal(0, len(votes))\n\n\texecutions, err := svc.GetExecutionsByAddress(ta.Addrinfo[\"charlie\"].Bech32(), 0, 10)\n\trequire.Nil(err)\n\trequire.Equal(2, len(executions))\n\n\texecutions, err = svc.GetExecutionsByAddress(ta.Addrinfo[\"alfa\"].Bech32(), 0, 10)\n\trequire.Nil(err)\n\trequire.Equal(1, len(executions))\n\n\ttransfers, err = svc.GetLastTransfersByRange(4, 1, 3, true)\n\trequire.Equal(3, len(transfers))\n\trequire.Nil(err)\n\tfor i := 0; i < len(transfers)-1; i++ {\n\t\trequire.True(transfers[i].Timestamp >= transfers[i+1].Timestamp)\n\t}\n\ttransfers, err = svc.GetLastTransfersByRange(4, 4, 5, true)\n\trequire.Equal(5, len(transfers))\n\trequire.Nil(err)\n\tfor i := 0; i < len(transfers)-1; i++ {\n\t\trequire.True(transfers[i].Timestamp >= transfers[i+1].Timestamp)\n\t}\n\n\ttransfers, err = svc.GetLastTransfersByRange(4, 1, 3, false)\n\trequire.Equal(3, len(transfers))\n\trequire.Nil(err)\n\tfor i := 0; i < len(transfers)-1; i++ {\n\t\trequire.True(transfers[i].Timestamp >= transfers[i+1].Timestamp)\n\t}\n\ttransfers, err = svc.GetLastTransfersByRange(4, 4, 5, false)\n\trequire.Equal(1, len(transfers))\n\trequire.Nil(err)\n\n\tvotes, err = svc.GetLastVotesByRange(4, 0, 10)\n\trequire.Equal(10, len(votes))\n\trequire.Nil(err)\n\tfor i := 0; i < len(votes)-1; i++ {\n\t\trequire.True(votes[i].Timestamp >= votes[i+1].Timestamp)\n\t}\n\tvotes, err = svc.GetLastVotesByRange(3, 0, 50)\n\trequire.Equal(22, len(votes))\n\trequire.Nil(err)\n\tfor i := 0; i < len(votes)-1; i++ {\n\t\trequire.True(votes[i].Timestamp >= votes[i+1].Timestamp)\n\t}\n\n\texecutions, err = svc.GetLastExecutionsByRange(4, 0, 3)\n\trequire.Equal(3, len(executions))\n\trequire.Nil(err)\n\tfor i := 0; i < len(executions)-1; i++ {\n\t\trequire.True(executions[i].Timestamp >= executions[i+1].Timestamp)\n\t}\n\texecutions, err = svc.GetLastExecutionsByRange(3, 0, 50)\n\trequire.Equal(1, len(executions))\n\trequire.Nil(err)\n\n\tblks, getBlkErr := svc.GetLastBlocksByRange(3, 4)\n\trequire.Nil(getBlkErr)\n\trequire.Equal(4, len(blks))\n\n\ttransfers, err = svc.GetTransfersByBlockID(blks[2].ID, 0, 10)\n\trequire.Nil(err)\n\trequire.Equal(2, len(transfers))\n\n\t// fail\n\t_, err = svc.GetTransfersByBlockID(\"\", 0, 10)\n\trequire.Error(err)\n\n\tvotes, err = svc.GetVotesByBlockID(blks[1].ID, 0, 0)\n\trequire.Nil(err)\n\trequire.Equal(0, len(votes))\n\n\tvotes, err = svc.GetVotesByBlockID(blks[1].ID, 0, 10)\n\trequire.Nil(err)\n\trequire.Equal(1, len(votes))\n\n\t// fail\n\t_, err = svc.GetVotesByBlockID(\"\", 0, 10)\n\trequire.Error(err)\n\n\t// fail\n\t_, err = svc.GetExecutionsByBlockID(\"\", 0, 10)\n\trequire.Error(err)\n\n\texecutions, err = svc.GetExecutionsByBlockID(blks[1].ID, 0, 10)\n\trequire.Nil(err)\n\trequire.Equal(1, len(executions))\n\n\ttransfer, err := svc.GetTransferByID(transfers[0].ID)\n\trequire.Nil(err)\n\trequire.Equal(transfers[0].Sender, transfer.Sender)\n\trequire.Equal(transfers[0].Recipient, transfer.Recipient)\n\trequire.Equal(transfers[0].BlockID, transfer.BlockID)\n\n\t// error\n\t_, err = svc.GetTransferByID(\"\")\n\trequire.Error(err)\n\n\tvote, err := svc.GetVoteByID(votes[0].ID)\n\trequire.Nil(err)\n\trequire.Equal(votes[0].Nonce, vote.Nonce)\n\trequire.Equal(votes[0].BlockID, vote.BlockID)\n\trequire.Equal(votes[0].Timestamp, vote.Timestamp)\n\trequire.Equal(votes[0].ID, vote.ID)\n\trequire.Equal(votes[0].Votee, vote.Votee)\n\trequire.Equal(votes[0].Voter, vote.Voter)\n\n\t// fail\n\t_, err = svc.GetVoteByID(\"\")\n\trequire.Error(err)\n\n\texecution, err := svc.GetExecutionByID(executions[0].ID)\n\trequire.Nil(err)\n\trequire.Equal(executions[0].Nonce, execution.Nonce)\n\trequire.Equal(executions[0].BlockID, execution.BlockID)\n\trequire.Equal(executions[0].Timestamp, execution.Timestamp)\n\trequire.Equal(executions[0].ID, execution.ID)\n\trequire.Equal(executions[0].Executor, execution.Executor)\n\trequire.Equal(executions[0].Contract, execution.Contract)\n\n\t// fail\n\t_, err = svc.GetExecutionByID(\"\")\n\trequire.Error(err)\n\n\tblk, err := svc.GetBlockByID(blks[0].ID)\n\trequire.Nil(err)\n\trequire.Equal(blks[0].Height, blk.Height)\n\trequire.Equal(blks[0].Timestamp, blk.Timestamp)\n\trequire.Equal(blks[0].Size, blk.Size)\n\trequire.Equal(int64(0), blk.Votes)\n\trequire.Equal(int64(0), blk.Executions)\n\trequire.Equal(int64(1), blk.Transfers)\n\n\t_, err = svc.GetBlockByID(\"\")\n\trequire.Error(err)\n\n\tstats, err := svc.GetCoinStatistic()\n\trequire.Nil(err)\n\trequire.Equal(blockchain.Gen.TotalSupply.String(), stats.Supply)\n\trequire.Equal(int64(4), stats.Height)\n\trequire.Equal(int64(9), stats.Transfers)\n\trequire.Equal(int64(24), stats.Votes)\n\trequire.Equal(int64(3), stats.Executions)\n\trequire.Equal(int64(15), stats.Aps)\n\n\t// success\n\tbalance, err := svc.GetAddressBalance(ta.Addrinfo[\"charlie\"].Bech32())\n\trequire.Nil(err)\n\trequire.Equal(\"3\", balance)\n\n\t// error\n\t_, err = svc.GetAddressBalance(\"\")\n\trequire.Error(err)\n\n\t// success\n\taddressDetails, err := svc.GetAddressDetails(ta.Addrinfo[\"charlie\"].Bech32())\n\trequire.Nil(err)\n\trequire.Equal(\"3\", addressDetails.TotalBalance)\n\trequire.Equal(int64(8), addressDetails.Nonce)\n\trequire.Equal(int64(9), addressDetails.PendingNonce)\n\trequire.Equal(ta.Addrinfo[\"charlie\"].Bech32(), addressDetails.Address)\n\n\t// error\n\t_, err = svc.GetAddressDetails(\"\")\n\trequire.Error(err)\n\n\ttip, err := svc.GetBlockchainHeight()\n\trequire.Nil(err)\n\trequire.Equal(4, int(tip))\n\n\terr = addActsToActPool(ap)\n\trequire.Nil(err)\n\n\t// success\n\ttransfers, err = svc.GetUnconfirmedTransfersByAddress(ta.Addrinfo[\"producer\"].Bech32(), 0, 3)\n\trequire.Nil(err)\n\trequire.Equal(2, len(transfers))\n\trequire.Equal(int64(2), transfers[0].Nonce)\n\trequire.Equal(int64(4), transfers[1].Nonce)\n\tvotes, err = svc.GetUnconfirmedVotesByAddress(ta.Addrinfo[\"producer\"].Bech32(), 0, 3)\n\trequire.Nil(err)\n\trequire.Equal(1, len(votes))\n\trequire.Equal(int64(3), votes[0].Nonce)\n\texecutions, err = svc.GetUnconfirmedExecutionsByAddress(ta.Addrinfo[\"producer\"].Bech32(), 0, 3)\n\trequire.Nil(err)\n\trequire.Equal(1, len(executions))\n\trequire.Equal(int64(5), executions[0].Nonce)\n\ttransfers, err = svc.GetUnconfirmedTransfersByAddress(ta.Addrinfo[\"producer\"].Bech32(), 1, 1)\n\trequire.Nil(err)\n\trequire.Equal(1, len(transfers))\n\trequire.Equal(int64(4), transfers[0].Nonce)\n\tvotes, err = svc.GetUnconfirmedVotesByAddress(ta.Addrinfo[\"producer\"].Bech32(), 1, 1)\n\trequire.Nil(err)\n\trequire.Equal(0, len(votes))\n\texecutions, err = svc.GetUnconfirmedExecutionsByAddress(ta.Addrinfo[\"producer\"].Bech32(), 1, 1)\n\trequire.Nil(err)\n\trequire.Equal(0, len(executions))\n\n\t// error\n\t_, err = svc.GetUnconfirmedTransfersByAddress(\"\", 0, 3)\n\trequire.Error(err)\n\t_, err = svc.GetUnconfirmedVotesByAddress(\"\", 0, 3)\n\trequire.Error(err)\n\t_, err = svc.GetUnconfirmedExecutionsByAddress(\"\", 0, 3)\n\trequire.Error(err)\n\n\t// test GetBlockOrActionByHash\n\tres, err := svc.GetBlockOrActionByHash(\"\")\n\trequire.NoError(err)\n\trequire.Nil(res.Block)\n\trequire.Nil(res.Transfer)\n\trequire.Nil(res.Vote)\n\trequire.Nil(res.Execution)\n\n\tres, err = svc.GetBlockOrActionByHash(blks[0].ID)\n\trequire.NoError(err)\n\trequire.Nil(res.Transfer)\n\trequire.Nil(res.Vote)\n\trequire.Nil(res.Execution)\n\trequire.Equal(&blks[0], res.Block)\n\n\tres, err = svc.GetBlockOrActionByHash(transfers[0].ID)\n\trequire.NoError(err)\n\trequire.Nil(res.Block)\n\trequire.Nil(res.Vote)\n\trequire.Nil(res.Execution)\n\trequire.Equal(&transfers[0], res.Transfer)\n\n\tvotes, err = svc.GetLastVotesByRange(3, 0, 50)\n\trequire.NoError(err)\n\tres, err = svc.GetBlockOrActionByHash(votes[0].ID)\n\trequire.NoError(err)\n\trequire.Nil(res.Block)\n\trequire.Nil(res.Transfer)\n\trequire.Nil(res.Execution)\n\trequire.Equal(&votes[0], res.Vote)\n\n\texecutions, err = svc.GetExecutionsByAddress(ta.Addrinfo[\"charlie\"].Bech32(), 0, 10)\n\trequire.NoError(err)\n\tres, err = svc.GetBlockOrActionByHash(executions[0].ID)\n\trequire.NoError(err)\n\trequire.Nil(res.Block)\n\trequire.Nil(res.Transfer)\n\trequire.Nil(res.Vote)\n\trequire.Equal(&executions[0], res.Execution)\n\trequire.Equal(len(executions), 2)\n\n\tsvc.gs.cfg.GasStation.DefaultGas = 1\n\tgasPrice, err := svc.SuggestGasPrice()\n\trequire.Nil(err)\n\trequire.Equal(gasPrice, int64(1))\n}\n\nfunc TestService_StateByAddr(t *testing.T) {\n\trequire := require.New(t)\n\n\tctrl := gomock.NewController(t)\n\tdefer ctrl.Finish()\n\n\ts := state.Account{\n\t\tBalance:      big.NewInt(46),\n\t\tNonce:        uint64(0),\n\t\tIsCandidate:  false,\n\t\tVotingWeight: big.NewInt(100),\n\t\tVotee:        \"456\",\n\t}\n\n\tmBc := mock_blockchain.NewMockBlockchain(ctrl)\n\tmBc.EXPECT().StateByAddr(\"123\").Times(1).Return(&s, nil)\n\n\tstate, err := mBc.StateByAddr(\"123\")\n\trequire.Nil(err)\n\trequire.Equal(big.NewInt(46), state.Balance)\n\trequire.Equal(uint64(0), state.Nonce)\n\trequire.Equal(false, state.IsCandidate)\n\trequire.Equal(big.NewInt(100), state.VotingWeight)\n\trequire.Equal(\"456\", state.Votee)\n}\n\nfunc TestService_GetConsensusMetrics(t *testing.T) {\n\tctrl := gomock.NewController(t)\n\tdefer ctrl.Finish()\n\n\tcandidates := []string{\n\t\t\"io1qyqsyqcy6nm58gjd2wr035wz5eyd5uq47zyqpng3gxe7nh\",\n\t\t\"io1qyqsyqcy6m6hkqkj3f4w4eflm2gzydmvc0mumm7kgax4l3\",\n\t\t\"io1qyqsyqcyyu9pfazcx0wglp35h2h4fm0hl8p8z2u35vkcwc\",\n\t\t\"io1qyqsyqcyg9pk8zg8xzkmv6g3630xggvacq9e77cwtd4rkc\",\n\t\t\"io1qyqsyqcy8anpz644uhw85rpjplwfv80s687pvhch5ues2k\",\n\t\t\"io1qyqsyqcy65j0upntgz8wq8sum6chetur8ft68uwnfa2m3k\",\n\t\t\"io1qyqsyqcyvx7pmg9pq5kefh5mkxx7fxfmct2x9fpg080r7m\",\n\t}\n\tc := mock_consensus.NewMockConsensus(ctrl)\n\tc.EXPECT().Metrics().Return(scheme.ConsensusMetrics{\n\t\tLatestEpoch:         1,\n\t\tLatestDelegates:     candidates[:4],\n\t\tLatestBlockProducer: candidates[3],\n\t\tCandidates:          candidates,\n\t}, nil)\n\n\tsvc := Service{c: c}\n\n\tm, err := svc.GetConsensusMetrics()\n\trequire.Nil(t, err)\n\trequire.NotNil(t, m)\n\trequire.Equal(t, int64(1), m.LatestEpoch)\n\trequire.Equal(\n\t\tt,\n\t\t[]string{\n\t\t\t\"io1qyqsyqcy6nm58gjd2wr035wz5eyd5uq47zyqpng3gxe7nh\",\n\t\t\t\"io1qyqsyqcy6m6hkqkj3f4w4eflm2gzydmvc0mumm7kgax4l3\",\n\t\t\t\"io1qyqsyqcyyu9pfazcx0wglp35h2h4fm0hl8p8z2u35vkcwc\",\n\t\t\t\"io1qyqsyqcyg9pk8zg8xzkmv6g3630xggvacq9e77cwtd4rkc\",\n\t\t},\n\t\tm.LatestDelegates,\n\t)\n\trequire.Equal(t, \"io1qyqsyqcyg9pk8zg8xzkmv6g3630xggvacq9e77cwtd4rkc\", m.LatestBlockProducer)\n\trequire.Equal(\n\t\tt,\n\t\t[]string{\n\t\t\t\"io1qyqsyqcy6nm58gjd2wr035wz5eyd5uq47zyqpng3gxe7nh\",\n\t\t\t\"io1qyqsyqcy6m6hkqkj3f4w4eflm2gzydmvc0mumm7kgax4l3\",\n\t\t\t\"io1qyqsyqcyyu9pfazcx0wglp35h2h4fm0hl8p8z2u35vkcwc\",\n\t\t\t\"io1qyqsyqcyg9pk8zg8xzkmv6g3630xggvacq9e77cwtd4rkc\",\n\t\t\t\"io1qyqsyqcy8anpz644uhw85rpjplwfv80s687pvhch5ues2k\",\n\t\t\t\"io1qyqsyqcy65j0upntgz8wq8sum6chetur8ft68uwnfa2m3k\",\n\t\t\t\"io1qyqsyqcyvx7pmg9pq5kefh5mkxx7fxfmct2x9fpg080r7m\",\n\t\t},\n\t\tm.Candidates,\n\t)\n}\n\nfunc TestService_SendTransfer(t *testing.T) {\n\trequire := require.New(t)\n\n\tctrl := gomock.NewController(t)\n\tdefer ctrl.Finish()\n\n\tchain := mock_blockchain.NewMockBlockchain(ctrl)\n\tmDp := mock_dispatcher.NewMockDispatcher(ctrl)\n\tbroadcastHandlerCount := 0\n\tsvc := Service{bc: chain, dp: mDp, broadcastHandler: func(_ uint32, _ proto.Message) error {\n\t\tbroadcastHandlerCount++\n\t\treturn nil\n\t}}\n\n\tchain.EXPECT().ChainID().Return(uint32(1)).Times(2)\n\tmDp.EXPECT().HandleBroadcast(gomock.Any(), gomock.Any()).Times(1)\n\n\tr := explorer.SendTransferRequest{\n\t\tVersion:      0x1,\n\t\tNonce:        1,\n\t\tSender:       ta.Addrinfo[\"producer\"].Bech32(),\n\t\tRecipient:    ta.Addrinfo[\"alfa\"].Bech32(),\n\t\tAmount:       big.NewInt(1).String(),\n\t\tGasPrice:     big.NewInt(0).String(),\n\t\tSenderPubKey: keypair.EncodePublicKey(ta.Keyinfo[\"producer\"].PubKey),\n\t\tSignature:    \"\",\n\t\tPayload:      \"\",\n\t}\n\tresponse, err := svc.SendTransfer(r)\n\trequire.NotNil(response.Hash)\n\trequire.Nil(err)\n\tgas, err := svc.EstimateGasForTransfer(r)\n\trequire.Nil(err)\n\trequire.Equal(gas, int64(10000))\n\tassert.Equal(t, 1, broadcastHandlerCount)\n}\n\nfunc TestService_SendVote(t *testing.T) {\n\trequire := require.New(t)\n\n\tctrl := gomock.NewController(t)\n\tdefer ctrl.Finish()\n\n\tchain := mock_blockchain.NewMockBlockchain(ctrl)\n\tmDp := mock_dispatcher.NewMockDispatcher(ctrl)\n\tbroadcastHandlerCount := 0\n\tsvc := Service{bc: chain, dp: mDp, broadcastHandler: func(_ uint32, _ proto.Message) error {\n\t\tbroadcastHandlerCount++\n\t\treturn nil\n\t}}\n\n\tchain.EXPECT().ChainID().Return(uint32(1)).Times(2)\n\tmDp.EXPECT().HandleBroadcast(gomock.Any(), gomock.Any()).Times(1)\n\n\tr := explorer.SendVoteRequest{\n\t\tVersion:     0x1,\n\t\tNonce:       1,\n\t\tVoter:       ta.Addrinfo[\"producer\"].Bech32(),\n\t\tVotee:       ta.Addrinfo[\"alfa\"].Bech32(),\n\t\tVoterPubKey: keypair.EncodePublicKey(ta.Keyinfo[\"producer\"].PubKey),\n\t\tGasPrice:    big.NewInt(0).String(),\n\t\tSignature:   \"\",\n\t}\n\n\tresponse, err := svc.SendVote(r)\n\trequire.NotNil(response.Hash)\n\trequire.Nil(err)\n\tgas, err := svc.EstimateGasForVote()\n\trequire.Nil(err)\n\trequire.Equal(gas, int64(10000))\n\tassert.Equal(t, 1, broadcastHandlerCount)\n}\n\nfunc TestService_SendSmartContract(t *testing.T) {\n\trequire := require.New(t)\n\n\tctrl := gomock.NewController(t)\n\tdefer ctrl.Finish()\n\n\tchain := mock_blockchain.NewMockBlockchain(ctrl)\n\tmDp := mock_dispatcher.NewMockDispatcher(ctrl)\n\tbroadcastHandlerCount := 0\n\tsvc := Service{bc: chain, dp: mDp, broadcastHandler: func(_ uint32, _ proto.Message) error {\n\t\tbroadcastHandlerCount++\n\t\treturn nil\n\t}, gs: GasStation{chain, config.Explorer{}}}\n\n\texecution, err := testutil.SignedExecution(ta.Addrinfo[\"producer\"].Bech32(), ta.Addrinfo[\"delta\"].Bech32(), ta.Keyinfo[\"producer\"].PriKey, 1,\n\t\tbig.NewInt(1), testutil.TestGasLimit, big.NewInt(testutil.TestGasPrice), []byte{1})\n\trequire.NoError(err)\n\texplorerExecution, _ := convertExecutionToExplorerExecution(execution, true)\n\texplorerExecution.Version = int64(execution.Version())\n\n\texe := execution.Action().(*action.Execution)\n\texplorerExecution.ExecutorPubKey = keypair.EncodePublicKey(exe.ExecutorPublicKey())\n\texplorerExecution.Signature = hex.EncodeToString(execution.Signature())\n\tchain.EXPECT().ExecuteContractRead(gomock.Any()).Return(&action.Receipt{GasConsumed: 1000}, nil)\n\n\tgas, err := svc.EstimateGasForSmartContract(explorerExecution)\n\trequire.Nil(err)\n\trequire.Equal(gas, int64(1000))\n\n\tchain.EXPECT().ChainID().Return(uint32(1)).Times(2)\n\tmDp.EXPECT().HandleBroadcast(gomock.Any(), gomock.Any()).Times(1)\n\n\tresponse, err := svc.SendSmartContract(explorerExecution)\n\trequire.NotNil(response.Hash)\n\trequire.Nil(err)\n\tassert.Equal(t, 1, broadcastHandlerCount)\n}\n\nfunc TestServicePutSubChainBlock(t *testing.T) {\n\trequire := require.New(t)\n\n\tctrl := gomock.NewController(t)\n\tdefer ctrl.Finish()\n\n\tchain := mock_blockchain.NewMockBlockchain(ctrl)\n\tmDp := mock_dispatcher.NewMockDispatcher(ctrl)\n\tbroadcastHandlerCount := 0\n\tsvc := Service{bc: chain, dp: mDp, broadcastHandler: func(_ uint32, _ proto.Message) error {\n\t\tbroadcastHandlerCount++\n\t\treturn nil\n\t}}\n\n\trequest := explorer.PutSubChainBlockRequest{}\n\tresponse, err := svc.PutSubChainBlock(request)\n\trequire.Equal(\"\", response.Hash)\n\trequire.NotNil(err)\n\n\tchain.EXPECT().ChainID().Return(uint32(1)).Times(2)\n\tmDp.EXPECT().HandleBroadcast(gomock.Any(), gomock.Any()).Times(1)\n\n\troots := []explorer.PutSubChainBlockMerkelRoot{\n\t\t{\n\t\t\tName:  \"a\",\n\t\t\tValue: hex.EncodeToString([]byte(\"xddd\")),\n\t\t},\n\t}\n\tr := explorer.PutSubChainBlockRequest{\n\t\tVersion:       0x1,\n\t\tNonce:         1,\n\t\tSenderAddress: ta.Addrinfo[\"producer\"].Bech32(),\n\t\tSenderPubKey:  keypair.EncodePublicKey(ta.Keyinfo[\"producer\"].PubKey),\n\t\tGasPrice:      big.NewInt(0).String(),\n\t\tSignature:     \"\",\n\t\tRoots:         roots,\n\t}\n\n\tresponse, err = svc.PutSubChainBlock(r)\n\trequire.NotNil(response.Hash)\n\trequire.Nil(err)\n\tassert.Equal(t, 1, broadcastHandlerCount)\n}\n\nfunc TestServiceSendAction(t *testing.T) {\n\trequire := require.New(t)\n\n\tctrl := gomock.NewController(t)\n\tdefer ctrl.Finish()\n\n\tchain := mock_blockchain.NewMockBlockchain(ctrl)\n\tmDp := mock_dispatcher.NewMockDispatcher(ctrl)\n\tbroadcastHandlerCount := 0\n\tsvc := Service{bc: chain, dp: mDp, broadcastHandler: func(_ uint32, _ proto.Message) error {\n\t\tbroadcastHandlerCount++\n\t\treturn nil\n\t}}\n\n\trequest := explorer.SendActionRequest{}\n\t_, err := svc.SendAction(request)\n\trequire.NotNil(err)\n\n\trequest.Payload = \"abc\"\n\t_, err = svc.SendAction(request)\n\trequire.NotNil(err)\n\n\troots := make(map[string]hash.Hash32B)\n\troots[\"10002\"] = byteutil.BytesTo32B([]byte(\"10002\"))\n\tpb := action.NewPutBlock(\n\t\t1,\n\t\t\"\",\n\t\tta.Addrinfo[\"producer\"].Bech32(),\n\t\t100,\n\t\troots,\n\t\t10000,\n\t\tbig.NewInt(0),\n\t)\n\tbd := &action.EnvelopeBuilder{}\n\telp := bd.SetAction(pb).\n\t\tSetDestinationAddress(\"\").\n\t\tSetGasLimit(10000).SetNonce(1).Build()\n\tselp, err := action.Sign(elp, ta.Addrinfo[\"producer\"].Bech32(), ta.Keyinfo[\"producer\"].PriKey)\n\trequire.NoError(err)\n\n\tvar marshaler jsonpb.Marshaler\n\tpayload, err := marshaler.MarshalToString(selp.Proto())\n\trequire.NoError(err)\n\trequest.Payload = payload\n\trequire.NoError(err)\n\n\tchain.EXPECT().ChainID().Return(uint32(1)).Times(2)\n\tmDp.EXPECT().HandleBroadcast(gomock.Any(), gomock.Any()).Times(1)\n\n\t_, err = svc.SendAction(request)\n\trequire.NoError(err)\n\tassert.Equal(t, 1, broadcastHandlerCount)\n}\n\nfunc TestServiceGetPeers(t *testing.T) {\n\trequire := require.New(t)\n\n\tctrl := gomock.NewController(t)\n\tdefer ctrl.Finish()\n\n\tmDp := mock_dispatcher.NewMockDispatcher(ctrl)\n\tsvc := Service{\n\t\tdp: mDp,\n\t\tneighborsHandler: func() []net.Addr {\n\n\t\t\treturn []net.Addr{\n\t\t\t\t&node.Node{Addr: \"127.0.0.1:10002\"},\n\t\t\t\t&node.Node{Addr: \"127.0.0.1:10003\"},\n\t\t\t\t&node.Node{Addr: \"127.0.0.1:10004\"},\n\t\t\t}\n\t\t},\n\t\tselfHandler: func() net.Addr {\n\t\t\treturn node.NewTCPNode(\"127.0.0.1:10001\")\n\t\t},\n\t}\n\n\tresponse, err := svc.GetPeers()\n\trequire.Nil(err)\n\trequire.Equal(\"127.0.0.1:10001\", response.Self.Address)\n\trequire.Len(response.Peers, 3)\n\trequire.Equal(\"127.0.0.1:10003\", response.Peers[1].Address)\n}\n\nfunc TestTransferPayloadBytesLimit(t *testing.T) {\n\tctrl := gomock.NewController(t)\n\tdefer ctrl.Finish()\n\n\tmDp := mock_dispatcher.NewMockDispatcher(ctrl)\n\tsvc := Service{cfg: config.Explorer{MaxTransferPayloadBytes: 8}, dp: mDp}\n\tvar payload [9]byte\n\treq := explorer.SendTransferRequest{\n\t\tPayload: hex.EncodeToString(payload[:]),\n\t}\n\tres, err := svc.SendTransfer(req)\n\tassert.Equal(t, explorer.SendTransferResponse{}, res)\n\tassert.Error(t, err)\n\tassert.Equal(\n\t\tt,\n\t\t\"transfer payload contains 9 bytes, and is longer than 8 bytes limit: invalid transfer\",\n\t\terr.Error(),\n\t)\n\tassert.Equal(t, ErrTransfer, errors.Cause(err))\n}\n\nfunc TestExplorerCandidateMetrics(t *testing.T) {\n\trequire := require.New(t)\n\tctrl := gomock.NewController(t)\n\tdefer ctrl.Finish()\n\n\tcandidates := []string{\n\t\t\"io1qyqsyqcy6nm58gjd2wr035wz5eyd5uq47zyqpng3gxe7nh\",\n\t\t\"io1qyqsyqcy6m6hkqkj3f4w4eflm2gzydmvc0mumm7kgax4l3\",\n\t\t\"io1qyqsyqcyyu9pfazcx0wglp35h2h4fm0hl8p8z2u35vkcwc\",\n\t\t\"io1qyqsyqcyg9pk8zg8xzkmv6g3630xggvacq9e77cwtd4rkc\",\n\t\t\"io1qyqsyqcy8anpz644uhw85rpjplwfv80s687pvhch5ues2k\",\n\t\t\"io1qyqsyqcy65j0upntgz8wq8sum6chetur8ft68uwnfa2m3k\",\n\t\t\"io1qyqsyqcyvx7pmg9pq5kefh5mkxx7fxfmct2x9fpg080r7m\",\n\t}\n\tc := mock_consensus.NewMockConsensus(ctrl)\n\tc.EXPECT().Metrics().Return(scheme.ConsensusMetrics{\n\t\tLatestEpoch:         1,\n\t\tLatestDelegates:     candidates[:4],\n\t\tLatestBlockProducer: candidates[3],\n\t\tCandidates:          candidates,\n\t}, nil)\n\tbc := mock_blockchain.NewMockBlockchain(ctrl)\n\tbc.EXPECT().CandidatesByHeight(gomock.Any()).Return([]*state.Candidate{\n\t\t{Address: candidates[0], Votes: big.NewInt(0)},\n\t\t{Address: candidates[1], Votes: big.NewInt(0)},\n\t\t{Address: candidates[2], Votes: big.NewInt(0)},\n\t\t{Address: candidates[3], Votes: big.NewInt(0)},\n\t\t{Address: candidates[4], Votes: big.NewInt(0)},\n\t\t{Address: candidates[5], Votes: big.NewInt(0)},\n\t\t{Address: candidates[6], Votes: big.NewInt(0)},\n\t}, nil)\n\n\tsvc := Service{c: c, bc: bc}\n\n\tmetrics, err := svc.GetCandidateMetrics()\n\trequire.NoError(err)\n\trequire.True(7 == len(metrics.Candidates))\n\trequire.True(0 == metrics.LatestHeight)\n\trequire.True(1 == metrics.LatestEpoch)\n}\n\nfunc TestExplorerGetReceiptByExecutionID(t *testing.T) {\n\trequire := require.New(t)\n\tcfg := config.Default\n\tcfg.Chain.TrieDBPath = testTriePath\n\tcfg.Chain.ChainDBPath = testDBPath\n\tcfg.Chain.WriteIndexInChainDB = true\n\tcfg.Explorer.Enabled = true\n\n\ttestutil.CleanupPath(t, testTriePath)\n\tdefer testutil.CleanupPath(t, testTriePath)\n\ttestutil.CleanupPath(t, testDBPath)\n\tdefer testutil.CleanupPath(t, testDBPath)\n\n\tsf, err := factory.NewFactory(cfg, factory.InMemTrieOption())\n\trequire.Nil(err)\n\trequire.Nil(sf.Start(context.Background()))\n\trequire.NoError(addCreatorToFactory(sf))\n\n\t// create chain\n\tctx := context.Background()\n\tbc := blockchain.NewBlockchain(cfg, blockchain.PrecreatedStateFactoryOption(sf), blockchain.InMemDaoOption())\n\trequire.NoError(bc.Start(ctx))\n\n\tsf.AddActionHandlers(execution.NewProtocol(bc))\n\n\tdefer func() {\n\t\trequire.NoError(bc.Stop(ctx))\n\t}()\n\n\tsvc := Service{\n\t\tbc: bc,\n\t\tcfg: config.Explorer{\n\t\t\tTpsWindow:               10,\n\t\t\tMaxTransferPayloadBytes: 1024,\n\t\t},\n\t}\n\n\tdata, _ := hex.DecodeString(\"608060405234801561001057600080fd5b5060df8061001f6000396000f3006080604052600436106049576000357c0100000000000000000000000000000000000000000000000000000000900463ffffffff16806360fe47b114604e5780636d4ce63c146078575b600080fd5b348015605957600080fd5b5060766004803603810190808035906020019092919050505060a0565b005b348015608357600080fd5b50608a60aa565b6040518082815260200191505060405180910390f35b8060008190555050565b600080549050905600a165627a7a7230582002faabbefbbda99b20217cf33cb8ab8100caf1542bf1f48117d72e2c59139aea0029\")\n\t// data, _ := hex.DecodeString(\"6060604052600436106100565763ffffffff7c010000000000000000000000000000000000000000000000000000000060003504166341c0e1b581146100585780637bf786f81461006b578063fbf788d61461009c575b005b341561006357600080fd5b6100566100ca565b341561007657600080fd5b61008a600160a060020a03600435166100f1565b60405190815260200160405180910390f35b34156100a757600080fd5b610056600160a060020a036004351660243560ff60443516606435608435610103565b60005433600160a060020a03908116911614156100ef57600054600160a060020a0316ff5b565b60016020526000908152604090205481565b600160a060020a0385166000908152600160205260408120548190861161012957600080fd5b3087876040516c01000000000000000000000000600160a060020a03948516810282529290931690910260148301526028820152604801604051809103902091506001828686866040516000815260200160405260006040516020015260405193845260ff90921660208085019190915260408085019290925260608401929092526080909201915160208103908084039060008661646e5a03f115156101cf57600080fd5b505060206040510351600054600160a060020a039081169116146101f257600080fd5b50600160a060020a03808716600090815260016020526040902054860390301631811161026257600160a060020a0387166000818152600160205260409081902088905582156108fc0290839051600060405180830381858888f19350505050151561025d57600080fd5b6102b7565b6000547f2250e2993c15843b32621c89447cc589ee7a9f049c026986e545d3c2c0c6f97890600160a060020a0316604051600160a060020a03909116815260200160405180910390a186600160a060020a0316ff5b505050505050505600a165627a7a72305820533e856fc37e3d64d1706bcc7dfb6b1d490c8d566ea498d9d01ec08965a896ca0029\")\n\n\texecution, err := testutil.SignedExecution(ta.Addrinfo[\"producer\"].Bech32(), action.EmptyAddress, ta.Keyinfo[\"producer\"].PriKey, 1,\n\t\tbig.NewInt(0), 1000000, big.NewInt(testutil.TestGasPrice), data)\n\trequire.NoError(err)\n\n\tactionMap := make(map[string][]action.SealedEnvelope)\n\tactionMap[execution.SrcAddr()] = []action.SealedEnvelope{execution}\n\tblk, err := bc.MintNewBlock(actionMap, ta.Keyinfo[\"producer\"].PubKey,\n\t\tta.Keyinfo[\"producer\"].PriKey, ta.Addrinfo[\"producer\"].Bech32(), nil, nil, \"\")\n\n\trequire.NoError(err)\n\trequire.Nil(bc.CommitBlock(blk))\n\n\teHash := execution.Hash()\n\teHashStr := hex.EncodeToString(eHash[:])\n\treceipt, err := svc.GetReceiptByExecutionID(eHashStr)\n\trequire.NoError(err)\n\trequire.Equal(eHashStr, receipt.Hash)\n}\n\nfunc TestService_CreateDeposit(t *testing.T) {\n\tt.Parallel()\n\n\trequire := require.New(t)\n\n\tctrl := gomock.NewController(t)\n\tdefer ctrl.Finish()\n\n\tcfg := config.Default\n\tbc := mock_blockchain.NewMockBlockchain(ctrl)\n\tbc.EXPECT().ChainID().Return(uint32(1)).Times(2)\n\tdp := mock_dispatcher.NewMockDispatcher(ctrl)\n\tdp.EXPECT().HandleBroadcast(gomock.Any(), gomock.Any()).Times(1)\n\n\tbroadcastHandlerCount := 0\n\tsvc := Service{\n\t\tcfg: cfg.Explorer,\n\t\tbc:  bc,\n\t\tbroadcastHandler: func(_ uint32, _ proto.Message) error {\n\t\t\tbroadcastHandlerCount++\n\t\t\treturn nil\n\t\t},\n\t\tdp: dp,\n\t}\n\n\tdeposit := action.NewCreateDeposit(\n\t\t10,\n\t\t2,\n\t\tbig.NewInt(10000),\n\t\tta.Addrinfo[\"producer\"].Bech32(),\n\t\t// Test explorer only, so that it doesn't matter the address is not on sub-chain\n\t\tta.Addrinfo[\"alfa\"].Bech32(),\n\t\t1000,\n\t\tbig.NewInt(100),\n\t)\n\tbd := &action.EnvelopeBuilder{}\n\telp := bd.SetAction(deposit).\n\t\tSetGasLimit(1000).\n\t\tSetGasPrice(big.NewInt(100)).SetDestinationAddress(ta.Addrinfo[\"alfa\"].Bech32()).\n\t\tSetNonce(10).Build()\n\tselp, err := action.Sign(elp, ta.Addrinfo[\"producer\"].Bech32(), ta.Keyinfo[\"producer\"].PriKey)\n\trequire.NoError(err)\n\n\tres, error := svc.CreateDeposit(explorer.CreateDepositRequest{\n\t\tVersion:      int64(deposit.Version()),\n\t\tNonce:        int64(deposit.Nonce()),\n\t\tChainID:      int64(deposit.ChainID()),\n\t\tSender:       deposit.Sender(),\n\t\tSenderPubKey: keypair.EncodePublicKey(deposit.SenderPublicKey()),\n\t\tRecipient:    deposit.Recipient(),\n\t\tAmount:       deposit.Amount().String(),\n\t\tSignature:    hex.EncodeToString(selp.Signature()),\n\t\tGasLimit:     int64(deposit.GasLimit()),\n\t\tGasPrice:     deposit.GasPrice().String(),\n\t})\n\trequire.NoError(error)\n\thash := deposit.Hash()\n\trequire.Equal(hex.EncodeToString(hash[:]), res.Hash)\n\tassert.Equal(t, 1, broadcastHandlerCount)\n}\n\nfunc TestService_SettleDeposit(t *testing.T) {\n\tt.Parallel()\n\n\trequire := require.New(t)\n\n\tctrl := gomock.NewController(t)\n\tdefer ctrl.Finish()\n\n\tcfg := config.Default\n\tbc := mock_blockchain.NewMockBlockchain(ctrl)\n\tbc.EXPECT().ChainID().Return(uint32(1)).Times(2)\n\tdp := mock_dispatcher.NewMockDispatcher(ctrl)\n\tdp.EXPECT().HandleBroadcast(gomock.Any(), gomock.Any()).Times(1)\n\n\tbroadcastHandlerCount := 0\n\tsvc := Service{\n\t\tcfg: cfg.Explorer,\n\t\tbc:  bc,\n\t\tbroadcastHandler: func(_ uint32, _ proto.Message) error {\n\t\t\tbroadcastHandlerCount++\n\t\t\treturn nil\n\t\t},\n\t\tdp: dp,\n\t}\n\n\tdeposit := action.NewSettleDeposit(\n\t\t10,\n\t\tbig.NewInt(10000),\n\t\t100000,\n\t\tta.Addrinfo[\"producer\"].Bech32(),\n\t\t// Test explorer only, so that it doesn't matter the address is not on sub-chain\n\t\tta.Addrinfo[\"alfa\"].Bech32(),\n\t\t1000,\n\t\tbig.NewInt(100),\n\t)\n\tbd := &action.EnvelopeBuilder{}\n\telp := bd.SetAction(deposit).\n\t\tSetGasLimit(1000).\n\t\tSetGasPrice(big.NewInt(100)).SetDestinationAddress(ta.Addrinfo[\"alfa\"].Bech32()).\n\t\tSetNonce(10).Build()\n\tselp, err := action.Sign(elp, ta.Addrinfo[\"producer\"].Bech32(), ta.Keyinfo[\"producer\"].PriKey)\n\trequire.NoError(err)\n\n\tres, error := svc.SettleDeposit(explorer.SettleDepositRequest{\n\t\tVersion:      int64(deposit.Version()),\n\t\tNonce:        int64(deposit.Nonce()),\n\t\tSender:       deposit.Sender(),\n\t\tSenderPubKey: keypair.EncodePublicKey(deposit.SenderPublicKey()),\n\t\tRecipient:    deposit.Recipient(),\n\t\tAmount:       deposit.Amount().String(),\n\t\tIndex:        int64(deposit.Index()),\n\t\tSignature:    hex.EncodeToString(selp.Signature()),\n\t\tGasLimit:     int64(deposit.GasLimit()),\n\t\tGasPrice:     deposit.GasPrice().String(),\n\t})\n\trequire.NoError(error)\n\thash := deposit.Hash()\n\trequire.Equal(hex.EncodeToString(hash[:]), res.Hash)\n\tassert.Equal(t, 1, broadcastHandlerCount)\n}\n\nfunc TestService_GetDeposits(t *testing.T) {\n\tt.Parallel()\n\n\trequire := require.New(t)\n\tassert := assert.New(t)\n\n\tctrl := gomock.NewController(t)\n\tcfg := config.Default\n\tctx := context.Background()\n\tbc := mock_blockchain.NewMockBlockchain(ctrl)\n\tsf, err := factory.NewFactory(cfg, factory.InMemTrieOption())\n\trequire.NoError(err)\n\trequire.NoError(sf.Start(ctx))\n\tbc.EXPECT().GetFactory().Return(sf).AnyTimes()\n\tsubChainAddr := ta.Addrinfo[\"producer\"]\n\tws, err := sf.NewWorkingSet()\n\trequire.NoError(err)\n\trequire.NoError(ws.PutState(\n\t\tmainchain.SubChainsInOperationKey,\n\t\tmainchain.SubChainsInOperation{\n\t\t\tmainchain.InOperation{\n\t\t\t\tID:   2,\n\t\t\t\tAddr: subChainAddr.Bytes(),\n\t\t\t},\n\t\t},\n\t))\n\trequire.NoError(ws.PutState(\n\t\tbyteutil.BytesTo20B(subChainAddr.Payload()),\n\t\t&mainchain.SubChain{\n\t\t\tDepositCount: 2,\n\t\t},\n\t))\n\tdepositAddr1 := ta.Addrinfo[\"alfa\"]\n\trequire.NoError(ws.PutState(\n\t\tmainchain.DepositAddress(subChainAddr.Bytes(), 0),\n\t\t&mainchain.Deposit{\n\t\t\tAmount:    big.NewInt(100),\n\t\t\tAddr:      depositAddr1.Bytes(),\n\t\t\tConfirmed: false,\n\t\t},\n\t))\n\tdepositAddr2 := ta.Addrinfo[\"bravo\"]\n\trequire.NoError(ws.PutState(\n\t\tmainchain.DepositAddress(subChainAddr.Bytes(), 1),\n\t\t&mainchain.Deposit{\n\t\t\tAmount:    big.NewInt(200),\n\t\t\tAddr:      depositAddr2.Bytes(),\n\t\t\tConfirmed: false,\n\t\t},\n\t))\n\trequire.NoError(sf.Commit(ws))\n\n\tdefer func() {\n\t\trequire.NoError(sf.Stop(ctx))\n\t\tctrl.Finish()\n\t}()\n\n\tp := mainchain.NewProtocol(bc)\n\tsvc := Service{\n\t\tmainChain: p,\n\t}\n\n\t_, err = svc.GetDeposits(3, 0, 1)\n\tassert.True(strings.Contains(err.Error(), \"is not found in operation\"))\n\n\tdeposits, err := svc.GetDeposits(2, 0, 1)\n\tassert.NoError(err)\n\tassert.Equal(1, len(deposits))\n\tassert.Equal(\"100\", deposits[0].Amount)\n\n\tdeposits, err = svc.GetDeposits(2, 1, 2)\n\tassert.NoError(err)\n\tassert.Equal(2, len(deposits))\n\tassert.Equal(\"200\", deposits[0].Amount)\n\tassert.Equal(\"100\", deposits[1].Amount)\n\n\tdeposits, err = svc.GetDeposits(2, 1, 3)\n\tassert.NoError(err)\n\tassert.Equal(2, len(deposits))\n\n\tdeposits, err = svc.GetDeposits(2, 3, 2)\n\tassert.NoError(err)\n\tassert.Equal(2, len(deposits))\n\n\tdeposits, err = svc.GetDeposits(2, 0, 2)\n\tassert.NoError(err)\n\tassert.Equal(1, len(deposits))\n}\n\nfunc TestService_GetStateRootHash(t *testing.T) {\n\tctrl := gomock.NewController(t)\n\tbc := mock_blockchain.NewMockBlockchain(ctrl)\n\tsf := mock_factory.NewMockFactory(ctrl)\n\tbc.EXPECT().GetFactory().Return(sf).AnyTimes()\n\trootHash := byteutil.BytesTo32B(hash.Hash256b([]byte(\"test\")))\n\tsf.EXPECT().RootHashByHeight(gomock.Any()).Return(rootHash, nil).Times(1)\n\n\tdefer ctrl.Finish()\n\n\tsvc := Service{bc: bc}\n\trootHashStr, err := svc.GetStateRootHash(1)\n\tassert.NoError(t, err)\n\tassert.Equal(t, hex.EncodeToString(rootHash[:]), rootHashStr)\n}\n\nfunc addCreatorToFactory(sf factory.Factory) error {\n\tws, err := sf.NewWorkingSet()\n\tif err != nil {\n\t\treturn err\n\t}\n\tif _, err = account.LoadOrCreateAccount(ws, ta.Addrinfo[\"producer\"].Bech32(),\n\t\tblockchain.Gen.TotalSupply); err != nil {\n\t\treturn err\n\t}\n\tgasLimit := testutil.TestGasLimit\n\tctx := protocol.WithRunActionsCtx(context.Background(),\n\t\tprotocol.RunActionsCtx{\n\t\t\tProducerAddr:    ta.Addrinfo[\"producer\"].Bech32(),\n\t\t\tGasLimit:        &gasLimit,\n\t\t\tEnableGasCharge: testutil.EnableGasCharge,\n\t\t})\n\tif _, _, err = ws.RunActions(ctx, 0, nil); err != nil {\n\t\treturn err\n\t}\n\treturn sf.Commit(ws)\n}\n", "idx": 4, "id": 14585, "msg": "", "proj": "iotexproject-iotex-core", "lang": "go"}
{"patch": "@@ -87,11 +87,6 @@ public class CustomServerUrlEditor extends Dialog {\n \t\tcancel();\n \t}\n \n-\t/**\n-\t * onStart will build the saved display, this will restore whatever the user\n-\t * typed before the rotate gets called after onStart, which is nice and\n-\t * means the controls are already hooked.\n-\t */\n \t@Override\n \tpublic void onRestoreInstanceState(Bundle savedInstanceState) {\n \t\tsuper.onRestoreInstanceState(savedInstanceState);", "y": 0, "oldf": "/*\n * Copyright (c) 2011, salesforce.com, inc.\n * All rights reserved.\n * Redistribution and use of this software in source and binary forms, with or\n * without modification, are permitted provided that the following conditions\n * are met:\n * - Redistributions of source code must retain the above copyright notice, this\n * list of conditions and the following disclaimer.\n * - Redistributions in binary form must reproduce the above copyright notice,\n * this list of conditions and the following disclaimer in the documentation\n * and/or other materials provided with the distribution.\n * - Neither the name of salesforce.com, inc. nor the names of its contributors\n * may be used to endorse or promote products derived from this software without\n * specific prior written permission of salesforce.com, inc.\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n * POSSIBILITY OF SUCH DAMAGE.\n */\npackage com.salesforce.androidsdk.ui;\n\nimport android.app.Dialog;\nimport android.content.Context;\nimport android.os.Bundle;\nimport android.text.Editable;\nimport android.text.SpannableString;\nimport android.view.View;\nimport android.view.View.OnFocusChangeListener;\nimport android.view.WindowManager.LayoutParams;\nimport android.webkit.URLUtil;\nimport android.widget.Button;\nimport android.widget.EditText;\nimport android.widget.Toast;\n\nimport com.salesforce.androidsdk.app.SalesforceSDKManager;\nimport com.salesforce.androidsdk.auth.LoginServerManager;\nimport com.salesforce.androidsdk.auth.LoginServerManager.LoginServer;\n\n/**\n * Custom dialog to allow the user to set a label and url to use for the login.\n */\npublic class CustomServerUrlEditor extends Dialog {\n\n\tprivate static final String PERSISTED_CTRL_FOCUS = \"focusedId\";\n\tprivate static final String PERSISTED_LABEL = \"label\";\n\tprivate static final String PERSISTED_URL_VALUE = \"url\";\n\n\tboolean isDefault;\n\tprivate SalesforceR salesforceR;\n\tprivate LoginServerManager loginServerManager;\n\tprivate int width;\n\n\tpublic CustomServerUrlEditor(Context context, int width) {\n\t\tsuper(context);\n\t\t\n\t\t// Object which allows reference to resources living outside the SDK\n\t\tsalesforceR = SalesforceSDKManager.getInstance().getSalesforceR();\n\t\t\n\t\t// Login server manager\n\t\tloginServerManager = SalesforceSDKManager.getInstance().getLoginServerManager();\n\t\t\n\t\t// Width\n\t\tthis.width = width;\n\t}\n\n\tprivate String getEditDefaultValue(int editId) {\n\t\tif (editId == salesforceR.idPickerCustomLabel()) {\n\t\t\treturn getString(salesforceR.stringServerUrlDefaultCustomLabel());\n\t\t} else { \n\t\t\treturn getString(salesforceR.stringServerUrlDefaultCustomUrl());\n\t\t}\n\t}\n\n\tprivate String getString(int resourceKey) {\n\t\treturn getContext().getString(resourceKey);\n\t}\n\n\t@Override\n\tpublic void onBackPressed() {\n\t\tcancel();\n\t}\n\n\t/**\n\t * onStart will build the saved display, this will restore whatever the user\n\t * typed before the rotate gets called after onStart, which is nice and\n\t * means the controls are already hooked.\n\t */\n\t@Override\n\tpublic void onRestoreInstanceState(Bundle savedInstanceState) {\n\t\tsuper.onRestoreInstanceState(savedInstanceState);\n\t\tsetEditText(salesforceR.idPickerCustomLabel(), savedInstanceState\n\t\t\t\t.getString(PERSISTED_LABEL));\n\t\tsetEditText(salesforceR.idPickerCustomUrl(), savedInstanceState\n\t\t\t\t.getString(PERSISTED_URL_VALUE));\n\t\tif (savedInstanceState.getInt(PERSISTED_CTRL_FOCUS) > 0) {\n\t\t\tEditText et = (EditText) findViewById(savedInstanceState\n\t\t\t\t\t.getInt(PERSISTED_CTRL_FOCUS));\n\t\t\tet.requestFocus();\n\t\t}\n\t}\n\n\t// save values of edit ctrls\n\t// save empty as \"\" not null\n\t@Override\n\tpublic Bundle onSaveInstanceState() {\n\t\tBundle superBundle = super.onSaveInstanceState();\n\t\tpersistEditCtrlInfo(superBundle, PERSISTED_LABEL, salesforceR.idPickerCustomLabel());\n\t\tpersistEditCtrlInfo(superBundle, PERSISTED_URL_VALUE, salesforceR.idPickerCustomUrl());\n\t\treturn superBundle;\n\t}\n\n\t@Override\n\tprotected void onCreate(Bundle savedInstance) {\n\t\tLoginServer customServer = loginServerManager.getCustomLoginServer();\n\t\tString label = (customServer != null ? customServer.name : \n\t\t\t\tgetEditDefaultValue((salesforceR.idPickerCustomLabel())));\n\t\tString urlValue = (customServer != null ? customServer.url : \n\t\t\t\tgetEditDefaultValue((salesforceR.idPickerCustomUrl())));\n\t\tisDefault = urlValue\n\t\t\t\t.equals(getString(salesforceR.stringServerUrlDefaultCustomUrl()));\n\t\tif (isDefault) {\n\t\t\tsetTitle(salesforceR.stringServerUrlAddTitle());\n\t\t} else {\n\t\t\tsetTitle(salesforceR.stringServerUrlEditTitle());\n\t\t}\n\t\tsetContentView(salesforceR.layoutCustomServerUrl());\n\t\tsetEditText(salesforceR.idPickerCustomLabel(), label);\n\t\tsetEditText(salesforceR.idPickerCustomUrl(), urlValue);\n\n\t\t// set handlers in code, otherwise it will default to a dialog listener,\n\t\t// which is not what we want here\n\t\tButton applyBtn = (Button) findViewById(salesforceR.idApplyButton());\n\t\tapplyBtn.setOnClickListener(new View.OnClickListener() {\n\n\t\t\t@Override\n\t\t\tpublic void onClick(View v) {\n\n\t\t\t\t// validate. if the values are non default just accept them\n\t\t\t\tString lbl = validateInput(salesforceR.idPickerCustomLabel());\n\t\t\t\tif (null == lbl) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tString val = validateInput(salesforceR.idPickerCustomUrl());\n\t\t\t\tif (null == val) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\t// save state and finish\n\t\t\t\tloginServerManager.setCustomLoginServer(lbl, val);\n\t\t\t\tdismiss();\n\t\t\t}\n\t\t});\n\t\tButton cancelBtn = (Button) findViewById(salesforceR.idCancelButton());\n\t\tcancelBtn.setOnClickListener(new View.OnClickListener() {\n\n\t\t\t@Override\n\t\t\tpublic void onClick(View v) {\n\t\t\t\tcancel();\n\t\t\t}\n\t\t});\n\n\t\t// can only get a dialog to resize after the layout has been set\n\t\t// we want to take up the full screen...\n\t\tLayoutParams params = getWindow().getAttributes();\n\t\tparams.width = (width != 0 ? width : LayoutParams.FILL_PARENT);\n\t\tgetWindow().setAttributes(params);\n\t}\n\n\tprivate void persistEditCtrlInfo(Bundle superBundle, String keyName,\n\t\t\tint ctrlId) {\n\t\tEditText et = (EditText) findViewById(ctrlId);\n\t\tsuperBundle.putString(keyName, et.getText().toString());\n\t\tif (et.hasFocus()) {\n\t\t\tsuperBundle.putInt(PERSISTED_CTRL_FOCUS, ctrlId);\n\t\t}\n\t}\n\n\tprivate void setEditText(int editId, String value) {\n\t\tif (null == value) {\n\t\t\tthrow new RuntimeException(\"Value cannot be null\");\n\t\t}\n\t\tEditText et = (EditText) findViewById(editId);\n\t\tSpannableString labelSpan = new SpannableString(value);\n\t\tif (et != null) {\n\t\t\tet.setText(labelSpan);\n\t\t\tif (et.getOnFocusChangeListener() == null) {\n\t\t\t\tet.setOnFocusChangeListener(new OnFocusChangeListener() {\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic void onFocusChange(View v, boolean hasFocus) {\n\t\t\t\t\t\tEditText et = (EditText) v;\n\t\t\t\t\t\tboolean isDefaultValue = et.getText().toString().equals(\n\t\t\t\t\t\t\t\tgetEditDefaultValue(et.getId()));\n\t\t\t\t\t\tif (hasFocus && isDefaultValue) {\n\t\t\t\t\t\t\tet.getText().clear();\n\t\t\t\t\t\t} else if (!hasFocus && et.getText().toString().equals(\"\")) {\n\t\t\t\t\t\t\tif (et.getId() == salesforceR.idPickerCustomLabel()) {\n\t\t\t\t\t\t\t\tsetEditText(salesforceR.idPickerCustomLabel(), getEditDefaultValue(et.getId()));\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tsetEditText(salesforceR.idPickerCustomUrl(), getEditDefaultValue(et.getId()));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\t}\n\n\tprivate String validateInput(int editId) {\n\t\tEditText et = (EditText) findViewById(editId);\n\t\tEditable etVal = et.getText();\n\t\tboolean isInvalidValue = etVal.toString().equals(\n\t\t\t\tgetEditDefaultValue(editId))\n\t\t\t\t|| etVal.toString().equals(\"\");\n\n\t\t// Ensure that the URL is a 'https://' URL, since OAuth requires\n\t\t// 'https://'.\n\t\tif (editId == salesforceR.idPickerCustomUrl()) {\n\t\t\tisInvalidValue = !URLUtil.isHttpsUrl(etVal.toString());\n\t\t\tif (isInvalidValue) {\n\t\t\t\tToast.makeText(getContext(), getContext().getString(salesforceR.stringInvalidServerUrl()),\n\t\t\t\t\t\tToast.LENGTH_SHORT).show();\n\t\t\t}\n\t\t}\n\t\tif (isInvalidValue) {\n\t\t\tet.selectAll();\n\t\t\tet.requestFocus();\n\t\t\treturn null;\n\t\t}\n\t\treturn etVal.toString();\n\t}\n}\n", "idx": 4, "id": 13840, "msg": "", "proj": "forcedotcom-SalesforceMobileSDK-Android", "lang": "java"}
{"patch": "@@ -0,0 +1,32 @@\n+# -*- coding: utf-8 -*-\n+##\n+## This file is part of Invenio.\n+## Copyright (C) 2014 CERN.\n+##\n+## Invenio is free software; you can redistribute it and/or\n+## modify it under the terms of the GNU General Public License as\n+## published by the Free Software Foundation; either version 2 of the\n+## License, or (at your option) any later version.\n+##\n+## Invenio is distributed in the hope that it will be useful, but\n+## WITHOUT ANY WARRANTY; without even the implied warranty of\n+## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n+## General Public License for more details.\n+##\n+## You should have received a copy of the GNU General Public License\n+## along with Invenio; if not, write to the Free Software Foundation, Inc.,\n+## 59 Temple Place, Suite 330, Boston, MA 02111-1307, USA.\n+\n+\"\"\"Group bundles.\"\"\"\n+\n+from invenio.ext.assets import Bundle, RequireJSFilter\n+from invenio.base.bundles import jquery as _j, invenio as _i\n+\n+js = Bundle(\n+    'vendors/jquery/dist/jquery.js',\n+    'vendors/typeahead.js/dist/typeahead.bundle.js',\n+    'js/groups/init.js',\n+    filters=RequireJSFilter(exclude=[_j, _i]),\n+    output=\"groups.js\",\n+    weight=50\n+)", "y": 1, "oldf": "", "idx": 1, "id": 13633, "msg": "you don't need to bundle jquery in `groups.js`", "proj": "inveniosoftware-invenio", "lang": "py"}
{"patch": "@@ -0,0 +1,35 @@\n+/* Copyright 2016 Google Inc\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.google.api.codegen.viewmodel;\n+\n+/** The concrete callable class type */\n+public enum ApiCallableImplType {\n+  SimpleApiCallable(ServiceMethodType.UnaryMethod),\n+  PagedApiCallable(ServiceMethodType.UnaryMethod),\n+  BundlingApiCallable(ServiceMethodType.UnaryMethod),\n+  StreamingApiCallable(ServiceMethodType.GrpcStreamingMethod),\n+  InitialOperationApiCallable(ServiceMethodType.UnaryMethod),\n+  OperationApiCallable(ServiceMethodType.LongRunningMethod);\n+\n+  public ServiceMethodType serviceMethodType() {\n+    return serviceMethodType;\n+  }\n+\n+  ApiCallableImplType(ServiceMethodType serviceMethodType) {\n+    this.serviceMethodType = serviceMethodType;\n+  }\n+\n+  private ServiceMethodType serviceMethodType;\n+}", "y": 1, "oldf": "", "idx": 1, "id": 19791, "msg": "I don't know what is normal for enums with structure like this - do you usually put the private fields at the bottom?", "proj": "googleapis-gapic-generator", "lang": "java"}
{"patch": "@@ -15,6 +15,7 @@\n package openflow\n \n import (\n+\t\"antrea.io/antrea/pkg/util/runtime\"\n \t\"fmt\"\n \t\"math/rand\"\n \t\"net\"", "y": 1, "oldf": "// Copyright 2019 Antrea Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage openflow\n\nimport (\n\t\"fmt\"\n\t\"math/rand\"\n\t\"net\"\n\n\t\"github.com/contiv/libOpenflow/protocol\"\n\t\"k8s.io/klog/v2\"\n\n\t\"antrea.io/antrea/pkg/agent/config\"\n\t\"antrea.io/antrea/pkg/agent/openflow/cookie\"\n\t\"antrea.io/antrea/pkg/agent/types\"\n\t\"antrea.io/antrea/pkg/agent/util\"\n\tbinding \"antrea.io/antrea/pkg/ovs/openflow\"\n\t\"antrea.io/antrea/third_party/proxy\"\n)\n\nconst maxRetryForOFSwitch = 5\n\n// Client is the interface to program OVS flows for entity connectivity of Antrea.\ntype Client interface {\n\t// Initialize sets up all basic flows on the specific OVS bridge. It returns a channel which\n\t// is used to notify the caller in case of a reconnection, in which case ReplayFlows should\n\t// be called to ensure that the set of OVS flows is correct. All flows programmed in the\n\t// switch which match the current round number will be deleted before any new flow is\n\t// installed.\n\tInitialize(roundInfo types.RoundInfo, config *config.NodeConfig, encapMode config.TrafficEncapModeType) (<-chan struct{}, error)\n\n\t// InstallGatewayFlows sets up flows related to an OVS gateway port, the gateway must exist.\n\tInstallGatewayFlows() error\n\n\t// InstallClusterServiceCIDRFlows sets up the appropriate flows so that traffic can reach\n\t// the different Services running in the Cluster. This method needs to be invoked once with\n\t// the Cluster Service CIDR as a parameter.\n\tInstallClusterServiceCIDRFlows(serviceNets []*net.IPNet) error\n\n\t// InstallClusterServiceFlows sets up the appropriate flows so that traffic can reach\n\t// the different Services running in the Cluster. This method needs to be invoked once.\n\tInstallClusterServiceFlows() error\n\n\t// InstallDefaultTunnelFlows sets up the classification flow for the default (flow based) tunnel.\n\tInstallDefaultTunnelFlows() error\n\n\t// InstallNodeFlows should be invoked when a connection to a remote Node is going to be set\n\t// up. The hostname is used to identify the added flows. When IPSec tunnel is enabled,\n\t// ipsecTunOFPort must be set to the OFPort number of the IPSec tunnel port to the remote Node;\n\t// otherwise ipsecTunOFPort must be set to 0.\n\t// InstallNodeFlows has all-or-nothing semantics(call succeeds if all the flows are installed\n\t// successfully, otherwise no flows will be installed). Calls to InstallNodeFlows are idempotent.\n\t// Concurrent calls to InstallNodeFlows and / or UninstallNodeFlows are supported as long as they\n\t// are all for different hostnames.\n\tInstallNodeFlows(\n\t\thostname string,\n\t\tpeerConfigs map[*net.IPNet]net.IP,\n\t\ttunnelPeerIP net.IP,\n\t\tipsecTunOFPort uint32,\n\t\tpeerNodeMAC net.HardwareAddr) error\n\n\t// UninstallNodeFlows removes the connection to the remote Node specified with the\n\t// hostname. UninstallNodeFlows will do nothing if no connection to the host was established.\n\tUninstallNodeFlows(hostname string) error\n\n\t// InstallPodFlows should be invoked when a connection to a Pod on current Node. The\n\t// interfaceName is used to identify the added flows. InstallPodFlows has all-or-nothing\n\t// semantics(call succeeds if all the flows are installed successfully, otherwise no\n\t// flows will be installed). Calls to InstallPodFlows are idempotent. Concurrent calls\n\t// to InstallPodFlows and / or UninstallPodFlows are supported as long as they are all\n\t// for different interfaceNames.\n\tInstallPodFlows(interfaceName string, podInterfaceIPs []net.IP, podInterfaceMAC net.HardwareAddr, ofPort uint32) error\n\n\t// UninstallPodFlows removes the connection to the local Pod specified with the\n\t// interfaceName. UninstallPodFlows will do nothing if no connection to the Pod was established.\n\tUninstallPodFlows(interfaceName string) error\n\n\t// InstallServiceGroup installs a group for Service LB. Each endpoint\n\t// is a bucket of the group. For now, each bucket has the same weight.\n\tInstallServiceGroup(groupID binding.GroupIDType, withSessionAffinity bool, endpoints []proxy.Endpoint) error\n\t// UninstallServiceGroup removes the group and its buckets that are\n\t// installed by InstallServiceGroup.\n\tUninstallServiceGroup(groupID binding.GroupIDType) error\n\n\t// InstallEndpointFlows installs flows for accessing Endpoints.\n\t// If an Endpoint is on the current Node, then flows for hairpin and endpoint\n\t// L2 forwarding should also be installed.\n\tInstallEndpointFlows(protocol binding.Protocol, endpoints []proxy.Endpoint) error\n\t// UninstallEndpointFlows removes flows of the Endpoint installed by\n\t// InstallEndpointFlows.\n\tUninstallEndpointFlows(protocol binding.Protocol, endpoint proxy.Endpoint) error\n\n\t// InstallServiceFlows installs flows for accessing Service with clusterIP.\n\t// It installs the flow that uses the group/bucket to do service LB. If the\n\t// affinityTimeout is not zero, it also installs the flow which has a learn\n\t// action to maintain the LB decision.\n\t// The group with the groupID must be installed before, otherwise the\n\t// installation will fail.\n\tInstallServiceFlows(groupID binding.GroupIDType, svcIP net.IP, svcPort uint16, protocol binding.Protocol, affinityTimeout uint16) error\n\t// UninstallServiceFlows removes flows installed by InstallServiceFlows.\n\tUninstallServiceFlows(svcIP net.IP, svcPort uint16, protocol binding.Protocol) error\n\t// InstallLoadBalancerServiceFromOutsideFlows installs flows for LoadBalancer Service traffic from outside node.\n\t// The traffic is received from uplink port and will be forwarded to gateway by the installed flows. And then\n\t// kube-proxy will handle the traffic.\n\t// This function is only used for Windows platform.\n\tInstallLoadBalancerServiceFromOutsideFlows(svcIP net.IP, svcPort uint16, protocol binding.Protocol) error\n\t// UninstallLoadBalancerServiceFromOutsideFlows removes flows installed by InstallLoadBalancerServiceFromOutsideFlows.\n\tUninstallLoadBalancerServiceFromOutsideFlows(svcIP net.IP, svcPort uint16, protocol binding.Protocol) error\n\n\t// GetFlowTableStatus should return an array of flow table status, all existing flow tables should be included in the list.\n\tGetFlowTableStatus() []binding.TableStatus\n\n\t// InstallPolicyRuleFlows installs flows for a new NetworkPolicy rule. Rule should include all fields in the\n\t// NetworkPolicy rule. Each ingress/egress policy rule installs Openflow entries on two tables, one for\n\t// ruleTable and the other for dropTable. If a packet does not pass the ruleTable, it will be dropped by the\n\t// dropTable.\n\tInstallPolicyRuleFlows(ofPolicyRule *types.PolicyRule) error\n\n\t// BatchInstallPolicyRuleFlows installs multiple flows for NetworkPolicy rules in batch.\n\tBatchInstallPolicyRuleFlows(ofPolicyRules []*types.PolicyRule) error\n\n\t// UninstallPolicyRuleFlows removes the Openflow entry relevant to the specified NetworkPolicy rule.\n\t// It also returns a slice of stale ofPriorities used by ClusterNetworkPolicies.\n\t// UninstallPolicyRuleFlows will do nothing if no Openflow entry for the rule is installed.\n\tUninstallPolicyRuleFlows(ruleID uint32) ([]string, error)\n\n\t// AddPolicyRuleAddress adds one or multiple addresses to the specified NetworkPolicy rule. If addrType is true, the\n\t// addresses are added to PolicyRule.From, else to PolicyRule.To.\n\tAddPolicyRuleAddress(ruleID uint32, addrType types.AddressType, addresses []types.Address, priority *uint16) error\n\n\t// DeletePolicyRuleAddress removes addresses from the specified NetworkPolicy rule. If addrType is srcAddress, the addresses\n\t// are removed from PolicyRule.From, else from PolicyRule.To.\n\tDeletePolicyRuleAddress(ruleID uint32, addrType types.AddressType, addresses []types.Address, priority *uint16) error\n\n\t// InstallBridgeUplinkFlows installs Openflow flows between bridge local port and uplink port to support\n\t// host networking.\n\t// This function is only used for Windows platform.\n\tInstallBridgeUplinkFlows() error\n\n\t// InstallExternalFlows sets up flows to enable Pods to communicate to\n\t// the external IP addresses. The flows identify the packets from local\n\t// Pods to the external IP address, and mark the packets to be SNAT'd\n\t// with the configured SNAT IPs. On Windows Node, the flows also perform\n\t// SNAT with the Openflow NAT action.\n\tInstallExternalFlows() error\n\n\t// InstallSNATMarkFlows installs flows for a local SNAT IP. On Linux, a\n\t// single flow is added to mark the packets tunnelled from remote Nodes\n\t// that should be SNAT'd with the SNAT IP. On Windows, an extra flow is\n\t// added to perform SNAT for the marked packets with the SNAT IP.\n\tInstallSNATMarkFlows(snatIP net.IP, mark uint32) error\n\n\t// UninstallSNATMarkFlows removes the flows installed to set the packet\n\t// mark for a SNAT IP.\n\tUninstallSNATMarkFlows(mark uint32) error\n\n\t// InstallSNATPolicyFlow installs the SNAT flows for a local Pod. If the\n\t// SNAT IP for the Pod is on the local Node, a non-zero SNAT ID should\n\t// allocated for the SNAT IP, and the installed flow sets the SNAT IP\n\t// mark on the egress packets from the ofPort; if the SNAT IP is on a\n\t// remote Node, snatMark should be set to 0, and the installed flow\n\t// tunnels egress packets to the remote Node using the SNAT IP as the\n\t// tunnel destination, and the packets should be SNAT'd on the remote\n\t// Node. As of now, a Pod can be configured to use only a single SNAT\n\t// IP in a single address family (IPv4 or IPv6).\n\tInstallPodSNATFlows(ofPort uint32, snatIP net.IP, snatMark uint32) error\n\n\t// UninstallPodSNATFlows removes the SNAT flows for the local Pod.\n\tUninstallPodSNATFlows(ofPort uint32) error\n\n\t// Disconnect disconnects the connection between client and OFSwitch.\n\tDisconnect() error\n\n\t// IsConnected returns the connection status between client and OFSwitch. The return value is true if the OFSwitch is connected.\n\tIsConnected() bool\n\n\t// ReplayFlows should be called when a spurious disconnection occurs. After we reconnect to\n\t// the OFSwitch, we need to replay all the flows cached by the client. ReplayFlows will try\n\t// to replay as many flows as possible, and will log an error when a flow cannot be\n\t// installed.\n\tReplayFlows()\n\n\t// DeleteStaleFlows deletes all flows from the previous round which are no longer needed. It\n\t// should be called by the agent after all required flows have been installed / updated with\n\t// the new round number.\n\tDeleteStaleFlows() error\n\n\t// GetTunnelVirtualMAC() returns globalVirtualMAC used for tunnel traffic.\n\tGetTunnelVirtualMAC() net.HardwareAddr\n\n\t// GetPodFlowKeys returns the keys (match strings) of the cached flows for a\n\t// Pod.\n\tGetPodFlowKeys(interfaceName string) []string\n\n\t// GetServiceFlowKeys returns the keys (match strings) of the cached\n\t// flows for a Service (port) and its endpoints.\n\tGetServiceFlowKeys(svcIP net.IP, svcPort uint16, protocol binding.Protocol, endpoints []proxy.Endpoint) []string\n\n\t// GetNetworkPolicyFlowKeys returns the keys (match strings) of the cached\n\t// flows for a NetworkPolicy. Flows are grouped by policy rules, and duplicated\n\t// entries can be added due to conjunctive match flows shared by multiple\n\t// rules.\n\tGetNetworkPolicyFlowKeys(npName, npNamespace string) []string\n\n\t// ReassignFlowPriorities takes a list of priority updates, and update the actionFlows to replace\n\t// the old priority with the desired one, for each priority update on that table.\n\tReassignFlowPriorities(updates map[uint16]uint16, table binding.TableIDType) error\n\n\t// SubscribePacketIn subscribes to packet in messages for the given reason. Packets\n\t// will be placed in the queue and if the queue is full, the packet in messages\n\t// will be dropped. pktInQueue supports rate-limiting for the consumer, in order to\n\t// constrain the compute resources that may be used by the consumer.\n\tSubscribePacketIn(reason uint8, pktInQueue *binding.PacketInQueue) error\n\n\t// SendTraceflowPacket injects packet to specified OVS port for Openflow.\n\tSendTraceflowPacket(dataplaneTag uint8, packet *binding.Packet, inPort uint32, outPort int32) error\n\n\t// InstallTraceflowFlows installs flows for a Traceflow request.\n\tInstallTraceflowFlows(dataplaneTag uint8, liveTraffic, droppedOnly, receiverOnly bool, packet *binding.Packet, ofPort uint32, timeoutSeconds uint16) error\n\n\t// UninstallTraceflowFlows uninstalls flows for a Traceflow request.\n\tUninstallTraceflowFlows(dataplaneTag uint8) error\n\n\t// Initial tun_metadata0 in TLV map for Traceflow.\n\tInitialTLVMap() error\n\n\t// Find Network Policy reference and OFpriority by conjunction ID.\n\tGetPolicyInfoFromConjunction(ruleID uint32) (string, string)\n\n\t// RegisterPacketInHandler uses SubscribePacketIn to get PacketIn message and process received\n\t// packets through registered handlers.\n\tRegisterPacketInHandler(packetHandlerReason uint8, packetHandlerName string, packetInHandler interface{})\n\n\tStartPacketInHandler(packetInStartedReason []uint8, stopCh <-chan struct{})\n\t// Get traffic metrics of each NetworkPolicy rule.\n\tNetworkPolicyMetrics() map[uint32]*types.RuleMetric\n\t// Returns if IPv4 is supported on this Node or not.\n\tIsIPv4Enabled() bool\n\t// Returns if IPv6 is supported on this Node or not.\n\tIsIPv6Enabled() bool\n\t// SendTCPPacketOut sends TCP packet as a packet-out to OVS.\n\tSendTCPPacketOut(\n\t\tsrcMAC string,\n\t\tdstMAC string,\n\t\tsrcIP string,\n\t\tdstIP string,\n\t\tinPort uint32,\n\t\toutPort int32,\n\t\tisIPv6 bool,\n\t\ttcpSrcPort uint16,\n\t\ttcpDstPort uint16,\n\t\ttcpAckNum uint32,\n\t\ttcpFlag uint8,\n\t\tisReject bool) error\n\t// SendICMPPacketOut sends ICMP packet as a packet-out to OVS.\n\tSendICMPPacketOut(\n\t\tsrcMAC string,\n\t\tdstMAC string,\n\t\tsrcIP string,\n\t\tdstIP string,\n\t\tinPort uint32,\n\t\toutPort int32,\n\t\tisIPv6 bool,\n\t\ticmpType uint8,\n\t\ticmpCode uint8,\n\t\ticmpData []byte,\n\t\tisReject bool) error\n}\n\n// GetFlowTableStatus returns an array of flow table status.\nfunc (c *client) GetFlowTableStatus() []binding.TableStatus {\n\treturn c.bridge.DumpTableStatus()\n}\n\n// IsConnected returns the connection status between client and OFSwitch.\nfunc (c *client) IsConnected() bool {\n\treturn c.bridge.IsConnected()\n}\n\n// addFlows installs the flows on the OVS bridge and then add them into the flow cache. If the flow cache exists,\n// it will return immediately, otherwise it will use Bundle to add all flows, and then add them into the flow cache.\n// If it fails to add the flows with Bundle, it will return the error and no flow cache is created.\nfunc (c *client) addFlows(cache *flowCategoryCache, flowCacheKey string, flows []binding.Flow) error {\n\t_, ok := cache.Load(flowCacheKey)\n\t// If a flow cache entry already exists for the key, return immediately. Otherwise, add the flows to the switch\n\t// and populate the cache with them.\n\tif ok {\n\t\tklog.V(2).Infof(\"Flows with cache key %s are already installed\", flowCacheKey)\n\t\treturn nil\n\t}\n\terr := c.ofEntryOperations.AddAll(flows)\n\tif err != nil {\n\t\treturn err\n\t}\n\tfCache := flowCache{}\n\t// Add the successfully installed flows into the flow cache.\n\tfor _, flow := range flows {\n\t\tfCache[flow.MatchString()] = flow\n\t}\n\tcache.Store(flowCacheKey, fCache)\n\treturn nil\n}\n\n// modifyFlows sets the flows of flowCategoryCache be exactly same as the provided slice for the given flowCacheKey.\nfunc (c *client) modifyFlows(cache *flowCategoryCache, flowCacheKey string, flows []binding.Flow) error {\n\toldFlowCacheI, ok := cache.Load(flowCacheKey)\n\tfCache := flowCache{}\n\tvar err error\n\tif !ok {\n\t\tfor _, flow := range flows {\n\t\t\tfCache[flow.MatchString()] = flow\n\t\t}\n\n\t\terr = c.ofEntryOperations.AddAll(flows)\n\t} else {\n\t\tvar adds, mods, dels []binding.Flow\n\t\toldFlowCache := oldFlowCacheI.(flowCache)\n\t\tfor _, flow := range flows {\n\t\t\tmatchString := flow.MatchString()\n\t\t\tif _, ok := oldFlowCache[matchString]; ok {\n\t\t\t\tmods = append(mods, flow)\n\t\t\t} else {\n\t\t\t\tadds = append(adds, flow)\n\t\t\t}\n\t\t\tfCache[matchString] = flow\n\t\t}\n\t\tfor k, v := range oldFlowCache {\n\t\t\tif _, ok := fCache[k]; !ok {\n\t\t\t\tdels = append(dels, v)\n\t\t\t}\n\t\t}\n\t\terr = c.ofEntryOperations.BundleOps(adds, mods, dels)\n\t}\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Modify the flows in the flow cache.\n\tcache.Store(flowCacheKey, fCache)\n\treturn nil\n}\n\n// deleteFlows deletes all the flows in the flow cache indexed by the provided flowCacheKey.\nfunc (c *client) deleteFlows(cache *flowCategoryCache, flowCacheKey string) error {\n\tfCacheI, ok := cache.Load(flowCacheKey)\n\tif !ok {\n\t\t// no matching flows found in the cache\n\t\treturn nil\n\t}\n\tfCache := fCacheI.(flowCache)\n\t// Delete flows from OVS.\n\tdelFlows := make([]binding.Flow, 0, len(fCache))\n\tfor _, flow := range fCache {\n\t\tdelFlows = append(delFlows, flow)\n\t}\n\tif err := c.ofEntryOperations.DeleteAll(delFlows); err != nil {\n\t\treturn err\n\t}\n\tcache.Delete(flowCacheKey)\n\treturn nil\n}\n\n// InstallNodeFlows installs flows for peer Nodes. Parameter remoteGatewayMAC is only for Windows.\nfunc (c *client) InstallNodeFlows(hostname string,\n\tpeerConfigs map[*net.IPNet]net.IP,\n\ttunnelPeerIP net.IP,\n\tipsecTunOFPort uint32,\n\tremoteGatewayMAC net.HardwareAddr) error {\n\tc.replayMutex.RLock()\n\tdefer c.replayMutex.RUnlock()\n\n\tvar flows []binding.Flow\n\tlocalGatewayMAC := c.nodeConfig.GatewayConfig.MAC\n\n\tfor peerPodCIDR, peerGatewayIP := range peerConfigs {\n\t\tif peerGatewayIP.To4() != nil {\n\t\t\t// Since broadcast is not supported in IPv6, ARP should happen only with IPv4 address, and ARP responder flows\n\t\t\t// only work for IPv4 addresses.\n\t\t\tflows = append(flows, c.arpResponderFlow(peerGatewayIP, cookie.Node))\n\t\t}\n\t\tif c.encapMode.NeedsEncapToPeer(tunnelPeerIP, c.nodeConfig.NodeIPAddr) {\n\t\t\t// tunnelPeerIP is the Node Internal Address. In a dual-stack setup, whether this address is an IPv4 address or an\n\t\t\t// IPv6 one is decided by the address family of Node Internal Address.\n\t\t\tflows = append(flows, c.l3FwdFlowToRemote(localGatewayMAC, *peerPodCIDR, tunnelPeerIP, cookie.Node))\n\t\t} else {\n\t\t\tflows = append(flows, c.l3FwdFlowToRemoteViaRouting(localGatewayMAC, remoteGatewayMAC, cookie.Node, tunnelPeerIP, peerPodCIDR)...)\n\t\t}\n\t}\n\n\tif ipsecTunOFPort != 0 {\n\t\t// When IPSec tunnel is enabled, packets received from the remote Node are\n\t\t// input from the Node's IPSec tunnel port, not the default tunnel port. So,\n\t\t// add a separate tunnelClassifierFlow for the IPSec tunnel port.\n\t\tflows = append(flows, c.tunnelClassifierFlow(ipsecTunOFPort, cookie.Node))\n\t}\n\n\t// For Windows Noencap Mode, the OVS flows for Node need be be exactly same as the provided 'flows' slice because\n\t// the Node flows may be processed more than once if the MAC annotation is updated.\n\treturn c.modifyFlows(c.nodeFlowCache, hostname, flows)\n}\n\nfunc (c *client) UninstallNodeFlows(hostname string) error {\n\tc.replayMutex.RLock()\n\tdefer c.replayMutex.RUnlock()\n\treturn c.deleteFlows(c.nodeFlowCache, hostname)\n}\n\nfunc (c *client) InstallPodFlows(interfaceName string, podInterfaceIPs []net.IP, podInterfaceMAC net.HardwareAddr, ofPort uint32) error {\n\tc.replayMutex.RLock()\n\tdefer c.replayMutex.RUnlock()\n\n\tlocalGatewayMAC := c.nodeConfig.GatewayConfig.MAC\n\tflows := []binding.Flow{\n\t\tc.podClassifierFlow(ofPort, cookie.Pod),\n\t\tc.l2ForwardCalcFlow(podInterfaceMAC, ofPort, false, cookie.Pod),\n\t}\n\n\t// Add support for IPv4 ARP responder.\n\tpodInterfaceIPv4 := util.GetIPv4Addr(podInterfaceIPs)\n\tif podInterfaceIPv4 != nil {\n\t\tflows = append(flows, c.arpSpoofGuardFlow(podInterfaceIPv4, podInterfaceMAC, ofPort, cookie.Pod))\n\t}\n\t// Add IP SpoofGuard flows for all validate IPs.\n\tflows = append(flows, c.podIPSpoofGuardFlow(podInterfaceIPs, podInterfaceMAC, ofPort, cookie.Pod)...)\n\t// Add L3 Routing flows to rewrite Pod's dst MAC for all validate IPs.\n\tflows = append(flows, c.l3FwdFlowToPod(localGatewayMAC, podInterfaceIPs, podInterfaceMAC, cookie.Pod)...)\n\n\tif c.encapMode.IsNetworkPolicyOnly() {\n\t\t// In policy-only mode, traffic to local Pod is routed based on destination IP.\n\t\tflows = append(flows,\n\t\t\tc.l3FwdFlowRouteToPod(podInterfaceIPs, podInterfaceMAC, cookie.Pod)...,\n\t\t)\n\t}\n\treturn c.addFlows(c.podFlowCache, interfaceName, flows)\n}\n\nfunc (c *client) UninstallPodFlows(interfaceName string) error {\n\tc.replayMutex.RLock()\n\tdefer c.replayMutex.RUnlock()\n\treturn c.deleteFlows(c.podFlowCache, interfaceName)\n}\n\nfunc (c *client) getFlowKeysFromCache(cache *flowCategoryCache, cacheKey string) []string {\n\tfCacheI, ok := cache.Load(cacheKey)\n\tif !ok {\n\t\treturn nil\n\t}\n\tfCache := fCacheI.(flowCache)\n\tflowKeys := make([]string, 0, len(fCache))\n\n\t// ReplayFlows() could change Flow internal state. Although its current\n\t// implementation does not impact Flow match string generation, we still\n\t// acquire read lock of replayMutex here for logic cleanliness.\n\tc.replayMutex.RLock()\n\tdefer c.replayMutex.RUnlock()\n\tfor _, flow := range fCache {\n\t\tflowKeys = append(flowKeys, flow.MatchString())\n\t}\n\treturn flowKeys\n}\n\nfunc (c *client) GetPodFlowKeys(interfaceName string) []string {\n\treturn c.getFlowKeysFromCache(c.podFlowCache, interfaceName)\n}\n\nfunc (c *client) InstallServiceGroup(groupID binding.GroupIDType, withSessionAffinity bool, endpoints []proxy.Endpoint) error {\n\tc.replayMutex.RLock()\n\tdefer c.replayMutex.RUnlock()\n\n\tgroup := c.serviceEndpointGroup(groupID, withSessionAffinity, endpoints...)\n\tif err := group.Add(); err != nil {\n\t\treturn fmt.Errorf(\"error when installing Service Endpoints Group: %w\", err)\n\t}\n\tc.groupCache.Store(groupID, group)\n\treturn nil\n}\n\nfunc (c *client) UninstallServiceGroup(groupID binding.GroupIDType) error {\n\tc.replayMutex.RLock()\n\tdefer c.replayMutex.RUnlock()\n\tif !c.bridge.DeleteGroup(groupID) {\n\t\treturn fmt.Errorf(\"group %d delete failed\", groupID)\n\t}\n\tc.groupCache.Delete(groupID)\n\treturn nil\n}\n\nfunc generateEndpointFlowCacheKey(endpointIP string, endpointPort int, protocol binding.Protocol) string {\n\treturn fmt.Sprintf(\"E%s%s%x\", endpointIP, protocol, endpointPort)\n}\n\nfunc generateServicePortFlowCacheKey(svcIP net.IP, svcPort uint16, protocol binding.Protocol) string {\n\treturn fmt.Sprintf(\"S%s%s%x\", svcIP, protocol, svcPort)\n}\n\nfunc (c *client) InstallEndpointFlows(protocol binding.Protocol, endpoints []proxy.Endpoint) error {\n\tc.replayMutex.RLock()\n\tdefer c.replayMutex.RUnlock()\n\n\tfor _, endpoint := range endpoints {\n\t\tvar flows []binding.Flow\n\t\tendpointPort, _ := endpoint.Port()\n\t\tendpointIP := net.ParseIP(endpoint.IP())\n\t\tportVal := portToUint16(endpointPort)\n\t\tcacheKey := generateEndpointFlowCacheKey(endpoint.IP(), endpointPort, protocol)\n\t\tflows = append(flows, c.endpointDNATFlow(endpointIP, portVal, protocol))\n\t\tif endpoint.GetIsLocal() {\n\t\t\tflows = append(flows, c.hairpinSNATFlow(endpointIP))\n\t\t}\n\t\tif err := c.addFlows(c.serviceFlowCache, cacheKey, flows); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (c *client) UninstallEndpointFlows(protocol binding.Protocol, endpoint proxy.Endpoint) error {\n\tc.replayMutex.RLock()\n\tdefer c.replayMutex.RUnlock()\n\n\tport, err := endpoint.Port()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error when getting port: %w\", err)\n\t}\n\tcacheKey := generateEndpointFlowCacheKey(endpoint.IP(), port, protocol)\n\treturn c.deleteFlows(c.serviceFlowCache, cacheKey)\n}\n\nfunc (c *client) InstallServiceFlows(groupID binding.GroupIDType, svcIP net.IP, svcPort uint16, protocol binding.Protocol, affinityTimeout uint16) error {\n\tc.replayMutex.RLock()\n\tdefer c.replayMutex.RUnlock()\n\tvar flows []binding.Flow\n\tflows = append(flows, c.serviceLBFlow(groupID, svcIP, svcPort, protocol, affinityTimeout != 0))\n\tif affinityTimeout != 0 {\n\t\tflows = append(flows, c.serviceLearnFlow(groupID, svcIP, svcPort, protocol, affinityTimeout))\n\t}\n\tcacheKey := generateServicePortFlowCacheKey(svcIP, svcPort, protocol)\n\treturn c.addFlows(c.serviceFlowCache, cacheKey, flows)\n}\n\nfunc (c *client) UninstallServiceFlows(svcIP net.IP, svcPort uint16, protocol binding.Protocol) error {\n\tc.replayMutex.RLock()\n\tdefer c.replayMutex.RUnlock()\n\tcacheKey := generateServicePortFlowCacheKey(svcIP, svcPort, protocol)\n\treturn c.deleteFlows(c.serviceFlowCache, cacheKey)\n}\n\nfunc (c *client) GetServiceFlowKeys(svcIP net.IP, svcPort uint16, protocol binding.Protocol, endpoints []proxy.Endpoint) []string {\n\tcacheKey := generateServicePortFlowCacheKey(svcIP, svcPort, protocol)\n\tflowKeys := c.getFlowKeysFromCache(c.serviceFlowCache, cacheKey)\n\tfor _, ep := range endpoints {\n\t\tepPort, _ := ep.Port()\n\t\tcacheKey = generateEndpointFlowCacheKey(ep.IP(), epPort, protocol)\n\t\tflowKeys = append(flowKeys, c.getFlowKeysFromCache(c.serviceFlowCache, cacheKey)...)\n\t}\n\treturn flowKeys\n}\n\nfunc (c *client) InstallClusterServiceFlows() error {\n\tflows := []binding.Flow{\n\t\tc.serviceNeedLBFlow(),\n\t\tc.sessionAffinityReselectFlow(),\n\t\tc.l2ForwardOutputServiceHairpinFlow(),\n\t}\n\tif c.IsIPv4Enabled() {\n\t\tflows = append(flows, c.serviceHairpinResponseDNATFlow(binding.ProtocolIP))\n\t\tflows = append(flows, c.serviceLBBypassFlows(binding.ProtocolIP)...)\n\t}\n\tif c.IsIPv6Enabled() {\n\t\tflows = append(flows, c.serviceHairpinResponseDNATFlow(binding.ProtocolIPv6))\n\t\tflows = append(flows, c.serviceLBBypassFlows(binding.ProtocolIPv6)...)\n\t}\n\tif err := c.ofEntryOperations.AddAll(flows); err != nil {\n\t\treturn err\n\t}\n\tc.defaultServiceFlows = flows\n\treturn nil\n}\n\nfunc (c *client) InstallClusterServiceCIDRFlows(serviceNets []*net.IPNet) error {\n\tflows := c.serviceCIDRDNATFlows(serviceNets)\n\tif err := c.ofEntryOperations.AddAll(flows); err != nil {\n\t\treturn err\n\t}\n\tc.defaultServiceFlows = flows\n\treturn nil\n}\n\nfunc (c *client) InstallGatewayFlows() error {\n\tgatewayConfig := c.nodeConfig.GatewayConfig\n\tgatewayIPs := []net.IP{}\n\n\tflows := []binding.Flow{\n\t\tc.gatewayClassifierFlow(cookie.Default),\n\t\tc.l2ForwardCalcFlow(gatewayConfig.MAC, config.HostGatewayOFPort, true, cookie.Default),\n\t}\n\tflows = append(flows, c.gatewayIPSpoofGuardFlows(cookie.Default)...)\n\n\t// Add ARP SpoofGuard flow for local gateway interface.\n\tif gatewayConfig.IPv4 != nil {\n\t\tgatewayIPs = append(gatewayIPs, gatewayConfig.IPv4)\n\t\tflows = append(flows, c.gatewayARPSpoofGuardFlow(gatewayConfig.IPv4, gatewayConfig.MAC, cookie.Default))\n\t}\n\tif gatewayConfig.IPv6 != nil {\n\t\tgatewayIPs = append(gatewayIPs, gatewayConfig.IPv6)\n\t}\n\n\t// Add flow to ensure the liveness check packet could be forwarded correctly.\n\tflows = append(flows, c.localProbeFlow(gatewayIPs, cookie.Default)...)\n\tflows = append(flows, c.ctRewriteDstMACFlows(gatewayConfig.MAC, cookie.Default)...)\n\tflows = append(flows, c.l3FwdFlowToGateway(gatewayIPs, gatewayConfig.MAC, cookie.Default)...)\n\n\tif err := c.ofEntryOperations.AddAll(flows); err != nil {\n\t\treturn err\n\t}\n\tc.gatewayFlows = flows\n\treturn nil\n}\n\nfunc (c *client) InstallDefaultTunnelFlows() error {\n\tflows := []binding.Flow{\n\t\tc.tunnelClassifierFlow(config.DefaultTunOFPort, cookie.Default),\n\t\tc.l2ForwardCalcFlow(globalVirtualMAC, config.DefaultTunOFPort, true, cookie.Default),\n\t}\n\tif err := c.ofEntryOperations.AddAll(flows); err != nil {\n\t\treturn err\n\t}\n\tc.defaultTunnelFlows = flows\n\treturn nil\n}\n\nfunc (c *client) initialize() error {\n\tif err := c.ofEntryOperations.AddAll(c.defaultFlows()); err != nil {\n\t\treturn fmt.Errorf(\"failed to install default flows: %v\", err)\n\t}\n\tif err := c.ofEntryOperations.Add(c.arpNormalFlow(cookie.Default)); err != nil {\n\t\treturn fmt.Errorf(\"failed to install arp normal flow: %v\", err)\n\t}\n\tif err := c.ofEntryOperations.AddAll(c.ipv6Flows(cookie.Default)); err != nil {\n\t\treturn fmt.Errorf(\"failed to install ipv6 flows: %v\", err)\n\t}\n\tif err := c.ofEntryOperations.AddAll(c.decTTLFlows(cookie.Default)); err != nil {\n\t\treturn fmt.Errorf(\"failed to install dec TTL flow on source Node: %v\", err)\n\t}\n\tif err := c.ofEntryOperations.AddAll(c.l2ForwardOutputFlows(cookie.Default)); err != nil {\n\t\treturn fmt.Errorf(\"failed to install L2 forward output flows: %v\", err)\n\t}\n\tif err := c.ofEntryOperations.AddAll(c.connectionTrackFlows(cookie.Default)); err != nil {\n\t\treturn fmt.Errorf(\"failed to install connection track flows: %v\", err)\n\t}\n\tif err := c.ofEntryOperations.AddAll(c.establishedConnectionFlows(cookie.Default)); err != nil {\n\t\treturn fmt.Errorf(\"failed to install flows to skip established connections: %v\", err)\n\t}\n\tif c.encapMode.IsNetworkPolicyOnly() {\n\t\tif err := c.setupPolicyOnlyFlows(); err != nil {\n\t\t\treturn fmt.Errorf(\"failed to setup policy only flows: %w\", err)\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (c *client) Initialize(roundInfo types.RoundInfo, nodeConfig *config.NodeConfig, encapMode config.TrafficEncapModeType) (<-chan struct{}, error) {\n\tc.nodeConfig = nodeConfig\n\tc.encapMode = encapMode\n\n\tif config.IsIPv4Enabled(nodeConfig, encapMode) {\n\t\tc.ipProtocols = append(c.ipProtocols, binding.ProtocolIP)\n\t}\n\tif config.IsIPv6Enabled(nodeConfig, encapMode) {\n\t\tc.ipProtocols = append(c.ipProtocols, binding.ProtocolIPv6)\n\t}\n\n\t// Initiate connections to target OFswitch, and create tables on the switch.\n\tconnCh := make(chan struct{})\n\tif err := c.bridge.Connect(maxRetryForOFSwitch, connCh); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Ignore first notification, it is not a \"reconnection\".\n\t<-connCh\n\n\tc.roundInfo = roundInfo\n\tc.cookieAllocator = cookie.NewAllocator(roundInfo.RoundNum)\n\n\t// In the normal case, there should be no existing flows with the current round number. This\n\t// is needed in case the agent was restarted before we had a chance to increment the round\n\t// number (incrementing the round number happens once we are satisfied that stale flows from\n\t// the previous round have been deleted).\n\tif err := c.deleteFlowsByRoundNum(roundInfo.RoundNum); err != nil {\n\t\treturn nil, fmt.Errorf(\"error when deleting exiting flows for current round number: %v\", err)\n\t}\n\n\treturn connCh, c.initialize()\n}\n\nfunc (c *client) InstallExternalFlows() error {\n\tnodeIP := c.nodeConfig.NodeIPAddr.IP\n\tlocalGatewayMAC := c.nodeConfig.GatewayConfig.MAC\n\n\tvar flows []binding.Flow\n\tif c.nodeConfig.PodIPv4CIDR != nil {\n\t\tflows = c.externalFlows(nodeIP, *c.nodeConfig.PodIPv4CIDR, localGatewayMAC)\n\t}\n\tif c.nodeConfig.PodIPv6CIDR != nil {\n\t\tflows = append(flows, c.externalFlows(nodeIP, *c.nodeConfig.PodIPv6CIDR, localGatewayMAC)...)\n\t}\n\n\tif err := c.ofEntryOperations.AddAll(flows); err != nil {\n\t\treturn fmt.Errorf(\"failed to install flows for external communication: %v\", err)\n\t}\n\tc.hostNetworkingFlows = append(c.hostNetworkingFlows, flows...)\n\treturn nil\n}\n\nfunc (c *client) InstallSNATMarkFlows(snatIP net.IP, mark uint32) error {\n\tflows := c.snatMarkFlows(snatIP, mark)\n\tcacheKey := fmt.Sprintf(\"s%x\", mark)\n\tc.replayMutex.RLock()\n\tdefer c.replayMutex.RUnlock()\n\treturn c.addFlows(c.snatFlowCache, cacheKey, flows)\n}\n\nfunc (c *client) UninstallSNATMarkFlows(mark uint32) error {\n\tcacheKey := fmt.Sprintf(\"s%x\", mark)\n\tc.replayMutex.RLock()\n\tdefer c.replayMutex.RUnlock()\n\treturn c.deleteFlows(c.snatFlowCache, cacheKey)\n}\n\nfunc (c *client) InstallPodSNATFlows(ofPort uint32, snatIP net.IP, snatMark uint32) error {\n\tflows := []binding.Flow{c.snatRuleFlow(ofPort, snatIP, snatMark, c.nodeConfig.GatewayConfig.MAC)}\n\tcacheKey := fmt.Sprintf(\"p%x\", ofPort)\n\tc.replayMutex.RLock()\n\tdefer c.replayMutex.RUnlock()\n\treturn c.addFlows(c.snatFlowCache, cacheKey, flows)\n}\n\nfunc (c *client) UninstallPodSNATFlows(ofPort uint32) error {\n\tcacheKey := fmt.Sprintf(\"p%x\", ofPort)\n\tc.replayMutex.RLock()\n\tdefer c.replayMutex.RUnlock()\n\treturn c.deleteFlows(c.snatFlowCache, cacheKey)\n}\n\nfunc (c *client) ReplayFlows() {\n\tc.replayMutex.Lock()\n\tdefer c.replayMutex.Unlock()\n\n\tif err := c.initialize(); err != nil {\n\t\tklog.Errorf(\"Error during flow replay: %v\", err)\n\t}\n\n\taddFixedFlows := func(flows []binding.Flow) {\n\t\tfor _, flow := range flows {\n\t\t\tflow.Reset()\n\t\t}\n\t\tif err := c.ofEntryOperations.AddAll(flows); err != nil {\n\t\t\tklog.Errorf(\"Error when replaying fixed flows: %v\", err)\n\t\t}\n\n\t}\n\n\taddFixedFlows(c.gatewayFlows)\n\taddFixedFlows(c.defaultServiceFlows)\n\taddFixedFlows(c.defaultTunnelFlows)\n\t// hostNetworkingFlows is used only on Windows. Replay the flows only when there are flows in this cache.\n\tif len(c.hostNetworkingFlows) > 0 {\n\t\taddFixedFlows(c.hostNetworkingFlows)\n\t}\n\n\tinstallCachedFlows := func(key, value interface{}) bool {\n\t\tfCache := value.(flowCache)\n\t\tcachedFlows := make([]binding.Flow, 0)\n\n\t\tfor _, flow := range fCache {\n\t\t\tflow.Reset()\n\t\t\tcachedFlows = append(cachedFlows, flow)\n\t\t}\n\n\t\tif err := c.ofEntryOperations.AddAll(cachedFlows); err != nil {\n\t\t\tklog.Errorf(\"Error when replaying cached flows: %v\", err)\n\t\t}\n\t\treturn true\n\t}\n\n\tc.groupCache.Range(func(id, value interface{}) bool {\n\t\tgroup := value.(binding.Group)\n\t\tgroup.Reset()\n\t\tif err := group.Add(); err != nil {\n\t\t\tklog.Errorf(\"Error when replaying cached group %d: %v\", id, err)\n\t\t}\n\t\treturn true\n\t})\n\tc.nodeFlowCache.Range(installCachedFlows)\n\tc.podFlowCache.Range(installCachedFlows)\n\tc.serviceFlowCache.Range(installCachedFlows)\n\n\tc.replayPolicyFlows()\n}\n\nfunc (c *client) deleteFlowsByRoundNum(roundNum uint64) error {\n\tcookieID, cookieMask := cookie.CookieMaskForRound(roundNum)\n\treturn c.bridge.DeleteFlowsByCookie(cookieID, cookieMask)\n}\n\nfunc (c *client) DeleteStaleFlows() error {\n\tif c.roundInfo.PrevRoundNum == nil {\n\t\tklog.V(2).Info(\"Previous round number is unset, no flows to delete\")\n\t\treturn nil\n\t}\n\treturn c.deleteFlowsByRoundNum(*c.roundInfo.PrevRoundNum)\n}\n\nfunc (c *client) setupPolicyOnlyFlows() error {\n\t// Rewrites MAC to gw port if the packet received is unmatched by local Pod flows.\n\tflows := c.l3FwdFlowRouteToGW(c.nodeConfig.GatewayConfig.MAC, cookie.Default)\n\t// If IPv6 is enabled, this flow will never get hit.\n\tflows = append(flows,\n\t\t// Replies any ARP request with the same global virtual MAC.\n\t\tc.arpResponderStaticFlow(cookie.Default),\n\t)\n\tif err := c.ofEntryOperations.AddAll(flows); err != nil {\n\t\treturn fmt.Errorf(\"failed to setup policy-only flows: %w\", err)\n\t}\n\treturn nil\n}\n\nfunc (c *client) SubscribePacketIn(reason uint8, pktInQueue *binding.PacketInQueue) error {\n\treturn c.bridge.SubscribePacketIn(reason, pktInQueue)\n}\n\nfunc (c *client) SendTraceflowPacket(dataplaneTag uint8, packet *binding.Packet, inPort uint32, outPort int32) error {\n\tpacketOutBuilder := c.bridge.BuildPacketOut()\n\n\tif packet.DestinationMAC == nil {\n\t\tpacket.DestinationMAC = c.nodeConfig.GatewayConfig.MAC\n\t}\n\t// Set ethernet header\n\tpacketOutBuilder = packetOutBuilder.SetDstMAC(packet.DestinationMAC).SetSrcMAC(packet.SourceMAC)\n\n\t// Set IP header\n\tpacketOutBuilder = packetOutBuilder.SetDstIP(packet.DestinationIP).SetSrcIP(packet.SourceIP).SetTTL(packet.TTL)\n\tif !packet.IsIPv6 {\n\t\tpacketOutBuilder = packetOutBuilder.SetIPFlags(packet.IPFlags)\n\t}\n\n\t// Set transport header\n\tswitch packet.IPProto {\n\tcase protocol.Type_ICMP, protocol.Type_IPv6ICMP:\n\t\tif packet.IPProto == protocol.Type_ICMP {\n\t\t\tpacketOutBuilder = packetOutBuilder.SetIPProtocol(binding.ProtocolICMP)\n\t\t} else {\n\t\t\tpacketOutBuilder = packetOutBuilder.SetIPProtocol(binding.ProtocolICMPv6)\n\t\t}\n\t\tpacketOutBuilder = packetOutBuilder.SetICMPType(packet.ICMPType).\n\t\t\tSetICMPCode(packet.ICMPCode).\n\t\t\tSetICMPID(packet.ICMPEchoID).\n\t\t\tSetICMPSequence(packet.ICMPEchoSeq)\n\tcase protocol.Type_TCP:\n\t\tif packet.IsIPv6 {\n\t\t\tpacketOutBuilder = packetOutBuilder.SetIPProtocol(binding.ProtocolTCPv6)\n\t\t} else {\n\t\t\tpacketOutBuilder = packetOutBuilder.SetIPProtocol(binding.ProtocolTCP)\n\t\t}\n\t\ttcpSrcPort := packet.SourcePort\n\t\tif tcpSrcPort == 0 {\n\t\t\t// #nosec G404: random number generator not used for security purposes.\n\t\t\ttcpSrcPort = uint16(rand.Uint32())\n\t\t}\n\t\tpacketOutBuilder = packetOutBuilder.SetTCPDstPort(packet.DestinationPort).\n\t\t\tSetTCPSrcPort(tcpSrcPort).\n\t\t\tSetTCPFlags(packet.TCPFlags)\n\tcase protocol.Type_UDP:\n\t\tif packet.IsIPv6 {\n\t\t\tpacketOutBuilder = packetOutBuilder.SetIPProtocol(binding.ProtocolUDPv6)\n\t\t} else {\n\t\t\tpacketOutBuilder = packetOutBuilder.SetIPProtocol(binding.ProtocolUDP)\n\t\t}\n\t\tpacketOutBuilder = packetOutBuilder.SetUDPDstPort(packet.DestinationPort).\n\t\t\tSetUDPSrcPort(packet.SourcePort)\n\tdefault:\n\t\tpacketOutBuilder = packetOutBuilder.SetIPProtocolValue(packet.IsIPv6, packet.IPProto)\n\t}\n\n\tpacketOutBuilder = packetOutBuilder.SetInport(inPort)\n\tif outPort != -1 {\n\t\tpacketOutBuilder = packetOutBuilder.SetOutport(uint32(outPort))\n\t}\n\tpacketOutBuilder = packetOutBuilder.AddLoadAction(binding.NxmFieldIPToS, uint64(dataplaneTag), traceflowTagToSRange)\n\n\tpacketOutObj := packetOutBuilder.Done()\n\treturn c.bridge.SendPacketOut(packetOutObj)\n}\n\nfunc (c *client) InstallTraceflowFlows(dataplaneTag uint8, liveTraffic, droppedOnly, receiverOnly bool, packet *binding.Packet, ofPort uint32, timeoutSeconds uint16) error {\n\tcacheKey := fmt.Sprintf(\"%x\", dataplaneTag)\n\tflows := []binding.Flow{}\n\tflows = append(flows, c.traceflowConnectionTrackFlows(dataplaneTag, receiverOnly, packet, ofPort, timeoutSeconds, cookie.Default)...)\n\tflows = append(flows, c.traceflowL2ForwardOutputFlows(dataplaneTag, liveTraffic, droppedOnly, timeoutSeconds, cookie.Default)...)\n\tflows = append(flows, c.traceflowNetworkPolicyFlows(dataplaneTag, timeoutSeconds, cookie.Default)...)\n\treturn c.addFlows(c.tfFlowCache, cacheKey, flows)\n}\n\nfunc (c *client) UninstallTraceflowFlows(dataplaneTag uint8) error {\n\tcacheKey := fmt.Sprintf(\"%x\", dataplaneTag)\n\treturn c.deleteFlows(c.tfFlowCache, cacheKey)\n}\n\n// Add TLV map optClass 0x0104, optType 0x80 optLength 4 tunMetadataIndex 0 to store data plane tag\n// in tunnel. Data plane tag will be stored to NXM_NX_TUN_METADATA0[28..31] when packet get encapsulated\n// into geneve, and will be stored back to NXM_NX_REG9[28..31] when packet get decapsulated.\nfunc (c *client) InitialTLVMap() error {\n\treturn c.bridge.AddTLVMap(0x0104, 0x80, 4, 0)\n}\n\nfunc (c *client) IsIPv4Enabled() bool {\n\treturn config.IsIPv4Enabled(c.nodeConfig, c.encapMode)\n}\n\nfunc (c *client) IsIPv6Enabled() bool {\n\treturn config.IsIPv6Enabled(c.nodeConfig, c.encapMode)\n}\n\n// setBasePacketOutBuilder sets base IP properties of a packetOutBuilder which can have more packet data added.\nfunc setBasePacketOutBuilder(packetOutBuilder binding.PacketOutBuilder, srcMAC string, dstMAC string, srcIP string, dstIP string, inPort uint32, outPort int32) (binding.PacketOutBuilder, error) {\n\t// Set ethernet header.\n\tparsedSrcMAC, err := net.ParseMAC(srcMAC)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tparsedDstMAC, err := net.ParseMAC(dstMAC)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tpacketOutBuilder = packetOutBuilder.SetSrcMAC(parsedSrcMAC)\n\tpacketOutBuilder = packetOutBuilder.SetDstMAC(parsedDstMAC)\n\n\t// Set IP header.\n\tparsedSrcIP := net.ParseIP(srcIP)\n\tparsedDstIP := net.ParseIP(dstIP)\n\tif parsedSrcIP == nil || parsedDstIP == nil {\n\t\treturn nil, fmt.Errorf(\"invalid IP\")\n\t}\n\tisIPv6 := parsedSrcIP.To4() == nil\n\tif isIPv6 != (parsedDstIP.To4() == nil) {\n\t\treturn nil, fmt.Errorf(\"IP version mismatch\")\n\t}\n\tpacketOutBuilder = packetOutBuilder.SetSrcIP(parsedSrcIP)\n\tpacketOutBuilder = packetOutBuilder.SetDstIP(parsedDstIP)\n\n\tpacketOutBuilder = packetOutBuilder.SetTTL(128)\n\n\tpacketOutBuilder = packetOutBuilder.SetInport(inPort)\n\tif outPort != -1 {\n\t\tpacketOutBuilder = packetOutBuilder.SetOutport(uint32(outPort))\n\t}\n\n\treturn packetOutBuilder, nil\n}\n\n// SendTCPReject generates TCP packet as a packet-out and sends it to OVS.\nfunc (c *client) SendTCPPacketOut(\n\tsrcMAC string,\n\tdstMAC string,\n\tsrcIP string,\n\tdstIP string,\n\tinPort uint32,\n\toutPort int32,\n\tisIPv6 bool,\n\ttcpSrcPort uint16,\n\ttcpDstPort uint16,\n\ttcpAckNum uint32,\n\ttcpFlag uint8,\n\tisReject bool) error {\n\t// Generate a base IP PacketOutBuilder.\n\tpacketOutBuilder, err := setBasePacketOutBuilder(c.bridge.BuildPacketOut(), srcMAC, dstMAC, srcIP, dstIP, inPort, outPort)\n\tif err != nil {\n\t\treturn err\n\t}\n\t// Set protocol.\n\tif isIPv6 {\n\t\tpacketOutBuilder = packetOutBuilder.SetIPProtocol(binding.ProtocolTCPv6)\n\t} else {\n\t\tpacketOutBuilder = packetOutBuilder.SetIPProtocol(binding.ProtocolTCP)\n\t}\n\t// Set TCP header data.\n\tpacketOutBuilder = packetOutBuilder.SetTCPSrcPort(tcpSrcPort)\n\tpacketOutBuilder = packetOutBuilder.SetTCPDstPort(tcpDstPort)\n\tpacketOutBuilder = packetOutBuilder.SetTCPAckNum(tcpAckNum)\n\tpacketOutBuilder = packetOutBuilder.SetTCPFlags(tcpFlag)\n\n\t// Reject response packet should bypass ConnTrack\n\tif isReject {\n\t\tname := fmt.Sprintf(\"%s%d\", binding.NxmFieldReg, marksReg)\n\t\tpacketOutBuilder = packetOutBuilder.AddLoadAction(name, uint64(CustomReasonReject), CustomReasonMarkRange)\n\t}\n\n\tpacketOutObj := packetOutBuilder.Done()\n\treturn c.bridge.SendPacketOut(packetOutObj)\n}\n\n// SendICMPReject generates ICMP packet as a packet-out and send it to OVS.\nfunc (c *client) SendICMPPacketOut(\n\tsrcMAC string,\n\tdstMAC string,\n\tsrcIP string,\n\tdstIP string,\n\tinPort uint32,\n\toutPort int32,\n\tisIPv6 bool,\n\ticmpType uint8,\n\ticmpCode uint8,\n\ticmpData []byte,\n\tisReject bool) error {\n\t// Generate a base IP PacketOutBuilder.\n\tpacketOutBuilder, err := setBasePacketOutBuilder(c.bridge.BuildPacketOut(), srcMAC, dstMAC, srcIP, dstIP, inPort, outPort)\n\tif err != nil {\n\t\treturn err\n\t}\n\t// Set protocol.\n\tif isIPv6 {\n\t\tpacketOutBuilder = packetOutBuilder.SetIPProtocol(binding.ProtocolICMPv6)\n\t} else {\n\t\tpacketOutBuilder = packetOutBuilder.SetIPProtocol(binding.ProtocolICMP)\n\t}\n\t// Set ICMP header data.\n\tpacketOutBuilder = packetOutBuilder.SetICMPType(icmpType)\n\tpacketOutBuilder = packetOutBuilder.SetICMPCode(icmpCode)\n\tpacketOutBuilder = packetOutBuilder.SetICMPData(icmpData)\n\n\t// Reject response packet should bypass ConnTrack\n\tif isReject {\n\t\tname := fmt.Sprintf(\"%s%d\", binding.NxmFieldReg, marksReg)\n\t\tpacketOutBuilder = packetOutBuilder.AddLoadAction(name, uint64(CustomReasonReject), CustomReasonMarkRange)\n\t}\n\n\tpacketOutObj := packetOutBuilder.Done()\n\treturn c.bridge.SendPacketOut(packetOutObj)\n}\n", "idx": 1, "id": 36209, "msg": "goimport format issue", "proj": "antrea-io-antrea", "lang": "go"}
{"patch": "@@ -1757,6 +1757,7 @@ class Booster(object):\n         ptr_string_buffer = ctypes.c_char_p(*[ctypes.addressof(string_buffer)])\n         _safe_call(_LIB.LGBM_BoosterSaveModelToString(\n             self.handle,\n+            ctypes.c_int(start_iteration),\n             ctypes.c_int(num_iteration),\n             ctypes.c_int64(buffer_len),\n             ctypes.byref(tmp_out_len),", "y": 0, "oldf": "# coding: utf-8\n# pylint: disable = invalid-name, C0111, C0301\n# pylint: disable = R0912, R0913, R0914, W0105, W0201, W0212\n\"\"\"Wrapper c_api of LightGBM\"\"\"\nfrom __future__ import absolute_import\n\nimport copy\nimport ctypes\nimport os\nimport warnings\nfrom tempfile import NamedTemporaryFile\n\nimport numpy as np\nimport scipy.sparse\n\nfrom .compat import (DataFrame, LGBMDeprecationWarning, Series,\n                     decode_string, integer_types,\n                     json, json_default_with_numpy,\n                     numeric_types, range_, string_type)\nfrom .libpath import find_lib_path\n\n\ndef _load_lib():\n    \"\"\"Load LightGBM Library.\"\"\"\n    lib_path = find_lib_path()\n    if len(lib_path) == 0:\n        return None\n    lib = ctypes.cdll.LoadLibrary(lib_path[0])\n    lib.LGBM_GetLastError.restype = ctypes.c_char_p\n    return lib\n\n\n_LIB = _load_lib()\n\n\nclass LightGBMError(Exception):\n    \"\"\"Error throwed by LightGBM\"\"\"\n    pass\n\n\ndef _safe_call(ret):\n    \"\"\"Check the return value of C API call\n    Parameters\n    ----------\n    ret : int\n        return value from API calls\n    \"\"\"\n    if ret != 0:\n        raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n\n\ndef is_numeric(obj):\n    \"\"\"Check is a number or not, include numpy number etc.\"\"\"\n    try:\n        float(obj)\n        return True\n    except (TypeError, ValueError):\n        # TypeError: obj is not a string or a number\n        # ValueError: invalid literal\n        return False\n\n\ndef is_numpy_1d_array(data):\n    \"\"\"Check is 1d numpy array\"\"\"\n    return isinstance(data, np.ndarray) and len(data.shape) == 1\n\n\ndef is_1d_list(data):\n    \"\"\"Check is 1d list\"\"\"\n    return isinstance(data, list) and \\\n        (not data or is_numeric(data[0]))\n\n\ndef list_to_1d_numpy(data, dtype=np.float32, name='list'):\n    \"\"\"convert to 1d numpy array\"\"\"\n    if is_numpy_1d_array(data):\n        if data.dtype == dtype:\n            return data\n        else:\n            return data.astype(dtype=dtype, copy=False)\n    elif is_1d_list(data):\n        return np.array(data, dtype=dtype, copy=False)\n    elif isinstance(data, Series):\n        return data.values.astype(dtype)\n    else:\n        raise TypeError(\"Wrong type({}) for {}, should be list or numpy array\".format(type(data).__name__, name))\n\n\ndef cfloat32_array_to_numpy(cptr, length):\n    \"\"\"Convert a ctypes float pointer array to a numpy array.\n    \"\"\"\n    if isinstance(cptr, ctypes.POINTER(ctypes.c_float)):\n        return np.fromiter(cptr, dtype=np.float32, count=length)\n    else:\n        raise RuntimeError('Expected float pointer')\n\n\ndef cfloat64_array_to_numpy(cptr, length):\n    \"\"\"Convert a ctypes double pointer array to a numpy array.\n    \"\"\"\n    if isinstance(cptr, ctypes.POINTER(ctypes.c_double)):\n        return np.fromiter(cptr, dtype=np.float64, count=length)\n    else:\n        raise RuntimeError('Expected double pointer')\n\n\ndef cint32_array_to_numpy(cptr, length):\n    \"\"\"Convert a ctypes float pointer array to a numpy array.\n    \"\"\"\n    if isinstance(cptr, ctypes.POINTER(ctypes.c_int32)):\n        return np.fromiter(cptr, dtype=np.int32, count=length)\n    else:\n        raise RuntimeError('Expected int pointer')\n\n\ndef c_str(string):\n    \"\"\"Convert a python string to cstring.\"\"\"\n    return ctypes.c_char_p(string.encode('utf-8'))\n\n\ndef c_array(ctype, values):\n    \"\"\"Convert a python array to c array.\"\"\"\n    return (ctype * len(values))(*values)\n\n\ndef param_dict_to_str(data):\n    if data is None or not data:\n        return \"\"\n    pairs = []\n    for key, val in data.items():\n        if isinstance(val, (list, tuple, set)) or is_numpy_1d_array(val):\n            pairs.append(str(key) + '=' + ','.join(map(str, val)))\n        elif isinstance(val, string_type) or isinstance(val, numeric_types) or is_numeric(val):\n            pairs.append(str(key) + '=' + str(val))\n        elif val is not None:\n            raise TypeError('Unknown type of parameter:%s, got:%s'\n                            % (key, type(val).__name__))\n    return ' '.join(pairs)\n\n\nclass _temp_file(object):\n    def __enter__(self):\n        with NamedTemporaryFile(prefix=\"lightgbm_tmp_\", delete=True) as f:\n            self.name = f.name\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        if os.path.isfile(self.name):\n            os.remove(self.name)\n\n    def readlines(self):\n        with open(self.name, \"r+\") as f:\n            ret = f.readlines()\n        return ret\n\n    def writelines(self, lines):\n        with open(self.name, \"w+\") as f:\n            f.writelines(lines)\n\n\n\"\"\"marco definition of data type in c_api of LightGBM\"\"\"\nC_API_DTYPE_FLOAT32 = 0\nC_API_DTYPE_FLOAT64 = 1\nC_API_DTYPE_INT32 = 2\nC_API_DTYPE_INT64 = 3\n\n\"\"\"Matric is row major in python\"\"\"\nC_API_IS_ROW_MAJOR = 1\n\n\"\"\"marco definition of prediction type in c_api of LightGBM\"\"\"\nC_API_PREDICT_NORMAL = 0\nC_API_PREDICT_RAW_SCORE = 1\nC_API_PREDICT_LEAF_INDEX = 2\nC_API_PREDICT_CONTRIB = 3\n\n\"\"\"data type of data field\"\"\"\nFIELD_TYPE_MAPPER = {\"label\": C_API_DTYPE_FLOAT32,\n                     \"weight\": C_API_DTYPE_FLOAT32,\n                     \"init_score\": C_API_DTYPE_FLOAT64,\n                     \"group\": C_API_DTYPE_INT32}\n\n\ndef convert_from_sliced_object(data):\n    \"\"\"fix the memory of multi-dimensional sliced object\"\"\"\n    if data.base is not None and isinstance(data, np.ndarray) and isinstance(data.base, np.ndarray):\n        if not data.flags.c_contiguous:\n            warnings.warn(\"Usage subset(sliced data) of np.ndarray is not recommended due to it will double the peak memory cost in LightGBM.\")\n            return np.copy(data)\n    return data\n\n\ndef c_float_array(data):\n    \"\"\"get pointer of float numpy array / list\"\"\"\n    if is_1d_list(data):\n        data = np.array(data, copy=False)\n    if is_numpy_1d_array(data):\n        data = convert_from_sliced_object(data)\n        assert data.flags.c_contiguous\n        if data.dtype == np.float32:\n            ptr_data = data.ctypes.data_as(ctypes.POINTER(ctypes.c_float))\n            type_data = C_API_DTYPE_FLOAT32\n        elif data.dtype == np.float64:\n            ptr_data = data.ctypes.data_as(ctypes.POINTER(ctypes.c_double))\n            type_data = C_API_DTYPE_FLOAT64\n        else:\n            raise TypeError(\"Expected np.float32 or np.float64, met type({})\"\n                            .format(data.dtype))\n    else:\n        raise TypeError(\"Unknown type({})\".format(type(data).__name__))\n    return (ptr_data, type_data, data)  # return `data` to avoid the temporary copy is freed\n\n\ndef c_int_array(data):\n    \"\"\"get pointer of int numpy array / list\"\"\"\n    if is_1d_list(data):\n        data = np.array(data, copy=False)\n    if is_numpy_1d_array(data):\n        data = convert_from_sliced_object(data)\n        assert data.flags.c_contiguous\n        if data.dtype == np.int32:\n            ptr_data = data.ctypes.data_as(ctypes.POINTER(ctypes.c_int32))\n            type_data = C_API_DTYPE_INT32\n        elif data.dtype == np.int64:\n            ptr_data = data.ctypes.data_as(ctypes.POINTER(ctypes.c_int64))\n            type_data = C_API_DTYPE_INT64\n        else:\n            raise TypeError(\"Expected np.int32 or np.int64, met type({})\"\n                            .format(data.dtype))\n    else:\n        raise TypeError(\"Unknown type({})\".format(type(data).__name__))\n    return (ptr_data, type_data, data)  # return `data` to avoid the temporary copy is freed\n\n\nPANDAS_DTYPE_MAPPER = {'int8': 'int', 'int16': 'int', 'int32': 'int',\n                       'int64': 'int', 'uint8': 'int', 'uint16': 'int',\n                       'uint32': 'int', 'uint64': 'int', 'float16': 'float',\n                       'float32': 'float', 'float64': 'float', 'bool': 'int'}\n\n\ndef _data_from_pandas(data, feature_name, categorical_feature, pandas_categorical):\n    if isinstance(data, DataFrame):\n        if len(data.shape) != 2 or data.shape[0] < 1:\n            raise ValueError('Input data must be 2 dimensional and non empty.')\n        if feature_name == 'auto' or feature_name is None:\n            data = data.rename(columns=str)\n        cat_cols = data.select_dtypes(include=['category']).columns\n        if pandas_categorical is None:  # train dataset\n            pandas_categorical = [list(data[col].cat.categories) for col in cat_cols]\n        else:\n            if len(cat_cols) != len(pandas_categorical):\n                raise ValueError('train and valid dataset categorical_feature do not match.')\n            for col, category in zip(cat_cols, pandas_categorical):\n                if list(data[col].cat.categories) != list(category):\n                    data[col] = data[col].cat.set_categories(category)\n        if len(cat_cols):  # cat_cols is pandas Index object\n            data = data.copy()  # not alter origin DataFrame\n            data[cat_cols] = data[cat_cols].apply(lambda x: x.cat.codes).replace({-1: np.nan})\n        if categorical_feature is not None:\n            if feature_name is None:\n                feature_name = list(data.columns)\n            if categorical_feature == 'auto':\n                categorical_feature = list(cat_cols)\n            else:\n                categorical_feature = list(categorical_feature) + list(cat_cols)\n        if feature_name == 'auto':\n            feature_name = list(data.columns)\n        data_dtypes = data.dtypes\n        if not all(dtype.name in PANDAS_DTYPE_MAPPER for dtype in data_dtypes):\n            bad_fields = [data.columns[i] for i, dtype in\n                          enumerate(data_dtypes) if dtype.name not in PANDAS_DTYPE_MAPPER]\n\n            msg = \"\"\"DataFrame.dtypes for data must be int, float or bool. Did not expect the data types in fields \"\"\"\n            raise ValueError(msg + ', '.join(bad_fields))\n        data = data.values.astype('float')\n    else:\n        if feature_name == 'auto':\n            feature_name = None\n        if categorical_feature == 'auto':\n            categorical_feature = None\n    return data, feature_name, categorical_feature, pandas_categorical\n\n\ndef _label_from_pandas(label):\n    if isinstance(label, DataFrame):\n        if len(label.columns) > 1:\n            raise ValueError('DataFrame for label cannot have multiple columns')\n        label_dtypes = label.dtypes\n        if not all(dtype.name in PANDAS_DTYPE_MAPPER for dtype in label_dtypes):\n            raise ValueError('DataFrame.dtypes for label must be int, float or bool')\n        label = label.values.astype('float')\n    return label\n\n\ndef _save_pandas_categorical(file_name, pandas_categorical):\n    with open(file_name, 'a') as f:\n        f.write('\\npandas_categorical:' + json.dumps(pandas_categorical, default=json_default_with_numpy) + '\\n')\n\n\ndef _load_pandas_categorical(file_name):\n    with open(file_name, 'r') as f:\n        lines = f.readlines()\n        last_line = lines[-1]\n        if last_line.strip() == \"\":\n            last_line = lines[-2]\n        if last_line.startswith('pandas_categorical:'):\n            return json.loads(last_line[len('pandas_categorical:'):])\n    return None\n\n\nclass _InnerPredictor(object):\n    \"\"\"\n    A _InnerPredictor of LightGBM.\n    Only used for prediction, usually used for continued-train\n    Note: Can convert from Booster, but cannot convert to Booster\n    \"\"\"\n    def __init__(self, model_file=None, booster_handle=None, pred_parameter=None):\n        \"\"\"Initialize the _InnerPredictor. Not expose to user\n\n        Parameters\n        ----------\n        model_file : string\n            Path to the model file.\n        booster_handle : Handle of Booster\n            use handle to init\n        pred_parameter: dict\n            Other parameters for the prediciton\n        \"\"\"\n        self.handle = ctypes.c_void_p()\n        self.__is_manage_handle = True\n        if model_file is not None:\n            \"\"\"Prediction task\"\"\"\n            out_num_iterations = ctypes.c_int(0)\n            _safe_call(_LIB.LGBM_BoosterCreateFromModelfile(\n                c_str(model_file),\n                ctypes.byref(out_num_iterations),\n                ctypes.byref(self.handle)))\n            out_num_class = ctypes.c_int(0)\n            _safe_call(_LIB.LGBM_BoosterGetNumClasses(\n                self.handle,\n                ctypes.byref(out_num_class)))\n            self.num_class = out_num_class.value\n            self.num_total_iteration = out_num_iterations.value\n            self.pandas_categorical = _load_pandas_categorical(model_file)\n        elif booster_handle is not None:\n            self.__is_manage_handle = False\n            self.handle = booster_handle\n            out_num_class = ctypes.c_int(0)\n            _safe_call(_LIB.LGBM_BoosterGetNumClasses(\n                self.handle,\n                ctypes.byref(out_num_class)))\n            self.num_class = out_num_class.value\n            out_num_iterations = ctypes.c_int(0)\n            _safe_call(_LIB.LGBM_BoosterGetCurrentIteration(\n                self.handle,\n                ctypes.byref(out_num_iterations)))\n            self.num_total_iteration = out_num_iterations.value\n            self.pandas_categorical = None\n        else:\n            raise TypeError('Need Model file or Booster handle to create a predictor')\n\n        pred_parameter = {} if pred_parameter is None else pred_parameter\n        self.pred_parameter = param_dict_to_str(pred_parameter)\n\n    def __del__(self):\n        try:\n            if self.__is_manage_handle:\n                _safe_call(_LIB.LGBM_BoosterFree(self.handle))\n        except AttributeError:\n            pass\n\n    def __getstate__(self):\n        this = self.__dict__.copy()\n        this.pop('handle', None)\n        return this\n\n    def predict(self, data, num_iteration=-1,\n                raw_score=False, pred_leaf=False, pred_contrib=False, data_has_header=False,\n                is_reshape=True):\n        \"\"\"\n        Predict logic\n\n        Parameters\n        ----------\n        data : string/numpy array/scipy.sparse\n            Data source for prediction\n            When data type is string, it represents the path of txt file\n        num_iteration : int\n            Used iteration for prediction\n        raw_score : bool\n            True for predict raw score\n        pred_leaf : bool\n            True for predict leaf index\n        pred_contrib : bool\n            True for predict feature contributions\n        data_has_header : bool\n            Used for txt data, True if txt data has header\n        is_reshape : bool\n            Reshape to (nrow, ncol) if true\n\n        Returns\n        -------\n        Prediction result\n        \"\"\"\n        if isinstance(data, Dataset):\n            raise TypeError(\"Cannot use Dataset instance for prediction, please use raw data instead\")\n        data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n        predict_type = C_API_PREDICT_NORMAL\n        if raw_score:\n            predict_type = C_API_PREDICT_RAW_SCORE\n        if pred_leaf:\n            predict_type = C_API_PREDICT_LEAF_INDEX\n        if pred_contrib:\n            predict_type = C_API_PREDICT_CONTRIB\n        int_data_has_header = 1 if data_has_header else 0\n        if num_iteration > self.num_total_iteration:\n            num_iteration = self.num_total_iteration\n\n        if isinstance(data, string_type):\n            with _temp_file() as f:\n                _safe_call(_LIB.LGBM_BoosterPredictForFile(\n                    self.handle,\n                    c_str(data),\n                    ctypes.c_int(int_data_has_header),\n                    ctypes.c_int(predict_type),\n                    ctypes.c_int(num_iteration),\n                    c_str(self.pred_parameter),\n                    c_str(f.name)))\n                lines = f.readlines()\n                nrow = len(lines)\n                preds = [float(token) for line in lines for token in line.split('\\t')]\n                preds = np.array(preds, dtype=np.float64, copy=False)\n        elif isinstance(data, scipy.sparse.csr_matrix):\n            preds, nrow = self.__pred_for_csr(data, num_iteration,\n                                              predict_type)\n        elif isinstance(data, scipy.sparse.csc_matrix):\n            preds, nrow = self.__pred_for_csc(data, num_iteration,\n                                              predict_type)\n        elif isinstance(data, np.ndarray):\n            preds, nrow = self.__pred_for_np2d(data, num_iteration,\n                                               predict_type)\n        elif isinstance(data, list):\n            try:\n                data = np.array(data)\n            except BaseException:\n                raise ValueError('Cannot convert data list to numpy array.')\n            preds, nrow = self.__pred_for_np2d(data, num_iteration,\n                                               predict_type)\n        else:\n            try:\n                warnings.warn('Converting data to scipy sparse matrix.')\n                csr = scipy.sparse.csr_matrix(data)\n            except BaseException:\n                raise TypeError('Cannot predict data for type {}'.format(type(data).__name__))\n            preds, nrow = self.__pred_for_csr(csr, num_iteration,\n                                              predict_type)\n        if pred_leaf:\n            preds = preds.astype(np.int32)\n        if is_reshape and preds.size != nrow:\n            if preds.size % nrow == 0:\n                preds = preds.reshape(nrow, -1)\n            else:\n                raise ValueError('Length of predict result (%d) cannot be divide nrow (%d)'\n                                 % (preds.size, nrow))\n        return preds\n\n    def __get_num_preds(self, num_iteration, nrow, predict_type):\n        \"\"\"\n        Get size of prediction result\n        \"\"\"\n        n_preds = ctypes.c_int64(0)\n        _safe_call(_LIB.LGBM_BoosterCalcNumPredict(\n            self.handle,\n            ctypes.c_int(nrow),\n            ctypes.c_int(predict_type),\n            ctypes.c_int(num_iteration),\n            ctypes.byref(n_preds)))\n        return n_preds.value\n\n    def __pred_for_np2d(self, mat, num_iteration, predict_type):\n        \"\"\"\n        Predict for a 2-D numpy matrix.\n        \"\"\"\n        if len(mat.shape) != 2:\n            raise ValueError('Input numpy.ndarray or list must be 2 dimensional')\n\n        if mat.dtype == np.float32 or mat.dtype == np.float64:\n            data = np.array(mat.reshape(mat.size), dtype=mat.dtype, copy=False)\n        else:\n            \"\"\"change non-float data to float data, need to copy\"\"\"\n            data = np.array(mat.reshape(mat.size), dtype=np.float32)\n        ptr_data, type_ptr_data, _ = c_float_array(data)\n        n_preds = self.__get_num_preds(num_iteration, mat.shape[0],\n                                       predict_type)\n        preds = np.zeros(n_preds, dtype=np.float64)\n        out_num_preds = ctypes.c_int64(0)\n        _safe_call(_LIB.LGBM_BoosterPredictForMat(\n            self.handle,\n            ptr_data,\n            ctypes.c_int(type_ptr_data),\n            ctypes.c_int(mat.shape[0]),\n            ctypes.c_int(mat.shape[1]),\n            ctypes.c_int(C_API_IS_ROW_MAJOR),\n            ctypes.c_int(predict_type),\n            ctypes.c_int(num_iteration),\n            c_str(self.pred_parameter),\n            ctypes.byref(out_num_preds),\n            preds.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n        if n_preds != out_num_preds.value:\n            raise ValueError(\"Wrong length for predict results\")\n        return preds, mat.shape[0]\n\n    def __pred_for_csr(self, csr, num_iteration, predict_type):\n        \"\"\"\n        Predict for a csr data\n        \"\"\"\n        nrow = len(csr.indptr) - 1\n        n_preds = self.__get_num_preds(num_iteration, nrow, predict_type)\n        preds = np.zeros(n_preds, dtype=np.float64)\n        out_num_preds = ctypes.c_int64(0)\n\n        ptr_indptr, type_ptr_indptr, __ = c_int_array(csr.indptr)\n        ptr_data, type_ptr_data, _ = c_float_array(csr.data)\n\n        _safe_call(_LIB.LGBM_BoosterPredictForCSR(\n            self.handle,\n            ptr_indptr,\n            ctypes.c_int32(type_ptr_indptr),\n            csr.indices.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),\n            ptr_data,\n            ctypes.c_int(type_ptr_data),\n            ctypes.c_int64(len(csr.indptr)),\n            ctypes.c_int64(len(csr.data)),\n            ctypes.c_int64(csr.shape[1]),\n            ctypes.c_int(predict_type),\n            ctypes.c_int(num_iteration),\n            c_str(self.pred_parameter),\n            ctypes.byref(out_num_preds),\n            preds.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n        if n_preds != out_num_preds.value:\n            raise ValueError(\"Wrong length for predict results\")\n        return preds, nrow\n\n    def __pred_for_csc(self, csc, num_iteration, predict_type):\n        \"\"\"\n        Predict for a csc data\n        \"\"\"\n        nrow = csc.shape[0]\n        n_preds = self.__get_num_preds(num_iteration, nrow, predict_type)\n        preds = np.zeros(n_preds, dtype=np.float64)\n        out_num_preds = ctypes.c_int64(0)\n\n        ptr_indptr, type_ptr_indptr, __ = c_int_array(csc.indptr)\n        ptr_data, type_ptr_data, _ = c_float_array(csc.data)\n\n        _safe_call(_LIB.LGBM_BoosterPredictForCSC(\n            self.handle,\n            ptr_indptr,\n            ctypes.c_int32(type_ptr_indptr),\n            csc.indices.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),\n            ptr_data,\n            ctypes.c_int(type_ptr_data),\n            ctypes.c_int64(len(csc.indptr)),\n            ctypes.c_int64(len(csc.data)),\n            ctypes.c_int64(csc.shape[0]),\n            ctypes.c_int(predict_type),\n            ctypes.c_int(num_iteration),\n            c_str(self.pred_parameter),\n            ctypes.byref(out_num_preds),\n            preds.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n        if n_preds != out_num_preds.value:\n            raise ValueError(\"Wrong length for predict results\")\n        return preds, nrow\n\n\nclass Dataset(object):\n    \"\"\"Dataset in LightGBM.\"\"\"\n    def __init__(self, data, label=None, reference=None,\n                 weight=None, group=None, init_score=None, silent=False,\n                 feature_name='auto', categorical_feature='auto', params=None,\n                 free_raw_data=True):\n        \"\"\"Constract Dataset.\n\n        Parameters\n        ----------\n        data : string, numpy array, scipy.sparse or list of numpy arrays\n            Data source of Dataset.\n            If string, it represents the path to txt file.\n        label : list, numpy 1-D array or None, optional (default=None)\n            Label of the data.\n        reference : Dataset or None, optional (default=None)\n            If this is Dataset for validation, training data should be used as reference.\n        weight : list, numpy 1-D array or None, optional (default=None)\n            Weight for each instance.\n        group : list, numpy 1-D array or None, optional (default=None)\n            Group/query size for Dataset.\n        init_score : list, numpy 1-D array or None, optional (default=None)\n            Init score for Dataset.\n        silent : bool, optional (default=False)\n            Whether to print messages during construction.\n        feature_name : list of strings or 'auto', optional (default=\"auto\")\n            Feature names.\n            If 'auto' and data is pandas DataFrame, data columns names are used.\n        categorical_feature : list of strings or int, or 'auto', optional (default=\"auto\")\n            Categorical features.\n            If list of int, interpreted as indices.\n            If list of strings, interpreted as feature names (need to specify ``feature_name`` as well).\n            If 'auto' and data is pandas DataFrame, pandas categorical columns are used.\n            All values should be less than int32 max value (2147483647).\n        params: dict or None, optional (default=None)\n            Other parameters.\n        free_raw_data: bool, optional (default=True)\n            If True, raw data is freed after constructing inner Dataset.\n        \"\"\"\n        self.handle = None\n        self.data = data\n        self.label = label\n        self.reference = reference\n        self.weight = weight\n        self.group = group\n        self.init_score = init_score\n        self.silent = silent\n        self.feature_name = feature_name\n        self.categorical_feature = categorical_feature\n        self.params = copy.deepcopy(params)\n        self.free_raw_data = free_raw_data\n        self.used_indices = None\n        self._predictor = None\n        self.pandas_categorical = None\n        self.params_back_up = None\n\n    def __del__(self):\n        try:\n            self._free_handle()\n        except AttributeError:\n            pass\n\n    def _free_handle(self):\n        if self.handle is not None:\n            _safe_call(_LIB.LGBM_DatasetFree(self.handle))\n            self.handle = None\n\n    def _lazy_init(self, data, label=None, reference=None,\n                   weight=None, group=None, init_score=None, predictor=None,\n                   silent=False, feature_name='auto',\n                   categorical_feature='auto', params=None):\n        if data is None:\n            self.handle = None\n            return\n        if reference is not None:\n            self.pandas_categorical = reference.pandas_categorical\n            categorical_feature = reference.categorical_feature\n        data, feature_name, categorical_feature, self.pandas_categorical = _data_from_pandas(data, feature_name, categorical_feature, self.pandas_categorical)\n        label = _label_from_pandas(label)\n        self.data_has_header = False\n        # process for args\n        params = {} if params is None else params\n        args_names = getattr(self.__class__, '_lazy_init').__code__.co_varnames[:getattr(self.__class__, '_lazy_init').__code__.co_argcount]\n        for key, _ in params.items():\n            if key in args_names:\n                warnings.warn('{0} keyword has been found in `params` and will be ignored. '\n                              'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n        self.predictor = predictor\n        if silent:\n            params[\"verbose\"] = 0\n        # get categorical features\n        if categorical_feature is not None:\n            categorical_indices = set()\n            feature_dict = {}\n            if feature_name is not None:\n                feature_dict = {name: i for i, name in enumerate(feature_name)}\n            for name in categorical_feature:\n                if isinstance(name, string_type) and name in feature_dict:\n                    categorical_indices.add(feature_dict[name])\n                elif isinstance(name, integer_types):\n                    categorical_indices.add(name)\n                else:\n                    raise TypeError(\"Wrong type({}) or unknown name({}) in categorical_feature\"\n                                    .format(type(name).__name__, name))\n            if categorical_indices:\n                if \"categorical_feature\" in params or \"categorical_column\" in params:\n                    warnings.warn('categorical_feature in param dict is overridden.')\n                    params.pop(\"categorical_feature\", None)\n                    params.pop(\"categorical_column\", None)\n                params['categorical_column'] = sorted(categorical_indices)\n\n        params_str = param_dict_to_str(params)\n        # process for reference dataset\n        ref_dataset = None\n        if isinstance(reference, Dataset):\n            ref_dataset = reference.construct().handle\n        elif reference is not None:\n            raise TypeError('Reference dataset should be None or dataset instance')\n        # start construct data\n        if isinstance(data, string_type):\n            # check data has header or not\n            if str(params.get(\"has_header\", \"\")).lower() == \"true\" \\\n                    or str(params.get(\"header\", \"\")).lower() == \"true\":\n                self.data_has_header = True\n            self.handle = ctypes.c_void_p()\n            _safe_call(_LIB.LGBM_DatasetCreateFromFile(\n                c_str(data),\n                c_str(params_str),\n                ref_dataset,\n                ctypes.byref(self.handle)))\n        elif isinstance(data, scipy.sparse.csr_matrix):\n            self.__init_from_csr(data, params_str, ref_dataset)\n        elif isinstance(data, scipy.sparse.csc_matrix):\n            self.__init_from_csc(data, params_str, ref_dataset)\n        elif isinstance(data, np.ndarray):\n            self.__init_from_np2d(data, params_str, ref_dataset)\n        elif isinstance(data, list) and len(data) > 0 and all(isinstance(x, np.ndarray) for x in data):\n            self.__init_from_list_np2d(data, params_str, ref_dataset)\n        else:\n            try:\n                csr = scipy.sparse.csr_matrix(data)\n                self.__init_from_csr(csr, params_str, ref_dataset)\n            except BaseException:\n                raise TypeError('Cannot initialize Dataset from {}'.format(type(data).__name__))\n        if label is not None:\n            self.set_label(label)\n        if self.get_label() is None:\n            raise ValueError(\"Label should not be None\")\n        if weight is not None:\n            self.set_weight(weight)\n        if group is not None:\n            self.set_group(group)\n        # load init score\n        if init_score is not None:\n            self.set_init_score(init_score)\n            if self.predictor is not None:\n                warnings.warn(\"The prediction of init_model will be overridden by init_score.\")\n        elif isinstance(self.predictor, _InnerPredictor):\n            init_score = self.predictor.predict(data,\n                                                raw_score=True,\n                                                data_has_header=self.data_has_header,\n                                                is_reshape=False)\n            if self.predictor.num_class > 1:\n                # need re group init score\n                new_init_score = np.zeros(init_score.size, dtype=np.float32)\n                num_data = self.num_data()\n                for i in range_(num_data):\n                    for j in range_(self.predictor.num_class):\n                        new_init_score[j * num_data + i] = init_score[i * self.predictor.num_class + j]\n                init_score = new_init_score\n            self.set_init_score(init_score)\n        elif self.predictor is not None:\n            raise TypeError('wrong predictor type {}'.format(type(self.predictor).__name__))\n        # set feature names\n        self.set_feature_name(feature_name)\n\n    def __init_from_np2d(self, mat, params_str, ref_dataset):\n        \"\"\"\n        Initialize data from a 2-D numpy matrix.\n        \"\"\"\n        if len(mat.shape) != 2:\n            raise ValueError('Input numpy.ndarray must be 2 dimensional')\n\n        self.handle = ctypes.c_void_p()\n        if mat.dtype == np.float32 or mat.dtype == np.float64:\n            data = np.array(mat.reshape(mat.size), dtype=mat.dtype, copy=False)\n        else:\n            # change non-float data to float data, need to copy\n            data = np.array(mat.reshape(mat.size), dtype=np.float32)\n\n        ptr_data, type_ptr_data, _ = c_float_array(data)\n        _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n            ptr_data,\n            ctypes.c_int(type_ptr_data),\n            ctypes.c_int(mat.shape[0]),\n            ctypes.c_int(mat.shape[1]),\n            ctypes.c_int(C_API_IS_ROW_MAJOR),\n            c_str(params_str),\n            ref_dataset,\n            ctypes.byref(self.handle)))\n\n    def __init_from_list_np2d(self, mats, params_str, ref_dataset):\n        \"\"\"\n        Initialize data from list of 2-D numpy matrices.\n        \"\"\"\n        ncol = mats[0].shape[1]\n        nrow = np.zeros((len(mats),), np.int32)\n        if mats[0].dtype == np.float64:\n            ptr_data = (ctypes.POINTER(ctypes.c_double) * len(mats))()\n        else:\n            ptr_data = (ctypes.POINTER(ctypes.c_float) * len(mats))()\n\n        holders = []\n        type_ptr_data = None\n\n        for i, mat in enumerate(mats):\n            if len(mat.shape) != 2:\n                raise ValueError('Input numpy.ndarray must be 2 dimensional')\n\n            if mat.shape[1] != ncol:\n                raise ValueError('Input arrays must have same number of columns')\n\n            nrow[i] = mat.shape[0]\n\n            if mat.dtype == np.float32 or mat.dtype == np.float64:\n                mats[i] = np.array(mat.reshape(mat.size), dtype=mat.dtype, copy=False)\n            else:\n                # change non-float data to float data, need to copy\n                mats[i] = np.array(mat.reshape(mat.size), dtype=np.float32)\n\n            chunk_ptr_data, chunk_type_ptr_data, holder = c_float_array(mats[i])\n            if type_ptr_data is not None and chunk_type_ptr_data != type_ptr_data:\n                raise ValueError('Input chunks must have same type')\n            ptr_data[i] = chunk_ptr_data\n            type_ptr_data = chunk_type_ptr_data\n            holders.append(holder)\n\n        self.handle = ctypes.c_void_p()\n        _safe_call(_LIB.LGBM_DatasetCreateFromMats(\n            ctypes.c_int(len(mats)),\n            ctypes.cast(ptr_data, ctypes.POINTER(ctypes.POINTER(ctypes.c_double))),\n            ctypes.c_int(type_ptr_data),\n            nrow.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),\n            ctypes.c_int(ncol),\n            ctypes.c_int(C_API_IS_ROW_MAJOR),\n            c_str(params_str),\n            ref_dataset,\n            ctypes.byref(self.handle)))\n\n    def __init_from_csr(self, csr, params_str, ref_dataset):\n        \"\"\"\n        Initialize data from a CSR matrix.\n        \"\"\"\n        if len(csr.indices) != len(csr.data):\n            raise ValueError('Length mismatch: {} vs {}'.format(len(csr.indices), len(csr.data)))\n        self.handle = ctypes.c_void_p()\n\n        ptr_indptr, type_ptr_indptr, __ = c_int_array(csr.indptr)\n        ptr_data, type_ptr_data, _ = c_float_array(csr.data)\n\n        _safe_call(_LIB.LGBM_DatasetCreateFromCSR(\n            ptr_indptr,\n            ctypes.c_int(type_ptr_indptr),\n            csr.indices.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),\n            ptr_data,\n            ctypes.c_int(type_ptr_data),\n            ctypes.c_int64(len(csr.indptr)),\n            ctypes.c_int64(len(csr.data)),\n            ctypes.c_int64(csr.shape[1]),\n            c_str(params_str),\n            ref_dataset,\n            ctypes.byref(self.handle)))\n\n    def __init_from_csc(self, csc, params_str, ref_dataset):\n        \"\"\"\n        Initialize data from a csc matrix.\n        \"\"\"\n        if len(csc.indices) != len(csc.data):\n            raise ValueError('Length mismatch: {} vs {}'.format(len(csc.indices), len(csc.data)))\n        self.handle = ctypes.c_void_p()\n\n        ptr_indptr, type_ptr_indptr, __ = c_int_array(csc.indptr)\n        ptr_data, type_ptr_data, _ = c_float_array(csc.data)\n\n        _safe_call(_LIB.LGBM_DatasetCreateFromCSC(\n            ptr_indptr,\n            ctypes.c_int(type_ptr_indptr),\n            csc.indices.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),\n            ptr_data,\n            ctypes.c_int(type_ptr_data),\n            ctypes.c_int64(len(csc.indptr)),\n            ctypes.c_int64(len(csc.data)),\n            ctypes.c_int64(csc.shape[0]),\n            c_str(params_str),\n            ref_dataset,\n            ctypes.byref(self.handle)))\n\n    def construct(self):\n        \"\"\"Lazy init.\n\n        Returns\n        -------\n        self : Dataset\n            Returns self.\n        \"\"\"\n        if self.handle is None:\n            if self.reference is not None:\n                if self.used_indices is None:\n                    # create valid\n                    self._lazy_init(self.data, label=self.label, reference=self.reference,\n                                    weight=self.weight, group=self.group, init_score=self.init_score, predictor=self._predictor,\n                                    silent=self.silent, feature_name=self.feature_name, params=self.params)\n                else:\n                    # construct subset\n                    used_indices = list_to_1d_numpy(self.used_indices, np.int32, name='used_indices')\n                    assert used_indices.flags.c_contiguous\n                    self.handle = ctypes.c_void_p()\n                    params_str = param_dict_to_str(self.params)\n                    _safe_call(_LIB.LGBM_DatasetGetSubset(\n                        self.reference.construct().handle,\n                        used_indices.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),\n                        ctypes.c_int(used_indices.shape[0]),\n                        c_str(params_str),\n                        ctypes.byref(self.handle)))\n                    if self.get_label() is None:\n                        raise ValueError(\"Label should not be None.\")\n            else:\n                # create train\n                self._lazy_init(self.data, label=self.label,\n                                weight=self.weight, group=self.group, init_score=self.init_score,\n                                predictor=self._predictor, silent=self.silent, feature_name=self.feature_name,\n                                categorical_feature=self.categorical_feature, params=self.params)\n            if self.free_raw_data:\n                self.data = None\n        return self\n\n    def create_valid(self, data, label=None, weight=None, group=None,\n                     init_score=None, silent=False, params=None):\n        \"\"\"Create validation data align with current Dataset.\n\n        Parameters\n        ----------\n        data : string, numpy array or scipy.sparse\n            Data source of Dataset.\n            If string, it represents the path to txt file.\n        label : list or numpy 1-D array, optional (default=None)\n            Label of the training data.\n        weight : list, numpy 1-D array or None, optional (default=None)\n            Weight for each instance.\n        group : list, numpy 1-D array or None, optional (default=None)\n            Group/query size for Dataset.\n        init_score : list, numpy 1-D array or None, optional (default=None)\n            Init score for Dataset.\n        silent : bool, optional (default=False)\n            Whether to print messages during construction.\n        params: dict or None, optional (default=None)\n            Other parameters.\n\n        Returns\n        -------\n        self : Dataset\n            Returns self.\n        \"\"\"\n        ret = Dataset(data, label=label, reference=self,\n                      weight=weight, group=group, init_score=init_score,\n                      silent=silent, params=params, free_raw_data=self.free_raw_data)\n        ret._predictor = self._predictor\n        ret.pandas_categorical = self.pandas_categorical\n        return ret\n\n    def subset(self, used_indices, params=None):\n        \"\"\"Get subset of current Dataset.\n\n        Parameters\n        ----------\n        used_indices : list of int\n            Indices used to create the subset.\n        params: dict or None, optional (default=None)\n            Other parameters.\n\n        Returns\n        -------\n        subset : Dataset\n            Subset of the current Dataset.\n        \"\"\"\n        if params is None:\n            params = self.params\n        ret = Dataset(None, reference=self, feature_name=self.feature_name,\n                      categorical_feature=self.categorical_feature, params=params)\n        ret._predictor = self._predictor\n        ret.pandas_categorical = self.pandas_categorical\n        ret.used_indices = used_indices\n        return ret\n\n    def save_binary(self, filename):\n        \"\"\"Save Dataset to binary file.\n\n        Parameters\n        ----------\n        filename : string\n            Name of the output file.\n        \"\"\"\n        _safe_call(_LIB.LGBM_DatasetSaveBinary(\n            self.construct().handle,\n            c_str(filename)))\n\n    def _update_params(self, params):\n        if not self.params:\n            self.params = params\n        else:\n            self.params_back_up = copy.deepcopy(self.params)\n            self.params.update(params)\n\n    def _reverse_update_params(self):\n        self.params = copy.deepcopy(self.params_back_up)\n        self.params_back_up = None\n\n    def set_field(self, field_name, data):\n        \"\"\"Set property into the Dataset.\n\n        Parameters\n        ----------\n        field_name: string\n            The field name of the information.\n        data: list, numpy array or None\n            The array of data to be set.\n        \"\"\"\n        if self.handle is None:\n            raise Exception(\"Cannot set %s before construct dataset\" % field_name)\n        if data is None:\n            # set to None\n            _safe_call(_LIB.LGBM_DatasetSetField(\n                self.handle,\n                c_str(field_name),\n                None,\n                ctypes.c_int(0),\n                ctypes.c_int(FIELD_TYPE_MAPPER[field_name])))\n            return\n        dtype = np.float32\n        if field_name == 'group':\n            dtype = np.int32\n        elif field_name == 'init_score':\n            dtype = np.float64\n        data = list_to_1d_numpy(data, dtype, name=field_name)\n        if data.dtype == np.float32 or data.dtype == np.float64:\n            ptr_data, type_data, _ = c_float_array(data)\n        elif data.dtype == np.int32:\n            ptr_data, type_data, _ = c_int_array(data)\n        else:\n            raise TypeError(\"Excepted np.float32/64 or np.int32, meet type({})\".format(data.dtype))\n        if type_data != FIELD_TYPE_MAPPER[field_name]:\n            raise TypeError(\"Input type error for set_field\")\n        _safe_call(_LIB.LGBM_DatasetSetField(\n            self.handle,\n            c_str(field_name),\n            ptr_data,\n            ctypes.c_int(len(data)),\n            ctypes.c_int(type_data)))\n\n    def get_field(self, field_name):\n        \"\"\"Get property from the Dataset.\n\n        Parameters\n        ----------\n        field_name: string\n            The field name of the information.\n\n        Returns\n        -------\n        info : numpy array\n            A numpy array with information from the Dataset.\n        \"\"\"\n        if self.handle is None:\n            raise Exception(\"Cannot get %s before construct Dataset\" % field_name)\n        tmp_out_len = ctypes.c_int()\n        out_type = ctypes.c_int()\n        ret = ctypes.POINTER(ctypes.c_void_p)()\n        _safe_call(_LIB.LGBM_DatasetGetField(\n            self.handle,\n            c_str(field_name),\n            ctypes.byref(tmp_out_len),\n            ctypes.byref(ret),\n            ctypes.byref(out_type)))\n        if out_type.value != FIELD_TYPE_MAPPER[field_name]:\n            raise TypeError(\"Return type error for get_field\")\n        if tmp_out_len.value == 0:\n            return None\n        if out_type.value == C_API_DTYPE_INT32:\n            return cint32_array_to_numpy(ctypes.cast(ret, ctypes.POINTER(ctypes.c_int32)), tmp_out_len.value)\n        elif out_type.value == C_API_DTYPE_FLOAT32:\n            return cfloat32_array_to_numpy(ctypes.cast(ret, ctypes.POINTER(ctypes.c_float)), tmp_out_len.value)\n        elif out_type.value == C_API_DTYPE_FLOAT64:\n            return cfloat64_array_to_numpy(ctypes.cast(ret, ctypes.POINTER(ctypes.c_double)), tmp_out_len.value)\n        else:\n            raise TypeError(\"Unknown type\")\n\n    def set_categorical_feature(self, categorical_feature):\n        \"\"\"Set categorical features.\n\n        Parameters\n        ----------\n        categorical_feature : list of int or strings\n            Names or indices of categorical features.\n        \"\"\"\n        if self.categorical_feature == categorical_feature:\n            return\n        if self.data is not None:\n            if self.categorical_feature is None:\n                self.categorical_feature = categorical_feature\n                self._free_handle()\n            elif categorical_feature == 'auto':\n                warnings.warn('Using categorical_feature in Dataset.')\n            else:\n                warnings.warn('categorical_feature in Dataset is overridden. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n                self.categorical_feature = categorical_feature\n                self._free_handle()\n        else:\n            raise LightGBMError(\"Cannot set categorical feature after freed raw data, set free_raw_data=False when construct Dataset to avoid this.\")\n\n    def _set_predictor(self, predictor):\n        \"\"\"\n        Set predictor for continued training, not recommended for user to call this function.\n        Please set init_model in engine.train or engine.cv\n        \"\"\"\n        if predictor is self._predictor:\n            return\n        if self.data is not None:\n            self._predictor = predictor\n            self._free_handle()\n        else:\n            raise LightGBMError(\"Cannot set predictor after freed raw data, set free_raw_data=False when construct Dataset to avoid this.\")\n\n    def set_reference(self, reference):\n        \"\"\"Set reference Dataset.\n\n        Parameters\n        ----------\n        reference : Dataset\n            Reference that is used as a template to consturct the current Dataset.\n        \"\"\"\n        self.set_categorical_feature(reference.categorical_feature)\n        self.set_feature_name(reference.feature_name)\n        self._set_predictor(reference._predictor)\n        # we're done if self and reference share a common upstrem reference\n        if self.get_ref_chain().intersection(reference.get_ref_chain()):\n            return\n        if self.data is not None:\n            self.reference = reference\n            self._free_handle()\n        else:\n            raise LightGBMError(\"Cannot set reference after freed raw data, set free_raw_data=False when construct Dataset to avoid this.\")\n\n    def set_feature_name(self, feature_name):\n        \"\"\"Set feature name.\n\n        Parameters\n        ----------\n        feature_name : list of strings\n            Feature names.\n        \"\"\"\n        if feature_name != 'auto':\n            self.feature_name = feature_name\n        if self.handle is not None and feature_name is not None and feature_name != 'auto':\n            if len(feature_name) != self.num_feature():\n                raise ValueError(\"Length of feature_name({}) and num_feature({}) don't match\".format(len(feature_name), self.num_feature()))\n            c_feature_name = [c_str(name) for name in feature_name]\n            _safe_call(_LIB.LGBM_DatasetSetFeatureNames(\n                self.handle,\n                c_array(ctypes.c_char_p, c_feature_name),\n                ctypes.c_int(len(feature_name))))\n\n    def set_label(self, label):\n        \"\"\"Set label of Dataset\n\n        Parameters\n        ----------\n        label: list, numpy array or None\n            The label information to be set into Dataset.\n        \"\"\"\n        self.label = label\n        if self.handle is not None:\n            label = list_to_1d_numpy(label, name='label')\n            self.set_field('label', label)\n\n    def set_weight(self, weight):\n        \"\"\"Set weight of each instance.\n\n        Parameters\n        ----------\n        weight : list, numpy array or None\n            Weight to be set for each data point.\n        \"\"\"\n        if weight is not None and np.all(weight == 1):\n            weight = None\n        self.weight = weight\n        if self.handle is not None and weight is not None:\n            weight = list_to_1d_numpy(weight, name='weight')\n            self.set_field('weight', weight)\n\n    def set_init_score(self, init_score):\n        \"\"\"Set init score of Booster to start from.\n\n        Parameters\n        ----------\n        init_score : list, numpy array or None\n            Init score for Booster.\n        \"\"\"\n        self.init_score = init_score\n        if self.handle is not None and init_score is not None:\n            init_score = list_to_1d_numpy(init_score, np.float64, name='init_score')\n            self.set_field('init_score', init_score)\n\n    def set_group(self, group):\n        \"\"\"Set group size of Dataset (used for ranking).\n\n        Parameters\n        ----------\n        group : list, numpy array or None\n            Group size of each group.\n        \"\"\"\n        self.group = group\n        if self.handle is not None and group is not None:\n            group = list_to_1d_numpy(group, np.int32, name='group')\n            self.set_field('group', group)\n\n    def get_label(self):\n        \"\"\"Get the label of the Dataset.\n\n        Returns\n        -------\n        label : numpy array\n            The label information from the Dataset.\n        \"\"\"\n        if self.label is None:\n            self.label = self.get_field('label')\n        return self.label\n\n    def get_weight(self):\n        \"\"\"Get the weight of the Dataset.\n\n        Returns\n        -------\n        weight : numpy array\n            Weight for each data point from the Dataset.\n        \"\"\"\n        if self.weight is None:\n            self.weight = self.get_field('weight')\n        return self.weight\n\n    def get_init_score(self):\n        \"\"\"Get the initial score of the Dataset.\n\n        Returns\n        -------\n        init_score : numpy array\n            Init score of Booster.\n        \"\"\"\n        if self.init_score is None:\n            self.init_score = self.get_field('init_score')\n        return self.init_score\n\n    def get_group(self):\n        \"\"\"Get the group of the Dataset.\n\n        Returns\n        -------\n        group : numpy array\n            Group size of each group.\n        \"\"\"\n        if self.group is None:\n            self.group = self.get_field('group')\n            if self.group is not None:\n                # group data from LightGBM is boundaries data, need to convert to group size\n                new_group = []\n                for i in range_(len(self.group) - 1):\n                    new_group.append(self.group[i + 1] - self.group[i])\n                self.group = new_group\n        return self.group\n\n    def num_data(self):\n        \"\"\"Get the number of rows in the Dataset.\n\n        Returns\n        -------\n        number_of_rows : int\n            The number of rows in the Dataset.\n        \"\"\"\n        if self.handle is not None:\n            ret = ctypes.c_int()\n            _safe_call(_LIB.LGBM_DatasetGetNumData(self.handle,\n                                                   ctypes.byref(ret)))\n            return ret.value\n        else:\n            raise LightGBMError(\"Cannot get num_data before construct dataset\")\n\n    def num_feature(self):\n        \"\"\"Get the number of columns (features) in the Dataset.\n\n        Returns\n        -------\n        number_of_columns : int\n            The number of columns (features) in the Dataset.\n        \"\"\"\n        if self.handle is not None:\n            ret = ctypes.c_int()\n            _safe_call(_LIB.LGBM_DatasetGetNumFeature(self.handle,\n                                                      ctypes.byref(ret)))\n            return ret.value\n        else:\n            raise LightGBMError(\"Cannot get num_feature before construct dataset\")\n\n    def get_ref_chain(self, ref_limit=100):\n        \"\"\"Get a chain of Dataset objects, starting with r, then going to r.reference if exists,\n        then to r.reference.reference, etc. until we hit ``ref_limit`` or a reference loop.\n\n        Parameters\n        ----------\n        ref_limit : int, optional (default=100)\n            The limit number of references.\n\n        Returns\n        -------\n        ref_chain : set of Dataset\n            Chain of references of the Datasets.\n        \"\"\"\n        head = self\n        ref_chain = set()\n        while len(ref_chain) < ref_limit:\n            if isinstance(head, Dataset):\n                ref_chain.add(head)\n                if (head.reference is not None) and (head.reference not in ref_chain):\n                    head = head.reference\n                else:\n                    break\n            else:\n                break\n        return(ref_chain)\n\n\nclass Booster(object):\n    \"\"\"Booster in LightGBM.\"\"\"\n    def __init__(self, params=None, train_set=None, model_file=None, silent=False):\n        \"\"\"Initialize the Booster.\n\n        Parameters\n        ----------\n        params: dict or None, optional (default=None)\n            Parameters for Booster.\n        train_set : Dataset or None, optional (default=None)\n            Training dataset.\n        model_file : string or None, optional (default=None)\n            Path to the model file.\n        silent : bool, optional (default=False)\n            Whether to print messages during construction.\n        \"\"\"\n        self.handle = None\n        self.network = False\n        self.__need_reload_eval_info = True\n        self.__train_data_name = \"training\"\n        self.__attr = {}\n        self.__set_objective_to_none = False\n        self.best_iteration = -1\n        self.best_score = {}\n        params = {} if params is None else params\n        if silent:\n            params[\"verbose\"] = 0\n        if train_set is not None:\n            # Training task\n            if not isinstance(train_set, Dataset):\n                raise TypeError('Training data should be Dataset instance, met {}'.format(type(train_set).__name__))\n            params_str = param_dict_to_str(params)\n            # construct booster object\n            self.handle = ctypes.c_void_p()\n            _safe_call(_LIB.LGBM_BoosterCreate(\n                train_set.construct().handle,\n                c_str(params_str),\n                ctypes.byref(self.handle)))\n            # save reference to data\n            self.train_set = train_set\n            self.valid_sets = []\n            self.name_valid_sets = []\n            self.__num_dataset = 1\n            self.__init_predictor = train_set._predictor\n            if self.__init_predictor is not None:\n                _safe_call(_LIB.LGBM_BoosterMerge(\n                    self.handle,\n                    self.__init_predictor.handle))\n            out_num_class = ctypes.c_int(0)\n            _safe_call(_LIB.LGBM_BoosterGetNumClasses(\n                self.handle,\n                ctypes.byref(out_num_class)))\n            self.__num_class = out_num_class.value\n            # buffer for inner predict\n            self.__inner_predict_buffer = [None]\n            self.__is_predicted_cur_iter = [False]\n            self.__get_eval_info()\n            self.pandas_categorical = train_set.pandas_categorical\n            # set network if necessary\n            for alias in [\"machines\", \"workers\", \"nodes\"]:\n                if alias in params:\n                    machines = params[alias]\n                    if isinstance(machines, string_type):\n                        num_machines = len(machines.split(','))\n                    elif isinstance(machines, (list, set)):\n                        num_machines = len(machines)\n                        machines = ','.join(machines)\n                    else:\n                        raise ValueError(\"Invalid machines in params.\")\n                    self.set_network(machines,\n                                     local_listen_port=params.get(\"local_listen_port\", 12400),\n                                     listen_time_out=params.get(\"listen_time_out\", 120),\n                                     num_machines=params.get(\"num_machines\", num_machines))\n                    break\n        elif model_file is not None:\n            # Prediction task\n            out_num_iterations = ctypes.c_int(0)\n            self.handle = ctypes.c_void_p()\n            _safe_call(_LIB.LGBM_BoosterCreateFromModelfile(\n                c_str(model_file),\n                ctypes.byref(out_num_iterations),\n                ctypes.byref(self.handle)))\n            out_num_class = ctypes.c_int(0)\n            _safe_call(_LIB.LGBM_BoosterGetNumClasses(\n                self.handle,\n                ctypes.byref(out_num_class)))\n            self.__num_class = out_num_class.value\n            self.pandas_categorical = _load_pandas_categorical(model_file)\n        elif 'model_str' in params:\n            self._load_model_from_string(params['model_str'])\n        else:\n            raise TypeError('Need at least one training dataset or model file to create booster instance')\n\n    def __del__(self):\n        try:\n            if self.network:\n                self.free_network()\n        except AttributeError:\n            pass\n        try:\n            if self.handle is not None:\n                _safe_call(_LIB.LGBM_BoosterFree(self.handle))\n        except AttributeError:\n            pass\n\n    def __copy__(self):\n        return self.__deepcopy__(None)\n\n    def __deepcopy__(self, _):\n        model_str = self._save_model_to_string()\n        booster = Booster({'model_str': model_str})\n        booster.pandas_categorical = self.pandas_categorical\n        return booster\n\n    def __getstate__(self):\n        this = self.__dict__.copy()\n        handle = this['handle']\n        this.pop('train_set', None)\n        this.pop('valid_sets', None)\n        if handle is not None:\n            this[\"handle\"] = self._save_model_to_string()\n        return this\n\n    def __setstate__(self, state):\n        model_str = state.get('handle', None)\n        if model_str is not None:\n            handle = ctypes.c_void_p()\n            out_num_iterations = ctypes.c_int(0)\n            _safe_call(_LIB.LGBM_BoosterLoadModelFromString(\n                c_str(model_str),\n                ctypes.byref(out_num_iterations),\n                ctypes.byref(handle)))\n            state['handle'] = handle\n        self.__dict__.update(state)\n\n    def free_dataset(self):\n        \"\"\"Free Booster's Datasets.\"\"\"\n        self.__dict__.pop('train_set', None)\n        self.__dict__.pop('valid_sets', None)\n        self.__num_dataset = 0\n\n    def _free_buffer(self):\n        self.__inner_predict_buffer = []\n        self.__is_predicted_cur_iter = []\n\n    def set_network(self, machines, local_listen_port=12400,\n                    listen_time_out=120, num_machines=1):\n        \"\"\"Set the network configuration.\n\n        Parameters\n        ----------\n        machines: list, set or string\n            Names of machines.\n        local_listen_port: int, optional (default=12400)\n            TCP listen port for local machines.\n        listen_time_out: int, optional (default=120)\n            Socket time-out in minutes.\n        num_machines: int, optional (default=1)\n            The number of machines for parallel learning application.\n        \"\"\"\n        _safe_call(_LIB.LGBM_NetworkInit(c_str(machines),\n                                         ctypes.c_int(local_listen_port),\n                                         ctypes.c_int(listen_time_out),\n                                         ctypes.c_int(num_machines)))\n        self.network = True\n\n    def free_network(self):\n        \"\"\"Free network.\"\"\"\n        _safe_call(_LIB.LGBM_NetworkFree())\n        self.network = False\n\n    def set_train_data_name(self, name):\n        \"\"\"Set the name to the training Dataset.\n\n        Parameters\n        ----------\n        name: string\n            Name for training Dataset.\n        \"\"\"\n        self.__train_data_name = name\n\n    def add_valid(self, data, name):\n        \"\"\"Add validation data.\n\n        Parameters\n        ----------\n        data : Dataset\n            Validation data.\n        name : string\n            Name of validation data.\n        \"\"\"\n        if not isinstance(data, Dataset):\n            raise TypeError('Validation data should be Dataset instance, met {}'.format(type(data).__name__))\n        if data._predictor is not self.__init_predictor:\n            raise LightGBMError(\"Add validation data failed, you should use same predictor for these data\")\n        _safe_call(_LIB.LGBM_BoosterAddValidData(\n            self.handle,\n            data.construct().handle))\n        self.valid_sets.append(data)\n        self.name_valid_sets.append(name)\n        self.__num_dataset += 1\n        self.__inner_predict_buffer.append(None)\n        self.__is_predicted_cur_iter.append(False)\n\n    def reset_parameter(self, params):\n        \"\"\"Reset parameters of Booster.\n\n        Parameters\n        ----------\n        params : dict\n            New parameters for Booster.\n        \"\"\"\n        if any(metric_alias in params for metric_alias in ('metric', 'metrics', 'metric_types')):\n            self.__need_reload_eval_info = True\n        params_str = param_dict_to_str(params)\n        if params_str:\n            _safe_call(_LIB.LGBM_BoosterResetParameter(\n                self.handle,\n                c_str(params_str)))\n\n    def update(self, train_set=None, fobj=None):\n        \"\"\"Update for one iteration.\n\n        Parameters\n        ----------\n        train_set : Dataset or None, optional (default=None)\n            Training data.\n            If None, last training data is used.\n        fobj : callable or None, optional (default=None)\n            Customized objective function.\n\n            For multi-class task, the score is group by class_id first, then group by row_id.\n            If you want to get i-th row score in j-th class, the access way is score[j * num_data + i]\n            and you should group grad and hess in this way as well.\n\n        Returns\n        -------\n        is_finished : bool\n            Whether the update was successfully finished.\n        \"\"\"\n\n        # need reset training data\n        if train_set is not None and train_set is not self.train_set:\n            if not isinstance(train_set, Dataset):\n                raise TypeError('Training data should be Dataset instance, met {}'.format(type(train_set).__name__))\n            if train_set._predictor is not self.__init_predictor:\n                raise LightGBMError(\"Replace training data failed, you should use same predictor for these data\")\n            self.train_set = train_set\n            _safe_call(_LIB.LGBM_BoosterResetTrainingData(\n                self.handle,\n                self.train_set.construct().handle))\n            self.__inner_predict_buffer[0] = None\n        is_finished = ctypes.c_int(0)\n        if fobj is None:\n            if self.__set_objective_to_none:\n                raise ValueError('Cannot update due to null objective function.')\n            _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n                self.handle,\n                ctypes.byref(is_finished)))\n            self.__is_predicted_cur_iter = [False for _ in range_(self.__num_dataset)]\n            return is_finished.value == 1\n        else:\n            if not self.__set_objective_to_none:\n                self.reset_parameter({\"objective\": \"none\"})\n                self.__set_objective_to_none = True\n            grad, hess = fobj(self.__inner_predict(0), self.train_set)\n            return self.__boost(grad, hess)\n\n    def __boost(self, grad, hess):\n        \"\"\"\n        Boost the booster for one iteration, with customized gradient statistics.\n        Note: for multi-class task, the score is group by class_id first, then group by row_id\n              if you want to get i-th row score in j-th class, the access way is score[j*num_data+i]\n              and you should group grad and hess in this way as well\n\n        Parameters\n        ----------\n        grad : 1d numpy or 1d list\n            The first order of gradient.\n        hess : 1d numpy or 1d list\n            The second order of gradient.\n\n        Returns\n        -------\n        is_finished, bool\n        \"\"\"\n        grad = list_to_1d_numpy(grad, name='gradient')\n        hess = list_to_1d_numpy(hess, name='hessian')\n        assert grad.flags.c_contiguous\n        assert hess.flags.c_contiguous\n        if len(grad) != len(hess):\n            raise ValueError(\"Lengths of gradient({}) and hessian({}) don't match\".format(len(grad), len(hess)))\n        is_finished = ctypes.c_int(0)\n        _safe_call(_LIB.LGBM_BoosterUpdateOneIterCustom(\n            self.handle,\n            grad.ctypes.data_as(ctypes.POINTER(ctypes.c_float)),\n            hess.ctypes.data_as(ctypes.POINTER(ctypes.c_float)),\n            ctypes.byref(is_finished)))\n        self.__is_predicted_cur_iter = [False for _ in range_(self.__num_dataset)]\n        return is_finished.value == 1\n\n    def rollback_one_iter(self):\n        \"\"\"Rollback one iteration.\"\"\"\n        _safe_call(_LIB.LGBM_BoosterRollbackOneIter(\n            self.handle))\n        self.__is_predicted_cur_iter = [False for _ in range_(self.__num_dataset)]\n\n    def current_iteration(self):\n        \"\"\"Get the index of the current iteration.\n\n        Returns\n        -------\n        cur_iter : int\n            The index of the current iteration.\n        \"\"\"\n        out_cur_iter = ctypes.c_int(0)\n        _safe_call(_LIB.LGBM_BoosterGetCurrentIteration(\n            self.handle,\n            ctypes.byref(out_cur_iter)))\n        return out_cur_iter.value\n\n    def eval(self, data, name, feval=None):\n        \"\"\"Evaluate for data.\n\n        Parameters\n        ----------\n        data : Dataset\n            Data for the evaluating.\n        name : string\n            Name of the data.\n        feval : callable or None, optional (default=None)\n            Customized evaluation function.\n            Should accept two parameters: preds, train_data.\n            For multi-class task, the preds is group by class_id first, then group by row_id.\n            If you want to get i-th row preds in j-th class, the access way is preds[j * num_data + i].\n            Note: should return (eval_name, eval_result, is_higher_better) or list of such tuples.\n\n        Returns\n        -------\n        result: list\n            List with evaluation results.\n        \"\"\"\n        if not isinstance(data, Dataset):\n            raise TypeError(\"Can only eval for Dataset instance\")\n        data_idx = -1\n        if data is self.train_set:\n            data_idx = 0\n        else:\n            for i in range_(len(self.valid_sets)):\n                if data is self.valid_sets[i]:\n                    data_idx = i + 1\n                    break\n        # need to push new valid data\n        if data_idx == -1:\n            self.add_valid(data, name)\n            data_idx = self.__num_dataset - 1\n\n        return self.__inner_eval(name, data_idx, feval)\n\n    def eval_train(self, feval=None):\n        \"\"\"Evaluate for training data.\n\n        Parameters\n        ----------\n        feval : callable or None, optional (default=None)\n            Customized evaluation function.\n            Should accept two parameters: preds, train_data.\n            For multi-class task, the preds is group by class_id first, then group by row_id.\n            If you want to get i-th row preds in j-th class, the access way is preds[j * num_data + i].\n            Note: should return (eval_name, eval_result, is_higher_better) or list of such tuples.\n\n        Returns\n        -------\n        result: list\n            List with evaluation results.\n        \"\"\"\n        return self.__inner_eval(self.__train_data_name, 0, feval)\n\n    def eval_valid(self, feval=None):\n        \"\"\"Evaluate for validation data.\n\n        Parameters\n        ----------\n        feval : callable or None, optional (default=None)\n            Customized evaluation function.\n            Should accept two parameters: preds, train_data.\n            For multi-class task, the preds is group by class_id first, then group by row_id.\n            If you want to get i-th row preds in j-th class, the access way is preds[j * num_data + i].\n            Note: should return (eval_name, eval_result, is_higher_better) or list of such tuples.\n\n        Returns\n        -------\n        result: list\n            List with evaluation results.\n        \"\"\"\n        return [item for i in range_(1, self.__num_dataset)\n                for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n\n    def save_model(self, filename, num_iteration=-1):\n        \"\"\"Save Booster to file.\n\n        Parameters\n        ----------\n        filename : string\n            Filename to save Booster.\n        num_iteration: int, optional (default=-1)\n            Index of the iteration that should to saved.\n            If <0, the best iteration (if exists) is saved.\n        \"\"\"\n        if num_iteration <= 0:\n            num_iteration = self.best_iteration\n        _safe_call(_LIB.LGBM_BoosterSaveModel(\n            self.handle,\n            ctypes.c_int(num_iteration),\n            c_str(filename)))\n        _save_pandas_categorical(filename, self.pandas_categorical)\n\n    def _load_model_from_string(self, model_str, verbose=True):\n        \"\"\"[Private] Load model from string\"\"\"\n        if self.handle is not None:\n            _safe_call(_LIB.LGBM_BoosterFree(self.handle))\n        self._free_buffer()\n        self.handle = ctypes.c_void_p()\n        out_num_iterations = ctypes.c_int(0)\n        _safe_call(_LIB.LGBM_BoosterLoadModelFromString(\n            c_str(model_str),\n            ctypes.byref(out_num_iterations),\n            ctypes.byref(self.handle)))\n        out_num_class = ctypes.c_int(0)\n        _safe_call(_LIB.LGBM_BoosterGetNumClasses(\n            self.handle,\n            ctypes.byref(out_num_class)))\n        if verbose:\n            print('Finished loading model, total used %d iterations' % (int(out_num_iterations.value)))\n        self.__num_class = out_num_class.value\n\n    def _save_model_to_string(self, num_iteration=-1):\n        \"\"\"[Private] Save model to string\"\"\"\n        if num_iteration <= 0:\n            num_iteration = self.best_iteration\n        buffer_len = 1 << 20\n        tmp_out_len = ctypes.c_int64(0)\n        string_buffer = ctypes.create_string_buffer(buffer_len)\n        ptr_string_buffer = ctypes.c_char_p(*[ctypes.addressof(string_buffer)])\n        _safe_call(_LIB.LGBM_BoosterSaveModelToString(\n            self.handle,\n            ctypes.c_int(num_iteration),\n            ctypes.c_int64(buffer_len),\n            ctypes.byref(tmp_out_len),\n            ptr_string_buffer))\n        actual_len = tmp_out_len.value\n        '''if buffer length is not long enough, re-allocate a buffer'''\n        if actual_len > buffer_len:\n            string_buffer = ctypes.create_string_buffer(actual_len)\n            ptr_string_buffer = ctypes.c_char_p(*[ctypes.addressof(string_buffer)])\n            _safe_call(_LIB.LGBM_BoosterSaveModelToString(\n                self.handle,\n                ctypes.c_int(num_iteration),\n                ctypes.c_int64(actual_len),\n                ctypes.byref(tmp_out_len),\n                ptr_string_buffer))\n        return string_buffer.value.decode()\n\n    def dump_model(self, num_iteration=-1):\n        \"\"\"Dump Booster to json format.\n\n        Parameters\n        ----------\n        num_iteration: int, optional (default=-1)\n            Index of the iteration that should to dumped.\n            If <0, the best iteration (if exists) is dumped.\n\n        Returns\n        -------\n        json_repr : dict\n            Json format of Booster.\n        \"\"\"\n        if num_iteration <= 0:\n            num_iteration = self.best_iteration\n        buffer_len = 1 << 20\n        tmp_out_len = ctypes.c_int64(0)\n        string_buffer = ctypes.create_string_buffer(buffer_len)\n        ptr_string_buffer = ctypes.c_char_p(*[ctypes.addressof(string_buffer)])\n        _safe_call(_LIB.LGBM_BoosterDumpModel(\n            self.handle,\n            ctypes.c_int(num_iteration),\n            ctypes.c_int64(buffer_len),\n            ctypes.byref(tmp_out_len),\n            ptr_string_buffer))\n        actual_len = tmp_out_len.value\n        '''if buffer length is not long enough, reallocate a buffer'''\n        if actual_len > buffer_len:\n            string_buffer = ctypes.create_string_buffer(actual_len)\n            ptr_string_buffer = ctypes.c_char_p(*[ctypes.addressof(string_buffer)])\n            _safe_call(_LIB.LGBM_BoosterDumpModel(\n                self.handle,\n                ctypes.c_int(num_iteration),\n                ctypes.c_int64(actual_len),\n                ctypes.byref(tmp_out_len),\n                ptr_string_buffer))\n        return json.loads(string_buffer.value.decode())\n\n    def predict(self, data, num_iteration=-1, raw_score=False, pred_leaf=False, pred_contrib=False,\n                data_has_header=False, is_reshape=True, pred_parameter=None, **kwargs):\n        \"\"\"Make a prediction.\n\n        Parameters\n        ----------\n        data : string, numpy array or scipy.sparse\n            Data source for prediction.\n            If string, it represents the path to txt file.\n        num_iteration : int, optional (default=-1)\n            Iteration used for prediction.\n            If <0, the best iteration (if exists) is used for prediction.\n        raw_score : bool, optional (default=False)\n            Whether to predict raw scores.\n        pred_leaf : bool, optional (default=False)\n            Whether to predict leaf index.\n        pred_contrib : bool, optional (default=False)\n            Whether to predict feature contributions.\n        data_has_header : bool, optional (default=False)\n            Whether the data has header.\n            Used only if data is string.\n        is_reshape : bool, optional (default=True)\n            If True, result is reshaped to [nrow, ncol].\n        pred_parameter : dict or None, optional (default=None)\n            Deprecated.\n            Other parameters for the prediction.\n        **kwargs : other parameters for the prediction\n\n        Returns\n        -------\n        result : numpy array\n            Prediction result.\n        \"\"\"\n        if pred_parameter:\n            warnings.warn(\"pred_parameter is deprecated and will be removed in 2.2 version.\\n\"\n                          \"Please use kwargs instead.\", LGBMDeprecationWarning)\n            pred_parameter.update(kwargs)\n        else:\n            pred_parameter = kwargs\n        predictor = self._to_predictor(pred_parameter)\n        if num_iteration <= 0:\n            num_iteration = self.best_iteration\n        return predictor.predict(data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\n\n    def get_leaf_output(self, tree_id, leaf_id):\n        \"\"\"Get the output of a leaf.\n\n        Parameters\n        ----------\n        tree_id : int\n            The index of the tree.\n        leaf_id : int\n            The index of the leaf in the tree.\n\n        Returns\n        -------\n        result : float\n            The output of the leaf.\n        \"\"\"\n        ret = ctypes.c_double(0)\n        _safe_call(_LIB.LGBM_BoosterGetLeafValue(\n            self.handle,\n            ctypes.c_int(tree_id),\n            ctypes.c_int(leaf_id),\n            ctypes.byref(ret)))\n        return ret.value\n\n    def _to_predictor(self, pred_parameter=None):\n        \"\"\"Convert to predictor\"\"\"\n        predictor = _InnerPredictor(booster_handle=self.handle, pred_parameter=pred_parameter)\n        predictor.pandas_categorical = self.pandas_categorical\n        return predictor\n\n    def num_feature(self):\n        \"\"\"Get number of features.\n\n        Returns\n        -------\n        num_feature : int\n            The number of features.\n        \"\"\"\n        out_num_feature = ctypes.c_int(0)\n        _safe_call(_LIB.LGBM_BoosterGetNumFeature(\n            self.handle,\n            ctypes.byref(out_num_feature)))\n        return out_num_feature.value\n\n    def feature_name(self):\n        \"\"\"Get names of features.\n\n        Returns\n        -------\n        result : list\n            List with names of features.\n        \"\"\"\n        num_feature = self.num_feature()\n        # Get name of features\n        tmp_out_len = ctypes.c_int(0)\n        string_buffers = [ctypes.create_string_buffer(255) for i in range_(num_feature)]\n        ptr_string_buffers = (ctypes.c_char_p * num_feature)(*map(ctypes.addressof, string_buffers))\n        _safe_call(_LIB.LGBM_BoosterGetFeatureNames(\n            self.handle,\n            ctypes.byref(tmp_out_len),\n            ptr_string_buffers))\n        if num_feature != tmp_out_len.value:\n            raise ValueError(\"Length of feature names doesn't equal with num_feature\")\n        return [string_buffers[i].value.decode() for i in range_(num_feature)]\n\n    def feature_importance(self, importance_type='split', iteration=-1):\n        \"\"\"Get feature importances.\n\n        Parameters\n        ----------\n        importance_type : string, optional (default=\"split\")\n            How the importance is calculated.\n            If \"split\", result contains numbers of times the feature is used in a model.\n            If \"gain\", result contains total gains of splits which use the feature.\n\n        Returns\n        -------\n        result : numpy array\n            Array with feature importances.\n        \"\"\"\n        if importance_type == \"split\":\n            importance_type_int = 0\n        elif importance_type == \"gain\":\n            importance_type_int = 1\n        else:\n            importance_type_int = -1\n        num_feature = self.num_feature()\n        result = np.array([0 for _ in range_(num_feature)], dtype=np.float64)\n        _safe_call(_LIB.LGBM_BoosterFeatureImportance(\n            self.handle,\n            ctypes.c_int(iteration),\n            ctypes.c_int(importance_type_int),\n            result.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n        if importance_type_int == 0:\n            return result.astype(int)\n        else:\n            return result\n\n    def __inner_eval(self, data_name, data_idx, feval=None):\n        \"\"\"\n        Evaulate training or validation data\n        \"\"\"\n        if data_idx >= self.__num_dataset:\n            raise ValueError(\"Data_idx should be smaller than number of dataset\")\n        self.__get_eval_info()\n        ret = []\n        if self.__num_inner_eval > 0:\n            result = np.zeros(self.__num_inner_eval, dtype=np.float64)\n            tmp_out_len = ctypes.c_int(0)\n            _safe_call(_LIB.LGBM_BoosterGetEval(\n                self.handle,\n                ctypes.c_int(data_idx),\n                ctypes.byref(tmp_out_len),\n                result.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n            if tmp_out_len.value != self.__num_inner_eval:\n                raise ValueError(\"Wrong length of eval results\")\n            for i in range_(self.__num_inner_eval):\n                ret.append((data_name, self.__name_inner_eval[i], result[i], self.__higher_better_inner_eval[i]))\n        if feval is not None:\n            if data_idx == 0:\n                cur_data = self.train_set\n            else:\n                cur_data = self.valid_sets[data_idx - 1]\n            feval_ret = feval(self.__inner_predict(data_idx), cur_data)\n            if isinstance(feval_ret, list):\n                for eval_name, val, is_higher_better in feval_ret:\n                    ret.append((data_name, eval_name, val, is_higher_better))\n            else:\n                eval_name, val, is_higher_better = feval_ret\n                ret.append((data_name, eval_name, val, is_higher_better))\n        return ret\n\n    def __inner_predict(self, data_idx):\n        \"\"\"\n        Predict for training and validation dataset\n        \"\"\"\n        if data_idx >= self.__num_dataset:\n            raise ValueError(\"Data_idx should be smaller than number of dataset\")\n        if self.__inner_predict_buffer[data_idx] is None:\n            if data_idx == 0:\n                n_preds = self.train_set.num_data() * self.__num_class\n            else:\n                n_preds = self.valid_sets[data_idx - 1].num_data() * self.__num_class\n            self.__inner_predict_buffer[data_idx] = np.zeros(n_preds, dtype=np.float64)\n        # avoid to predict many time in one iteration\n        if not self.__is_predicted_cur_iter[data_idx]:\n            tmp_out_len = ctypes.c_int64(0)\n            data_ptr = self.__inner_predict_buffer[data_idx].ctypes.data_as(ctypes.POINTER(ctypes.c_double))\n            _safe_call(_LIB.LGBM_BoosterGetPredict(\n                self.handle,\n                ctypes.c_int(data_idx),\n                ctypes.byref(tmp_out_len),\n                data_ptr))\n            if tmp_out_len.value != len(self.__inner_predict_buffer[data_idx]):\n                raise ValueError(\"Wrong length of predict results for data %d\" % (data_idx))\n            self.__is_predicted_cur_iter[data_idx] = True\n        return self.__inner_predict_buffer[data_idx]\n\n    def __get_eval_info(self):\n        \"\"\"\n        Get inner evaluation count and names\n        \"\"\"\n        if self.__need_reload_eval_info:\n            self.__need_reload_eval_info = False\n            out_num_eval = ctypes.c_int(0)\n            # Get num of inner evals\n            _safe_call(_LIB.LGBM_BoosterGetEvalCounts(\n                self.handle,\n                ctypes.byref(out_num_eval)))\n            self.__num_inner_eval = out_num_eval.value\n            if self.__num_inner_eval > 0:\n                # Get name of evals\n                tmp_out_len = ctypes.c_int(0)\n                string_buffers = [ctypes.create_string_buffer(255) for i in range_(self.__num_inner_eval)]\n                ptr_string_buffers = (ctypes.c_char_p * self.__num_inner_eval)(*map(ctypes.addressof, string_buffers))\n                _safe_call(_LIB.LGBM_BoosterGetEvalNames(\n                    self.handle,\n                    ctypes.byref(tmp_out_len),\n                    ptr_string_buffers))\n                if self.__num_inner_eval != tmp_out_len.value:\n                    raise ValueError(\"Length of eval names doesn't equal with num_evals\")\n                self.__name_inner_eval = \\\n                    [string_buffers[i].value.decode() for i in range_(self.__num_inner_eval)]\n                self.__higher_better_inner_eval = \\\n                    [name.startswith(('auc', 'ndcg@', 'map@')) for name in self.__name_inner_eval]\n\n    def attr(self, key):\n        \"\"\"Get attribute string from the Booster.\n\n        Parameters\n        ----------\n        key : string\n            The name of the attribute.\n\n        Returns\n        -------\n        value : string or None\n            The attribute value.\n            Returns None if attribute do not exist.\n        \"\"\"\n        return self.__attr.get(key, None)\n\n    def set_attr(self, **kwargs):\n        \"\"\"Set the attribute of the Booster.\n\n        Parameters\n        ----------\n        **kwargs\n            The attributes to set.\n            Setting a value to None deletes an attribute.\n        \"\"\"\n        for key, value in kwargs.items():\n            if value is not None:\n                if not isinstance(value, string_type):\n                    raise ValueError(\"Set attr only accepts strings\")\n                self.__attr[key] = value\n            else:\n                self.__attr.pop(key, None)\n", "idx": 5, "id": 18784, "msg": "", "proj": "microsoft-LightGBM", "lang": "cpp"}
{"patch": "@@ -113,11 +113,12 @@ func (db *DB) put(mode storage.ModePut, chs ...swarm.Chunk) (exist []bool, err e\n \t\t\t}\n \t\t\tgcSizeChange += c\n \t\t\tif mode == storage.ModePutUploadPin {\n-\t\t\t\terr = db.setPin(batch, ch.Address())\n+\t\t\t\tc, err = db.setPin(batch, item)\n \t\t\t\tif err != nil {\n \t\t\t\t\treturn nil, err\n \t\t\t\t}\n \t\t\t}\n+\t\t\tgcSizeChange += c\n \t\t}\n \n \tcase storage.ModePutSync:", "y": 0, "oldf": "// Copyright 2018 The go-ethereum Authors\n// This file is part of the go-ethereum library.\n//\n// The go-ethereum library is free software: you can redistribute it and/or modify\n// it under the terms of the GNU Lesser General Public License as published by\n// the Free Software Foundation, either version 3 of the License, or\n// (at your option) any later version.\n//\n// The go-ethereum library is distributed in the hope that it will be useful,\n// but WITHOUT ANY WARRANTY; without even the implied warranty of\n// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n// GNU Lesser General Public License for more details.\n//\n// You should have received a copy of the GNU Lesser General Public License\n// along with the go-ethereum library. If not, see <http://www.gnu.org/licenses/>.\n\npackage localstore\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"time\"\n\n\t\"github.com/ethersphere/bee/pkg/shed\"\n\t\"github.com/ethersphere/bee/pkg/storage\"\n\t\"github.com/ethersphere/bee/pkg/swarm\"\n\t\"github.com/syndtr/goleveldb/leveldb\"\n)\n\n// Put stores Chunks to database and depending\n// on the Putter mode, it updates required indexes.\n// Put is required to implement storage.Store\n// interface.\nfunc (db *DB) Put(ctx context.Context, mode storage.ModePut, chs ...swarm.Chunk) (exist []bool, err error) {\n\n\tdb.metrics.ModePut.Inc()\n\tdefer totalTimeMetric(db.metrics.TotalTimePut, time.Now())\n\n\texist, err = db.put(mode, chs...)\n\tif err != nil {\n\t\tdb.metrics.ModePutFailure.Inc()\n\t}\n\n\treturn exist, err\n}\n\n// put stores Chunks to database and updates other indexes. It acquires lockAddr\n// to protect two calls of this function for the same address in parallel. Item\n// fields Address and Data must not be with their nil values. If chunks with the\n// same address are passed in arguments, only the first chunk will be stored,\n// and following ones will have exist set to true for their index in exist\n// slice. This is the same behaviour as if the same chunks are passed one by one\n// in multiple put method calls.\nfunc (db *DB) put(mode storage.ModePut, chs ...swarm.Chunk) (exist []bool, err error) {\n\t// protect parallel updates\n\tdb.batchMu.Lock()\n\tdefer db.batchMu.Unlock()\n\n\tbatch := new(leveldb.Batch)\n\n\t// variables that provide information for operations\n\t// to be done after write batch function successfully executes\n\tvar gcSizeChange int64                      // number to add or subtract from gcSize\n\tvar triggerPushFeed bool                    // signal push feed subscriptions to iterate\n\ttriggerPullFeed := make(map[uint8]struct{}) // signal pull feed subscriptions to iterate\n\n\texist = make([]bool, len(chs))\n\n\t// A lazy populated map of bin ids to properly set\n\t// BinID values for new chunks based on initial value from database\n\t// and incrementing them.\n\t// Values from this map are stored with the batch\n\tbinIDs := make(map[uint8]uint64)\n\n\tswitch mode {\n\tcase storage.ModePutRequest, storage.ModePutRequestPin:\n\t\tfor i, ch := range chs {\n\t\t\tif containsChunk(ch.Address(), chs[:i]...) {\n\t\t\t\texist[i] = true\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\texists, c, err := db.putRequest(batch, binIDs, chunkToItem(ch))\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\texist[i] = exists\n\t\t\tgcSizeChange += c\n\n\t\t\tif mode == storage.ModePutRequestPin {\n\t\t\t\terr = db.setPin(batch, ch.Address())\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\tcase storage.ModePutUpload, storage.ModePutUploadPin:\n\t\tfor i, ch := range chs {\n\t\t\tif containsChunk(ch.Address(), chs[:i]...) {\n\t\t\t\texist[i] = true\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\texists, c, err := db.putUpload(batch, binIDs, chunkToItem(ch))\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\texist[i] = exists\n\t\t\tif !exists {\n\t\t\t\t// chunk is new so, trigger subscription feeds\n\t\t\t\t// after the batch is successfully written\n\t\t\t\ttriggerPullFeed[db.po(ch.Address())] = struct{}{}\n\t\t\t\ttriggerPushFeed = true\n\t\t\t}\n\t\t\tgcSizeChange += c\n\t\t\tif mode == storage.ModePutUploadPin {\n\t\t\t\terr = db.setPin(batch, ch.Address())\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\tcase storage.ModePutSync:\n\t\tfor i, ch := range chs {\n\t\t\tif containsChunk(ch.Address(), chs[:i]...) {\n\t\t\t\texist[i] = true\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\texists, c, err := db.putSync(batch, binIDs, chunkToItem(ch))\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\texist[i] = exists\n\t\t\tif !exists {\n\t\t\t\t// chunk is new so, trigger pull subscription feed\n\t\t\t\t// after the batch is successfully written\n\t\t\t\ttriggerPullFeed[db.po(ch.Address())] = struct{}{}\n\t\t\t}\n\t\t\tgcSizeChange += c\n\t\t}\n\n\tdefault:\n\t\treturn nil, ErrInvalidMode\n\t}\n\n\tfor po, id := range binIDs {\n\t\tdb.binIDs.PutInBatch(batch, uint64(po), id)\n\t}\n\n\terr = db.incGCSizeInBatch(batch, gcSizeChange)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\terr = db.shed.WriteBatch(batch)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor po := range triggerPullFeed {\n\t\tdb.triggerPullSubscriptions(po)\n\t}\n\tif triggerPushFeed {\n\t\tdb.triggerPushSubscriptions()\n\t}\n\treturn exist, nil\n}\n\n// putRequest adds an Item to the batch by updating required indexes:\n//  - put to indexes: retrieve, gc\n//  - it does not enter the syncpool\n// The batch can be written to the database.\n// Provided batch and binID map are updated.\nfunc (db *DB) putRequest(batch *leveldb.Batch, binIDs map[uint8]uint64, item shed.Item) (exists bool, gcSizeChange int64, err error) {\n\thas, err := db.retrievalDataIndex.Has(item)\n\tif err != nil {\n\t\treturn false, 0, err\n\t}\n\tif has {\n\t\treturn true, 0, nil\n\t}\n\n\titem.StoreTimestamp = now()\n\titem.BinID, err = db.incBinID(binIDs, db.po(swarm.NewAddress(item.Address)))\n\tif err != nil {\n\t\treturn false, 0, err\n\t}\n\n\tgcSizeChange, err = db.setGC(batch, item)\n\tif err != nil {\n\t\treturn false, 0, err\n\t}\n\n\terr = db.retrievalDataIndex.PutInBatch(batch, item)\n\tif err != nil {\n\t\treturn false, 0, err\n\t}\n\n\treturn false, gcSizeChange, nil\n}\n\n// putUpload adds an Item to the batch by updating required indexes:\n//  - put to indexes: retrieve, push, pull\n// The batch can be written to the database.\n// Provided batch and binID map are updated.\nfunc (db *DB) putUpload(batch *leveldb.Batch, binIDs map[uint8]uint64, item shed.Item) (exists bool, gcSizeChange int64, err error) {\n\texists, err = db.retrievalDataIndex.Has(item)\n\tif err != nil {\n\t\treturn false, 0, err\n\t}\n\tif exists {\n\t\treturn true, 0, nil\n\t}\n\n\titem.StoreTimestamp = now()\n\titem.BinID, err = db.incBinID(binIDs, db.po(swarm.NewAddress(item.Address)))\n\tif err != nil {\n\t\treturn false, 0, err\n\t}\n\terr = db.retrievalDataIndex.PutInBatch(batch, item)\n\tif err != nil {\n\t\treturn false, 0, err\n\t}\n\terr = db.pullIndex.PutInBatch(batch, item)\n\tif err != nil {\n\t\treturn false, 0, err\n\t}\n\terr = db.pushIndex.PutInBatch(batch, item)\n\tif err != nil {\n\t\treturn false, 0, err\n\t}\n\n\treturn false, 0, nil\n}\n\n// putSync adds an Item to the batch by updating required indexes:\n//  - put to indexes: retrieve, pull, gc\n// The batch can be written to the database.\n// Provided batch and binID map are updated.\nfunc (db *DB) putSync(batch *leveldb.Batch, binIDs map[uint8]uint64, item shed.Item) (exists bool, gcSizeChange int64, err error) {\n\texists, err = db.retrievalDataIndex.Has(item)\n\tif err != nil {\n\t\treturn false, 0, err\n\t}\n\tif exists {\n\t\treturn true, 0, nil\n\t}\n\n\titem.StoreTimestamp = now()\n\titem.BinID, err = db.incBinID(binIDs, db.po(swarm.NewAddress(item.Address)))\n\tif err != nil {\n\t\treturn false, 0, err\n\t}\n\terr = db.retrievalDataIndex.PutInBatch(batch, item)\n\tif err != nil {\n\t\treturn false, 0, err\n\t}\n\terr = db.pullIndex.PutInBatch(batch, item)\n\tif err != nil {\n\t\treturn false, 0, err\n\t}\n\tgcSizeChange, err = db.setGC(batch, item)\n\tif err != nil {\n\t\treturn false, 0, err\n\t}\n\n\treturn false, gcSizeChange, nil\n}\n\n// setGC is a helper function used to add chunks to the retrieval access\n// index and the gc index in the cases that the putToGCCheck condition\n// warrants a gc set. this is to mitigate index leakage in edge cases where\n// a chunk is added to a node's localstore and given that the chunk is\n// already within that node's NN (thus, it can be added to the gc index\n// safely)\nfunc (db *DB) setGC(batch *leveldb.Batch, item shed.Item) (gcSizeChange int64, err error) {\n\tif item.BinID == 0 {\n\t\ti, err := db.retrievalDataIndex.Get(item)\n\t\tif err != nil {\n\t\t\treturn 0, err\n\t\t}\n\t\titem.BinID = i.BinID\n\t}\n\ti, err := db.retrievalAccessIndex.Get(item)\n\tswitch {\n\tcase err == nil:\n\t\titem.AccessTimestamp = i.AccessTimestamp\n\t\terr = db.gcIndex.DeleteInBatch(batch, item)\n\t\tif err != nil {\n\t\t\treturn 0, err\n\t\t}\n\t\tgcSizeChange--\n\tcase errors.Is(err, leveldb.ErrNotFound):\n\t\t// the chunk is not accessed before\n\tdefault:\n\t\treturn 0, err\n\t}\n\titem.AccessTimestamp = now()\n\terr = db.retrievalAccessIndex.PutInBatch(batch, item)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\t// add new entry to gc index ONLY if it is not present in pinIndex\n\tok, err := db.pinIndex.Has(item)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\tif !ok {\n\t\terr = db.gcIndex.PutInBatch(batch, item)\n\t\tif err != nil {\n\t\t\treturn 0, err\n\t\t}\n\t\tgcSizeChange++\n\t}\n\n\treturn gcSizeChange, nil\n}\n\n// incBinID is a helper function for db.put* methods that increments bin id\n// based on the current value in the database. This function must be called under\n// a db.batchMu lock. Provided binID map is updated.\nfunc (db *DB) incBinID(binIDs map[uint8]uint64, po uint8) (id uint64, err error) {\n\tif _, ok := binIDs[po]; !ok {\n\t\tbinIDs[po], err = db.binIDs.Get(uint64(po))\n\t\tif err != nil {\n\t\t\treturn 0, err\n\t\t}\n\t}\n\tbinIDs[po]++\n\treturn binIDs[po], nil\n}\n\n// containsChunk returns true if the chunk with a specific address\n// is present in the provided chunk slice.\nfunc containsChunk(addr swarm.Address, chs ...swarm.Chunk) bool {\n\tfor _, c := range chs {\n\t\tif addr.Equal(c.Address()) {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n", "idx": 4, "id": 14093, "msg": "", "proj": "ethersphere-bee", "lang": "go"}
{"patch": "@@ -457,6 +457,8 @@ class Automaton:\n             extfd = external_fd.get(n)\n             if type(extfd) is not tuple:\n                 extfd = (extfd,extfd)\n+            elif WINDOWS:\n+                raise OSError(\"Tuples are not allowed as external_fd on windows\")\n             ioin,ioout = extfd                \n             if ioin is None:\n                 ioin = ObjectPipe()", "y": 0, "oldf": "## This file is part of Scapy\n## See http://www.secdev.org/projects/scapy for more informations\n## Copyright (C) Philippe Biondi <phil@secdev.org>\n## This program is published under a GPLv2 license\n\n\"\"\"\nAutomata with states, transitions and actions.\n\"\"\"\n\nimport types,itertools,time,os,sys,socket,traceback\nfrom select import select\nfrom collections import deque\nimport thread\nfrom scapy.config import conf\nfrom scapy.utils import do_graph\nfrom scapy.error import log_interactive\nfrom scapy.plist import PacketList\nfrom scapy.data import MTU\nfrom scapy.supersocket import SuperSocket\n\nclass ObjectPipe:\n    def __init__(self):\n        self.rd,self.wr = os.pipe()\n        self.queue = deque()\n    def fileno(self):\n        return self.rd\n    def send(self, obj):\n        self.queue.append(obj)\n        os.write(self.wr,\"X\")\n    def recv(self, n=0):\n        os.read(self.rd,1)\n        return self.queue.popleft()\n\n\nclass Message:\n    def __init__(self, **args):\n        self.__dict__.update(args)\n    def __repr__(self):\n        return \"<Message %s>\" % \" \".join(\"%s=%r\"%(k,v)\n                                         for (k,v) in self.__dict__.iteritems()\n                                         if not k.startswith(\"_\"))\n\nclass _instance_state:\n    def __init__(self, instance):\n        self.im_self = instance.im_self\n        self.im_func = instance.im_func\n        self.im_class = instance.im_class\n    def __getattr__(self, attr):\n        return getattr(self.im_func, attr)\n\n    def __call__(self, *args, **kargs):\n        return self.im_func(self.im_self, *args, **kargs)\n    def breaks(self):\n        return self.im_self.add_breakpoints(self.im_func)\n    def intercepts(self):\n        return self.im_self.add_interception_points(self.im_func)\n    def unbreaks(self):\n        return self.im_self.remove_breakpoints(self.im_func)\n    def unintercepts(self):\n        return self.im_self.remove_interception_points(self.im_func)\n        \n\n##############\n## Automata ##\n##############\n\nclass ATMT:\n    STATE = \"State\"\n    ACTION = \"Action\"\n    CONDITION = \"Condition\"\n    RECV = \"Receive condition\"\n    TIMEOUT = \"Timeout condition\"\n    IOEVENT = \"I/O event\"\n\n    class NewStateRequested(Exception):\n        def __init__(self, state_func, automaton, *args, **kargs):\n            self.func = state_func\n            self.state = state_func.atmt_state\n            self.initial = state_func.atmt_initial\n            self.error = state_func.atmt_error\n            self.final = state_func.atmt_final\n            Exception.__init__(self, \"Request state [%s]\" % self.state)\n            self.automaton = automaton\n            self.args = args\n            self.kargs = kargs\n            self.action_parameters() # init action parameters\n        def action_parameters(self, *args, **kargs):\n            self.action_args = args\n            self.action_kargs = kargs\n            return self\n        def run(self):\n            return self.func(self.automaton, *self.args, **self.kargs)\n        def __repr__(self):\n            return \"NewStateRequested(%s)\" % self.state\n\n    @staticmethod\n    def state(initial=0,final=0,error=0):\n        def deco(f,initial=initial, final=final):\n            f.atmt_type = ATMT.STATE\n            f.atmt_state = f.func_name\n            f.atmt_initial = initial\n            f.atmt_final = final\n            f.atmt_error = error\n            def state_wrapper(self, *args, **kargs):\n                return ATMT.NewStateRequested(f, self, *args, **kargs)\n\n            state_wrapper.func_name = \"%s_wrapper\" % f.func_name\n            state_wrapper.atmt_type = ATMT.STATE\n            state_wrapper.atmt_state = f.func_name\n            state_wrapper.atmt_initial = initial\n            state_wrapper.atmt_final = final\n            state_wrapper.atmt_error = error\n            state_wrapper.atmt_origfunc = f\n            return state_wrapper\n        return deco\n    @staticmethod\n    def action(cond, prio=0):\n        def deco(f,cond=cond):\n            if not hasattr(f,\"atmt_type\"):\n                f.atmt_cond = {}\n            f.atmt_type = ATMT.ACTION\n            f.atmt_cond[cond.atmt_condname] = prio\n            return f\n        return deco\n    @staticmethod\n    def condition(state, prio=0):\n        def deco(f, state=state):\n            f.atmt_type = ATMT.CONDITION\n            f.atmt_state = state.atmt_state\n            f.atmt_condname = f.func_name\n            f.atmt_prio = prio\n            return f\n        return deco\n    @staticmethod\n    def receive_condition(state, prio=0):\n        def deco(f, state=state):\n            f.atmt_type = ATMT.RECV\n            f.atmt_state = state.atmt_state\n            f.atmt_condname = f.func_name\n            f.atmt_prio = prio\n            return f\n        return deco\n    @staticmethod\n    def ioevent(state, name, prio=0, as_supersocket=None):\n        def deco(f, state=state):\n            f.atmt_type = ATMT.IOEVENT\n            f.atmt_state = state.atmt_state\n            f.atmt_condname = f.func_name\n            f.atmt_ioname = name\n            f.atmt_prio = prio\n            f.atmt_as_supersocket = as_supersocket\n            return f\n        return deco\n    @staticmethod\n    def timeout(state, timeout):\n        def deco(f, state=state, timeout=timeout):\n            f.atmt_type = ATMT.TIMEOUT\n            f.atmt_state = state.atmt_state\n            f.atmt_timeout = timeout\n            f.atmt_condname = f.func_name\n            return f\n        return deco\n\nclass _ATMT_Command:\n    RUN = \"RUN\"\n    NEXT = \"NEXT\"\n    FREEZE = \"FREEZE\"\n    STOP = \"STOP\"\n    END = \"END\"\n    EXCEPTION = \"EXCEPTION\"\n    SINGLESTEP = \"SINGLESTEP\"\n    BREAKPOINT = \"BREAKPOINT\"\n    INTERCEPT = \"INTERCEPT\"\n    ACCEPT = \"ACCEPT\"\n    REPLACE = \"REPLACE\"\n    REJECT = \"REJECT\"\n\nclass _ATMT_supersocket(SuperSocket):\n    def __init__(self, name, ioevent, automaton, proto, args, kargs):\n        self.name = name\n        self.ioevent = ioevent\n        self.proto = proto\n        self.spa,self.spb = socket.socketpair(socket.AF_UNIX, socket.SOCK_DGRAM)\n        kargs[\"external_fd\"] = {ioevent:self.spb}\n        self.atmt = automaton(*args, **kargs)\n        self.atmt.runbg()\n    def fileno(self):\n        return self.spa.fileno()\n    def send(self, s):\n        if type(s) is not str:\n            s = str(s)\n        return self.spa.send(s)\n    def recv(self, n=MTU):\n        r = self.spa.recv(n)\n        if self.proto is not None:\n            r = self.proto(r)\n        return r\n    def close(self):\n        pass\n\nclass _ATMT_to_supersocket:\n    def __init__(self, name, ioevent, automaton):\n        self.name = name\n        self.ioevent = ioevent\n        self.automaton = automaton\n    def __call__(self, proto, *args, **kargs):\n        return _ATMT_supersocket(self.name, self.ioevent, self.automaton, proto, args, kargs)\n\nclass Automaton_metaclass(type):\n    def __new__(cls, name, bases, dct):\n        cls = super(Automaton_metaclass, cls).__new__(cls, name, bases, dct)\n        cls.states={}\n        cls.state = None\n        cls.recv_conditions={}\n        cls.conditions={}\n        cls.ioevents={}\n        cls.timeout={}\n        cls.actions={}\n        cls.initial_states=[]\n        cls.ionames = []\n        cls.iosupersockets = []\n\n        members = {}\n        classes = [cls]\n        while classes:\n            c = classes.pop(0) # order is important to avoid breaking method overloading\n            classes += list(c.__bases__)\n            for k,v in c.__dict__.iteritems():\n                if k not in members:\n                    members[k] = v\n\n        decorated = [v for v in members.itervalues()\n                     if type(v) is types.FunctionType and hasattr(v, \"atmt_type\")]\n        \n        for m in decorated:\n            if m.atmt_type == ATMT.STATE:\n                s = m.atmt_state\n                cls.states[s] = m\n                cls.recv_conditions[s]=[]\n                cls.ioevents[s]=[]\n                cls.conditions[s]=[]\n                cls.timeout[s]=[]\n                if m.atmt_initial:\n                    cls.initial_states.append(m)\n            elif m.atmt_type in [ATMT.CONDITION, ATMT.RECV, ATMT.TIMEOUT, ATMT.IOEVENT]:\n                cls.actions[m.atmt_condname] = []\n    \n        for m in decorated:\n            if m.atmt_type == ATMT.CONDITION:\n                cls.conditions[m.atmt_state].append(m)\n            elif m.atmt_type == ATMT.RECV:\n                cls.recv_conditions[m.atmt_state].append(m)\n            elif m.atmt_type == ATMT.IOEVENT:\n                cls.ioevents[m.atmt_state].append(m)\n                cls.ionames.append(m.atmt_ioname)\n                if m.atmt_as_supersocket is not None:\n                    cls.iosupersockets.append(m)\n            elif m.atmt_type == ATMT.TIMEOUT:\n                cls.timeout[m.atmt_state].append((m.atmt_timeout, m))\n            elif m.atmt_type == ATMT.ACTION:\n                for c in m.atmt_cond:\n                    cls.actions[c].append(m)\n            \n\n        for v in cls.timeout.itervalues():\n            v.sort(lambda (t1,f1),(t2,f2): cmp(t1,t2))\n            v.append((None, None))\n        for v in itertools.chain(cls.conditions.itervalues(),\n                                 cls.recv_conditions.itervalues(),\n                                 cls.ioevents.itervalues()):\n            v.sort(lambda c1,c2: cmp(c1.atmt_prio,c2.atmt_prio))\n        for condname,actlst in cls.actions.iteritems():\n            actlst.sort(lambda c1,c2: cmp(c1.atmt_cond[condname], c2.atmt_cond[condname]))\n\n        for ioev in cls.iosupersockets:\n            setattr(cls, ioev.atmt_as_supersocket, _ATMT_to_supersocket(ioev.atmt_as_supersocket, ioev.atmt_ioname, cls))\n\n        return cls\n\n    def graph(self, **kargs):\n        s = 'digraph \"%s\" {\\n'  % self.__class__.__name__\n        \n        se = \"\" # Keep initial nodes at the begining for better rendering\n        for st in self.states.itervalues():\n            if st.atmt_initial:\n                se = ('\\t\"%s\" [ style=filled, fillcolor=blue, shape=box, root=true];\\n' % st.atmt_state)+se\n            elif st.atmt_final:\n                se += '\\t\"%s\" [ style=filled, fillcolor=green, shape=octagon ];\\n' % st.atmt_state\n            elif st.atmt_error:\n                se += '\\t\"%s\" [ style=filled, fillcolor=red, shape=octagon ];\\n' % st.atmt_state\n        s += se\n\n        for st in self.states.itervalues():\n            for n in st.atmt_origfunc.func_code.co_names+st.atmt_origfunc.func_code.co_consts:\n                if n in self.states:\n                    s += '\\t\"%s\" -> \"%s\" [ color=green ];\\n' % (st.atmt_state,n)\n            \n\n        for c,k,v in ([(\"purple\",k,v) for k,v in self.conditions.items()]+\n                      [(\"red\",k,v) for k,v in self.recv_conditions.items()]+\n                      [(\"orange\",k,v) for k,v in self.ioevents.items()]):\n            for f in v:\n                for n in f.func_code.co_names+f.func_code.co_consts:\n                    if n in self.states:\n                        l = f.atmt_condname\n                        for x in self.actions[f.atmt_condname]:\n                            l += \"\\\\l>[%s]\" % x.func_name\n                        s += '\\t\"%s\" -> \"%s\" [label=\"%s\", color=%s];\\n' % (k,n,l,c)\n        for k,v in self.timeout.iteritems():\n            for t,f in v:\n                if f is None:\n                    continue\n                for n in f.func_code.co_names+f.func_code.co_consts:\n                    if n in self.states:\n                        l = \"%s/%.1fs\" % (f.atmt_condname,t)                        \n                        for x in self.actions[f.atmt_condname]:\n                            l += \"\\\\l>[%s]\" % x.func_name\n                        s += '\\t\"%s\" -> \"%s\" [label=\"%s\",color=blue];\\n' % (k,n,l)\n        s += \"}\\n\"\n        return do_graph(s, **kargs)\n        \n\n\nclass Automaton:\n    __metaclass__ = Automaton_metaclass\n\n    ## Methods to overload\n    def parse_args(self, debug=0, store=1, **kargs):\n        self.debug_level=debug\n        self.socket_kargs = kargs\n        self.store_packets = store        \n\n    def master_filter(self, pkt):\n        return True\n\n    def my_send(self, pkt):\n        self.send_sock.send(pkt)\n\n\n    ## Utility classes and exceptions\n    class _IO_fdwrapper:\n        def __init__(self,rd,wr):\n            if rd is not None and type(rd) is not int:\n                rd = rd.fileno()\n            if wr is not None and type(wr) is not int:\n                wr = wr.fileno()\n            self.rd = rd\n            self.wr = wr\n        def fileno(self):\n            return self.rd\n        def read(self, n=65535):\n            return os.read(self.rd, n)\n        def write(self, msg):\n            return os.write(self.wr,msg)\n        def recv(self, n=65535):\n            return self.read(n)        \n        def send(self, msg):\n            return self.write(msg)\n\n    class _IO_mixer:\n        def __init__(self,rd,wr):\n            self.rd = rd\n            self.wr = wr\n        def fileno(self):\n            if type(self.rd) is int:\n                return self.rd\n            return self.rd.fileno()\n        def recv(self, n=None):\n            return self.rd.recv(n)\n        def read(self, n=None):\n            return self.rd.recv(n)        \n        def send(self, msg):\n            return self.wr.send(msg)\n        def write(self, msg):\n            return self.wr.send(msg)\n\n\n    class AutomatonException(Exception):\n        def __init__(self, msg, state=None, result=None):\n            Exception.__init__(self, msg)\n            self.state = state\n            self.result = result\n\n    class AutomatonError(AutomatonException):\n        pass\n    class ErrorState(AutomatonException):\n        pass\n    class Stuck(AutomatonException):\n        pass\n    class AutomatonStopped(AutomatonException):\n        pass\n    \n    class Breakpoint(AutomatonStopped):\n        pass\n    class Singlestep(AutomatonStopped):\n        pass\n    class InterceptionPoint(AutomatonStopped):\n        def __init__(self, msg, state=None, result=None, packet=None):\n            Automaton.AutomatonStopped.__init__(self, msg, state=state, result=result)\n            self.packet = packet\n\n    class CommandMessage(AutomatonException):\n        pass\n\n\n    ## Services\n    def debug(self, lvl, msg):\n        if self.debug_level >= lvl:\n            log_interactive.debug(msg)            \n\n    def send(self, pkt):\n        if self.state.state in self.interception_points:\n            self.debug(3,\"INTERCEPT: packet intercepted: %s\" % pkt.summary())\n            self.intercepted_packet = pkt\n            cmd = Message(type = _ATMT_Command.INTERCEPT, state=self.state, pkt=pkt)\n            self.cmdout.send(cmd)\n            cmd = self.cmdin.recv()\n            self.intercepted_packet = None\n            if cmd.type == _ATMT_Command.REJECT:\n                self.debug(3,\"INTERCEPT: packet rejected\")\n                return\n            elif cmd.type == _ATMT_Command.REPLACE:\n                pkt = cmd.pkt\n                self.debug(3,\"INTERCEPT: packet replaced by: %s\" % pkt.summary())\n            elif cmd.type == _ATMT_Command.ACCEPT:\n                self.debug(3,\"INTERCEPT: packet accepted\")\n            else:\n                raise self.AutomatonError(\"INTERCEPT: unkown verdict: %r\" % cmd.type)\n        self.my_send(pkt)\n        self.debug(3,\"SENT : %s\" % pkt.summary())\n        \n        if self.store_packets:\n            self.packets.append(pkt.copy())\n\n\n    ## Internals\n    def __init__(self, *args, **kargs):\n        external_fd = kargs.pop(\"external_fd\",{})\n        self.send_sock_class = kargs.pop(\"ll\", conf.L3socket)\n        self.recv_sock_class = kargs.pop(\"recvsock\", conf.L2listen)\n        self.started = thread.allocate_lock()\n        self.threadid = None\n        self.breakpointed = None\n        self.breakpoints = set()\n        self.interception_points = set()\n        self.intercepted_packet = None\n        self.debug_level=0\n        self.init_args=args\n        self.init_kargs=kargs\n        self.io = type.__new__(type, \"IOnamespace\",(),{})\n        self.oi = type.__new__(type, \"IOnamespace\",(),{})\n        self.cmdin = ObjectPipe()\n        self.cmdout = ObjectPipe()\n        self.ioin = {}\n        self.ioout = {}\n        for n in self.ionames:\n            extfd = external_fd.get(n)\n            if type(extfd) is not tuple:\n                extfd = (extfd,extfd)\n            ioin,ioout = extfd                \n            if ioin is None:\n                ioin = ObjectPipe()\n            elif type(ioin) is not types.InstanceType:\n                ioin = self._IO_fdwrapper(ioin,None)\n            if ioout is None:\n                ioout = ObjectPipe()\n            elif type(ioout) is not types.InstanceType:\n                ioout = self._IO_fdwrapper(None,ioout)\n\n            self.ioin[n] = ioin\n            self.ioout[n] = ioout \n            ioin.ioname = n\n            ioout.ioname = n\n            setattr(self.io, n, self._IO_mixer(ioout,ioin))\n            setattr(self.oi, n, self._IO_mixer(ioin,ioout))\n\n        for stname in self.states:\n            setattr(self, stname, \n                    _instance_state(getattr(self, stname)))\n        \n        self.parse_args(*args, **kargs)\n\n        self.start()\n\n    def __iter__(self):\n        return self        \n\n    def __del__(self):\n        self.stop()\n\n    def _run_condition(self, cond, *args, **kargs):\n        try:\n            self.debug(5, \"Trying %s [%s]\" % (cond.atmt_type, cond.atmt_condname))\n            cond(self,*args, **kargs)\n        except ATMT.NewStateRequested, state_req:\n            self.debug(2, \"%s [%s] taken to state [%s]\" % (cond.atmt_type, cond.atmt_condname, state_req.state))\n            if cond.atmt_type == ATMT.RECV:\n                if self.store_packets:\n                    self.packets.append(args[0])\n            for action in self.actions[cond.atmt_condname]:\n                self.debug(2, \"   + Running action [%s]\" % action.func_name)\n                action(self, *state_req.action_args, **state_req.action_kargs)\n            raise\n        except Exception,e:\n            self.debug(2, \"%s [%s] raised exception [%s]\" % (cond.atmt_type, cond.atmt_condname, e))\n            raise\n        else:\n            self.debug(2, \"%s [%s] not taken\" % (cond.atmt_type, cond.atmt_condname))\n\n    def _do_start(self, *args, **kargs):\n        \n        thread.start_new_thread(self._do_control, args, kargs)\n\n\n    def _do_control(self, *args, **kargs):\n        with self.started:\n            self.threadid = thread.get_ident()\n\n            # Update default parameters\n            a = args+self.init_args[len(args):]\n            k = self.init_kargs.copy()\n            k.update(kargs)\n            self.parse_args(*a,**k)\n    \n            # Start the automaton\n            self.state=self.initial_states[0](self)\n            self.send_sock = self.send_sock_class()\n            self.listen_sock = self.recv_sock_class(**self.socket_kargs)\n            self.packets = PacketList(name=\"session[%s]\"%self.__class__.__name__)\n\n            singlestep = True\n            iterator = self._do_iter()\n            self.debug(3, \"Starting control thread [tid=%i]\" % self.threadid)\n            try:\n                while True:\n                    c = self.cmdin.recv()\n                    self.debug(5, \"Received command %s\" % c.type)\n                    if c.type == _ATMT_Command.RUN:\n                        singlestep = False\n                    elif c.type == _ATMT_Command.NEXT:\n                        singlestep = True\n                    elif c.type == _ATMT_Command.FREEZE:\n                        continue\n                    elif c.type == _ATMT_Command.STOP:\n                        break\n                    while True:\n                        state = iterator.next()\n                        if isinstance(state, self.CommandMessage):\n                            break\n                        elif isinstance(state, self.Breakpoint):\n                            c = Message(type=_ATMT_Command.BREAKPOINT,state=state)\n                            self.cmdout.send(c)\n                            break\n                        if singlestep:\n                            c = Message(type=_ATMT_Command.SINGLESTEP,state=state)\n                            self.cmdout.send(c)\n                            break\n            except StopIteration,e:\n                c = Message(type=_ATMT_Command.END, result=e.args[0])\n                self.cmdout.send(c)\n            except Exception,e:\n                exc_info = sys.exc_info()\n                self.debug(3, \"Transfering exception from tid=%i:\\n%s\"% (self.threadid, traceback.format_exc(exc_info)))\n                m = Message(type=_ATMT_Command.EXCEPTION, exception=e, exc_info=exc_info)\n                self.cmdout.send(m)        \n            self.debug(3, \"Stopping control thread (tid=%i)\"%self.threadid)\n            self.threadid = None\n    \n    def _do_iter(self):\n        while True:\n            try:\n                self.debug(1, \"## state=[%s]\" % self.state.state)\n    \n                # Entering a new state. First, call new state function\n                if self.state.state in self.breakpoints and self.state.state != self.breakpointed: \n                    self.breakpointed = self.state.state\n                    yield self.Breakpoint(\"breakpoint triggered on state %s\" % self.state.state,\n                                          state = self.state.state)\n                self.breakpointed = None\n                state_output = self.state.run()\n                if self.state.error:\n                    raise self.ErrorState(\"Reached %s: [%r]\" % (self.state.state, state_output), \n                                          result=state_output, state=self.state.state)\n                if self.state.final:\n                    raise StopIteration(state_output)\n    \n                if state_output is None:\n                    state_output = ()\n                elif type(state_output) is not list:\n                    state_output = state_output,\n                \n                # Then check immediate conditions\n                for cond in self.conditions[self.state.state]:\n                    self._run_condition(cond, *state_output)\n    \n                # If still there and no conditions left, we are stuck!\n                if ( len(self.recv_conditions[self.state.state]) == 0 and\n                     len(self.ioevents[self.state.state]) == 0 and\n                     len(self.timeout[self.state.state]) == 1 ):\n                    raise self.Stuck(\"stuck in [%s]\" % self.state.state,\n                                     state=self.state.state, result=state_output)\n    \n                # Finally listen and pay attention to timeouts\n                expirations = iter(self.timeout[self.state.state])\n                next_timeout,timeout_func = expirations.next()\n                t0 = time.time()\n                \n                fds = [self.cmdin]\n                if len(self.recv_conditions[self.state.state]) > 0:\n                    fds.append(self.listen_sock)\n                for ioev in self.ioevents[self.state.state]:\n                    fds.append(self.ioin[ioev.atmt_ioname])\n                while 1:\n                    t = time.time()-t0\n                    if next_timeout is not None:\n                        if next_timeout <= t:\n                            self._run_condition(timeout_func, *state_output)\n                            next_timeout,timeout_func = expirations.next()\n                    if next_timeout is None:\n                        remain = None\n                    else:\n                        remain = next_timeout-t\n    \n                    self.debug(5, \"Select on %r\" % fds)\n                    r,_,_ = select(fds,[],[],remain)\n                    self.debug(5, \"Selected %r\" % r)\n                    for fd in r:\n                        self.debug(5, \"Looking at %r\" % fd)\n                        if fd == self.cmdin:\n                            yield self.CommandMessage(\"Received command message\")\n                        elif fd == self.listen_sock:\n                            pkt = self.listen_sock.recv(MTU)\n                            if pkt is not None:\n                                if self.master_filter(pkt):\n                                    self.debug(3, \"RECVD: %s\" % pkt.summary())\n                                    for rcvcond in self.recv_conditions[self.state.state]:\n                                        self._run_condition(rcvcond, pkt, *state_output)\n                                else:\n                                    self.debug(4, \"FILTR: %s\" % pkt.summary())\n                        else:\n                            self.debug(3, \"IOEVENT on %s\" % fd.ioname)\n                            for ioevt in self.ioevents[self.state.state]:\n                                if ioevt.atmt_ioname == fd.ioname:\n                                    self._run_condition(ioevt, fd, *state_output)\n    \n            except ATMT.NewStateRequested,state_req:\n                self.debug(2, \"switching from [%s] to [%s]\" % (self.state.state,state_req.state))\n                self.state = state_req\n                yield state_req\n\n    ## Public API\n    def add_interception_points(self, *ipts):\n        for ipt in ipts:\n            if hasattr(ipt,\"atmt_state\"):\n                ipt = ipt.atmt_state\n            self.interception_points.add(ipt)\n        \n    def remove_interception_points(self, *ipts):\n        for ipt in ipts:\n            if hasattr(ipt,\"atmt_state\"):\n                ipt = ipt.atmt_state\n            self.interception_points.discard(ipt)\n\n    def add_breakpoints(self, *bps):\n        for bp in bps:\n            if hasattr(bp,\"atmt_state\"):\n                bp = bp.atmt_state\n            self.breakpoints.add(bp)\n\n    def remove_breakpoints(self, *bps):\n        for bp in bps:\n            if hasattr(bp,\"atmt_state\"):\n                bp = bp.atmt_state\n            self.breakpoints.discard(bp)\n\n    def start(self, *args, **kargs):\n        if not self.started.locked():\n            self._do_start(*args, **kargs)\n        \n    def run(self, resume=None, wait=True):\n        if resume is None:\n            resume = Message(type = _ATMT_Command.RUN)\n        self.cmdin.send(resume)\n        if wait:\n            try:\n                c = self.cmdout.recv()\n            except KeyboardInterrupt:\n                self.cmdin.send(Message(type = _ATMT_Command.FREEZE))\n                return\n            if c.type == _ATMT_Command.END:\n                return c.result\n            elif c.type == _ATMT_Command.INTERCEPT:\n                raise self.InterceptionPoint(\"packet intercepted\", state=c.state.state, packet=c.pkt)\n            elif c.type == _ATMT_Command.SINGLESTEP:\n                raise self.Singlestep(\"singlestep state=[%s]\"%c.state.state, state=c.state.state)\n            elif c.type == _ATMT_Command.BREAKPOINT:\n                raise self.Breakpoint(\"breakpoint triggered on state [%s]\"%c.state.state, state=c.state.state)\n            elif c.type == _ATMT_Command.EXCEPTION:\n                raise c.exc_info[0],c.exc_info[1],c.exc_info[2]\n\n    def runbg(self, resume=None, wait=False):\n        self.run(resume, wait)\n\n    def next(self):\n        return self.run(resume = Message(type=_ATMT_Command.NEXT))\n\n    def stop(self):\n        self.cmdin.send(Message(type=_ATMT_Command.STOP))\n        with self.started:\n            # Flush command pipes\n            while True:\n                r,_,_ = select([self.cmdin, self.cmdout],[],[],0)\n                if not r:\n                    break\n                for fd in r:\n                    fd.recv()\n                \n    def restart(self, *args, **kargs):\n        self.stop()\n        self.start(*args, **kargs)\n\n    def accept_packet(self, pkt=None, wait=False):\n        rsm = Message()\n        if pkt is None:\n            rsm.type = _ATMT_Command.ACCEPT\n        else:\n            rsm.type = _ATMT_Command.REPLACE\n            rsm.pkt = pkt\n        return self.run(resume=rsm, wait=wait)\n\n    def reject_packet(self, wait=False):\n        rsm = Message(type = _ATMT_Command.REJECT)\n        return self.run(resume=rsm, wait=wait)\n\n    \n\n", "idx": 8, "id": 9378, "msg": "", "proj": "secdev-scapy", "lang": "py"}
{"patch": "@@ -946,7 +946,7 @@ int main (int argc, char * const * argv)\n \t\t\t\t            .balance (balances[i])\n \t\t\t\t            .link (genesis_latest)\n \t\t\t\t            .sign (keys[i].prv, keys[i].pub)\n-\t\t\t\t            .work (*work.generate (nano::work_version::work_1, keys[i].pub, node->network_params.network.publish_thresholds.epoch_1))\n+\t\t\t\t            .work (*node->work.generate (nano::work_version::work_1, keys[i].pub, node->network_params.network.publish_thresholds.epoch_1))\n \t\t\t\t            .build ();\n \n \t\t\t\tfrontiers[i] = open->hash ();", "y": 0, "oldf": "#include <nano/crypto_lib/random_pool.hpp>\n#include <nano/lib/cli.hpp>\n#include <nano/lib/utility.hpp>\n#include <nano/nano_node/daemon.hpp>\n#include <nano/node/cli.hpp>\n#include <nano/node/daemonconfig.hpp>\n#include <nano/node/ipc/ipc_server.hpp>\n#include <nano/node/json_handler.hpp>\n#include <nano/node/node.hpp>\n\n#include <boost/dll/runtime_symbol_info.hpp>\n#include <boost/filesystem/operations.hpp>\n#include <boost/format.hpp>\n#include <boost/lexical_cast.hpp>\n#include <boost/program_options.hpp>\n#include <boost/range/adaptor/reversed.hpp>\n#include <boost/unordered_map.hpp>\n#include <boost/unordered_set.hpp>\n\n#include <numeric>\n#include <sstream>\n\n#include <argon2.h>\n\n// Some builds (mac) fail due to \"Boost.Stacktrace requires `_Unwind_Backtrace` function\".\n#ifndef _WIN32\n#ifdef NANO_STACKTRACE_BACKTRACE\n#define BOOST_STACKTRACE_USE_BACKTRACE\n#endif\n#ifndef _GNU_SOURCE\n#define BEFORE_GNU_SOURCE 0\n#define _GNU_SOURCE\n#else\n#define BEFORE_GNU_SOURCE 1\n#endif\n#endif\n#include <boost/stacktrace.hpp>\n#ifndef _WIN32\n#if !BEFORE_GNU_SOURCE\n#undef _GNU_SOURCE\n#endif\n#endif\n\nnamespace\n{\nclass uint64_from_hex // For use with boost::lexical_cast to read hexadecimal strings\n{\npublic:\n\tuint64_t value;\n};\nstd::istream & operator>> (std::istream & in, uint64_from_hex & out_val);\n\nclass address_library_pair\n{\npublic:\n\tuint64_t address;\n\tstd::string library;\n\n\taddress_library_pair (uint64_t address, std::string library);\n\tbool operator< (const address_library_pair & other) const;\n\tbool operator== (const address_library_pair & other) const;\n};\n}\n\nint main (int argc, char * const * argv)\n{\n\tnano::set_umask ();\n\tnano::node_singleton_memory_pool_purge_guard memory_pool_cleanup_guard;\n\tboost::program_options::options_description description (\"Command line options\");\n\t// clang-format off\n\tdescription.add_options ()\n\t\t(\"help\", \"Print out options\")\n\t\t(\"version\", \"Prints out version\")\n\t\t(\"config\", boost::program_options::value<std::vector<nano::config_key_value_pair>>()->multitoken(), \"Pass node configuration values. This takes precedence over any values in the configuration file. This option can be repeated multiple times.\")\n\t\t(\"daemon\", \"Start node daemon\")\n\t\t(\"compare_rep_weights\", \"Display a summarized comparison between the hardcoded bootstrap weights and representative weights from the ledger. Full comparison is output to logs\")\n\t\t(\"debug_block_count\", \"Display the number of blocks\")\n\t\t(\"debug_bootstrap_generate\", \"Generate bootstrap sequence of blocks\")\n\t\t(\"debug_dump_frontier_unchecked_dependents\", \"Dump frontiers which have matching unchecked keys\")\n\t\t(\"debug_dump_trended_weight\", \"Dump trended weights table\")\n\t\t(\"debug_dump_representatives\", \"List representatives and weights\")\n\t\t(\"debug_account_count\", \"Display the number of accounts\")\n\t\t(\"debug_profile_generate\", \"Profile work generation\")\n\t\t(\"debug_profile_validate\", \"Profile work validation\")\n\t\t(\"debug_opencl\", \"OpenCL work generation\")\n\t\t(\"debug_profile_kdf\", \"Profile kdf function\")\n\t\t(\"debug_output_last_backtrace_dump\", \"Displays the contents of the latest backtrace in the event of a nano_node crash\")\n\t\t(\"debug_generate_crash_report\", \"Consolidates the nano_node_backtrace.dump file. Requires addr2line installed on Linux\")\n\t\t(\"debug_sys_logging\", \"Test the system logger\")\n\t\t(\"debug_verify_profile\", \"Profile signature verification\")\n\t\t(\"debug_verify_profile_batch\", \"Profile batch signature verification\")\n\t\t(\"debug_profile_bootstrap\", \"Profile bootstrap style blocks processing (at least 10GB of free storage space required)\")\n\t\t(\"debug_profile_sign\", \"Profile signature generation\")\n\t\t(\"debug_profile_process\", \"Profile active blocks processing (only for nano_dev_network)\")\n\t\t(\"debug_profile_votes\", \"Profile votes processing (only for nano_dev_network)\")\n\t\t(\"debug_profile_frontiers_confirmation\", \"Profile frontiers confirmation speed (only for nano_dev_network)\")\n\t\t(\"debug_random_feed\", \"Generates output to RNG test suites\")\n\t\t(\"debug_rpc\", \"Read an RPC command from stdin and invoke it. Network operations will have no effect.\")\n\t\t(\"debug_peers\", \"Display peer IPv6:port connections\")\n\t\t(\"debug_cemented_block_count\", \"Displays the number of cemented (confirmed) blocks\")\n\t\t(\"debug_stacktrace\", \"Display an example stacktrace\")\n\t\t(\"debug_account_versions\", \"Display the total counts of each version for all accounts (including unpocketed)\")\n\t\t(\"debug_unconfirmed_frontiers\", \"Displays the account, height (sorted), frontier and cemented frontier for all accounts which are not fully confirmed\")\n\t\t(\"validate_blocks,debug_validate_blocks\", \"Check all blocks for correct hash, signature, work value\")\n\t\t(\"debug_prune\", \"Prune accounts up to last confirmed blocks (EXPERIMENTAL)\")\n\t\t(\"platform\", boost::program_options::value<std::string> (), \"Defines the <platform> for OpenCL commands\")\n\t\t(\"device\", boost::program_options::value<std::string> (), \"Defines <device> for OpenCL command\")\n\t\t(\"threads\", boost::program_options::value<std::string> (), \"Defines <threads> count for various commands\")\n\t\t(\"difficulty\", boost::program_options::value<std::string> (), \"Defines <difficulty> for OpenCL command, HEX\")\n\t\t(\"multiplier\", boost::program_options::value<std::string> (), \"Defines <multiplier> for work generation. Overrides <difficulty>\")\n\t\t(\"count\", boost::program_options::value<std::string> (), \"Defines <count> for various commands\")\n\t\t(\"pow_sleep_interval\", boost::program_options::value<std::string> (), \"Defines the amount to sleep inbetween each pow calculation attempt\")\n\t\t(\"address_column\", boost::program_options::value<std::string> (), \"Defines which column the addresses are located, 0 indexed (check --debug_output_last_backtrace_dump output)\")\n\t\t(\"silent\", \"Silent command execution\");\n\t// clang-format on\n\tnano::add_node_options (description);\n\tnano::add_node_flag_options (description);\n\tboost::program_options::variables_map vm;\n\ttry\n\t{\n\t\tboost::program_options::store (boost::program_options::parse_command_line (argc, argv, description), vm);\n\t}\n\tcatch (boost::program_options::error const & err)\n\t{\n\t\tstd::cerr << err.what () << std::endl;\n\t\treturn 1;\n\t}\n\tboost::program_options::notify (vm);\n\tint result (0);\n\n\tauto network (vm.find (\"network\"));\n\tif (network != vm.end ())\n\t{\n\t\tauto err (nano::network_constants::set_active_network (network->second.as<std::string> ()));\n\t\tif (err)\n\t\t{\n\t\t\tstd::cerr << nano::network_constants::active_network_err_msg << std::endl;\n\t\t\tstd::exit (1);\n\t\t}\n\t}\n\n\tauto data_path_it = vm.find (\"data_path\");\n\tif (data_path_it == vm.end ())\n\t{\n\t\tstd::string error_string;\n\t\tif (!nano::migrate_working_path (error_string))\n\t\t{\n\t\t\tstd::cerr << error_string << std::endl;\n\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tboost::filesystem::path data_path ((data_path_it != vm.end ()) ? data_path_it->second.as<std::string> () : nano::working_path ());\n\tauto ec = nano::handle_node_options (vm);\n\tif (ec == nano::error_cli::unknown_command)\n\t{\n\t\tif (vm.count (\"daemon\") > 0)\n\t\t{\n\t\t\tnano_daemon::daemon daemon;\n\t\t\tnano::node_flags flags;\n\t\t\tauto flags_ec = nano::update_flags (flags, vm);\n\t\t\tif (flags_ec)\n\t\t\t{\n\t\t\t\tstd::cerr << flags_ec.message () << std::endl;\n\t\t\t\tstd::exit (1);\n\t\t\t}\n\t\t\tdaemon.run (data_path, flags);\n\t\t}\n\t\telse if (vm.count (\"compare_rep_weights\"))\n\t\t{\n\t\t\tif (!nano::network_constants ().is_dev_network ())\n\t\t\t{\n\t\t\t\tauto node_flags = nano::inactive_node_flag_defaults ();\n\t\t\t\tnano::update_flags (node_flags, vm);\n\t\t\t\tnode_flags.generate_cache.reps = true;\n\t\t\t\tnano::inactive_node inactive_node (data_path, node_flags);\n\t\t\t\tauto node = inactive_node.node;\n\n\t\t\t\tauto const bootstrap_weights = node->get_bootstrap_weights ();\n\t\t\t\tauto const & hardcoded = bootstrap_weights.second;\n\t\t\t\tauto const hardcoded_height = bootstrap_weights.first;\n\t\t\t\tauto const ledger_unfiltered = node->ledger.cache.rep_weights.get_rep_amounts ();\n\t\t\t\tauto const ledger_height = node->ledger.cache.block_count.load ();\n\n\t\t\t\tauto get_total = [](decltype (bootstrap_weights.second) const & reps) -> nano::uint128_union {\n\t\t\t\t\treturn std::accumulate (reps.begin (), reps.end (), nano::uint128_t{ 0 }, [](auto sum, auto const & rep) { return sum + rep.second; });\n\t\t\t\t};\n\n\t\t\t\t// Hardcoded weights are filtered to a cummulative weight of 99%, need to do the same for ledger weights\n\t\t\t\tstd::remove_const_t<decltype (ledger_unfiltered)> ledger;\n\t\t\t\t{\n\t\t\t\t\tstd::vector<std::pair<nano::account, nano::uint128_t>> sorted;\n\t\t\t\t\tsorted.reserve (ledger_unfiltered.size ());\n\t\t\t\t\tstd::copy (ledger_unfiltered.begin (), ledger_unfiltered.end (), std::back_inserter (sorted));\n\t\t\t\t\tstd::sort (sorted.begin (), sorted.end (), [](auto const & left, auto const & right) { return left.second > right.second; });\n\t\t\t\t\tauto const total_unfiltered = get_total (ledger_unfiltered);\n\t\t\t\t\tnano::uint128_t sum{ 0 };\n\t\t\t\t\tauto target = (total_unfiltered.number () / 100) * 99;\n\t\t\t\t\tfor (auto i (sorted.begin ()), n (sorted.end ()); i != n && sum <= target; sum += i->second, ++i)\n\t\t\t\t\t{\n\t\t\t\t\t\tledger.insert (*i);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tauto const total_ledger = get_total (ledger);\n\t\t\t\tauto const total_hardcoded = get_total (hardcoded);\n\n\t\t\t\tstruct mismatched_t\n\t\t\t\t{\n\t\t\t\t\tnano::account rep;\n\t\t\t\t\tnano::uint128_union hardcoded;\n\t\t\t\t\tnano::uint128_union ledger;\n\t\t\t\t\tnano::uint128_union diff;\n\t\t\t\t\tstd::string get_entry () const\n\t\t\t\t\t{\n\t\t\t\t\t\treturn boost::str (boost::format (\"representative %1% hardcoded %2% ledger %3% mismatch %4%\")\n\t\t\t\t\t\t% rep.to_account () % hardcoded.format_balance (nano::Mxrb_ratio, 0, true) % ledger.format_balance (nano::Mxrb_ratio, 0, true) % diff.format_balance (nano::Mxrb_ratio, 0, true));\n\t\t\t\t\t}\n\t\t\t\t};\n\n\t\t\t\tstd::vector<mismatched_t> mismatched;\n\t\t\t\tmismatched.reserve (hardcoded.size ());\n\t\t\t\tstd::transform (hardcoded.begin (), hardcoded.end (), std::back_inserter (mismatched), [&ledger](auto const & rep) {\n\t\t\t\t\tauto ledger_rep (ledger.find (rep.first));\n\t\t\t\t\tnano::uint128_t ledger_weight = (ledger_rep == ledger.end () ? 0 : ledger_rep->second);\n\t\t\t\t\tauto absolute = ledger_weight > rep.second ? ledger_weight - rep.second : rep.second - ledger_weight;\n\t\t\t\t\treturn mismatched_t{ rep.first, rep.second, ledger_weight, absolute };\n\t\t\t\t});\n\n\t\t\t\t// Sort by descending difference\n\t\t\t\tstd::sort (mismatched.begin (), mismatched.end (), [](mismatched_t const & left, mismatched_t const & right) { return left.diff > right.diff; });\n\n\t\t\t\tnano::uint128_union const mismatch_total = std::accumulate (mismatched.begin (), mismatched.end (), nano::uint128_t{ 0 }, [](auto sum, mismatched_t const & sample) { return sum + sample.diff.number (); });\n\t\t\t\tnano::uint128_union const mismatch_mean = mismatch_total.number () / mismatched.size ();\n\n\t\t\t\tnano::uint512_union mismatch_variance = std::accumulate (mismatched.begin (), mismatched.end (), nano::uint512_t (0), [M = mismatch_mean.number (), N = mismatched.size ()](nano::uint512_t sum, mismatched_t const & sample) {\n\t\t\t\t\tauto x = sample.diff.number ();\n\t\t\t\t\tnano::uint512_t const mean_diff = x > M ? x - M : M - x;\n\t\t\t\t\tnano::uint512_t const sqr = mean_diff * mean_diff;\n\t\t\t\t\treturn sum + sqr;\n\t\t\t\t})\n\t\t\t\t/ mismatched.size ();\n\n\t\t\t\tnano::uint128_union const mismatch_stddev = nano::narrow_cast<nano::uint128_t> (boost::multiprecision::sqrt (mismatch_variance.number ()));\n\n\t\t\t\tauto const outlier_threshold = std::max (nano::Gxrb_ratio, mismatch_mean.number () + 1 * mismatch_stddev.number ());\n\t\t\t\tdecltype (mismatched) outliers;\n\t\t\t\tstd::copy_if (mismatched.begin (), mismatched.end (), std::back_inserter (outliers), [outlier_threshold](mismatched_t const & sample) {\n\t\t\t\t\treturn sample.diff > outlier_threshold;\n\t\t\t\t});\n\n\t\t\t\tauto const newcomer_threshold = std::max (nano::Gxrb_ratio, mismatch_mean.number ());\n\t\t\t\tstd::vector<std::pair<nano::account, nano::uint128_t>> newcomers;\n\t\t\t\tstd::copy_if (ledger.begin (), ledger.end (), std::back_inserter (newcomers), [&hardcoded](auto const & rep) {\n\t\t\t\t\treturn !hardcoded.count (rep.first) && rep.second;\n\t\t\t\t});\n\n\t\t\t\t// Sort by descending weight\n\t\t\t\tstd::sort (newcomers.begin (), newcomers.end (), [](auto const & left, auto const & right) { return left.second > right.second; });\n\n\t\t\t\tauto newcomer_entry = [](auto const & rep) {\n\t\t\t\t\treturn boost::str (boost::format (\"representative %1% hardcoded --- ledger %2%\") % rep.first.to_account () % nano::uint128_union (rep.second).format_balance (nano::Mxrb_ratio, 0, true));\n\t\t\t\t};\n\n\t\t\t\tstd::cout << boost::str (boost::format (\"hardcoded weight %1% Mnano at %2% blocks\\nledger weight %3% Mnano at %4% blocks\\nmismatched\\n\\tsamples %5%\\n\\ttotal %6% Mnano\\n\\tmean %7% Mnano\\n\\tsigma %8% Mnano\\n\")\n\t\t\t\t% total_hardcoded.format_balance (nano::Mxrb_ratio, 0, true)\n\t\t\t\t% hardcoded_height\n\t\t\t\t% total_ledger.format_balance (nano::Mxrb_ratio, 0, true)\n\t\t\t\t% ledger_height\n\t\t\t\t% mismatched.size ()\n\t\t\t\t% mismatch_total.format_balance (nano::Mxrb_ratio, 0, true)\n\t\t\t\t% mismatch_mean.format_balance (nano::Mxrb_ratio, 0, true)\n\t\t\t\t% mismatch_stddev.format_balance (nano::Mxrb_ratio, 0, true));\n\n\t\t\t\tif (!outliers.empty ())\n\t\t\t\t{\n\t\t\t\t\tstd::cout << \"outliers\\n\";\n\t\t\t\t\tfor (auto const & outlier : outliers)\n\t\t\t\t\t{\n\t\t\t\t\t\tstd::cout << '\\t' << outlier.get_entry () << '\\n';\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (!newcomers.empty ())\n\t\t\t\t{\n\t\t\t\t\tstd::cout << \"newcomers\\n\";\n\t\t\t\t\tfor (auto const & newcomer : newcomers)\n\t\t\t\t\t{\n\t\t\t\t\t\tif (newcomer.second > newcomer_threshold)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tstd::cout << '\\t' << newcomer_entry (newcomer) << '\\n';\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Log more data\n\t\t\t\tauto const log_threshold = nano::Gxrb_ratio;\n\t\t\t\tfor (auto const & sample : mismatched)\n\t\t\t\t{\n\t\t\t\t\tif (sample.diff > log_threshold)\n\t\t\t\t\t{\n\t\t\t\t\t\tnode->logger.always_log (sample.get_entry ());\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfor (auto const & newcomer : newcomers)\n\t\t\t\t{\n\t\t\t\t\tif (newcomer.second > log_threshold)\n\t\t\t\t\t{\n\t\t\t\t\t\tnode->logger.always_log (newcomer_entry (newcomer));\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tstd::cout << \"Not available for the test network\" << std::endl;\n\t\t\t\tresult = -1;\n\t\t\t}\n\t\t}\n\t\telse if (vm.count (\"debug_block_count\"))\n\t\t{\n\t\t\tauto node_flags = nano::inactive_node_flag_defaults ();\n\t\t\tnano::update_flags (node_flags, vm);\n\t\t\tnode_flags.generate_cache.block_count = true;\n\t\t\tnano::inactive_node inactive_node (data_path, node_flags);\n\t\t\tauto node = inactive_node.node;\n\t\t\tstd::cout << boost::str (boost::format (\"Block count: %1%\\n\") % node->ledger.cache.block_count);\n\t\t}\n\t\telse if (vm.count (\"debug_bootstrap_generate\"))\n\t\t{\n\t\t\tauto key_it = vm.find (\"key\");\n\t\t\tif (key_it != vm.end ())\n\t\t\t{\n\t\t\t\tnano::uint256_union key;\n\t\t\t\tif (!key.decode_hex (key_it->second.as<std::string> ()))\n\t\t\t\t{\n\t\t\t\t\tnano::keypair genesis (key.to_string ());\n\t\t\t\t\tnano::work_pool work (std::numeric_limits<unsigned>::max ());\n\t\t\t\t\tstd::cout << \"Genesis: \" << genesis.prv.data.to_string () << \"\\n\"\n\t\t\t\t\t          << \"Public: \" << genesis.pub.to_string () << \"\\n\"\n\t\t\t\t\t          << \"Account: \" << genesis.pub.to_account () << \"\\n\";\n\t\t\t\t\tnano::keypair landing;\n\t\t\t\t\tstd::cout << \"Landing: \" << landing.prv.data.to_string () << \"\\n\"\n\t\t\t\t\t          << \"Public: \" << landing.pub.to_string () << \"\\n\"\n\t\t\t\t\t          << \"Account: \" << landing.pub.to_account () << \"\\n\";\n\t\t\t\t\tfor (auto i (0); i != 32; ++i)\n\t\t\t\t\t{\n\t\t\t\t\t\tnano::keypair rep;\n\t\t\t\t\t\tstd::cout << \"Rep\" << i << \": \" << rep.prv.data.to_string () << \"\\n\"\n\t\t\t\t\t\t          << \"Public: \" << rep.pub.to_string () << \"\\n\"\n\t\t\t\t\t\t          << \"Account: \" << rep.pub.to_account () << \"\\n\";\n\t\t\t\t\t}\n\t\t\t\t\tnano::network_constants network_constants;\n\t\t\t\t\tnano::uint128_t balance (std::numeric_limits<nano::uint128_t>::max ());\n\t\t\t\t\tnano::open_block genesis_block (reinterpret_cast<const nano::block_hash &> (genesis.pub), genesis.pub, genesis.pub, genesis.prv, genesis.pub, *work.generate (nano::work_version::work_1, genesis.pub, network_constants.publish_thresholds.epoch_1));\n\t\t\t\t\tstd::cout << genesis_block.to_json ();\n\t\t\t\t\tstd::cout.flush ();\n\t\t\t\t\tnano::block_hash previous (genesis_block.hash ());\n\t\t\t\t\tfor (auto i (0); i != 8; ++i)\n\t\t\t\t\t{\n\t\t\t\t\t\tnano::uint128_t yearly_distribution (nano::uint128_t (1) << (127 - (i == 7 ? 6 : i)));\n\t\t\t\t\t\tauto weekly_distribution (yearly_distribution / 52);\n\t\t\t\t\t\tfor (auto j (0); j != 52; ++j)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tdebug_assert (balance > weekly_distribution);\n\t\t\t\t\t\t\tbalance = balance < (weekly_distribution * 2) ? 0 : balance - weekly_distribution;\n\t\t\t\t\t\t\tnano::send_block send (previous, landing.pub, balance, genesis.prv, genesis.pub, *work.generate (nano::work_version::work_1, previous, network_constants.publish_thresholds.epoch_1));\n\t\t\t\t\t\t\tprevious = send.hash ();\n\t\t\t\t\t\t\tstd::cout << send.to_json ();\n\t\t\t\t\t\t\tstd::cout.flush ();\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tstd::cerr << \"Invalid key\\n\";\n\t\t\t\t\tresult = -1;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tstd::cerr << \"Bootstrapping requires one <key> option\\n\";\n\t\t\t\tresult = -1;\n\t\t\t}\n\t\t}\n\t\telse if (vm.count (\"debug_dump_trended_weight\"))\n\t\t{\n\t\t\tauto inactive_node = nano::default_inactive_node (data_path, vm);\n\t\t\tauto node = inactive_node->node;\n\t\t\tauto current (node->online_reps.trended ());\n\t\t\tstd::cout << boost::str (boost::format (\"Trended Weight %1%\\n\") % current);\n\t\t\tauto transaction (node->store.tx_begin_read ());\n\t\t\tfor (auto i (node->store.online_weight_begin (transaction)), n (node->store.online_weight_end ()); i != n; ++i)\n\t\t\t{\n\t\t\t\tusing time_point = std::chrono::system_clock::time_point;\n\t\t\t\ttime_point ts (std::chrono::duration_cast<time_point::duration> (std::chrono::nanoseconds (i->first)));\n\t\t\t\tstd::time_t timestamp = std::chrono::system_clock::to_time_t (ts);\n\t\t\t\tstd::string weight;\n\t\t\t\ti->second.encode_dec (weight);\n\t\t\t\tstd::cout << boost::str (boost::format (\"Timestamp %1% Weight %2%\\n\") % ctime (&timestamp) % weight);\n\t\t\t}\n\t\t}\n\t\telse if (vm.count (\"debug_dump_representatives\"))\n\t\t{\n\t\t\tauto node_flags = nano::inactive_node_flag_defaults ();\n\t\t\tnano::update_flags (node_flags, vm);\n\t\t\tnode_flags.generate_cache.reps = true;\n\t\t\tnano::inactive_node inactive_node (data_path, node_flags);\n\t\t\tauto node = inactive_node.node;\n\t\t\tauto transaction (node->store.tx_begin_read ());\n\t\t\tnano::uint128_t total;\n\t\t\tauto rep_amounts = node->ledger.cache.rep_weights.get_rep_amounts ();\n\t\t\tstd::map<nano::account, nano::uint128_t> ordered_reps (rep_amounts.begin (), rep_amounts.end ());\n\t\t\tfor (auto const & rep : ordered_reps)\n\t\t\t{\n\t\t\t\ttotal += rep.second;\n\t\t\t\tstd::cout << boost::str (boost::format (\"%1% %2% %3%\\n\") % rep.first.to_account () % rep.second.convert_to<std::string> () % total.convert_to<std::string> ());\n\t\t\t}\n\t\t}\n\t\telse if (vm.count (\"debug_dump_frontier_unchecked_dependents\"))\n\t\t{\n\t\t\tauto inactive_node = nano::default_inactive_node (data_path, vm);\n\t\t\tauto node = inactive_node->node;\n\t\t\tstd::cout << \"Outputting any frontier hashes which have associated key hashes in the unchecked table (may take some time)...\\n\";\n\n\t\t\t// Cache the account heads to make searching quicker against unchecked keys.\n\t\t\tauto transaction (node->store.tx_begin_read ());\n\t\t\tstd::unordered_set<nano::block_hash> frontier_hashes;\n\t\t\tfor (auto i (node->store.accounts_begin (transaction)), n (node->store.accounts_end ()); i != n; ++i)\n\t\t\t{\n\t\t\t\tfrontier_hashes.insert (i->second.head);\n\t\t\t}\n\n\t\t\t// Check all unchecked keys for matching frontier hashes. Indicates an issue with process_batch algorithm\n\t\t\tfor (auto i (node->store.unchecked_begin (transaction)), n (node->store.unchecked_end ()); i != n; ++i)\n\t\t\t{\n\t\t\t\tauto it = frontier_hashes.find (i->first.key ());\n\t\t\t\tif (it != frontier_hashes.cend ())\n\t\t\t\t{\n\t\t\t\t\tstd::cout << it->to_string () << \"\\n\";\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse if (vm.count (\"debug_account_count\"))\n\t\t{\n\t\t\tauto node_flags = nano::inactive_node_flag_defaults ();\n\t\t\tnano::update_flags (node_flags, vm);\n\t\t\tnode_flags.generate_cache.account_count = true;\n\t\t\tnano::inactive_node inactive_node (data_path, node_flags);\n\t\t\tstd::cout << boost::str (boost::format (\"Frontier count: %1%\\n\") % inactive_node.node->ledger.cache.account_count);\n\t\t}\n\t\telse if (vm.count (\"debug_profile_kdf\"))\n\t\t{\n\t\t\tnano::network_params network_params;\n\t\t\tnano::uint256_union result;\n\t\t\tnano::uint256_union salt (0);\n\t\t\tstd::string password (\"\");\n\t\t\twhile (true)\n\t\t\t{\n\t\t\t\tauto begin1 (std::chrono::high_resolution_clock::now ());\n\t\t\t\tauto success (argon2_hash (1, network_params.kdf_work, 1, password.data (), password.size (), salt.bytes.data (), salt.bytes.size (), result.bytes.data (), result.bytes.size (), NULL, 0, Argon2_d, 0x10));\n\t\t\t\t(void)success;\n\t\t\t\tauto end1 (std::chrono::high_resolution_clock::now ());\n\t\t\t\tstd::cerr << boost::str (boost::format (\"Derivation time: %1%us\\n\") % std::chrono::duration_cast<std::chrono::microseconds> (end1 - begin1).count ());\n\t\t\t}\n\t\t}\n\t\telse if (vm.count (\"debug_profile_generate\"))\n\t\t{\n\t\t\tnano::network_constants network_constants;\n\t\t\tuint64_t difficulty{ network_constants.publish_full.base };\n\t\t\tauto multiplier_it = vm.find (\"multiplier\");\n\t\t\tif (multiplier_it != vm.end ())\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\tauto multiplier (boost::lexical_cast<double> (multiplier_it->second.as<std::string> ()));\n\t\t\t\t\tdifficulty = nano::difficulty::from_multiplier (multiplier, difficulty);\n\t\t\t\t}\n\t\t\t\tcatch (boost::bad_lexical_cast &)\n\t\t\t\t{\n\t\t\t\t\tstd::cerr << \"Invalid multiplier\\n\";\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tauto difficulty_it = vm.find (\"difficulty\");\n\t\t\t\tif (difficulty_it != vm.end ())\n\t\t\t\t{\n\t\t\t\t\tif (nano::from_string_hex (difficulty_it->second.as<std::string> (), difficulty))\n\t\t\t\t\t{\n\t\t\t\t\t\tstd::cerr << \"Invalid difficulty\\n\";\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tauto pow_rate_limiter = std::chrono::nanoseconds (0);\n\t\t\tauto pow_sleep_interval_it = vm.find (\"pow_sleep_interval\");\n\t\t\tif (pow_sleep_interval_it != vm.cend ())\n\t\t\t{\n\t\t\t\tpow_rate_limiter = std::chrono::nanoseconds (boost::lexical_cast<uint64_t> (pow_sleep_interval_it->second.as<std::string> ()));\n\t\t\t}\n\n\t\t\tnano::work_pool work (std::numeric_limits<unsigned>::max (), pow_rate_limiter);\n\t\t\tnano::change_block block (0, 0, nano::keypair ().prv, 0, 0);\n\t\t\tif (!result)\n\t\t\t{\n\t\t\t\tstd::cerr << boost::str (boost::format (\"Starting generation profiling. Difficulty: %1$#x (%2%x from base difficulty %3$#x)\\n\") % difficulty % nano::to_string (nano::difficulty::to_multiplier (difficulty, network_constants.publish_full.base), 4) % network_constants.publish_full.base);\n\t\t\t\twhile (!result)\n\t\t\t\t{\n\t\t\t\t\tblock.hashables.previous.qwords[0] += 1;\n\t\t\t\t\tauto begin1 (std::chrono::high_resolution_clock::now ());\n\t\t\t\t\tblock.block_work_set (*work.generate (nano::work_version::work_1, block.root (), difficulty));\n\t\t\t\t\tauto end1 (std::chrono::high_resolution_clock::now ());\n\t\t\t\t\tstd::cerr << boost::str (boost::format (\"%|1$ 12d|\\n\") % std::chrono::duration_cast<std::chrono::microseconds> (end1 - begin1).count ());\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse if (vm.count (\"debug_profile_validate\"))\n\t\t{\n\t\t\tuint64_t difficulty{ nano::network_constants ().publish_full.base };\n\t\t\tstd::cerr << \"Starting validation profile\" << std::endl;\n\t\t\tauto start (std::chrono::steady_clock::now ());\n\t\t\tbool valid{ false };\n\t\t\tnano::block_hash hash{ 0 };\n\t\t\tuint64_t count{ 10000000U }; // 10M\n\t\t\tfor (uint64_t i (0); i < count; ++i)\n\t\t\t{\n\t\t\t\tvalid = nano::work_v1::value (hash, i) > difficulty;\n\t\t\t}\n\t\t\tstd::ostringstream oss (valid ? \"true\" : \"false\"); // IO forces compiler to not dismiss the variable\n\t\t\tauto total_time (std::chrono::duration_cast<std::chrono::nanoseconds> (std::chrono::steady_clock::now () - start).count ());\n\t\t\tuint64_t average (total_time / count);\n\t\t\tstd::cout << \"Average validation time: \" << std::to_string (average) << \" ns (\" << std::to_string (static_cast<unsigned> (count * 1e9 / total_time)) << \" validations/s)\" << std::endl;\n\t\t}\n\t\telse if (vm.count (\"debug_opencl\"))\n\t\t{\n\t\t\tnano::network_constants network_constants;\n\t\t\tbool error (false);\n\t\t\tnano::opencl_environment environment (error);\n\t\t\tif (!error)\n\t\t\t{\n\t\t\t\tunsigned short platform (0);\n\t\t\t\tauto platform_it = vm.find (\"platform\");\n\t\t\t\tif (platform_it != vm.end ())\n\t\t\t\t{\n\t\t\t\t\ttry\n\t\t\t\t\t{\n\t\t\t\t\t\tplatform = boost::lexical_cast<unsigned short> (platform_it->second.as<std::string> ());\n\t\t\t\t\t}\n\t\t\t\t\tcatch (boost::bad_lexical_cast &)\n\t\t\t\t\t{\n\t\t\t\t\t\tstd::cerr << \"Invalid platform id\\n\";\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tunsigned short device (0);\n\t\t\t\tauto device_it = vm.find (\"device\");\n\t\t\t\tif (device_it != vm.end ())\n\t\t\t\t{\n\t\t\t\t\ttry\n\t\t\t\t\t{\n\t\t\t\t\t\tdevice = boost::lexical_cast<unsigned short> (device_it->second.as<std::string> ());\n\t\t\t\t\t}\n\t\t\t\t\tcatch (boost::bad_lexical_cast &)\n\t\t\t\t\t{\n\t\t\t\t\t\tstd::cerr << \"Invalid device id\\n\";\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tunsigned threads (1024 * 1024);\n\t\t\t\tauto threads_it = vm.find (\"threads\");\n\t\t\t\tif (threads_it != vm.end ())\n\t\t\t\t{\n\t\t\t\t\ttry\n\t\t\t\t\t{\n\t\t\t\t\t\tthreads = boost::lexical_cast<unsigned> (threads_it->second.as<std::string> ());\n\t\t\t\t\t}\n\t\t\t\t\tcatch (boost::bad_lexical_cast &)\n\t\t\t\t\t{\n\t\t\t\t\t\tstd::cerr << \"Invalid threads count\\n\";\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tuint64_t difficulty (network_constants.publish_full.base);\n\t\t\t\tauto multiplier_it = vm.find (\"multiplier\");\n\t\t\t\tif (multiplier_it != vm.end ())\n\t\t\t\t{\n\t\t\t\t\ttry\n\t\t\t\t\t{\n\t\t\t\t\t\tauto multiplier (boost::lexical_cast<double> (multiplier_it->second.as<std::string> ()));\n\t\t\t\t\t\tdifficulty = nano::difficulty::from_multiplier (multiplier, difficulty);\n\t\t\t\t\t}\n\t\t\t\t\tcatch (boost::bad_lexical_cast &)\n\t\t\t\t\t{\n\t\t\t\t\t\tstd::cerr << \"Invalid multiplier\\n\";\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tauto difficulty_it = vm.find (\"difficulty\");\n\t\t\t\t\tif (difficulty_it != vm.end ())\n\t\t\t\t\t{\n\t\t\t\t\t\tif (nano::from_string_hex (difficulty_it->second.as<std::string> (), difficulty))\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tstd::cerr << \"Invalid difficulty\\n\";\n\t\t\t\t\t\t\treturn -1;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (!result)\n\t\t\t\t{\n\t\t\t\t\terror |= platform >= environment.platforms.size ();\n\t\t\t\t\tif (!error)\n\t\t\t\t\t{\n\t\t\t\t\t\terror |= device >= environment.platforms[platform].devices.size ();\n\t\t\t\t\t\tif (!error)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tnano::logger_mt logger;\n\t\t\t\t\t\t\tnano::opencl_config config (platform, device, threads);\n\t\t\t\t\t\t\tauto opencl (nano::opencl_work::create (true, config, logger));\n\t\t\t\t\t\t\tnano::work_pool work_pool (0, std::chrono::nanoseconds (0), opencl ? [&opencl](nano::work_version const version_a, nano::root const & root_a, uint64_t difficulty_a, std::atomic<int> &) {\n\t\t\t\t\t\t\t\treturn opencl->generate_work (version_a, root_a, difficulty_a);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t                                                                   : std::function<boost::optional<uint64_t> (nano::work_version const, nano::root const &, uint64_t, std::atomic<int> &)> (nullptr));\n\t\t\t\t\t\t\tnano::change_block block (0, 0, nano::keypair ().prv, 0, 0);\n\t\t\t\t\t\t\tstd::cerr << boost::str (boost::format (\"Starting OpenCL generation profiling. Platform: %1%. Device: %2%. Threads: %3%. Difficulty: %4$#x (%5%x from base difficulty %6$#x)\\n\") % platform % device % threads % difficulty % nano::to_string (nano::difficulty::to_multiplier (difficulty, network_constants.publish_full.base), 4) % network_constants.publish_full.base);\n\t\t\t\t\t\t\tfor (uint64_t i (0); true; ++i)\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tblock.hashables.previous.qwords[0] += 1;\n\t\t\t\t\t\t\t\tauto begin1 (std::chrono::high_resolution_clock::now ());\n\t\t\t\t\t\t\t\tblock.block_work_set (*work_pool.generate (nano::work_version::work_1, block.root (), difficulty));\n\t\t\t\t\t\t\t\tauto end1 (std::chrono::high_resolution_clock::now ());\n\t\t\t\t\t\t\t\tstd::cerr << boost::str (boost::format (\"%|1$ 12d|\\n\") % std::chrono::duration_cast<std::chrono::microseconds> (end1 - begin1).count ());\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tstd::cout << \"Not available device id\\n\"\n\t\t\t\t\t\t\t          << std::endl;\n\t\t\t\t\t\t\tresult = -1;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\tstd::cout << \"Not available platform id\\n\"\n\t\t\t\t\t\t          << std::endl;\n\t\t\t\t\t\tresult = -1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tstd::cout << \"Error initializing OpenCL\" << std::endl;\n\t\t\t\tresult = -1;\n\t\t\t}\n\t\t}\n\t\telse if (vm.count (\"debug_output_last_backtrace_dump\"))\n\t\t{\n\t\t\tif (boost::filesystem::exists (\"nano_node_backtrace.dump\"))\n\t\t\t{\n\t\t\t\t// There is a backtrace, so output the contents\n\t\t\t\tstd::ifstream ifs (\"nano_node_backtrace.dump\");\n\n\t\t\t\tboost::stacktrace::stacktrace st = boost::stacktrace::stacktrace::from_dump (ifs);\n\t\t\t\tstd::cout << \"Latest crash backtrace:\\n\"\n\t\t\t\t          << st << std::endl;\n\t\t\t}\n\t\t}\n\t\telse if (vm.count (\"debug_generate_crash_report\"))\n\t\t{\n\t\t\tif (boost::filesystem::exists (\"nano_node_backtrace.dump\"))\n\t\t\t{\n\t\t\t\t// There is a backtrace, so output the contents\n\t\t\t\tstd::ifstream ifs (\"nano_node_backtrace.dump\");\n\t\t\t\tboost::stacktrace::stacktrace st = boost::stacktrace::stacktrace::from_dump (ifs);\n\n\t\t\t\tstd::string crash_report_filename = \"nano_node_crash_report.txt\";\n\n#if defined(_WIN32) || defined(__APPLE__)\n\t\t\t\t// Only linux has load addresses, so just write the dump to a readable file.\n\t\t\t\t// It's the best we can do to keep consistency.\n\t\t\t\tstd::ofstream ofs (crash_report_filename);\n\t\t\t\tofs << st;\n#else\n\t\t\t\t// Read all the nano node files\n\t\t\t\tboost::system::error_code err;\n\t\t\t\tauto running_executable_filepath = boost::dll::program_location (err);\n\t\t\t\tif (!err)\n\t\t\t\t{\n\t\t\t\t\tauto num = 0;\n\t\t\t\t\tauto format = boost::format (\"nano_node_crash_load_address_dump_%1%.txt\");\n\t\t\t\t\tstd::vector<address_library_pair> base_addresses;\n\n\t\t\t\t\t// The first one only has the load address\n\t\t\t\t\tuint64_from_hex base_address;\n\t\t\t\t\tstd::string line;\n\t\t\t\t\tif (boost::filesystem::exists (boost::str (format % num)))\n\t\t\t\t\t{\n\t\t\t\t\t\tstd::getline (std::ifstream (boost::str (format % num)), line);\n\t\t\t\t\t\tif (boost::conversion::try_lexical_convert (line, base_address))\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tbase_addresses.emplace_back (base_address.value, running_executable_filepath.string ());\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t++num;\n\n\t\t\t\t\t// Now do the rest of the files\n\t\t\t\t\twhile (boost::filesystem::exists (boost::str (format % num)))\n\t\t\t\t\t{\n\t\t\t\t\t\tstd::ifstream ifs_dump_filename (boost::str (format % num));\n\n\t\t\t\t\t\t// 2 lines, the path to the dynamic library followed by the load address\n\t\t\t\t\t\tstd::string dynamic_lib_path;\n\t\t\t\t\t\tstd::getline (ifs_dump_filename, dynamic_lib_path);\n\t\t\t\t\t\tstd::getline (ifs_dump_filename, line);\n\n\t\t\t\t\t\tif (boost::conversion::try_lexical_convert (line, base_address))\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tbase_addresses.emplace_back (base_address.value, dynamic_lib_path);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t++num;\n\t\t\t\t\t}\n\n\t\t\t\t\tstd::sort (base_addresses.begin (), base_addresses.end ());\n\n\t\t\t\t\tauto address_column_it = vm.find (\"address_column\");\n\t\t\t\t\tauto column = -1;\n\t\t\t\t\tif (address_column_it != vm.end ())\n\t\t\t\t\t{\n\t\t\t\t\t\tif (!boost::conversion::try_lexical_convert (address_column_it->second.as<std::string> (), column))\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tstd::cerr << \"Error: Invalid address column\\n\";\n\t\t\t\t\t\t\tresult = -1;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t// Extract the addresses from the dump file.\n\t\t\t\t\tstd::stringstream stacktrace_ss;\n\t\t\t\t\tstacktrace_ss << st;\n\t\t\t\t\tstd::vector<uint64_t> backtrace_addresses;\n\t\t\t\t\twhile (std::getline (stacktrace_ss, line))\n\t\t\t\t\t{\n\t\t\t\t\t\tstd::istringstream iss (line);\n\t\t\t\t\t\tstd::vector<std::string> results (std::istream_iterator<std::string>{ iss }, std::istream_iterator<std::string> ());\n\n\t\t\t\t\t\tif (column != -1)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tif (column < results.size ())\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tuint64_from_hex address_hex;\n\t\t\t\t\t\t\t\tif (boost::conversion::try_lexical_convert (results[column], address_hex))\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tbacktrace_addresses.push_back (address_hex.value);\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\telse\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tstd::cerr << \"Error: Address column does not point to valid addresses\\n\";\n\t\t\t\t\t\t\t\t\tresult = -1;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\telse\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tstd::cerr << \"Error: Address column too high\\n\";\n\t\t\t\t\t\t\t\tresult = -1;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tfor (const auto & text : results)\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tuint64_from_hex address_hex;\n\t\t\t\t\t\t\t\tif (boost::conversion::try_lexical_convert (text, address_hex))\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tbacktrace_addresses.push_back (address_hex.value);\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t// Recreate the crash report with an empty file\n\t\t\t\t\tboost::filesystem::remove (crash_report_filename);\n\t\t\t\t\t{\n\t\t\t\t\t\tstd::ofstream ofs (crash_report_filename);\n\t\t\t\t\t\tnano::set_secure_perm_file (crash_report_filename);\n\t\t\t\t\t}\n\n\t\t\t\t\t// Hold the results from all addr2line calls, if all fail we can assume that addr2line is not installed,\n\t\t\t\t\t// and inform the user that it needs installing\n\t\t\t\t\tstd::vector<int> system_codes;\n\n\t\t\t\t\tauto run_addr2line = [&backtrace_addresses, &base_addresses, &system_codes, &crash_report_filename](bool use_relative_addresses) {\n\t\t\t\t\t\tfor (auto backtrace_address : backtrace_addresses)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t// Find the closest address to it\n\t\t\t\t\t\t\tfor (auto base_address : boost::adaptors::reverse (base_addresses))\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tif (backtrace_address > base_address.address)\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t// Addresses need to be in hex for addr2line to work\n\t\t\t\t\t\t\t\t\tauto address = use_relative_addresses ? backtrace_address - base_address.address : backtrace_address;\n\t\t\t\t\t\t\t\t\tstd::stringstream ss;\n\t\t\t\t\t\t\t\t\tss << std::uppercase << std::hex << address;\n\n\t\t\t\t\t\t\t\t\t// Call addr2line to convert the address into something readable.\n\t\t\t\t\t\t\t\t\tauto res = std::system (boost::str (boost::format (\"addr2line -fCi %1% -e %2% >> %3%\") % ss.str () % base_address.library % crash_report_filename).c_str ());\n\t\t\t\t\t\t\t\t\tsystem_codes.push_back (res);\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t};\n\n\t\t\t\t\t// First run addr2line using absolute addresses\n\t\t\t\t\trun_addr2line (false);\n\t\t\t\t\t{\n\t\t\t\t\t\tstd::ofstream ofs (crash_report_filename, std::ios_base::out | std::ios_base::app);\n\t\t\t\t\t\tofs << std::endl\n\t\t\t\t\t\t    << \"Using relative addresses:\" << std::endl; // Add an empty line to separate the absolute & relative output\n\t\t\t\t\t}\n\n\t\t\t\t\t// Now run using relative addresses. This will give actual results for other dlls, the results from the nano_node executable.\n\t\t\t\t\trun_addr2line (true);\n\n\t\t\t\t\tif (std::find (system_codes.begin (), system_codes.end (), 0) == system_codes.end ())\n\t\t\t\t\t{\n\t\t\t\t\t\tstd::cerr << \"Error: Check that addr2line is installed and that nano_node_crash_load_address_dump_*.txt files exist.\" << std::endl;\n\t\t\t\t\t\tresult = -1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tstd::cerr << \"Error: Could not determine running executable path\" << std::endl;\n\t\t\t\t\tresult = -1;\n\t\t\t\t}\n#endif\n\t\t\t\tif (result == 0)\n\t\t\t\t{\n\t\t\t\t\tstd::cout << (boost::format (\"%1% created\") % crash_report_filename).str () << std::endl;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tstd::cerr << \"Error: nano_node_backtrace.dump could not be found\";\n\t\t\t\tresult = -1;\n\t\t\t}\n\t\t}\n\t\telse if (vm.count (\"debug_verify_profile\"))\n\t\t{\n\t\t\tnano::keypair key;\n\t\t\tnano::uint256_union message;\n\t\t\tauto signature = nano::sign_message (key.prv, key.pub, message);\n\t\t\tauto begin (std::chrono::high_resolution_clock::now ());\n\t\t\tfor (auto i (0u); i < 1000; ++i)\n\t\t\t{\n\t\t\t\tnano::validate_message (key.pub, message, signature);\n\t\t\t}\n\t\t\tauto end (std::chrono::high_resolution_clock::now ());\n\t\t\tstd::cerr << \"Signature verifications \" << std::chrono::duration_cast<std::chrono::microseconds> (end - begin).count () << std::endl;\n\t\t}\n\t\telse if (vm.count (\"debug_verify_profile_batch\"))\n\t\t{\n\t\t\tnano::keypair key;\n\t\t\tsize_t batch_count (1000);\n\t\t\tnano::uint256_union message;\n\t\t\tnano::uint512_union signature (nano::sign_message (key.prv, key.pub, message));\n\t\t\tstd::vector<unsigned char const *> messages (batch_count, message.bytes.data ());\n\t\t\tstd::vector<size_t> lengths (batch_count, sizeof (message));\n\t\t\tstd::vector<unsigned char const *> pub_keys (batch_count, key.pub.bytes.data ());\n\t\t\tstd::vector<unsigned char const *> signatures (batch_count, signature.bytes.data ());\n\t\t\tstd::vector<int> verifications;\n\t\t\tverifications.resize (batch_count);\n\t\t\tauto begin (std::chrono::high_resolution_clock::now ());\n\t\t\tnano::validate_message_batch (messages.data (), lengths.data (), pub_keys.data (), signatures.data (), batch_count, verifications.data ());\n\t\t\tauto end (std::chrono::high_resolution_clock::now ());\n\t\t\tstd::cerr << \"Batch signature verifications \" << std::chrono::duration_cast<std::chrono::microseconds> (end - begin).count () << std::endl;\n\t\t}\n\t\telse if (vm.count (\"debug_profile_sign\"))\n\t\t{\n\t\t\tstd::cerr << \"Starting blocks signing profiling\\n\";\n\t\t\twhile (true)\n\t\t\t{\n\t\t\t\tnano::keypair key;\n\t\t\t\tnano::block_hash latest (0);\n\t\t\t\tauto begin1 (std::chrono::high_resolution_clock::now ());\n\t\t\t\tfor (uint64_t balance (0); balance < 1000; ++balance)\n\t\t\t\t{\n\t\t\t\t\tnano::send_block send (latest, key.pub, balance, key.prv, key.pub, 0);\n\t\t\t\t\tlatest = send.hash ();\n\t\t\t\t}\n\t\t\t\tauto end1 (std::chrono::high_resolution_clock::now ());\n\t\t\t\tstd::cerr << boost::str (boost::format (\"%|1$ 12d|\\n\") % std::chrono::duration_cast<std::chrono::microseconds> (end1 - begin1).count ());\n\t\t\t}\n\t\t}\n\t\telse if (vm.count (\"debug_profile_process\"))\n\t\t{\n\t\t\tnano::network_constants::set_active_network (nano::nano_networks::nano_dev_network);\n\t\t\tnano::network_params dev_params;\n\t\t\tnano::block_builder builder;\n\t\t\tsize_t num_accounts (100000);\n\t\t\tsize_t num_iterations (5); // 100,000 * 5 * 2 = 1,000,000 blocks\n\t\t\tsize_t max_blocks (2 * num_accounts * num_iterations + num_accounts * 2); //  1,000,000 + 2 * 100,000 = 1,200,000 blocks\n\t\t\tstd::cout << boost::str (boost::format (\"Starting pregenerating %1% blocks\\n\") % max_blocks);\n\t\t\tboost::asio::io_context io_ctx;\n\t\t\tnano::alarm alarm (io_ctx);\n\t\t\tnano::work_pool work (std::numeric_limits<unsigned>::max ());\n\t\t\tnano::logging logging;\n\t\t\tauto path (nano::unique_path ());\n\t\t\tlogging.init (path);\n\t\t\tnano::node_flags node_flags;\n\t\t\tnano::update_flags (node_flags, vm);\n\t\t\tauto node (std::make_shared<nano::node> (io_ctx, 24001, path, alarm, logging, work, node_flags));\n\t\t\tnano::block_hash genesis_latest (node->latest (dev_params.ledger.dev_genesis_key.pub));\n\t\t\tnano::uint128_t genesis_balance (std::numeric_limits<nano::uint128_t>::max ());\n\t\t\t// Generating keys\n\t\t\tstd::vector<nano::keypair> keys (num_accounts);\n\t\t\tstd::vector<nano::root> frontiers (num_accounts);\n\t\t\tstd::vector<nano::uint128_t> balances (num_accounts, 1000000000);\n\t\t\t// Generating blocks\n\t\t\tstd::deque<std::shared_ptr<nano::block>> blocks;\n\t\t\tfor (auto i (0); i != num_accounts; ++i)\n\t\t\t{\n\t\t\t\tgenesis_balance = genesis_balance - 1000000000;\n\n\t\t\t\tauto send = builder.state ()\n\t\t\t\t            .account (dev_params.ledger.dev_genesis_key.pub)\n\t\t\t\t            .previous (genesis_latest)\n\t\t\t\t            .representative (dev_params.ledger.dev_genesis_key.pub)\n\t\t\t\t            .balance (genesis_balance)\n\t\t\t\t            .link (keys[i].pub)\n\t\t\t\t            .sign (dev_params.ledger.dev_genesis_key.prv, dev_params.ledger.dev_genesis_key.pub)\n\t\t\t\t            .work (*work.generate (nano::work_version::work_1, genesis_latest, node->network_params.network.publish_thresholds.epoch_1))\n\t\t\t\t            .build ();\n\n\t\t\t\tgenesis_latest = send->hash ();\n\t\t\t\tblocks.push_back (std::move (send));\n\n\t\t\t\tauto open = builder.state ()\n\t\t\t\t            .account (keys[i].pub)\n\t\t\t\t            .previous (0)\n\t\t\t\t            .representative (keys[i].pub)\n\t\t\t\t            .balance (balances[i])\n\t\t\t\t            .link (genesis_latest)\n\t\t\t\t            .sign (keys[i].prv, keys[i].pub)\n\t\t\t\t            .work (*work.generate (nano::work_version::work_1, keys[i].pub, node->network_params.network.publish_thresholds.epoch_1))\n\t\t\t\t            .build ();\n\n\t\t\t\tfrontiers[i] = open->hash ();\n\t\t\t\tblocks.push_back (std::move (open));\n\t\t\t}\n\t\t\tfor (auto i (0); i != num_iterations; ++i)\n\t\t\t{\n\t\t\t\tfor (auto j (0); j != num_accounts; ++j)\n\t\t\t\t{\n\t\t\t\t\tsize_t other (num_accounts - j - 1);\n\t\t\t\t\t// Sending to other account\n\t\t\t\t\t--balances[j];\n\n\t\t\t\t\tauto send = builder.state ()\n\t\t\t\t\t            .account (keys[j].pub)\n\t\t\t\t\t            .previous (frontiers[j].as_block_hash ())\n\t\t\t\t\t            .representative (keys[j].pub)\n\t\t\t\t\t            .balance (balances[j])\n\t\t\t\t\t            .link (keys[other].pub)\n\t\t\t\t\t            .sign (keys[j].prv, keys[j].pub)\n\t\t\t\t\t            .work (*work.generate (nano::work_version::work_1, frontiers[j], node->network_params.network.publish_thresholds.epoch_1))\n\t\t\t\t\t            .build ();\n\n\t\t\t\t\tfrontiers[j] = send->hash ();\n\t\t\t\t\tblocks.push_back (std::move (send));\n\t\t\t\t\t// Receiving\n\t\t\t\t\t++balances[other];\n\n\t\t\t\t\tauto receive = builder.state ()\n\t\t\t\t\t               .account (keys[other].pub)\n\t\t\t\t\t               .previous (frontiers[other].as_block_hash ())\n\t\t\t\t\t               .representative (keys[other].pub)\n\t\t\t\t\t               .balance (balances[other])\n\t\t\t\t\t               .link (frontiers[j].as_block_hash ())\n\t\t\t\t\t               .sign (keys[other].prv, keys[other].pub)\n\t\t\t\t\t               .work (*work.generate (nano::work_version::work_1, frontiers[other], node->network_params.network.publish_thresholds.epoch_1))\n\t\t\t\t\t               .build ();\n\n\t\t\t\t\tfrontiers[other] = receive->hash ();\n\t\t\t\t\tblocks.push_back (std::move (receive));\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Processing blocks\n\t\t\tstd::cout << boost::str (boost::format (\"Starting processing %1% blocks\\n\") % max_blocks);\n\t\t\tauto begin (std::chrono::high_resolution_clock::now ());\n\t\t\twhile (!blocks.empty ())\n\t\t\t{\n\t\t\t\tauto block (blocks.front ());\n\t\t\t\tnode->process_active (block);\n\t\t\t\tblocks.pop_front ();\n\t\t\t}\n\t\t\tnano::timer<std::chrono::seconds> timer_l (nano::timer_state::started);\n\t\t\twhile (node->ledger.cache.block_count != max_blocks + 1)\n\t\t\t{\n\t\t\t\tstd::this_thread::sleep_for (std::chrono::milliseconds (10));\n\t\t\t\t// Message each 15 seconds\n\t\t\t\tif (timer_l.after_deadline (std::chrono::seconds (15)))\n\t\t\t\t{\n\t\t\t\t\ttimer_l.restart ();\n\t\t\t\t\tstd::cout << boost::str (boost::format (\"%1% (%2%) blocks processed (unchecked), %3% remaining\") % node->ledger.cache.block_count % node->store.unchecked_count (node->store.tx_begin_read ()) % node->block_processor.size ()) << std::endl;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tnode->block_processor.flush ();\n\t\t\tauto end (std::chrono::high_resolution_clock::now ());\n\t\t\tauto time (std::chrono::duration_cast<std::chrono::microseconds> (end - begin).count ());\n\t\t\tnode->stop ();\n\t\t\tstd::cout << boost::str (boost::format (\"%|1$ 12d| us \\n%2% blocks per second\\n\") % time % (max_blocks * 1000000 / time));\n\t\t\trelease_assert (node->ledger.cache.block_count == max_blocks + 1);\n\t\t}\n\t\telse if (vm.count (\"debug_profile_votes\"))\n\t\t{\n\t\t\tnano::network_constants::set_active_network (nano::nano_networks::nano_dev_network);\n\t\t\tnano::network_params dev_params;\n\t\t\tnano::block_builder builder;\n\t\t\tsize_t num_elections (40000);\n\t\t\tsize_t num_representatives (25);\n\t\t\tsize_t max_votes (num_elections * num_representatives); // 40,000 * 25 = 1,000,000 votes\n\t\t\tstd::cerr << boost::str (boost::format (\"Starting pregenerating %1% votes\\n\") % max_votes);\n\t\t\tboost::asio::io_context io_ctx;\n\t\t\tnano::alarm alarm (io_ctx);\n\t\t\tnano::work_pool work (std::numeric_limits<unsigned>::max ());\n\t\t\tnano::logging logging;\n\t\t\tauto path (nano::unique_path ());\n\t\t\tlogging.init (path);\n\t\t\tauto node (std::make_shared<nano::node> (io_ctx, 24001, path, alarm, logging, work));\n\t\t\tnano::block_hash genesis_latest (node->latest (dev_params.ledger.dev_genesis_key.pub));\n\t\t\tnano::uint128_t genesis_balance (std::numeric_limits<nano::uint128_t>::max ());\n\t\t\t// Generating keys\n\t\t\tstd::vector<nano::keypair> keys (num_representatives);\n\t\t\tnano::uint128_t balance ((node->config.online_weight_minimum.number () / num_representatives) + 1);\n\t\t\tfor (auto i (0); i != num_representatives; ++i)\n\t\t\t{\n\t\t\t\tauto transaction (node->store.tx_begin_write ());\n\t\t\t\tgenesis_balance = genesis_balance - balance;\n\n\t\t\t\tauto send = builder.state ()\n\t\t\t\t            .account (dev_params.ledger.dev_genesis_key.pub)\n\t\t\t\t            .previous (genesis_latest)\n\t\t\t\t            .representative (dev_params.ledger.dev_genesis_key.pub)\n\t\t\t\t            .balance (genesis_balance)\n\t\t\t\t            .link (keys[i].pub)\n\t\t\t\t            .sign (dev_params.ledger.dev_genesis_key.prv, dev_params.ledger.dev_genesis_key.pub)\n\t\t\t\t            .work (*work.generate (nano::work_version::work_1, genesis_latest, node->network_params.network.publish_thresholds.epoch_1))\n\t\t\t\t            .build ();\n\n\t\t\t\tgenesis_latest = send->hash ();\n\t\t\t\tnode->ledger.process (transaction, *send);\n\n\t\t\t\tauto open = builder.state ()\n\t\t\t\t            .account (keys[i].pub)\n\t\t\t\t            .previous (0)\n\t\t\t\t            .representative (keys[i].pub)\n\t\t\t\t            .balance (balance)\n\t\t\t\t            .link (genesis_latest)\n\t\t\t\t            .sign (keys[i].prv, keys[i].pub)\n\t\t\t\t            .work (*work.generate (nano::work_version::work_1, keys[i].pub, node->network_params.network.publish_thresholds.epoch_1))\n\t\t\t\t            .build ();\n\n\t\t\t\tnode->ledger.process (transaction, *open);\n\t\t\t}\n\t\t\t// Generating blocks\n\t\t\tstd::deque<std::shared_ptr<nano::block>> blocks;\n\t\t\tfor (auto i (0); i != num_elections; ++i)\n\t\t\t{\n\t\t\t\tgenesis_balance = genesis_balance - 1;\n\t\t\t\tnano::keypair destination;\n\n\t\t\t\tauto send = builder.state ()\n\t\t\t\t            .account (dev_params.ledger.dev_genesis_key.pub)\n\t\t\t\t            .previous (genesis_latest)\n\t\t\t\t            .representative (dev_params.ledger.dev_genesis_key.pub)\n\t\t\t\t            .balance (genesis_balance)\n\t\t\t\t            .link (destination.pub)\n\t\t\t\t            .sign (dev_params.ledger.dev_genesis_key.prv, dev_params.ledger.dev_genesis_key.pub)\n\t\t\t\t            .work (*work.generate (nano::work_version::work_1, genesis_latest, node->network_params.network.publish_thresholds.epoch_1))\n\t\t\t\t            .build ();\n\n\t\t\t\tgenesis_latest = send->hash ();\n\t\t\t\tblocks.push_back (std::move (send));\n\t\t\t}\n\t\t\t// Generating votes\n\t\t\tstd::deque<std::shared_ptr<nano::vote>> votes;\n\t\t\tfor (auto j (0); j != num_representatives; ++j)\n\t\t\t{\n\t\t\t\tuint64_t sequence (1);\n\t\t\t\tfor (auto & i : blocks)\n\t\t\t\t{\n\t\t\t\t\tauto vote (std::make_shared<nano::vote> (keys[j].pub, keys[j].prv, sequence, std::vector<nano::block_hash> (1, i->hash ())));\n\t\t\t\t\tvotes.push_back (vote);\n\t\t\t\t\tsequence++;\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Processing block & start elections\n\t\t\twhile (!blocks.empty ())\n\t\t\t{\n\t\t\t\tauto block (blocks.front ());\n\t\t\t\tnode->process_active (block);\n\t\t\t\tblocks.pop_front ();\n\t\t\t}\n\t\t\tnode->block_processor.flush ();\n\t\t\t// Processing votes\n\t\t\tstd::cerr << boost::str (boost::format (\"Starting processing %1% votes\\n\") % max_votes);\n\t\t\tauto begin (std::chrono::high_resolution_clock::now ());\n\t\t\twhile (!votes.empty ())\n\t\t\t{\n\t\t\t\tauto vote (votes.front ());\n\t\t\t\tauto channel (std::make_shared<nano::transport::channel_loopback> (*node));\n\t\t\t\tnode->vote_processor.vote (vote, channel);\n\t\t\t\tvotes.pop_front ();\n\t\t\t}\n\t\t\twhile (!node->active.empty ())\n\t\t\t{\n\t\t\t\tstd::this_thread::sleep_for (std::chrono::milliseconds (100));\n\t\t\t}\n\t\t\tauto end (std::chrono::high_resolution_clock::now ());\n\t\t\tauto time (std::chrono::duration_cast<std::chrono::microseconds> (end - begin).count ());\n\t\t\tnode->stop ();\n\t\t\tstd::cerr << boost::str (boost::format (\"%|1$ 12d| us \\n%2% votes per second\\n\") % time % (max_votes * 1000000 / time));\n\t\t}\n\t\telse if (vm.count (\"debug_profile_frontiers_confirmation\"))\n\t\t{\n\t\t\tnano::force_nano_dev_network ();\n\t\t\tnano::network_params dev_params;\n\t\t\tnano::block_builder builder;\n\t\t\tsize_t count (32 * 1024);\n\t\t\tauto count_it = vm.find (\"count\");\n\t\t\tif (count_it != vm.end ())\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\tcount = boost::lexical_cast<size_t> (count_it->second.as<std::string> ());\n\t\t\t\t}\n\t\t\t\tcatch (boost::bad_lexical_cast &)\n\t\t\t\t{\n\t\t\t\t\tstd::cerr << \"Invalid count\\n\";\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tstd::cout << boost::str (boost::format (\"Starting generating %1% blocks...\\n\") % (count * 2));\n\t\t\tboost::asio::io_context io_ctx1;\n\t\t\tboost::asio::io_context io_ctx2;\n\t\t\tnano::alarm alarm1 (io_ctx1);\n\t\t\tnano::alarm alarm2 (io_ctx2);\n\t\t\tnano::work_pool work (std::numeric_limits<unsigned>::max ());\n\t\t\tnano::logging logging;\n\t\t\tauto path1 (nano::unique_path ());\n\t\t\tauto path2 (nano::unique_path ());\n\t\t\tlogging.init (path1);\n\t\t\tnano::node_config config1 (24000, logging);\n\t\t\tnano::node_flags flags;\n\t\t\tflags.disable_lazy_bootstrap = true;\n\t\t\tflags.disable_legacy_bootstrap = true;\n\t\t\tflags.disable_wallet_bootstrap = true;\n\t\t\tflags.disable_bootstrap_listener = true;\n\t\t\tauto node1 (std::make_shared<nano::node> (io_ctx1, path1, alarm1, config1, work, flags, 0));\n\t\t\tnano::block_hash genesis_latest (node1->latest (dev_params.ledger.dev_genesis_key.pub));\n\t\t\tnano::uint128_t genesis_balance (std::numeric_limits<nano::uint128_t>::max ());\n\t\t\t// Generating blocks\n\t\t\tstd::deque<std::shared_ptr<nano::block>> blocks;\n\t\t\tfor (auto i (0); i != count; ++i)\n\t\t\t{\n\t\t\t\tnano::keypair key;\n\t\t\t\tgenesis_balance = genesis_balance - 1;\n\n\t\t\t\tauto send = builder.state ()\n\t\t\t\t            .account (dev_params.ledger.dev_genesis_key.pub)\n\t\t\t\t            .previous (genesis_latest)\n\t\t\t\t            .representative (dev_params.ledger.dev_genesis_key.pub)\n\t\t\t\t            .balance (genesis_balance)\n\t\t\t\t            .link (key.pub)\n\t\t\t\t            .sign (dev_params.ledger.dev_genesis_key.prv, dev_params.ledger.dev_genesis_key.pub)\n\t\t\t\t            .work (*work.generate (nano::work_version::work_1, genesis_latest, dev_params.network.publish_thresholds.epoch_1))\n\t\t\t\t            .build ();\n\n\t\t\t\tgenesis_latest = send->hash ();\n\n\t\t\t\tauto open = builder.state ()\n\t\t\t\t            .account (key.pub)\n\t\t\t\t            .previous (0)\n\t\t\t\t            .representative (key.pub)\n\t\t\t\t            .balance (1)\n\t\t\t\t            .link (genesis_latest)\n\t\t\t\t            .sign (key.prv, key.pub)\n\t\t\t\t            .work (*work.generate (nano::work_version::work_1, key.pub, dev_params.network.publish_thresholds.epoch_1))\n\t\t\t\t            .build ();\n\n\t\t\t\tblocks.push_back (std::move (send));\n\t\t\t\tblocks.push_back (std::move (open));\n\t\t\t\tif (i % 20000 == 0 && i != 0)\n\t\t\t\t{\n\t\t\t\t\tstd::cout << boost::str (boost::format (\"%1% blocks generated\\n\") % (i * 2));\n\t\t\t\t}\n\t\t\t}\n\t\t\tnode1->start ();\n\t\t\tnano::thread_runner runner1 (io_ctx1, node1->config.io_threads);\n\n\t\t\tstd::cout << boost::str (boost::format (\"Processing %1% blocks\\n\") % (count * 2));\n\t\t\tfor (auto & block : blocks)\n\t\t\t{\n\t\t\t\tnode1->block_processor.add (block);\n\t\t\t}\n\t\t\tnode1->block_processor.flush ();\n\t\t\tauto iteration (0);\n\t\t\twhile (node1->ledger.cache.block_count != count * 2 + 1)\n\t\t\t{\n\t\t\t\tstd::this_thread::sleep_for (std::chrono::milliseconds (500));\n\t\t\t\tif (++iteration % 60 == 0)\n\t\t\t\t{\n\t\t\t\t\tstd::cout << boost::str (boost::format (\"%1% blocks processed\\n\") % node1->ledger.cache.block_count);\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Confirm blocks for node1\n\t\t\tfor (auto & block : blocks)\n\t\t\t{\n\t\t\t\tnode1->confirmation_height_processor.add (block->hash ());\n\t\t\t}\n\t\t\twhile (node1->ledger.cache.cemented_count != node1->ledger.cache.block_count)\n\t\t\t{\n\t\t\t\tstd::this_thread::sleep_for (std::chrono::milliseconds (500));\n\t\t\t\tif (++iteration % 60 == 0)\n\t\t\t\t{\n\t\t\t\t\tstd::cout << boost::str (boost::format (\"%1% blocks cemented\\n\") % node1->ledger.cache.cemented_count);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Start new node\n\t\t\tnano::node_config config2 (24001, logging);\n\t\t\t// Config override\n\t\t\tstd::vector<std::string> config_overrides;\n\t\t\tauto config (vm.find (\"config\"));\n\t\t\tif (config != vm.end ())\n\t\t\t{\n\t\t\t\tconfig_overrides = config->second.as<std::vector<std::string>> ();\n\t\t\t}\n\t\t\tif (!config_overrides.empty ())\n\t\t\t{\n\t\t\t\tauto path (nano::unique_path ());\n\t\t\t\tnano::daemon_config daemon_config (path);\n\t\t\t\tauto error = nano::read_node_config_toml (path, daemon_config, config_overrides);\n\t\t\t\tif (error)\n\t\t\t\t{\n\t\t\t\t\tstd::cerr << \"\\n\"\n\t\t\t\t\t          << error.get_message () << std::endl;\n\t\t\t\t\tstd::exit (1);\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tconfig2.frontiers_confirmation = daemon_config.node.frontiers_confirmation;\n\t\t\t\t\tconfig2.active_elections_size = daemon_config.node.active_elections_size;\n\t\t\t\t}\n\t\t\t}\n\t\t\tauto node2 (std::make_shared<nano::node> (io_ctx2, path2, alarm2, config2, work, flags, 1));\n\t\t\tnode2->start ();\n\t\t\tnano::thread_runner runner2 (io_ctx2, node2->config.io_threads);\n\t\t\tstd::cout << boost::str (boost::format (\"Processing %1% blocks (test node)\\n\") % (count * 2));\n\t\t\t// Processing block\n\t\t\twhile (!blocks.empty ())\n\t\t\t{\n\t\t\t\tauto block (blocks.front ());\n\t\t\t\tnode2->block_processor.add (block);\n\t\t\t\tblocks.pop_front ();\n\t\t\t}\n\t\t\tnode2->block_processor.flush ();\n\t\t\twhile (node2->ledger.cache.block_count != count * 2 + 1)\n\t\t\t{\n\t\t\t\tstd::this_thread::sleep_for (std::chrono::milliseconds (500));\n\t\t\t\tif (++iteration % 60 == 0)\n\t\t\t\t{\n\t\t\t\t\tstd::cout << boost::str (boost::format (\"%1% blocks processed\\n\") % node2->ledger.cache.block_count);\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Insert representative\n\t\t\tstd::cout << \"Initializing representative\\n\";\n\t\t\tauto wallet (node1->wallets.create (nano::random_wallet_id ()));\n\t\t\twallet->insert_adhoc (dev_params.ledger.dev_genesis_key.prv);\n\t\t\tnode2->network.merge_peer (node1->network.endpoint ());\n\t\t\twhile (node2->rep_crawler.representative_count () == 0)\n\t\t\t{\n\t\t\t\tstd::this_thread::sleep_for (std::chrono::milliseconds (10));\n\t\t\t\tif (++iteration % 500 == 0)\n\t\t\t\t{\n\t\t\t\t\tstd::cout << \"Representative initialization iteration...\\n\";\n\t\t\t\t}\n\t\t\t}\n\t\t\tauto begin (std::chrono::high_resolution_clock::now ());\n\t\t\tstd::cout << boost::str (boost::format (\"Starting confirming %1% frontiers (test node)\\n\") % (count + 1));\n\t\t\t// Wait for full frontiers confirmation\n\t\t\twhile (node2->ledger.cache.cemented_count != node2->ledger.cache.block_count)\n\t\t\t{\n\t\t\t\tstd::this_thread::sleep_for (std::chrono::milliseconds (25));\n\t\t\t\tif (++iteration % 1200 == 0)\n\t\t\t\t{\n\t\t\t\t\tstd::cout << boost::str (boost::format (\"%1% blocks confirmed\\n\") % node2->ledger.cache.cemented_count);\n\t\t\t\t}\n\t\t\t}\n\t\t\tauto end (std::chrono::high_resolution_clock::now ());\n\t\t\tauto time (std::chrono::duration_cast<std::chrono::microseconds> (end - begin).count ());\n\t\t\tstd::cout << boost::str (boost::format (\"%|1$ 12d| us \\n%2% frontiers per second\\n\") % time % ((count + 1) * 1000000 / time));\n\t\t\tio_ctx1.stop ();\n\t\t\tio_ctx2.stop ();\n\t\t\trunner1.join ();\n\t\t\trunner2.join ();\n\t\t\tnode1->stop ();\n\t\t\tnode2->stop ();\n\t\t}\n\t\telse if (vm.count (\"debug_random_feed\"))\n\t\t{\n\t\t\t/*\n\t\t\t * This command redirects an infinite stream of bytes from the random pool to standard out.\n\t\t\t * The result can be fed into various tools for testing RNGs and entropy pools.\n\t\t\t *\n\t\t\t * Example, running the entire dieharder test suite:\n\t\t\t *\n\t\t\t *   ./nano_node --debug_random_feed | dieharder -a -g 200\n\t\t\t */\n\t\t\tnano::raw_key seed;\n\t\t\tfor (;;)\n\t\t\t{\n\t\t\t\tnano::random_pool::generate_block (seed.data.bytes.data (), seed.data.bytes.size ());\n\t\t\t\tstd::cout.write (reinterpret_cast<const char *> (seed.data.bytes.data ()), seed.data.bytes.size ());\n\t\t\t}\n\t\t}\n\t\telse if (vm.count (\"debug_rpc\"))\n\t\t{\n\t\t\tstd::string rpc_input_l;\n\t\t\tstd::ostringstream command_l;\n\t\t\twhile (std::cin >> rpc_input_l)\n\t\t\t{\n\t\t\t\tcommand_l << rpc_input_l;\n\t\t\t}\n\n\t\t\tauto response_handler_l ([](std::string const & response_a) {\n\t\t\t\tstd::cout << response_a;\n\t\t\t\t// Terminate as soon as we have the result, even if background threads (like work generation) are running.\n\t\t\t\tstd::exit (0);\n\t\t\t});\n\n\t\t\tauto node_flags = nano::inactive_node_flag_defaults ();\n\t\t\tnano::update_flags (node_flags, vm);\n\t\t\tnode_flags.generate_cache.enable_all ();\n\t\t\tnano::inactive_node inactive_node_l (data_path, node_flags);\n\n\t\t\tnano::node_rpc_config config;\n\t\t\tnano::ipc::ipc_server server (*inactive_node_l.node, config);\n\t\t\tauto handler_l (std::make_shared<nano::json_handler> (*inactive_node_l.node, config, command_l.str (), response_handler_l));\n\t\t\thandler_l->process_request ();\n\t\t}\n\t\telse if (vm.count (\"validate_blocks\") || vm.count (\"debug_validate_blocks\"))\n\t\t{\n\t\t\tnano::timer<std::chrono::seconds> timer;\n\t\t\ttimer.start ();\n\t\t\tauto node_flags = nano::inactive_node_flag_defaults ();\n\t\t\tnano::update_flags (node_flags, vm);\n\t\t\tnode_flags.generate_cache.block_count = true;\n\t\t\tnano::inactive_node inactive_node (data_path, node_flags);\n\t\t\tauto node = inactive_node.node;\n\t\t\tbool const silent (vm.count (\"silent\"));\n\t\t\tunsigned threads_count (1);\n\t\t\tauto threads_it = vm.find (\"threads\");\n\t\t\tif (threads_it != vm.end ())\n\t\t\t{\n\t\t\t\tif (!boost::conversion::try_lexical_convert (threads_it->second.as<std::string> (), threads_count))\n\t\t\t\t{\n\t\t\t\t\tstd::cerr << \"Invalid threads count\\n\";\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tthreads_count = std::max (1u, threads_count);\n\t\t\tstd::vector<std::thread> threads;\n\t\t\tstd::mutex mutex;\n\t\t\tnano::condition_variable condition;\n\t\t\tstd::atomic<bool> finished (false);\n\t\t\tstd::deque<std::pair<nano::account, nano::account_info>> accounts;\n\t\t\tstd::atomic<size_t> count (0);\n\t\t\tstd::atomic<uint64_t> block_count (0);\n\t\t\tstd::atomic<uint64_t> errors (0);\n\n\t\t\tauto print_error_message = [&silent, &errors](std::string const & error_message_a) {\n\t\t\t\tif (!silent)\n\t\t\t\t{\n\t\t\t\t\tstatic std::mutex cerr_mutex;\n\t\t\t\t\tnano::lock_guard<std::mutex> lock (cerr_mutex);\n\t\t\t\t\tstd::cerr << error_message_a;\n\t\t\t\t}\n\t\t\t\t++errors;\n\t\t\t};\n\n\t\t\tauto start_threads = [node, &threads_count, &threads, &mutex, &condition, &finished](const auto & function_a, auto & deque_a) {\n\t\t\t\tfor (auto i (0U); i < threads_count; ++i)\n\t\t\t\t{\n\t\t\t\t\tthreads.emplace_back ([&function_a, node, &mutex, &condition, &finished, &deque_a]() {\n\t\t\t\t\t\tauto transaction (node->store.tx_begin_read ());\n\t\t\t\t\t\tnano::unique_lock<std::mutex> lock (mutex);\n\t\t\t\t\t\twhile (!deque_a.empty () || !finished)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\twhile (deque_a.empty () && !finished)\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tcondition.wait (lock);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (!deque_a.empty ())\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tauto pair (deque_a.front ());\n\t\t\t\t\t\t\t\tdeque_a.pop_front ();\n\t\t\t\t\t\t\t\tlock.unlock ();\n\t\t\t\t\t\t\t\tfunction_a (node, transaction, pair.first, pair.second);\n\t\t\t\t\t\t\t\tlock.lock ();\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t};\n\n\t\t\tauto check_account = [&print_error_message, &silent, &count, &block_count](std::shared_ptr<nano::node> const & node, nano::read_transaction const & transaction, nano::account const & account, nano::account_info const & info) {\n\t\t\t\t++count;\n\t\t\t\tif (!silent && (count % 20000) == 0)\n\t\t\t\t{\n\t\t\t\t\tstd::cout << boost::str (boost::format (\"%1% accounts validated\\n\") % count);\n\t\t\t\t}\n\t\t\t\tnano::confirmation_height_info confirmation_height_info;\n\t\t\t\tnode->store.confirmation_height_get (transaction, account, confirmation_height_info);\n\n\t\t\t\tif (confirmation_height_info.height > info.block_count)\n\t\t\t\t{\n\t\t\t\t\tprint_error_message (boost::str (boost::format (\"Confirmation height %1% greater than block count %2% for account: %3%\\n\") % confirmation_height_info.height % info.block_count % account.to_account ()));\n\t\t\t\t}\n\n\t\t\t\tauto hash (info.open_block);\n\t\t\t\tnano::block_hash calculated_hash (0);\n\t\t\t\tauto block (node->store.block_get (transaction, hash)); // Block data\n\t\t\t\tuint64_t height (0);\n\t\t\t\tif (node->ledger.pruning && confirmation_height_info.height != 0)\n\t\t\t\t{\n\t\t\t\t\thash = confirmation_height_info.frontier;\n\t\t\t\t\tblock = node->store.block_get (transaction, hash);\n\t\t\t\t\t// Iteration until pruned block\n\t\t\t\t\tbool pruned_block (false);\n\t\t\t\t\twhile (!pruned_block && !block->previous ().is_zero ())\n\t\t\t\t\t{\n\t\t\t\t\t\tauto previous_block (node->store.block_get (transaction, block->previous ()));\n\t\t\t\t\t\tif (previous_block != nullptr)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\thash = previous_block->hash ();\n\t\t\t\t\t\t\tblock = previous_block;\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tpruned_block = true;\n\t\t\t\t\t\t\tif (!node->store.pruned_exists (transaction, block->previous ()))\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tprint_error_message (boost::str (boost::format (\"Pruned previous block does not exist %1%\\n\") % block->previous ().to_string ()));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tcalculated_hash = block->previous ();\n\t\t\t\t\theight = block->sideband ().height - 1;\n\t\t\t\t\tif (!node->store.block_or_pruned_exists (transaction, info.open_block))\n\t\t\t\t\t{\n\t\t\t\t\t\tprint_error_message (boost::str (boost::format (\"Open block does not exist %1%\\n\") % info.open_block.to_string ()));\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tuint64_t previous_timestamp (0);\n\t\t\t\tnano::account calculated_representative (0);\n\t\t\t\twhile (!hash.is_zero () && block != nullptr)\n\t\t\t\t{\n\t\t\t\t\t++block_count;\n\t\t\t\t\tauto const & sideband (block->sideband ());\n\t\t\t\t\t// Check for state & open blocks if account field is correct\n\t\t\t\t\tif (block->type () == nano::block_type::open || block->type () == nano::block_type::state)\n\t\t\t\t\t{\n\t\t\t\t\t\tif (block->account () != account)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tprint_error_message (boost::str (boost::format (\"Incorrect account field for block %1%\\n\") % hash.to_string ()));\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t// Check if sideband account is correct\n\t\t\t\t\telse if (sideband.account != account)\n\t\t\t\t\t{\n\t\t\t\t\t\tprint_error_message (boost::str (boost::format (\"Incorrect sideband account for block %1%\\n\") % hash.to_string ()));\n\t\t\t\t\t}\n\t\t\t\t\t// Check if previous field is correct\n\t\t\t\t\tif (calculated_hash != block->previous ())\n\t\t\t\t\t{\n\t\t\t\t\t\tprint_error_message (boost::str (boost::format (\"Incorrect previous field for block %1%\\n\") % hash.to_string ()));\n\t\t\t\t\t}\n\t\t\t\t\t// Check if previous & type for open blocks are correct\n\t\t\t\t\tif (height == 0 && !block->previous ().is_zero ())\n\t\t\t\t\t{\n\t\t\t\t\t\tprint_error_message (boost::str (boost::format (\"Incorrect previous for open block %1%\\n\") % hash.to_string ()));\n\t\t\t\t\t}\n\t\t\t\t\tif (height == 0 && block->type () != nano::block_type::open && block->type () != nano::block_type::state)\n\t\t\t\t\t{\n\t\t\t\t\t\tprint_error_message (boost::str (boost::format (\"Incorrect type for open block %1%\\n\") % hash.to_string ()));\n\t\t\t\t\t}\n\t\t\t\t\t// Check if block data is correct (calculating hash)\n\t\t\t\t\tcalculated_hash = block->hash ();\n\t\t\t\t\tif (calculated_hash != hash)\n\t\t\t\t\t{\n\t\t\t\t\t\tprint_error_message (boost::str (boost::format (\"Invalid data inside block %1% calculated hash: %2%\\n\") % hash.to_string () % calculated_hash.to_string ()));\n\t\t\t\t\t}\n\t\t\t\t\t// Check if block signature is correct\n\t\t\t\t\tif (validate_message (account, hash, block->block_signature ()))\n\t\t\t\t\t{\n\t\t\t\t\t\tbool invalid (true);\n\t\t\t\t\t\t// Epoch blocks\n\t\t\t\t\t\tif (block->type () == nano::block_type::state)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tauto & state_block (static_cast<nano::state_block &> (*block.get ()));\n\t\t\t\t\t\t\tnano::amount prev_balance (0);\n\t\t\t\t\t\t\tbool error_or_pruned (false);\n\t\t\t\t\t\t\tif (!state_block.hashables.previous.is_zero ())\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tprev_balance = node->ledger.balance_safe (transaction, state_block.hashables.previous, error_or_pruned);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (node->ledger.is_epoch_link (state_block.hashables.link))\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tif ((state_block.hashables.balance == prev_balance && !error_or_pruned) || (node->ledger.pruning && error_or_pruned && block->sideband ().details.is_epoch))\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tinvalid = validate_message (node->ledger.epoch_signer (block->link ()), hash, block->block_signature ());\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (invalid)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tprint_error_message (boost::str (boost::format (\"Invalid signature for block %1%\\n\") % hash.to_string ()));\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t// Validate block details set in the sideband\n\t\t\t\t\tbool block_details_error = false;\n\t\t\t\t\tif (block->type () != nano::block_type::state)\n\t\t\t\t\t{\n\t\t\t\t\t\t// Not state\n\t\t\t\t\t\tblock_details_error = sideband.details.is_send || sideband.details.is_receive || sideband.details.is_epoch;\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\tbool error_or_pruned (false);\n\t\t\t\t\t\tauto prev_balance (node->ledger.balance_safe (transaction, block->previous (), error_or_pruned));\n\t\t\t\t\t\tif (!node->ledger.pruning || !error_or_pruned)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tif (block->balance () < prev_balance)\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t// State send\n\t\t\t\t\t\t\t\tblock_details_error = !sideband.details.is_send || sideband.details.is_receive || sideband.details.is_epoch;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\telse\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tif (block->link ().is_zero ())\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t// State change\n\t\t\t\t\t\t\t\t\tblock_details_error = sideband.details.is_send || sideband.details.is_receive || sideband.details.is_epoch;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\telse if (block->balance () == prev_balance && node->ledger.is_epoch_link (block->link ()))\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t// State epoch\n\t\t\t\t\t\t\t\t\tblock_details_error = !sideband.details.is_epoch || sideband.details.is_send || sideband.details.is_receive;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\telse\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t// State receive\n\t\t\t\t\t\t\t\t\tblock_details_error = !sideband.details.is_receive || sideband.details.is_send || sideband.details.is_epoch;\n\t\t\t\t\t\t\t\t\tblock_details_error |= !node->ledger.block_or_pruned_exists (transaction, block->link ().as_block_hash ());\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse if (!node->store.pruned_exists (transaction, block->previous ()))\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tprint_error_message (boost::str (boost::format (\"Previous pruned block does not exist %1%\\n\") % block->previous ().to_string ()));\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif (block_details_error)\n\t\t\t\t\t{\n\t\t\t\t\t\tprint_error_message (boost::str (boost::format (\"Incorrect sideband block details for block %1%\\n\") % hash.to_string ()));\n\t\t\t\t\t}\n\t\t\t\t\t// Check link epoch version\n\t\t\t\t\tif (sideband.details.is_receive && (!node->ledger.pruning || !node->store.pruned_exists (transaction, block->link ().as_block_hash ())))\n\t\t\t\t\t{\n\t\t\t\t\t\tif (sideband.source_epoch != node->store.block_version (transaction, block->link ().as_block_hash ()))\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tprint_error_message (boost::str (boost::format (\"Incorrect source epoch for block %1%\\n\") % hash.to_string ()));\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t// Check if block work value is correct\n\t\t\t\t\tif (block->difficulty () < nano::work_threshold (block->work_version (), block->sideband ().details))\n\t\t\t\t\t{\n\t\t\t\t\t\tprint_error_message (boost::str (boost::format (\"Invalid work for block %1% value: %2%\\n\") % hash.to_string () % nano::to_string_hex (block->block_work ())));\n\t\t\t\t\t}\n\t\t\t\t\t// Check if sideband height is correct\n\t\t\t\t\t++height;\n\t\t\t\t\tif (sideband.height != height)\n\t\t\t\t\t{\n\t\t\t\t\t\tprint_error_message (boost::str (boost::format (\"Incorrect sideband height for block %1%. Sideband: %2%. Expected: %3%\\n\") % hash.to_string () % sideband.height % height));\n\t\t\t\t\t}\n\t\t\t\t\t// Check if sideband timestamp is after previous timestamp\n\t\t\t\t\tif (sideband.timestamp < previous_timestamp)\n\t\t\t\t\t{\n\t\t\t\t\t\tprint_error_message (boost::str (boost::format (\"Incorrect sideband timestamp for block %1%\\n\") % hash.to_string ()));\n\t\t\t\t\t}\n\t\t\t\t\tprevious_timestamp = sideband.timestamp;\n\t\t\t\t\t// Calculate representative block\n\t\t\t\t\tif (block->type () == nano::block_type::open || block->type () == nano::block_type::change || block->type () == nano::block_type::state)\n\t\t\t\t\t{\n\t\t\t\t\t\tcalculated_representative = block->representative ();\n\t\t\t\t\t}\n\t\t\t\t\t// Retrieving successor block hash\n\t\t\t\t\thash = node->store.block_successor (transaction, hash);\n\t\t\t\t\t// Retrieving block data\n\t\t\t\t\tif (!hash.is_zero ())\n\t\t\t\t\t{\n\t\t\t\t\t\tblock = node->store.block_get (transaction, hash);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// Check if required block exists\n\t\t\t\tif (!hash.is_zero () && block == nullptr)\n\t\t\t\t{\n\t\t\t\t\tprint_error_message (boost::str (boost::format (\"Required block in account %1% chain was not found in ledger: %2%\\n\") % account.to_account () % hash.to_string ()));\n\t\t\t\t}\n\t\t\t\t// Check account block count\n\t\t\t\tif (info.block_count != height)\n\t\t\t\t{\n\t\t\t\t\tprint_error_message (boost::str (boost::format (\"Incorrect block count for account %1%. Actual: %2%. Expected: %3%\\n\") % account.to_account () % height % info.block_count));\n\t\t\t\t}\n\t\t\t\t// Check account head block (frontier)\n\t\t\t\tif (info.head != calculated_hash)\n\t\t\t\t{\n\t\t\t\t\tprint_error_message (boost::str (boost::format (\"Incorrect frontier for account %1%. Actual: %2%. Expected: %3%\\n\") % account.to_account () % calculated_hash.to_string () % info.head.to_string ()));\n\t\t\t\t}\n\t\t\t\t// Check account representative block\n\t\t\t\tif (info.representative != calculated_representative)\n\t\t\t\t{\n\t\t\t\t\tprint_error_message (boost::str (boost::format (\"Incorrect representative for account %1%. Actual: %2%. Expected: %3%\\n\") % account.to_account () % calculated_representative.to_string () % info.representative.to_string ()));\n\t\t\t\t}\n\t\t\t};\n\n\t\t\tstart_threads (check_account, accounts);\n\n\t\t\tif (!silent)\n\t\t\t{\n\t\t\t\tstd::cout << boost::str (boost::format (\"Performing %1% threads blocks hash, signature, work validation...\\n\") % threads_count);\n\t\t\t}\n\t\t\tsize_t const accounts_deque_overflow (32 * 1024);\n\t\t\tauto transaction (node->store.tx_begin_read ());\n\t\t\tfor (auto i (node->store.accounts_begin (transaction)), n (node->store.accounts_end ()); i != n; ++i)\n\t\t\t{\n\t\t\t\t{\n\t\t\t\t\tnano::unique_lock<std::mutex> lock (mutex);\n\t\t\t\t\tif (accounts.size () > accounts_deque_overflow)\n\t\t\t\t\t{\n\t\t\t\t\t\tauto wait_ms (250 * accounts.size () / accounts_deque_overflow);\n\t\t\t\t\t\tconst auto wakeup (std::chrono::steady_clock::now () + std::chrono::milliseconds (wait_ms));\n\t\t\t\t\t\tcondition.wait_until (lock, wakeup);\n\t\t\t\t\t}\n\t\t\t\t\taccounts.emplace_back (i->first, i->second);\n\t\t\t\t}\n\t\t\t\tcondition.notify_all ();\n\t\t\t}\n\t\t\t{\n\t\t\t\tnano::lock_guard<std::mutex> lock (mutex);\n\t\t\t\tfinished = true;\n\t\t\t}\n\t\t\tcondition.notify_all ();\n\t\t\tfor (auto & thread : threads)\n\t\t\t{\n\t\t\t\tthread.join ();\n\t\t\t}\n\t\t\tthreads.clear ();\n\t\t\tif (!silent)\n\t\t\t{\n\t\t\t\tstd::cout << boost::str (boost::format (\"%1% accounts validated\\n\") % count);\n\t\t\t}\n\n\t\t\t// Validate total block count\n\t\t\tauto ledger_block_count (node->store.block_count (transaction));\n\t\t\tif (node->flags.enable_pruning)\n\t\t\t{\n\t\t\t\tblock_count += 1; // Add disconnected genesis block\n\t\t\t}\n\t\t\tif (block_count != ledger_block_count)\n\t\t\t{\n\t\t\t\tprint_error_message (boost::str (boost::format (\"Incorrect total block count. Blocks validated %1%. Block count in database: %2%\\n\") % block_count % ledger_block_count));\n\t\t\t}\n\n\t\t\t// Validate pending blocks\n\t\t\tcount = 0;\n\t\t\tfinished = false;\n\t\t\tstd::deque<std::pair<nano::pending_key, nano::pending_info>> pending;\n\n\t\t\tauto check_pending = [&print_error_message, &silent, &count](std::shared_ptr<nano::node> const & node, nano::read_transaction const & transaction, nano::pending_key const & key, nano::pending_info const & info) {\n\t\t\t\t++count;\n\t\t\t\tif (!silent && (count % 500000) == 0)\n\t\t\t\t{\n\t\t\t\t\tstd::cout << boost::str (boost::format (\"%1% pending blocks validated\\n\") % count);\n\t\t\t\t}\n\t\t\t\t// Check block existance\n\t\t\t\tauto block (node->store.block_get_no_sideband (transaction, key.hash));\n\t\t\t\tbool pruned (false);\n\t\t\t\tif (block == nullptr)\n\t\t\t\t{\n\t\t\t\t\tpruned = node->ledger.pruning && node->store.pruned_exists (transaction, key.hash);\n\t\t\t\t\tif (!pruned)\n\t\t\t\t\t{\n\t\t\t\t\t\tprint_error_message (boost::str (boost::format (\"Pending block does not exist %1%\\n\") % key.hash.to_string ()));\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\t// Check if pending destination is correct\n\t\t\t\t\tnano::account destination (0);\n\t\t\t\t\tbool previous_pruned = node->ledger.pruning && node->store.pruned_exists (transaction, block->previous ());\n\t\t\t\t\tif (previous_pruned)\n\t\t\t\t\t{\n\t\t\t\t\t\tblock = node->store.block_get (transaction, key.hash);\n\t\t\t\t\t}\n\t\t\t\t\tif (auto state = dynamic_cast<nano::state_block *> (block.get ()))\n\t\t\t\t\t{\n\t\t\t\t\t\tif (node->ledger.is_send (transaction, *state))\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tdestination = state->hashables.link.as_account ();\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\telse if (auto send = dynamic_cast<nano::send_block *> (block.get ()))\n\t\t\t\t\t{\n\t\t\t\t\t\tdestination = send->hashables.destination;\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\tprint_error_message (boost::str (boost::format (\"Incorrect type for pending block %1%\\n\") % key.hash.to_string ()));\n\t\t\t\t\t}\n\t\t\t\t\tif (key.account != destination)\n\t\t\t\t\t{\n\t\t\t\t\t\tprint_error_message (boost::str (boost::format (\"Incorrect destination for pending block %1%\\n\") % key.hash.to_string ()));\n\t\t\t\t\t}\n\t\t\t\t\t// Check if pending source is correct\n\t\t\t\t\tauto account (node->ledger.account (transaction, key.hash));\n\t\t\t\t\tif (info.source != account && !pruned)\n\t\t\t\t\t{\n\t\t\t\t\t\tprint_error_message (boost::str (boost::format (\"Incorrect source for pending block %1%\\n\") % key.hash.to_string ()));\n\t\t\t\t\t}\n\t\t\t\t\t// Check if pending amount is correct\n\t\t\t\t\tif (!pruned && !previous_pruned)\n\t\t\t\t\t{\n\t\t\t\t\t\tauto amount (node->ledger.amount (transaction, key.hash));\n\t\t\t\t\t\tif (info.amount != amount)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tprint_error_message (boost::str (boost::format (\"Incorrect amount for pending block %1%\\n\") % key.hash.to_string ()));\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\n\t\t\tstart_threads (check_pending, pending);\n\n\t\t\tsize_t const pending_deque_overflow (64 * 1024);\n\t\t\tfor (auto i (node->store.pending_begin (transaction)), n (node->store.pending_end ()); i != n; ++i)\n\t\t\t{\n\t\t\t\t{\n\t\t\t\t\tnano::unique_lock<std::mutex> lock (mutex);\n\t\t\t\t\tif (pending.size () > pending_deque_overflow)\n\t\t\t\t\t{\n\t\t\t\t\t\tauto wait_ms (50 * pending.size () / pending_deque_overflow);\n\t\t\t\t\t\tconst auto wakeup (std::chrono::steady_clock::now () + std::chrono::milliseconds (wait_ms));\n\t\t\t\t\t\tcondition.wait_until (lock, wakeup);\n\t\t\t\t\t}\n\t\t\t\t\tpending.emplace_back (i->first, i->second);\n\t\t\t\t}\n\t\t\t\tcondition.notify_all ();\n\t\t\t}\n\t\t\t{\n\t\t\t\tnano::lock_guard<std::mutex> lock (mutex);\n\t\t\t\tfinished = true;\n\t\t\t}\n\t\t\tcondition.notify_all ();\n\t\t\tfor (auto & thread : threads)\n\t\t\t{\n\t\t\t\tthread.join ();\n\t\t\t}\n\t\t\tif (!silent)\n\t\t\t{\n\t\t\t\tstd::cout << boost::str (boost::format (\"%1% pending blocks validated\\n\") % count);\n\t\t\t\ttimer.stop ();\n\t\t\t\tstd::cout << boost::str (boost::format (\"%1% %2% validation time\\n\") % timer.value ().count () % timer.unit ());\n\t\t\t}\n\t\t\tif (errors == 0)\n\t\t\t{\n\t\t\t\tstd::cout << \"Validation status: Ok\\n\";\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tstd::cout << boost::str (boost::format (\"Validation status: Failed\\n%1% errors found\\n\") % errors);\n\t\t\t}\n\t\t}\n\t\telse if (vm.count (\"debug_profile_bootstrap\"))\n\t\t{\n\t\t\tauto node_flags = nano::inactive_node_flag_defaults ();\n\t\t\tnode_flags.read_only = false;\n\t\t\tnano::update_flags (node_flags, vm);\n\t\t\tnano::inactive_node node (nano::unique_path (), node_flags);\n\t\t\tnano::genesis genesis;\n\t\t\tauto begin (std::chrono::high_resolution_clock::now ());\n\t\t\tuint64_t block_count (0);\n\t\t\tsize_t count (0);\n\t\t\tstd::deque<nano::unchecked_info> epoch_open_blocks;\n\t\t\t{\n\t\t\t\tauto node_flags = nano::inactive_node_flag_defaults ();\n\t\t\t\tnano::update_flags (node_flags, vm);\n\t\t\t\tnode_flags.generate_cache.block_count = true;\n\t\t\t\tnano::inactive_node inactive_node (data_path, node_flags);\n\t\t\t\tauto source_node = inactive_node.node;\n\t\t\t\tauto transaction (source_node->store.tx_begin_read ());\n\t\t\t\tblock_count = source_node->ledger.cache.block_count;\n\t\t\t\tstd::cout << boost::str (boost::format (\"Performing bootstrap emulation, %1% blocks in ledger...\") % block_count) << std::endl;\n\t\t\t\tfor (auto i (source_node->store.accounts_begin (transaction)), n (source_node->store.accounts_end ()); i != n; ++i)\n\t\t\t\t{\n\t\t\t\t\tnano::account const & account (i->first);\n\t\t\t\t\tnano::account_info const & info (i->second);\n\t\t\t\t\tauto hash (info.head);\n\t\t\t\t\twhile (!hash.is_zero ())\n\t\t\t\t\t{\n\t\t\t\t\t\t// Retrieving block data\n\t\t\t\t\t\tauto block (source_node->store.block_get_no_sideband (transaction, hash));\n\t\t\t\t\t\tif (block != nullptr)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t++count;\n\t\t\t\t\t\t\tif ((count % 500000) == 0)\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tstd::cout << boost::str (boost::format (\"%1% blocks retrieved\") % count) << std::endl;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tnano::unchecked_info unchecked_info (block, account, 0, nano::signature_verification::unknown);\n\t\t\t\t\t\t\tnode.node->block_processor.add (unchecked_info);\n\t\t\t\t\t\t\tif (block->type () == nano::block_type::state && block->previous ().is_zero () && source_node->ledger.is_epoch_link (block->link ()))\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t// Epoch open blocks can be rejected without processed pending blocks to account, push it later again\n\t\t\t\t\t\t\t\tepoch_open_blocks.push_back (unchecked_info);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t// Retrieving previous block hash\n\t\t\t\t\t\t\thash = block->previous ();\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tnano::timer<std::chrono::seconds> timer_l (nano::timer_state::started);\n\t\t\twhile (node.node->ledger.cache.block_count != block_count)\n\t\t\t{\n\t\t\t\tstd::this_thread::sleep_for (std::chrono::milliseconds (500));\n\t\t\t\t// Add epoch open blocks again if required\n\t\t\t\tif (node.node->block_processor.size () == 0)\n\t\t\t\t{\n\t\t\t\t\tfor (auto & unchecked_info : epoch_open_blocks)\n\t\t\t\t\t{\n\t\t\t\t\t\tnode.node->block_processor.add (unchecked_info);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// Message each 60 seconds\n\t\t\t\tif (timer_l.after_deadline (std::chrono::seconds (60)))\n\t\t\t\t{\n\t\t\t\t\ttimer_l.restart ();\n\t\t\t\t\tstd::cout << boost::str (boost::format (\"%1% (%2%) blocks processed (unchecked)\") % node.node->ledger.cache.block_count % node.node->store.unchecked_count (node.node->store.tx_begin_read ())) << std::endl;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tnode.node->block_processor.flush ();\n\n\t\t\tauto end (std::chrono::high_resolution_clock::now ());\n\t\t\tauto time (std::chrono::duration_cast<std::chrono::microseconds> (end - begin).count ());\n\t\t\tauto us_in_second (1000000);\n\t\t\tauto seconds (time / us_in_second);\n\t\t\tnano::remove_temporary_directories ();\n\t\t\tstd::cout << boost::str (boost::format (\"%|1$ 12d| seconds \\n%2% blocks per second\") % seconds % (block_count * us_in_second / time)) << std::endl;\n\t\t\trelease_assert (node.node->ledger.cache.block_count == block_count);\n\t\t}\n\t\telse if (vm.count (\"debug_peers\"))\n\t\t{\n\t\t\tauto inactive_node = nano::default_inactive_node (data_path, vm);\n\t\t\tauto node = inactive_node->node;\n\t\t\tauto transaction (node->store.tx_begin_read ());\n\n\t\t\tfor (auto i (node->store.peers_begin (transaction)), n (node->store.peers_end ()); i != n; ++i)\n\t\t\t{\n\t\t\t\tstd::cout << boost::str (boost::format (\"%1%\\n\") % nano::endpoint (boost::asio::ip::address_v6 (i->first.address_bytes ()), i->first.port ()));\n\t\t\t}\n\t\t}\n\t\telse if (vm.count (\"debug_cemented_block_count\"))\n\t\t{\n\t\t\tauto node_flags = nano::inactive_node_flag_defaults ();\n\t\t\tnode_flags.generate_cache.cemented_count = true;\n\t\t\tnano::update_flags (node_flags, vm);\n\t\t\tnano::inactive_node node (data_path, node_flags);\n\t\t\tstd::cout << \"Total cemented block count: \" << node.node->ledger.cache.cemented_count << std::endl;\n\t\t}\n\t\telse if (vm.count (\"debug_prune\"))\n\t\t{\n\t\t\tauto node_flags = nano::inactive_node_flag_defaults ();\n\t\t\tnode_flags.read_only = false;\n\t\t\tnano::update_flags (node_flags, vm);\n\t\t\tnano::inactive_node inactive_node (data_path, node_flags);\n\t\t\tauto node = inactive_node.node;\n\t\t\tnode->ledger_pruning (node_flags.block_processor_batch_size != 0 ? node_flags.block_processor_batch_size : 16 * 1024, true, true);\n\t\t}\n\t\telse if (vm.count (\"debug_stacktrace\"))\n\t\t{\n\t\t\tstd::cout << boost::stacktrace::stacktrace ();\n\t\t}\n\t\telse if (vm.count (\"debug_sys_logging\"))\n\t\t{\n#ifdef BOOST_WINDOWS\n\t\t\tif (!nano::event_log_reg_entry_exists () && !nano::is_windows_elevated ())\n\t\t\t{\n\t\t\t\tstd::cerr << \"The event log requires the HKEY_LOCAL_MACHINE\\\\SYSTEM\\\\CurrentControlSet\\\\Services\\\\EventLog\\\\Nano\\\\Nano registry entry, run again as administator to create it.\\n\";\n\t\t\t\treturn 1;\n\t\t\t}\n#endif\n\t\t\tauto inactive_node = nano::default_inactive_node (data_path, vm);\n\t\t\tinactive_node->node->logger.always_log (nano::severity_level::error, \"Testing system logger\");\n\t\t}\n\t\telse if (vm.count (\"debug_account_versions\"))\n\t\t{\n\t\t\tauto inactive_node = nano::default_inactive_node (data_path, vm);\n\t\t\tauto node = inactive_node->node;\n\t\t\tauto const epoch_count = nano::normalized_epoch (nano::epoch::max) + static_cast<std::underlying_type<nano::epoch>::type> (1);\n\t\t\t// Cache the accounts in a collection to make searching quicker against unchecked keys. Group by epoch\n\t\t\tnano::locked<std::vector<boost::unordered_set<nano::account>>> opened_account_versions_shared (epoch_count);\n\t\t\tusing opened_account_versions_t = decltype (opened_account_versions_shared)::value_type;\n\t\t\tnode->store.accounts_for_each_par (\n\t\t\t[&opened_account_versions_shared, epoch_count](nano::read_transaction const & /*unused*/, nano::store_iterator<nano::account, nano::account_info> i, nano::store_iterator<nano::account, nano::account_info> n) {\n\t\t\t\t// First cache locally\n\t\t\t\topened_account_versions_t opened_account_versions_l (epoch_count);\n\t\t\t\tfor (; i != n; ++i)\n\t\t\t\t{\n\t\t\t\t\tauto const & account (i->first);\n\t\t\t\t\tauto const & account_info (i->second);\n\n\t\t\t\t\t// Epoch 0 will be index 0 for instance\n\t\t\t\t\tauto epoch_idx = nano::normalized_epoch (account_info.epoch ());\n\t\t\t\t\topened_account_versions_l[epoch_idx].emplace (account);\n\t\t\t\t}\n\t\t\t\t// Now merge\n\t\t\t\tauto opened_account_versions = opened_account_versions_shared.lock ();\n\t\t\t\tdebug_assert (opened_account_versions->size () == opened_account_versions_l.size ());\n\t\t\t\tfor (auto idx (0); idx < opened_account_versions_l.size (); ++idx)\n\t\t\t\t{\n\t\t\t\t\tauto & accounts = opened_account_versions->at (idx);\n\t\t\t\t\tauto const & accounts_l = opened_account_versions_l.at (idx);\n\t\t\t\t\taccounts.insert (accounts_l.begin (), accounts_l.end ());\n\t\t\t\t}\n\t\t\t});\n\n\t\t\t// Caching in a single set speeds up lookup\n\t\t\tboost::unordered_set<nano::account> opened_accounts;\n\t\t\t{\n\t\t\t\tauto opened_account_versions = opened_account_versions_shared.lock ();\n\t\t\t\tfor (auto const & account_version : *opened_account_versions)\n\t\t\t\t{\n\t\t\t\t\topened_accounts.insert (account_version.cbegin (), account_version.cend ());\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Iterate all pending blocks and collect the lowest version for each unopened account\n\t\t\tnano::locked<boost::unordered_map<nano::account, std::underlying_type_t<nano::epoch>>> unopened_highest_pending_shared;\n\t\t\tusing unopened_highest_pending_t = decltype (unopened_highest_pending_shared)::value_type;\n\t\t\tnode->store.pending_for_each_par (\n\t\t\t[&unopened_highest_pending_shared, &opened_accounts](nano::read_transaction const & /*unused*/, nano::store_iterator<nano::pending_key, nano::pending_info> i, nano::store_iterator<nano::pending_key, nano::pending_info> n) {\n\t\t\t\t// First cache locally\n\t\t\t\tunopened_highest_pending_t unopened_highest_pending_l;\n\t\t\t\tfor (; i != n; ++i)\n\t\t\t\t{\n\t\t\t\t\tnano::pending_key const & key (i->first);\n\t\t\t\t\tnano::pending_info const & info (i->second);\n\t\t\t\t\tauto & account = key.account;\n\t\t\t\t\tauto exists = opened_accounts.find (account) != opened_accounts.end ();\n\t\t\t\t\tif (!exists)\n\t\t\t\t\t{\n\t\t\t\t\t\t// This is an unopened account, store the lowest pending version\n\t\t\t\t\t\tauto epoch = nano::normalized_epoch (info.epoch);\n\t\t\t\t\t\tauto & existing_or_new = unopened_highest_pending_l[key.account];\n\t\t\t\t\t\texisting_or_new = std::max (epoch, existing_or_new);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// Now merge\n\t\t\t\tauto unopened_highest_pending = unopened_highest_pending_shared.lock ();\n\t\t\t\tfor (auto const & [account, epoch] : unopened_highest_pending_l)\n\t\t\t\t{\n\t\t\t\t\tauto & existing_or_new = unopened_highest_pending->operator[] (account);\n\t\t\t\t\texisting_or_new = std::max (epoch, existing_or_new);\n\t\t\t\t}\n\t\t\t});\n\n\t\t\tauto output_account_version_number = [](auto version, auto num_accounts) {\n\t\t\t\tstd::cout << \"Account version \" << version << \" num accounts: \" << num_accounts << \"\\n\";\n\t\t\t};\n\n\t\t\t// Only single-threaded access from now on\n\t\t\tauto const & opened_account_versions = *opened_account_versions_shared.lock ();\n\t\t\tauto const & unopened_highest_pending = *unopened_highest_pending_shared.lock ();\n\n\t\t\t// Output total version counts for the opened accounts\n\t\t\tstd::cout << \"Opened accounts:\\n\";\n\t\t\tfor (auto i = 0u; i < opened_account_versions.size (); ++i)\n\t\t\t{\n\t\t\t\toutput_account_version_number (i, opened_account_versions[i].size ());\n\t\t\t}\n\n\t\t\t// Accumulate the version numbers for the highest pending epoch for each unopened account.\n\t\t\tstd::vector<size_t> unopened_account_version_totals (epoch_count);\n\t\t\tfor (auto const & [account, epoch] : unopened_highest_pending)\n\t\t\t{\n\t\t\t\t++unopened_account_version_totals[epoch];\n\t\t\t}\n\n\t\t\t// Output total version counts for the unopened accounts\n\t\t\tstd::cout << \"\\nUnopened accounts:\\n\";\n\t\t\tfor (auto i = 0u; i < unopened_account_version_totals.size (); ++i)\n\t\t\t{\n\t\t\t\toutput_account_version_number (i, unopened_account_version_totals[i]);\n\t\t\t}\n\t\t}\n\t\telse if (vm.count (\"debug_unconfirmed_frontiers\"))\n\t\t{\n\t\t\tauto inactive_node = nano::default_inactive_node (data_path, vm);\n\t\t\tauto node = inactive_node->node;\n\n\t\t\tauto unconfirmed_frontiers = node->ledger.unconfirmed_frontiers ();\n\t\t\tstd::cout << \"Account: Height delta | Frontier | Confirmed frontier\\n\";\n\t\t\tfor (auto const & [height_delta, unconfirmed_info] : unconfirmed_frontiers)\n\t\t\t{\n\t\t\t\tstd::cout << (boost::format (\"%1%: %2% %3% %4%\\n\") % unconfirmed_info.account.to_account () % height_delta % unconfirmed_info.frontier.to_string () % unconfirmed_info.cemented_frontier.to_string ()).str ();\n\t\t\t}\n\n\t\t\tstd::cout << \"\\nNumber of unconfirmed frontiers: \" << unconfirmed_frontiers.size () << std::endl;\n\t\t}\n\t\telse if (vm.count (\"version\"))\n\t\t{\n\t\t\tstd::cout << \"Version \" << NANO_VERSION_STRING << \"\\n\"\n\t\t\t          << \"Build Info \" << BUILD_INFO << std::endl;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tstd::cout << description << std::endl;\n\t\t\tresult = -1;\n\t\t}\n\t}\n\treturn result;\n}\n\nnamespace\n{\nstd::istream & operator>> (std::istream & in, uint64_from_hex & out_val)\n{\n\tin >> std::hex >> out_val.value;\n\treturn in;\n}\n\naddress_library_pair::address_library_pair (uint64_t address, std::string library) :\naddress (address), library (library)\n{\n}\n\nbool address_library_pair::operator< (const address_library_pair & other) const\n{\n\treturn address < other.address;\n}\n\nbool address_library_pair::operator== (const address_library_pair & other) const\n{\n\treturn address == other.address;\n}\n}\n", "idx": 3, "id": 16605, "msg": "", "proj": "nanocurrency-nano-node", "lang": "cpp"}
{"patch": "@@ -10,6 +10,8 @@ import (\n \t\"context\"\n \t\"encoding/hex\"\n \t\"math/big\"\n+\t\"math/rand\"\n+\t\"sort\"\n \t\"testing\"\n \t\"time\"\n ", "y": 0, "oldf": "// Copyright (c) 2019 IoTeX\n// This is an alpha (internal) release and is not suitable for production. This source code is provided 'as is' and no\n// warranties are given as to title or non-infringement, merchantability or fitness for purpose and, to the extent\n// permitted by law, all liability for your use of the code is disclaimed. This source code is governed by Apache\n// License 2.0 that can be found in the LICENSE file.\n\npackage api\n\nimport (\n\t\"context\"\n\t\"encoding/hex\"\n\t\"math/big\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/golang/mock/gomock\"\n\t\"github.com/golang/protobuf/proto\"\n\t\"github.com/iotexproject/iotex-election/test/mock/mock_committee\"\n\t\"github.com/iotexproject/iotex-election/types\"\n\t\"github.com/pkg/errors\"\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/require\"\n\n\t\"github.com/iotexproject/iotex-core/action\"\n\t\"github.com/iotexproject/iotex-core/action/protocol\"\n\t\"github.com/iotexproject/iotex-core/action/protocol/account\"\n\taccountutil \"github.com/iotexproject/iotex-core/action/protocol/account/util\"\n\t\"github.com/iotexproject/iotex-core/action/protocol/execution\"\n\t\"github.com/iotexproject/iotex-core/action/protocol/poll\"\n\t\"github.com/iotexproject/iotex-core/action/protocol/poll/pollpb\"\n\t\"github.com/iotexproject/iotex-core/action/protocol/rewarding\"\n\t\"github.com/iotexproject/iotex-core/action/protocol/rolldpos\"\n\t\"github.com/iotexproject/iotex-core/action/protocol/vote\"\n\t\"github.com/iotexproject/iotex-core/actpool\"\n\t\"github.com/iotexproject/iotex-core/blockchain\"\n\t\"github.com/iotexproject/iotex-core/blockchain/genesis\"\n\t\"github.com/iotexproject/iotex-core/config\"\n\t\"github.com/iotexproject/iotex-core/gasstation\"\n\t\"github.com/iotexproject/iotex-core/pkg/unit\"\n\t\"github.com/iotexproject/iotex-core/pkg/util/byteutil\"\n\t\"github.com/iotexproject/iotex-core/protogen/iotexapi\"\n\t\"github.com/iotexproject/iotex-core/protogen/iotextypes\"\n\t\"github.com/iotexproject/iotex-core/state/factory\"\n\t\"github.com/iotexproject/iotex-core/test/identityset\"\n\t\"github.com/iotexproject/iotex-core/test/mock/mock_blockchain\"\n\t\"github.com/iotexproject/iotex-core/test/mock/mock_dispatcher\"\n\tta \"github.com/iotexproject/iotex-core/test/testaddress\"\n\t\"github.com/iotexproject/iotex-core/testutil\"\n)\n\nconst (\n\ttestTriePath = \"trie.test\"\n\ttestDBPath   = \"db.test\"\n)\n\nvar (\n\ttestTransfer, _ = testutil.SignedTransfer(ta.Addrinfo[\"alfa\"].String(),\n\t\tta.Keyinfo[\"alfa\"].PriKey, 3, big.NewInt(10), []byte{}, testutil.TestGasLimit,\n\t\tbig.NewInt(testutil.TestGasPrice))\n\n\ttestTransferPb = testTransfer.Proto()\n\n\ttestExecution, _ = testutil.SignedExecution(ta.Addrinfo[\"bravo\"].String(),\n\t\tta.Keyinfo[\"bravo\"].PriKey, 1, big.NewInt(0), testutil.TestGasLimit,\n\t\tbig.NewInt(testutil.TestGasPrice), []byte{})\n\n\ttestExecutionPb = testExecution.Proto()\n\n\ttestTransfer1, _ = testutil.SignedTransfer(ta.Addrinfo[\"charlie\"].String(), ta.Keyinfo[\"producer\"].PriKey, 1,\n\t\tbig.NewInt(10), []byte{}, testutil.TestGasLimit, big.NewInt(testutil.TestGasPrice))\n\ttransferHash1 = testTransfer1.Hash()\n\ttestVote1, _  = testutil.SignedVote(ta.Addrinfo[\"charlie\"].String(), ta.Keyinfo[\"charlie\"].PriKey, 5,\n\t\ttestutil.TestGasLimit, big.NewInt(testutil.TestGasPrice))\n\tvoteHash1         = testVote1.Hash()\n\ttestExecution1, _ = testutil.SignedExecution(ta.Addrinfo[\"delta\"].String(), ta.Keyinfo[\"producer\"].PriKey, 5,\n\t\tbig.NewInt(1), testutil.TestGasLimit, big.NewInt(10), []byte{1})\n\texecutionHash1    = testExecution1.Hash()\n\ttestExecution2, _ = testutil.SignedExecution(ta.Addrinfo[\"delta\"].String(), ta.Keyinfo[\"charlie\"].PriKey, 6,\n\t\tbig.NewInt(1), testutil.TestGasLimit, big.NewInt(testutil.TestGasPrice), []byte{1})\n\texecutionHash2    = testExecution2.Hash()\n\ttestExecution3, _ = testutil.SignedExecution(ta.Addrinfo[\"delta\"].String(), ta.Keyinfo[\"alfa\"].PriKey, 2,\n\t\tbig.NewInt(1), testutil.TestGasLimit, big.NewInt(testutil.TestGasPrice), []byte{1})\n\texecutionHash3 = testExecution3.Hash()\n)\n\nvar (\n\tdelegates = []genesis.Delegate{\n\t\t{\n\t\t\tOperatorAddrStr: identityset.Address(0).String(),\n\t\t\tVotesStr:        \"10\",\n\t\t},\n\t\t{\n\t\t\tOperatorAddrStr: identityset.Address(1).String(),\n\t\t\tVotesStr:        \"10\",\n\t\t},\n\t\t{\n\t\t\tOperatorAddrStr: identityset.Address(2).String(),\n\t\t\tVotesStr:        \"10\",\n\t\t},\n\t}\n)\n\nvar (\n\tgetAccountTests = []struct {\n\t\tin           string\n\t\taddress      string\n\t\tbalance      string\n\t\tnonce        uint64\n\t\tpendingNonce uint64\n\t}{\n\t\t{ta.Addrinfo[\"charlie\"].String(),\n\t\t\t\"io1d4c5lp4ea4754wy439g2t99ue7wryu5r2lslh2\",\n\t\t\t\"3\",\n\t\t\t8,\n\t\t\t9,\n\t\t},\n\t\t{\n\t\t\tta.Addrinfo[\"producer\"].String(),\n\t\t\t\"io1mflp9m6hcgm2qcghchsdqj3z3eccrnekx9p0ms\",\n\t\t\t\"9999999999999999999999999991\",\n\t\t\t1,\n\t\t\t6,\n\t\t},\n\t}\n\n\tgetActionsTests = []struct {\n\t\tstart      uint64\n\t\tcount      uint64\n\t\tnumActions int\n\t}{\n\t\t{\n\t\t\t1,\n\t\t\t11,\n\t\t\t11,\n\t\t},\n\t\t{\n\t\t\t11,\n\t\t\t5,\n\t\t\t4,\n\t\t},\n\t}\n\n\tgetActionTests = []struct {\n\t\tcheckPending bool\n\t\tin           string\n\t\tnonce        uint64\n\t\tsenderPubKey string\n\t}{\n\t\t{\n\t\t\tfalse,\n\t\t\thex.EncodeToString(transferHash1[:]),\n\t\t\t1,\n\t\t\ttestTransfer1.SrcPubkey().HexString(),\n\t\t},\n\t\t{\n\t\t\tfalse,\n\t\t\thex.EncodeToString(voteHash1[:]),\n\t\t\t5,\n\t\t\ttestVote1.SrcPubkey().HexString(),\n\t\t},\n\t\t{\n\t\t\ttrue,\n\t\t\thex.EncodeToString(executionHash1[:]),\n\t\t\t5,\n\t\t\ttestExecution1.SrcPubkey().HexString(),\n\t\t},\n\t}\n\n\tgetActionsByAddressTests = []struct {\n\t\taddress    string\n\t\tstart      uint64\n\t\tcount      uint64\n\t\tnumActions int\n\t}{\n\t\t{\n\t\t\tta.Addrinfo[\"producer\"].String(),\n\t\t\t0,\n\t\t\t3,\n\t\t\t2,\n\t\t},\n\t\t{\n\t\t\tta.Addrinfo[\"charlie\"].String(),\n\t\t\t1,\n\t\t\t8,\n\t\t\t8,\n\t\t},\n\t}\n\n\tgetUnconfirmedActionsByAddressTests = []struct {\n\t\taddress    string\n\t\tstart      uint64\n\t\tcount      uint64\n\t\tnumActions int\n\t}{\n\t\t{\n\t\t\tta.Addrinfo[\"producer\"].String(),\n\t\t\t0,\n\t\t\t4,\n\t\t\t4,\n\t\t},\n\t}\n\n\tgetActionsByBlockTests = []struct {\n\t\tblkHeight  uint64\n\t\tstart      uint64\n\t\tcount      uint64\n\t\tnumActions int\n\t}{\n\t\t{\n\t\t\t2,\n\t\t\t0,\n\t\t\t7,\n\t\t\t7,\n\t\t},\n\t\t{\n\t\t\t4,\n\t\t\t0,\n\t\t\t5,\n\t\t\t5,\n\t\t},\n\t}\n\n\tgetBlockMetasTests = []struct {\n\t\tstart   uint64\n\t\tcount   uint64\n\t\tnumBlks int\n\t}{\n\t\t{\n\t\t\t0,\n\t\t\t4,\n\t\t\t4,\n\t\t},\n\t\t{\n\t\t\t1,\n\t\t\t5,\n\t\t\t3,\n\t\t},\n\t}\n\n\tgetBlockMetaTests = []struct {\n\t\tblkHeight      uint64\n\t\tnumActions     int64\n\t\ttransferAmount string\n\t}{\n\t\t{\n\t\t\t2,\n\t\t\t7,\n\t\t\t\"4\",\n\t\t},\n\t\t{\n\t\t\t4,\n\t\t\t5,\n\t\t\t\"0\",\n\t\t},\n\t}\n\n\tgetChainMetaTests = []struct {\n\t\theight     uint64\n\t\tnumActions int64\n\t\ttps        int64\n\t\tepoch      iotextypes.EpochData\n\t}{\n\t\t{\n\t\t\t4,\n\t\t\t15,\n\t\t\t15,\n\t\t\tiotextypes.EpochData{\n\t\t\t\tNum:    1,\n\t\t\t\tHeight: 1,\n\t\t\t},\n\t\t},\n\t}\n\n\tsendActionTests = []struct {\n\t\tactionPb *iotextypes.Action\n\t}{\n\t\t{\n\t\t\ttestTransferPb,\n\t\t},\n\t\t{\n\t\t\ttestExecutionPb,\n\t\t},\n\t}\n\n\tgetReceiptByActionTests = []struct {\n\t\tin     string\n\t\tstatus uint64\n\t}{\n\t\t{\n\t\t\thex.EncodeToString(executionHash2[:]),\n\t\t\t1,\n\t\t},\n\t\t{\n\t\t\thex.EncodeToString(executionHash3[:]),\n\t\t\t1,\n\t\t},\n\t}\n\n\treadContractTests = []struct {\n\t\texecHash string\n\t\tretValue string\n\t}{\n\t\t{\n\t\t\thex.EncodeToString(executionHash2[:]),\n\t\t\t\"\",\n\t\t},\n\t}\n\n\tsuggestGasPriceTests = []struct {\n\t\tdefaultGasPrice   uint64\n\t\tsuggestedGasPrice uint64\n\t}{\n\t\t{\n\t\t\t1,\n\t\t\t1,\n\t\t},\n\t}\n\n\testimateGasForActionTests = []struct {\n\t\tactionHash   string\n\t\testimatedGas uint64\n\t}{\n\t\t{\n\t\t\thex.EncodeToString(transferHash1[:]),\n\t\t\t10000,\n\t\t},\n\t\t{\n\t\t\thex.EncodeToString(voteHash1[:]),\n\t\t\t10000,\n\t\t},\n\t}\n\n\treadUnclaimedBalanceTests = []struct {\n\t\t// Arguments\n\t\tprotocolID string\n\t\tmethodName string\n\t\taddr       string\n\t\t// Expected values\n\t\treturnErr bool\n\t\tbalance   *big.Int\n\t}{\n\t\t{\n\t\t\tprotocolID: rewarding.ProtocolID,\n\t\t\tmethodName: \"UnclaimedBalance\",\n\t\t\taddr:       identityset.Address(0).String(),\n\t\t\treturnErr:  false,\n\t\t\tbalance:    unit.ConvertIotxToRau(144), // 4 block * 36 IOTX reward by default = 144 IOTX\n\t\t},\n\t\t{\n\t\t\tprotocolID: rewarding.ProtocolID,\n\t\t\tmethodName: \"UnclaimedBalance\",\n\t\t\taddr:       identityset.Address(1).String(),\n\t\t\treturnErr:  false,\n\t\t\tbalance:    unit.ConvertIotxToRau(0), // 4 block * 36 IOTX reward by default = 144 IOTX\n\t\t},\n\t\t{\n\t\t\tprotocolID: \"Wrong ID\",\n\t\t\tmethodName: \"UnclaimedBalance\",\n\t\t\taddr:       ta.Addrinfo[\"producer\"].String(),\n\t\t\treturnErr:  true,\n\t\t},\n\t\t{\n\t\t\tprotocolID: rewarding.ProtocolID,\n\t\t\tmethodName: \"Wrong Method\",\n\t\t\taddr:       ta.Addrinfo[\"producer\"].String(),\n\t\t\treturnErr:  true,\n\t\t},\n\t}\n\n\treadActiveBlockProducersByHeightTests = []struct {\n\t\t// Arguments\n\t\tprotocolID            string\n\t\tprotocolType          string\n\t\tmethodName            string\n\t\theight                uint64\n\t\tnumCandidateDelegates uint64\n\t\t// Expected Values\n\t\tnumActiveBlockProducers int\n\t}{\n\t\t{\n\t\t\tprotocolID:              \"poll\",\n\t\t\tprotocolType:            \"lifeLongDelegates\",\n\t\t\tmethodName:              \"ActiveBlockProducersByHeight\",\n\t\t\theight:                  1,\n\t\t\tnumActiveBlockProducers: 3,\n\t\t},\n\t\t{\n\t\t\tprotocolID:              \"poll\",\n\t\t\tprotocolType:            \"lifeLongDelegates\",\n\t\t\tmethodName:              \"ActiveBlockProducersByHeight\",\n\t\t\theight:                  4,\n\t\t\tnumActiveBlockProducers: 3,\n\t\t},\n\t\t{\n\t\t\tprotocolID:              \"poll\",\n\t\t\tprotocolType:            \"governanceChainCommittee\",\n\t\t\tmethodName:              \"ActiveBlockProducersByHeight\",\n\t\t\theight:                  1,\n\t\t\tnumCandidateDelegates:   2,\n\t\t\tnumActiveBlockProducers: 2,\n\t\t},\n\t\t{\n\t\t\tprotocolID:              \"poll\",\n\t\t\tprotocolType:            \"governanceChainCommittee\",\n\t\t\tmethodName:              \"ActiveBlockProducersByHeight\",\n\t\t\theight:                  4,\n\t\t\tnumCandidateDelegates:   1,\n\t\t\tnumActiveBlockProducers: 1,\n\t\t},\n\t}\n\n\treadCommitteeProducersByHeightTests = []struct {\n\t\t// Arguments\n\t\tprotocolID   string\n\t\tprotocolType string\n\t\tmethodName   string\n\t\theight       uint64\n\t\tnumDelegates uint64\n\t\t// Expected Values\n\t\tnumCommitteeBlockProducers int\n\t}{\n\t\t{\n\t\t\tprotocolID:                 \"poll\",\n\t\t\tprotocolType:               \"lifeLongDelegates\",\n\t\t\tmethodName:                 \"CommitteeBlockProducersByHeight\",\n\t\t\theight:                     1,\n\t\t\tnumCommitteeBlockProducers: 3,\n\t\t},\n\t\t{\n\t\t\tprotocolID:                 \"poll\",\n\t\t\tprotocolType:               \"lifeLongDelegates\",\n\t\t\tmethodName:                 \"CommitteeBlockProducersByHeight\",\n\t\t\theight:                     4,\n\t\t\tnumCommitteeBlockProducers: 3,\n\t\t},\n\t\t{\n\t\t\tprotocolID:                 \"poll\",\n\t\t\tprotocolType:               \"governanceChainCommittee\",\n\t\t\tmethodName:                 \"CommitteeBlockProducersByHeight\",\n\t\t\theight:                     1,\n\t\t\tnumDelegates:               2,\n\t\t\tnumCommitteeBlockProducers: 2,\n\t\t},\n\t\t{\n\t\t\tprotocolID:                 \"poll\",\n\t\t\tprotocolType:               \"governanceChainCommittee\",\n\t\t\tmethodName:                 \"CommitteeBlockProducersByHeight\",\n\t\t\theight:                     4,\n\t\t\tnumDelegates:               1,\n\t\t\tnumCommitteeBlockProducers: 1,\n\t\t},\n\t}\n)\n\nfunc TestServer_GetAccount(t *testing.T) {\n\trequire := require.New(t)\n\tcfg := newConfig()\n\n\ttestutil.CleanupPath(t, testTriePath)\n\tdefer testutil.CleanupPath(t, testTriePath)\n\ttestutil.CleanupPath(t, testDBPath)\n\tdefer testutil.CleanupPath(t, testDBPath)\n\n\tsvr, err := createServer(cfg, true)\n\trequire.NoError(err)\n\n\t// success\n\tfor _, test := range getAccountTests {\n\t\trequest := &iotexapi.GetAccountRequest{Address: test.in}\n\t\tres, err := svr.GetAccount(context.Background(), request)\n\t\trequire.NoError(err)\n\t\taccountMeta := res.AccountMeta\n\t\trequire.Equal(test.address, accountMeta.Address)\n\t\trequire.Equal(test.balance, accountMeta.Balance)\n\t\trequire.Equal(test.nonce, accountMeta.Nonce)\n\t\trequire.Equal(test.pendingNonce, accountMeta.PendingNonce)\n\t}\n\t// failure\n\t_, err = svr.GetAccount(context.Background(), &iotexapi.GetAccountRequest{})\n\trequire.Error(err)\n}\n\nfunc TestServer_GetActions(t *testing.T) {\n\trequire := require.New(t)\n\tcfg := newConfig()\n\n\ttestutil.CleanupPath(t, testTriePath)\n\tdefer testutil.CleanupPath(t, testTriePath)\n\ttestutil.CleanupPath(t, testDBPath)\n\tdefer testutil.CleanupPath(t, testDBPath)\n\n\tsvr, err := createServer(cfg, false)\n\trequire.NoError(err)\n\n\tfor _, test := range getActionsTests {\n\t\trequest := &iotexapi.GetActionsRequest{\n\t\t\tLookup: &iotexapi.GetActionsRequest_ByIndex{\n\t\t\t\tByIndex: &iotexapi.GetActionsByIndexRequest{\n\t\t\t\t\tStart: test.start,\n\t\t\t\t\tCount: test.count,\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tres, err := svr.GetActions(context.Background(), request)\n\t\trequire.NoError(err)\n\t\trequire.Equal(test.numActions, len(res.Actions))\n\t}\n}\n\nfunc TestServer_GetAction(t *testing.T) {\n\trequire := require.New(t)\n\tcfg := newConfig()\n\n\ttestutil.CleanupPath(t, testTriePath)\n\tdefer testutil.CleanupPath(t, testTriePath)\n\ttestutil.CleanupPath(t, testDBPath)\n\tdefer testutil.CleanupPath(t, testDBPath)\n\n\tsvr, err := createServer(cfg, true)\n\trequire.NoError(err)\n\n\tfor _, test := range getActionTests {\n\t\trequest := &iotexapi.GetActionsRequest{\n\t\t\tLookup: &iotexapi.GetActionsRequest_ByHash{\n\t\t\t\tByHash: &iotexapi.GetActionByHashRequest{\n\t\t\t\t\tActionHash:   test.in,\n\t\t\t\t\tCheckPending: test.checkPending,\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tres, err := svr.GetActions(context.Background(), request)\n\t\trequire.NoError(err)\n\t\trequire.Equal(1, len(res.Actions))\n\t\tactPb := res.Actions[0]\n\t\trequire.Equal(test.nonce, actPb.GetCore().GetNonce())\n\t\trequire.Equal(test.senderPubKey, hex.EncodeToString(actPb.SenderPubKey))\n\t}\n}\n\nfunc TestServer_GetActionsByAddress(t *testing.T) {\n\trequire := require.New(t)\n\tcfg := newConfig()\n\n\ttestutil.CleanupPath(t, testTriePath)\n\tdefer testutil.CleanupPath(t, testTriePath)\n\ttestutil.CleanupPath(t, testDBPath)\n\tdefer testutil.CleanupPath(t, testDBPath)\n\n\tsvr, err := createServer(cfg, false)\n\trequire.NoError(err)\n\n\tfor _, test := range getActionsByAddressTests {\n\t\trequest := &iotexapi.GetActionsRequest{\n\t\t\tLookup: &iotexapi.GetActionsRequest_ByAddr{\n\t\t\t\tByAddr: &iotexapi.GetActionsByAddressRequest{\n\t\t\t\t\tAddress: test.address,\n\t\t\t\t\tStart:   test.start,\n\t\t\t\t\tCount:   test.count,\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tres, err := svr.GetActions(context.Background(), request)\n\t\trequire.NoError(err)\n\t\trequire.Equal(test.numActions, len(res.Actions))\n\t}\n}\n\nfunc TestServer_GetUnconfirmedActionsByAddress(t *testing.T) {\n\trequire := require.New(t)\n\tcfg := newConfig()\n\n\ttestutil.CleanupPath(t, testTriePath)\n\tdefer testutil.CleanupPath(t, testTriePath)\n\ttestutil.CleanupPath(t, testDBPath)\n\tdefer testutil.CleanupPath(t, testDBPath)\n\n\tsvr, err := createServer(cfg, true)\n\trequire.NoError(err)\n\n\tfor _, test := range getUnconfirmedActionsByAddressTests {\n\t\trequest := &iotexapi.GetActionsRequest{\n\t\t\tLookup: &iotexapi.GetActionsRequest_UnconfirmedByAddr{\n\t\t\t\tUnconfirmedByAddr: &iotexapi.GetUnconfirmedActionsByAddressRequest{\n\t\t\t\t\tAddress: test.address,\n\t\t\t\t\tStart:   test.start,\n\t\t\t\t\tCount:   test.count,\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tres, err := svr.GetActions(context.Background(), request)\n\t\trequire.NoError(err)\n\t\trequire.Equal(test.numActions, len(res.Actions))\n\t}\n}\n\nfunc TestServer_GetActionsByBlock(t *testing.T) {\n\trequire := require.New(t)\n\tcfg := newConfig()\n\n\ttestutil.CleanupPath(t, testTriePath)\n\tdefer testutil.CleanupPath(t, testTriePath)\n\ttestutil.CleanupPath(t, testDBPath)\n\tdefer testutil.CleanupPath(t, testDBPath)\n\n\tsvr, err := createServer(cfg, false)\n\trequire.NoError(err)\n\n\tfor _, test := range getActionsByBlockTests {\n\t\tblk, err := svr.bc.GetBlockByHeight(test.blkHeight)\n\t\trequire.NoError(err)\n\t\tblkHash := blk.HashBlock()\n\t\trequest := &iotexapi.GetActionsRequest{\n\t\t\tLookup: &iotexapi.GetActionsRequest_ByBlk{\n\t\t\t\tByBlk: &iotexapi.GetActionsByBlockRequest{\n\t\t\t\t\tBlkHash: hex.EncodeToString(blkHash[:]),\n\t\t\t\t\tStart:   test.start,\n\t\t\t\t\tCount:   test.count,\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tres, err := svr.GetActions(context.Background(), request)\n\t\trequire.NoError(err)\n\t\trequire.Equal(test.numActions, len(res.Actions))\n\t}\n}\n\nfunc TestServer_GetBlockMetas(t *testing.T) {\n\trequire := require.New(t)\n\tcfg := newConfig()\n\n\ttestutil.CleanupPath(t, testTriePath)\n\tdefer testutil.CleanupPath(t, testTriePath)\n\ttestutil.CleanupPath(t, testDBPath)\n\tdefer testutil.CleanupPath(t, testDBPath)\n\n\tsvr, err := createServer(cfg, false)\n\trequire.NoError(err)\n\n\tfor _, test := range getBlockMetasTests {\n\t\trequest := &iotexapi.GetBlockMetasRequest{\n\t\t\tLookup: &iotexapi.GetBlockMetasRequest_ByIndex{\n\t\t\t\tByIndex: &iotexapi.GetBlockMetasByIndexRequest{\n\t\t\t\t\tStart: test.start,\n\t\t\t\t\tCount: test.count,\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tres, err := svr.GetBlockMetas(context.Background(), request)\n\t\trequire.NoError(err)\n\t\trequire.Equal(test.numBlks, len(res.BlkMetas))\n\t\tvar prevBlkPb *iotextypes.BlockMeta\n\t\tfor _, blkPb := range res.BlkMetas {\n\t\t\tif prevBlkPb != nil {\n\t\t\t\trequire.True(blkPb.Height > prevBlkPb.Height)\n\t\t\t}\n\t\t\tprevBlkPb = blkPb\n\t\t}\n\t}\n}\n\nfunc TestServer_GetBlockMeta(t *testing.T) {\n\trequire := require.New(t)\n\tcfg := newConfig()\n\n\ttestutil.CleanupPath(t, testTriePath)\n\tdefer testutil.CleanupPath(t, testTriePath)\n\ttestutil.CleanupPath(t, testDBPath)\n\tdefer testutil.CleanupPath(t, testDBPath)\n\n\tsvr, err := createServer(cfg, false)\n\trequire.NoError(err)\n\n\tfor _, test := range getBlockMetaTests {\n\t\tblk, err := svr.bc.GetBlockByHeight(test.blkHeight)\n\t\trequire.NoError(err)\n\t\tblkHash := blk.HashBlock()\n\t\trequest := &iotexapi.GetBlockMetasRequest{\n\t\t\tLookup: &iotexapi.GetBlockMetasRequest_ByHash{\n\t\t\t\tByHash: &iotexapi.GetBlockMetaByHashRequest{\n\t\t\t\t\tBlkHash: hex.EncodeToString(blkHash[:]),\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tres, err := svr.GetBlockMetas(context.Background(), request)\n\t\trequire.NoError(err)\n\t\trequire.Equal(1, len(res.BlkMetas))\n\t\tblkPb := res.BlkMetas[0]\n\t\trequire.Equal(test.numActions, blkPb.NumActions)\n\t\trequire.Equal(test.transferAmount, blkPb.TransferAmount)\n\t}\n}\n\nfunc TestServer_GetChainMeta(t *testing.T) {\n\trequire := require.New(t)\n\tcfg := newConfig()\n\n\ttestutil.CleanupPath(t, testTriePath)\n\tdefer testutil.CleanupPath(t, testTriePath)\n\ttestutil.CleanupPath(t, testDBPath)\n\tdefer testutil.CleanupPath(t, testDBPath)\n\n\tsvr, err := createServer(cfg, false)\n\trequire.NoError(err)\n\n\tfor _, test := range getChainMetaTests {\n\t\tres, err := svr.GetChainMeta(context.Background(), &iotexapi.GetChainMetaRequest{})\n\t\trequire.NoError(err)\n\t\tchainMetaPb := res.ChainMeta\n\t\trequire.Equal(test.height, chainMetaPb.Height)\n\t\trequire.Equal(test.numActions, chainMetaPb.NumActions)\n\t\trequire.Equal(test.tps, chainMetaPb.Tps)\n\t\trequire.Equal(test.epoch.Num, chainMetaPb.Epoch.Num)\n\t\trequire.Equal(test.epoch.Height, chainMetaPb.Epoch.Height)\n\t}\n}\n\nfunc TestServer_SendAction(t *testing.T) {\n\trequire := require.New(t)\n\n\tctrl := gomock.NewController(t)\n\tdefer ctrl.Finish()\n\n\tchain := mock_blockchain.NewMockBlockchain(ctrl)\n\tmDp := mock_dispatcher.NewMockDispatcher(ctrl)\n\tbroadcastHandlerCount := 0\n\tsvr := Server{bc: chain, dp: mDp, broadcastHandler: func(_ context.Context, _ uint32, _ proto.Message) error {\n\t\tbroadcastHandlerCount++\n\t\treturn nil\n\t}}\n\n\tchain.EXPECT().ChainID().Return(uint32(1)).Times(4)\n\tmDp.EXPECT().HandleBroadcast(gomock.Any(), gomock.Any(), gomock.Any()).Times(2)\n\n\tfor i, test := range sendActionTests {\n\t\trequest := &iotexapi.SendActionRequest{Action: test.actionPb}\n\t\t_, err := svr.SendAction(context.Background(), request)\n\t\trequire.NoError(err)\n\t\trequire.Equal(i+1, broadcastHandlerCount)\n\t}\n}\n\nfunc TestServer_GetReceiptByAction(t *testing.T) {\n\trequire := require.New(t)\n\tcfg := newConfig()\n\n\ttestutil.CleanupPath(t, testTriePath)\n\tdefer testutil.CleanupPath(t, testTriePath)\n\ttestutil.CleanupPath(t, testDBPath)\n\tdefer testutil.CleanupPath(t, testDBPath)\n\n\tsvr, err := createServer(cfg, false)\n\trequire.NoError(err)\n\n\tfor _, test := range getReceiptByActionTests {\n\t\trequest := &iotexapi.GetReceiptByActionRequest{ActionHash: test.in}\n\t\tres, err := svr.GetReceiptByAction(context.Background(), request)\n\t\trequire.NoError(err)\n\t\treceiptPb := res.Receipt\n\t\trequire.Equal(test.status, receiptPb.Status)\n\t}\n}\n\nfunc TestServer_ReadContract(t *testing.T) {\n\trequire := require.New(t)\n\tcfg := newConfig()\n\n\ttestutil.CleanupPath(t, testTriePath)\n\tdefer testutil.CleanupPath(t, testTriePath)\n\ttestutil.CleanupPath(t, testDBPath)\n\tdefer testutil.CleanupPath(t, testDBPath)\n\n\tsvr, err := createServer(cfg, false)\n\trequire.NoError(err)\n\n\tfor _, test := range readContractTests {\n\t\thash, err := toHash256(test.execHash)\n\t\trequire.NoError(err)\n\t\texec, err := svr.bc.GetActionByActionHash(hash)\n\t\trequire.NoError(err)\n\t\trequest := &iotexapi.ReadContractRequest{Action: exec.Proto()}\n\n\t\tres, err := svr.ReadContract(context.Background(), request)\n\t\trequire.NoError(err)\n\t\trequire.Equal(test.retValue, res.Data)\n\t}\n}\n\nfunc TestServer_SuggestGasPrice(t *testing.T) {\n\trequire := require.New(t)\n\tcfg := newConfig()\n\n\ttestutil.CleanupPath(t, testTriePath)\n\tdefer testutil.CleanupPath(t, testTriePath)\n\ttestutil.CleanupPath(t, testDBPath)\n\tdefer testutil.CleanupPath(t, testDBPath)\n\n\tfor _, test := range suggestGasPriceTests {\n\t\tcfg.API.GasStation.DefaultGas = test.defaultGasPrice\n\t\tsvr, err := createServer(cfg, false)\n\t\trequire.NoError(err)\n\t\tres, err := svr.SuggestGasPrice(context.Background(), &iotexapi.SuggestGasPriceRequest{})\n\t\trequire.NoError(err)\n\t\trequire.Equal(test.suggestedGasPrice, res.GasPrice)\n\t}\n}\n\nfunc TestServer_EstimateGasForAction(t *testing.T) {\n\trequire := require.New(t)\n\tcfg := newConfig()\n\n\ttestutil.CleanupPath(t, testTriePath)\n\tdefer testutil.CleanupPath(t, testTriePath)\n\ttestutil.CleanupPath(t, testDBPath)\n\tdefer testutil.CleanupPath(t, testDBPath)\n\n\tsvr, err := createServer(cfg, false)\n\trequire.NoError(err)\n\n\tfor _, test := range estimateGasForActionTests {\n\t\thash, err := toHash256(test.actionHash)\n\t\trequire.NoError(err)\n\t\tact, err := svr.bc.GetActionByActionHash(hash)\n\t\trequire.NoError(err)\n\t\trequest := &iotexapi.EstimateGasForActionRequest{Action: act.Proto()}\n\n\t\tres, err := svr.EstimateGasForAction(context.Background(), request)\n\t\trequire.NoError(err)\n\t\trequire.Equal(test.estimatedGas, res.Gas)\n\t}\n}\n\nfunc TestServer_ReadUnclaimedBalance(t *testing.T) {\n\tcfg := newConfig()\n\ttestutil.CleanupPath(t, testTriePath)\n\tdefer testutil.CleanupPath(t, testTriePath)\n\ttestutil.CleanupPath(t, testDBPath)\n\tdefer testutil.CleanupPath(t, testDBPath)\n\n\tsvr, err := createServer(cfg, false)\n\trequire.NoError(t, err)\n\n\tfor _, test := range readUnclaimedBalanceTests {\n\t\tout, err := svr.ReadState(context.Background(), &iotexapi.ReadStateRequest{\n\t\t\tProtocolID: []byte(test.protocolID),\n\t\t\tMethodName: []byte(test.methodName),\n\t\t\tArguments:  [][]byte{[]byte(test.addr)},\n\t\t})\n\t\tif test.returnErr {\n\t\t\trequire.Error(t, err)\n\t\t\tcontinue\n\t\t}\n\t\trequire.NoError(t, err)\n\t\tval, ok := big.NewInt(0).SetString(string(out.Data), 10)\n\t\trequire.True(t, ok)\n\t\tassert.Equal(t, test.balance, val)\n\t}\n}\n\nfunc TestServer_ReadActiveBlockProducersByHeight(t *testing.T) {\n\trequire := require.New(t)\n\tcfg := newConfig()\n\n\ttestutil.CleanupPath(t, testTriePath)\n\tdefer testutil.CleanupPath(t, testTriePath)\n\ttestutil.CleanupPath(t, testDBPath)\n\tdefer testutil.CleanupPath(t, testDBPath)\n\n\tctrl := gomock.NewController(t)\n\tdefer ctrl.Finish()\n\tcommittee := mock_committee.NewMockCommittee(ctrl)\n\tr := types.NewElectionResultForTest(time.Now())\n\tcommittee.EXPECT().ResultByHeight(gomock.Any()).Return(r, nil).Times(2)\n\tcommittee.EXPECT().HeightByTime(gomock.Any()).Return(uint64(123456), nil).AnyTimes()\n\n\tfor _, test := range readActiveBlockProducersByHeightTests {\n\t\tvar pol poll.Protocol\n\t\tif test.protocolType == \"lifeLongDelegates\" {\n\t\t\tcfg.Genesis.Delegates = delegates\n\t\t\tpol = poll.NewLifeLongDelegatesProtocol(cfg.Genesis.Delegates)\n\t\t} else {\n\t\t\tpol, _ = poll.NewGovernanceChainCommitteeProtocol(\n\t\t\t\tcommittee,\n\t\t\t\tuint64(123456),\n\t\t\t\tfunc(uint64) (time.Time, error) { return time.Now(), nil },\n\t\t\t\tfunc(uint64) uint64 { return 1 },\n\t\t\t\tfunc(uint64) uint64 { return 1 },\n\t\t\t\ttest.numCandidateDelegates,\n\t\t\t\tcfg.Genesis.NumDelegates,\n\t\t\t)\n\t\t}\n\t\tsvr, err := createServer(cfg, false)\n\t\trequire.NoError(err)\n\t\trequire.NoError(svr.registry.Register(poll.ProtocolID, pol))\n\n\t\tres, err := svr.ReadState(context.Background(), &iotexapi.ReadStateRequest{\n\t\t\tProtocolID: []byte(test.protocolID),\n\t\t\tMethodName: []byte(test.methodName),\n\t\t\tArguments:  [][]byte{byteutil.Uint64ToBytes(test.height)},\n\t\t})\n\t\trequire.NoError(err)\n\t\tvar activeBlockProducers pollpb.BlockProducerList\n\t\trequire.NoError(proto.Unmarshal(res.Data, &activeBlockProducers))\n\t\trequire.Equal(test.numActiveBlockProducers, len(activeBlockProducers.BlockProducers))\n\t}\n}\n\nfunc TestServer_ReadCommitteeBlockProducersByHeight(t *testing.T) {\n\trequire := require.New(t)\n\tcfg := newConfig()\n\n\ttestutil.CleanupPath(t, testTriePath)\n\tdefer testutil.CleanupPath(t, testTriePath)\n\ttestutil.CleanupPath(t, testDBPath)\n\tdefer testutil.CleanupPath(t, testDBPath)\n\n\tctrl := gomock.NewController(t)\n\tdefer ctrl.Finish()\n\tcommittee := mock_committee.NewMockCommittee(ctrl)\n\tr := types.NewElectionResultForTest(time.Now())\n\tcommittee.EXPECT().ResultByHeight(gomock.Any()).Return(r, nil).Times(2)\n\tcommittee.EXPECT().HeightByTime(gomock.Any()).Return(uint64(123456), nil).AnyTimes()\n\n\tfor _, test := range readCommitteeProducersByHeightTests {\n\t\tvar pol poll.Protocol\n\t\tif test.protocolType == \"lifeLongDelegates\" {\n\t\t\tcfg.Genesis.Delegates = delegates\n\t\t\tpol = poll.NewLifeLongDelegatesProtocol(cfg.Genesis.Delegates)\n\t\t} else {\n\t\t\tpol, _ = poll.NewGovernanceChainCommitteeProtocol(\n\t\t\t\tcommittee,\n\t\t\t\tuint64(123456),\n\t\t\t\tfunc(uint64) (time.Time, error) { return time.Now(), nil },\n\t\t\t\tfunc(uint64) uint64 { return 1 },\n\t\t\t\tfunc(uint64) uint64 { return 1 },\n\t\t\t\tcfg.Genesis.NumCandidateDelegates,\n\t\t\t\ttest.numDelegates,\n\t\t\t)\n\t\t}\n\t\tsvr, err := createServer(cfg, false)\n\t\trequire.NoError(err)\n\t\trequire.NoError(svr.registry.Register(poll.ProtocolID, pol))\n\n\t\tres, err := svr.ReadState(context.Background(), &iotexapi.ReadStateRequest{\n\t\t\tProtocolID: []byte(test.protocolID),\n\t\t\tMethodName: []byte(test.methodName),\n\t\t\tArguments:  [][]byte{byteutil.Uint64ToBytes(test.height)},\n\t\t})\n\t\trequire.NoError(err)\n\t\tvar committeeBlockProducers pollpb.BlockProducerList\n\t\trequire.NoError(proto.Unmarshal(res.Data, &committeeBlockProducers))\n\t\trequire.Equal(test.numCommitteeBlockProducers, len(committeeBlockProducers.BlockProducers))\n\t}\n}\n\nfunc addProducerToFactory(sf factory.Factory) error {\n\tws, err := sf.NewWorkingSet()\n\tif err != nil {\n\t\treturn err\n\t}\n\tif _, err = accountutil.LoadOrCreateAccount(\n\t\tws,\n\t\tta.Addrinfo[\"producer\"].String(),\n\t\tunit.ConvertIotxToRau(10000000000),\n\t); err != nil {\n\t\treturn err\n\t}\n\tgasLimit := testutil.TestGasLimit\n\tctx := protocol.WithRunActionsCtx(context.Background(),\n\t\tprotocol.RunActionsCtx{\n\t\t\tProducer: ta.Addrinfo[\"producer\"],\n\t\t\tGasLimit: &gasLimit,\n\t\t})\n\tif _, err = ws.RunActions(ctx, 0, nil); err != nil {\n\t\treturn err\n\t}\n\treturn sf.Commit(ws)\n}\n\nfunc addTestingBlocks(bc blockchain.Blockchain) error {\n\taddr0 := ta.Addrinfo[\"producer\"].String()\n\tpriKey0 := ta.Keyinfo[\"producer\"].PriKey\n\taddr1 := ta.Addrinfo[\"alfa\"].String()\n\tpriKey1 := ta.Keyinfo[\"alfa\"].PriKey\n\taddr2 := ta.Addrinfo[\"bravo\"].String()\n\taddr3 := ta.Addrinfo[\"charlie\"].String()\n\tpriKey3 := ta.Keyinfo[\"charlie\"].PriKey\n\taddr4 := ta.Addrinfo[\"delta\"].String()\n\t// Add block 1\n\t// Producer transfer--> C\n\ttsf, err := testutil.SignedTransfer(addr3, priKey0, 1, big.NewInt(10), []byte{}, testutil.TestGasLimit, big.NewInt(testutil.TestGasPrice))\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tactionMap := make(map[string][]action.SealedEnvelope)\n\tactionMap[addr0] = []action.SealedEnvelope{tsf}\n\tblk, err := bc.MintNewBlock(\n\t\tactionMap,\n\t\ttime.Now().Unix(),\n\t)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif err := bc.ValidateBlock(blk); err != nil {\n\t\treturn err\n\t}\n\tif err := bc.CommitBlock(blk); err != nil {\n\t\treturn err\n\t}\n\n\t// Add block 2\n\t// Charlie transfer--> A, B, D, P\n\t// Charlie vote--> C\n\t// Charlie exec--> D\n\trecipients := []string{addr1, addr2, addr4, addr0}\n\tselps := make([]action.SealedEnvelope, 0)\n\tfor i, recipient := range recipients {\n\t\tselp, err := testutil.SignedTransfer(recipient, priKey3, uint64(i+1), big.NewInt(1), []byte{}, testutil.TestGasLimit, big.NewInt(testutil.TestGasPrice))\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tselps = append(selps, selp)\n\t}\n\tvote1, err := testutil.SignedVote(addr3, priKey3, 5, testutil.TestGasLimit, big.NewInt(testutil.TestGasPrice))\n\tif err != nil {\n\t\treturn err\n\t}\n\texecution1, err := testutil.SignedExecution(addr4, priKey3, 6,\n\t\tbig.NewInt(1), testutil.TestGasLimit, big.NewInt(testutil.TestGasPrice), []byte{1})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tselps = append(selps, vote1)\n\tselps = append(selps, execution1)\n\tactionMap = make(map[string][]action.SealedEnvelope)\n\tactionMap[addr3] = selps\n\tif blk, err = bc.MintNewBlock(\n\t\tactionMap,\n\t\ttime.Now().Unix(),\n\t); err != nil {\n\t\treturn err\n\t}\n\tif err := bc.ValidateBlock(blk); err != nil {\n\t\treturn err\n\t}\n\tif err := bc.CommitBlock(blk); err != nil {\n\t\treturn err\n\t}\n\n\t// Add block 3\n\t// Empty actions\n\tif blk, err = bc.MintNewBlock(\n\t\tnil,\n\t\ttime.Now().Unix(),\n\t); err != nil {\n\t\treturn err\n\t}\n\tif err := bc.ValidateBlock(blk); err != nil {\n\t\treturn err\n\t}\n\tif err := bc.CommitBlock(blk); err != nil {\n\t\treturn err\n\t}\n\n\t// Add block 4\n\t// Charlie vote--> C\n\t// Charlie exec--> D\n\t// Alfa vote--> A\n\t// Alfa exec--> D\n\tvote1, err = testutil.SignedVote(addr3, priKey3, 7, testutil.TestGasLimit, big.NewInt(testutil.TestGasPrice))\n\tif err != nil {\n\t\treturn err\n\t}\n\tvote2, err := testutil.SignedVote(addr1, priKey1, 1, testutil.TestGasLimit, big.NewInt(testutil.TestGasPrice))\n\tif err != nil {\n\t\treturn err\n\t}\n\texecution1, err = testutil.SignedExecution(addr4, priKey3, 8,\n\t\tbig.NewInt(2), testutil.TestGasLimit, big.NewInt(testutil.TestGasPrice), []byte{1})\n\tif err != nil {\n\t\treturn err\n\t}\n\texecution2, err := testutil.SignedExecution(addr4, priKey1, 2,\n\t\tbig.NewInt(1), testutil.TestGasLimit, big.NewInt(testutil.TestGasPrice), []byte{1})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tactionMap = make(map[string][]action.SealedEnvelope)\n\tactionMap[addr3] = []action.SealedEnvelope{vote1, execution1}\n\tactionMap[addr1] = []action.SealedEnvelope{vote2, execution2}\n\tif blk, err = bc.MintNewBlock(\n\t\tactionMap,\n\t\ttime.Now().Unix(),\n\t); err != nil {\n\t\treturn err\n\t}\n\tif err := bc.ValidateBlock(blk); err != nil {\n\t\treturn err\n\t}\n\treturn bc.CommitBlock(blk)\n}\n\nfunc addActsToActPool(ap actpool.ActPool) error {\n\t// Producer transfer--> A\n\ttsf1, err := testutil.SignedTransfer(ta.Addrinfo[\"alfa\"].String(), ta.Keyinfo[\"producer\"].PriKey, 2, big.NewInt(20), []byte{}, testutil.TestGasLimit, big.NewInt(testutil.TestGasPrice))\n\tif err != nil {\n\t\treturn err\n\t}\n\t// Producer vote--> P\n\tvote1, err := testutil.SignedVote(ta.Addrinfo[\"producer\"].String(), ta.Keyinfo[\"producer\"].PriKey, 3, testutil.TestGasLimit, big.NewInt(testutil.TestGasPrice))\n\tif err != nil {\n\t\treturn err\n\t}\n\t// Producer transfer--> B\n\ttsf2, err := testutil.SignedTransfer(ta.Addrinfo[\"bravo\"].String(), ta.Keyinfo[\"producer\"].PriKey, 4, big.NewInt(20), []byte{}, testutil.TestGasLimit, big.NewInt(testutil.TestGasPrice))\n\tif err != nil {\n\t\treturn err\n\t}\n\t// Producer exec--> D\n\texecution1, err := testutil.SignedExecution(ta.Addrinfo[\"delta\"].String(), ta.Keyinfo[\"producer\"].PriKey, 5,\n\t\tbig.NewInt(1), testutil.TestGasLimit, big.NewInt(10), []byte{1})\n\tif err != nil {\n\t\treturn err\n\t}\n\tif err := ap.Add(tsf1); err != nil {\n\t\treturn err\n\t}\n\tif err := ap.Add(vote1); err != nil {\n\t\treturn err\n\t}\n\tif err := ap.Add(tsf2); err != nil {\n\t\treturn err\n\t}\n\treturn ap.Add(execution1)\n}\n\nfunc setupChain(cfg config.Config) (blockchain.Blockchain, *protocol.Registry, error) {\n\tcfg.Chain.ProducerPrivKey = hex.EncodeToString(identityset.PrivateKey(0).Bytes())\n\tsf, err := factory.NewFactory(cfg, factory.InMemTrieOption())\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\t// create chain\n\tregistry := protocol.Registry{}\n\tbc := blockchain.NewBlockchain(\n\t\tcfg,\n\t\tblockchain.PrecreatedStateFactoryOption(sf),\n\t\tblockchain.InMemDaoOption(),\n\t\tblockchain.RegistryOption(&registry),\n\t)\n\tif bc == nil {\n\t\treturn nil, nil, errors.New(\"failed to create blockchain\")\n\t}\n\n\tacc := account.NewProtocol()\n\tv := vote.NewProtocol(bc)\n\tevm := execution.NewProtocol(bc)\n\trolldposProtocol := rolldpos.NewProtocol(\n\t\tgenesis.Default.NumCandidateDelegates,\n\t\tgenesis.Default.NumDelegates,\n\t\tgenesis.Default.NumSubEpochs,\n\t)\n\tr := rewarding.NewProtocol(bc, rolldposProtocol)\n\n\tif err := registry.Register(rolldpos.ProtocolID, rolldposProtocol); err != nil {\n\t\treturn nil, nil, err\n\t}\n\tif err := registry.Register(account.ProtocolID, acc); err != nil {\n\t\treturn nil, nil, err\n\t}\n\tif err := registry.Register(vote.ProtocolID, v); err != nil {\n\t\treturn nil, nil, err\n\t}\n\tif err := registry.Register(execution.ProtocolID, evm); err != nil {\n\t\treturn nil, nil, err\n\t}\n\tif err := registry.Register(rewarding.ProtocolID, r); err != nil {\n\t\treturn nil, nil, err\n\t}\n\tsf.AddActionHandlers(acc, v, evm, r)\n\tbc.Validator().AddActionEnvelopeValidators(protocol.NewGenericValidator(bc, genesis.Default.ActionGasLimit))\n\tbc.Validator().AddActionValidators(acc, v, evm, r)\n\n\treturn bc, &registry, nil\n}\n\nfunc setupActPool(bc blockchain.Blockchain, cfg config.ActPool) (actpool.ActPool, error) {\n\tap, err := actpool.NewActPool(bc, cfg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tap.AddActionEnvelopeValidators(protocol.NewGenericValidator(bc, genesis.Default.ActionGasLimit))\n\tap.AddActionValidators(vote.NewProtocol(bc), execution.NewProtocol(bc))\n\n\treturn ap, nil\n}\n\nfunc newConfig() config.Config {\n\tcfg := config.Default\n\tcfg.Chain.TrieDBPath = testTriePath\n\tcfg.Chain.ChainDBPath = testDBPath\n\tcfg.Chain.EnableIndex = true\n\treturn cfg\n}\n\nfunc createServer(cfg config.Config, needActPool bool) (*Server, error) {\n\tbc, registry, err := setupChain(cfg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tctx := context.Background()\n\n\t// Start blockchain\n\tif err := bc.Start(ctx); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Create state for producer\n\tif err := addProducerToFactory(bc.GetFactory()); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Add testing blocks\n\tif err := addTestingBlocks(bc); err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar ap actpool.ActPool\n\tif needActPool {\n\t\tap, err = setupActPool(bc, cfg.ActPool)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\t// Add actions to actpool\n\t\tif err := addActsToActPool(ap); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tapiCfg := config.API{TpsWindow: 10, MaxTransferPayloadBytes: 1024, GasStation: cfg.API.GasStation}\n\n\tsvr := &Server{\n\t\tbc:       bc,\n\t\tap:       ap,\n\t\tcfg:      apiCfg,\n\t\tgs:       gasstation.NewGasStation(bc, apiCfg),\n\t\tregistry: registry,\n\t}\n\n\treturn svr, nil\n}\n", "idx": 1, "id": 16148, "msg": "", "proj": "iotexproject-iotex-core", "lang": "go"}
{"patch": "@@ -123,6 +123,11 @@ describe \"when running over the local transport\" do\n       expect(result.map { |r| r['stdout'].strip }).to eq(%w[root root])\n     end\n \n+    it 'returns merged output', :reset_puppet_settings do\n+      result = run_nodes([\"command\", \"run\", \">&2 echo Hello $USER && whoami\"] + config_flags)\n+      expect(result.map { |r| r['merged_output'].strip }).to eq([\"Hello root\\nroot\", \"Hello root\\nroot\"])\n+    end\n+\n     it 'with script with parameters', :reset_puppet_settings do\n       with_tempfile_containing('script', \"#!/usr/bin/env bash \\n echo $1\", '.sh') do |script|\n         results = run_cli_json(%W[script run #{script.path} hello] + config_flags)", "y": 1, "oldf": "# frozen_string_literal: true\n\nrequire 'spec_helper'\nrequire 'bolt_spec/files'\nrequire 'bolt_spec/integration'\n\ndescribe \"when running over the local transport\" do\n  include BoltSpec::Files\n  include BoltSpec::Integration\n\n  let(:modulepath) { fixtures_path('modules') }\n  let(:uri) { 'localhost,local://foo' }\n  let(:user) { ENV['USER'] }\n  let(:sudo_user) { 'root' }\n  let(:sudo_password) { 'runner' }\n  let(:stdin_task) { \"sample::stdin\" }\n\n  after(:each) { Puppet.settings.send(:clear_everything_for_tests) }\n\n  context 'when using CLI options' do\n    let(:echo) { \"echo hi\" }\n    let(:config_flags) {\n      %W[--targets localhost --format json --modulepath #{modulepath}]\n    }\n\n    it 'runs multiple commands' do\n      result = run_nodes(%W[command run #{echo} --targets #{uri} --format json])\n      expect(result.map { |r| r['stdout'].strip }).to eq(%w[hi hi])\n    end\n\n    it 'reports errors when command fails' do\n      result = run_failed_nodes(%W[command run boop --targets #{uri} --format json])\n      expect(result[0]['_error']).to be\n    end\n\n    it 'returns correct exit code', :reset_puppet_settings do\n      cmd = \"puppet apply --trace --detailed-exitcodes -e 'notify {foo:}'\"\n      result = run_failed_nodes(%W[command run #{cmd} -t localhost]).first\n      expect(result['_error']['msg']).to eq('The command failed with exit code 2')\n      expect(result['_error']['details']['exit_code']).to eq(2)\n    end\n\n    it 'runs a ruby task using bolt ruby', :reset_puppet_settings do\n      result = run_one_node(%w[task run sample::bolt_ruby message=somemessage] + config_flags)\n      expect(result['env']).to match(/somemessage/)\n      expect(result['stdin']).to match(/somemessage/)\n    end\n\n    context 'specifying transport on the CLI' do\n      let(:config_flags) { %W[--targets 127.0.0.1 -m #{modulepath} --transport local] }\n\n      it \"applies bundled-ruby config\" do\n        data = { 'config' => { 'local' => { 'bundled-ruby' => true } } }\n        with_tempfile_containing('inv', data.to_yaml) do |inv|\n          cmd = %W[task run sample::bolt_ruby message=somemessage --inventoryfile #{inv.path}]\n          result = run_one_node(cmd + config_flags)\n          expect(result['env']).to match(/somemessage/)\n          expect(result['stdin']).to match(/somemessage/)\n        end\n      end\n    end\n  end\n\n  context 'when using CLI options on POSIX OS', bash: true do\n    let(:config_flags) {\n      %W[--targets #{uri} --format json --modulepath #{modulepath}]\n    }\n\n    it 'runs script with parameter', :reset_puppet_settings do\n      with_tempfile_containing('script', \"#!/usr/bin/env bash \\n echo $1\", '.sh') do |script|\n        results = run_cli_json(%W[script run #{script.path} param --targets localhost])\n        results['items'].each do |result|\n          expect(result['status']).to eq('success')\n          expect(result['value']).to eq(\n            \"stdout\"        => \"param\\n\",\n            \"stderr\"        => \"\",\n            \"merged_output\" => \"param\\n\",\n            \"exit_code\"     => 0\n          )\n        end\n      end\n    end\n\n    it 'runs multiple tasks', :reset_puppet_settings do\n      result = run_nodes(%W[task run #{stdin_task} message=somemessage] + config_flags)\n      expect(result.map { |r| r['message'].strip }).to eq(%w[somemessage somemessage])\n    end\n\n    it 'reports errors when task fails', :reset_puppet_settings do\n      result = run_failed_nodes(%w[task run results fail=true] + config_flags)\n      expect(result[0]['_error']).to be\n    end\n\n    context 'with environment variables set' do\n      before(:each) { ENV['test_var'] = \"testing this\" }\n      after(:each) { ENV.delete('test_var') }\n      # Only works with localhost's default configuration\n      let(:uri) { 'localhost' }\n\n      it 'exposes environment variables to the task' do\n        result = run_one_node(%w[task run env_var::get_var] + config_flags)\n        output = result['_output'].strip\n        expect(output).to eq(\"testing this\")\n      end\n\n      it 'exposes environment variables during apply' do\n        result = run_cli_json(%w[plan run env_var::get_var] + config_flags)\n        expect(result).not_to include('kind')\n        event = result.first['value']['report']['resource_statuses']['Notify[gettingvar]']['events'].first\n        expect(event).to include('message' => \"defined 'message' as 'testing this'\")\n      end\n    end\n  end\n\n  context 'runs as an escalated user', sudo: true do\n    let(:config_flags) {\n      %W[--targets #{uri} --format json --modulepath #{modulepath}] +\n        %W[--run-as #{sudo_user} --sudo-password #{sudo_password}]\n    }\n\n    it 'runs a command', :reset_puppet_settings do\n      result = run_nodes(%w[command run whoami] + config_flags)\n      expect(result.map { |r| r['stdout'].strip }).to eq(%w[root root])\n    end\n\n    it 'with script with parameters', :reset_puppet_settings do\n      with_tempfile_containing('script', \"#!/usr/bin/env bash \\n echo $1\", '.sh') do |script|\n        results = run_cli_json(%W[script run #{script.path} hello] + config_flags)\n        results['items'].each do |result|\n          expect(result['status']).to eq('success')\n          expect(result['value']).to eq(\n            \"stdout\"        => \"hello\\n\",\n            \"stderr\"        => \"\",\n            \"merged_output\" => \"hello\\n\",\n            \"exit_code\"     => 0\n          )\n        end\n      end\n    end\n  end\n\n  context 'when using CLI options on Windows OS', windows: true do\n    let(:config_flags) {\n      %W[--targets localhost --format json --modulepath #{modulepath}]\n    }\n\n    it 'runs powershell script with parameter', :reset_puppet_settings do\n      with_tempfile_containing('script', \"Write-Host $args\", '.ps1') do |script|\n        results = run_cli_json(%W[script run #{script.path} param --targets localhost])\n        results['items'].each do |result|\n          expect(result['status']).to eq('success')\n          expect(result['value']).to eq(\n            \"stdout\"        => \"param\\n\",\n            \"stderr\"        => \"\",\n            \"merged_output\" => \"param\\n\",\n            \"exit_code\"     => 0\n          )\n        end\n      end\n    end\n\n    it 'runs ruby script with parameter', :reset_puppet_settings do\n      ruby_script = \"puts 'Ruby' \\n ARGV.each {|a| puts a}\"\n      with_tempfile_containing('script', ruby_script, '.rb') do |script|\n        results = run_cli_json(%W[script run #{script.path} param --targets localhost])\n        results['items'].each do |result|\n          expect(result['status']).to eq('success')\n          expect(result['value']).to eq(\n            \"stdout\"        => \"Ruby\\r\\nparam\\r\\n\",\n            \"stderr\"        => \"\",\n            \"merged_output\" => \"Ruby\\r\\nparam\\r\\n\",\n            \"exit_code\"     => 0\n          )\n        end\n      end\n    end\n\n    it 'runs a task reading from stdin', :reset_puppet_settings do\n      result = run_one_node(%w[task run sample::winstdin message=somemessage] + config_flags)\n      output = result['_output'].strip\n      expect(output).to match(/STDIN: {\"message\":\"somemessage\"/)\n    end\n\n    it 'runs a task reading from $input', :reset_puppet_settings do\n      result = run_one_node(%w[task run sample::wininput message=somemessage] + config_flags)\n      output = result['_output'].strip\n      expect(output).to match(/INPUT: {\"message\":\"somemessage\"/)\n    end\n\n    it 'runs a task with parameters', :reset_puppet_settings do\n      result = run_one_node(%w[task run sample::winparams message=\u00b5somemessage] + config_flags)\n      output = result['_output'].strip\n      expect(output).to match(/Message: \u00b5somemessage/)\n    end\n\n    it 'runs a task reading from environment variables', :reset_puppet_settings do\n      result = run_one_node(%w[task run sample::winenv message=somemessage] + config_flags)\n      output = result['_output'].strip\n      expect(output).to match(/ENV: somemessage/)\n    end\n\n    it 'runs a task with complex parameters', :reset_puppet_settings do\n      complex_input_file = fixtures_path('complex_params', 'input.json')\n      expected = File.open(fixtures_path('complex_params', 'output'), 'rb', &:read)\n      result = run_one_node(%W[task run sample::complex_params --params @#{complex_input_file}] + config_flags)\n      expect(result['_output']).to eq(expected)\n    end\n  end\nend\n", "idx": 1, "id": 18196, "msg": "Verified this fails *without* these changes.", "proj": "puppetlabs-bolt", "lang": "rb"}
{"patch": "@@ -15,7 +15,6 @@ end\n I18n.load_path += Dir[File.join(mydir, 'locales', '**/*.yml')]\n I18n.reload! if I18n.backend.initialized?\n \n-\n module Faker\n   class Config\n     @locale = nil", "y": 0, "oldf": "# -*- coding: utf-8 -*-\nmydir = File.expand_path(File.dirname(__FILE__))\n\nbegin\n  require 'psych'\nrescue LoadError\nend\n\nrequire 'i18n'\nrequire 'set' # Fixes a bug in i18n 0.6.11\n\nif I18n.respond_to?(:enforce_available_locales=)\n  I18n.enforce_available_locales = true\nend\nI18n.load_path += Dir[File.join(mydir, 'locales', '**/*.yml')]\nI18n.reload! if I18n.backend.initialized?\n\n\nmodule Faker\n  class Config\n    @locale = nil\n    @random = nil\n\n    class << self\n      attr_writer :locale\n      attr_writer :random\n\n      def locale\n        @locale || I18n.locale\n      end\n\n      def own_locale\n        @locale\n      end\n\n      def random\n        @random || Random::DEFAULT\n      end\n    end\n  end\n\n  class Base\n    Numbers = Array(0..9)\n    ULetters = Array('A'..'Z')\n    Letters = ULetters + Array('a'..'z')\n\n    class << self\n      ## make sure numerify results doesn\u2019t start with a zero\n      def numerify(number_string)\n        number_string.sub(/#/) { (rand(9)+1).to_s }.gsub(/#/) { rand(10).to_s }\n      end\n\n      def letterify(letter_string)\n        letter_string.gsub(/\\?/) { sample(ULetters) }\n      end\n\n      def bothify(string)\n        letterify(numerify(string))\n      end\n\n      # Given a regular expression, attempt to generate a string\n      # that would match it.  This is a rather simple implementation,\n      # so don't be shocked if it blows up on you in a spectacular fashion.\n      #\n      # It does not handle ., *, unbounded ranges such as {1,},\n      # extensions such as (?=), character classes, some abbreviations\n      # for character classes, and nested parentheses.\n      #\n      # I told you it was simple. :) It's also probably dog-slow,\n      # so you shouldn't use it.\n      #\n      # It will take a regex like this:\n      #\n      # /^[A-PR-UWYZ0-9][A-HK-Y0-9][AEHMNPRTVXY0-9]?[ABEHMNPRVWXY0-9]? {1,2}[0-9][ABD-HJLN-UW-Z]{2}$/\n      #\n      # and generate a string like this:\n      #\n      # \"U3V  3TP\"\n      #\n      def regexify(re)\n        re = re.source if re.respond_to?(:source) # Handle either a Regexp or a String that looks like a Regexp\n        re.\n          gsub(/^\\/?\\^?/, '').gsub(/\\$?\\/?$/, '').                                                                      # Ditch the anchors\n          gsub(/\\{(\\d+)\\}/, '{\\1,\\1}').gsub(/\\?/, '{0,1}').                                                             # All {2} become {2,2} and ? become {0,1}\n          gsub(/(\\[[^\\]]+\\])\\{(\\d+),(\\d+)\\}/) {|match| $1 * sample(Array(Range.new($2.to_i, $3.to_i))) }.                # [12]{1,2} becomes [12] or [12][12]\n          gsub(/(\\([^\\)]+\\))\\{(\\d+),(\\d+)\\}/) {|match| $1 * sample(Array(Range.new($2.to_i, $3.to_i))) }.                # (12|34){1,2} becomes (12|34) or (12|34)(12|34)\n          gsub(/(\\\\?.)\\{(\\d+),(\\d+)\\}/) {|match| $1 * sample(Array(Range.new($2.to_i, $3.to_i))) }.                      # A{1,2} becomes A or AA or \\d{3} becomes \\d\\d\\d\n          gsub(/\\((.*?)\\)/) {|match| sample(match.gsub(/[\\(\\)]/, '').split('|')) }.                                      # (this|that) becomes 'this' or 'that'\n          gsub(/\\[([^\\]]+)\\]/) {|match| match.gsub(/(\\w\\-\\w)/) {|range| sample(Array(Range.new(*range.split('-')))) } }. # All A-Z inside of [] become C (or X, or whatever)\n          gsub(/\\[([^\\]]+)\\]/) {|match| sample($1.split('')) }.                                                          # All [ABC] become B (or A or C)\n          gsub('\\d') {|match| sample(Numbers) }.\n          gsub('\\w') {|match| sample(Letters) }\n      end\n\n      # Helper for the common approach of grabbing a translation\n      # with an array of values and selecting one of them.\n      def fetch(key)\n        fetched = sample(translate(\"faker.#{key}\"))\n        if fetched && fetched.match(/^\\//) && fetched.match(/\\/$/) # A regex\n          regexify(fetched)\n        else\n          fetched\n        end\n      end\n\n      # Helper for the common approach of grabbing a translation\n      # with an array of values and returning all of them.\n      def fetch_all(key)\n        fetched = translate(\"faker.#{key}\")\n        fetched = fetched.last if fetched.size <= 1\n        if !fetched.respond_to?(:sample) && fetched.match(/^\\//) && fetched.match(/\\/$/) # A regex\n          regexify(fetched)\n        else\n          fetched\n        end\n      end\n\n      # Load formatted strings from the locale, \"parsing\" them\n      # into method calls that can be used to generate a\n      # formatted translation: e.g., \"#{first_name} #{last_name}\".\n      def parse(key)\n        fetched = fetch(key)\n        parts = fetched.scan(/(\\(?)#\\{([A-Za-z]+\\.)?([^\\}]+)\\}([^#]+)?/).map {|prefix, kls, meth, etc|\n          # If the token had a class Prefix (e.g., Name.first_name)\n          # grab the constant, otherwise use self\n          cls = kls ? Faker.const_get(kls.chop) : self\n\n          # If an optional leading parentheses is not present, prefix.should == \"\", otherwise prefix.should == \"(\"\n          # In either case the information will be retained for reconstruction of the string.\n          text = prefix\n\n          # If the class has the method, call it, otherwise\n          # fetch the transation (i.e., faker.name.first_name)\n          text += cls.respond_to?(meth) ? cls.send(meth) : fetch(\"#{(kls || self).to_s.split('::').last.downcase}.#{meth.downcase}\")\n\n          # And tack on spaces, commas, etc. left over in the string\n          text += etc.to_s\n        }\n        # If the fetched key couldn't be parsed, then fallback to numerify\n        parts.any? ? parts.join : numerify(fetched)\n      end\n\n      # Call I18n.translate with our configured locale if no\n      # locale is specified\n      def translate(*args)\n        opts = args.last.is_a?(Hash) ? args.pop : {}\n        opts[:locale] ||= Faker::Config.locale\n        opts[:raise] = true\n        I18n.translate(*(args.push(opts)))\n      rescue I18n::MissingTranslationData\n        opts = args.last.is_a?(Hash) ? args.pop : {}\n        opts[:locale] = :en\n\n        # Super-simple fallback -- fallback to en if the\n        # translation was missing.  If the translation isn't\n        # in en either, then it will raise again.\n        I18n.translate(*(args.push(opts)))\n      end\n\n      # Executes block with given locale set.\n      def with_locale(tmp_locale = nil)\n        current_locale = Faker::Config.own_locale\n        Faker::Config.locale = tmp_locale\n        I18n.with_locale(tmp_locale) { yield }\n      ensure\n        Faker::Config.locale = current_locale\n      end\n\n      def flexible(key)\n        @flexible_key = key\n      end\n\n      # You can add whatever you want to the locale file, and it will get caught here.\n      # E.g., in your locale file, create a\n      #   name:\n      #     girls_name: [\"Alice\", \"Cheryl\", \"Tatiana\"]\n      # Then you can call Faker::Name.girls_name and it will act like #first_name\n      def method_missing(m, *args, &block)\n        super unless @flexible_key\n\n        # Use the alternate form of translate to get a nil rather than a \"missing translation\" string\n        if translation = translate(:faker)[@flexible_key][m]\n          sample(translation)\n        else\n          super\n        end\n      end\n\n      # Generates a random value between the interval\n      def rand_in_range(from, to)\n        from, to = to, from if to < from\n        rand(from..to)\n      end\n\n      def unique(max_retries = 10_000)\n        @unique_generator ||= UniqueGenerator.new(self, max_retries)\n      end\n\n      def sample(list)\n        list.respond_to?(:sample) ? list.sample(random: Faker::Config.random) : list\n      end\n\n      def shuffle(list)\n        list.shuffle(random: Faker::Config.random)\n      end\n\n      def rand(max = nil)\n        if max.nil?\n          Faker::Config.random.rand\n        elsif max.is_a?(Range) || max.to_i > 0\n          Faker::Config.random.rand(max)\n        else\n          0\n        end\n      end\n    end\n  end\nend\n\nDir.glob(File.join(File.dirname(__FILE__), 'faker','*.rb')).sort.each {|f| require f }\n\nrequire 'extensions/array'\nrequire 'extensions/symbol'\n\nrequire 'helpers/char'\nrequire 'helpers/unique_generator'\n", "idx": 2, "id": 8166, "msg": "", "proj": "faker-ruby-faker", "lang": "rb"}
{"patch": "@@ -258,23 +258,6 @@ func (sf *factory) NewWorkingSet() (WorkingSet, error) {\n \treturn NewWorkingSet(sf.currentChainHeight, sf.dao, sf.rootHash, sf.actionHandlers)\n }\n \n-// RunActions will be called 2 times in\n-// 1. In MintNewBlock(), the block producer runs all executions in new block and get the new trie root hash (which\n-// is written in block header), but all changes are not committed to blockchain yet\n-// 2. In CommitBlock(), all nodes except block producer will run all execution and verify the trie root hash match\n-// what's written in the block header\n-func (sf *factory) RunActions(\n-\tblockHeight uint64,\n-\ttsf []*action.Transfer,\n-\tvote []*action.Vote,\n-\texecutions []*action.Execution,\n-\tactions []action.Action) (hash.Hash32B, error) {\n-\tsf.mutex.Lock()\n-\tdefer sf.mutex.Unlock()\n-\t// use the default working set to run the actions\n-\treturn sf.activeWs.RunActions(blockHeight, tsf, vote, executions, actions)\n-}\n-\n // Commit persists all changes in RunActions() into the DB\n func (sf *factory) Commit(ws WorkingSet) error {\n \tsf.mutex.Lock()", "y": 0, "oldf": "// Copyright (c) 2018 IoTeX\n// This is an alpha (internal) release and is not suitable for production. This source code is provided 'as is' and no\n// warranties are given as to title or non-infringement, merchantability or fitness for purpose and, to the extent\n// permitted by law, all liability for your use of the code is disclaimed. This source code is governed by Apache\n// License 2.0 that can be found in the LICENSE file.\n\npackage state\n\nimport (\n\t\"context\"\n\t\"math/big\"\n\t\"sort\"\n\t\"sync\"\n\n\t\"github.com/boltdb/bolt\"\n\t\"github.com/pkg/errors\"\n\n\t\"github.com/iotexproject/iotex-core/action\"\n\t\"github.com/iotexproject/iotex-core/config\"\n\t\"github.com/iotexproject/iotex-core/db\"\n\t\"github.com/iotexproject/iotex-core/logger\"\n\t\"github.com/iotexproject/iotex-core/pkg/hash\"\n\t\"github.com/iotexproject/iotex-core/pkg/lifecycle\"\n\t\"github.com/iotexproject/iotex-core/pkg/util/byteutil\"\n\t\"github.com/iotexproject/iotex-core/trie\"\n)\n\nvar (\n\t// ErrNotEnoughBalance is the error that the balance is not enough\n\tErrNotEnoughBalance = errors.New(\"not enough balance\")\n\n\t// ErrAccountNotExist is the error that the account does not exist\n\tErrAccountNotExist = errors.New(\"account does not exist\")\n\n\t// ErrAccountCollision is the error that the account already exists\n\tErrAccountCollision = errors.New(\"account already exists\")\n\n\t// ErrFailedToMarshalState is the error that the state marshaling is failed\n\tErrFailedToMarshalState = errors.New(\"failed to marshal state\")\n\n\t// ErrFailedToUnmarshalState is the error that the state un-marshaling is failed\n\tErrFailedToUnmarshalState = errors.New(\"failed to unmarshal state\")\n)\n\nconst (\n\t// CurrentHeightKey indicates the key of current factory height in underlying DB\n\tCurrentHeightKey = \"currentHeight\"\n\t// AccountTrieRootKey indicates the key of accountTrie root hash in underlying DB\n\tAccountTrieRootKey = \"accountTrieRoot\"\n)\n\ntype (\n\t// Factory defines an interface for managing states\n\tFactory interface {\n\t\tlifecycle.StartStopper\n\t\t// Accounts\n\t\tLoadOrCreateAccountState(string, *big.Int) (*Account, error)\n\t\tBalance(string) (*big.Int, error)\n\t\tNonce(string) (uint64, error) // Note that Nonce starts with 1.\n\t\tAccountState(string) (*Account, error)\n\t\tCachedAccountState(string) (*Account, error)\n\t\tRootHash() hash.Hash32B\n\t\tHeight() (uint64, error)\n\t\tNewWorkingSet() (WorkingSet, error)\n\t\tRunActions(uint64, []*action.Transfer, []*action.Vote, []*action.Execution, []action.Action) (hash.Hash32B, error)\n\t\tCommit(WorkingSet) error\n\t\t// Contracts\n\t\tGetCodeHash(hash.PKHash) (hash.Hash32B, error)\n\t\tGetCode(hash.PKHash) ([]byte, error)\n\t\tSetCode(hash.PKHash, []byte) error\n\t\tGetContractState(hash.PKHash, hash.Hash32B) (hash.Hash32B, error)\n\t\tSetContractState(hash.PKHash, hash.Hash32B, hash.Hash32B) error\n\t\t// Candidate pool\n\t\tCandidates() (uint64, []*Candidate)\n\t\tCandidatesByHeight(uint64) ([]*Candidate, error)\n\t}\n\n\t// factory implements StateFactory interface, tracks changes to account/contract and batch-commits to DB\n\tfactory struct {\n\t\tlifecycle          lifecycle.Lifecycle\n\t\tmutex              sync.RWMutex\n\t\tcurrentChainHeight uint64\n\t\tnumCandidates      uint\n\t\tactiveWs           WorkingSet      // active working set\n\t\trootHash           hash.Hash32B    // new root hash after running executions in this block\n\t\tdao                db.KVStore      // the underlying DB for account/contract storage\n\t\tactionHandlers     []ActionHandler // the handlers to handle actions\n\t}\n\n\t// ActionHandler is the interface for the action handlers. For each incoming action, the assembled actions will be\n\t// called one by one to process it. ActionHandler implementation is supposed to parse the sub-type of the action to\n\t// decide if it wants to handle this action or not.\n\tActionHandler interface {\n\t\tHandle(action.Action, WorkingSet) error\n\t}\n)\n\n// FactoryOption sets Factory construction parameter\ntype FactoryOption func(*factory, *config.Config) error\n\n// PrecreatedTrieDBOption uses pre-created trie DB for state factory\nfunc PrecreatedTrieDBOption(kv db.KVStore) FactoryOption {\n\treturn func(sf *factory, cfg *config.Config) error {\n\t\tif kv == nil {\n\t\t\treturn errors.New(\"Invalid empty trie db\")\n\t\t}\n\t\tif err := kv.Start(context.Background()); err != nil {\n\t\t\treturn errors.Wrap(err, \"failed to start trie db\")\n\t\t}\n\t\tsf.dao = kv\n\t\t// get state trie root\n\t\troot, err := sf.getRoot(trie.AccountKVNameSpace, AccountTrieRootKey)\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"failed to get accountTrie's root hash from underlying DB\")\n\t\t}\n\t\tsf.rootHash = root\n\t\treturn nil\n\t}\n}\n\n// DefaultTrieOption creates trie from config for state factory\nfunc DefaultTrieOption() FactoryOption {\n\treturn func(sf *factory, cfg *config.Config) error {\n\t\tdbPath := cfg.Chain.TrieDBPath\n\t\tif len(dbPath) == 0 {\n\t\t\treturn errors.New(\"Invalid empty trie db path\")\n\t\t}\n\t\ttrieDB := db.NewBoltDB(dbPath, &cfg.DB)\n\t\tif err := trieDB.Start(context.Background()); err != nil {\n\t\t\treturn errors.Wrap(err, \"failed to start trie db\")\n\t\t}\n\t\tsf.dao = trieDB\n\t\t// get state trie root\n\t\troot, err := sf.getRoot(trie.AccountKVNameSpace, AccountTrieRootKey)\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"failed to get accountTrie's root hash from underlying DB\")\n\t\t}\n\t\tsf.rootHash = root\n\t\treturn nil\n\t}\n}\n\n// InMemTrieOption creates in memory trie for state factory\nfunc InMemTrieOption() FactoryOption {\n\treturn func(sf *factory, cfg *config.Config) error {\n\t\ttrieDB := db.NewMemKVStore()\n\t\tif err := trieDB.Start(context.Background()); err != nil {\n\t\t\treturn errors.Wrap(err, \"failed to start trie db\")\n\t\t}\n\t\tsf.dao = trieDB\n\t\t// get state trie root\n\t\troot, err := sf.getRoot(trie.AccountKVNameSpace, AccountTrieRootKey)\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"failed to get accountTrie's root hash from underlying DB\")\n\t\t}\n\t\tsf.rootHash = root\n\t\treturn nil\n\t}\n}\n\n// ActionHandlerOption sets the action handlers for state factory\nfunc ActionHandlerOption(actionHandlers ...ActionHandler) FactoryOption {\n\treturn func(sf *factory, cfg *config.Config) error {\n\t\tsf.actionHandlers = actionHandlers\n\t\treturn nil\n\t}\n}\n\n// NewFactory creates a new state factory\nfunc NewFactory(cfg *config.Config, opts ...FactoryOption) (Factory, error) {\n\tsf := &factory{\n\t\tcurrentChainHeight: 0,\n\t\tnumCandidates:      cfg.Chain.NumCandidates,\n\t}\n\n\tfor _, opt := range opts {\n\t\tif err := opt(sf, cfg); err != nil {\n\t\t\tlogger.Error().Err(err).Msgf(\"Failed to execute state factory creation option %p\", opt)\n\t\t\treturn nil, err\n\t\t}\n\t}\n\t// create default working set\n\tws, err := sf.NewWorkingSet()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tsf.activeWs = ws\n\tif sf.dao != nil {\n\t\tsf.lifecycle.Add(sf.dao)\n\t}\n\treturn sf, nil\n}\n\nfunc (sf *factory) Start(ctx context.Context) error { return sf.lifecycle.OnStart(ctx) }\n\nfunc (sf *factory) Stop(ctx context.Context) error { return sf.lifecycle.OnStop(ctx) }\n\n//======================================\n// account functions\n//======================================\n// LoadOrCreateAccountState loads existing or adds a new account with initial balance to the factory\n// addr should be a bech32 properly-encoded string\nfunc (sf *factory) LoadOrCreateAccountState(addr string, init *big.Int) (*Account, error) {\n\tsf.mutex.Lock()\n\tdefer sf.mutex.Unlock()\n\treturn sf.activeWs.LoadOrCreateAccountState(addr, init)\n}\n\n// Balance returns balance\nfunc (sf *factory) Balance(addr string) (*big.Int, error) {\n\tsf.mutex.RLock()\n\tdefer sf.mutex.RUnlock()\n\treturn sf.activeWs.Balance(addr)\n}\n\n// Nonce returns the Nonce if the account exists\nfunc (sf *factory) Nonce(addr string) (uint64, error) {\n\tsf.mutex.RLock()\n\tdefer sf.mutex.RUnlock()\n\treturn sf.activeWs.Nonce(addr)\n}\n\n// account returns the confirmed account state on the chain\nfunc (sf *factory) AccountState(addr string) (*Account, error) {\n\tsf.mutex.RLock()\n\tdefer sf.mutex.RUnlock()\n\treturn sf.activeWs.AccountState(addr)\n}\n\n// CachedAccountState returns the cached account state if the address exists in local cache\nfunc (sf *factory) CachedAccountState(addr string) (*Account, error) {\n\tsf.mutex.RLock()\n\tdefer sf.mutex.RUnlock()\n\treturn sf.activeWs.CachedAccountState(addr)\n}\n\n// RootHash returns the hash of the root node of the state trie\nfunc (sf *factory) RootHash() hash.Hash32B {\n\tsf.mutex.RLock()\n\tdefer sf.mutex.RUnlock()\n\treturn sf.rootHash\n}\n\n// Height returns factory's height\nfunc (sf *factory) Height() (uint64, error) {\n\tsf.mutex.RLock()\n\tdefer sf.mutex.RUnlock()\n\theight, err := sf.dao.Get(trie.AccountKVNameSpace, []byte(CurrentHeightKey))\n\tif err != nil {\n\t\treturn 0, errors.Wrap(err, \"failed to get factory's height from underlying DB\")\n\t}\n\treturn byteutil.BytesToUint64(height), nil\n}\n\nfunc (sf *factory) NewWorkingSet() (WorkingSet, error) {\n\tsf.mutex.Lock()\n\tdefer sf.mutex.Unlock()\n\treturn NewWorkingSet(sf.currentChainHeight, sf.dao, sf.rootHash, sf.actionHandlers)\n}\n\n// RunActions will be called 2 times in\n// 1. In MintNewBlock(), the block producer runs all executions in new block and get the new trie root hash (which\n// is written in block header), but all changes are not committed to blockchain yet\n// 2. In CommitBlock(), all nodes except block producer will run all execution and verify the trie root hash match\n// what's written in the block header\nfunc (sf *factory) RunActions(\n\tblockHeight uint64,\n\ttsf []*action.Transfer,\n\tvote []*action.Vote,\n\texecutions []*action.Execution,\n\tactions []action.Action) (hash.Hash32B, error) {\n\tsf.mutex.Lock()\n\tdefer sf.mutex.Unlock()\n\t// use the default working set to run the actions\n\treturn sf.activeWs.RunActions(blockHeight, tsf, vote, executions, actions)\n}\n\n// Commit persists all changes in RunActions() into the DB\nfunc (sf *factory) Commit(ws WorkingSet) error {\n\tsf.mutex.Lock()\n\tdefer sf.mutex.Unlock()\n\tif ws != nil {\n\t\tif sf.currentChainHeight != ws.Version() {\n\t\t\t// another working set with correct version already committed, do nothing\n\t\t\treturn nil\n\t\t}\n\t\tsf.activeWs = nil\n\t\tsf.activeWs = ws\n\t}\n\tif err := sf.activeWs.Commit(); err != nil {\n\t\treturn errors.Wrap(err, \"failed to commit working set\")\n\t}\n\t// Update chain height and root\n\tsf.currentChainHeight = sf.activeWs.Height()\n\tsf.rootHash = sf.activeWs.RootHash()\n\treturn nil\n}\n\n//======================================\n// Contract functions\n//======================================\n// GetCodeHash returns contract's code hash\nfunc (sf *factory) GetCodeHash(addr hash.PKHash) (hash.Hash32B, error) {\n\tsf.mutex.RLock()\n\tdefer sf.mutex.RUnlock()\n\treturn sf.activeWs.GetCodeHash(addr)\n}\n\n// GetCode returns contract's code\nfunc (sf *factory) GetCode(addr hash.PKHash) ([]byte, error) {\n\tsf.mutex.RLock()\n\tdefer sf.mutex.RUnlock()\n\treturn sf.activeWs.GetCode(addr)\n}\n\n// SetCode sets contract's code\nfunc (sf *factory) SetCode(addr hash.PKHash, code []byte) error {\n\tsf.mutex.Lock()\n\tdefer sf.mutex.Unlock()\n\treturn sf.activeWs.SetCode(addr, code)\n}\n\n// GetContractState returns contract's storage value\nfunc (sf *factory) GetContractState(addr hash.PKHash, key hash.Hash32B) (hash.Hash32B, error) {\n\tsf.mutex.RLock()\n\tdefer sf.mutex.RUnlock()\n\treturn sf.activeWs.GetContractState(addr, key)\n}\n\n// SetContractState writes contract's storage value\nfunc (sf *factory) SetContractState(addr hash.PKHash, key, value hash.Hash32B) error {\n\tsf.mutex.Lock()\n\tdefer sf.mutex.Unlock()\n\treturn sf.activeWs.SetContractState(addr, key, value)\n}\n\n//======================================\n// Candidate functions\n//======================================\n// Candidates returns array of Candidates in candidate pool\nfunc (sf *factory) Candidates() (uint64, []*Candidate) {\n\tsf.mutex.Lock()\n\tdefer sf.mutex.Unlock()\n\tcandidates, err := MapToCandidates(sf.activeWs.WorkingCandidates())\n\tif err != nil {\n\t\treturn sf.currentChainHeight, nil\n\t}\n\tif len(candidates) <= int(sf.numCandidates) {\n\t\treturn sf.currentChainHeight, candidates\n\t}\n\tsort.Sort(candidates)\n\treturn sf.currentChainHeight, candidates[:sf.numCandidates]\n}\n\n// CandidatesByHeight returns array of Candidates in candidate pool of a given height\nfunc (sf *factory) CandidatesByHeight(height uint64) ([]*Candidate, error) {\n\tsf.mutex.Lock()\n\tdefer sf.mutex.Unlock()\n\t// Load Candidates on the given height from underlying db\n\tcandidates, err := sf.activeWs.GetCandidates(height)\n\tif err != nil {\n\t\treturn []*Candidate{}, errors.Wrapf(err, \"failed to get candidates on height %d\", height)\n\t}\n\tif len(candidates) > int(sf.numCandidates) {\n\t\tcandidates = candidates[:sf.numCandidates]\n\t}\n\treturn candidates, nil\n}\n\n//======================================\n// private trie constructor functions\n//======================================\nfunc (sf *factory) getRoot(nameSpace string, key string) (hash.Hash32B, error) {\n\tvar trieRoot hash.Hash32B\n\tswitch root, err := sf.dao.Get(nameSpace, []byte(key)); errors.Cause(err) {\n\tcase nil:\n\t\ttrieRoot = byteutil.BytesTo32B(root)\n\tcase bolt.ErrBucketNotFound:\n\t\ttrieRoot = trie.EmptyRoot\n\tdefault:\n\t\treturn hash.ZeroHash32B, err\n\t}\n\treturn trieRoot, nil\n}\n", "idx": 8, "id": 12689, "msg": "", "proj": "iotexproject-iotex-core", "lang": "go"}
{"patch": "@@ -356,8 +356,8 @@ static void PrintMethodFields(Printer* p, VARS& vars,\n     vars[\"method_field_name\"] = MethodPropertiesFieldName(method.get());\n     vars[\"method_new_field_name\"] = MethodPropertiesGetterName(method.get());\n     vars[\"method_method_name\"] = MethodPropertiesGetterName(method.get());\n-    bool client_streaming = method->ClientStreaming();\n-    bool server_streaming = method->ServerStreaming();\n+    bool client_streaming = method->ClientStreaming() || method->BidiStreaming();\n+    bool server_streaming = method->ServerStreaming() || method->BidiStreaming();\n     if (client_streaming) {\n       if (server_streaming) {\n         vars[\"method_type\"] = \"BIDI_STREAMING\";", "y": 1, "oldf": "/*\n * Copyright 2016 Google Inc. All rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n#include \"java_generator.h\"\n\n#include <algorithm>\n#include <iostream>\n#include <iterator>\n#include <map>\n#include <utility>\n#include <vector>\n\n// just to get flatbuffer_version_string()\n#include <flatbuffers/flatbuffers.h>\n#include <flatbuffers/util.h>\n#define to_string flatbuffers::NumToString\n\n// Stringify helpers used solely to cast GRPC_VERSION\n#ifndef STR\n#define STR(s) #s\n#endif\n\n#ifndef XSTR\n#define XSTR(s) STR(s)\n#endif\n\n#ifndef FALLTHROUGH_INTENDED\n#define FALLTHROUGH_INTENDED\n#endif\n\ntypedef grpc_generator::Printer Printer;\ntypedef std::map<grpc::string, grpc::string> VARS;\ntypedef grpc_generator::Service ServiceDescriptor;\ntypedef grpc_generator::CommentHolder\n    DescriptorType;  // base class of all 'descriptors'\ntypedef grpc_generator::Method MethodDescriptor;\n\nnamespace grpc_java_generator {\ntypedef std::string string;\n// Generates imports for the service\nvoid GenerateImports(grpc_generator::File* file,\n                     grpc_generator::Printer* printer, VARS& vars) {\n  vars[\"filename\"] = file->filename();\n  printer->Print(\n      vars,\n      \"//Generated by flatc compiler (version $flatc_version$)\\n\");\n  printer->Print(\"//If you make any local changes, they will be lost\\n\");\n  printer->Print(vars, \"//source: $filename$.fbs\\n\\n\");\n  printer->Print(vars, \"package $Package$;\\n\\n\");\n  vars[\"Package\"] = vars[\"Package\"] + \".\";\n  if (!file->additional_headers().empty()) {\n    printer->Print(file->additional_headers().c_str());\n    printer->Print(\"\\n\\n\");\n  }\n}\n\n// Adjust a method name prefix identifier to follow the JavaBean spec:\n//   - decapitalize the first letter\n//   - remove embedded underscores & capitalize the following letter\nstatic string MixedLower(const string& word) {\n  string w;\n  w += static_cast<string::value_type>(tolower(word[0]));\n  bool after_underscore = false;\n  for (size_t i = 1; i < word.length(); ++i) {\n    if (word[i] == '_') {\n      after_underscore = true;\n    } else {\n      w += after_underscore ? static_cast<string::value_type>(toupper(word[i]))\n                            : word[i];\n      after_underscore = false;\n    }\n  }\n  return w;\n}\n\n// Converts to the identifier to the ALL_UPPER_CASE format.\n//   - An underscore is inserted where a lower case letter is followed by an\n//     upper case letter.\n//   - All letters are converted to upper case\nstatic string ToAllUpperCase(const string& word) {\n  string w;\n  for (size_t i = 0; i < word.length(); ++i) {\n    w += static_cast<string::value_type>(toupper(word[i]));\n    if ((i < word.length() - 1) && islower(word[i]) && isupper(word[i + 1])) {\n      w += '_';\n    }\n  }\n  return w;\n}\n\nstatic inline string LowerMethodName(const MethodDescriptor* method) {\n  return MixedLower(method->name());\n}\n\nstatic inline string MethodPropertiesFieldName(const MethodDescriptor* method) {\n  return \"METHOD_\" + ToAllUpperCase(method->name());\n}\n\nstatic inline string MethodPropertiesGetterName(\n    const MethodDescriptor* method) {\n  return MixedLower(\"get_\" + method->name() + \"_method\");\n}\n\nstatic inline string MethodIdFieldName(const MethodDescriptor* method) {\n  return \"METHODID_\" + ToAllUpperCase(method->name());\n}\n\nstatic inline string JavaClassName(VARS& vars, const string& name) {\n  // string name = google::protobuf::compiler::java::ClassName(desc);\n  return vars[\"Package\"] + name;\n}\n\nstatic inline string ServiceClassName(const string& service_name) {\n  return service_name + \"Grpc\";\n}\n\n// TODO(nmittler): Remove once protobuf includes javadoc methods in\n// distribution.\ntemplate <typename ITR>\nstatic void GrpcSplitStringToIteratorUsing(const string& full,\n                                           const char* delim, ITR& result) {\n  // Optimize the common case where delim is a single character.\n  if (delim[0] != '\\0' && delim[1] == '\\0') {\n    char c = delim[0];\n    const char* p = full.data();\n    const char* end = p + full.size();\n    while (p != end) {\n      if (*p == c) {\n        ++p;\n      } else {\n        const char* start = p;\n        while (++p != end && *p != c)\n          ;\n        *result++ = string(start, p - start);\n      }\n    }\n    return;\n  }\n\n  string::size_type begin_index, end_index;\n  begin_index = full.find_first_not_of(delim);\n  while (begin_index != string::npos) {\n    end_index = full.find_first_of(delim, begin_index);\n    if (end_index == string::npos) {\n      *result++ = full.substr(begin_index);\n      return;\n    }\n    *result++ = full.substr(begin_index, (end_index - begin_index));\n    begin_index = full.find_first_not_of(delim, end_index);\n  }\n}\n\nstatic void GrpcSplitStringUsing(const string& full, const char* delim,\n                                 std::vector<string>* result) {\n  std::back_insert_iterator<std::vector<string>> it(*result);\n  GrpcSplitStringToIteratorUsing(full, delim, it);\n}\n\nstatic std::vector<string> GrpcSplit(const string& full, const char* delim) {\n  std::vector<string> result;\n  GrpcSplitStringUsing(full, delim, &result);\n  return result;\n}\n\n// TODO(nmittler): Remove once protobuf includes javadoc methods in\n// distribution.\nstatic string GrpcEscapeJavadoc(const string& input) {\n  string result;\n  result.reserve(input.size() * 2);\n\n  char prev = '*';\n\n  for (string::size_type i = 0; i < input.size(); i++) {\n    char c = input[i];\n    switch (c) {\n      case '*':\n        // Avoid \"/*\".\n        if (prev == '/') {\n          result.append(\"&#42;\");\n        } else {\n          result.push_back(c);\n        }\n        break;\n      case '/':\n        // Avoid \"*/\".\n        if (prev == '*') {\n          result.append(\"&#47;\");\n        } else {\n          result.push_back(c);\n        }\n        break;\n      case '@':\n        // '@' starts javadoc tags including the @deprecated tag, which will\n        // cause a compile-time error if inserted before a declaration that\n        // does not have a corresponding @Deprecated annotation.\n        result.append(\"&#64;\");\n        break;\n      case '<':\n        // Avoid interpretation as HTML.\n        result.append(\"&lt;\");\n        break;\n      case '>':\n        // Avoid interpretation as HTML.\n        result.append(\"&gt;\");\n        break;\n      case '&':\n        // Avoid interpretation as HTML.\n        result.append(\"&amp;\");\n        break;\n      case '\\\\':\n        // Java interprets Unicode escape sequences anywhere!\n        result.append(\"&#92;\");\n        break;\n      default:\n        result.push_back(c);\n        break;\n    }\n\n    prev = c;\n  }\n\n  return result;\n}\n\nstatic std::vector<string> GrpcGetDocLines(const string& comments) {\n  if (!comments.empty()) {\n    // TODO(kenton):  Ideally we should parse the comment text as Markdown and\n    //   write it back as HTML, but this requires a Markdown parser.  For now\n    //   we just use <pre> to get fixed-width text formatting.\n\n    // If the comment itself contains block comment start or end markers,\n    // HTML-escape them so that they don't accidentally close the doc comment.\n    string escapedComments = GrpcEscapeJavadoc(comments);\n\n    std::vector<string> lines = GrpcSplit(escapedComments, \"\\n\");\n    while (!lines.empty() && lines.back().empty()) {\n      lines.pop_back();\n    }\n    return lines;\n  }\n  return std::vector<string>();\n}\n\nstatic std::vector<string> GrpcGetDocLinesForDescriptor(\n    const DescriptorType* descriptor) {\n  return descriptor->GetAllComments();\n  // return GrpcGetDocLines(descriptor->GetLeadingComments(\"///\"));\n}\n\nstatic void GrpcWriteDocCommentBody(Printer* printer, VARS& vars,\n                                    const std::vector<string>& lines,\n                                    bool surroundWithPreTag) {\n  if (!lines.empty()) {\n    if (surroundWithPreTag) {\n      printer->Print(\" * <pre>\\n\");\n    }\n\n    for (size_t i = 0; i < lines.size(); i++) {\n      // Most lines should start with a space.  Watch out for lines that start\n      // with a /, since putting that right after the leading asterisk will\n      // close the comment.\n      vars[\"line\"] = lines[i];\n      if (!lines[i].empty() && lines[i][0] == '/') {\n        printer->Print(vars, \" * $line$\\n\");\n      } else {\n        printer->Print(vars, \" *$line$\\n\");\n      }\n    }\n\n    if (surroundWithPreTag) {\n      printer->Print(\" * </pre>\\n\");\n    }\n  }\n}\n\nstatic void GrpcWriteDocComment(Printer* printer, VARS& vars,\n                                const string& comments) {\n  printer->Print(\"/**\\n\");\n  std::vector<string> lines = GrpcGetDocLines(comments);\n  GrpcWriteDocCommentBody(printer, vars, lines, false);\n  printer->Print(\" */\\n\");\n}\n\nstatic void GrpcWriteServiceDocComment(Printer* printer, VARS& vars,\n                                       const ServiceDescriptor* service) {\n  printer->Print(\"/**\\n\");\n  std::vector<string> lines = GrpcGetDocLinesForDescriptor(service);\n  GrpcWriteDocCommentBody(printer, vars, lines, true);\n  printer->Print(\" */\\n\");\n}\n\nvoid GrpcWriteMethodDocComment(Printer* printer, VARS& vars,\n                               const MethodDescriptor* method) {\n  printer->Print(\"/**\\n\");\n  std::vector<string> lines = GrpcGetDocLinesForDescriptor(method);\n  GrpcWriteDocCommentBody(printer, vars, lines, true);\n  printer->Print(\" */\\n\");\n}\n\n//outputs static singleton extractor for type stored in \"extr_type\" and \"extr_type_name\" vars\nstatic void PrintTypeExtractor(Printer* p, VARS& vars) {\n  p->Print(\n    vars,\n    \"private static volatile FlatbuffersUtils.FBExtactor<$extr_type$> \"\n    \"extractorOf$extr_type_name$;\\n\"\n    \"private static FlatbuffersUtils.FBExtactor<$extr_type$> \"\n    \"getExtractorOf$extr_type_name$() {\\n\"\n    \"    if (extractorOf$extr_type_name$ != null) return \"\n    \"extractorOf$extr_type_name$;\\n\"\n    \"    synchronized ($service_class_name$.class) {\\n\"\n    \"        if (extractorOf$extr_type_name$ != null) return \"\n    \"extractorOf$extr_type_name$;\\n\"\n    \"        extractorOf$extr_type_name$ = new \"\n    \"FlatbuffersUtils.FBExtactor<$extr_type$>() {\\n\"\n    \"            public $extr_type$ extract (ByteBuffer buffer) {\\n\"\n    \"                return \"\n    \"$extr_type$.getRootAs$extr_type_name$(buffer);\\n\"\n    \"            }\\n\"\n    \"        };\\n\"\n    \"        return extractorOf$extr_type_name$;\\n\"\n    \"    }\\n\"\n    \"}\\n\\n\");\n}\nstatic void PrintMethodFields(Printer* p, VARS& vars,\n                              const ServiceDescriptor* service) {\n  p->Print(\"// Static method descriptors that strictly reflect the proto.\\n\");\n  vars[\"service_name\"] = service->name();\n\n  //set of names of rpc input- and output- types that were already encountered.\n  //this is needed to avoid duplicating type extractor since it's possible that\n  //the same type is used as an input or output type of more than a single RPC method\n  std::set<std::string> encounteredTypes;\n\n  for (int i = 0; i < service->method_count(); ++i) {\n    auto method = service->method(i);\n    vars[\"arg_in_id\"] = to_string(2L * i); //trying to make msvc 10 happy\n    vars[\"arg_out_id\"] = to_string(2L * i + 1);\n    vars[\"method_name\"] = method->name();\n    vars[\"input_type_name\"] = method->get_input_type_name();\n    vars[\"output_type_name\"] = method->get_output_type_name();\n    vars[\"input_type\"] = JavaClassName(vars, method->get_input_type_name());\n    vars[\"output_type\"] = JavaClassName(vars, method->get_output_type_name());\n    vars[\"method_field_name\"] = MethodPropertiesFieldName(method.get());\n    vars[\"method_new_field_name\"] = MethodPropertiesGetterName(method.get());\n    vars[\"method_method_name\"] = MethodPropertiesGetterName(method.get());\n    bool client_streaming = method->ClientStreaming();\n    bool server_streaming = method->ServerStreaming();\n    if (client_streaming) {\n      if (server_streaming) {\n        vars[\"method_type\"] = \"BIDI_STREAMING\";\n      } else {\n        vars[\"method_type\"] = \"CLIENT_STREAMING\";\n      }\n    } else {\n      if (server_streaming) {\n        vars[\"method_type\"] = \"SERVER_STREAMING\";\n      } else {\n        vars[\"method_type\"] = \"UNARY\";\n      }\n    }\n\n    p->Print(\n        vars,\n        \"@$ExperimentalApi$(\\\"https://github.com/grpc/grpc-java/issues/\"\n        \"1901\\\")\\n\"\n        \"@$Deprecated$ // Use {@link #$method_method_name$()} instead. \\n\"\n        \"public static final $MethodDescriptor$<$input_type$,\\n\"\n        \"    $output_type$> $method_field_name$ = $method_method_name$();\\n\"\n        \"\\n\"\n        \"private static volatile $MethodDescriptor$<$input_type$,\\n\"\n        \"    $output_type$> $method_new_field_name$;\\n\"\n        \"\\n\");\n\n    if (encounteredTypes.insert(vars[\"input_type_name\"]).second) {\n      vars[\"extr_type\"] = vars[\"input_type\"];\n      vars[\"extr_type_name\"] = vars[\"input_type_name\"];\n      PrintTypeExtractor(p, vars);\n    }\n\n    if (encounteredTypes.insert(vars[\"output_type_name\"]).second) {\n      vars[\"extr_type\"] = vars[\"output_type\"];\n      vars[\"extr_type_name\"] = vars[\"output_type_name\"];\n      PrintTypeExtractor(p, vars);\n    }\n\n    p->Print(\n      vars,\n      \"@$ExperimentalApi$(\\\"https://github.com/grpc/grpc-java/issues/\"\n      \"1901\\\")\\n\"\n      \"public static $MethodDescriptor$<$input_type$,\\n\"\n      \"    $output_type$> $method_method_name$() {\\n\"\n      \"  $MethodDescriptor$<$input_type$, $output_type$> \"\n      \"$method_new_field_name$;\\n\"\n      \"  if (($method_new_field_name$ = \"\n      \"$service_class_name$.$method_new_field_name$) == null) {\\n\"\n      \"    synchronized ($service_class_name$.class) {\\n\"\n      \"      if (($method_new_field_name$ = \"\n      \"$service_class_name$.$method_new_field_name$) == null) {\\n\"\n      \"        $service_class_name$.$method_new_field_name$ = \"\n      \"$method_new_field_name$ = \\n\"\n      \"            $MethodDescriptor$.<$input_type$, \"\n      \"$output_type$>newBuilder()\\n\"\n      \"            .setType($MethodType$.$method_type$)\\n\"\n      \"            .setFullMethodName(generateFullMethodName(\\n\"\n      \"                \\\"$Package$$service_name$\\\", \\\"$method_name$\\\"))\\n\"\n      \"            .setSampledToLocalTracing(true)\\n\"\n      \"            .setRequestMarshaller(FlatbuffersUtils.marshaller(\\n\"\n      \"                $input_type$.class, \"\n      \"getExtractorOf$input_type_name$()))\\n\"\n      \"            .setResponseMarshaller(FlatbuffersUtils.marshaller(\\n\"\n      \"                $output_type$.class, \"\n      \"getExtractorOf$output_type_name$()))\\n\");\n\n    //            vars[\"proto_method_descriptor_supplier\"] = service->name() +\n    //            \"MethodDescriptorSupplier\";\n    p->Print(vars, \"                .setSchemaDescriptor(null)\\n\");\n    //\"                .setSchemaDescriptor(new\n    //$proto_method_descriptor_supplier$(\\\"$method_name$\\\"))\\n\");\n\n    p->Print(vars, \"                .build();\\n\");\n    p->Print(vars,\n             \"        }\\n\"\n             \"      }\\n\"\n             \"   }\\n\"\n             \"   return $method_new_field_name$;\\n\"\n             \"}\\n\");\n\n    p->Print(\"\\n\");\n  }\n}\nenum StubType {\n  ASYNC_INTERFACE = 0,\n  BLOCKING_CLIENT_INTERFACE = 1,\n  FUTURE_CLIENT_INTERFACE = 2,\n  BLOCKING_SERVER_INTERFACE = 3,\n  ASYNC_CLIENT_IMPL = 4,\n  BLOCKING_CLIENT_IMPL = 5,\n  FUTURE_CLIENT_IMPL = 6,\n  ABSTRACT_CLASS = 7,\n};\n\nenum CallType { ASYNC_CALL = 0, BLOCKING_CALL = 1, FUTURE_CALL = 2 };\n\nstatic void PrintBindServiceMethodBody(Printer* p, VARS& vars,\n                                       const ServiceDescriptor* service);\n\n// Prints a client interface or implementation class, or a server interface.\nstatic void PrintStub(Printer* p, VARS& vars, const ServiceDescriptor* service,\n                      StubType type) {\n  const string service_name = service->name();\n  vars[\"service_name\"] = service_name;\n  vars[\"abstract_name\"] = service_name + \"ImplBase\";\n  string stub_name = service_name;\n  string client_name = service_name;\n  CallType call_type = ASYNC_CALL;\n  bool impl_base = false;\n  bool interface = false;\n  switch (type) {\n    case ABSTRACT_CLASS:\n      call_type = ASYNC_CALL;\n      impl_base = true;\n      break;\n    case ASYNC_CLIENT_IMPL:\n      call_type = ASYNC_CALL;\n      stub_name += \"Stub\";\n      break;\n    case BLOCKING_CLIENT_INTERFACE:\n      interface = true;\n      FALLTHROUGH_INTENDED;  // fallthrough\n    case BLOCKING_CLIENT_IMPL:\n      call_type = BLOCKING_CALL;\n      stub_name += \"BlockingStub\";\n      client_name += \"BlockingClient\";\n      break;\n    case FUTURE_CLIENT_INTERFACE:\n      interface = true;\n      FALLTHROUGH_INTENDED;  // fallthrough\n    case FUTURE_CLIENT_IMPL:\n      call_type = FUTURE_CALL;\n      stub_name += \"FutureStub\";\n      client_name += \"FutureClient\";\n      break;\n    case ASYNC_INTERFACE:\n      call_type = ASYNC_CALL;\n      interface = true;\n      break;\n    default:\n      GRPC_CODEGEN_FAIL << \"Cannot determine class name for StubType: \" << type;\n  }\n  vars[\"stub_name\"] = stub_name;\n  vars[\"client_name\"] = client_name;\n\n  // Class head\n  if (!interface) {\n    GrpcWriteServiceDocComment(p, vars, service);\n  }\n  if (impl_base) {\n    p->Print(vars,\n             \"public static abstract class $abstract_name$ implements \"\n             \"$BindableService$ {\\n\");\n  } else {\n    p->Print(vars,\n             \"public static final class $stub_name$ extends \"\n             \"$AbstractStub$<$stub_name$> {\\n\");\n  }\n  p->Indent();\n\n  // Constructor and build() method\n  if (!impl_base && !interface) {\n    p->Print(vars, \"private $stub_name$($Channel$ channel) {\\n\");\n    p->Indent();\n    p->Print(\"super(channel);\\n\");\n    p->Outdent();\n    p->Print(\"}\\n\\n\");\n    p->Print(vars,\n             \"private $stub_name$($Channel$ channel,\\n\"\n             \"    $CallOptions$ callOptions) {\\n\");\n    p->Indent();\n    p->Print(\"super(channel, callOptions);\\n\");\n    p->Outdent();\n    p->Print(\"}\\n\\n\");\n    p->Print(vars,\n             \"@$Override$\\n\"\n             \"protected $stub_name$ build($Channel$ channel,\\n\"\n             \"    $CallOptions$ callOptions) {\\n\");\n    p->Indent();\n    p->Print(vars, \"return new $stub_name$(channel, callOptions);\\n\");\n    p->Outdent();\n    p->Print(\"}\\n\");\n  }\n\n  // RPC methods\n  for (int i = 0; i < service->method_count(); ++i) {\n    auto method = service->method(i);\n    vars[\"input_type\"] = JavaClassName(vars, method->get_input_type_name());\n    vars[\"output_type\"] = JavaClassName(vars, method->get_output_type_name());\n    vars[\"lower_method_name\"] = LowerMethodName(&*method);\n    vars[\"method_method_name\"] = MethodPropertiesGetterName(&*method);\n    bool client_streaming = method->ClientStreaming();\n    bool server_streaming = method->ServerStreaming();\n\n    if (call_type == BLOCKING_CALL && client_streaming) {\n      // Blocking client interface with client streaming is not available\n      continue;\n    }\n\n    if (call_type == FUTURE_CALL && (client_streaming || server_streaming)) {\n      // Future interface doesn't support streaming.\n      continue;\n    }\n\n    // Method signature\n    p->Print(\"\\n\");\n    // TODO(nmittler): Replace with WriteMethodDocComment once included by the\n    // protobuf distro.\n    if (!interface) {\n      GrpcWriteMethodDocComment(p, vars, &*method);\n    }\n    p->Print(\"public \");\n    switch (call_type) {\n      case BLOCKING_CALL:\n        GRPC_CODEGEN_CHECK(!client_streaming)\n            << \"Blocking client interface with client streaming is unavailable\";\n        if (server_streaming) {\n          // Server streaming\n          p->Print(vars,\n                   \"$Iterator$<$output_type$> $lower_method_name$(\\n\"\n                   \"    $input_type$ request)\");\n        } else {\n          // Simple RPC\n          p->Print(vars,\n                   \"$output_type$ $lower_method_name$($input_type$ request)\");\n        }\n        break;\n      case ASYNC_CALL:\n        if (client_streaming) {\n          // Bidirectional streaming or client streaming\n          p->Print(vars,\n                   \"$StreamObserver$<$input_type$> $lower_method_name$(\\n\"\n                   \"    $StreamObserver$<$output_type$> responseObserver)\");\n        } else {\n          // Server streaming or simple RPC\n          p->Print(vars,\n                   \"void $lower_method_name$($input_type$ request,\\n\"\n                   \"    $StreamObserver$<$output_type$> responseObserver)\");\n        }\n        break;\n      case FUTURE_CALL:\n        GRPC_CODEGEN_CHECK(!client_streaming && !server_streaming)\n            << \"Future interface doesn't support streaming. \"\n            << \"client_streaming=\" << client_streaming << \", \"\n            << \"server_streaming=\" << server_streaming;\n        p->Print(vars,\n                 \"$ListenableFuture$<$output_type$> $lower_method_name$(\\n\"\n                 \"    $input_type$ request)\");\n        break;\n    }\n\n    if (interface) {\n      p->Print(\";\\n\");\n      continue;\n    }\n    // Method body.\n    p->Print(\" {\\n\");\n    p->Indent();\n    if (impl_base) {\n      switch (call_type) {\n          // NB: Skipping validation of service methods. If something is wrong,\n          // we wouldn't get to this point as compiler would return errors when\n          // generating service interface.\n        case ASYNC_CALL:\n          if (client_streaming) {\n            p->Print(vars,\n                     \"return \"\n                     \"asyncUnimplementedStreamingCall($method_method_name$(), \"\n                     \"responseObserver);\\n\");\n          } else {\n            p->Print(vars,\n                     \"asyncUnimplementedUnaryCall($method_method_name$(), \"\n                     \"responseObserver);\\n\");\n          }\n          break;\n        default:\n          break;\n      }\n    } else if (!interface) {\n      switch (call_type) {\n        case BLOCKING_CALL:\n          GRPC_CODEGEN_CHECK(!client_streaming)\n              << \"Blocking client streaming interface is not available\";\n          if (server_streaming) {\n            vars[\"calls_method\"] = \"blockingServerStreamingCall\";\n            vars[\"params\"] = \"request\";\n          } else {\n            vars[\"calls_method\"] = \"blockingUnaryCall\";\n            vars[\"params\"] = \"request\";\n          }\n          p->Print(vars,\n                   \"return $calls_method$(\\n\"\n                   \"    getChannel(), $method_method_name$(), \"\n                   \"getCallOptions(), $params$);\\n\");\n          break;\n        case ASYNC_CALL:\n          if (server_streaming) {\n            if (client_streaming) {\n              vars[\"calls_method\"] = \"asyncBidiStreamingCall\";\n              vars[\"params\"] = \"responseObserver\";\n            } else {\n              vars[\"calls_method\"] = \"asyncServerStreamingCall\";\n              vars[\"params\"] = \"request, responseObserver\";\n            }\n          } else {\n            if (client_streaming) {\n              vars[\"calls_method\"] = \"asyncClientStreamingCall\";\n              vars[\"params\"] = \"responseObserver\";\n            } else {\n              vars[\"calls_method\"] = \"asyncUnaryCall\";\n              vars[\"params\"] = \"request, responseObserver\";\n            }\n          }\n          vars[\"last_line_prefix\"] = client_streaming ? \"return \" : \"\";\n          p->Print(vars,\n                   \"$last_line_prefix$$calls_method$(\\n\"\n                   \"    getChannel().newCall($method_method_name$(), \"\n                   \"getCallOptions()), $params$);\\n\");\n          break;\n        case FUTURE_CALL:\n          GRPC_CODEGEN_CHECK(!client_streaming && !server_streaming)\n              << \"Future interface doesn't support streaming. \"\n              << \"client_streaming=\" << client_streaming << \", \"\n              << \"server_streaming=\" << server_streaming;\n          vars[\"calls_method\"] = \"futureUnaryCall\";\n          p->Print(vars,\n                   \"return $calls_method$(\\n\"\n                   \"    getChannel().newCall($method_method_name$(), \"\n                   \"getCallOptions()), request);\\n\");\n          break;\n      }\n    }\n    p->Outdent();\n    p->Print(\"}\\n\");\n  }\n\n  if (impl_base) {\n    p->Print(\"\\n\");\n    p->Print(\n        vars,\n        \"@$Override$ public final $ServerServiceDefinition$ bindService() {\\n\");\n    vars[\"instance\"] = \"this\";\n    PrintBindServiceMethodBody(p, vars, service);\n    p->Print(\"}\\n\");\n  }\n\n  p->Outdent();\n  p->Print(\"}\\n\\n\");\n}\n\nstatic bool CompareMethodClientStreaming(\n    const std::unique_ptr<const grpc_generator::Method>& method1,\n    const std::unique_ptr<const grpc_generator::Method>& method2) {\n  return method1->ClientStreaming() < method2->ClientStreaming();\n}\n\n// Place all method invocations into a single class to reduce memory footprint\n// on Android.\nstatic void PrintMethodHandlerClass(Printer* p, VARS& vars,\n                                    const ServiceDescriptor* service) {\n  // Sort method ids based on ClientStreaming() so switch tables are compact.\n  std::vector<std::unique_ptr<const grpc_generator::Method>> sorted_methods(\n      service->method_count());\n  for (int i = 0; i < service->method_count(); ++i) {\n    sorted_methods[i] = service->method(i);\n  }\n  stable_sort(sorted_methods.begin(), sorted_methods.end(),\n              CompareMethodClientStreaming);\n  for (size_t i = 0; i < sorted_methods.size(); i++) {\n    auto& method = sorted_methods[i];\n    vars[\"method_id\"] = to_string(i);\n    vars[\"method_id_name\"] = MethodIdFieldName(&*method);\n    p->Print(vars,\n             \"private static final int $method_id_name$ = $method_id$;\\n\");\n  }\n  p->Print(\"\\n\");\n  vars[\"service_name\"] = service->name() + \"ImplBase\";\n  p->Print(vars,\n           \"private static final class MethodHandlers<Req, Resp> implements\\n\"\n           \"    io.grpc.stub.ServerCalls.UnaryMethod<Req, Resp>,\\n\"\n           \"    io.grpc.stub.ServerCalls.ServerStreamingMethod<Req, Resp>,\\n\"\n           \"    io.grpc.stub.ServerCalls.ClientStreamingMethod<Req, Resp>,\\n\"\n           \"    io.grpc.stub.ServerCalls.BidiStreamingMethod<Req, Resp> {\\n\"\n           \"  private final $service_name$ serviceImpl;\\n\"\n           \"  private final int methodId;\\n\"\n           \"\\n\"\n           \"  MethodHandlers($service_name$ serviceImpl, int methodId) {\\n\"\n           \"    this.serviceImpl = serviceImpl;\\n\"\n           \"    this.methodId = methodId;\\n\"\n           \"  }\\n\\n\");\n  p->Indent();\n  p->Print(vars,\n           \"@$Override$\\n\"\n           \"@java.lang.SuppressWarnings(\\\"unchecked\\\")\\n\"\n           \"public void invoke(Req request, $StreamObserver$<Resp> \"\n           \"responseObserver) {\\n\"\n           \"  switch (methodId) {\\n\");\n  p->Indent();\n  p->Indent();\n\n  for (int i = 0; i < service->method_count(); ++i) {\n    auto method = service->method(i);\n    if (method->ClientStreaming()) {\n      continue;\n    }\n    vars[\"method_id_name\"] = MethodIdFieldName(&*method);\n    vars[\"lower_method_name\"] = LowerMethodName(&*method);\n    vars[\"input_type\"] = JavaClassName(vars, method->get_input_type_name());\n    vars[\"output_type\"] = JavaClassName(vars, method->get_output_type_name());\n    p->Print(vars,\n             \"case $method_id_name$:\\n\"\n             \"  serviceImpl.$lower_method_name$(($input_type$) request,\\n\"\n             \"      ($StreamObserver$<$output_type$>) responseObserver);\\n\"\n             \"  break;\\n\");\n  }\n  p->Print(\n      \"default:\\n\"\n      \"  throw new AssertionError();\\n\");\n\n  p->Outdent();\n  p->Outdent();\n  p->Print(\n      \"  }\\n\"\n      \"}\\n\\n\");\n\n  p->Print(vars,\n           \"@$Override$\\n\"\n           \"@java.lang.SuppressWarnings(\\\"unchecked\\\")\\n\"\n           \"public $StreamObserver$<Req> invoke(\\n\"\n           \"    $StreamObserver$<Resp> responseObserver) {\\n\"\n           \"  switch (methodId) {\\n\");\n  p->Indent();\n  p->Indent();\n\n  for (int i = 0; i < service->method_count(); ++i) {\n    auto method = service->method(i);\n    if (!method->ClientStreaming()) {\n      continue;\n    }\n    vars[\"method_id_name\"] = MethodIdFieldName(&*method);\n    vars[\"lower_method_name\"] = LowerMethodName(&*method);\n    vars[\"input_type\"] = JavaClassName(vars, method->get_input_type_name());\n    vars[\"output_type\"] = JavaClassName(vars, method->get_output_type_name());\n    p->Print(\n        vars,\n        \"case $method_id_name$:\\n\"\n        \"  return ($StreamObserver$<Req>) serviceImpl.$lower_method_name$(\\n\"\n        \"      ($StreamObserver$<$output_type$>) responseObserver);\\n\");\n  }\n  p->Print(\n      \"default:\\n\"\n      \"  throw new AssertionError();\\n\");\n\n  p->Outdent();\n  p->Outdent();\n  p->Print(\n      \"  }\\n\"\n      \"}\\n\");\n\n  p->Outdent();\n  p->Print(\"}\\n\\n\");\n}\n\nstatic void PrintGetServiceDescriptorMethod(Printer* p, VARS& vars,\n                                            const ServiceDescriptor* service) {\n  vars[\"service_name\"] = service->name();\n  //        vars[\"proto_base_descriptor_supplier\"] = service->name() +\n  //        \"BaseDescriptorSupplier\"; vars[\"proto_file_descriptor_supplier\"] =\n  //        service->name() + \"FileDescriptorSupplier\";\n  //        vars[\"proto_method_descriptor_supplier\"] = service->name() +\n  //        \"MethodDescriptorSupplier\"; vars[\"proto_class_name\"] =\n  //        google::protobuf::compiler::java::ClassName(service->file());\n  //        p->Print(\n  //                 vars,\n  //                 \"private static abstract class\n  //                 $proto_base_descriptor_supplier$\\n\" \"    implements\n  //                 $ProtoFileDescriptorSupplier$,\n  //                 $ProtoServiceDescriptorSupplier$ {\\n\" \"\n  //                 $proto_base_descriptor_supplier$() {}\\n\"\n  //                 \"\\n\"\n  //                 \"  @$Override$\\n\"\n  //                 \"  public com.google.protobuf.Descriptors.FileDescriptor\n  //                 getFileDescriptor() {\\n\" \"    return\n  //                 $proto_class_name$.getDescriptor();\\n\" \"  }\\n\"\n  //                 \"\\n\"\n  //                 \"  @$Override$\\n\"\n  //                 \"  public com.google.protobuf.Descriptors.ServiceDescriptor\n  //                 getServiceDescriptor() {\\n\" \"    return\n  //                 getFileDescriptor().findServiceByName(\\\"$service_name$\\\");\\n\"\n  //                 \"  }\\n\"\n  //                 \"}\\n\"\n  //                 \"\\n\"\n  //                 \"private static final class\n  //                 $proto_file_descriptor_supplier$\\n\" \"    extends\n  //                 $proto_base_descriptor_supplier$ {\\n\" \"\n  //                 $proto_file_descriptor_supplier$() {}\\n\"\n  //                 \"}\\n\"\n  //                 \"\\n\"\n  //                 \"private static final class\n  //                 $proto_method_descriptor_supplier$\\n\" \"    extends\n  //                 $proto_base_descriptor_supplier$\\n\" \"    implements\n  //                 $ProtoMethodDescriptorSupplier$ {\\n\" \"  private final\n  //                 String methodName;\\n\"\n  //                 \"\\n\"\n  //                 \"  $proto_method_descriptor_supplier$(String methodName)\n  //                 {\\n\" \"    this.methodName = methodName;\\n\" \"  }\\n\"\n  //                 \"\\n\"\n  //                 \"  @$Override$\\n\"\n  //                 \"  public com.google.protobuf.Descriptors.MethodDescriptor\n  //                 getMethodDescriptor() {\\n\" \"    return\n  //                 getServiceDescriptor().findMethodByName(methodName);\\n\" \"\n  //                 }\\n\"\n  //                 \"}\\n\\n\");\n\n  p->Print(\n      vars,\n      \"private static volatile $ServiceDescriptor$ serviceDescriptor;\\n\\n\");\n\n  p->Print(vars,\n           \"public static $ServiceDescriptor$ getServiceDescriptor() {\\n\");\n  p->Indent();\n  p->Print(vars, \"$ServiceDescriptor$ result = serviceDescriptor;\\n\");\n  p->Print(\"if (result == null) {\\n\");\n  p->Indent();\n  p->Print(vars, \"synchronized ($service_class_name$.class) {\\n\");\n  p->Indent();\n  p->Print(\"result = serviceDescriptor;\\n\");\n  p->Print(\"if (result == null) {\\n\");\n  p->Indent();\n\n  p->Print(vars,\n           \"serviceDescriptor = result = \"\n           \"$ServiceDescriptor$.newBuilder(SERVICE_NAME)\");\n  p->Indent();\n  p->Indent();\n  p->Print(vars, \"\\n.setSchemaDescriptor(null)\");\n  for (int i = 0; i < service->method_count(); ++i) {\n    auto method = service->method(i);\n    vars[\"method_method_name\"] = MethodPropertiesGetterName(&*method);\n    p->Print(vars, \"\\n.addMethod($method_method_name$())\");\n  }\n  p->Print(\"\\n.build();\\n\");\n  p->Outdent();\n  p->Outdent();\n\n  p->Outdent();\n  p->Print(\"}\\n\");\n  p->Outdent();\n  p->Print(\"}\\n\");\n  p->Outdent();\n  p->Print(\"}\\n\");\n  p->Print(\"return result;\\n\");\n  p->Outdent();\n  p->Print(\"}\\n\");\n}\n\nstatic void PrintBindServiceMethodBody(Printer* p, VARS& vars,\n                                       const ServiceDescriptor* service) {\n  vars[\"service_name\"] = service->name();\n  p->Indent();\n  p->Print(vars,\n           \"return \"\n           \"$ServerServiceDefinition$.builder(getServiceDescriptor())\\n\");\n  p->Indent();\n  p->Indent();\n  for (int i = 0; i < service->method_count(); ++i) {\n    auto method = service->method(i);\n    vars[\"lower_method_name\"] = LowerMethodName(&*method);\n    vars[\"method_method_name\"] = MethodPropertiesGetterName(&*method);\n    vars[\"input_type\"] = JavaClassName(vars, method->get_input_type_name());\n    vars[\"output_type\"] = JavaClassName(vars, method->get_output_type_name());\n    vars[\"method_id_name\"] = MethodIdFieldName(&*method);\n    bool client_streaming = method->ClientStreaming();\n    bool server_streaming = method->ServerStreaming();\n    if (client_streaming) {\n      if (server_streaming) {\n        vars[\"calls_method\"] = \"asyncBidiStreamingCall\";\n      } else {\n        vars[\"calls_method\"] = \"asyncClientStreamingCall\";\n      }\n    } else {\n      if (server_streaming) {\n        vars[\"calls_method\"] = \"asyncServerStreamingCall\";\n      } else {\n        vars[\"calls_method\"] = \"asyncUnaryCall\";\n      }\n    }\n    p->Print(vars, \".addMethod(\\n\");\n    p->Indent();\n    p->Print(vars,\n             \"$method_method_name$(),\\n\"\n             \"$calls_method$(\\n\");\n    p->Indent();\n    p->Print(vars,\n             \"new MethodHandlers<\\n\"\n             \"  $input_type$,\\n\"\n             \"  $output_type$>(\\n\"\n             \"    $instance$, $method_id_name$)))\\n\");\n    p->Outdent();\n    p->Outdent();\n  }\n  p->Print(\".build();\\n\");\n  p->Outdent();\n  p->Outdent();\n  p->Outdent();\n}\n\nstatic void PrintService(Printer* p, VARS& vars,\n                         const ServiceDescriptor* service,\n                         bool disable_version) {\n  vars[\"service_name\"] = service->name();\n  vars[\"service_class_name\"] = ServiceClassName(service->name());\n  vars[\"grpc_version\"] = \"\";\n#ifdef GRPC_VERSION\n  if (!disable_version) {\n    vars[\"grpc_version\"] = \" (version \" XSTR(GRPC_VERSION) \")\";\n  }\n#else\n  (void)disable_version;\n#endif\n  // TODO(nmittler): Replace with WriteServiceDocComment once included by\n  // protobuf distro.\n  GrpcWriteServiceDocComment(p, vars, service);\n  p->Print(vars,\n           \"@$Generated$(\\n\"\n           \"    value = \\\"by gRPC proto compiler$grpc_version$\\\",\\n\"\n           \"    comments = \\\"Source: $file_name$.fbs\\\")\\n\"\n           \"public final class $service_class_name$ {\\n\\n\");\n  p->Indent();\n  p->Print(vars, \"private $service_class_name$() {}\\n\\n\");\n\n  p->Print(vars,\n           \"public static final String SERVICE_NAME = \"\n           \"\\\"$Package$$service_name$\\\";\\n\\n\");\n\n  PrintMethodFields(p, vars, service);\n\n  // TODO(nmittler): Replace with WriteDocComment once included by protobuf\n  // distro.\n  GrpcWriteDocComment(\n      p, vars,\n      \" Creates a new async stub that supports all call types for the service\");\n  p->Print(vars,\n           \"public static $service_name$Stub newStub($Channel$ channel) {\\n\");\n  p->Indent();\n  p->Print(vars, \"return new $service_name$Stub(channel);\\n\");\n  p->Outdent();\n  p->Print(\"}\\n\\n\");\n\n  // TODO(nmittler): Replace with WriteDocComment once included by protobuf\n  // distro.\n  GrpcWriteDocComment(\n      p, vars,\n      \" Creates a new blocking-style stub that supports unary and streaming \"\n      \"output calls on the service\");\n  p->Print(vars,\n           \"public static $service_name$BlockingStub newBlockingStub(\\n\"\n           \"    $Channel$ channel) {\\n\");\n  p->Indent();\n  p->Print(vars, \"return new $service_name$BlockingStub(channel);\\n\");\n  p->Outdent();\n  p->Print(\"}\\n\\n\");\n\n  // TODO(nmittler): Replace with WriteDocComment once included by protobuf\n  // distro.\n  GrpcWriteDocComment(\n      p, vars,\n      \" Creates a new ListenableFuture-style stub that supports unary calls \"\n      \"on the service\");\n  p->Print(vars,\n           \"public static $service_name$FutureStub newFutureStub(\\n\"\n           \"    $Channel$ channel) {\\n\");\n  p->Indent();\n  p->Print(vars, \"return new $service_name$FutureStub(channel);\\n\");\n  p->Outdent();\n  p->Print(\"}\\n\\n\");\n\n  PrintStub(p, vars, service, ABSTRACT_CLASS);\n  PrintStub(p, vars, service, ASYNC_CLIENT_IMPL);\n  PrintStub(p, vars, service, BLOCKING_CLIENT_IMPL);\n  PrintStub(p, vars, service, FUTURE_CLIENT_IMPL);\n\n  PrintMethodHandlerClass(p, vars, service);\n  PrintGetServiceDescriptorMethod(p, vars, service);\n  p->Outdent();\n  p->Print(\"}\\n\");\n}\n\nvoid PrintStaticImports(Printer* p) {\n  p->Print(\n      \"import java.nio.ByteBuffer;\\n\"\n      \"import static \"\n      \"io.grpc.MethodDescriptor.generateFullMethodName;\\n\"\n      \"import static \"\n      \"io.grpc.stub.ClientCalls.asyncBidiStreamingCall;\\n\"\n      \"import static \"\n      \"io.grpc.stub.ClientCalls.asyncClientStreamingCall;\\n\"\n      \"import static \"\n      \"io.grpc.stub.ClientCalls.asyncServerStreamingCall;\\n\"\n      \"import static \"\n      \"io.grpc.stub.ClientCalls.asyncUnaryCall;\\n\"\n      \"import static \"\n      \"io.grpc.stub.ClientCalls.blockingServerStreamingCall;\\n\"\n      \"import static \"\n      \"io.grpc.stub.ClientCalls.blockingUnaryCall;\\n\"\n      \"import static \"\n      \"io.grpc.stub.ClientCalls.futureUnaryCall;\\n\"\n      \"import static \"\n      \"io.grpc.stub.ServerCalls.asyncBidiStreamingCall;\\n\"\n      \"import static \"\n      \"io.grpc.stub.ServerCalls.asyncClientStreamingCall;\\n\"\n      \"import static \"\n      \"io.grpc.stub.ServerCalls.asyncServerStreamingCall;\\n\"\n      \"import static \"\n      \"io.grpc.stub.ServerCalls.asyncUnaryCall;\\n\"\n      \"import static \"\n      \"io.grpc.stub.ServerCalls.asyncUnimplementedStreamingCall;\\n\"\n      \"import static \"\n      \"io.grpc.stub.ServerCalls.asyncUnimplementedUnaryCall;\\n\\n\");\n}\n\nvoid GenerateService(const grpc_generator::Service* service,\n                     grpc_generator::Printer* printer, VARS& vars,\n                     bool disable_version) {\n  // All non-generated classes must be referred by fully qualified names to\n  // avoid collision with generated classes.\n  vars[\"String\"] = \"java.lang.String\";\n  vars[\"Deprecated\"] = \"java.lang.Deprecated\";\n  vars[\"Override\"] = \"java.lang.Override\";\n  vars[\"Channel\"] = \"io.grpc.Channel\";\n  vars[\"CallOptions\"] = \"io.grpc.CallOptions\";\n  vars[\"MethodType\"] = \"io.grpc.MethodDescriptor.MethodType\";\n  vars[\"ServerMethodDefinition\"] = \"io.grpc.ServerMethodDefinition\";\n  vars[\"BindableService\"] = \"io.grpc.BindableService\";\n  vars[\"ServerServiceDefinition\"] = \"io.grpc.ServerServiceDefinition\";\n  vars[\"ServiceDescriptor\"] = \"io.grpc.ServiceDescriptor\";\n  vars[\"ProtoFileDescriptorSupplier\"] =\n      \"io.grpc.protobuf.ProtoFileDescriptorSupplier\";\n  vars[\"ProtoServiceDescriptorSupplier\"] =\n      \"io.grpc.protobuf.ProtoServiceDescriptorSupplier\";\n  vars[\"ProtoMethodDescriptorSupplier\"] =\n      \"io.grpc.protobuf.ProtoMethodDescriptorSupplier\";\n  vars[\"AbstractStub\"] = \"io.grpc.stub.AbstractStub\";\n  vars[\"MethodDescriptor\"] = \"io.grpc.MethodDescriptor\";\n  vars[\"NanoUtils\"] = \"io.grpc.protobuf.nano.NanoUtils\";\n  vars[\"StreamObserver\"] = \"io.grpc.stub.StreamObserver\";\n  vars[\"Iterator\"] = \"java.util.Iterator\";\n  vars[\"Generated\"] = \"javax.annotation.Generated\";\n  vars[\"ListenableFuture\"] =\n      \"com.google.common.util.concurrent.ListenableFuture\";\n  vars[\"ExperimentalApi\"] = \"io.grpc.ExperimentalApi\";\n\n  PrintStaticImports(printer);\n\n  PrintService(printer, vars, service, disable_version);\n}\n\ngrpc::string GenerateServiceSource(\n    grpc_generator::File* file, const grpc_generator::Service* service,\n    grpc_java_generator::Parameters* parameters) {\n  grpc::string out;\n  auto printer = file->CreatePrinter(&out);\n  VARS vars;\n  vars[\"flatc_version\"] = grpc::string(\n      FLATBUFFERS_STRING(FLATBUFFERS_VERSION_MAJOR) \".\" FLATBUFFERS_STRING(\n          FLATBUFFERS_VERSION_MINOR) \".\" FLATBUFFERS_STRING(FLATBUFFERS_VERSION_REVISION));\n\n  vars[\"file_name\"] = file->filename();\n\n  if (!parameters->package_name.empty()) {\n    vars[\"Package\"] = parameters->package_name;  // ServiceJavaPackage(service);\n  }\n  GenerateImports(file, &*printer, vars);\n  GenerateService(service, &*printer, vars, false);\n  return out;\n}\n\n}  // namespace grpc_java_generator\n", "idx": 1, "id": 14584, "msg": "this file is copied from the GRPC project.. are these fixing from upstream? if not, worth seeing if it has been fixed upstream and pulling in the latest file?", "proj": "google-flatbuffers", "lang": "java"}
{"patch": "@@ -269,7 +269,7 @@ func runExecutions(\n \t\tif nonce, ok = nonces[executor]; !ok {\n \t\t\tstate, err := accountutil.AccountState(sf, executor)\n \t\t\tif err != nil {\n-\t\t\t\treturn nil, err\n+\t\t\t\treturn nil, err, nil\n \t\t\t}\n \t\t\tnonce = state.Nonce\n \t\t}", "y": 0, "oldf": "// Copyright (c) 2019 IoTeX Foundation\n// This is an alpha (internal) release and is not suitable for production. This source code is provided 'as is' and no\n// warranties are given as to title or non-infringement, merchantability or fitness for purpose and, to the extent\n// permitted by law, all liability for your use of the code is disclaimed. This source code is governed by Apache\n// License 2.0 that can be found in the LICENSE file.\n\npackage execution\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/hex\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"math/big\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/pkg/errors\"\n\t\"github.com/stretchr/testify/require\"\n\t\"go.uber.org/zap\"\n\n\t\"github.com/iotexproject/go-pkgs/crypto\"\n\t\"github.com/iotexproject/go-pkgs/hash\"\n\t\"github.com/iotexproject/iotex-address/address\"\n\t\"github.com/iotexproject/iotex-proto/golang/iotextypes\"\n\n\t\"github.com/iotexproject/iotex-core/action\"\n\t\"github.com/iotexproject/iotex-core/action/protocol\"\n\t\"github.com/iotexproject/iotex-core/action/protocol/account\"\n\taccountutil \"github.com/iotexproject/iotex-core/action/protocol/account/util\"\n\t\"github.com/iotexproject/iotex-core/action/protocol/execution/evm\"\n\t\"github.com/iotexproject/iotex-core/action/protocol/rewarding\"\n\t\"github.com/iotexproject/iotex-core/action/protocol/rolldpos\"\n\t\"github.com/iotexproject/iotex-core/actpool\"\n\t\"github.com/iotexproject/iotex-core/blockchain\"\n\t\"github.com/iotexproject/iotex-core/blockchain/block\"\n\t\"github.com/iotexproject/iotex-core/blockchain/blockdao\"\n\t\"github.com/iotexproject/iotex-core/blockindex\"\n\t\"github.com/iotexproject/iotex-core/config\"\n\t\"github.com/iotexproject/iotex-core/db\"\n\t\"github.com/iotexproject/iotex-core/pkg/log\"\n\t\"github.com/iotexproject/iotex-core/pkg/unit\"\n\t\"github.com/iotexproject/iotex-core/state/factory\"\n\t\"github.com/iotexproject/iotex-core/test/identityset\"\n\t\"github.com/iotexproject/iotex-core/testutil\"\n)\n\n// ExpectedBalance defines an account-balance pair\ntype ExpectedBalance struct {\n\tAccount    string `json:\"account\"`\n\tRawBalance string `json:\"rawBalance\"`\n}\n\n// GenesisBlockHeight defines an genesis blockHeight\ntype GenesisBlockHeight struct {\n\tIsBering  bool `json:\"isBering\"`\n\tIsIceland bool `json:\"isIceland\"`\n}\n\nfunc (eb *ExpectedBalance) Balance() *big.Int {\n\tbalance, ok := new(big.Int).SetString(eb.RawBalance, 10)\n\tif !ok {\n\t\tlog.L().Panic(\"invalid balance\", zap.String(\"balance\", eb.RawBalance))\n\t}\n\treturn balance\n}\n\nfunc readCode(sr protocol.StateReader, addr []byte) ([]byte, error) {\n\tvar c evm.SerializableBytes\n\taccount, err := accountutil.LoadAccount(sr, hash.BytesToHash160(addr))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\t_, err = sr.State(&c, protocol.NamespaceOption(evm.CodeKVNameSpace), protocol.KeyOption(account.CodeHash[:]))\n\n\treturn c[:], err\n}\n\ntype Log struct {\n\tTopics []string `json:\"topics\"`\n\tData   string   `json:\"data\"`\n}\n\ntype ExecutionConfig struct {\n\tComment                 string            `json:\"comment\"`\n\tContractIndex           int               `json:\"contractIndex\"`\n\tAppendContractAddress   bool              `json:\"appendContractAddress\"`\n\tContractIndexToAppend   int               `json:\"contractIndexToAppend\"`\n\tContractAddressToAppend string            `json:\"contractAddressToAppend\"`\n\tReadOnly                bool              `json:\"readOnly\"`\n\tRawPrivateKey           string            `json:\"rawPrivateKey\"`\n\tRawByteCode             string            `json:\"rawByteCode\"`\n\tRawAmount               string            `json:\"rawAmount\"`\n\tRawGasLimit             uint              `json:\"rawGasLimit\"`\n\tRawGasPrice             string            `json:\"rawGasPrice\"`\n\tFailed                  bool              `json:\"failed\"`\n\tRawReturnValue          string            `json:\"rawReturnValue\"`\n\tRawExpectedGasConsumed  uint              `json:\"rawExpectedGasConsumed\"`\n\tExpectedStatus          uint64            `json:\"expectedStatus\"`\n\tExpectedBalances        []ExpectedBalance `json:\"expectedBalances\"`\n\tExpectedLogs            []Log             `json:\"expectedLogs\"`\n\tExpectedErrorMsg        string            `json:\"expectedErrorMsg\"`\n}\n\nfunc (cfg *ExecutionConfig) PrivateKey() crypto.PrivateKey {\n\tpriKey, err := crypto.HexStringToPrivateKey(cfg.RawPrivateKey)\n\tif err != nil {\n\t\tlog.L().Panic(\n\t\t\t\"invalid private key\",\n\t\t\tzap.String(\"privateKey\", cfg.RawPrivateKey),\n\t\t\tzap.Error(err),\n\t\t)\n\t}\n\n\treturn priKey\n}\n\nfunc (cfg *ExecutionConfig) Executor() address.Address {\n\tpriKey := cfg.PrivateKey()\n\taddr := priKey.PublicKey().Address()\n\tif addr == nil {\n\t\tlog.L().Panic(\n\t\t\t\"invalid private key\",\n\t\t\tzap.String(\"privateKey\", cfg.RawPrivateKey),\n\t\t\tzap.Error(errors.New(\"failed to get address\")),\n\t\t)\n\t}\n\n\treturn addr\n}\n\nfunc (cfg *ExecutionConfig) ByteCode() []byte {\n\tbyteCode, err := hex.DecodeString(cfg.RawByteCode)\n\tif err != nil {\n\t\tlog.L().Panic(\n\t\t\t\"invalid byte code\",\n\t\t\tzap.String(\"byteCode\", cfg.RawByteCode),\n\t\t\tzap.Error(err),\n\t\t)\n\t}\n\tif cfg.AppendContractAddress {\n\t\taddr, err := address.FromString(cfg.ContractAddressToAppend)\n\t\tif err != nil {\n\t\t\tlog.L().Panic(\n\t\t\t\t\"invalid contract address to append\",\n\t\t\t\tzap.String(\"contractAddressToAppend\", cfg.ContractAddressToAppend),\n\t\t\t\tzap.Error(err),\n\t\t\t)\n\t\t}\n\t\tba := addr.Bytes()\n\t\tba = append(make([]byte, 12), ba...)\n\t\tbyteCode = append(byteCode, ba...)\n\t}\n\n\treturn byteCode\n}\n\nfunc (cfg *ExecutionConfig) Amount() *big.Int {\n\tamount, ok := new(big.Int).SetString(cfg.RawAmount, 10)\n\tif !ok {\n\t\tlog.L().Panic(\"invalid amount\", zap.String(\"amount\", cfg.RawAmount))\n\t}\n\n\treturn amount\n}\n\nfunc (cfg *ExecutionConfig) GasPrice() *big.Int {\n\tprice, ok := new(big.Int).SetString(cfg.RawGasPrice, 10)\n\tif !ok {\n\t\tlog.L().Panic(\"invalid gas price\", zap.String(\"gasPrice\", cfg.RawGasPrice))\n\t}\n\n\treturn price\n}\n\nfunc (cfg *ExecutionConfig) GasLimit() uint64 {\n\treturn uint64(cfg.RawGasLimit)\n}\n\nfunc (cfg *ExecutionConfig) ExpectedGasConsumed() uint64 {\n\treturn uint64(cfg.RawExpectedGasConsumed)\n}\n\nfunc (cfg *ExecutionConfig) ExpectedReturnValue() []byte {\n\tretval, err := hex.DecodeString(cfg.RawReturnValue)\n\tif err != nil {\n\t\tlog.L().Panic(\n\t\t\t\"invalid return value\",\n\t\t\tzap.String(\"returnValue\", cfg.RawReturnValue),\n\t\t\tzap.Error(err),\n\t\t)\n\t}\n\n\treturn retval\n}\n\ntype SmartContractTest struct {\n\t// the order matters\n\tInitGenesis  GenesisBlockHeight `json:\"initGenesis\"`\n\tInitBalances []ExpectedBalance  `json:\"initBalances\"`\n\tDeployments  []ExecutionConfig  `json:\"deployments\"`\n\tExecutions   []ExecutionConfig  `json:\"executions\"`\n}\n\nfunc NewSmartContractTest(t *testing.T, file string) {\n\trequire := require.New(t)\n\tjsonFile, err := os.Open(file)\n\trequire.NoError(err)\n\tsctBytes, err := ioutil.ReadAll(jsonFile)\n\trequire.NoError(err)\n\tsct := &SmartContractTest{}\n\trequire.NoError(json.Unmarshal(sctBytes, sct))\n\tsct.run(require)\n}\n\nfunc readExecution(\n\tbc blockchain.Blockchain,\n\tsf factory.Factory,\n\tdao blockdao.BlockDAO,\n\tap actpool.ActPool,\n\tecfg *ExecutionConfig,\n\tcontractAddr string,\n) ([]byte, *action.Receipt, error) {\n\tlog.S().Info(ecfg.Comment)\n\tstate, err := accountutil.AccountState(sf, ecfg.Executor().String())\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\texec, err := action.NewExecution(\n\t\tcontractAddr,\n\t\tstate.Nonce+1,\n\t\tecfg.Amount(),\n\t\tecfg.GasLimit(),\n\t\tecfg.GasPrice(),\n\t\tecfg.ByteCode(),\n\t)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\taddr := ecfg.PrivateKey().PublicKey().Address()\n\tif addr == nil {\n\t\treturn nil, nil, errors.New(\"failed to get address\")\n\t}\n\tctx, err := bc.Context(context.Background())\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\treturn sf.SimulateExecution(ctx, addr, exec, dao.GetBlockHash)\n}\n\nfunc runExecutions(\n\tbc blockchain.Blockchain,\n\tsf factory.Factory,\n\tdao blockdao.BlockDAO,\n\tap actpool.ActPool,\n\tecfgs []*ExecutionConfig,\n\tcontractAddrs []string,\n) ([]*action.Receipt, error) {\n\tnonces := map[string]uint64{}\n\thashes := []hash.Hash256{}\n\tfor i, ecfg := range ecfgs {\n\t\tlog.S().Info(ecfg.Comment)\n\t\tvar nonce uint64\n\t\tvar ok bool\n\t\texecutor := ecfg.Executor().String()\n\t\tif nonce, ok = nonces[executor]; !ok {\n\t\t\tstate, err := accountutil.AccountState(sf, executor)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tnonce = state.Nonce\n\t\t}\n\t\tnonce = nonce + 1\n\t\tnonces[executor] = nonce\n\t\texec, err := action.NewExecution(\n\t\t\tcontractAddrs[i],\n\t\t\tnonce,\n\t\t\tecfg.Amount(),\n\t\t\tecfg.GasLimit(),\n\t\t\tecfg.GasPrice(),\n\t\t\tecfg.ByteCode(),\n\t\t)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tbuilder := &action.EnvelopeBuilder{}\n\t\telp := builder.SetAction(exec).\n\t\t\tSetNonce(exec.Nonce()).\n\t\t\tSetGasLimit(ecfg.GasLimit()).\n\t\t\tSetGasPrice(ecfg.GasPrice()).\n\t\t\tBuild()\n\t\tselp, err := action.Sign(elp, ecfg.PrivateKey())\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif err := ap.Add(context.Background(), selp); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tselpHash, err := selp.Hash()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\thashes = append(hashes, selpHash)\n\t}\n\tblk, err := bc.MintNewBlock(testutil.TimestampNow())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif err := bc.CommitBlock(blk); err != nil {\n\t\treturn nil, err\n\t}\n\treceipts := []*action.Receipt{}\n\tfor _, hash := range hashes {\n\t\treceipt, err := dao.GetReceiptByActionHash(hash, blk.Height())\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treceipts = append(receipts, receipt)\n\t}\n\n\treturn receipts, nil\n}\n\nfunc (sct *SmartContractTest) prepareBlockchain(\n\tctx context.Context,\n\tcfg config.Config,\n\tr *require.Assertions,\n) (blockchain.Blockchain, factory.Factory, blockdao.BlockDAO, actpool.ActPool) {\n\tdefer func() {\n\t\tdelete(cfg.Plugins, config.GatewayPlugin)\n\t}()\n\tcfg.Plugins[config.GatewayPlugin] = true\n\tcfg.Chain.EnableAsyncIndexWrite = false\n\tcfg.Genesis.EnableGravityChainVoting = false\n\ttestTriePath, err := testutil.PathOfTempFile(\"trie\")\n\tr.NoError(err)\n\n\tcfg.Chain.TrieDBPath = testTriePath\n\tcfg.ActPool.MinGasPriceStr = \"0\"\n\tif sct.InitGenesis.IsBering {\n\t\tcfg.Genesis.Blockchain.AleutianBlockHeight = 0\n\t\tcfg.Genesis.Blockchain.BeringBlockHeight = 0\n\t}\n\tcfg.Genesis.HawaiiBlockHeight = 0\n\tif sct.InitGenesis.IsIceland {\n\t\tcfg.Genesis.CookBlockHeight = 0\n\t\tcfg.Genesis.DardanellesBlockHeight = 0\n\t\tcfg.Genesis.DaytonaBlockHeight = 0\n\t\tcfg.Genesis.EasterBlockHeight = 0\n\t\tcfg.Genesis.FbkMigrationBlockHeight = 0\n\t\tcfg.Genesis.FairbankBlockHeight = 0\n\t\tcfg.Genesis.GreenlandBlockHeight = 0\n\t\tcfg.Genesis.IcelandBlockHeight = 0\n\t}\n\tfor _, expectedBalance := range sct.InitBalances {\n\t\tcfg.Genesis.InitBalanceMap[expectedBalance.Account] = expectedBalance.Balance().String()\n\t}\n\tregistry := protocol.NewRegistry()\n\tacc := account.NewProtocol(rewarding.DepositGas)\n\tr.NoError(acc.Register(registry))\n\trp := rolldpos.NewProtocol(cfg.Genesis.NumCandidateDelegates, cfg.Genesis.NumDelegates, cfg.Genesis.NumSubEpochs)\n\tr.NoError(rp.Register(registry))\n\t// create state factory\n\tvar sf factory.Factory\n\tif cfg.Chain.EnableTrielessStateDB {\n\t\tif cfg.Chain.EnableStateDBCaching {\n\t\t\tsf, err = factory.NewStateDB(cfg, factory.CachedStateDBOption(), factory.RegistryStateDBOption(registry))\n\t\t} else {\n\t\t\tsf, err = factory.NewStateDB(cfg, factory.DefaultStateDBOption(), factory.RegistryStateDBOption(registry))\n\t\t}\n\t} else {\n\t\tsf, err = factory.NewFactory(cfg, factory.InMemTrieOption(), factory.RegistryOption(registry))\n\t}\n\tr.NoError(err)\n\tap, err := actpool.NewActPool(sf, cfg.ActPool)\n\tr.NoError(err)\n\t// create indexer\n\tindexer, err := blockindex.NewIndexer(db.NewMemKVStore(), cfg.Genesis.Hash())\n\tr.NoError(err)\n\t// create BlockDAO\n\tdao := blockdao.NewBlockDAOInMemForTest([]blockdao.BlockIndexer{sf, indexer})\n\tr.NotNil(dao)\n\tbc := blockchain.NewBlockchain(\n\t\tcfg,\n\t\tdao,\n\t\tfactory.NewMinter(sf, ap),\n\t\tblockchain.BlockValidatorOption(block.NewValidator(\n\t\t\tsf,\n\t\t\tprotocol.NewGenericValidator(sf, accountutil.AccountState),\n\t\t)),\n\t)\n\treward := rewarding.NewProtocol(0, 0)\n\tr.NoError(reward.Register(registry))\n\n\tr.NotNil(bc)\n\texecution := NewProtocol(dao.GetBlockHash, rewarding.DepositGas)\n\tr.NoError(execution.Register(registry))\n\tr.NoError(bc.Start(ctx))\n\n\treturn bc, sf, dao, ap\n}\n\nfunc (sct *SmartContractTest) deployContracts(\n\tbc blockchain.Blockchain,\n\tsf factory.Factory,\n\tdao blockdao.BlockDAO,\n\tap actpool.ActPool,\n\tr *require.Assertions,\n) (contractAddresses []string) {\n\tfor i, contract := range sct.Deployments {\n\t\tif contract.AppendContractAddress {\n\t\t\tcontract.ContractAddressToAppend = contractAddresses[contract.ContractIndexToAppend]\n\t\t}\n\t\treceipts, err := runExecutions(bc, sf, dao, ap, []*ExecutionConfig{&contract}, []string{action.EmptyAddress})\n\t\tr.NoError(err)\n\t\tr.Equal(1, len(receipts))\n\t\treceipt := receipts[0]\n\t\tr.NotNil(receipt)\n\t\tif sct.InitGenesis.IsBering {\n\t\t\t// if it is post bering, it compares the status with expected status\n\t\t\tr.Equal(sct.Deployments[i].ExpectedStatus, receipt.Status)\n\t\t\tif receipt.Status != uint64(iotextypes.ReceiptStatus_Success) {\n\t\t\t\treturn []string{}\n\t\t\t}\n\t\t} else {\n\t\t\tif !sct.Deployments[i].Failed {\n\t\t\t\tr.Equal(uint64(iotextypes.ReceiptStatus_Success), receipt.Status, i)\n\t\t\t} else {\n\t\t\t\tr.Equal(uint64(iotextypes.ReceiptStatus_Failure), receipt.Status, i)\n\t\t\t\treturn []string{}\n\t\t\t}\n\t\t}\n\t\tif sct.Deployments[i].ExpectedGasConsumed() != 0 {\n\t\t\tr.Equal(sct.Deployments[i].ExpectedGasConsumed(), receipt.GasConsumed)\n\t\t}\n\n\t\taddr, _ := address.FromString(receipt.ContractAddress)\n\t\tc, err := readCode(sf, addr.Bytes())\n\t\tr.NoError(err)\n\t\tif contract.AppendContractAddress {\n\t\t\tlenOfByteCode := len(contract.ByteCode())\n\t\t\tr.True(bytes.Contains(contract.ByteCode()[:lenOfByteCode-32], c))\n\t\t} else {\n\t\t\tr.True(bytes.Contains(sct.Deployments[i].ByteCode(), c))\n\t\t}\n\t\tcontractAddresses = append(contractAddresses, receipt.ContractAddress)\n\t}\n\treturn\n}\n\nfunc (sct *SmartContractTest) run(r *require.Assertions) {\n\t// prepare blockchain\n\tctx := context.Background()\n\tcfg := config.Default\n\tcfg.Chain.EnableTrielessStateDB = false\n\tbc, sf, dao, ap := sct.prepareBlockchain(ctx, cfg, r)\n\tdefer func() {\n\t\tr.NoError(bc.Stop(ctx))\n\t}()\n\n\t// deploy smart contract\n\tcontractAddresses := sct.deployContracts(bc, sf, dao, ap, r)\n\tif len(contractAddresses) == 0 {\n\t\treturn\n\t}\n\n\t// run executions\n\tfor i, exec := range sct.Executions {\n\t\tcontractAddr := contractAddresses[exec.ContractIndex]\n\t\tif exec.AppendContractAddress {\n\t\t\texec.ContractAddressToAppend = contractAddresses[exec.ContractIndexToAppend]\n\t\t}\n\t\tvar retval []byte\n\t\tvar receipt *action.Receipt\n\t\tvar err error\n\t\tif exec.ReadOnly {\n\t\t\tretval, receipt, err = readExecution(bc, sf, dao, ap, &exec, contractAddr)\n\t\t\tr.NoError(err)\n\t\t\texpected := exec.ExpectedReturnValue()\n\t\t\tif len(expected) == 0 {\n\t\t\t\tr.Equal(0, len(retval))\n\t\t\t} else {\n\t\t\t\tr.Equal(expected, retval)\n\t\t\t}\n\t\t} else {\n\t\t\treceipts, err := runExecutions(bc, sf, dao, ap, []*ExecutionConfig{&exec}, []string{contractAddr})\n\t\t\tr.NoError(err)\n\t\t\tr.Equal(1, len(receipts))\n\t\t\treceipt = receipts[0]\n\t\t\tr.NotNil(receipt)\n\t\t}\n\n\t\tif sct.InitGenesis.IsBering {\n\t\t\t// if it is post bering, it compares the status with expected status\n\t\t\tr.Equal(exec.ExpectedStatus, receipt.Status)\n\t\t} else {\n\t\t\tif exec.Failed {\n\t\t\t\tr.Equal(uint64(iotextypes.ReceiptStatus_Failure), receipt.Status)\n\t\t\t} else {\n\t\t\t\tr.Equal(uint64(iotextypes.ReceiptStatus_Success), receipt.Status)\n\t\t\t}\n\t\t}\n\t\tif exec.ExpectedGasConsumed() != 0 {\n\t\t\tr.Equal(exec.ExpectedGasConsumed(), receipt.GasConsumed, i)\n\t\t}\n\t\tfor _, expectedBalance := range exec.ExpectedBalances {\n\t\t\taccount := expectedBalance.Account\n\t\t\tif account == \"\" {\n\t\t\t\taccount = contractAddr\n\t\t\t}\n\t\t\tstate, err := accountutil.AccountState(sf, account)\n\t\t\tr.NoError(err)\n\t\t\tr.Equal(\n\t\t\t\t0,\n\t\t\t\tstate.Balance.Cmp(expectedBalance.Balance()),\n\t\t\t\t\"balance of account %s is different from expectation, %d vs %d\",\n\t\t\t\taccount,\n\t\t\t\tstate.Balance,\n\t\t\t\texpectedBalance.Balance(),\n\t\t\t)\n\t\t}\n\t\tif receipt.Status == uint64(iotextypes.ReceiptStatus_Success) {\n\t\t\tr.Equal(len(exec.ExpectedLogs), len(receipt.Logs()), i)\n\t\t\t// TODO: check value of logs\n\t\t}\n\t\tif receipt.Status == uint64(iotextypes.ReceiptStatus_ErrExecutionReverted) {\n\t\t\tr.Equal(exec.ExpectedErrorMsg, receipt.ExecutionRevertMsg())\n\t\t}\n\t}\n}\n\nfunc TestProtocol_Validate(t *testing.T) {\n\trequire := require.New(t)\n\tp := NewProtocol(func(uint64) (hash.Hash256, error) {\n\t\treturn hash.ZeroHash256, nil\n\t}, rewarding.DepositGas)\n\tdata := make([]byte, 32769)\n\n\tex, err := action.NewExecution(\"2\", uint64(1), big.NewInt(0), uint64(0), big.NewInt(0), data)\n\trequire.NoError(err)\n\trequire.Equal(action.ErrActPool, errors.Cause(p.Validate(context.Background(), ex, nil)))\n}\n\nfunc TestProtocol_Handle(t *testing.T) {\n\ttestEVM := func(t *testing.T) {\n\t\tlog.S().Info(\"Test EVM\")\n\t\trequire := require.New(t)\n\n\t\tctx := context.Background()\n\t\tcfg := config.Default\n\t\tdefer func() {\n\t\t\tdelete(cfg.Plugins, config.GatewayPlugin)\n\t\t}()\n\n\t\ttestTriePath, err := testutil.PathOfTempFile(\"trie\")\n\t\trequire.NoError(err)\n\t\ttestDBPath, err := testutil.PathOfTempFile(\"db\")\n\t\trequire.NoError(err)\n\t\ttestIndexPath, err := testutil.PathOfTempFile(\"index\")\n\t\trequire.NoError(err)\n\n\t\tcfg.Plugins[config.GatewayPlugin] = true\n\t\tcfg.Chain.TrieDBPath = testTriePath\n\t\tcfg.Chain.ChainDBPath = testDBPath\n\t\tcfg.Chain.IndexDBPath = testIndexPath\n\t\tcfg.Chain.EnableAsyncIndexWrite = false\n\t\tcfg.Genesis.EnableGravityChainVoting = false\n\t\tcfg.ActPool.MinGasPriceStr = \"0\"\n\t\tcfg.Genesis.InitBalanceMap[identityset.Address(27).String()] = unit.ConvertIotxToRau(1000000000).String()\n\t\tregistry := protocol.NewRegistry()\n\t\tacc := account.NewProtocol(rewarding.DepositGas)\n\t\trequire.NoError(acc.Register(registry))\n\t\trp := rolldpos.NewProtocol(cfg.Genesis.NumCandidateDelegates, cfg.Genesis.NumDelegates, cfg.Genesis.NumSubEpochs)\n\t\trequire.NoError(rp.Register(registry))\n\t\t// create state factory\n\t\tsf, err := factory.NewStateDB(cfg, factory.CachedStateDBOption(), factory.RegistryStateDBOption(registry))\n\t\trequire.NoError(err)\n\t\tap, err := actpool.NewActPool(sf, cfg.ActPool)\n\t\trequire.NoError(err)\n\t\t// create indexer\n\t\tcfg.DB.DbPath = cfg.Chain.IndexDBPath\n\t\tindexer, err := blockindex.NewIndexer(db.NewBoltDB(cfg.DB), hash.ZeroHash256)\n\t\trequire.NoError(err)\n\t\t// create BlockDAO\n\t\tcfg.DB.DbPath = cfg.Chain.ChainDBPath\n\t\tdao := blockdao.NewBlockDAOInMemForTest([]blockdao.BlockIndexer{sf, indexer})\n\t\trequire.NotNil(dao)\n\t\tbc := blockchain.NewBlockchain(\n\t\t\tcfg,\n\t\t\tdao,\n\t\t\tfactory.NewMinter(sf, ap),\n\t\t\tblockchain.BlockValidatorOption(block.NewValidator(\n\t\t\t\tsf,\n\t\t\t\tprotocol.NewGenericValidator(sf, accountutil.AccountState),\n\t\t\t)),\n\t\t)\n\t\texeProtocol := NewProtocol(dao.GetBlockHash, rewarding.DepositGas)\n\t\trequire.NoError(exeProtocol.Register(registry))\n\t\trequire.NoError(bc.Start(ctx))\n\t\trequire.NotNil(bc)\n\t\tdefer func() {\n\t\t\trequire.NoError(bc.Stop(ctx))\n\t\t}()\n\n\t\tdata, _ := hex.DecodeString(\"608060405234801561001057600080fd5b5060df8061001f6000396000f3006080604052600436106049576000357c0100000000000000000000000000000000000000000000000000000000900463ffffffff16806360fe47b114604e5780636d4ce63c146078575b600080fd5b348015605957600080fd5b5060766004803603810190808035906020019092919050505060a0565b005b348015608357600080fd5b50608a60aa565b6040518082815260200191505060405180910390f35b8060008190555050565b600080549050905600a165627a7a7230582002faabbefbbda99b20217cf33cb8ab8100caf1542bf1f48117d72e2c59139aea0029\")\n\t\texecution, err := action.NewExecution(action.EmptyAddress, 1, big.NewInt(0), uint64(100000), big.NewInt(0), data)\n\t\trequire.NoError(err)\n\n\t\tbd := &action.EnvelopeBuilder{}\n\t\telp := bd.SetAction(execution).\n\t\t\tSetNonce(1).\n\t\t\tSetGasLimit(100000).Build()\n\t\tselp, err := action.Sign(elp, identityset.PrivateKey(27))\n\t\trequire.NoError(err)\n\n\t\trequire.NoError(ap.Add(context.Background(), selp))\n\t\tblk, err := bc.MintNewBlock(testutil.TimestampNow())\n\t\trequire.NoError(err)\n\t\trequire.NoError(bc.CommitBlock(blk))\n\t\trequire.Equal(1, len(blk.Receipts))\n\n\t\teHash, err := selp.Hash()\n\t\trequire.NoError(err)\n\t\tr, _ := dao.GetReceiptByActionHash(eHash, blk.Height())\n\t\trequire.NotNil(r)\n\t\trequire.Equal(eHash, r.ActionHash)\n\t\tcontract, err := address.FromString(r.ContractAddress)\n\t\trequire.NoError(err)\n\n\t\t// test IsContract\n\t\tstate, err := accountutil.AccountState(sf, contract.String())\n\t\trequire.NoError(err)\n\t\trequire.True(state.IsContract())\n\n\t\tc, err := readCode(sf, contract.Bytes())\n\t\trequire.NoError(err)\n\t\trequire.Equal(data[31:], c)\n\n\t\texe, _, err := dao.GetActionByActionHash(eHash, blk.Height())\n\t\trequire.NoError(err)\n\t\texeHash, err := exe.Hash()\n\t\trequire.NoError(err)\n\t\trequire.Equal(eHash, exeHash)\n\n\t\taddr27 := hash.BytesToHash160(identityset.Address(27).Bytes())\n\t\ttotal, err := indexer.GetActionCountByAddress(addr27)\n\t\trequire.NoError(err)\n\t\texes, err := indexer.GetActionsByAddress(addr27, 0, total)\n\t\trequire.NoError(err)\n\t\trequire.Equal(1, len(exes))\n\t\trequire.Equal(eHash[:], exes[0])\n\n\t\tactIndex, err := indexer.GetActionIndex(eHash[:])\n\t\trequire.NoError(err)\n\t\tblkHash, err := dao.GetBlockHash(actIndex.BlockHeight())\n\t\trequire.NoError(err)\n\t\trequire.Equal(blk.HashBlock(), blkHash)\n\n\t\t// store to key 0\n\t\tdata, _ = hex.DecodeString(\"60fe47b1000000000000000000000000000000000000000000000000000000000000000f\")\n\t\texecution, err = action.NewExecution(r.ContractAddress, 2, big.NewInt(0), uint64(120000), big.NewInt(0), data)\n\t\trequire.NoError(err)\n\n\t\tbd = &action.EnvelopeBuilder{}\n\t\telp = bd.SetAction(execution).\n\t\t\tSetNonce(2).\n\t\t\tSetGasLimit(120000).Build()\n\t\tselp, err = action.Sign(elp, identityset.PrivateKey(27))\n\t\trequire.NoError(err)\n\n\t\tlog.S().Infof(\"execution %+v\", execution)\n\n\t\trequire.NoError(ap.Add(context.Background(), selp))\n\t\tblk, err = bc.MintNewBlock(testutil.TimestampNow())\n\t\trequire.NoError(err)\n\t\trequire.NoError(bc.CommitBlock(blk))\n\t\trequire.Equal(1, len(blk.Receipts))\n\n\t\t// TODO (zhi): reenable the unit test\n\t\t/*\n\t\t\tws, err = sf.NewWorkingSet()\n\t\t\trequire.NoError(err)\n\t\t\tstateDB = evm.NewStateDBAdapter(ws, uint64(0), true, hash.ZeroHash256)\n\t\t\tvar emptyEVMHash common.Hash\n\t\t\tv := stateDB.GetState(evmContractAddrHash, emptyEVMHash)\n\t\t\trequire.Equal(byte(15), v[31])\n\t\t*/\n\t\teHash, err = selp.Hash()\n\t\trequire.NoError(err)\n\t\tr, err = dao.GetReceiptByActionHash(eHash, blk.Height())\n\t\trequire.NoError(err)\n\t\trequire.Equal(eHash, r.ActionHash)\n\n\t\t// read from key 0\n\t\tdata, err = hex.DecodeString(\"6d4ce63c\")\n\t\trequire.NoError(err)\n\t\texecution, err = action.NewExecution(r.ContractAddress, 3, big.NewInt(0), uint64(120000), big.NewInt(0), data)\n\t\trequire.NoError(err)\n\n\t\tbd = &action.EnvelopeBuilder{}\n\t\telp = bd.SetAction(execution).\n\t\t\tSetNonce(3).\n\t\t\tSetGasLimit(120000).Build()\n\t\tselp, err = action.Sign(elp, identityset.PrivateKey(27))\n\t\trequire.NoError(err)\n\n\t\tlog.S().Infof(\"execution %+v\", execution)\n\t\trequire.NoError(ap.Add(context.Background(), selp))\n\t\tblk, err = bc.MintNewBlock(testutil.TimestampNow())\n\t\trequire.NoError(err)\n\t\trequire.NoError(bc.CommitBlock(blk))\n\t\trequire.Equal(1, len(blk.Receipts))\n\n\t\teHash, err = selp.Hash()\n\t\trequire.NoError(err)\n\t\tr, err = dao.GetReceiptByActionHash(eHash, blk.Height())\n\t\trequire.NoError(err)\n\t\trequire.Equal(eHash, r.ActionHash)\n\n\t\tdata, _ = hex.DecodeString(\"608060405234801561001057600080fd5b5060df8061001f6000396000f3006080604052600436106049576000357c0100000000000000000000000000000000000000000000000000000000900463ffffffff16806360fe47b114604e5780636d4ce63c146078575b600080fd5b348015605957600080fd5b5060766004803603810190808035906020019092919050505060a0565b005b348015608357600080fd5b50608a60aa565b6040518082815260200191505060405180910390f35b8060008190555050565b600080549050905600a165627a7a7230582002faabbefbbda99b20217cf33cb8ab8100caf1542bf1f48117d72e2c59139aea0029\")\n\t\texecution1, err := action.NewExecution(action.EmptyAddress, 4, big.NewInt(0), uint64(100000), big.NewInt(10), data)\n\t\trequire.NoError(err)\n\t\tbd = &action.EnvelopeBuilder{}\n\n\t\telp = bd.SetAction(execution1).\n\t\t\tSetNonce(4).\n\t\t\tSetGasLimit(100000).SetGasPrice(big.NewInt(10)).Build()\n\t\tselp, err = action.Sign(elp, identityset.PrivateKey(27))\n\t\trequire.NoError(err)\n\n\t\trequire.NoError(ap.Add(context.Background(), selp))\n\t\tblk, err = bc.MintNewBlock(testutil.TimestampNow())\n\t\trequire.NoError(err)\n\t\trequire.NoError(bc.CommitBlock(blk))\n\t\trequire.Equal(1, len(blk.Receipts))\n\t}\n\n\tt.Run(\"EVM\", func(t *testing.T) {\n\t\ttestEVM(t)\n\t})\n\t/**\n\t * source of smart contract: https://etherscan.io/address/0x6fb3e0a217407efff7ca062d46c26e5d60a14d69#code\n\t */\n\tt.Run(\"ERC20\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/erc20.json\")\n\t})\n\t/**\n\t * Source of smart contract: https://etherscan.io/address/0x8dd5fbce2f6a956c3022ba3663759011dd51e73e#code\n\t */\n\tt.Run(\"DelegateERC20\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/delegate_erc20.json\")\n\t})\n\t/*\n\t * Source code: https://kovan.etherscan.io/address/0x81f85886749cbbf3c2ec742db7255c6b07c63c69\n\t */\n\tt.Run(\"InfiniteLoop\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/infiniteloop.json\")\n\t})\n\t// RollDice\n\tt.Run(\"RollDice\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/rolldice.json\")\n\t})\n\t// ChangeState\n\tt.Run(\"ChangeState\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/changestate.json\")\n\t})\n\t// array-return\n\tt.Run(\"ArrayReturn\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/array-return.json\")\n\t})\n\t// basic-token\n\tt.Run(\"BasicToken\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/basic-token.json\")\n\t})\n\t// call-dynamic\n\tt.Run(\"CallDynamic\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/call-dynamic.json\")\n\t})\n\t// factory\n\tt.Run(\"Factory\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/factory.json\")\n\t})\n\t// mapping-delete\n\tt.Run(\"MappingDelete\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/mapping-delete.json\")\n\t})\n\t// f.value\n\tt.Run(\"F.value\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/f.value.json\")\n\t})\n\t// proposal\n\tt.Run(\"Proposal\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/proposal.json\")\n\t})\n\t// public-length\n\tt.Run(\"PublicLength\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/public-length.json\")\n\t})\n\t// public-mapping\n\tt.Run(\"PublicMapping\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/public-mapping.json\")\n\t})\n\t// no-variable-length-returns\n\tt.Run(\"NoVariableLengthReturns\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/no-variable-length-returns.json\")\n\t})\n\t// tuple\n\tt.Run(\"Tuple\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/tuple.json\")\n\t})\n\t// tail-recursion\n\tt.Run(\"TailRecursion\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/tail-recursion.json\")\n\t})\n\t// sha3\n\tt.Run(\"Sha3\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/sha3.json\")\n\t})\n\t// remove-from-array\n\tt.Run(\"RemoveFromArray\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/remove-from-array.json\")\n\t})\n\t// send-eth\n\tt.Run(\"SendEth\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/send-eth.json\")\n\t})\n\t// modifier\n\tt.Run(\"Modifier\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/modifiers.json\")\n\t})\n\t// multisend\n\tt.Run(\"Multisend\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/multisend.json\")\n\t})\n\tt.Run(\"Multisend2\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/multisend2.json\")\n\t})\n\t// reentry\n\tt.Run(\"reentry-attack\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/reentry-attack.json\")\n\t})\n\t// cashier\n\tt.Run(\"cashier\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/cashier.json\")\n\t})\n\t// wireconnection\n\t// [Issue #1422] This unit test proves that there is no problem when we want to deploy and execute the contract\n\t// which inherits abstract contract and implements abstract functions and call each other (Utterance() calls utterance())\n\tt.Run(\"wireconnection\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/wireconnection.json\")\n\t})\n\t// gas-test\n\tt.Run(\"gas-test\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/gas-test.json\")\n\t})\n\t// storage-test\n\tt.Run(\"storage-test\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/storage-test.json\")\n\t})\n\t// cashier-bering\n\tt.Run(\"cashier-bering\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/cashier-bering.json\")\n\t})\n\t// infiniteloop-bering\n\tt.Run(\"infiniteloop-bering\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/infiniteloop-bering.json\")\n\t})\n\t// self-destruct\n\tt.Run(\"self-destruct\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/self-destruct.json\")\n\t})\n}\n\nfunc TestMaxTime(t *testing.T) {\n\tt.Run(\"max-time\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/maxtime.json\")\n\t})\n\n\tt.Run(\"max-time-2\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata/maxtime2.json\")\n\t})\n}\n\nfunc TestIstanbulEVM(t *testing.T) {\n\tcfg := config.Default\n\tconfig.SetEVMNetworkID(cfg.Chain.EVMNetworkID)\n\tt.Run(\"ArrayReturn\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata-istanbul/array-return.json\")\n\t})\n\tt.Run(\"BasicToken\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata-istanbul/basic-token.json\")\n\t})\n\tt.Run(\"CallDynamic\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata-istanbul/call-dynamic.json\")\n\t})\n\tt.Run(\"chainid-selfbalance\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata-istanbul/chainid-selfbalance.json\")\n\t})\n\tt.Run(\"ChangeState\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata-istanbul/changestate.json\")\n\t})\n\tt.Run(\"F.value\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata-istanbul/f.value.json\")\n\t})\n\tt.Run(\"Gas-test\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata-istanbul/gas-test.json\")\n\t})\n\tt.Run(\"InfiniteLoop\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata-istanbul/infiniteloop.json\")\n\t})\n\tt.Run(\"MappingDelete\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata-istanbul/mapping-delete.json\")\n\t})\n\tt.Run(\"max-time\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata-istanbul/maxtime.json\")\n\t})\n\tt.Run(\"Modifier\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata-istanbul/modifiers.json\")\n\t})\n\tt.Run(\"Multisend\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata-istanbul/multisend.json\")\n\t})\n\tt.Run(\"NoVariableLengthReturns\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata-istanbul/no-variable-length-returns.json\")\n\t})\n\tt.Run(\"PublicMapping\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata-istanbul/public-mapping.json\")\n\t})\n\tt.Run(\"reentry-attack\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata-istanbul/reentry-attack.json\")\n\t})\n\tt.Run(\"RemoveFromArray\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata-istanbul/remove-from-array.json\")\n\t})\n\tt.Run(\"SendEth\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata-istanbul/send-eth.json\")\n\t})\n\tt.Run(\"Sha3\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata-istanbul/sha3.json\")\n\t})\n\tt.Run(\"storage-test\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata-istanbul/storage-test.json\")\n\t})\n\tt.Run(\"TailRecursion\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata-istanbul/tail-recursion.json\")\n\t})\n\tt.Run(\"Tuple\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata-istanbul/tuple.json\")\n\t})\n\tt.Run(\"wireconnection\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata-istanbul/wireconnection.json\")\n\t})\n\tt.Run(\"self-destruct\", func(t *testing.T) {\n\t\tNewSmartContractTest(t, \"testdata-istanbul/self-destruct.json\")\n\t})\n}\n\nfunc benchmarkHotContractWithFactory(b *testing.B, async bool) {\n\tsct := SmartContractTest{\n\t\tInitBalances: []ExpectedBalance{\n\t\t\t{\n\t\t\t\tAccount:    \"io1mflp9m6hcgm2qcghchsdqj3z3eccrnekx9p0ms\",\n\t\t\t\tRawBalance: \"1000000000000000000000000000\",\n\t\t\t},\n\t\t},\n\t\tDeployments: []ExecutionConfig{\n\t\t\t{\n\t\t\t\tContractIndex: 0,\n\t\t\t\tRawPrivateKey: \"cfa6ef757dee2e50351620dca002d32b9c090cfda55fb81f37f1d26b273743f1\",\n\t\t\t\tRawByteCode:   \"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\",\n\t\t\t\tRawAmount:     \"0\",\n\t\t\t\tRawGasLimit:   5000000,\n\t\t\t\tRawGasPrice:   \"0\",\n\t\t\t},\n\t\t},\n\t}\n\tr := require.New(b)\n\tctx := context.Background()\n\tcfg := config.Default\n\tcfg.Genesis.NumSubEpochs = uint64(b.N)\n\tcfg.Chain.EnableTrielessStateDB = false\n\tif async {\n\t\tcfg.Genesis.GreenlandBlockHeight = 0\n\t} else {\n\t\tcfg.Genesis.GreenlandBlockHeight = 10000000000\n\t}\n\tbc, sf, dao, ap := sct.prepareBlockchain(ctx, cfg, r)\n\tdefer func() {\n\t\tr.NoError(bc.Stop(ctx))\n\t}()\n\tcontractAddresses := sct.deployContracts(bc, sf, dao, ap, r)\n\tr.Equal(1, len(contractAddresses))\n\tcontractAddr := contractAddresses[0]\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\treceipts, err := runExecutions(\n\t\t\tbc, sf, dao, ap, []*ExecutionConfig{\n\t\t\t\t{\n\t\t\t\t\tRawPrivateKey: \"cfa6ef757dee2e50351620dca002d32b9c090cfda55fb81f37f1d26b273743f1\",\n\t\t\t\t\tRawByteCode:   \"1249c58b\",\n\t\t\t\t\tRawAmount:     \"0\",\n\t\t\t\t\tRawGasLimit:   5000000,\n\t\t\t\t\tRawGasPrice:   \"0\",\n\t\t\t\t\tFailed:        false,\n\t\t\t\t\tComment:       \"mint token\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t[]string{contractAddr},\n\t\t)\n\t\tr.NoError(err)\n\t\tr.Equal(1, len(receipts))\n\t\tr.Equal(uint64(1), receipts[0].Status)\n\t\tecfgs := []*ExecutionConfig{}\n\t\tcontractAddrs := []string{}\n\t\tfor j := 0; j < 100; j++ {\n\t\t\tecfgs = append(ecfgs, &ExecutionConfig{\n\t\t\t\tRawPrivateKey: \"cfa6ef757dee2e50351620dca002d32b9c090cfda55fb81f37f1d26b273743f1\",\n\t\t\t\tRawByteCode:   fmt.Sprintf(\"a9059cbb000000000000000000000000123456789012345678900987%016x0000000000000000000000000000000000000000000000000000000000000039\", 100*i+j),\n\t\t\t\tRawAmount:     \"0\",\n\t\t\t\tRawGasLimit:   5000000,\n\t\t\t\tRawGasPrice:   \"0\",\n\t\t\t\tFailed:        false,\n\t\t\t\tComment:       \"send token\",\n\t\t\t})\n\t\t\tcontractAddrs = append(contractAddrs, contractAddr)\n\t\t}\n\t\treceipts, err = runExecutions(bc, sf, dao, ap, ecfgs, contractAddrs)\n\t\tr.NoError(err)\n\t\tfor _, receipt := range receipts {\n\t\t\tr.Equal(uint64(1), receipt.Status)\n\t\t}\n\t}\n\tb.StopTimer()\n}\n\nfunc benchmarkHotContractWithStateDB(b *testing.B, cachedStateDBOption bool) {\n\tsct := SmartContractTest{\n\t\tInitBalances: []ExpectedBalance{\n\t\t\t{\n\t\t\t\tAccount:    \"io1mflp9m6hcgm2qcghchsdqj3z3eccrnekx9p0ms\",\n\t\t\t\tRawBalance: \"1000000000000000000000000000\",\n\t\t\t},\n\t\t},\n\t\tDeployments: []ExecutionConfig{\n\t\t\t{\n\t\t\t\tContractIndex: 0,\n\t\t\t\tRawPrivateKey: \"cfa6ef757dee2e50351620dca002d32b9c090cfda55fb81f37f1d26b273743f1\",\n\t\t\t\tRawByteCode:   \"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\",\n\t\t\t\tRawAmount:     \"0\",\n\t\t\t\tRawGasLimit:   5000000,\n\t\t\t\tRawGasPrice:   \"0\",\n\t\t\t},\n\t\t},\n\t}\n\tr := require.New(b)\n\tctx := context.Background()\n\tcfg := config.Default\n\tcfg.Genesis.NumSubEpochs = uint64(b.N)\n\tif cachedStateDBOption {\n\t\tcfg.Chain.EnableStateDBCaching = true\n\t} else {\n\t\tcfg.Chain.EnableStateDBCaching = false\n\t}\n\tbc, sf, dao, ap := sct.prepareBlockchain(ctx, cfg, r)\n\tdefer func() {\n\t\tr.NoError(bc.Stop(ctx))\n\t}()\n\tcontractAddresses := sct.deployContracts(bc, sf, dao, ap, r)\n\tr.Equal(1, len(contractAddresses))\n\tcontractAddr := contractAddresses[0]\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\treceipts, err := runExecutions(\n\t\t\tbc, sf, dao, ap, []*ExecutionConfig{\n\t\t\t\t{\n\t\t\t\t\tRawPrivateKey: \"cfa6ef757dee2e50351620dca002d32b9c090cfda55fb81f37f1d26b273743f1\",\n\t\t\t\t\tRawByteCode:   \"1249c58b\",\n\t\t\t\t\tRawAmount:     \"0\",\n\t\t\t\t\tRawGasLimit:   5000000,\n\t\t\t\t\tRawGasPrice:   \"0\",\n\t\t\t\t\tFailed:        false,\n\t\t\t\t\tComment:       \"mint token\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t[]string{contractAddr},\n\t\t)\n\t\tr.NoError(err)\n\t\tr.Equal(1, len(receipts))\n\t\tr.Equal(uint64(1), receipts[0].Status)\n\t\tecfgs := []*ExecutionConfig{}\n\t\tcontractAddrs := []string{}\n\t\tfor j := 0; j < 100; j++ {\n\t\t\tecfgs = append(ecfgs, &ExecutionConfig{\n\t\t\t\tRawPrivateKey: \"cfa6ef757dee2e50351620dca002d32b9c090cfda55fb81f37f1d26b273743f1\",\n\t\t\t\tRawByteCode:   fmt.Sprintf(\"a9059cbb000000000000000000000000123456789012345678900987%016x0000000000000000000000000000000000000000000000000000000000000039\", 100*i+j),\n\t\t\t\tRawAmount:     \"0\",\n\t\t\t\tRawGasLimit:   5000000,\n\t\t\t\tRawGasPrice:   \"0\",\n\t\t\t\tFailed:        false,\n\t\t\t\tComment:       \"send token\",\n\t\t\t})\n\t\t\tcontractAddrs = append(contractAddrs, contractAddr)\n\t\t}\n\t\treceipts, err = runExecutions(bc, sf, dao, ap, ecfgs, contractAddrs)\n\t\tr.NoError(err)\n\t\tfor _, receipt := range receipts {\n\t\t\tr.Equal(uint64(1), receipt.Status)\n\t\t}\n\t}\n\tb.StopTimer()\n}\n\nfunc BenchmarkHotContract(b *testing.B) {\n\tb.Run(\"async mode\", func(b *testing.B) {\n\t\tbenchmarkHotContractWithFactory(b, true)\n\t})\n\tb.Run(\"sync mode\", func(b *testing.B) {\n\t\tbenchmarkHotContractWithFactory(b, false)\n\t})\n\tb.Run(\"cachedStateDB\", func(b *testing.B) {\n\t\tbenchmarkHotContractWithStateDB(b, true)\n\t})\n\tb.Run(\"defaultStateDB\", func(b *testing.B) {\n\t\tbenchmarkHotContractWithStateDB(b, false)\n\t})\n}\n", "idx": 4, "id": 23785, "msg": "", "proj": "iotexproject-iotex-core", "lang": "go"}
